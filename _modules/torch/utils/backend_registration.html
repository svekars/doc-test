
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>torch.utils.backend_registration &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=949a1ff5" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/jit.css?v=8de1ea5d" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css?v=3ccf5357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom2.css?v=baa440dc" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=a8da1a53"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=940804e7"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/torch/utils/backend_registration';</script>
    <script src="../../../_static/js/star-rating.js?v=8861fcb6"></script>
    <script src="../../../_static/js/send-feedback.js?v=5646bf45"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="main (2.6.0 )" />
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script type="text/javascript" src="../../../_static/js/send-feedback.js"></script>
<script type="text/javascript" src="../../../_static/js/star-rating.js"></script>
<script type="text/javascript" src="../../../_static/js/cookie-banner.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-TEST12345"></script>
    <script type="text/javascript">
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-TEST12345');
    </script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
<body data-feedback-url="https://github.com/pytorch/pytorch">
  <div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later.
          <li>
            <div class="main-menu-item">
             <a href="" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Home</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../python-api/index.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../notes/index.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../python-api/index.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../notes/index.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    
    <li class="breadcrumb-item"><a href="../../torch.html" class="nav-link">torch</a></li>
    
    
    <li class="breadcrumb-item"><a href="../utils.html" class="nav-link">torch.utils</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">torch.utils.backend_registration</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-value="1">★</span>
        
        <span class="star" data-value="2">★</span>
        
        <span class="star" data-value="3">★</span>
        
        <span class="star" data-value="4">★</span>
        
        <span class="star" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for torch.utils.backend_registration</h1><div class="highlight"><pre>
<span></span><span class="c1"># mypy: allow-untyped-defs</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.overrides</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">handle_torch_function</span><span class="p">,</span>
    <span class="n">has_torch_function_unary</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._C</span><span class="w"> </span><span class="kn">import</span> <span class="n">_rename_privateuse1_backend</span><span class="p">,</span> <span class="n">_get_privateuse1_backend_name</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;rename_privateuse1_backend&quot;</span><span class="p">,</span> <span class="s2">&quot;generate_methods_for_privateuse1_backend&quot;</span><span class="p">]</span>

<span class="c1"># TODO: Should use `torch._C._get_privateuse1_backend_name()` to get</span>
<span class="c1"># renamed-backend name for `privateuse1`, but the func will cause an</span>
<span class="c1"># error with torch.jit.script, so we use the global variable named</span>
<span class="c1"># `_privateuse1_backend_name`.</span>
<span class="n">_privateuse1_backend_name</span> <span class="o">=</span> <span class="s2">&quot;privateuseone&quot;</span>

<div class="viewcode-block" id="rename_privateuse1_backend">
<a class="viewcode-back" href="../../../python-api/generated/torch.utils.rename_privateuse1_backend.html#torch.utils.rename_privateuse1_backend">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">rename_privateuse1_backend</span><span class="p">(</span><span class="n">backend_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rename the privateuse1 backend device to make it more convenient to use as a device name within PyTorch APIs.</span>

<span class="sd">    The steps are:</span>

<span class="sd">    (1) (In C++) implement kernels for various torch operations, and register them</span>
<span class="sd">        to the PrivateUse1 dispatch key.</span>
<span class="sd">    (2) (In python) call torch.utils.rename_privateuse1_backend(&quot;foo&quot;)</span>

<span class="sd">    You can now use &quot;foo&quot; as an ordinary device string in python.</span>

<span class="sd">    Note: this API can only be called once per process. Attempting to change</span>
<span class="sd">    the external backend after it&#39;s already been set will result in an error.</span>

<span class="sd">    Note(AMP): If you want to support AMP on your device, you can register a custom backend module.</span>
<span class="sd">    The backend must register a custom backend module with ``torch._register_device_module(&quot;foo&quot;, BackendModule)``.</span>
<span class="sd">    BackendModule needs to have the following API&#39;s:</span>

<span class="sd">    (1) ``get_amp_supported_dtype() -&gt; List[torch.dtype]``</span>
<span class="sd">        get the supported dtypes on your &quot;foo&quot; device in AMP, maybe the &quot;foo&quot; device supports one more dtype.</span>

<span class="sd">    Note(random): If you want to support to set seed for your device, BackendModule needs to have the following API&#39;s:</span>

<span class="sd">    (1) ``_is_in_bad_fork() -&gt; bool``</span>
<span class="sd">        Return ``True`` if now it is in bad_fork, else return ``False``.</span>

<span class="sd">    (2) ``manual_seed_all(seed int) -&gt; None``</span>
<span class="sd">        Sets the seed for generating random numbers for your devices.</span>

<span class="sd">    (3) ``device_count() -&gt; int``</span>
<span class="sd">        Returns the number of &quot;foo&quot;s available.</span>

<span class="sd">    (4) ``get_rng_state(device: Union[int, str, torch.device] = &#39;foo&#39;) -&gt; Tensor``</span>
<span class="sd">        Returns a list of ByteTensor representing the random number states of all devices.</span>

<span class="sd">    (5) ``set_rng_state(new_state: Tensor, device: Union[int, str, torch.device] = &#39;foo&#39;) -&gt; None``</span>
<span class="sd">        Sets the random number generator state of the specified &quot;foo&quot; device.</span>

<span class="sd">    And there are some common funcs:</span>

<span class="sd">    (1) ``is_available() -&gt; bool``</span>
<span class="sd">        Returns a bool indicating if &quot;foo&quot; is currently available.</span>

<span class="sd">    (2) ``current_device() -&gt; int``</span>
<span class="sd">        Returns the index of a currently selected device.</span>

<span class="sd">    For more details, see https://pytorch.org/tutorials/advanced/extend_dispatcher.html#get-a-dispatch-key-for-your-backend</span>
<span class="sd">    For an existing example, see https://github.com/bdhirsh/pytorch_open_registration_example</span>

<span class="sd">    Example::</span>

<span class="sd">        &gt;&gt;&gt; # xdoctest: +SKIP(&quot;failing&quot;)</span>
<span class="sd">        &gt;&gt;&gt; torch.utils.rename_privateuse1_backend(&quot;foo&quot;)</span>
<span class="sd">        # This will work, assuming that you&#39;ve implemented the right C++ kernels</span>
<span class="sd">        # to implement torch.ones.</span>
<span class="sd">        &gt;&gt;&gt; a = torch.ones(2, device=&quot;foo&quot;)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_rename_privateuse1_backend</span><span class="p">(</span><span class="n">backend_name</span><span class="p">)</span>
    <span class="k">global</span> <span class="n">_privateuse1_backend_name</span>
    <span class="n">_privateuse1_backend_name</span> <span class="o">=</span> <span class="n">backend_name</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_check_register_once</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The custom device module of </span><span class="si">{</span><span class="n">module</span><span class="si">}</span><span class="s2"> has already been registered with </span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_normalization_device</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_get_current_device_index</span><span class="p">():</span>
        <span class="n">_get_device_index</span> <span class="o">=</span> <span class="s2">&quot;current_device&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">)</span> <span class="ow">and</span> \
                <span class="nb">hasattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">),</span> <span class="n">_get_device_index</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">),</span> <span class="n">_get_device_index</span><span class="p">)()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># The default device index is 0.</span>
            <span class="k">return</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_get_current_device_index</span><span class="p">()</span>
    <span class="c1"># if isinstance(device, str), this means that the parameter passed in is in the string format &quot;foo:0&quot;</span>
    <span class="c1"># convert str object to torch.device object, and then process it uniformly</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># variable devcie can only be torch.device type or int type</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="n">custom_backend_name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid device, must be </span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2"> device&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">device</span><span class="o">.</span><span class="n">index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device_idx</span> <span class="o">=</span> <span class="n">_get_current_device_index</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">device_idx</span> <span class="o">=</span> <span class="n">device</span><span class="o">.</span><span class="n">index</span>
    <span class="c1"># if isinstance(device, int), we can take the index number directly</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">device_idx</span> <span class="o">=</span> <span class="n">device</span>
    <span class="k">return</span> <span class="n">device_idx</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_generate_tensor_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nd">@property</span>  <span class="c1"># type: ignore[misc]</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_tensor_backend</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">has_torch_function_unary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="c1"># TODO mypy doesn&#39;t support @property, see: https://github.com/python/mypy/issues/6185</span>
            <span class="k">return</span> <span class="n">handle_torch_function</span><span class="p">(</span><span class="n">wrap_tensor_backend</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="p">,),</span> <span class="bp">self</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">custom_backend_name</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">wrap_tensor_backend</span><span class="o">.</span><span class="n">fget</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span>  <span class="c1"># type: ignore[attr-defined]</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">wrap_tensor_backend</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_tensor_to</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                       <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform Tensor device conversion. Call the to operator implementation.</span>

<span class="sd">        .. note::</span>
<span class="sd">            If the ``self`` Tensor already</span>
<span class="sd">            has the correct :class:`torch.device`, then ``self`` is returned.</span>
<span class="sd">            Otherwise, the returned tensor is a copy of ``self`` with the desired :class:`torch.device`.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (int, optional): if specified, all parameters will be copied to that device</span>
<span class="sd">            non_blocking (bool): If ``True`` and the source is in pinned memory,</span>
<span class="sd">                the copy will be asynchronous with respect to the host. Otherwise,</span>
<span class="sd">                the argument has no effect.</span>
<span class="sd">            **kwargs (dict): For compatibility, may contain the key ``memory_format`` argument.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">has_torch_function_unary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">handle_torch_function</span><span class="p">(</span><span class="n">wrap_tensor_to</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="p">,),</span> <span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">device_idx</span> <span class="o">=</span> <span class="n">_normalization_device</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">device_idx</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">),</span> <span class="n">non_blocking</span><span class="o">=</span><span class="n">non_blocking</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">)</span>
    <span class="n">wrap_tensor_to</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="n">custom_backend_name</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">,</span> <span class="n">wrap_tensor_to</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_generate_module_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># Generate Module attributes and methods depends on Tensor methods,</span>
    <span class="c1"># so we need to check whether Tensor methods is already registered.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Can not automatically generate </span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2">() method for torch.nn.Module.&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Because torch.Tensor doesn&#39;t has the method </span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2">().&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;For this error, you can try setting for_tensor=True.&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_module_to</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                       <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">T</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Move all model parameters and buffers to the custom device.</span>

<span class="sd">        This also makes associated parameters and buffers different objects. So</span>
<span class="sd">        it should be called before constructing optimizer if the module will</span>
<span class="sd">        live on device while being optimized.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This method modifies the module in-place.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (int, optional): if specified, all parameters will be copied to that device</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">)(</span><span class="n">device</span><span class="p">))</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">,</span> <span class="n">wrap_module_to</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_generate_packed_sequence_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># Generate PackedSequence Module attributes and methods depends on Tensor methods,</span>
    <span class="c1"># so we need to check whether Tensor methods is already registered.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span> <span class="ow">or</span> \
       <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Can not automatically generate is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2">() or &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2">() method for torch.nn.utils.rnn.PackedSequence.&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Because torch.Tensor doesn&#39;t has the method is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2">()&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;or </span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2">().&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;For this error, you can try setting for_tensor=True.&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>  <span class="c1"># type: ignore[misc]</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_tensor_backend</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">PackedSequence</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">custom_backend_name</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">PackedSequence</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">PackedSequence</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">wrap_tensor_backend</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_module_to</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">PackedSequence</span><span class="p">,</span>
                       <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">PackedSequence</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Move all model parameters and buffers to the custom device.</span>

<span class="sd">        This also makes associated parameters and buffers different objects. So</span>
<span class="sd">        it should be called before constructing optimizer if the module will</span>
<span class="sd">        live on device while being optimized.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This method modifies the module in-place.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (int, optional): if specified, all parameters will be copied to that device</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ex</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ex</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">custom_backend_name</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">custom_backend_name</span><span class="p">})</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">PackedSequence</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">PackedSequence</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">,</span> <span class="n">wrap_module_to</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">_generate_storage_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                                                      <span class="n">unsupported_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># Attribute is registered in the _StorageBase class</span>
    <span class="c1"># and UntypedStorage obtains through inheritance.</span>
    <span class="nd">@property</span>  <span class="c1"># type: ignore[misc]</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_storage_backend</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">_StorageBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the internal :class:`torch.UntypedStorage`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">custom_backend_name</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">_StorageBase</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">_StorageBase</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">wrap_storage_backend</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_storage_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return a copy of this object in custom device memory.</span>

<span class="sd">        If this object is already in device memory and on the correct device, then</span>
<span class="sd">        no copy is performed and the original object is returned.</span>

<span class="sd">        Args:</span>
<span class="sd">            device (int): The destination device id. Defaults to the current device.</span>
<span class="sd">            non_blocking (bool): If ``True`` and the source is in pinned memory,</span>
<span class="sd">            the copy will be asynchronous with respect to the host. Otherwise,</span>
<span class="sd">            the argument has no effect.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># There should be a judgment related to storage device and a judgment related to storage type,</span>
        <span class="c1"># but it depends on the extended function, so this part is temporarily omitted in the automatic generation.</span>
        <span class="n">device_idx</span> <span class="o">=</span> <span class="n">_normalization_device</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">):</span>
            <span class="c1"># storage has already on expected device.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span> <span class="o">==</span> <span class="n">device_idx</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span>
        <span class="c1"># For sparse storage, custom need to extend the implementation by themselves.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Can not support a sparse storage move to </span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2"> backend&quot;</span><span class="p">)</span>
        <span class="c1"># create untyped_storage and copy data</span>
        <span class="n">untyped_storage</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">UntypedStorage</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">:</span><span class="si">{</span><span class="n">device_idx</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">untyped_storage</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">untyped_storage</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">_StorageBase</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">_StorageBase</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">,</span> <span class="n">wrap_storage_to</span><span class="p">)</span>

    <span class="c1"># Register the corresponding attribute for the TypedStorage class.</span>
    <span class="c1"># When the TypedStorage class is removed, the registration is also removed.</span>

    <span class="nd">@property</span>  <span class="c1"># type: ignore[misc]</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_typed_storage_backend</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">TypedStorage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">_warn_typed_storage_removal</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_untyped_storage</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="n">custom_backend_name</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">TypedStorage</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">TypedStorage</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;is_</span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">wrap_typed_storage_backend</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">wrap_typed_storage_to</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">TypedStorage</span><span class="p">,</span>
                              <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">TypedStorage</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">_warn_typed_storage_removal</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">unsupported_dtype</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="n">unsupported_dtype</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot create </span><span class="si">{</span><span class="n">custom_backend_name</span><span class="si">}</span><span class="s2"> storage &quot;</span>
                               <span class="sa">f</span><span class="s2">&quot;as </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> dtype is not supported by this backend&quot;</span><span class="p">)</span>
        <span class="n">custom_backend_storage</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">UntypedStorage</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_untyped_storage</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">)(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_wrapped_storage</span><span class="p">(</span><span class="n">custom_backend_storage</span><span class="p">)</span>

    <span class="n">_check_register_once</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">TypedStorage</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">TypedStorage</span><span class="p">,</span> <span class="n">custom_backend_name</span><span class="p">,</span> <span class="n">wrap_typed_storage_to</span><span class="p">)</span>


<div class="viewcode-block" id="generate_methods_for_privateuse1_backend">
<a class="viewcode-back" href="../../../python-api/generated/torch.utils.generate_methods_for_privateuse1_backend.html#torch.utils.generate_methods_for_privateuse1_backend">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">generate_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">for_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">for_module</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                                             <span class="n">for_packed_sequence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                                             <span class="n">for_storage</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                             <span class="n">unsupported_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Automatically generate attributes and methods for the custom backend after rename privateuse1 backend.</span>

<span class="sd">    In the default scenario, storage-related methods will not be generated automatically.</span>

<span class="sd">    When you implement kernels for various torch operations, and register them to the PrivateUse1 dispatch key.</span>
<span class="sd">    And call the function torch.rename_privateuse1_backend(&quot;foo&quot;) to rename your backend name.</span>
<span class="sd">    At this point, you can easily register specific methods and attributes by calling this function.</span>
<span class="sd">    Just like torch.Tensor.foo(), torch.Tensor.is_foo, torch.Storage.foo(), torch.Storage.is_foo.</span>

<span class="sd">    Note: We recommend you use generic functions (check devices are equal or to(device=)).</span>
<span class="sd">    We provide these methods for convenience only and they will be &quot;monkey patched&quot; onto the objects</span>
<span class="sd">    and so will not be properly typed. For Storage methods generate, if you need to support sparse data storage,</span>
<span class="sd">    you need to extend the implementation yourself.</span>

<span class="sd">    Args:</span>
<span class="sd">        for_tensor (bool): whether register related methods for torch.Tensor class.</span>
<span class="sd">        for_module (bool): whether register related methods for torch.nn.Module class.</span>
<span class="sd">        for_storage (bool): whether register related methods for torch.Storage class.</span>
<span class="sd">        unsupported_dtype (List[torch.dtype]): takes effect only when the storage method needs to be generated,</span>
<span class="sd">            indicating that the storage does not support the torch.dtype type.</span>

<span class="sd">    Example::</span>

<span class="sd">        &gt;&gt;&gt; # xdoctest: +SKIP(&quot;failing&quot;)</span>
<span class="sd">        &gt;&gt;&gt; torch.utils.rename_privateuse1_backend(&quot;foo&quot;)</span>
<span class="sd">        &gt;&gt;&gt; torch.utils.generate_methods_for_privateuse1_backend()</span>
<span class="sd">        # Then automatically generate backend-related attributes and methods.</span>
<span class="sd">        &gt;&gt;&gt; a = torch.tensor(2).foo()</span>
<span class="sd">        &gt;&gt;&gt; a.is_foo</span>
<span class="sd">        &gt;&gt;&gt; hasattr(torch.nn.Module, &#39;foo&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">custom_backend_name</span> <span class="o">=</span> <span class="n">_get_privateuse1_backend_name</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">for_tensor</span><span class="p">:</span>
        <span class="n">_generate_tensor_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">for_module</span><span class="p">:</span>
        <span class="n">_generate_module_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">for_storage</span><span class="p">:</span>
        <span class="n">_generate_storage_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">,</span> <span class="n">unsupported_dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">for_packed_sequence</span><span class="p">:</span>
        <span class="n">_generate_packed_sequence_methods_for_privateuse1_backend</span><span class="p">(</span><span class="n">custom_backend_name</span><span class="p">)</span></div>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_custom_mod_func</span><span class="p">(</span><span class="n">func_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the func named `func_name` defined in custom device module. If not defined,</span>
<span class="sd">    return `None`. And the func is registered with `torch.utils.rename_privateuse1_backend(&#39;foo&#39;)`</span>
<span class="sd">    and `torch._register_device_module(&#39;foo&#39;, BackendModule)`.</span>
<span class="sd">    If the custom device module or the func is not defined, it will give warning or error message.</span>
<span class="sd">    Args:</span>
<span class="sd">        func_name (str): return the callable func named func_name defined in custom device module.</span>
<span class="sd">    Example::</span>
<span class="sd">        class DummyfooModule:</span>
<span class="sd">            @staticmethod</span>
<span class="sd">            def is_available():</span>
<span class="sd">                return True</span>
<span class="sd">            @staticmethod</span>
<span class="sd">            def func_name(*args, **kwargs):</span>
<span class="sd">                ....</span>
<span class="sd">        torch.utils.rename_privateuse1_backend(&quot;foo&quot;)</span>
<span class="sd">        torch._register_device_module(&quot;foo&quot;, DummyfooModule)</span>
<span class="sd">        foo_is_available_func = torch.utils.backend_registration._get_custom_mod_func(&quot;is_available&quot;)</span>
<span class="sd">        if foo_is_available_func:</span>
<span class="sd">            foo_is_available = foo_is_available_func()</span>
<span class="sd">        func_ = torch.utils.backend_registration._get_custom_mod_func(&quot;func_name&quot;)</span>
<span class="sd">        if func_:</span>
<span class="sd">            result = func_(*args, **kwargs)</span>
<span class="sd">    Attention: This function is not meant to be used directly by users, which is why</span>
<span class="sd">    it is marked as private. It is a convenience function for backend implementers to</span>
<span class="sd">    more easily call the hooks into their backend extensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="nb">str</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;func_name must be `str`, but got `</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">func_name</span><span class="p">)</span><span class="si">}</span><span class="s2">`.&quot;</span>
    <span class="n">backend_name</span> <span class="o">=</span> <span class="n">_get_privateuse1_backend_name</span><span class="p">()</span>
    <span class="n">custom_device_mod</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">backend_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>
    <span class="n">function</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">custom_device_mod</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>
    <span class="k">if</span> <span class="n">custom_device_mod</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Try to call torch.</span><span class="si">{</span><span class="n">backend_name</span><span class="si">}</span><span class="s1">.</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s1">. The backend must register a custom backend &#39;</span>
        <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;module with `torch._register_device_module(&#39;</span><span class="si">{</span><span class="n">backend_name</span><span class="si">}</span><span class="s2">&#39;, BackendModule)`. And &quot;</span>
        <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;BackendModule needs to have the following API&#39;s:</span><span class="se">\n</span><span class="s2"> `</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">(*args, **kwargs)`. </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">function</span>
</pre></div>

                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-value="1">★</span>
        
        <span class="star" data-value="2">★</span>
        
        <span class="star" data-value="3">★</span>
        
        <span class="star" data-value="4">★</span>
        
        <span class="star" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn" onclick="openGitHubIssue()">Send Feedback</button>
  </div>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
    
    <div class="bd-footer__inner bd-page-width">
      
        <div class="footer-items__start">
          
            <div class="footer-item">

  <p class="copyright">
    
      © Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
          
            <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.0.
    <br/>
  </p>
</div>
          
        </div>
      
    
    
      <div class="footer-items__end">
        
          <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
        
      </div>
    
   </div>
   

   <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
      <div class="container">
        <div class="row">
          <div class="col-md-4 text-center">
            <h2>Docs</h2>
            <p>Access comprehensive developer documentation for PyTorch</p>
            <a class="with-right-arrow" href="">View Docs</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Tutorials</h2>
            <p>Get in-depth tutorials for beginners and advanced developers</p>
            <a class="with-right-arrow" href="">View Tutorials</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Resources</h2>
            <p>Find development resources and get your questions answered</p>
            <a class="with-right-arrow" href="">View Resources</a>
          </div>
        </div>
      </div>
  </div>

  <footer class="site-footer">
      <div class="container footer-container">
        <div class="footer-logo-wrapper">
          <a href="" class="footer-logo"></a>
        </div>

        <div class="footer-links-wrapper">
          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">PyTorch</a></li>
              <li><a href="">Get Started</a></li>
              <li><a href="">Features</a></li>
              <li><a href="">Ecosystem</a></li>
              <li><a href="">Blog</a></li>
              <li><a href="">Contributing</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">Resources</a></li>
              <li><a href="">Tutorials</a></li>
              <li><a href="">Docs</a></li>
              <li><a href="" target="_blank">Discuss</a></li>
              <li><a href="" target="_blank">Github Issues</a></li>
              <li><a href="" target="_blank">Brand Guidelines</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">Stay up to date</li>
              <li><a href="" target="_blank">Facebook</a></li>
              <li><a href="" target="_blank">Twitter</a></li>
              <li><a href="" target="_blank">YouTube</a></li>
              <li><a href="" target="_blank">LinkedIn</a></li>
            </ul>
            </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">PyTorch Podcasts</li>
              <li><a href="" target="_blank">Spotify</a></li>
              <li><a href="" target="_blank">Apple</a></li>
              <li><a href="" target="_blank">Google</a></li>
              <li><a href="" target="_blank">Amazon</a></li>
            </ul>
           </div>
          </div>

          <div class="privacy-policy">
            <ul>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
              <li class="privacy-policy-links">|</li>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
            </ul>
          </div>
          <div class="copyright">
          <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
            For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
            <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
            project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
            please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
        </div>
       </div>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/img/pytorch-x.svg">
  </div>
</div>
  </footer>


  </body>
</html>