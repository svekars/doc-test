
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>torch._tensor_str &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=949a1ff5" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/jit.css?v=8de1ea5d" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css?v=3ccf5357" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom2.css?v=baa440dc" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=a8da1a53"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=940804e7"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/torch/_tensor_str';</script>
    <script src="../../_static/js/star-rating.js?v=8861fcb6"></script>
    <script src="../../_static/js/send-feedback.js?v=5646bf45"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="main (2.6.0 )" />
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script type="text/javascript" src="../../_static/js/send-feedback.js"></script>
<script type="text/javascript" src="../../_static/js/star-rating.js"></script>
<script type="text/javascript" src="../../_static/js/cookie-banner.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-TEST12345"></script>
    <script type="text/javascript">
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-TEST12345');
    </script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
<body data-feedback-url="https://github.com/pytorch/pytorch">
  <div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later.
          <li>
            <div class="main-menu-item">
             <a href="" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Home</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../python-api/index.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../notes/index.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../python-api/index.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../notes/index.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Module code</a></li>
    
    
    <li class="breadcrumb-item"><a href="../torch.html" class="nav-link">torch</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">torch._tensor_str</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-value="1">★</span>
        
        <span class="star" data-value="2">★</span>
        
        <span class="star" data-value="3">★</span>
        
        <span class="star" data-value="4">★</span>
        
        <span class="star" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for torch._tensor_str</h1><div class="highlight"><pre>
<span></span><span class="c1"># mypy: allow-untyped-defs</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">contextlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dataclasses</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">textwrap</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">inf</span>


<span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">__PrinterOptions</span><span class="p">:</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">edgeitems</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">linewidth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="n">sci_mode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>


<span class="n">PRINT_OPTS</span> <span class="o">=</span> <span class="n">__PrinterOptions</span><span class="p">()</span>


<span class="c1"># We could use **kwargs, but this will give better docs</span>
<div class="viewcode-block" id="set_printoptions">
<a class="viewcode-back" href="../../python-api/generated/torch.set_printoptions.html#torch.set_printoptions">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">set_printoptions</span><span class="p">(</span>
    <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">edgeitems</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">profile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sci_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Set options for printing. Items shamelessly taken from NumPy</span>

<span class="sd">    Args:</span>
<span class="sd">        precision: Number of digits of precision for floating point output</span>
<span class="sd">            (default = 4).</span>
<span class="sd">        threshold: Total number of array elements which trigger summarization</span>
<span class="sd">            rather than full `repr` (default = 1000).</span>
<span class="sd">        edgeitems: Number of array items in summary at beginning and end of</span>
<span class="sd">            each dimension (default = 3).</span>
<span class="sd">        linewidth: The number of characters per line for the purpose of</span>
<span class="sd">            inserting line breaks (default = 80). Thresholded matrices will</span>
<span class="sd">            ignore this parameter.</span>
<span class="sd">        profile: Sane defaults for pretty printing. Can override with any of</span>
<span class="sd">            the above options. (any one of `default`, `short`, `full`)</span>
<span class="sd">        sci_mode: Enable (True) or disable (False) scientific notation. If</span>
<span class="sd">            None (default) is specified, the value is defined by</span>
<span class="sd">            `torch._tensor_str._Formatter`. This value is automatically chosen</span>
<span class="sd">            by the framework.</span>

<span class="sd">    Example::</span>

<span class="sd">        &gt;&gt;&gt; # Limit the precision of elements</span>
<span class="sd">        &gt;&gt;&gt; torch.set_printoptions(precision=2)</span>
<span class="sd">        &gt;&gt;&gt; torch.tensor([1.12345])</span>
<span class="sd">        tensor([1.12])</span>
<span class="sd">        &gt;&gt;&gt; # Limit the number of elements shown</span>
<span class="sd">        &gt;&gt;&gt; torch.set_printoptions(threshold=5)</span>
<span class="sd">        &gt;&gt;&gt; torch.arange(10)</span>
<span class="sd">        tensor([0, 1, 2, ..., 7, 8, 9])</span>
<span class="sd">        &gt;&gt;&gt; # Restore defaults</span>
<span class="sd">        &gt;&gt;&gt; torch.set_printoptions(profile=&#39;default&#39;)</span>
<span class="sd">        &gt;&gt;&gt; torch.tensor([1.12345])</span>
<span class="sd">        tensor([1.1235])</span>
<span class="sd">        &gt;&gt;&gt; torch.arange(10)</span>
<span class="sd">        tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">profile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">profile</span> <span class="o">==</span> <span class="s2">&quot;default&quot;</span><span class="p">:</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="mi">4</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="mi">1000</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mi">80</span>
        <span class="k">elif</span> <span class="n">profile</span> <span class="o">==</span> <span class="s2">&quot;short&quot;</span><span class="p">:</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="mi">1000</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mi">80</span>
        <span class="k">elif</span> <span class="n">profile</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="mi">4</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">inf</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span> <span class="o">=</span> <span class="mi">3</span>
            <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">linewidth</span> <span class="o">=</span> <span class="mi">80</span>

    <span class="k">if</span> <span class="n">precision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span> <span class="o">=</span> <span class="n">precision</span>
    <span class="k">if</span> <span class="n">threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
    <span class="k">if</span> <span class="n">edgeitems</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span> <span class="o">=</span> <span class="n">edgeitems</span>
    <span class="k">if</span> <span class="n">linewidth</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">linewidth</span> <span class="o">=</span> <span class="n">linewidth</span>
    <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">sci_mode</span> <span class="o">=</span> <span class="n">sci_mode</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">get_printoptions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gets the current options for printing, as a dictionary that</span>
<span class="sd">    can be passed as ``**kwargs`` to set_printoptions().</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">PRINT_OPTS</span><span class="p">)</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span><span class="w"> </span><span class="nf">printoptions</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Context manager that temporarily changes the print options.  Accepted</span>
<span class="sd">    arguments are same as :func:`set_printoptions`.&quot;&quot;&quot;</span>
    <span class="n">old_kwargs</span> <span class="o">=</span> <span class="n">get_printoptions</span><span class="p">()</span>
    <span class="n">set_printoptions</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">set_printoptions</span><span class="p">(</span><span class="o">**</span><span class="n">old_kwargs</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">tensor_totype</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">float</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">t</span><span class="o">.</span><span class="n">is_mps</span>
            <span class="ow">or</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">is_xpu</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">has_fp64</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_Formatter</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">floating_dtype</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating_point</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">int_mode</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sci_mode</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_width</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">tensor_view</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">floating_dtype</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">tensor_view</span><span class="p">:</span>
                <span class="n">value_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_width</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_str</span><span class="p">))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">nonzero_finite_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span>
                <span class="n">tensor_view</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">tensor_view</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">tensor_view</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">nonzero_finite_vals</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># no valid number, do nothing</span>
                <span class="k">return</span>

            <span class="c1"># Convert to double for easy calculation. HalfTensor overflows with 1e8, and there&#39;s no div() on CPU.</span>
            <span class="n">nonzero_finite_abs</span> <span class="o">=</span> <span class="n">tensor_totype</span><span class="p">(</span><span class="n">nonzero_finite_vals</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span>
            <span class="n">nonzero_finite_min</span> <span class="o">=</span> <span class="n">tensor_totype</span><span class="p">(</span><span class="n">nonzero_finite_abs</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
            <span class="n">nonzero_finite_max</span> <span class="o">=</span> <span class="n">tensor_totype</span><span class="p">(</span><span class="n">nonzero_finite_abs</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>

            <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">nonzero_finite_vals</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">value</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">int_mode</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">break</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">int_mode</span><span class="p">:</span>
                <span class="c1"># in int_mode for floats, all numbers are integers, and we append a decimal to nonfinites</span>
                <span class="c1"># to indicate that the tensor is of floating type. add 1 to the len to account for this.</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">nonzero_finite_max</span> <span class="o">/</span> <span class="n">nonzero_finite_min</span> <span class="o">&gt;</span> <span class="mf">1000.0</span>
                    <span class="ow">or</span> <span class="n">nonzero_finite_max</span> <span class="o">&gt;</span> <span class="mf">1.0e8</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sci_mode</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">nonzero_finite_vals</span><span class="p">:</span>
                        <span class="n">value_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">{{</span><span class="s2">:.</span><span class="si">{</span><span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span><span class="si">}</span><span class="s2">e</span><span class="se">}}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">max_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_width</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_str</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">nonzero_finite_vals</span><span class="p">:</span>
                        <span class="n">value_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">max_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_width</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_str</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Check if scientific representation should be used.</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">nonzero_finite_max</span> <span class="o">/</span> <span class="n">nonzero_finite_min</span> <span class="o">&gt;</span> <span class="mf">1000.0</span>
                    <span class="ow">or</span> <span class="n">nonzero_finite_max</span> <span class="o">&gt;</span> <span class="mf">1.0e8</span>
                    <span class="ow">or</span> <span class="n">nonzero_finite_min</span> <span class="o">&lt;</span> <span class="mf">1.0e-4</span>
                <span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sci_mode</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">nonzero_finite_vals</span><span class="p">:</span>
                        <span class="n">value_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">{{</span><span class="s2">:.</span><span class="si">{</span><span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span><span class="si">}</span><span class="s2">e</span><span class="se">}}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">max_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_width</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_str</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">nonzero_finite_vals</span><span class="p">:</span>
                        <span class="n">value_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">{{</span><span class="s2">:.</span><span class="si">{</span><span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="se">}}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">max_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_width</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">value_str</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">sci_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sci_mode</span> <span class="o">=</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">sci_mode</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">width</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_width</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">format</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">floating_dtype</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sci_mode</span><span class="p">:</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">{{</span><span class="s2">:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_width</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span><span class="si">}</span><span class="s2">e</span><span class="se">}}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">int_mode</span><span class="p">:</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="ow">or</span> <span class="n">math</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">value</span><span class="p">)):</span>
                    <span class="n">ret</span> <span class="o">+=</span> <span class="s2">&quot;.&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ret</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">{{</span><span class="s2">:.</span><span class="si">{</span><span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">precision</span><span class="si">}</span><span class="s2">f</span><span class="se">}}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_width</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">))</span> <span class="o">*</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">ret</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_scalar_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">formatter2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">real_str</span> <span class="o">=</span> <span class="n">_scalar_str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">)</span>
        <span class="n">imag_str</span> <span class="o">=</span> <span class="p">(</span><span class="n">_scalar_str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imag</span><span class="p">,</span> <span class="n">formatter2</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;j&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span>
        <span class="c1"># handles negative numbers, +0.0, -0.0</span>
        <span class="k">if</span> <span class="n">imag_str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;+&quot;</span> <span class="ow">or</span> <span class="n">imag_str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;-&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">real_str</span> <span class="o">+</span> <span class="n">imag_str</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">real_str</span> <span class="o">+</span> <span class="s2">&quot;+&quot;</span> <span class="o">+</span> <span class="n">imag_str</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">formatter1</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_vector_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="p">,</span> <span class="n">summarize</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># length includes spaces and comma between elements</span>
    <span class="n">element_length</span> <span class="o">=</span> <span class="n">formatter1</span><span class="o">.</span><span class="n">width</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">formatter2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># width for imag_formatter + an extra j for complex</span>
        <span class="n">element_length</span> <span class="o">+=</span> <span class="n">formatter2</span><span class="o">.</span><span class="n">width</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">elements_per_line</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">((</span><span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">linewidth</span> <span class="o">-</span> <span class="n">indent</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">element_length</span><span class="p">)))</span>
    <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_val_formatter</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">formatter1</span><span class="o">=</span><span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span><span class="o">=</span><span class="n">formatter2</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">formatter2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">real_str</span> <span class="o">=</span> <span class="n">formatter1</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">real</span><span class="p">)</span>
            <span class="n">imag_str</span> <span class="o">=</span> <span class="p">(</span><span class="n">formatter2</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">imag</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;j&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span>
            <span class="c1"># handles negative numbers, +0.0, -0.0</span>
            <span class="k">if</span> <span class="n">imag_str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;+&quot;</span> <span class="ow">or</span> <span class="n">imag_str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;-&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">real_str</span> <span class="o">+</span> <span class="n">imag_str</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">real_str</span> <span class="o">+</span> <span class="s2">&quot;+&quot;</span> <span class="o">+</span> <span class="n">imag_str</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">formatter1</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">summarize</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">:</span>
        <span class="c1"># Deal with edge case that negative zero is zero</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;...&quot;</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">summarize</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span><span class="n">_val_formatter</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">[:</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()]</span>
            <span class="o">+</span> <span class="p">[</span><span class="s2">&quot; ...&quot;</span><span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span><span class="n">_val_formatter</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">[</span><span class="o">-</span><span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span> <span class="p">:]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()]</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">_val_formatter</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tolist</span><span class="p">()]</span>

    <span class="n">data_lines</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">elements_per_line</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">elements_per_line</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">data_lines</span><span class="p">]</span>
    <span class="k">return</span> <span class="s2">&quot;[&quot;</span> <span class="o">+</span> <span class="p">(</span><span class="s2">&quot;,&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">(</span><span class="n">indent</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span>


<span class="c1"># formatter2 is only used for printing complex tensors.</span>
<span class="c1"># For complex tensors, formatter1 and formatter2 are the formatters for tensor.real</span>
<span class="c1"># and tensor.imag respesectively</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_tensor_str_with_formatter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="p">,</span> <span class="n">summarize</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_scalar_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_vector_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="p">,</span> <span class="n">summarize</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">summarize</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">:</span>
        <span class="n">slices</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span>
                <span class="n">_tensor_str_with_formatter</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">indent</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">summarize</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;...&quot;</span><span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span>
                <span class="n">_tensor_str_with_formatter</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">indent</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">summarize</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
            <span class="p">]</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">slices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">_tensor_str_with_formatter</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">indent</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">summarize</span><span class="p">,</span> <span class="n">formatter1</span><span class="p">,</span> <span class="n">formatter2</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="p">]</span>

    <span class="n">tensor_str</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;,&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">*</span> <span class="p">(</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">(</span><span class="n">indent</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">slices</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;[&quot;</span> <span class="o">+</span> <span class="n">tensor_str</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_tensor_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;[]&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_names</span><span class="p">():</span>
        <span class="c1"># There are two main codepaths (possibly more) that tensor printing goes through:</span>
        <span class="c1"># - tensor data can fit comfortably on screen</span>
        <span class="c1"># - tensor data needs to be summarized</span>
        <span class="c1"># Some of the codepaths don&#39;t fully support named tensors, so we send in</span>
        <span class="c1"># an unnamed tensor to the formatting code as a workaround.</span>
        <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">summarize</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">threshold</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_zerotensor</span><span class="p">():</span>
        <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

    <span class="c1"># handle the negative bit</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_neg</span><span class="p">():</span>
        <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resolve_neg</span><span class="p">()</span>

    <span class="c1"># TODO: Remove me when `masked_select` is implemented for FP8</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">float8_e5m2</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">float8_e5m2fnuz</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">float8_e4m3fn</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">float8_e4m3fnuz</span><span class="p">,</span>
    <span class="p">]:</span>
        <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_complex</span><span class="p">:</span>
        <span class="c1"># handle the conjugate bit</span>
        <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resolve_conj</span><span class="p">()</span>
        <span class="n">real_formatter</span> <span class="o">=</span> <span class="n">_Formatter</span><span class="p">(</span>
            <span class="n">get_summarized_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">real</span><span class="p">)</span> <span class="k">if</span> <span class="n">summarize</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">real</span>
        <span class="p">)</span>
        <span class="n">imag_formatter</span> <span class="o">=</span> <span class="n">_Formatter</span><span class="p">(</span>
            <span class="n">get_summarized_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imag</span><span class="p">)</span> <span class="k">if</span> <span class="n">summarize</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">imag</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">_tensor_str_with_formatter</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="p">,</span> <span class="n">summarize</span><span class="p">,</span> <span class="n">real_formatter</span><span class="p">,</span> <span class="n">imag_formatter</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">formatter</span> <span class="o">=</span> <span class="n">_Formatter</span><span class="p">(</span><span class="n">get_summarized_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="k">if</span> <span class="n">summarize</span> <span class="k">else</span> <span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_tensor_str_with_formatter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="p">,</span> <span class="n">summarize</span><span class="p">,</span> <span class="n">formatter</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_add_suffixes</span><span class="p">(</span><span class="n">tensor_str</span><span class="p">,</span> <span class="n">suffixes</span><span class="p">,</span> <span class="n">indent</span><span class="p">,</span> <span class="n">force_newline</span><span class="p">):</span>
    <span class="n">tensor_strs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor_str</span><span class="p">]</span>
    <span class="n">last_line_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_str</span><span class="p">)</span> <span class="o">-</span> <span class="n">tensor_str</span><span class="o">.</span><span class="n">rfind</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">suffix</span> <span class="ow">in</span> <span class="n">suffixes</span><span class="p">:</span>
        <span class="n">suffix_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">suffix</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">force_newline</span> <span class="ow">or</span> <span class="n">last_line_len</span> <span class="o">+</span> <span class="n">suffix_len</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">&gt;</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">linewidth</span><span class="p">:</span>
            <span class="n">tensor_strs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="n">indent</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">)</span>
            <span class="n">last_line_len</span> <span class="o">=</span> <span class="n">indent</span> <span class="o">+</span> <span class="n">suffix_len</span>
            <span class="n">force_newline</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor_strs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;, &quot;</span> <span class="o">+</span> <span class="n">suffix</span><span class="p">)</span>
            <span class="n">last_line_len</span> <span class="o">+=</span> <span class="n">suffix_len</span> <span class="o">+</span> <span class="mi">2</span>
    <span class="n">tensor_strs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;)&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tensor_strs</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_summarized_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="p">[:</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">],</span> <span class="bp">self</span><span class="p">[</span><span class="o">-</span><span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span> <span class="p">:])</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_empty</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">())</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">)]</span>
        <span class="n">end</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">get_summarized_data</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">end</span><span class="p">)])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">get_summarized_data</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">])</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_str_intern</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tensor_contents</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">is_functorch_wrapped_tensor</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_functorch_wrapper_str_intern</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tensor_contents</span><span class="o">=</span><span class="n">tensor_contents</span><span class="p">)</span>
    <span class="n">is_plain_tensor</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span>
    <span class="k">if</span> <span class="n">inp</span><span class="o">.</span><span class="n">is_nested</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;nested_tensor(&quot;</span>
    <span class="k">elif</span> <span class="n">is_plain_tensor</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;tensor(&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(&quot;</span>
    <span class="n">indent</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>
    <span class="n">suffixes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">custom_contents_provided</span> <span class="o">=</span> <span class="n">tensor_contents</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">custom_contents_provided</span><span class="p">:</span>
        <span class="n">tensor_str</span> <span class="o">=</span> <span class="n">tensor_contents</span>

    <span class="c1"># This is used to extract the primal value and thus disable the forward AD</span>
    <span class="c1"># within this function.</span>
    <span class="c1"># TODO(albanD) This needs to be updated when more than one level is supported</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">tangent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">forward_ad</span><span class="o">.</span><span class="n">unpack_dual</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>

    <span class="c1"># Note [Print tensor device]:</span>
    <span class="c1"># A general logic here is we only print device when it doesn&#39;t match</span>
    <span class="c1"># the device specified in default tensor type.</span>
    <span class="c1"># Currently torch.set_default_tensor_type() only supports CPU/CUDA, thus</span>
    <span class="c1"># torch._C._get_default_device() only returns either cpu or cuda.</span>
    <span class="c1"># In other cases, we don&#39;t have a way to set them as default yet,</span>
    <span class="c1"># and we should always print out device for them.</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_default_device</span><span class="p">()</span>
        <span class="ow">or</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span>
            <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">index</span>
        <span class="p">)</span>
        <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;mps&quot;</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;device=&#39;&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">)</span>

    <span class="c1"># Tensor printing performs tensor operations like slice, indexing, etc to make it in a</span>
    <span class="c1"># representable format. These operations on ipu/xla/lazy/mtia tensor results in compilations. Hence,</span>
    <span class="c1"># to avoid compilations, copying the tensor to cpu before printing.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;xla&quot;</span><span class="p">,</span> <span class="s2">&quot;lazy&quot;</span><span class="p">,</span> <span class="s2">&quot;ipu&quot;</span><span class="p">,</span> <span class="s2">&quot;mtia&quot;</span><span class="p">]:</span>
        <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="c1"># TODO: add an API to map real -&gt; complex dtypes</span>
    <span class="n">_default_complex_dtype</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">cfloat</span>
    <span class="p">)</span>
    <span class="n">has_default_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">(),</span>
        <span class="n">_default_complex_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torch._subclasses.fake_tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">FakeTensor</span>

        <span class="n">is_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_meta</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">FakeTensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_meta</span><span class="p">:</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;nnz=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nnz</span><span class="p">()))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">has_default_dtype</span><span class="p">:</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dtype=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_contents_provided</span><span class="p">:</span>
            <span class="n">indices_prefix</span> <span class="o">=</span> <span class="s2">&quot;indices=tensor(&quot;</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_indices</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">is_meta</span><span class="p">:</span>
                <span class="n">indices_str</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">indices_str</span> <span class="o">=</span> <span class="n">_tensor_str</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indent</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices_prefix</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">is_meta</span> <span class="ow">or</span> <span class="n">indices</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">indices_str</span> <span class="o">+=</span> <span class="s2">&quot;, size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">values_prefix</span> <span class="o">=</span> <span class="s2">&quot;values=tensor(&quot;</span>
            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_values</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">is_meta</span><span class="p">:</span>
                <span class="n">values_str</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">values_str</span> <span class="o">=</span> <span class="n">_tensor_str</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">indent</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">values_prefix</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">is_meta</span> <span class="ow">or</span> <span class="n">values</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">values_str</span> <span class="o">+=</span> <span class="s2">&quot;, size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">tensor_str</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">indices_prefix</span>
                <span class="o">+</span> <span class="n">indices_str</span>
                <span class="o">+</span> <span class="s2">&quot;),</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="n">indent</span>
                <span class="o">+</span> <span class="n">values_prefix</span>
                <span class="o">+</span> <span class="n">values_str</span>
                <span class="o">+</span> <span class="s2">&quot;)&quot;</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span> <span class="ow">in</span> <span class="p">{</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csr</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csc</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsr</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsc</span><span class="p">,</span>
    <span class="p">}:</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torch._subclasses.fake_tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">FakeTensor</span>

        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
        <span class="n">is_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_meta</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">FakeTensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_meta</span><span class="p">:</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;nnz=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_nnz</span><span class="p">()))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">has_default_dtype</span><span class="p">:</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dtype=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_contents_provided</span><span class="p">:</span>
            <span class="n">compressed_indices_method</span><span class="p">,</span> <span class="n">plain_indices_method</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csr</span><span class="p">:</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">col_indices</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csc</span><span class="p">:</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">ccol_indices</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">row_indices</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsr</span><span class="p">:</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">col_indices</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsc</span><span class="p">:</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">ccol_indices</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">row_indices</span><span class="p">),</span>
            <span class="p">}[</span><span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span> <span class="ow">in</span> <span class="p">{</span><span class="n">torch</span><span class="o">.</span><span class="n">sparse_csr</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsr</span><span class="p">}:</span>
                <span class="n">cdimname</span><span class="p">,</span> <span class="n">pdimname</span> <span class="o">=</span> <span class="s2">&quot;row&quot;</span><span class="p">,</span> <span class="s2">&quot;column&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cdimname</span><span class="p">,</span> <span class="n">pdimname</span> <span class="o">=</span> <span class="s2">&quot;column&quot;</span><span class="p">,</span> <span class="s2">&quot;row&quot;</span>
            <span class="n">compressed_indices_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;c</span><span class="si">{</span><span class="n">cdimname</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">_indices=tensor(&quot;</span>
            <span class="n">compressed_indices</span> <span class="o">=</span> <span class="n">compressed_indices_method</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">is_meta</span><span class="p">:</span>
                <span class="n">compressed_indices_str</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">compressed_indices_str</span> <span class="o">=</span> <span class="n">_tensor_str</span><span class="p">(</span>
                    <span class="n">compressed_indices</span><span class="p">,</span> <span class="n">indent</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">compressed_indices_prefix</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">compressed_indices</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">is_meta</span><span class="p">:</span>
                <span class="n">compressed_indices_str</span> <span class="o">+=</span> <span class="s2">&quot;, size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span>
                    <span class="nb">tuple</span><span class="p">(</span><span class="n">compressed_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">plain_indices_prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pdimname</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">_indices=tensor(&quot;</span>
            <span class="n">plain_indices</span> <span class="o">=</span> <span class="n">plain_indices_method</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">is_meta</span><span class="p">:</span>
                <span class="n">plain_indices_str</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">plain_indices_str</span> <span class="o">=</span> <span class="n">_tensor_str</span><span class="p">(</span>
                    <span class="n">plain_indices</span><span class="p">,</span> <span class="n">indent</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">plain_indices_prefix</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">plain_indices</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">is_meta</span><span class="p">:</span>
                <span class="n">plain_indices_str</span> <span class="o">+=</span> <span class="s2">&quot;, size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">plain_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">values_prefix</span> <span class="o">=</span> <span class="s2">&quot;values=tensor(&quot;</span>
            <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">is_meta</span><span class="p">:</span>
                <span class="n">values_str</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">values_str</span> <span class="o">=</span> <span class="n">_tensor_str</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">indent</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">values_prefix</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">values</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">is_meta</span><span class="p">:</span>
                <span class="n">values_str</span> <span class="o">+=</span> <span class="s2">&quot;, size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">tensor_str</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">compressed_indices_prefix</span>
                <span class="o">+</span> <span class="n">compressed_indices_str</span>
                <span class="o">+</span> <span class="s2">&quot;),</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="n">indent</span>
                <span class="o">+</span> <span class="n">plain_indices_prefix</span>
                <span class="o">+</span> <span class="n">plain_indices_str</span>
                <span class="o">+</span> <span class="s2">&quot;),</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="n">indent</span>
                <span class="o">+</span> <span class="n">values_prefix</span>
                <span class="o">+</span> <span class="n">values_str</span>
                <span class="o">+</span> <span class="s2">&quot;)&quot;</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_quantized</span><span class="p">:</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">has_default_dtype</span><span class="p">:</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dtype=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;quantization_scheme=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">qscheme</span><span class="p">()))</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qscheme</span><span class="p">()</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">per_tensor_affine</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">qscheme</span><span class="p">()</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">per_tensor_symmetric</span>
        <span class="p">):</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;scale=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_scale</span><span class="p">()))</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;zero_point=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_zero_point</span><span class="p">()))</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">qscheme</span><span class="p">()</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">per_channel_affine</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">qscheme</span><span class="p">()</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">per_channel_symmetric</span>
            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">qscheme</span><span class="p">()</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">per_channel_affine_float_qparams</span>
        <span class="p">):</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;scale=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_per_channel_scales</span><span class="p">()))</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;zero_point=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_per_channel_zero_points</span><span class="p">()))</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;axis=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_per_channel_axis</span><span class="p">()))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_contents_provided</span><span class="p">:</span>
            <span class="n">tensor_str</span> <span class="o">=</span> <span class="n">_tensor_str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dequantize</span><span class="p">(),</span> <span class="n">indent</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_nested</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_contents_provided</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">indented_str</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">indent</span><span class="p">):</span>
                <span class="k">return</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">))</span>

            <span class="n">strs</span> <span class="o">=</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="n">indented_str</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">indent</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">unbind</span><span class="o">.</span><span class="n">int</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">tensor_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;[</span><span class="se">\n</span><span class="si">{</span><span class="n">strs</span><span class="si">}</span><span class="se">\n</span><span class="s2">]&quot;</span>
    <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">_is_functional_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;_to_functional_tensor(&quot;</span>
        <span class="n">tensor_str</span> <span class="o">=</span> <span class="nb">repr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_from_functional_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Circular import problem, so we import it here</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torch._subclasses.fake_tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">FakeTensor</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_meta</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">FakeTensor</span><span class="p">):</span>
            <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">():</span>
                <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dtype=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
            <span class="c1"># TODO: This implies that ellipses is valid syntax for allocating</span>
            <span class="c1"># a meta tensor or FakeTensor, which it could be, but it isn&#39;t right now</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_contents_provided</span><span class="p">:</span>
                <span class="n">tensor_str</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
                <span class="c1"># Explicitly print the shape if it is not (0,), to match NumPy behavior</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>

                <span class="c1"># In an empty tensor, there are no elements to infer if the dtype</span>
                <span class="c1"># should be int64, so it must be shown explicitly.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">():</span>
                    <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dtype=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_contents_provided</span><span class="p">:</span>
                    <span class="n">tensor_str</span> <span class="o">=</span> <span class="s2">&quot;[]&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">PRINT_OPTS</span><span class="o">.</span><span class="n">edgeitems</span><span class="p">:</span>
                    <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;size=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">has_default_dtype</span><span class="p">:</span>
                    <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dtype=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">custom_contents_provided</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">:</span>
                        <span class="n">tensor_str</span> <span class="o">=</span> <span class="n">_tensor_str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(),</span> <span class="n">indent</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">tensor_str</span> <span class="o">=</span> <span class="n">_tensor_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indent</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layout</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">:</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;layout=&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layout</span><span class="p">))</span>

    <span class="c1"># Use inp here to get the original grad_fn and not the one generated by the forward grad</span>
    <span class="c1"># unpacking.</span>
    <span class="n">grad_fn_name</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">grad_fn</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">grad_fn</span>
    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
        <span class="c1"># Accessing the grad_fn calls rebasing logic which would cause an error</span>
        <span class="c1"># if that tensor is a view created in no-grad mode modified in-place in</span>
        <span class="c1"># no-grad mode. See: https://github.com/pytorch/pytorch/issues/99968</span>
        <span class="n">grad_fn_name</span> <span class="o">=</span> <span class="s2">&quot;Invalid&quot;</span>

    <span class="k">if</span> <span class="n">grad_fn_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">grad_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore[possibly-undefined]</span>
        <span class="n">grad_fn_name</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">grad_fn</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="k">if</span> <span class="n">grad_fn_name</span> <span class="o">==</span> <span class="s2">&quot;CppFunction&quot;</span><span class="p">:</span>
            <span class="n">grad_fn_name</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="o">.</span><span class="n">name</span><span class="p">()</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;::&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">grad_fn_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;grad_fn=&lt;</span><span class="si">{</span><span class="n">grad_fn_name</span><span class="si">}</span><span class="s2">&gt;&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">inp</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;requires_grad=True&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_names</span><span class="p">():</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;names=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">tangent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">suffixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tangent=</span><span class="si">{</span><span class="n">tangent</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">string_repr</span> <span class="o">=</span> <span class="n">_add_suffixes</span><span class="p">(</span>
        <span class="n">prefix</span> <span class="o">+</span> <span class="n">tensor_str</span><span class="p">,</span>  <span class="c1"># type: ignore[possibly-undefined]</span>
        <span class="n">suffixes</span><span class="p">,</span>
        <span class="n">indent</span><span class="p">,</span>
        <span class="n">force_newline</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Check if this instance is flagged as a parameter and change the repr accordingly.</span>
    <span class="c1"># Unfortunately, this function has to be aware of this detail.</span>
    <span class="c1"># NB: This is currently skipped for plain tensor parameters to maintain BC. In the future,</span>
    <span class="c1"># this should be done for those as well to produce a valid repr.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_plain_tensor</span><span class="p">:</span>
        <span class="n">string_repr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Parameter(</span><span class="si">{</span><span class="n">string_repr</span><span class="si">}</span><span class="s2">)&quot;</span>

    <span class="k">return</span> <span class="n">string_repr</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_functorch_wrapper_str_intern</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tensor_contents</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">level</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">maybe_get_level</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">level</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">is_functionaltensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="c1"># Since we&#39;re unwrapping the FunctionalTensorWrapper, we need to make sure</span>
        <span class="c1"># that it&#39;s up to date first</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_sync</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

    <span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">get_unwrapped</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="n">value_repr</span> <span class="o">=</span> <span class="nb">repr</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

    <span class="n">indented_value_repr</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">indent</span><span class="p">(</span><span class="n">value_repr</span><span class="p">,</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">is_batchedtensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="n">bdim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">maybe_get_bdim</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">bdim</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;BatchedTensor(lvl=</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">, bdim=</span><span class="si">{</span><span class="n">bdim</span><span class="si">}</span><span class="s2">, value=</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">indented_value_repr</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;)&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">is_gradtrackingtensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;GradTrackingTensor(lvl=</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">, value=</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">indented_value_repr</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="sa">f</span><span class="s2">&quot;)&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_functorch</span><span class="o">.</span><span class="n">is_functionaltensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;FunctionalTensor(lvl=</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">, value=</span><span class="se">\\\n</span><span class="si">{</span><span class="n">value_repr</span><span class="si">}</span><span class="s2">)&quot;</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;We don&#39;t know how to print this, please file us an issue&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tensor_contents</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">_python_dispatch</span><span class="o">.</span><span class="n">_disable_current_modes</span><span class="p">():</span>
        <span class="n">guard</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_DisableFuncTorch</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_str_intern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor_contents</span><span class="o">=</span><span class="n">tensor_contents</span><span class="p">)</span>
</pre></div>

                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-value="1">★</span>
        
        <span class="star" data-value="2">★</span>
        
        <span class="star" data-value="3">★</span>
        
        <span class="star" data-value="4">★</span>
        
        <span class="star" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn" onclick="openGitHubIssue()">Send Feedback</button>
  </div>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
    
    <div class="bd-footer__inner bd-page-width">
      
        <div class="footer-items__start">
          
            <div class="footer-item">

  <p class="copyright">
    
      © Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
          
            <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.0.
    <br/>
  </p>
</div>
          
        </div>
      
    
    
      <div class="footer-items__end">
        
          <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
        
      </div>
    
   </div>
   

   <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
      <div class="container">
        <div class="row">
          <div class="col-md-4 text-center">
            <h2>Docs</h2>
            <p>Access comprehensive developer documentation for PyTorch</p>
            <a class="with-right-arrow" href="">View Docs</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Tutorials</h2>
            <p>Get in-depth tutorials for beginners and advanced developers</p>
            <a class="with-right-arrow" href="">View Tutorials</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Resources</h2>
            <p>Find development resources and get your questions answered</p>
            <a class="with-right-arrow" href="">View Resources</a>
          </div>
        </div>
      </div>
  </div>

  <footer class="site-footer">
      <div class="container footer-container">
        <div class="footer-logo-wrapper">
          <a href="" class="footer-logo"></a>
        </div>

        <div class="footer-links-wrapper">
          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">PyTorch</a></li>
              <li><a href="">Get Started</a></li>
              <li><a href="">Features</a></li>
              <li><a href="">Ecosystem</a></li>
              <li><a href="">Blog</a></li>
              <li><a href="">Contributing</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">Resources</a></li>
              <li><a href="">Tutorials</a></li>
              <li><a href="">Docs</a></li>
              <li><a href="" target="_blank">Discuss</a></li>
              <li><a href="" target="_blank">Github Issues</a></li>
              <li><a href="" target="_blank">Brand Guidelines</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">Stay up to date</li>
              <li><a href="" target="_blank">Facebook</a></li>
              <li><a href="" target="_blank">Twitter</a></li>
              <li><a href="" target="_blank">YouTube</a></li>
              <li><a href="" target="_blank">LinkedIn</a></li>
            </ul>
            </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">PyTorch Podcasts</li>
              <li><a href="" target="_blank">Spotify</a></li>
              <li><a href="" target="_blank">Apple</a></li>
              <li><a href="" target="_blank">Google</a></li>
              <li><a href="" target="_blank">Amazon</a></li>
            </ul>
           </div>
          </div>

          <div class="privacy-policy">
            <ul>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
              <li class="privacy-policy-links">|</li>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
            </ul>
          </div>
          <div class="copyright">
          <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
            For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
            <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
            project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
            please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
        </div>
       </div>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/img/pytorch-x.svg">
  </div>
</div>
  </footer>


  </body>
</html>