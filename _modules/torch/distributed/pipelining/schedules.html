
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>torch.distributed.pipelining.schedules &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=949a1ff5" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/jit.css?v=8de1ea5d" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css?v=3ccf5357" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom2.css?v=baa440dc" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=a8da1a53"></script>
    <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=940804e7"></script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/torch/distributed/pipelining/schedules';</script>
    <script src="../../../../_static/js/star-rating.js?v=8861fcb6"></script>
    <script src="../../../../_static/js/send-feedback.js?v=5646bf45"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="main (2.6.0 )" />
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script type="text/javascript" src="../../../../_static/js/send-feedback.js"></script>
<script type="text/javascript" src="../../../../_static/js/star-rating.js"></script>
<script type="text/javascript" src="../../../../_static/js/cookie-banner.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-TEST12345"></script>
    <script type="text/javascript">
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-TEST12345');
    </script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
<body data-feedback-url="https://github.com/pytorch/pytorch">
  <div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later.
          <li>
            <div class="main-menu-item">
             <a href="" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Home</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../python-api/index.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../notes/index.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../python-api/index.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../notes/index.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../index.html" class="nav-link">Module code</a></li>
    
    
    <li class="breadcrumb-item"><a href="../../../torch.html" class="nav-link">torch</a></li>
    
    
    <li class="breadcrumb-item"><a href="../../distributed.html" class="nav-link">torch.distributed</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">torch.distributed.pipelining.schedules</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-value="1">★</span>
        
        <span class="star" data-value="2">★</span>
        
        <span class="star" data-value="3">★</span>
        
        <span class="star" data-value="4">★</span>
        
        <span class="star" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for torch.distributed.pipelining.schedules</h1><div class="highlight"><pre>
<span></span><span class="c1"># mypy: allow-untyped-defs</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">csv</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">itertools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">defaultdict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">enum</span><span class="w"> </span><span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">NamedTuple</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Set</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed.fsdp</span><span class="w"> </span><span class="kn">import</span> <span class="n">FSDPModule</span><span class="p">,</span> <span class="n">UnshardHandle</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.profiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">record_function</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.microbatch</span><span class="w"> </span><span class="kn">import</span> <span class="n">merge_chunks</span><span class="p">,</span> <span class="n">split_args_kwargs_into_chunks</span><span class="p">,</span> <span class="n">TensorChunkSpec</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.stage</span><span class="w"> </span><span class="kn">import</span> <span class="n">_PipelineStageBase</span>


<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="n">Work</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;get_schedule_class&quot;</span><span class="p">,</span>
    <span class="s2">&quot;PipelineScheduleSingle&quot;</span><span class="p">,</span>
    <span class="s2">&quot;PipelineScheduleMulti&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Schedule1F1B&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleGPipe&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleInterleaved1F1B&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleLoopedBFS&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleInterleavedZeroBubble&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleZBVZeroBubble&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_ComputationType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="c1"># TODO(whc) rename to _ActType?</span>
    <span class="n">FORWARD</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">BACKWARD_INPUT</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">BACKWARD_WEIGHT</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">UNSHARD</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">RESHARD</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">SEND_F</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">RECV_F</span> <span class="o">=</span> <span class="mi">7</span>
    <span class="n">SEND_B</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">RECV_B</span> <span class="o">=</span> <span class="mi">9</span>
    <span class="n">FULL_BACKWARD</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">str_map</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span> <span class="s2">&quot;F&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_INPUT</span><span class="p">:</span> <span class="s2">&quot;I&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_WEIGHT</span><span class="p">:</span> <span class="s2">&quot;W&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">UNSHARD</span><span class="p">:</span> <span class="s2">&quot;UNSHARD&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RESHARD</span><span class="p">:</span> <span class="s2">&quot;RESHARD&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_F</span><span class="p">:</span> <span class="s2">&quot;SEND_F&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_F</span><span class="p">:</span> <span class="s2">&quot;RECV_F&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_B</span><span class="p">:</span> <span class="s2">&quot;SEND_B&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_B</span><span class="p">:</span> <span class="s2">&quot;RECV_B&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FULL_BACKWARD</span><span class="p">:</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">str_map</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_str</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;F&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;I&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_INPUT</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;W&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_WEIGHT</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;UNSHARD&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">UNSHARD</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;RESHARD&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RESHARD</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;SEND_F&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_F</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;RECV_F&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_F</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;SEND_B&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_B</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;RECV_B&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_B</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;B&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FULL_BACKWARD</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid computation type </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="n">FORWARD</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span>
<span class="n">BACKWARD_INPUT</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_INPUT</span>
<span class="n">BACKWARD_WEIGHT</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_WEIGHT</span>
<span class="n">UNSHARD</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">UNSHARD</span>
<span class="n">RESHARD</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RESHARD</span>
<span class="n">SEND_F</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_F</span>
<span class="n">RECV_F</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_F</span>
<span class="n">SEND_B</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_B</span>
<span class="n">RECV_B</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_B</span>
<span class="n">FULL_BACKWARD</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FULL_BACKWARD</span>

<span class="c1"># Convenience shorthand for compute actions only since they are used in &#39;simple schedule format&#39;</span>
<span class="n">F</span> <span class="o">=</span> <span class="n">FORWARD</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">BACKWARD_INPUT</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">BACKWARD_WEIGHT</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">FULL_BACKWARD</span>

<span class="c1"># Helper to parse an action string like 1F0 into a tuple of (stage_index, computation_type, microbatch_index)</span>
<span class="n">_action_regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="sa">r</span><span class="s2">&quot;(\d+)(F|I|B|W|UNSHARD|RESHARD|SEND_F|RECV_F|SEND_B|RECV_B)(\d*)&quot;</span>
<span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_Action</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="n">stage_index</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">computation_type</span><span class="p">:</span> <span class="n">_ComputationType</span>
    <span class="n">microbatch_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">repr</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)</span>
        <span class="nb">repr</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">computation_type</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">repr</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">repr</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_str</span><span class="p">(</span><span class="n">action_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reverse of __repr__</span>

<span class="sd">        String should be formatted as [stage][action type][(microbatch)]</span>
<span class="sd">            e.g. `2F0`, `1UNSHARD`, `3SEND_F1`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">action_string</span> <span class="o">=</span> <span class="n">action_string</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">match</span> <span class="o">:=</span> <span class="n">_action_regex</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">action_string</span><span class="p">):</span>
            <span class="n">stage_index</span><span class="p">,</span> <span class="n">computation_type</span><span class="p">,</span> <span class="n">microbatch_index</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">_Action</span><span class="p">(</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">stage_index</span><span class="p">),</span>
                <span class="n">_ComputationType</span><span class="o">.</span><span class="n">from_str</span><span class="p">(</span><span class="n">computation_type</span><span class="p">),</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">action_string</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid action string: </span><span class="si">{</span><span class="n">action_string</span><span class="si">}</span><span class="s2">, should be formatted as [stage][action type][(microbatch)] e.g. 2F0&quot;</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_format_pipeline_order</span><span class="p">(</span>
    <span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]],</span>
    <span class="n">error_step_number</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Formats the pipeline order in a timestep (row) x rank (column) grid of actions</span>
<span class="sd">    and returns the formatted string.</span>

<span class="sd">    If `error_step_number` is passed in, an additional label will be added to signify which step</span>
<span class="sd">    that it is erroring on.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># don&#39;t mutate the original</span>
    <span class="n">pipeline_order</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)</span>

    <span class="c1"># Replace None with &quot;&quot;</span>
    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">pipeline_order</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">])):</span>
            <span class="k">if</span> <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># TODO make a real &#39;None action&#39; that prints as empty string and make mypy happy</span>
                <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>  <span class="c1"># type: ignore[call-overload]</span>

    <span class="c1"># Calculate the maximum number of steps across all ranks</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">pipeline_order</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="n">step_labels</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;Step &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Sorting the dictionary by keys and retrieving values in that order</span>
    <span class="n">rank_actions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">pipeline_order</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_steps</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Transpose the list of lists (rows to columns)</span>
    <span class="n">transposed_actions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="o">*</span><span class="n">rank_actions</span><span class="p">,</span> <span class="n">fillvalue</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">))</span>
    <span class="c1"># Generate column labels for ranks</span>
    <span class="n">num_ranks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)</span>
    <span class="n">rank_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Rank &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_ranks</span><span class="p">)]</span>
    <span class="c1"># Calculate the maximum length of each column, considering labels</span>
    <span class="n">max_lengths</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">))</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">col</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">step_labels</span><span class="p">,</span> <span class="o">*</span><span class="n">transposed_actions</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Format the header row with rank labels</span>
    <span class="n">header_row</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">step_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">:</span><span class="s2">&lt;</span><span class="si">{</span><span class="n">max_lengths</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rank_labels</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># Format each row with its corresponding label</span>
    <span class="n">formatted_rows</span> <span class="o">=</span> <span class="p">[</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">: &quot;</span>
        <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="si">:</span><span class="s2">&lt;</span><span class="si">{</span><span class="n">max_lengths</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row</span><span class="p">))</span>
        <span class="o">+</span> <span class="p">(</span>
            <span class="s2">&quot; &lt;-- ERROR HERE&quot;</span>
            <span class="k">if</span> <span class="n">error_step_number</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">error_step_number</span>
            <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">step_labels</span><span class="p">,</span> <span class="n">transposed_actions</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Join the rows into a single string</span>
    <span class="n">formatted_table</span> <span class="o">=</span> <span class="n">header_row</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">formatted_rows</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">formatted_table</span>


<span class="k">class</span><span class="w"> </span><span class="nc">_PipelineSchedule</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># From arguments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">=</span> <span class="n">n_microbatches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="c1"># Chunking specification for positional inputs. (default: `None`)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_args_chunk_spec</span> <span class="o">=</span> <span class="n">args_chunk_spec</span>
        <span class="c1"># Chunking specification for keyword inputs. (default: `None`)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_kwargs_chunk_spec</span> <span class="o">=</span> <span class="n">kwargs_chunk_spec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_merge_spec</span> <span class="o">=</span> <span class="n">output_merge_spec</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        # args_chunk_spec and kwargs_chunk_spec specify how to chunk inputs.</span>
<span class="sd">        # They are used to convert batch to microbatches in `step(x)`.  See</span>
<span class="sd">        # `TensorChunkSpec` for helper methods for creating them.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Derived</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="c1"># Holds the losses for each microbatch.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">[</span><span class="n">mb_index</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">):</span>
        <span class="n">valid_index</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">mb_index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="ow">and</span> <span class="n">valid_index</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">[</span><span class="n">mb_index</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">valid_index</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Loss for microbatch </span><span class="si">{</span><span class="n">mb_index</span><span class="si">}</span><span class="s2"> is not available. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Available losses for microbatches: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stages</span><span class="p">,</span> <span class="n">losses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the losses to those in the internal state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if stages not a list turn into a list</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stages</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span><span class="n">stages</span><span class="p">]</span>
        <span class="n">contains_last_stage</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">stages</span><span class="p">)</span>

        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="k">if</span> <span class="n">contains_last_stage</span> <span class="ow">and</span> <span class="n">losses</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expecting </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="si">}</span><span class="s2"> losses but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Clean external container first</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="c1"># Copy internal losses to external container</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with list of microbatches.</span>
<span class="sd">        Will go through all the microbatches according to the schedule</span>
<span class="sd">        implementation.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatches: list of microbatch args.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with *whole-batch* input.</span>
<span class="sd">        Will chunk the input into microbatches automatically, and go through the</span>
<span class="sd">        microbatches according to the schedule implementation.</span>

<span class="sd">        args: positional arguments to the model (as in non-pipeline case).</span>
<span class="sd">        kwargs: keyword arguments to the model (as in non-pipeline case).</span>
<span class="sd">        target: target for the loss function.</span>
<span class="sd">        losses: a list to store the losses for each microbatch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_check_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pre-process/check inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">check_type_and_len</span><span class="p">(</span><span class="n">mbs</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mbs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> must be a list but got a </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">mbs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mbs</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expecting </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mbs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">arg_mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">check_type_and_len</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="s2">&quot;arg_mbs&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">arg_mbs</span> <span class="o">=</span> <span class="p">[()]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>

        <span class="k">if</span> <span class="n">kwarg_mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">check_type_and_len</span><span class="p">(</span><span class="n">kwarg_mbs</span><span class="p">,</span> <span class="s2">&quot;kwarg_mbs&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="p">[{}]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>

        <span class="k">if</span> <span class="n">target_mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">check_type_and_len</span><span class="p">(</span><span class="n">target_mbs</span><span class="p">,</span> <span class="s2">&quot;target_mbs&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">losses</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;losses must be a list but got a </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_split_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Splits a full-batch input into chunks (i.e. microbatches) and returns</span>
<span class="sd">        the chunks</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">args</span> <span class="ow">or</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span> <span class="o">=</span> <span class="n">split_args_kwargs_into_chunks</span><span class="p">(</span>
                <span class="n">args</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_args_chunk_spec</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_kwargs_chunk_spec</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Empty inputs (e.g. when called on middle stages)</span>
            <span class="c1"># Return a list of empty tuples/dicts with matching length as chunks</span>
            <span class="k">return</span> <span class="p">[()]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span> <span class="p">[{}]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_merge_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Merge output chunks back to a batch state.</span>
<span class="sd">        If output_merge_spec is None, the utility will merge output chunks by dimension 0 (batch dim).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">merge_chunks</span><span class="p">(</span>
            <span class="n">output_chunks</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_batch_p2p</span><span class="p">(</span><span class="n">p2p_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">],</span> <span class="n">desc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple wrapper over batch_isend_irecv from torch.distributed, which just adds a descriptive logger on top.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">p2p_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="n">desc_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">desc</span><span class="si">}</span><span class="s2">, &quot;</span> <span class="k">if</span> <span class="n">desc</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;batch_p2p </span><span class="si">%s%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">desc_str</span><span class="p">,</span> <span class="n">p2p_ops</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">batch_isend_irecv</span><span class="p">(</span><span class="n">p2p_ops</span><span class="p">)</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_sorted_batch_p2p</span><span class="p">(</span>
    <span class="n">p2p_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">],</span> <span class="n">desc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sorts the list of P2P ops by the peer rank, and then calls</span>
<span class="sd">    batch_isend_irecv. Return a dictionary of works by peer rank. This function</span>
<span class="sd">    helps us avoid hangs in case of skip connections.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Arrange p2p_ops by peer rank:</span>
    <span class="c1">#   int is the peer rank;</span>
    <span class="c1">#   List is the list of ops towards the peer</span>
    <span class="n">ops_by_peer</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">work_by_peer</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">p2p_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">work_by_peer</span>

    <span class="c1"># Classify the ops by peer rank</span>
    <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">p2p_ops</span><span class="p">:</span>
        <span class="n">ops_by_peer</span><span class="p">[</span><span class="n">op</span><span class="o">.</span><span class="n">peer</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

    <span class="c1"># Call batch_isend_irecv per peer, in sorted order of the peers (to avoid hangs)</span>
    <span class="k">for</span> <span class="n">peer</span><span class="p">,</span> <span class="n">ops</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">ops_by_peer</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="n">work_by_peer</span><span class="p">[</span><span class="n">peer</span><span class="p">]</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="n">desc</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">work_by_peer</span>


<div class="viewcode-block" id="PipelineScheduleSingle">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.PipelineScheduleSingle">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PipelineScheduleSingle</span><span class="p">(</span><span class="n">_PipelineSchedule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for single-stage schedules.</span>
<span class="sd">    Implements the `step` method.</span>
<span class="sd">    Derived classes should implement `_step_microbatches`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stage</span><span class="p">:</span> <span class="n">_PipelineStageBase</span><span class="p">,</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Init parent</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Self attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span> <span class="o">=</span> <span class="n">stage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">num_stages</span>
        <span class="c1"># Set the same has_backward flag for stage object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">has_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage_initialized</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_stage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">_prepare_forward_infra</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">_prepare_backward_infra</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage_initialized</span> <span class="o">=</span> <span class="kc">True</span>

<div class="viewcode-block" id="PipelineScheduleSingle.step">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.PipelineScheduleSingle.step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with *whole-batch* input.</span>
<span class="sd">        Will chunk the input into microbatches automatically, and go through the</span>
<span class="sd">        microbatches according to the schedule implementation.</span>

<span class="sd">        args: positional arguments to the model (as in non-pipeline case).</span>
<span class="sd">        kwargs: keyword arguments to the model (as in non-pipeline case).</span>
<span class="sd">        target: target for the loss function.</span>
<span class="sd">        losses: a list to store the losses for each microbatch.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Clean per iteration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">clear_runtime_states</span><span class="p">()</span>

        <span class="c1"># Split inputs into microbatches</span>
        <span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_inputs</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Split target into microbatches</span>
        <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">targets_split</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">targets_split</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Run microbatches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_step_microbatches</span><span class="p">(</span><span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span><span class="p">,</span> <span class="n">targets_split</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Return merged results per original format</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">is_last</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merge_outputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">output_chunks</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span></div>
</div>



<span class="k">class</span><span class="w"> </span><span class="nc">_ScheduleForwardOnly</span><span class="p">(</span><span class="n">PipelineScheduleSingle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The forward-only schedule.</span>
<span class="sd">    Will go through all the microbatches and perform only the forward pass</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">target_mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">losses</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Forward-only schedule does not support loss computation&quot;</span>
            <span class="p">)</span>

        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_stage</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Delay send waits</span>
        <span class="n">fwd_sends_to_wait</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Run microbatches</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Forward </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_recv&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>

                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_send&quot;</span><span class="p">)</span>
                <span class="n">fwd_sends_to_wait</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">%s</span><span class="s2">] Forwarded microbatch </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="c1"># Wait for all forward sends to finish</span>
        <span class="c1"># This should not have performance impact because by the time the first</span>
        <span class="c1"># backward arrives all the forward sends should have been finished.</span>
        <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">fwd_sends_to_wait</span><span class="p">:</span>
            <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>


<div class="viewcode-block" id="ScheduleGPipe">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleGPipe">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ScheduleGPipe</span><span class="p">(</span><span class="n">PipelineScheduleSingle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The GPipe schedule.</span>
<span class="sd">    Will go through all the microbatches in a fill-drain manner.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with list of microbatches.</span>
<span class="sd">        Will go through all the microbatches according to the GPipe schedule.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatches: list of microbatch args.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_stage</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Delay send waits</span>
        <span class="n">fwd_sends_to_wait</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Run microbatches</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Forward </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_recv&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>

                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_send&quot;</span><span class="p">)</span>
                <span class="n">fwd_sends_to_wait</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">%s</span><span class="s2">] Forwarded microbatch </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="c1"># Wait for all forward sends to finish</span>
        <span class="c1"># This should not have performance impact because by the time the first</span>
        <span class="c1"># backward arrives all the forward sends should have been finished.</span>
        <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">fwd_sends_to_wait</span><span class="p">:</span>
            <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="c1"># No loss function, no need to run backward</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Run backward</span>
        <span class="c1"># Delay send waits</span>
        <span class="n">bwd_sends_to_wait</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Backward </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_recv&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span>
                    <span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">last_backward</span><span class="o">=</span><span class="n">i</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="p">)</span>

                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_send&quot;</span><span class="p">)</span>
                <span class="n">bwd_sends_to_wait</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">%s</span><span class="s2">] Backwarded microbatch </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Wait for all backward sends to finish</span>
        <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">bwd_sends_to_wait</span><span class="p">:</span>
            <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span></div>



<div class="viewcode-block" id="Schedule1F1B">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.Schedule1F1B">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Schedule1F1B</span><span class="p">(</span><span class="n">PipelineScheduleSingle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The 1F1B schedule.</span>
<span class="sd">    Will perform one forward and one backward on the microbatches in steady state.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with list of microbatches.</span>
<span class="sd">        Will go through all the microbatches according to the 1F1B schedule.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatches: list of microbatch args.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_stage</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Last stage has 1 warmup, second-to-last 2 warmups, ...</span>
        <span class="c1"># first stage `num_stages` warmups</span>
        <span class="n">warmup_chunks</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Chunk counters</span>
        <span class="n">fwd_mb_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">bwd_mb_index</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Warmup phase</span>
        <span class="n">send_work</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">fwd_sends</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup_chunks</span><span class="p">):</span>
            <span class="c1"># Receive activations</span>
            <span class="n">fwd_recvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">recv_work</span> <span class="o">:=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">fwd_recvs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_recv&quot;</span><span class="p">):</span>
                <span class="n">recv_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Compute</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">fwd_mb_index</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">fwd_mb_index</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>

            <span class="c1"># Clear previous chunk&#39;s forward sends (hopefully they have well</span>
            <span class="c1"># finished, otherwise, we are heavily communication bound, in which</span>
            <span class="c1"># case it doesn&#39;t create a lot of benefit to compute next chunk</span>
            <span class="c1"># eagerly either)</span>
            <span class="k">if</span> <span class="n">send_work</span><span class="p">:</span>
                <span class="n">send_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Send activations</span>
            <span class="n">fwd_sends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fwd_mb_index</span> <span class="o">!=</span> <span class="n">warmup_chunks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Safe to fire</span>
                <span class="n">send_work</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">fwd_sends</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_send&quot;</span><span class="p">)</span>
            <span class="c1"># otherwise:</span>
            <span class="c1">#   The last foward send is left for fuse with first 1B in 1B1F below</span>

            <span class="c1"># Compute loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="n">fwd_mb_index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Now we should have send ops left over, to be fused with first 1B of 1B1F phase below.</span>

        <span class="c1"># 1B1F phase</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>  <span class="c1"># Don&#39;t worry, we have a break inside</span>
            <span class="c1"># We actually do 1B first as the `1B1F` name indicates, so prepare its recv ops</span>
            <span class="n">bwd_recvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">)</span>

            <span class="c1"># Now, we need to fire the fwd_sends and bwd_recvs together</span>
            <span class="k">if</span> <span class="n">fuse_work</span> <span class="o">:=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">fwd_sends</span> <span class="o">+</span> <span class="n">bwd_recvs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_send_bwd_recv&quot;</span><span class="p">):</span>
                <span class="n">fuse_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Backward one chunk</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span>
                <span class="n">bwd_mb_index</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">last_backward</span><span class="o">=</span><span class="n">bwd_mb_index</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Get the bwd send ops, but don&#39;t fire, to be fused with the 1F below</span>
            <span class="n">bwd_sends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="n">bwd_mb_index</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">fwd_mb_index</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">:</span>
                <span class="c1"># We are done with 1B1F, so break with some left-over bwd_sends</span>
                <span class="k">break</span>

            <span class="c1"># We prepare 1F of the `1B1F`</span>
            <span class="n">fwd_recvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">)</span>

            <span class="c1"># Fuse it with bwd_sends above</span>
            <span class="k">if</span> <span class="n">fuse_work</span> <span class="o">:=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">bwd_sends</span> <span class="o">+</span> <span class="n">fwd_recvs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_send_fwd_recv&quot;</span><span class="p">):</span>
                <span class="n">fuse_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Now do the fwd</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">fwd_mb_index</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">fwd_mb_index</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>

            <span class="c1"># Compute loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">fwd_mb_index</span><span class="p">)</span>

            <span class="c1"># Get the fwd send ops, but don&#39;t fire, leave it for the next iter (wrap-around)</span>
            <span class="n">fwd_sends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="n">fwd_mb_index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Remember we still have some bwd_sends left over after the break? Now it is time to fire it</span>
        <span class="n">send_work</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">bwd_sends</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_send&quot;</span><span class="p">)</span>

        <span class="c1"># Cooldown</span>
        <span class="k">while</span> <span class="n">bwd_mb_index</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">:</span>
            <span class="c1"># prepare bwd recv ops</span>
            <span class="n">bwd_recvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">recv_work</span> <span class="o">:=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">bwd_recvs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_recv&quot;</span><span class="p">):</span>
                <span class="n">recv_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Backward one chunk</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span>
                <span class="n">bwd_mb_index</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">last_backward</span><span class="o">=</span><span class="n">bwd_mb_index</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Clear previous chunk&#39;s backward sends (hopefully they have well finished)</span>
            <span class="k">if</span> <span class="n">send_work</span><span class="p">:</span>
                <span class="n">send_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Get the bwd send ops, fire it</span>
            <span class="n">bwd_sends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="n">send_work</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">bwd_sends</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_send&quot;</span><span class="p">)</span>
            <span class="n">bwd_mb_index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Wait for the last backward send to finish</span>
        <span class="k">if</span> <span class="n">send_work</span><span class="p">:</span>
            <span class="n">send_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_add_unshard_reshard</span><span class="p">(</span>
    <span class="n">compute_actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]],</span>
    <span class="n">max_active_stages</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Given a basic schedule involving only compute actions (F,B,W), add UNSHARD/RESHARD actions for FSDP.</span>

<span class="sd">    UNSHARD refers to fetching the full contents of an FSDP-sharded layer, requiring an all-gather operation.</span>
<span class="sd">    RESHARD does the opposite, releasing memory (but doing no commmunication)</span>

<span class="sd">    We abandon the &quot;timestep lock&quot;  during lowering</span>

<span class="sd">    max_active_stages controls how many prefetches we allow. It should be measured in mb and tuneable but in practice</span>
<span class="sd">    3 stages is probably the thing we want?</span>
<span class="sd">    (to account for having one f and one b active, and something else prefetching?)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">next_stage_indices</span><span class="p">(</span>
        <span class="n">count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">next_actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove duplicates (same stage, different microbatch), find next &#39;count&#39; stages that will do compute.&quot;&quot;&quot;</span>
        <span class="n">seen</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">ret</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">next_actions</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">a</span><span class="o">.</span><span class="n">stage_index</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
                <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)</span>
                <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="o">==</span> <span class="n">count</span><span class="p">:</span>
                    <span class="k">break</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="n">active_stages</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">fsdp_aware_actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_unshard</span><span class="p">(</span><span class="n">stage_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">active_stages</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">stage_index</span><span class="p">)</span>
        <span class="n">fsdp_aware_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_Action</span><span class="p">(</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">UNSHARD</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_reshard</span><span class="p">(</span><span class="n">stage_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">active_stages</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">stage_index</span><span class="p">)</span>
        <span class="n">fsdp_aware_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_Action</span><span class="p">(</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">RESHARD</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="c1"># We prefetch the next N stages we&#39;ll see, dropping existing stages to make room</span>
        <span class="n">next_n</span> <span class="o">=</span> <span class="n">next_stage_indices</span><span class="p">(</span><span class="n">max_active_stages</span><span class="p">,</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
        <span class="c1"># Fetch needs to be ordered correctly, so don&#39;t use a set</span>
        <span class="n">fetch</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">active_stages</span><span class="p">,</span> <span class="n">next_n</span><span class="p">))</span>
        <span class="c1"># Unclear what the best policy is for eviction, but we can maintain order so we do</span>
        <span class="n">evict</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">next_n</span><span class="p">,</span> <span class="n">active_stages</span><span class="p">))</span>

        <span class="c1"># logger.debug(</span>
        <span class="c1">#     &quot;_add_unshard_reshard Step %d active: %s fetch %s, evict %s&quot;,</span>
        <span class="c1">#     i,</span>
        <span class="c1">#     active_stages,</span>
        <span class="c1">#     fetch,</span>
        <span class="c1">#     evict,</span>
        <span class="c1"># )</span>

        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">evict</span><span class="p">:</span>
            <span class="n">_reshard</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">fetch</span><span class="p">:</span>
            <span class="n">_unshard</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
        <span class="n">fsdp_aware_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fsdp_aware_actions</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_merge_bw</span><span class="p">(</span>
    <span class="n">compute_actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Given a basic schedule involving only compute actions (F,I,W), merge adjacent I and W ops into B ops.</span>
<span class="sd">    (note: I = BACKWARD_INPUT, W = BACKWARD_WEIGHT, B = FULL_BACKWARD)</span>

<span class="sd">    B refers to running the whole backward (not separating grad_input and grad_weight), which can be more efficient</span>
<span class="sd">    in some cases.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">merged_actions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="n">compute_actions</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">compute_actions</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">next_action</span> <span class="o">:=</span> <span class="n">compute_actions</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># remove any None actions between &#39;action&#39; and &#39;next_action&#39;</span>
            <span class="n">compute_actions</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">BACKWARD_INPUT</span>
            <span class="ow">and</span> <span class="n">next_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="n">next_action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">BACKWARD_WEIGHT</span>
            <span class="ow">and</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">==</span> <span class="n">next_action</span><span class="o">.</span><span class="n">stage_index</span>
            <span class="ow">and</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span> <span class="o">==</span> <span class="n">next_action</span><span class="o">.</span><span class="n">microbatch_index</span>
        <span class="p">):</span>
            <span class="n">merged_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">FULL_BACKWARD</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">compute_actions</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">merged_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">merged_actions</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_add_send_recv</span><span class="p">(</span>
    <span class="n">compute_actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]],</span>
    <span class="n">stage_to_rank</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]:</span>
    <span class="n">comm_actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">compute_actions</span><span class="p">}</span>
    <span class="n">prev_actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="nb">set</span><span class="p">()</span> <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">compute_actions</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_has_comms</span><span class="p">(</span><span class="n">action</span><span class="p">:</span> <span class="n">_Action</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">F</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">!=</span> <span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">stage_to_rank</span><span class="p">(</span>
                <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="p">)</span> <span class="o">!=</span> <span class="n">stage_to_rank</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="ow">in</span> <span class="p">(</span><span class="n">BACKWARD_INPUT</span><span class="p">,</span> <span class="n">FULL_BACKWARD</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">stage_to_rank</span><span class="p">(</span>
                <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="p">)</span> <span class="o">!=</span> <span class="n">stage_to_rank</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_comms</span><span class="p">(</span><span class="n">action</span><span class="p">:</span> <span class="n">_Action</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">_Action</span><span class="p">,</span> <span class="n">_Action</span><span class="p">]:</span>
        <span class="k">assert</span> <span class="n">_has_comms</span><span class="p">(</span><span class="n">action</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2"> is not a valid comm action&quot;</span>
        <span class="n">stage_idx</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
        <span class="n">ctype</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
        <span class="n">mb_idx</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
        <span class="n">send</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">SEND_F</span> <span class="k">if</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">F</span> <span class="k">else</span> <span class="n">SEND_B</span><span class="p">,</span> <span class="n">mb_idx</span><span class="p">)</span>
        <span class="n">recv_stage_idx</span> <span class="o">=</span> <span class="n">stage_idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">F</span> <span class="k">else</span> <span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">recv</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span><span class="n">recv_stage_idx</span><span class="p">,</span> <span class="n">RECV_F</span> <span class="k">if</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">F</span> <span class="k">else</span> <span class="n">RECV_B</span><span class="p">,</span> <span class="n">mb_idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">send</span><span class="p">,</span> <span class="n">recv</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_ready_to_schedule</span><span class="p">(</span>
        <span class="n">action</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">],</span> <span class="n">prev_actions</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">_Action</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;We don&#39;t put our own recv ops in the schedule, we let a sender on another rank put our recv ops in place.</span>
<span class="sd">        This helps ensure a sane (non-hanging) ordering of sends and recvs.</span>
<span class="sd">        But it also means we might not be able to schedule our next compute action yet.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">F</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">RECV_F</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
                <span class="ow">in</span> <span class="n">prev_actions</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
                <span class="ow">in</span> <span class="n">prev_actions</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="ow">in</span> <span class="p">(</span><span class="n">BACKWARD_INPUT</span><span class="p">,</span> <span class="n">FULL_BACKWARD</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">==</span> <span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">RECV_B</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
                <span class="ow">in</span> <span class="n">prev_actions</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">BACKWARD_INPUT</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
                <span class="ow">in</span> <span class="n">prev_actions</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">FULL_BACKWARD</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
                <span class="ow">in</span> <span class="n">prev_actions</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

    <span class="k">while</span> <span class="n">compute_actions</span><span class="p">:</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># go in order of ranks even if dict keys aren&#39;t ordered</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">):</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rank</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span><span class="si">=}</span><span class="s2">&quot;</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">_ready_to_schedule</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">prev_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]):</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">comm_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">prev_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">_has_comms</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
                    <span class="n">send</span><span class="p">,</span> <span class="n">recv</span> <span class="o">=</span> <span class="n">_get_comms</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                    <span class="c1"># TODO we can avoid send/recv if the 2 stages are on the same rank.</span>
                    <span class="c1"># should we avoid that in the runtime or here?</span>
                    <span class="n">comm_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">send</span><span class="p">)</span>
                    <span class="n">prev_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">send</span><span class="p">)</span>
                    <span class="n">comm_actions</span><span class="p">[</span><span class="n">stage_to_rank</span><span class="p">(</span><span class="n">recv</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recv</span><span class="p">)</span>
                    <span class="n">prev_actions</span><span class="p">[</span><span class="n">stage_to_rank</span><span class="p">(</span><span class="n">recv</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">recv</span><span class="p">)</span>

            <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
            <span class="n">progress</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">assert</span> <span class="n">progress</span><span class="p">,</span> <span class="s2">&quot;Malformed compute schedule, can&#39;t schedule sends/recvs&quot;</span>
    <span class="k">return</span> <span class="n">comm_actions</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_validate_schedule</span><span class="p">(</span>
    <span class="n">actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]],</span>
    <span class="n">pp_group_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">==</span> <span class="n">pp_group_size</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Schedule has incorrect number of ranks - expected </span><span class="si">{</span><span class="n">pp_group_size</span><span class="si">}</span><span class="s2">, actual </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_group_size</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Schedule is missing actions for rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># We will count all the actions per stage and ensure they happen in a valid order</span>
    <span class="c1"># (e.g. F before (B, I) before W for a given microbatch)</span>
    <span class="n">stage_actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">_ComputationType</span><span class="p">,</span> <span class="n">Set</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">stage_id</span><span class="p">:</span> <span class="p">{</span>
            <span class="n">F</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>
            <span class="n">B</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>
            <span class="n">I</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>
            <span class="n">W</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">stage_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_stages</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">action</span><span class="p">,</span> <span class="n">_Action</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Got an invalid action: </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">, expected instance of _Action&quot;</span>
            <span class="n">s_id</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
            <span class="n">ctype</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
            <span class="n">mb_id</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
            <span class="k">if</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">F</span><span class="p">:</span>
                <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">F</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mb_id</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">B</span><span class="p">:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">mb_id</span> <span class="ow">in</span> <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">F</span><span class="p">]</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Running Full Backward for stage </span><span class="si">{</span><span class="n">s_id</span><span class="si">}</span><span class="s2">, microbatch </span><span class="si">{</span><span class="n">mb_id</span><span class="si">}</span><span class="s2"> without first running Forward&quot;</span>
                <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mb_id</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">I</span><span class="p">:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">mb_id</span> <span class="ow">in</span> <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">F</span><span class="p">]</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Running Backward Input for stage </span><span class="si">{</span><span class="n">s_id</span><span class="si">}</span><span class="s2">, microbatch </span><span class="si">{</span><span class="n">mb_id</span><span class="si">}</span><span class="s2"> without first running Forward&quot;</span>
                <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">I</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mb_id</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">W</span><span class="p">:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">mb_id</span> <span class="ow">in</span> <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">I</span><span class="p">]</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Running Backward Weight for stage </span><span class="si">{</span><span class="n">s_id</span><span class="si">}</span><span class="s2">, microbatch </span><span class="si">{</span><span class="n">mb_id</span><span class="si">}</span><span class="s2"> without first running Backward Input&quot;</span>
                <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">W</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mb_id</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">s_id</span> <span class="ow">in</span> <span class="n">stage_actions</span><span class="p">:</span>
        <span class="n">f_mb</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">F</span><span class="p">])</span>
        <span class="n">b_mb</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">B</span><span class="p">])</span>
        <span class="n">i_mb</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">I</span><span class="p">])</span>
        <span class="n">w_mb</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">W</span><span class="p">])</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">f_mb</span> <span class="o">==</span> <span class="n">num_microbatches</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="n">f_mb</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">F</span><span class="si">}</span><span class="s2"> microbatches for stage </span><span class="si">{</span><span class="n">s_id</span><span class="si">}</span><span class="s2">, expected </span><span class="si">{</span><span class="n">num_microbatches</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">b_mb</span> <span class="o">+</span> <span class="p">(</span><span class="n">i_mb</span> <span class="o">+</span> <span class="n">w_mb</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">==</span> <span class="n">num_microbatches</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Invalid backward microbatches for stage </span><span class="si">{</span><span class="n">s_id</span><span class="si">}</span><span class="s2">: expected </span><span class="si">{</span><span class="n">num_microbatches</span><span class="si">}</span><span class="s2"> total backwards, </span><span class="se">\</span>
<span class="s2">            but got B=</span><span class="si">{</span><span class="n">b_mb</span><span class="si">}</span><span class="s2">, I=</span><span class="si">{</span><span class="n">i_mb</span><span class="si">}</span><span class="s2">, W=</span><span class="si">{</span><span class="n">w_mb</span><span class="si">}</span><span class="s2">&quot;</span>


<div class="viewcode-block" id="PipelineScheduleMulti">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.PipelineScheduleMulti">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PipelineScheduleMulti</span><span class="p">(</span><span class="n">_PipelineSchedule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for multi-stage schedules.</span>
<span class="sd">    Implements the `step` method.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stage_index_to_group_rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_full_backward</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Init parent</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Self attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span> <span class="o">=</span> <span class="n">stages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_stages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_rank</span>
        <span class="c1"># Set the pipeline stage states</span>
        <span class="k">if</span> <span class="n">stage_index_to_group_rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
                <span class="n">stage</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span> <span class="o">=</span> <span class="n">stage_index_to_group_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span>

        <span class="c1"># Set the same has_backward flag for stage object</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">has_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stages_initialized</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># avoid putting a reference to &#39;self&#39; inside the lambda, it creates a ref cycle</span>
        <span class="n">has_loss</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_should_compute_loss</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">stage</span><span class="p">:</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="ow">and</span> <span class="n">has_loss</span>

        <span class="c1"># This will be set during init of derived schedules</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="n">use_full_backward</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Deprecation warning: &#39;use_full_backward&#39; is no longer supported. &quot;</span>
                <span class="s2">&quot;Simply stop passing it, and everything should still work fine.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_stages</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># may be &#39;none&#39; value (if this stage sends its output shapes to the next stage via P2P)</span>
        <span class="c1"># or real value (if this stage and next stage are on the same device)</span>
        <span class="n">next_stage_args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_first</span><span class="p">:</span>
                <span class="n">next_stage_args</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">_prepare_forward_infra</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">next_stage_args</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">_prepare_forward_infra</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span> <span class="n">next_stage_args</span><span class="p">,</span> <span class="n">kwargs</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
                <span class="n">stage</span><span class="o">.</span><span class="n">_prepare_backward_infra</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stages_initialized</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_dump_csv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Dump a CSV representation of the schedule into a file with the provided filename.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
            <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">csvfile</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_csv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;compute_only&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a CSV representation of the schedule from a file with the provided filename.</span>
<span class="sd">        This API will most likely get renamed/refactored so is marked as internal for now.</span>

<span class="sd">        format must be &quot;compute_only&quot; for PipelineScheduleMulti</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;compute_only&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
            <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reader</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">_Action</span><span class="o">.</span><span class="n">from_str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span>
        <span class="n">_validate_schedule</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="PipelineScheduleMulti.step">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.PipelineScheduleMulti.step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with *whole-batch* input.</span>
<span class="sd">        Will chunk the input into microbatches automatically, and go through the</span>
<span class="sd">        microbatches according to the schedule implementation.</span>

<span class="sd">        args: positional arguments to the model (as in non-pipeline case).</span>
<span class="sd">        kwargs: keyword arguments to the model (as in non-pipeline case).</span>
<span class="sd">        target: target for the loss function.</span>
<span class="sd">        losses: a list to store the losses for each microbatch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Clean per iteration</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">clear_runtime_states</span><span class="p">()</span>

        <span class="c1"># Split inputs into microbatches</span>
        <span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_inputs</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Split target into microbatches</span>
        <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">targets_split</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">targets_split</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Run microbatches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_step_microbatches</span><span class="p">(</span><span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span><span class="p">,</span> <span class="n">targets_split</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Return merged results per original format</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merge_outputs</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">output_chunks</span><span class="p">)</span>
        <span class="c1"># Does not contain the last stage</span>
        <span class="k">return</span> <span class="kc">None</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Operate on the microbatches for looped schedules (multiple stages on each rank).</span>

<span class="sd">        TODO: Does not use sorted_batch_isend_irecv(). As a result, this schedule does</span>
<span class="sd">        not support models with skip connections.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_stages</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Based on the plan in Step 1 created in __init__:</span>
        <span class="c1"># 2. Perform communication based on the pipeline_order</span>
        <span class="n">stage_index_to_stage</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">_PipelineStageBase</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">:</span> <span class="n">stage</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span>
        <span class="p">}</span>

        <span class="c1"># determine prev_rank and next_rank based on which ranks are next to</span>
        <span class="c1"># the stages in the pipeline_order</span>
        <span class="n">all_prev_ranks</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">all_next_ranks</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">stage_index</span> <span class="ow">in</span> <span class="n">stage_index_to_stage</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="c1"># TODO: assumption that stages only communicate from distances of +1/-1 (no skip connections)</span>
            <span class="k">if</span> <span class="n">stage_index</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">all_prev_ranks</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span><span class="p">[</span><span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">stage_index</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">all_next_ranks</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span><span class="p">[</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="c1"># count either full_backward or backward_weight together, to determine when to sync DP grads</span>
        <span class="n">backward_counter</span><span class="p">:</span> <span class="n">Counter</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">]):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">computation_type</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
                    <span class="n">mb_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
                    <span class="n">stage_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="p">),</span> <span class="s2">&quot;All currently supported action types require valid microbatch_index&quot;</span>
                    <span class="k">if</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span>
                        <span class="c1"># perform forward computation</span>
                        <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                        <span class="n">output</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span>
                            <span class="n">mb_index</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">mb_index</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">mb_index</span><span class="p">]</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                        <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                    <span class="k">elif</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FULL_BACKWARD</span><span class="p">:</span>
                        <span class="c1"># perform backward computation</span>
                        <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                        <span class="n">backward_counter</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="n">stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span>
                            <span class="n">mb_index</span><span class="p">,</span>
                            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                            <span class="n">full_backward</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">last_backward</span><span class="o">=</span><span class="n">backward_counter</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                            <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                    <span class="k">elif</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_INPUT</span><span class="p">:</span>
                        <span class="c1"># perform backward computation</span>
                        <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                        <span class="n">stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span>
                            <span class="n">mb_index</span><span class="p">,</span>
                            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                            <span class="n">full_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">last_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                    <span class="k">elif</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_WEIGHT</span><span class="p">:</span>
                        <span class="c1"># perform weight update</span>
                        <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                        <span class="n">backward_counter</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="n">stage</span><span class="o">.</span><span class="n">backward_weight_one_chunk</span><span class="p">(</span>
                            <span class="n">mb_index</span><span class="p">,</span>
                            <span class="n">last_backward</span><span class="o">=</span><span class="n">backward_counter</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                            <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown computation type </span><span class="si">{</span><span class="n">computation_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Look at the neighboring ranks for this current timestep and determine whether</span>
                <span class="c1"># this current rank needs to do any recv communication</span>
                <span class="k">for</span> <span class="n">prev_rank</span> <span class="ow">in</span> <span class="n">all_prev_ranks</span><span class="p">:</span>
                    <span class="n">prev_rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">prev_rank</span><span class="p">]</span>
                    <span class="n">prev_rank_action</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">time_step</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">prev_rank_ops</span><span class="p">):</span>
                        <span class="n">prev_rank_action</span> <span class="o">=</span> <span class="n">prev_rank_ops</span><span class="p">[</span><span class="n">time_step</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">prev_rank_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">computation_type</span> <span class="o">=</span> <span class="n">prev_rank_action</span><span class="o">.</span><span class="n">computation_type</span>
                        <span class="n">mb_index</span> <span class="o">=</span> <span class="n">prev_rank_action</span><span class="o">.</span><span class="n">microbatch_index</span>
                        <span class="n">stage_index</span> <span class="o">=</span> <span class="n">prev_rank_action</span><span class="o">.</span><span class="n">stage_index</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="p">),</span> <span class="s2">&quot;All currently supported action types require valid microbatch_index&quot;</span>
                        <span class="c1"># Only handle sends for the forward from a previous rank</span>
                        <span class="k">if</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span>
                            <span class="c1"># If not the last stage, then receive fwd activations</span>
                            <span class="k">if</span> <span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">stage_index_to_stage</span><span class="p">:</span>
                                <span class="c1"># TODO: We are assuming that stage will always receive from stage-1</span>
                                <span class="c1"># however that is not necessarily true of get_fwd_recv_ops</span>
                                <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                                <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                        <span class="k">elif</span> <span class="n">computation_type</span> <span class="ow">in</span> <span class="p">(</span>
                            <span class="n">FULL_BACKWARD</span><span class="p">,</span>
                            <span class="n">BACKWARD_INPUT</span><span class="p">,</span>
                            <span class="n">BACKWARD_WEIGHT</span><span class="p">,</span>
                        <span class="p">):</span>
                            <span class="c1"># Previous rank doing backward has no influence for the current rank forward recv</span>
                            <span class="k">pass</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Unknown computation type </span><span class="si">{</span><span class="n">computation_type</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>
                <span class="k">for</span> <span class="n">next_rank</span> <span class="ow">in</span> <span class="n">all_next_ranks</span><span class="p">:</span>
                    <span class="n">next_rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">next_rank</span><span class="p">]</span>
                    <span class="n">next_rank_action</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">time_step</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">next_rank_ops</span><span class="p">):</span>
                        <span class="n">next_rank_action</span> <span class="o">=</span> <span class="n">next_rank_ops</span><span class="p">[</span><span class="n">time_step</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">next_rank_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">computation_type</span> <span class="o">=</span> <span class="n">next_rank_action</span><span class="o">.</span><span class="n">computation_type</span>
                        <span class="n">mb_index</span> <span class="o">=</span> <span class="n">next_rank_action</span><span class="o">.</span><span class="n">microbatch_index</span>
                        <span class="n">stage_index</span> <span class="o">=</span> <span class="n">next_rank_action</span><span class="o">.</span><span class="n">stage_index</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="p">),</span> <span class="s2">&quot;All currently supported action types require valid microbatch_index&quot;</span>
                        <span class="c1"># Only handle receives for the backwards from a next rank</span>
                        <span class="k">if</span> <span class="n">computation_type</span> <span class="ow">in</span> <span class="p">(</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">BACKWARD_WEIGHT</span><span class="p">):</span>
                            <span class="c1"># Next rank doing forward or weight update has no influence for the current rank backward recv</span>
                            <span class="k">pass</span>
                        <span class="k">elif</span> <span class="n">computation_type</span> <span class="ow">in</span> <span class="p">(</span><span class="n">BACKWARD_INPUT</span><span class="p">,</span> <span class="n">FULL_BACKWARD</span><span class="p">):</span>
                            <span class="c1"># If not the first stage, then receive bwd gradients</span>
                            <span class="k">if</span> <span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">stage_index_to_stage</span><span class="p">:</span>
                                <span class="c1"># TODO: We are assuming that stage will always receive from stage+1</span>
                                <span class="c1"># however that is not necessarily true of get_bwd_recv_ops</span>
                                <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                                <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Unknown computation type </span><span class="si">{</span><span class="n">computation_type</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>

                <span class="c1"># do the communication</span>
                <span class="k">if</span> <span class="n">ops</span><span class="p">:</span>
                    <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">)</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;[Rank </span><span class="si">%s</span><span class="s2">] pipeline schedule </span><span class="si">%s</span><span class="s2"> caught the following exception </span><span class="se">\</span>
<span class="s2">                     at time_step </span><span class="si">%s</span><span class="s2"> when running action </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                    <span class="n">time_step</span><span class="p">,</span>
                    <span class="n">action</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">_format_pipeline_order</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">,</span> <span class="n">error_step_number</span><span class="o">=</span><span class="n">time_step</span>
                    <span class="p">),</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="n">e</span>
        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span></div>



<span class="k">class</span><span class="w"> </span><span class="nc">_PipelineScheduleRuntime</span><span class="p">(</span><span class="n">PipelineScheduleMulti</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Provides a simple runtime that requires a &#39;schedule IR&#39; including specified communication operations.</span>

<span class="sd">    Can be instantiated directly by creating _PipelineScheduleRuntime and calling load_csv, or can be</span>
<span class="sd">    subclassed and the subclass can be responsible for creating a schedule IR.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_actions</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]],</span>
        <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;compute_only&quot;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given an in-memory representation for a simple compute-only schedule, lower it to a complex schedule including</span>
<span class="sd">        communication actions.  Stores the schedule in self, and must be called before running step_mo()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;stage_index_to_group_rank is required for PipelineScheduleRuntime&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;compute_comms&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]:</span>
                    <span class="k">assert</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="c1"># TODO what level of validation should we offer for compute+comms schedule?</span>
        <span class="k">elif</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;compute_only&quot;</span><span class="p">:</span>
            <span class="c1"># Perform schedule lowering</span>
            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">_add_unshard_reshard</span><span class="p">(</span>
                    <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span> <span class="o">=</span> <span class="n">_add_send_recv</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">,</span>
                <span class="n">stage_to_rank</span><span class="o">=</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span><span class="p">[</span><span class="n">s</span><span class="p">],</span>
                <span class="n">num_stages</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">format</span><span class="si">=}</span><span class="s2"> is not implemented&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_load_csv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;compute_only&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Loads a csv in simple format and then lowers it to include comunication actions</span>

<span class="sd">        format must be either &quot;compute_only&quot; or &quot;compute_comms&quot;.  If compute_only, the lowering passes</span>
<span class="sd">        will automatically be run to generate a compute_comms schedule.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;compute_only&quot;</span><span class="p">:</span>
            <span class="c1"># this will populate self.pipeline_order</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_load_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
            <span class="c1"># this will populate self.pipeline_order_with_comms</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_load_actions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;compute_comms&quot;</span><span class="p">:</span>
            <span class="n">actions</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
                <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reader</span><span class="p">):</span>
                    <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">_Action</span><span class="o">.</span><span class="n">from_str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_load_actions</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="nb">format</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">format</span><span class="si">=}</span><span class="s2"> is not implemented&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_dump_csv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Dump a CSV representation of the compute + comms schedule into a file with the provided filename.&quot;&quot;&quot;</span>
        <span class="c1"># TODO should there be an option to dump the compute_only schedule from PipelineScheduleRuntime? It&#39;s possible</span>
        <span class="c1"># that it does not exist if it was created from a compute_comms schedule.</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;Must initialize compute_comms schedule before dump_csv&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
            <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">csvfile</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">:</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_simulate_comms_compute</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">,</span>
            <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span><span class="p">[</span><span class="n">s</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Operate on the microbatches for looped schedules (multiple stages on each rank).</span>

<span class="sd">        TODO: Does not use sorted_batch_isend_irecv(). As a result, this schedule does</span>
<span class="sd">        not support models with skip connections.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_stages</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Based on the plan in Step 1 created in __init__:</span>
        <span class="c1"># 2. Perform communication based on the pipeline_order</span>
        <span class="n">stage_index_to_stage</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">_PipelineStageBase</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">:</span> <span class="n">stage</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span>
        <span class="p">}</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;Must call _load_actions() before calling _step_microbatches()&quot;</span>

        <span class="c1"># recv ops indexed by (stage_idx, mb_idx) need to be waited on before use</span>
        <span class="n">bwd_recv_ops</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">fwd_recv_ops</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># send ops should be waited on before step() exists, mainly for hygeine</span>
        <span class="n">send_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># we track which stages are &#39;active&#39; when used with FSDP, and wait on unshard ops before computing on stages</span>
        <span class="n">unshard_ops</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">UnshardHandle</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">unsharded_stages</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_assert_unsharded</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;If an unshard is active for `stage_idx`, wait() it and mark `stage_idx` unshared.&quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="n">stage_idx</span> <span class="ow">in</span> <span class="n">unshard_ops</span><span class="p">:</span>
                <span class="n">unshard_ops</span><span class="p">[</span><span class="n">stage_idx</span><span class="p">]</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
                <span class="k">del</span> <span class="n">unshard_ops</span><span class="p">[</span><span class="n">stage_idx</span><span class="p">]</span>
                <span class="n">unsharded_stages</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">)</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">stage_idx</span> <span class="ow">in</span> <span class="n">unsharded_stages</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Attempted to compute on sharded </span><span class="si">{</span><span class="n">stage_idx</span><span class="si">=}</span><span class="s2">&quot;</span>

        <span class="c1"># count either full_backward or backward_weight together, to determine when to sync DP grads</span>
        <span class="n">backward_counter</span><span class="p">:</span> <span class="n">Counter</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">]):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">comp_type</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
                <span class="n">mb_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
                    <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
                <span class="p">)</span>
                <span class="k">assert</span> <span class="n">mb_index</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">comp_type</span> <span class="ow">in</span> <span class="p">(</span>
                    <span class="n">UNSHARD</span><span class="p">,</span>
                    <span class="n">RESHARD</span><span class="p">,</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">action</span><span class="si">=}</span><span class="s2"> missing mb_index&quot;</span>
                <span class="n">stage_idx</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
                <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_idx</span><span class="p">]</span>
                <span class="n">stage_uses_fsdp</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">submod</span><span class="p">,</span> <span class="n">FSDPModule</span><span class="p">)</span>
                <span class="c1"># see [Note: V-schedule special case]</span>
                <span class="n">is_next_stage_on_this_rank</span> <span class="o">=</span> <span class="n">stage_idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">stage_index_to_stage</span>
                <span class="n">is_prev_stage_on_this_rank</span> <span class="o">=</span> <span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">stage_index_to_stage</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="s2">&quot;_PipelineScheduleRuntime running time_step </span><span class="si">%d</span><span class="s2">, action </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">time_step</span><span class="p">,</span>
                    <span class="n">action</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># TODO(whc) it&#39;s not actually safe to use _batch_p2p here in the uncommon case the model has skip-connections,</span>
                <span class="c1"># since we do not want to batch up ops between more than a pair of ranks.  _sorted_batch_p2p would be</span>
                <span class="c1"># safe to use instead.</span>
                <span class="c1"># However, I was wondering if I should avoid calling batched operators at all in the case that there is</span>
                <span class="c1"># only one operator per batch.  I could iterate through the &#39;fwd_send_ops&#39; one by one and run them.</span>
                <span class="k">if</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">SEND_F</span><span class="p">:</span>
                    <span class="n">send_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_batch_p2p</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">)))</span>
                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">SEND_B</span><span class="p">:</span>
                    <span class="n">send_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_batch_p2p</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">)))</span>
                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">RECV_F</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="n">stage_idx</span><span class="p">,</span>
                        <span class="n">mb_index</span><span class="p">,</span>
                    <span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">fwd_recv_ops</span><span class="p">,</span> <span class="s2">&quot;Recv twice for {stage_idx=} {mb_index=} without executing forward&quot;</span>
                    <span class="n">fwd_recv_ops</span><span class="p">[(</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)]</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span>
                        <span class="n">stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">RECV_B</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="n">stage_idx</span><span class="p">,</span>
                        <span class="n">mb_index</span><span class="p">,</span>
                    <span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bwd_recv_ops</span><span class="p">,</span> <span class="s2">&quot;Recv twice for {stage_idx=} {mb_index=} without executing backward&quot;</span>
                    <span class="n">bwd_recv_ops</span><span class="p">[(</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)]</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span>
                        <span class="n">stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">UNSHARD</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">stage_uses_fsdp</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">stage_idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unsharded_stages</span>
                            <span class="ow">and</span> <span class="n">stage_idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unshard_ops</span>
                        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Unsharding the same </span><span class="si">{</span><span class="n">stage_idx</span><span class="si">=}</span><span class="s2"> twice&quot;</span>
                        <span class="n">unshard_ops</span><span class="p">[</span><span class="n">stage_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">submod</span><span class="o">.</span><span class="n">unshard</span><span class="p">(</span><span class="n">async_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore[operator]</span>
                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">RESHARD</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">stage_uses_fsdp</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">stage_idx</span> <span class="ow">in</span> <span class="n">unsharded_stages</span>
                        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Resharding </span><span class="si">{</span><span class="n">stage_idx</span><span class="si">=}</span><span class="s2"> without unsharding&quot;</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">stage_idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unshard_ops</span>
                        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Resharding </span><span class="si">{</span><span class="n">stage_idx</span><span class="si">=}</span><span class="s2"> before finishing unshard&quot;</span>
                        <span class="n">stage</span><span class="o">.</span><span class="n">submod</span><span class="o">.</span><span class="n">reshard</span><span class="p">()</span>  <span class="c1"># type: ignore[operator]</span>
                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">FORWARD</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">stage_uses_fsdp</span><span class="p">:</span>
                        <span class="n">_assert_unsharded</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">)</span>

                    <span class="k">if</span> <span class="p">(</span>
                        <span class="ow">not</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_first</span>
                        <span class="c1"># no recv op expected for V-schedule special case (see [Note: V-schedule special case])</span>
                        <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_prev_stage_on_this_rank</span>
                    <span class="p">):</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">stage_idx</span><span class="p">,</span>
                            <span class="n">mb_index</span><span class="p">,</span>
                        <span class="p">)</span> <span class="ow">in</span> <span class="n">fwd_recv_ops</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Computing </span><span class="si">{</span><span class="n">action</span><span class="si">=}</span><span class="s2"> before receiving input&quot;</span>
                        <span class="n">fwd_recv_ops</span><span class="o">.</span><span class="n">pop</span><span class="p">((</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">))</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

                    <span class="n">output</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span>
                        <span class="n">mb_index</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">mb_index</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">mb_index</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>

                    <span class="c1"># SEND/RECV op are avoided for special case with 2 adjacent stages on same rank</span>
                    <span class="c1"># see [Note: V-schedule special case]</span>
                    <span class="k">if</span> <span class="n">is_next_stage_on_this_rank</span><span class="p">:</span>
                        <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_local_fwd_input</span><span class="p">(</span>
                            <span class="n">output</span><span class="p">,</span> <span class="n">mb_index</span>
                        <span class="p">)</span>

                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">FULL_BACKWARD</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">stage_uses_fsdp</span><span class="p">:</span>
                        <span class="n">_assert_unsharded</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">)</span>

                    <span class="k">if</span> <span class="p">(</span>
                        <span class="ow">not</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span>
                        <span class="c1"># no recv op expected for V-schedule special case (see [Note: V-schedule special case])</span>
                        <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_next_stage_on_this_rank</span>
                    <span class="p">):</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">stage_idx</span><span class="p">,</span>
                            <span class="n">mb_index</span><span class="p">,</span>
                        <span class="p">)</span> <span class="ow">in</span> <span class="n">bwd_recv_ops</span><span class="p">,</span> <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Attempted to run compute </span><span class="si">{</span><span class="n">action</span><span class="si">=}</span><span class="s2"> before receiving input&quot;</span>
                        <span class="p">)</span>
                        <span class="n">bwd_recv_ops</span><span class="o">.</span><span class="n">pop</span><span class="p">((</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">))</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                    <span class="n">backward_counter</span><span class="p">[</span><span class="n">stage_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span>
                        <span class="n">mb_index</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                        <span class="n">full_backward</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">last_backward</span><span class="o">=</span><span class="n">backward_counter</span><span class="p">[</span><span class="n">stage_idx</span><span class="p">]</span>
                        <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="c1"># SEND/RECV op are avoided for special case with 2 adjacent stages on same rank</span>
                    <span class="c1"># see [Note: V-schedule special case]</span>
                    <span class="k">if</span> <span class="n">is_prev_stage_on_this_rank</span><span class="p">:</span>
                        <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_local_bwd_input</span><span class="p">(</span>
                            <span class="n">stage</span><span class="o">.</span><span class="n">get_local_bwd_output</span><span class="p">(</span><span class="n">mb_index</span><span class="p">),</span> <span class="n">mb_index</span>
                        <span class="p">)</span>
                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">BACKWARD_INPUT</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">stage_uses_fsdp</span><span class="p">:</span>
                        <span class="n">_assert_unsharded</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">)</span>

                    <span class="k">if</span> <span class="ow">not</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_next_stage_on_this_rank</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">stage_idx</span><span class="p">,</span>
                            <span class="n">mb_index</span><span class="p">,</span>
                        <span class="p">)</span> <span class="ow">in</span> <span class="n">bwd_recv_ops</span><span class="p">,</span> <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Attempted to run compute </span><span class="si">{</span><span class="n">action</span><span class="si">=}</span><span class="s2"> before receiving input&quot;</span>
                        <span class="p">)</span>
                        <span class="n">bwd_recv_ops</span><span class="o">.</span><span class="n">pop</span><span class="p">((</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">))</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                    <span class="n">stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span>
                        <span class="n">mb_index</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                        <span class="n">full_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">last_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="c1"># SEND/RECV op are avoided for special case with 2 adjacent stages on same rank</span>
                    <span class="c1"># see [Note: V-schedule special case]</span>
                    <span class="k">if</span> <span class="n">is_prev_stage_on_this_rank</span><span class="p">:</span>
                        <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_local_bwd_input</span><span class="p">(</span>
                            <span class="n">stage</span><span class="o">.</span><span class="n">get_local_bwd_output</span><span class="p">(</span><span class="n">mb_index</span><span class="p">),</span> <span class="n">mb_index</span>
                        <span class="p">)</span>
                <span class="k">elif</span> <span class="n">comp_type</span> <span class="o">==</span> <span class="n">BACKWARD_WEIGHT</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">stage_uses_fsdp</span><span class="p">:</span>
                        <span class="n">_assert_unsharded</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">)</span>
                    <span class="n">backward_counter</span><span class="p">[</span><span class="n">stage_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">stage</span><span class="o">.</span><span class="n">backward_weight_one_chunk</span><span class="p">(</span>
                        <span class="n">mb_index</span><span class="p">,</span>
                        <span class="n">last_backward</span><span class="o">=</span><span class="n">backward_counter</span><span class="p">[</span><span class="n">stage_idx</span><span class="p">]</span>
                        <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">action</span><span class="si">=}</span><span class="s2"> is unknown or unsupported&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;_PipelineScheduleRuntime caught exception at step </span><span class="si">%s</span><span class="s2"> when running action </span><span class="si">%s</span><span class="s2">.  Full Schedule:&quot;</span><span class="p">,</span>
                    <span class="n">time_step</span><span class="p">,</span>
                    <span class="n">action</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># TODO(whc) what is the best practice for printing a multiline log?</span>
                <span class="c1"># logger will split it into multiple log lines, but this makes it hard to read (too wide)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">_format_pipeline_order</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order_with_comms</span><span class="p">,</span> <span class="n">error_step_number</span><span class="o">=</span><span class="n">time_step</span><span class="p">))</span>  <span class="c1"># type: ignore[arg-type]</span>
                <span class="k">raise</span> <span class="n">e</span>

        <span class="c1"># Mostly these operations should have finished long ago, but there isn&#39;t an obvious time when to wait for them</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">send_ops</span><span class="p">):</span>
            <span class="n">send_ops</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">unshard_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Unused unshard operations&quot;</span>

        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>


<div class="viewcode-block" id="ScheduleLoopedBFS">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleLoopedBFS">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ScheduleLoopedBFS</span><span class="p">(</span><span class="n">PipelineScheduleMulti</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Breadth-First Pipeline Parallelism.</span>
<span class="sd">    See https://arxiv.org/abs/2211.05953 for details.</span>
<span class="sd">    Simliar to Interleaved 1F1B, Looped BFS supports multiple stages per rank.</span>
<span class="sd">    What is different is that when microbatches are ready for multiple local</span>
<span class="sd">    stages, Loops BFS will prioritizes the earlier stage, running all available</span>
<span class="sd">    microbatches at once.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="n">stages</span><span class="p">,</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 1. Create the pipeline_order (all ranks do this calculation)</span>
        <span class="c1"># This will be used to keep track of the current state of the entire pipeline</span>
        <span class="c1"># pipeline_order[rank] = [Action(computation_type, microbatch_index, stage_index), ...]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># ========================================================================</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_single_rank_operations</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_ops</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_calculate_single_rank_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="p">):</span>
        <span class="n">n_local_stages</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">)</span>
        <span class="n">stage_indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span>
            <span class="n">rank</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">*</span> <span class="n">n_local_stages</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span>
        <span class="p">)</span>

        <span class="c1"># Store the list of operations used for that rank</span>
        <span class="c1"># Pre-padding, rank starts with no-ops based on the warmup.</span>
        <span class="n">rank_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rank</span><span class="p">)]</span>

        <span class="k">for</span> <span class="n">stage_index</span> <span class="ow">in</span> <span class="n">stage_indices</span><span class="p">:</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">mb_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># wait for the first backward to trickle up</span>
        <span class="c1"># which is 2 for every hop away</span>
        <span class="n">post_warmup_ops</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
        <span class="n">rank_ops</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">post_warmup_ops</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">stage_index</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">stage_indices</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FULL_BACKWARD</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">mb_index</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">rank_ops</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">_get_1f1b_rank_ops</span><span class="p">(</span>
    <span class="n">n_local_stages</span><span class="p">,</span>
    <span class="n">pp_group_size</span><span class="p">,</span>
    <span class="n">warmup_ops</span><span class="p">,</span>
    <span class="n">fwd_bwd_ops</span><span class="p">,</span>
    <span class="n">cooldown_ops</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">,</span>
    <span class="n">forward_stage_index</span><span class="p">,</span>
    <span class="n">backward_stage_index</span><span class="p">,</span>
    <span class="n">num_1f1b_microbatches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">enable_zero_bubble</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="c1"># All stages start with handling microbatch 0</span>
    <span class="n">fwd_stage_mb_index</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">bwd_stage_mb_index</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">weight_stage_mb_index</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Store the list of operations used for that rank</span>
    <span class="c1"># Pre-padding, rank starts with no-ops based on the warmup.</span>
    <span class="n">rank_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rank</span><span class="p">)]</span>
    <span class="c1"># These are used to calculate the number of slots to fill with no-ops, to account for the delay in warmup</span>
    <span class="c1"># when we want to wait for the backward to trickle back up and start 1f1b to align all ranks.</span>
    <span class="c1"># Formula:</span>
    <span class="c1"># pre-padding + warmup_ops + post_warmup_ops = earliest time step of first backward</span>
    <span class="c1"># post_warmup_ops = [earliest time step of first backward] - (warmup_ops + pre-padding)</span>
    <span class="c1"># earliest time step of first backward = [local_stages * group_size + 2 * (group_size - 1 - rank)]</span>
    <span class="c1"># warmup_ops = calculated above</span>
    <span class="n">post_warmup_ops</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">n_local_stages</span> <span class="o">*</span> <span class="n">pp_group_size</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">rank</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">enable_zero_bubble</span><span class="p">:</span>
        <span class="n">post_warmup_ops</span> <span class="o">=</span> <span class="n">pp_group_size</span> <span class="o">-</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">total_ops</span> <span class="o">=</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span> <span class="o">+</span> <span class="n">cooldown_ops</span>

    <span class="n">backward_op_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">weight_op_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">FULL_BACKWARD_OR_BACKWARD_INPUT</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">BACKWARD_INPUT</span> <span class="k">if</span> <span class="n">enable_zero_bubble</span> <span class="k">else</span> <span class="n">FULL_BACKWARD</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_ops</span><span class="p">):</span>
        <span class="c1"># Warmup phase</span>
        <span class="k">if</span> <span class="n">op</span> <span class="o">&lt;</span> <span class="n">warmup_ops</span><span class="p">:</span>
            <span class="n">fwd_stage_index</span> <span class="o">=</span> <span class="n">forward_stage_index</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="c1"># This will assign the current microbatch index and update it as well</span>
            <span class="n">fwd_stage_mb_index</span><span class="p">[</span><span class="n">fwd_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">mb_index</span> <span class="o">:=</span> <span class="n">fwd_stage_mb_index</span><span class="p">[</span><span class="n">fwd_stage_index</span><span class="p">]</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">fwd_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="n">warmup_ops</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># This is the last step in the warmup phase, so we need to wait for the backward to trickle back up</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">post_warmup_ops</span><span class="p">)</span>
        <span class="c1"># 1F1B Phase (forward and backward)</span>
        <span class="k">elif</span> <span class="n">warmup_ops</span> <span class="o">&lt;=</span> <span class="n">op</span> <span class="o">&lt;</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span><span class="p">:</span>
            <span class="n">fwd_stage_index</span> <span class="o">=</span> <span class="n">forward_stage_index</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">fwd_stage_mb_index</span><span class="p">[</span><span class="n">fwd_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">fwd_mb_index</span> <span class="o">:=</span> <span class="n">fwd_stage_mb_index</span><span class="p">[</span><span class="n">fwd_stage_index</span><span class="p">]</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">fwd_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">bwd_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">bwd_stage_mb_index</span><span class="p">[</span><span class="n">bwd_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">bwd_mb_index</span> <span class="o">:=</span> <span class="n">bwd_stage_mb_index</span><span class="p">[</span><span class="n">bwd_stage_index</span><span class="p">]</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">bwd_stage_index</span><span class="p">,</span> <span class="n">FULL_BACKWARD_OR_BACKWARD_INPUT</span><span class="p">,</span> <span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">backward_op_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">enable_zero_bubble</span> <span class="ow">and</span> <span class="n">op</span> <span class="o">-</span> <span class="n">warmup_ops</span> <span class="o">&gt;=</span> <span class="n">num_1f1b_microbatches</span><span class="p">:</span>
                <span class="n">weight_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span>
                    <span class="n">backward_op_ids</span><span class="p">[</span><span class="n">weight_op_count</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">weight_mb_index</span> <span class="o">:=</span> <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span>
                <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">_Action</span><span class="p">(</span>
                        <span class="n">weight_stage_index</span><span class="p">,</span>
                        <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_WEIGHT</span><span class="p">,</span>
                        <span class="n">weight_mb_index</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">weight_op_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Cooldown phase</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># During cooldown phase, we need steps to align with 1f1b happening in other ranks</span>
            <span class="c1"># TODO: we don&#39;t need to always append, after all 1f1b are finished we can stop appending None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">enable_zero_bubble</span><span class="p">:</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">bwd_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">bwd_stage_mb_index</span><span class="p">[</span><span class="n">bwd_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">bwd_mb_index</span> <span class="o">:=</span> <span class="n">bwd_stage_mb_index</span><span class="p">[</span><span class="n">bwd_stage_index</span><span class="p">]</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">bwd_stage_index</span><span class="p">,</span> <span class="n">FULL_BACKWARD_OR_BACKWARD_INPUT</span><span class="p">,</span> <span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">backward_op_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">enable_zero_bubble</span> <span class="ow">and</span> <span class="n">op</span> <span class="o">-</span> <span class="n">warmup_ops</span> <span class="o">&gt;=</span> <span class="n">num_1f1b_microbatches</span><span class="p">:</span>
                <span class="n">weight_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span>
                    <span class="n">backward_op_ids</span><span class="p">[</span><span class="n">weight_op_count</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">weight_mb_index</span> <span class="o">:=</span> <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span>
                <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">_Action</span><span class="p">(</span>
                        <span class="n">weight_stage_index</span><span class="p">,</span>
                        <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_WEIGHT</span><span class="p">,</span>
                        <span class="n">weight_mb_index</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">weight_op_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">while</span> <span class="n">enable_zero_bubble</span> <span class="ow">and</span> <span class="n">weight_op_count</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">backward_op_ids</span><span class="p">):</span>
        <span class="n">weight_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span><span class="n">backward_op_ids</span><span class="p">[</span><span class="n">weight_op_count</span><span class="p">])</span>
        <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">weight_mb_index</span> <span class="o">:=</span> <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span>
        <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">_Action</span><span class="p">(</span>
                <span class="n">weight_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD_WEIGHT</span><span class="p">,</span> <span class="n">weight_mb_index</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">weight_op_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">rank_ops</span>


<div class="viewcode-block" id="ScheduleInterleaved1F1B">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleInterleaved1F1B">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ScheduleInterleaved1F1B</span><span class="p">(</span><span class="n">PipelineScheduleMulti</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Interleaved 1F1B schedule.</span>
<span class="sd">    See https://arxiv.org/pdf/2104.04473 for details.</span>
<span class="sd">    Will perform one forward and one backward on the microbatches in steady</span>
<span class="sd">    state and supports multiple stages per rank. When microbatches are ready for</span>
<span class="sd">    multiple local stages, Interleaved 1F1B prioritizes the earlier microbatch</span>
<span class="sd">    (also called &quot;depth first&quot;).</span>

<span class="sd">    This schedule is mostly similar to the original paper.</span>
<span class="sd">    It differs by being relaxing the requirement of num_microbatch % pp_size == 0.</span>
<span class="sd">    Using the flex_pp schedule, we will have num_rounds = max(1, n_microbatches // pp_group_size) and</span>
<span class="sd">    it works as long as n_microbatches % num_rounds is 0. As a few examples, support</span>

<span class="sd">    1. pp_group_size = 4, n_microbatches = 10. We will have num_rounds = 2 and n_microbatches % 2 is 0.</span>
<span class="sd">    2. pp_group_size = 4, n_microbatches = 3. We will have num_rounds = 1 and n_microbatches % 1 is 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_size</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="n">stages</span><span class="p">,</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stages</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_microbatches</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span> <span class="o">=</span> <span class="n">n_microbatches</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span>
        <span class="k">if</span> <span class="n">n_microbatches</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Interleaved 1F1B requires the number of microbatches to be a &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;multiple of the number of rounds (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="n">n_microbatches</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># 1. Create the pipeline_order (all ranks do this calculation)</span>
        <span class="c1"># This will be used to keep track of the current state of the entire pipeline</span>
        <span class="c1"># pipeline_order[rank] = [Action(computation_type, microbatch_index, stage_index), ...]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_single_rank_operations</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_ops</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_calculate_single_rank_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]:</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">get_rank_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
            <span class="c1"># Warms up operations for last stage</span>
            <span class="n">warmups_ops_last_stage</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span>
            <span class="c1"># Increment warmup operations by 2 for each hop away from the last stage</span>
            <span class="n">multiply_factor</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">warmups_ops_last_stage</span> <span class="o">+</span> <span class="n">multiply_factor</span> <span class="o">*</span> <span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rank</span>
            <span class="p">)</span>

            <span class="c1"># We cannot have more warmup operations than there are number of microbatches, so cap it there</span>
            <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">warmup_ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">)</span>

        <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">get_rank_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
        <span class="n">microbatch_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>
        <span class="c1"># fwd_bwd_ops should encompass the remaining forwards</span>
        <span class="n">fwd_bwd_ops</span> <span class="o">=</span> <span class="n">microbatch_ops</span> <span class="o">-</span> <span class="n">warmup_ops</span>
        <span class="c1"># cooldown_ops should encompass the remaining backwards</span>
        <span class="n">cooldown_ops</span> <span class="o">=</span> <span class="n">microbatch_ops</span> <span class="o">-</span> <span class="n">fwd_bwd_ops</span>
        <span class="c1"># total ops encompass both forward and backward ops</span>
        <span class="n">total_ops</span> <span class="o">=</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span> <span class="o">+</span> <span class="n">cooldown_ops</span>
        <span class="c1"># warmup_ops + fwd_bwd_ops * 2 + cooldown_ops == microbatch_ops * 2</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;rank </span><span class="si">%s</span><span class="s2">, warmup_ops </span><span class="si">%s</span><span class="s2">, 1f1b </span><span class="si">%s</span><span class="s2">, cooldown_ops </span><span class="si">%s</span><span class="s2"> total_ops </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">warmup_ops</span><span class="p">,</span>
            <span class="n">fwd_bwd_ops</span><span class="p">,</span>
            <span class="n">cooldown_ops</span><span class="p">,</span>
            <span class="n">total_ops</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Calculates the stage index based on step and pp_group_size</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">forward_stage_index</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="c1"># Get the local index from 0 to n_local_stages-1</span>
            <span class="n">local_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_index</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">backward_stage_index</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="n">local_index</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
                <span class="o">-</span> <span class="mi">1</span>
                <span class="o">-</span> <span class="p">((</span><span class="n">step</span> <span class="o">-</span> <span class="n">warmup_ops</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span><span class="p">)</span>
                <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_index</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="k">return</span> <span class="n">_get_1f1b_rank_ops</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">,</span>
            <span class="n">warmup_ops</span><span class="p">,</span>
            <span class="n">fwd_bwd_ops</span><span class="p">,</span>
            <span class="n">cooldown_ops</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">forward_stage_index</span><span class="p">,</span>
            <span class="n">backward_stage_index</span><span class="p">,</span>
        <span class="p">)</span></div>



<div class="viewcode-block" id="ScheduleInterleavedZeroBubble">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleInterleavedZeroBubble">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ScheduleInterleavedZeroBubble</span><span class="p">(</span><span class="n">PipelineScheduleMulti</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Interleaved Zero Bubble schedule.</span>
<span class="sd">    See https://arxiv.org/pdf/2401.10241 for details.</span>
<span class="sd">    Will perform one forward and one backward on inputs for the microbatches in steady</span>
<span class="sd">    state and supports multiple stages per rank. Uses the backward for weights to fill in</span>
<span class="sd">    the pipeline bubble.</span>

<span class="sd">    In particular this is implementing the ZB1P schedule in the paper.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_size</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="n">stages</span><span class="p">,</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stages</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_microbatches</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span> <span class="o">=</span> <span class="n">n_microbatches</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span>
        <span class="k">if</span> <span class="n">n_microbatches</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Zero bubble requires the number of microbatches to be a &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;multiple of the number of rounds (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="n">n_microbatches</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># 1. Create the pipeline_order (all ranks do this calculation)</span>
        <span class="c1"># This will be used to keep track of the current state of the entire pipeline</span>
        <span class="c1"># pipeline_order[rank] = [Action(computation_type, microbatch_index, stage_index), ...]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_single_rank_operations</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_ops</span>

        <span class="c1"># This function add bubbles to the generated schedule based on dependencies of actions</span>
        <span class="c1"># Note that the ZB1P schedule will not require bubbles to be manually added and it is</span>
        <span class="c1"># only useful when n_microbatches &lt;= microbatches_per_round</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_bubbles_to_actions</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_calculate_single_rank_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]:</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">get_rank_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
            <span class="c1"># Warms up operations for last stage</span>
            <span class="n">warmups_ops_last_stage</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span>
            <span class="c1"># Increment warmup operations by 2 for each hop away from the last stage</span>
            <span class="n">multiply_factor</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">warmups_ops_last_stage</span> <span class="o">+</span> <span class="n">multiply_factor</span> <span class="o">*</span> <span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rank</span>
            <span class="p">)</span>

            <span class="c1"># We cannot have more warmup operations than there are number of microbatches, so cap it there</span>
            <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">warmup_ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">)</span>

        <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">get_rank_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
        <span class="n">microbatch_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>
        <span class="c1"># fwd_bwd_ops should encompass the remaining forwards</span>
        <span class="n">fwd_bwd_ops</span> <span class="o">=</span> <span class="n">microbatch_ops</span> <span class="o">-</span> <span class="n">warmup_ops</span>
        <span class="c1"># cooldown_ops should encompass the remaining backwards</span>
        <span class="n">cooldown_ops</span> <span class="o">=</span> <span class="n">microbatch_ops</span> <span class="o">-</span> <span class="n">fwd_bwd_ops</span>
        <span class="c1"># total ops encompass both forward and backward ops</span>
        <span class="n">total_ops</span> <span class="o">=</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span> <span class="o">+</span> <span class="n">cooldown_ops</span>
        <span class="c1"># warmup_ops + fwd_bwd_ops * 2 + cooldown_ops == microbatch_ops * 2</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;rank </span><span class="si">%s</span><span class="s2">, warmup_ops </span><span class="si">%s</span><span class="s2">, 1f1b </span><span class="si">%s</span><span class="s2">, cooldown_ops </span><span class="si">%s</span><span class="s2"> total_ops </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">warmup_ops</span><span class="p">,</span>
            <span class="n">fwd_bwd_ops</span><span class="p">,</span>
            <span class="n">cooldown_ops</span><span class="p">,</span>
            <span class="n">total_ops</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Calculates the stage index based on step and pp_group_size</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">forward_stage_index</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="c1"># Get the local index from 0 to n_local_stages-1</span>
            <span class="n">local_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_index</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">backward_stage_index</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="n">local_index</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
                <span class="o">-</span> <span class="mi">1</span>
                <span class="o">-</span> <span class="p">((</span><span class="n">step</span> <span class="o">-</span> <span class="n">warmup_ops</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span><span class="p">)</span>
                <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_index</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="n">num_1f1b_microbatches</span> <span class="o">=</span> <span class="n">rank</span>

        <span class="k">return</span> <span class="n">_get_1f1b_rank_ops</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">,</span>
            <span class="n">warmup_ops</span><span class="p">,</span>
            <span class="n">fwd_bwd_ops</span><span class="p">,</span>
            <span class="n">cooldown_ops</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">forward_stage_index</span><span class="p">,</span>
            <span class="n">backward_stage_index</span><span class="p">,</span>
            <span class="n">num_1f1b_microbatches</span><span class="p">,</span>
            <span class="n">enable_zero_bubble</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_add_bubbles_to_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_stages_global</span><span class="p">):</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">need_bubble</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">,</span> <span class="n">num_stages_global</span><span class="p">,</span> <span class="n">seen_ops</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">stage</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">stage</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen_ops</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FULL_BACKWARD</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="n">num_stages_global</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen_ops</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">stage</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen_ops</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">seen_ops</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">next_pointer</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">bubbles_added</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">total_bubbles_added</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">result</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">next_pointer</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">bubbles_added</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">should_stop</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="n">temp_seen_ops</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
                <span class="n">timestamp</span> <span class="o">=</span> <span class="n">next_pointer</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">timestamp</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]):</span>
                    <span class="k">continue</span>

                <span class="n">should_stop</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="k">if</span> <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">timestamp</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">temp_action</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">timestamp</span><span class="p">]</span>
                    <span class="k">assert</span> <span class="n">temp_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="n">stage_index</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span> <span class="o">=</span> <span class="n">temp_action</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">need_bubble</span><span class="p">(</span>
                        <span class="n">stage_index</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">,</span> <span class="n">num_stages_global</span><span class="p">,</span> <span class="n">seen_ops</span>
                    <span class="p">):</span>
                        <span class="n">result</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">timestamp</span><span class="p">])</span>
                        <span class="k">if</span> <span class="n">microbatch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">temp_seen_ops</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">))</span>
                        <span class="n">next_pointer</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">result</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                        <span class="n">bubbles_added</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">next_pointer</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">result</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">seen_ops</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">temp_seen_ops</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">should_stop</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="n">total_bubbles_added</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Non zero bubbles added: total_bubbles_added=</span><span class="si">%s</span><span class="s2"> bubbles_added=</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">total_bubbles_added</span><span class="p">,</span>
                <span class="n">bubbles_added</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>



<div class="viewcode-block" id="ScheduleZBVZeroBubble">
<a class="viewcode-back" href="../../../../python-api/distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleZBVZeroBubble">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ScheduleZBVZeroBubble</span><span class="p">(</span><span class="n">PipelineScheduleMulti</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Zero Bubble schedule (ZBV variant).</span>
<span class="sd">    See https://arxiv.org/pdf/2401.10241 Section 6 for details.</span>

<span class="sd">    This schedules requires exactly two stages per rank.</span>

<span class="sd">    This schedule will perform one forward and one backward on inputs for the microbatches in steady</span>
<span class="sd">    state and supports multiple stages per rank. Uses backward with respect to weights to fill in</span>
<span class="sd">    the pipeline bubble.</span>

<span class="sd">    This ZB-V schedule would have the &quot;zero bubble&quot; property only if time forward == time backward input == time backward weights.</span>
<span class="sd">    In practice, this is not likely true for real models so alternatively</span>
<span class="sd">    a greedy scheduler could be implemented for unequal/unbalanced time.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stage_index_to_group_rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_size</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="n">stages</span><span class="p">,</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
            <span class="n">stage_index_to_group_rank</span><span class="o">=</span><span class="n">stage_index_to_group_rank</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stages</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;ZBV requires exactly 2 stages per rank, but got &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_stages</span>

        <span class="c1"># 1. Create the pipeline_order (all ranks do this calculation)</span>
        <span class="c1"># This will be used to keep track of the current state of the entire pipeline</span>
        <span class="c1"># pipeline_order[rank] = [Action(computation_type, microbatch_index, stage_index), ...]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_single_rank_operations</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_ops</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_calculate_single_rank_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]:</span>
        <span class="c1"># max(2 * self.pp_group_size - 1, ...) ensure the number of microbatches is at least</span>
        <span class="c1"># as large of the number of microbatches needed to fully utilize the pipeline</span>
        <span class="n">n_micro</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">)</span>
        <span class="n">rank_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rank</span><span class="p">)]</span>

        <span class="c1"># Forward and backward action counts for stage chunk 0 and chunk 1</span>
        <span class="n">f0_cnt</span><span class="p">,</span> <span class="n">f1_cnt</span><span class="p">,</span> <span class="n">b0_cnt</span><span class="p">,</span> <span class="n">b1_cnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="c1"># warm-up phase</span>
        <span class="n">warmup_n1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">stage_id_chunk0</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="n">stage_id_chunk1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">rank</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup_n1</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">F</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">f0_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">f0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">warmup_n2</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup_n2</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">F</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">f1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">f1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">F</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">f0_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">f0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">warmup_n3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup_n3</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">F</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">f1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">f1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">b1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># stable phase</span>
        <span class="k">while</span> <span class="n">f1_cnt</span> <span class="o">&lt;</span> <span class="n">f0_cnt</span> <span class="ow">or</span> <span class="n">f0_cnt</span> <span class="o">&lt;</span> <span class="n">n_micro</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">f0_cnt</span> <span class="o">&lt;</span> <span class="n">n_micro</span><span class="p">:</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">_Action</span><span class="p">(</span>
                        <span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">F</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">f0_cnt</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">f0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b0_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b0_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">b0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">F</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">f1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">f1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">b1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># cool-down phase</span>
        <span class="n">w0_cnt</span><span class="p">,</span> <span class="n">w1_cnt</span> <span class="o">=</span> <span class="n">b0_cnt</span><span class="p">,</span> <span class="n">b1_cnt</span>
        <span class="n">cooldown_n1</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cooldown_n1</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b0_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">b0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">b1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">cooldown_n2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cooldown_n2</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">b0_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">b0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">w0_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">w0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">w1_cnt</span> <span class="o">&lt;</span> <span class="n">b1_cnt</span><span class="p">:</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk1</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">w1_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">w1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">w0_cnt</span> <span class="o">&lt;</span> <span class="n">b0_cnt</span><span class="p">:</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">stage_id_chunk0</span><span class="p">,</span> <span class="n">computation_type</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="n">w0_cnt</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">w0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">assert</span> <span class="n">w0_cnt</span> <span class="o">==</span> <span class="n">b0_cnt</span> <span class="ow">and</span> <span class="n">b0_cnt</span> <span class="o">==</span> <span class="n">f0_cnt</span>
        <span class="k">assert</span> <span class="n">w1_cnt</span> <span class="o">==</span> <span class="n">b1_cnt</span> <span class="ow">and</span> <span class="n">b1_cnt</span> <span class="o">==</span> <span class="n">f1_cnt</span>
        <span class="c1"># We use max() in the n_micro computation above, so we may need to</span>
        <span class="c1"># remove redundant microbatches</span>
        <span class="n">rank_ops</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span>
                <span class="n">action</span>
                <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">rank_ops</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">rank_ops</span></div>



<span class="k">def</span><span class="w"> </span><span class="nf">get_schedule_class</span><span class="p">(</span><span class="n">schedule_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Maps a schedule name (case insensitive) to its corresponding class object.</span>

<span class="sd">    Args:</span>
<span class="sd">        schedule_name (str): The name of the schedule.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">schedule_map</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;1F1B&quot;</span><span class="p">:</span> <span class="n">Schedule1F1B</span><span class="p">,</span>
        <span class="s2">&quot;Interleaved1F1B&quot;</span><span class="p">:</span> <span class="n">ScheduleInterleaved1F1B</span><span class="p">,</span>
        <span class="s2">&quot;GPipe&quot;</span><span class="p">:</span> <span class="n">ScheduleGPipe</span><span class="p">,</span>
        <span class="s2">&quot;LoopedBFS&quot;</span><span class="p">:</span> <span class="n">ScheduleLoopedBFS</span><span class="p">,</span>
        <span class="s2">&quot;InterleavedZeroBubble&quot;</span><span class="p">:</span> <span class="n">ScheduleInterleavedZeroBubble</span><span class="p">,</span>
        <span class="s2">&quot;PipelineScheduleSingle&quot;</span><span class="p">:</span> <span class="n">PipelineScheduleSingle</span><span class="p">,</span>
        <span class="s2">&quot;PipelineScheduleMulti&quot;</span><span class="p">:</span> <span class="n">PipelineScheduleMulti</span><span class="p">,</span>
        <span class="s2">&quot;ZBVZeroBubble&quot;</span><span class="p">:</span> <span class="n">ScheduleZBVZeroBubble</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">lowercase_keys</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">schedule_map</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
    <span class="n">lowercase_schedule_name</span> <span class="o">=</span> <span class="n">schedule_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">lowercase_schedule_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lowercase_keys</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unknown schedule name &#39;</span><span class="si">{</span><span class="n">schedule_name</span><span class="si">}</span><span class="s2">&#39;. The valid options are </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">schedule_map</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">schedule_map</span><span class="p">[</span><span class="n">lowercase_keys</span><span class="p">[</span><span class="n">lowercase_schedule_name</span><span class="p">]]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_simulate_comms_compute</span><span class="p">(</span>
    <span class="n">pipeline_order</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">],</span> <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function dry-run simulates the actions in the schedule from the perspective of all ranks, and flags</span>
<span class="sd">    any deadlocks caused by missing or misordered communications.  It also simulates any bubbles in time where a rank</span>
<span class="sd">    can not execute any action due to waiting for unmet dependencies.  The total number of simulator steps can be used</span>
<span class="sd">    as a metric for unit tests involving IR optimization passes as reordering and merging of IR can reduce the number</span>
<span class="sd">    of simulated steps.</span>

<span class="sd">    The simulation is not high-fidelity and does not model overlapping of compute and communication, or cuda streams.</span>
<span class="sd">    Future work may be to enhance this and model the compute time, comms overlap, and even memory.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pipeline_order</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">rank</span><span class="p">:</span> <span class="p">[</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="n">_schedule</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">rank</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">_prev_ops_rank</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="nb">set</span><span class="p">()</span> <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">_schedule</span><span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">add_to_schedule</span><span class="p">(</span><span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]):</span>
        <span class="n">_schedule</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_prev_ops_rank</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_ready_to_schedule</span><span class="p">(</span><span class="n">action</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="n">stage_idx</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
        <span class="n">prev_ops</span> <span class="o">=</span> <span class="n">_prev_ops_rank</span><span class="p">[</span><span class="n">stage_to_rank</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">F</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">RECV_F</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span> <span class="ow">in</span> <span class="n">prev_ops</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span> <span class="ow">in</span> <span class="n">prev_ops</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="ow">in</span> <span class="p">(</span><span class="n">BACKWARD_INPUT</span><span class="p">,</span> <span class="n">FULL_BACKWARD</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">==</span> <span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">RECV_B</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span> <span class="ow">in</span> <span class="n">prev_ops</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">BACKWARD_INPUT</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
                <span class="ow">in</span> <span class="n">prev_ops</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">FULL_BACKWARD</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
                <span class="ow">in</span> <span class="n">prev_ops</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">BACKWARD_WEIGHT</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">SEND_F</span><span class="p">:</span>
            <span class="n">expected_f</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">expected_f</span> <span class="ow">in</span> <span class="n">prev_ops</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">RECV_F</span><span class="p">:</span>
            <span class="n">peer_stage_idx</span> <span class="o">=</span> <span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">expected_send</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span><span class="n">peer_stage_idx</span><span class="p">,</span> <span class="n">SEND_F</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">expected_send</span> <span class="ow">in</span> <span class="n">_prev_ops_rank</span><span class="p">[</span><span class="n">stage_to_rank</span><span class="p">(</span><span class="n">peer_stage_idx</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">SEND_B</span><span class="p">:</span>
            <span class="n">expected_b</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span>
                <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">BACKWARD_INPUT</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
            <span class="p">)</span>
            <span class="n">expected_bw</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span>
                <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">FULL_BACKWARD</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">expected_b</span> <span class="ow">in</span> <span class="n">prev_ops</span> <span class="ow">or</span> <span class="n">expected_bw</span> <span class="ow">in</span> <span class="n">prev_ops</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">RECV_B</span><span class="p">:</span>
            <span class="n">peer_stage_idx</span> <span class="o">=</span> <span class="n">stage_idx</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">expected_send</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span><span class="n">peer_stage_idx</span><span class="p">,</span> <span class="n">SEND_B</span><span class="p">,</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">expected_send</span> <span class="ow">in</span> <span class="n">_prev_ops_rank</span><span class="p">[</span><span class="n">stage_to_rank</span><span class="p">(</span><span class="n">peer_stage_idx</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported action type </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">while</span> <span class="n">pipeline_order</span><span class="p">:</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">action</span> <span class="o">=</span> <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">_ready_to_schedule</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">add_to_schedule</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
                <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">progress</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">add_to_schedule</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">pipeline_order</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="c1"># hacky, but do a second pass to replace any &#39;none&#39; at this timestep with a real action, if it got unblocked</span>
        <span class="c1"># by one of the later ranks</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">_schedule</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="n">action</span> <span class="o">=</span> <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">_ready_to_schedule</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">_schedule</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">action</span>
                    <span class="n">_prev_ops_rank</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">pipeline_order</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">progress</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WIP comms schedule:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">_format_pipeline_order</span><span class="p">(</span><span class="n">_schedule</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">pipeline_order</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rank</span><span class="si">=}</span><span class="s2"> next action= </span><span class="si">{</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Schedule is not progressing&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_schedule</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_dump_chrometrace</span><span class="p">(</span><span class="n">schedule</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function dumps a schedule IR into a chrometrace format so it can be visualized.</span>

<span class="sd">    It is currently very basic and only serves as a graphical alternative to dumping the schedule IR as text.</span>

<span class="sd">    As future work we may extend this to include more accurate heuristics for durations, or let users input durations,</span>
<span class="sd">    add &#39;flow events&#39; to let the UI show the connection between sends and recvs, and model cuda streams for comm/compute</span>
<span class="sd">    as separate streams on the chrometrace view.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">events</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">schedule</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">schedule</span><span class="p">[</span><span class="n">rank</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">events</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">),</span>
                    <span class="s2">&quot;cat&quot;</span><span class="p">:</span> <span class="p">(</span>
                        <span class="s2">&quot;computation&quot;</span>
                        <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="ow">in</span> <span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
                        <span class="k">else</span> <span class="s2">&quot;communication&quot;</span>
                    <span class="p">),</span>
                    <span class="s2">&quot;ph&quot;</span><span class="p">:</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;pid&quot;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
                    <span class="s2">&quot;tid&quot;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
                    <span class="s2">&quot;ts&quot;</span><span class="p">:</span> <span class="n">timestep</span><span class="p">,</span>
                    <span class="s2">&quot;dur&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">({</span><span class="s2">&quot;traceEvents&quot;</span><span class="p">:</span> <span class="n">events</span><span class="p">},</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-value="1">★</span>
        
        <span class="star" data-value="2">★</span>
        
        <span class="star" data-value="3">★</span>
        
        <span class="star" data-value="4">★</span>
        
        <span class="star" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn" onclick="openGitHubIssue()">Send Feedback</button>
  </div>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
    
    <div class="bd-footer__inner bd-page-width">
      
        <div class="footer-items__start">
          
            <div class="footer-item">

  <p class="copyright">
    
      © Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
          
            <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.0.
    <br/>
  </p>
</div>
          
        </div>
      
    
    
      <div class="footer-items__end">
        
          <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
        
      </div>
    
   </div>
   

   <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
      <div class="container">
        <div class="row">
          <div class="col-md-4 text-center">
            <h2>Docs</h2>
            <p>Access comprehensive developer documentation for PyTorch</p>
            <a class="with-right-arrow" href="">View Docs</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Tutorials</h2>
            <p>Get in-depth tutorials for beginners and advanced developers</p>
            <a class="with-right-arrow" href="">View Tutorials</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Resources</h2>
            <p>Find development resources and get your questions answered</p>
            <a class="with-right-arrow" href="">View Resources</a>
          </div>
        </div>
      </div>
  </div>

  <footer class="site-footer">
      <div class="container footer-container">
        <div class="footer-logo-wrapper">
          <a href="" class="footer-logo"></a>
        </div>

        <div class="footer-links-wrapper">
          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">PyTorch</a></li>
              <li><a href="">Get Started</a></li>
              <li><a href="">Features</a></li>
              <li><a href="">Ecosystem</a></li>
              <li><a href="">Blog</a></li>
              <li><a href="">Contributing</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">Resources</a></li>
              <li><a href="">Tutorials</a></li>
              <li><a href="">Docs</a></li>
              <li><a href="" target="_blank">Discuss</a></li>
              <li><a href="" target="_blank">Github Issues</a></li>
              <li><a href="" target="_blank">Brand Guidelines</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">Stay up to date</li>
              <li><a href="" target="_blank">Facebook</a></li>
              <li><a href="" target="_blank">Twitter</a></li>
              <li><a href="" target="_blank">YouTube</a></li>
              <li><a href="" target="_blank">LinkedIn</a></li>
            </ul>
            </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">PyTorch Podcasts</li>
              <li><a href="" target="_blank">Spotify</a></li>
              <li><a href="" target="_blank">Apple</a></li>
              <li><a href="" target="_blank">Google</a></li>
              <li><a href="" target="_blank">Amazon</a></li>
            </ul>
           </div>
          </div>

          <div class="privacy-policy">
            <ul>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
              <li class="privacy-policy-links">|</li>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
            </ul>
          </div>
          <div class="copyright">
          <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
            For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
            <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
            project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
            please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
        </div>
       </div>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/img/pytorch-x.svg">
  </div>
</div>
  </footer>


  </body>
</html>