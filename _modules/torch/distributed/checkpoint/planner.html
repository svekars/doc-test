
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>torch.distributed.checkpoint.planner &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=949a1ff5" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/jit.css?v=8de1ea5d" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom.css?v=3ccf5357" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom2.css?v=baa440dc" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=a8da1a53"></script>
    <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=940804e7"></script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/torch/distributed/checkpoint/planner';</script>
    <script src="../../../../_static/js/star-rating.js?v=8861fcb6"></script>
    <script src="../../../../_static/js/send-feedback.js?v=5646bf45"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="main (2.6.0 )" />
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script type="text/javascript" src="../../../../_static/js/send-feedback.js"></script>
<script type="text/javascript" src="../../../../_static/js/star-rating.js"></script>
<script type="text/javascript" src="../../../../_static/js/cookie-banner.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-TEST12345"></script>
    <script type="text/javascript">
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-TEST12345');
    </script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
<body data-feedback-url="https://github.com/pytorch/pytorch">
  <div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later.
          <li>
            <div class="main-menu-item">
             <a href="" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Home</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../python-api/index.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../notes/index.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../python-api/index.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../notes/index.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch" title="PyPI" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-custom fa-pypi fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPI</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../index.html" class="nav-link">Module code</a></li>
    
    
    <li class="breadcrumb-item"><a href="../../../torch.html" class="nav-link">torch</a></li>
    
    
    <li class="breadcrumb-item"><a href="../../distributed.html" class="nav-link">torch.distributed</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">torch.distributed.checkpoint.planner</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-value="1">★</span>
        
        <span class="star" data-value="2">★</span>
        
        <span class="star" data-value="3">★</span>
        
        <span class="star" data-value="4">★</span>
        
        <span class="star" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for torch.distributed.checkpoint.planner</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">abc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">io</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">operator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">enum</span><span class="w"> </span><span class="kn">import</span> <span class="n">auto</span><span class="p">,</span> <span class="n">Enum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed.checkpoint.metadata</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ChunkStorageMetadata</span><span class="p">,</span>
    <span class="n">Metadata</span><span class="p">,</span>
    <span class="n">MetadataIndex</span><span class="p">,</span>
    <span class="n">STATE_DICT_TYPE</span><span class="p">,</span>
    <span class="n">StorageMeta</span><span class="p">,</span>
    <span class="n">TensorProperties</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;WriteItemType&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LoadItemType&quot;</span><span class="p">,</span>
    <span class="s2">&quot;TensorWriteData&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WriteItem&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ReadItem&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SavePlan&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LoadPlan&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SavePlanner&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LoadPlanner&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">class</span><span class="w"> </span><span class="nc">WriteItemType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">TENSOR</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">SHARD</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">BYTE_IO</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LoadItemType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">TENSOR</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">BYTE_IO</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>


<span class="nd">@dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TensorWriteData</span><span class="p">:</span>
    <span class="n">chunk</span><span class="p">:</span> <span class="n">ChunkStorageMetadata</span>
    <span class="n">properties</span><span class="p">:</span> <span class="n">TensorProperties</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span>


<div class="viewcode-block" id="WriteItem">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.WriteItem">[docs]</a>
<span class="nd">@dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">WriteItem</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dataclass which holds information about what needs to be written to storage.&quot;&quot;&quot;</span>

    <span class="n">index</span><span class="p">:</span> <span class="n">MetadataIndex</span>
    <span class="nb">type</span><span class="p">:</span> <span class="n">WriteItemType</span>

    <span class="c1"># Value present if it&#39;s a tensor write</span>
    <span class="n">tensor_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorWriteData</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="WriteItem.tensor_storage_size">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.WriteItem.tensor_storage_size">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">tensor_storage_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the storage size of the underlying tensor, or None if this is not a tensor write.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Optional[int] storage size, in bytes of underlying tensor if any.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">numels</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_data</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">dtype_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_utils</span><span class="o">.</span><span class="n">_element_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor_data</span><span class="o">.</span><span class="n">properties</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">numels</span> <span class="o">*</span> <span class="n">dtype_size</span></div>
</div>



<div class="viewcode-block" id="ReadItem">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.ReadItem">[docs]</a>
<span class="nd">@dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ReadItem</span><span class="p">:</span>
    <span class="c1"># Read Item</span>
    <span class="nb">type</span><span class="p">:</span> <span class="n">LoadItemType</span>

    <span class="c1"># Index into the state_dict</span>
    <span class="n">dest_index</span><span class="p">:</span> <span class="n">MetadataIndex</span>
    <span class="c1"># Offsets into destination tensor</span>
    <span class="n">dest_offsets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span>

    <span class="c1"># Index into the checkpoint</span>
    <span class="n">storage_index</span><span class="p">:</span> <span class="n">MetadataIndex</span>
    <span class="c1"># Offset into the checkpoint data</span>
    <span class="n">storage_offsets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span>

    <span class="c1"># Size of the hypercube to copy</span>
    <span class="n">lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span></div>



<div class="viewcode-block" id="SavePlan">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.SavePlan">[docs]</a>
<span class="nd">@dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SavePlan</span><span class="p">:</span>
    <span class="n">items</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">WriteItem</span><span class="p">]</span>
    <span class="n">storage_data</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">planner_data</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span></div>



<div class="viewcode-block" id="LoadPlan">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlan">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LoadPlan</span><span class="p">:</span>
    <span class="n">items</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ReadItem</span><span class="p">]</span>
    <span class="n">storage_data</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">planner_data</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span></div>



<div class="viewcode-block" id="SavePlanner">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SavePlanner</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class defining the protocol used by save_state_dict to plan the save process.</span>

<span class="sd">    SavePlanners are stateful objects that can be used to customize the whole save process.</span>

<span class="sd">    SavePlanner acts as an access proxy to the state_dict, so any transformation done to it</span>
<span class="sd">    will be visible to the whole process.</span>

<span class="sd">    A planner subclass can expect the following sequence of calls during save_state_dict:</span>

<span class="sd">    1) set_up_planner - called on all ranks.</span>
<span class="sd">        Signals the start of a checkpoint save.</span>

<span class="sd">    2) create_local_plan - called on all ranks.</span>
<span class="sd">        Process the state_dict and produces a `SavePlan` that will be sent for global planning.</span>

<span class="sd">    3) create_global_plan - called on the coordinator rank only.</span>
<span class="sd">        Takes the SavePlan from all ranks and make any global decision.</span>

<span class="sd">    4) finish_plan - called on all ranks.</span>
<span class="sd">        This gives each rank a chance to adjust to global planning decisions.</span>

<span class="sd">    5) resolve_data - called multiple times on each rank</span>
<span class="sd">        Lookups a value on the `state_dict` for the storage layer to write.</span>

<span class="sd">    Users are recommended to extend DefaultSavePlanner instead of this interface directly as</span>
<span class="sd">    most changes can be expressed by changes in a single method.</span>

<span class="sd">    There are 3 usual patterns of extension:</span>

<span class="sd">    Rewriting state_dict. This is the simplest way to extend the save process as it</span>
<span class="sd">    doesn&#39;t requite understanding the intrincacies of how SavePlan works:</span>

<span class="sd">    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="sd">    &gt;&gt;&gt; class RenamePlanner(DefaultSavePlanner):</span>
<span class="sd">    &gt;&gt;&gt;     def set_up_planner(</span>
<span class="sd">    &gt;&gt;&gt;         self,</span>
<span class="sd">    &gt;&gt;&gt;         state_dict: STATE_DICT_TYPE,</span>
<span class="sd">    &gt;&gt;&gt;         storage_meta: Optional[StorageMeta],</span>
<span class="sd">    &gt;&gt;&gt;         is_coordinator: bool,</span>
<span class="sd">    &gt;&gt;&gt;     ) -&gt; None:</span>
<span class="sd">    &gt;&gt;&gt;         # prefix all keys with `foo_``</span>
<span class="sd">    &gt;&gt;&gt;         super().set_up_planner({&quot;foo_&quot; + k: v for k, v in state_dict.items()}, storage_meta, is_coordinator)</span>

<span class="sd">    Modifying local plan and lookup in tandem. This is useful when fine control of how data is persisted</span>

<span class="sd">    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="sd">    &gt;&gt;&gt; class FP16Planner(DefaultSavePlanner):</span>
<span class="sd">    &gt;&gt;&gt;     def create_local_plan(self):</span>
<span class="sd">    &gt;&gt;&gt;         plan = super().create_local_plan()</span>
<span class="sd">    &gt;&gt;&gt;         for p in plan:</span>
<span class="sd">    &gt;&gt;&gt;             if p.tensor_data is not None:</span>
<span class="sd">    &gt;&gt;&gt;                 p.tensor_data.properties.dtype = torch.float16</span>
<span class="sd">    &gt;&gt;&gt;         return plan</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;     def resolve_data(self, write_item):</span>
<span class="sd">    &gt;&gt;&gt;         item = super().resolve_data(write_item)</span>
<span class="sd">    &gt;&gt;&gt;         return item if write_item.type == WriteItemType.BYTE_IO else item.to(torch.float16)</span>

<span class="sd">    Using the global planning step to make central decisions that can&#39;t be made individually by each rank</span>

<span class="sd">    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="sd">    &gt;&gt;&gt; from itertools import zip_longest</span>
<span class="sd">    &gt;&gt;&gt; from dataclasses import replace</span>
<span class="sd">    &gt;&gt;&gt; class DDPLoadBalancingPlanner(DefaultSavePlanner):</span>
<span class="sd">    &gt;&gt;&gt;     # This uses the default local plan behavior of having all non-sharded writes in rank 0</span>
<span class="sd">    &gt;&gt;&gt;     # This sample doesn&#39;t handle ShardedTensors</span>
<span class="sd">    &gt;&gt;&gt;     def create_global_plan(self, all_plans):</span>
<span class="sd">    &gt;&gt;&gt;         iters = [iter(all_plans[0].items)] * len(all_plans)</span>
<span class="sd">    &gt;&gt;&gt;         items_per_rank = [</span>
<span class="sd">    &gt;&gt;&gt;             [item for item in items if item is not None]</span>
<span class="sd">    &gt;&gt;&gt;             for items in zip(*zip_longest(*iters), strict=True)</span>
<span class="sd">    &gt;&gt;&gt;         ]</span>
<span class="sd">    &gt;&gt;&gt;         all_plans = [</span>
<span class="sd">    &gt;&gt;&gt;             replace(plan, items=items)</span>
<span class="sd">    &gt;&gt;&gt;             for plan, items in zip(all_plans, items_per_rank, strict=True)</span>
<span class="sd">    &gt;&gt;&gt;         ]</span>
<span class="sd">    &gt;&gt;&gt;         return super().create_global_plan(all_plans)</span>

<span class="sd">    Finally, some planners need to save additional metadata in the checkpoint, this is</span>
<span class="sd">    accomplished by having each rank contribute their data items in the local plan and</span>
<span class="sd">    the global planner aggregate them:</span>

<span class="sd">    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="sd">    &gt;&gt;&gt; class SaveExtraDataPlanner(DefaultSavePlanner):</span>
<span class="sd">    &gt;&gt;&gt;     def create_local_plan(self) -&gt; SavePlan:</span>
<span class="sd">    &gt;&gt;&gt;         plan = super().create_local_plan()</span>
<span class="sd">    &gt;&gt;&gt;         return replace(plan, planner_data=&quot;per-rank-data&quot;)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;     def create_global_plan(self, all_plans: List[SavePlan]) -&gt; Tuple[List[SavePlan], Metadata]:</span>
<span class="sd">    &gt;&gt;&gt;         global_plan, metadata = super().create_global_plan(all_plans)</span>
<span class="sd">    &gt;&gt;&gt;         merged_data = [p.planner_data for p in global_plan]</span>
<span class="sd">    &gt;&gt;&gt;         metadata = replace(metadata, planner_data=merged_data)</span>
<span class="sd">    &gt;&gt;&gt;         return global_plan, metadata</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="SavePlanner.set_up_planner">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.set_up_planner">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_up_planner</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">state_dict</span><span class="p">:</span> <span class="n">STATE_DICT_TYPE</span><span class="p">,</span>
        <span class="n">storage_meta</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">StorageMeta</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">is_coordinator</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize this planner to save ``state_dict``.</span>

<span class="sd">        Implementations should save those values as they won&#39;t be provided lated in the save process.</span>

<span class="sd">        This is called on all ranks.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="SavePlanner.create_local_plan">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.create_local_plan">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_local_plan</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SavePlan</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the save plan for the current rank.</span>

<span class="sd">        This will be aggregated and passed to create_global_plan.</span>
<span class="sd">        Planner specific data can be passed through SavePlan::planner_data.</span>

<span class="sd">        This is called on all ranks.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="SavePlanner.create_global_plan">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.create_global_plan">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_global_plan</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">all_plans</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SavePlan</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">SavePlan</span><span class="p">],</span> <span class="n">Metadata</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the global checkpoint plan and return the local plan of each rank.</span>

<span class="sd">        This is called on the coordinator rank only.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="SavePlanner.finish_plan">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.finish_plan">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">finish_plan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_plan</span><span class="p">:</span> <span class="n">SavePlan</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SavePlan</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Merge the plan created by `create_local_plan` and the result of `create_global_plan`.</span>

<span class="sd">        This is called on all ranks.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="SavePlanner.resolve_data">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.resolve_data">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">resolve_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">write_item</span><span class="p">:</span> <span class="n">WriteItem</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transform and prepare ``write_item`` from ``state_dict`` for storage, ensuring idempotency and thread-safety.</span>

<span class="sd">        Lookup the object associated with ``write_item`` in ``state_dict`` and apply any</span>
<span class="sd">        transformation (such as serialization) prior to the storage layer consuming it.</span>

<span class="sd">        Called on each rank multiple times, at least once per WriteItem in the final SavePlan.</span>

<span class="sd">        This method should be idempotent and thread-save. StorageWriter implementations</span>
<span class="sd">        are free to call it as frequently as they need.</span>

<span class="sd">        Any transformation that allocates memory should be lazily done when his method</span>
<span class="sd">        is called in order to reduce peak memory required by checkpointing.</span>

<span class="sd">        When returning tensors, they can be on any device or format, they can be views too.</span>
<span class="sd">        It&#39;s the storage layer responsibility to figure out how to save them.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>
</div>



<div class="viewcode-block" id="LoadPlanner">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LoadPlanner</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class defining the protocol used by load_state_dict to plan the load process.</span>

<span class="sd">    LoadPlanner are stateful objects that can be used to customize the whole load process.</span>

<span class="sd">    LoadPlanner acts as an access proxy to the state_dict, so any transformation done to it</span>
<span class="sd">    will be visible to the whole process.</span>

<span class="sd">    A planner subclass can expect the following sequence of calls during load_state_dict:</span>

<span class="sd">    1) set_up_planner - called on all ranks.</span>
<span class="sd">        Signals the start of loading a checkpoint.</span>

<span class="sd">    2) create_local_plan - called on all ranks.</span>
<span class="sd">        Process the state_dict and produces a `LoadPlan` that will be sent for global planning.</span>

<span class="sd">    3) create_global_plan - called on the coordinator rank only.</span>
<span class="sd">        Takes the LoadPlan from all ranks and make any global decision.</span>

<span class="sd">    4) load_bytes - called multiple times on each rank</span>
<span class="sd">        This is called once per non-tensor value in state_dict.</span>

<span class="sd">    5) resolve_tensor and commit_tensor - called multiple times on each rank</span>
<span class="sd">        They are called in pair for each Tensor value in state_dict.</span>

<span class="sd">    Users are recommended to extend DefaultLoadPlanner instead of this interface directly as</span>
<span class="sd">    most changes can be expressed by changes in a single method.</span>

<span class="sd">    There are two usual patterns of extension:</span>

<span class="sd">    Rewriting state_dict. This is the simplest way to extend the load process as it</span>
<span class="sd">    doesn&#39;t requite understanding the intrincacies of how LoadPlan works. We need</span>
<span class="sd">    to keep a reference to the original state_dict as load happens in place so</span>
<span class="sd">    we need to be able to perform it in place</span>

<span class="sd">    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="sd">    &gt;&gt;&gt; class RenamePlanner(DefaultLoadPlanner):</span>
<span class="sd">    &gt;&gt;&gt;     def set_up_planner(</span>
<span class="sd">    &gt;&gt;&gt;         self,</span>
<span class="sd">    &gt;&gt;&gt;         state_dict: STATE_DICT_TYPE,</span>
<span class="sd">    &gt;&gt;&gt;         metadata: Metadata,</span>
<span class="sd">    &gt;&gt;&gt;         is_coordinator: bool,</span>
<span class="sd">    &gt;&gt;&gt;     ) -&gt; None:</span>
<span class="sd">    &gt;&gt;&gt;         self.original_state_dict = state_dict</span>
<span class="sd">    &gt;&gt;&gt;         state_dict = {&quot;foo_&quot; + k: v for k, v in state_dict.items()}</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;         if self.flatten_sharded_tensors:</span>
<span class="sd">    &gt;&gt;&gt;             state_dict = _flatten_sharded_tensors(state_dict)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;         if self.flatten_state_dict:</span>
<span class="sd">    &gt;&gt;&gt;             state_dict, self.mappings = flatten_state_dict(state_dict)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;         self.state_dict = state_dict</span>
<span class="sd">    &gt;&gt;&gt;         self.metadata = metadata</span>
<span class="sd">    &gt;&gt;&gt;         self.is_coordinator = is_coordinator</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;     def load_bytes(self, read_item, value):</span>
<span class="sd">    &gt;&gt;&gt;         # Remove the &quot;foo_&quot; prefix</span>
<span class="sd">    &gt;&gt;&gt;         self.original_state_dict[read_item.dest_index.fqn[4:]] = torch.load(value, weights_only=False)</span>


<span class="sd">    Modifying resolve_tensor and commit_tensor to handle load time transformation.</span>

<span class="sd">    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="sd">    &gt;&gt;&gt; class MetaModelMaterialize(DefaultSavePlanner):</span>
<span class="sd">    &gt;&gt;&gt;     def resolve_tensor(self, read_item):</span>
<span class="sd">    &gt;&gt;&gt;         tensor = super().resolve_tensor(read_item)</span>
<span class="sd">    &gt;&gt;&gt;         return torch.empty_like(tensor, device=&quot;cpu&quot;)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;     def commit_tensor(self, read_item, tensor):</span>
<span class="sd">    &gt;&gt;&gt;         self.state_dict[read_item.dest_index.fqn] = tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LoadPlanner.set_up_planner">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.set_up_planner">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_up_planner</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">state_dict</span><span class="p">:</span> <span class="n">STATE_DICT_TYPE</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Metadata</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">is_coordinator</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize this instance to load data into ``state_dict``.</span>

<span class="sd">        . N.B. This is called on every rank.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="LoadPlanner.create_local_plan">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.create_local_plan">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_local_plan</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LoadPlan</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a LoadPlan based on state_dict and metadata provided by set_up_planner.</span>

<span class="sd">        . N.B. This is called on every rank.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="LoadPlanner.create_global_plan">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.create_global_plan">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_global_plan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_plan</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">LoadPlan</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">LoadPlan</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the global load plan and return plans for each rank.</span>

<span class="sd">        . N.B. This is called on the coordinator rank only</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="LoadPlanner.finish_plan">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.finish_plan">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">finish_plan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">central_plan</span><span class="p">:</span> <span class="n">LoadPlan</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LoadPlan</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Accept the plan from coordinator and return final LoadPlan.&quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="LoadPlanner.load_bytes">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.load_bytes">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">read_item</span><span class="p">:</span> <span class="n">ReadItem</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load the item described by ``read_item``and ``value``.</span>

<span class="sd">        This method is expected to modify in-place the underlying state_dict.</span>

<span class="sd">        The contents of ``value`` are defined by the SavePlanner used to produce</span>
<span class="sd">        the checkpoint being loaded.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="LoadPlanner.resolve_bytes">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.resolve_bytes">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">resolve_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">read_item</span><span class="p">:</span> <span class="n">ReadItem</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the BytesIO to be used by the StorageReader to load `read_item`.</span>

<span class="sd">        The BytesIO should alias with one on the underlying state_dict as StorageReader will replace its contents.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;LoadPlanner.resolve_bytes is not implemented&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="LoadPlanner.resolve_tensor">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.resolve_tensor">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">resolve_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">read_item</span><span class="p">:</span> <span class="n">ReadItem</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the tensor described by ``read_item`` to be used by the StorageReader to load `read_item`.</span>

<span class="sd">        The tensor should alias with one on the underlying state_dict as StorageReader will replace its contents.</span>
<span class="sd">        If, for any reason, that&#39;s not possible, the planner can use the ``commit_tensor`` method to copy the data</span>
<span class="sd">        back to the one in state_dict.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="LoadPlanner.commit_tensor">
<a class="viewcode-back" href="../../../../python-api/distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.commit_tensor">[docs]</a>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">commit_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">read_item</span><span class="p">:</span> <span class="n">ReadItem</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call once the StorageReader finished loading data into ``tensor``.</span>

<span class="sd">        The provided tensor is the same one returned by the call to ``resolve_tensor``.</span>
<span class="sd">        This method is only needed if this LoadPlanner needs to post process ``tensor`` prior to</span>
<span class="sd">        copying it back to the one in the state_dict.</span>

<span class="sd">        The contents of tensor will follow its device synchronization model.</span>
<span class="sd">        &quot;&quot;&quot;</span></div>
</div>

</pre></div>

                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-value="1">★</span>
        
        <span class="star" data-value="2">★</span>
        
        <span class="star" data-value="3">★</span>
        
        <span class="star" data-value="4">★</span>
        
        <span class="star" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn" onclick="openGitHubIssue()">Send Feedback</button>
  </div>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
    
    <div class="bd-footer__inner bd-page-width">
      
        <div class="footer-items__start">
          
            <div class="footer-item">

  <p class="copyright">
    
      © Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
          
            <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.0.
    <br/>
  </p>
</div>
          
        </div>
      
    
    
      <div class="footer-items__end">
        
          <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
        
      </div>
    
   </div>
   

   <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
      <div class="container">
        <div class="row">
          <div class="col-md-4 text-center">
            <h2>Docs</h2>
            <p>Access comprehensive developer documentation for PyTorch</p>
            <a class="with-right-arrow" href="">View Docs</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Tutorials</h2>
            <p>Get in-depth tutorials for beginners and advanced developers</p>
            <a class="with-right-arrow" href="">View Tutorials</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Resources</h2>
            <p>Find development resources and get your questions answered</p>
            <a class="with-right-arrow" href="">View Resources</a>
          </div>
        </div>
      </div>
  </div>

  <footer class="site-footer">
      <div class="container footer-container">
        <div class="footer-logo-wrapper">
          <a href="" class="footer-logo"></a>
        </div>

        <div class="footer-links-wrapper">
          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">PyTorch</a></li>
              <li><a href="">Get Started</a></li>
              <li><a href="">Features</a></li>
              <li><a href="">Ecosystem</a></li>
              <li><a href="">Blog</a></li>
              <li><a href="">Contributing</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">Resources</a></li>
              <li><a href="">Tutorials</a></li>
              <li><a href="">Docs</a></li>
              <li><a href="" target="_blank">Discuss</a></li>
              <li><a href="" target="_blank">Github Issues</a></li>
              <li><a href="" target="_blank">Brand Guidelines</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">Stay up to date</li>
              <li><a href="" target="_blank">Facebook</a></li>
              <li><a href="" target="_blank">Twitter</a></li>
              <li><a href="" target="_blank">YouTube</a></li>
              <li><a href="" target="_blank">LinkedIn</a></li>
            </ul>
            </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">PyTorch Podcasts</li>
              <li><a href="" target="_blank">Spotify</a></li>
              <li><a href="" target="_blank">Apple</a></li>
              <li><a href="" target="_blank">Google</a></li>
              <li><a href="" target="_blank">Amazon</a></li>
            </ul>
           </div>
          </div>

          <div class="privacy-policy">
            <ul>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
              <li class="privacy-policy-links">|</li>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
            </ul>
          </div>
          <div class="copyright">
          <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
            For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
            <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
            project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
            please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
        </div>
       </div>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/img/pytorch-x.svg">
  </div>
</div>
  </footer>


  </body>
</html>