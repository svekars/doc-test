Search.setIndex({"docnames": ["accelerator", "amp", "autograd", "backends", "benchmark_utils", "bottleneck", "checkpoint", "community/build_ci_governance", "community/contribution_guide", "community/design", "community/governance", "community/index", "community/persons_of_interest", "complex_numbers", "cond", "config_mod", "cpp_extension", "cpp_index", "cpu", "cuda", "cuda._sanitizer", "cuda.tunable", "cuda_environment_variables", "cudnn_persistent_rnn", "cudnn_rnn_determinism", "data", "ddp_comm_hooks", "debugging_environment_variables", "deploy", "deterministic", "distributed", "distributed.algorithms.join", "distributed.checkpoint", "distributed.elastic", "distributed.fsdp.fully_shard", "distributed.optim", "distributed.pipelining", "distributed.tensor", "distributed.tensor.parallel", "distributions", "dlpack", "elastic/agent", "elastic/control_plane", "elastic/customization", "elastic/errors", "elastic/events", "elastic/examples", "elastic/kubernetes", "elastic/metrics", "elastic/multiprocessing", "elastic/quickstart", "elastic/rendezvous", "elastic/run", "elastic/subprocess_handler", "elastic/timer", "elastic/train_script", "export", "export.ir_spec", "export.programming_model", "fft", "fsdp", "func", "func.api", "func.batch_norm", "func.migrating", "func.ux_limitations", "func.whirlwind_tour", "future_mod", "futures", "fx", "fx.experimental", "generated/exportdb/index", "generated/exportdb/python.assert", "generated/exportdb/python.builtin", "generated/exportdb/python.closure", "generated/exportdb/python.context-manager", "generated/exportdb/python.control-flow", "generated/exportdb/python.data-structure", "generated/exportdb/python.object-model", "generated/exportdb/torch.cond", "generated/exportdb/torch.dynamic-shape", "generated/exportdb/torch.dynamic-value", "generated/exportdb/torch.escape-hatch", "generated/exportdb/torch.map", "generated/exportdb/torch.mutation", "generated/exportdb/torch.operator", "generated/torch.Event", "generated/torch.Generator", "generated/torch.Stream", "generated/torch.Tensor.abs", "generated/torch.Tensor.abs_", "generated/torch.Tensor.absolute", "generated/torch.Tensor.absolute_", "generated/torch.Tensor.acos", "generated/torch.Tensor.acos_", "generated/torch.Tensor.acosh", "generated/torch.Tensor.acosh_", "generated/torch.Tensor.add", "generated/torch.Tensor.add_", "generated/torch.Tensor.addbmm", "generated/torch.Tensor.addbmm_", "generated/torch.Tensor.addcdiv", "generated/torch.Tensor.addcdiv_", "generated/torch.Tensor.addcmul", "generated/torch.Tensor.addcmul_", "generated/torch.Tensor.addmm", "generated/torch.Tensor.addmm_", "generated/torch.Tensor.addmv", "generated/torch.Tensor.addmv_", "generated/torch.Tensor.addr", "generated/torch.Tensor.addr_", "generated/torch.Tensor.adjoint", "generated/torch.Tensor.all", "generated/torch.Tensor.allclose", "generated/torch.Tensor.amax", "generated/torch.Tensor.amin", "generated/torch.Tensor.aminmax", "generated/torch.Tensor.angle", "generated/torch.Tensor.any", "generated/torch.Tensor.apply_", "generated/torch.Tensor.arccos", "generated/torch.Tensor.arccos_", "generated/torch.Tensor.arccosh", "generated/torch.Tensor.arccosh_", "generated/torch.Tensor.arcsin", "generated/torch.Tensor.arcsin_", "generated/torch.Tensor.arcsinh", "generated/torch.Tensor.arcsinh_", "generated/torch.Tensor.arctan", "generated/torch.Tensor.arctan2", "generated/torch.Tensor.arctan2_", "generated/torch.Tensor.arctan_", "generated/torch.Tensor.arctanh", "generated/torch.Tensor.arctanh_", "generated/torch.Tensor.argmax", "generated/torch.Tensor.argmin", "generated/torch.Tensor.argsort", "generated/torch.Tensor.argwhere", "generated/torch.Tensor.as_strided", "generated/torch.Tensor.as_subclass", "generated/torch.Tensor.asin", "generated/torch.Tensor.asin_", "generated/torch.Tensor.asinh", "generated/torch.Tensor.asinh_", "generated/torch.Tensor.atan", "generated/torch.Tensor.atan2", "generated/torch.Tensor.atan2_", "generated/torch.Tensor.atan_", "generated/torch.Tensor.atanh", "generated/torch.Tensor.atanh_", "generated/torch.Tensor.backward", "generated/torch.Tensor.baddbmm", "generated/torch.Tensor.baddbmm_", "generated/torch.Tensor.bernoulli", "generated/torch.Tensor.bernoulli_", "generated/torch.Tensor.bfloat16", "generated/torch.Tensor.bincount", "generated/torch.Tensor.bitwise_and", "generated/torch.Tensor.bitwise_and_", "generated/torch.Tensor.bitwise_left_shift", "generated/torch.Tensor.bitwise_left_shift_", "generated/torch.Tensor.bitwise_not", "generated/torch.Tensor.bitwise_not_", "generated/torch.Tensor.bitwise_or", "generated/torch.Tensor.bitwise_or_", "generated/torch.Tensor.bitwise_right_shift", "generated/torch.Tensor.bitwise_right_shift_", "generated/torch.Tensor.bitwise_xor", "generated/torch.Tensor.bitwise_xor_", "generated/torch.Tensor.bmm", "generated/torch.Tensor.bool", "generated/torch.Tensor.broadcast_to", "generated/torch.Tensor.byte", "generated/torch.Tensor.cauchy_", "generated/torch.Tensor.ccol_indices", "generated/torch.Tensor.cdouble", "generated/torch.Tensor.ceil", "generated/torch.Tensor.ceil_", "generated/torch.Tensor.cfloat", "generated/torch.Tensor.chalf", "generated/torch.Tensor.char", "generated/torch.Tensor.cholesky", "generated/torch.Tensor.cholesky_inverse", "generated/torch.Tensor.cholesky_solve", "generated/torch.Tensor.chunk", "generated/torch.Tensor.clamp", "generated/torch.Tensor.clamp_", "generated/torch.Tensor.clip", "generated/torch.Tensor.clip_", "generated/torch.Tensor.clone", "generated/torch.Tensor.coalesce", "generated/torch.Tensor.col_indices", "generated/torch.Tensor.conj", "generated/torch.Tensor.conj_physical", "generated/torch.Tensor.conj_physical_", "generated/torch.Tensor.contiguous", "generated/torch.Tensor.copy_", "generated/torch.Tensor.copysign", "generated/torch.Tensor.copysign_", "generated/torch.Tensor.corrcoef", "generated/torch.Tensor.cos", "generated/torch.Tensor.cos_", "generated/torch.Tensor.cosh", "generated/torch.Tensor.cosh_", "generated/torch.Tensor.count_nonzero", "generated/torch.Tensor.cov", "generated/torch.Tensor.cpu", "generated/torch.Tensor.cross", "generated/torch.Tensor.crow_indices", "generated/torch.Tensor.cuda", "generated/torch.Tensor.cummax", "generated/torch.Tensor.cummin", "generated/torch.Tensor.cumprod", "generated/torch.Tensor.cumprod_", "generated/torch.Tensor.cumsum", "generated/torch.Tensor.cumsum_", "generated/torch.Tensor.data_ptr", "generated/torch.Tensor.deg2rad", "generated/torch.Tensor.dense_dim", "generated/torch.Tensor.dequantize", "generated/torch.Tensor.det", "generated/torch.Tensor.detach", "generated/torch.Tensor.detach_", "generated/torch.Tensor.device", "generated/torch.Tensor.diag", "generated/torch.Tensor.diag_embed", "generated/torch.Tensor.diagflat", "generated/torch.Tensor.diagonal", "generated/torch.Tensor.diagonal_scatter", "generated/torch.Tensor.diff", "generated/torch.Tensor.digamma", "generated/torch.Tensor.digamma_", "generated/torch.Tensor.dim", "generated/torch.Tensor.dim_order", "generated/torch.Tensor.dist", "generated/torch.Tensor.div", "generated/torch.Tensor.div_", "generated/torch.Tensor.divide", "generated/torch.Tensor.divide_", "generated/torch.Tensor.dot", "generated/torch.Tensor.double", "generated/torch.Tensor.dsplit", "generated/torch.Tensor.element_size", "generated/torch.Tensor.eq", "generated/torch.Tensor.eq_", "generated/torch.Tensor.equal", "generated/torch.Tensor.erf", "generated/torch.Tensor.erf_", "generated/torch.Tensor.erfc", "generated/torch.Tensor.erfc_", "generated/torch.Tensor.erfinv", "generated/torch.Tensor.erfinv_", "generated/torch.Tensor.exp", "generated/torch.Tensor.exp_", "generated/torch.Tensor.expand", "generated/torch.Tensor.expand_as", "generated/torch.Tensor.expm1", "generated/torch.Tensor.expm1_", "generated/torch.Tensor.exponential_", "generated/torch.Tensor.fill_", "generated/torch.Tensor.fill_diagonal_", "generated/torch.Tensor.fix", "generated/torch.Tensor.fix_", "generated/torch.Tensor.flatten", "generated/torch.Tensor.flip", "generated/torch.Tensor.fliplr", "generated/torch.Tensor.flipud", "generated/torch.Tensor.float", "generated/torch.Tensor.float_power", "generated/torch.Tensor.float_power_", "generated/torch.Tensor.floor", "generated/torch.Tensor.floor_", "generated/torch.Tensor.floor_divide", "generated/torch.Tensor.floor_divide_", "generated/torch.Tensor.fmax", "generated/torch.Tensor.fmin", "generated/torch.Tensor.fmod", "generated/torch.Tensor.fmod_", "generated/torch.Tensor.frac", "generated/torch.Tensor.frac_", "generated/torch.Tensor.frexp", "generated/torch.Tensor.gather", "generated/torch.Tensor.gcd", "generated/torch.Tensor.gcd_", "generated/torch.Tensor.ge", "generated/torch.Tensor.ge_", "generated/torch.Tensor.geometric_", "generated/torch.Tensor.geqrf", "generated/torch.Tensor.ger", "generated/torch.Tensor.get_device", "generated/torch.Tensor.grad", "generated/torch.Tensor.greater", "generated/torch.Tensor.greater_", "generated/torch.Tensor.greater_equal", "generated/torch.Tensor.greater_equal_", "generated/torch.Tensor.gt", "generated/torch.Tensor.gt_", "generated/torch.Tensor.half", "generated/torch.Tensor.hardshrink", "generated/torch.Tensor.heaviside", "generated/torch.Tensor.histc", "generated/torch.Tensor.histogram", "generated/torch.Tensor.hsplit", "generated/torch.Tensor.hypot", "generated/torch.Tensor.hypot_", "generated/torch.Tensor.i0", "generated/torch.Tensor.i0_", "generated/torch.Tensor.igamma", "generated/torch.Tensor.igamma_", "generated/torch.Tensor.igammac", "generated/torch.Tensor.igammac_", "generated/torch.Tensor.imag", "generated/torch.Tensor.index_add", "generated/torch.Tensor.index_add_", "generated/torch.Tensor.index_copy", "generated/torch.Tensor.index_copy_", "generated/torch.Tensor.index_fill", "generated/torch.Tensor.index_fill_", "generated/torch.Tensor.index_put", "generated/torch.Tensor.index_put_", "generated/torch.Tensor.index_reduce", "generated/torch.Tensor.index_reduce_", "generated/torch.Tensor.index_select", "generated/torch.Tensor.indices", "generated/torch.Tensor.inner", "generated/torch.Tensor.int", "generated/torch.Tensor.int_repr", "generated/torch.Tensor.inverse", "generated/torch.Tensor.is_coalesced", "generated/torch.Tensor.is_complex", "generated/torch.Tensor.is_conj", "generated/torch.Tensor.is_contiguous", "generated/torch.Tensor.is_cuda", "generated/torch.Tensor.is_floating_point", "generated/torch.Tensor.is_inference", "generated/torch.Tensor.is_leaf", "generated/torch.Tensor.is_meta", "generated/torch.Tensor.is_pinned", "generated/torch.Tensor.is_quantized", "generated/torch.Tensor.is_set_to", "generated/torch.Tensor.is_shared", "generated/torch.Tensor.is_signed", "generated/torch.Tensor.is_sparse", "generated/torch.Tensor.is_sparse_csr", "generated/torch.Tensor.isclose", "generated/torch.Tensor.isfinite", "generated/torch.Tensor.isinf", "generated/torch.Tensor.isnan", "generated/torch.Tensor.isneginf", "generated/torch.Tensor.isposinf", "generated/torch.Tensor.isreal", "generated/torch.Tensor.istft", "generated/torch.Tensor.item", "generated/torch.Tensor.itemsize", "generated/torch.Tensor.kthvalue", "generated/torch.Tensor.lcm", "generated/torch.Tensor.lcm_", "generated/torch.Tensor.ldexp", "generated/torch.Tensor.ldexp_", "generated/torch.Tensor.le", "generated/torch.Tensor.le_", "generated/torch.Tensor.lerp", "generated/torch.Tensor.lerp_", "generated/torch.Tensor.less", "generated/torch.Tensor.less_", "generated/torch.Tensor.less_equal", "generated/torch.Tensor.less_equal_", "generated/torch.Tensor.lgamma", "generated/torch.Tensor.lgamma_", "generated/torch.Tensor.log", "generated/torch.Tensor.log10", "generated/torch.Tensor.log10_", "generated/torch.Tensor.log1p", "generated/torch.Tensor.log1p_", "generated/torch.Tensor.log2", "generated/torch.Tensor.log2_", "generated/torch.Tensor.log_", "generated/torch.Tensor.log_normal_", "generated/torch.Tensor.logaddexp", "generated/torch.Tensor.logaddexp2", "generated/torch.Tensor.logcumsumexp", "generated/torch.Tensor.logdet", "generated/torch.Tensor.logical_and", "generated/torch.Tensor.logical_and_", "generated/torch.Tensor.logical_not", "generated/torch.Tensor.logical_not_", "generated/torch.Tensor.logical_or", "generated/torch.Tensor.logical_or_", "generated/torch.Tensor.logical_xor", "generated/torch.Tensor.logical_xor_", "generated/torch.Tensor.logit", "generated/torch.Tensor.logit_", "generated/torch.Tensor.logsumexp", "generated/torch.Tensor.long", "generated/torch.Tensor.lt", "generated/torch.Tensor.lt_", "generated/torch.Tensor.lu", "generated/torch.Tensor.lu_solve", "generated/torch.Tensor.map_", "generated/torch.Tensor.masked_fill", "generated/torch.Tensor.masked_fill_", "generated/torch.Tensor.masked_scatter", "generated/torch.Tensor.masked_scatter_", "generated/torch.Tensor.masked_select", "generated/torch.Tensor.matmul", "generated/torch.Tensor.matrix_exp", "generated/torch.Tensor.matrix_power", "generated/torch.Tensor.max", "generated/torch.Tensor.maximum", "generated/torch.Tensor.mean", "generated/torch.Tensor.median", "generated/torch.Tensor.min", "generated/torch.Tensor.minimum", "generated/torch.Tensor.mm", "generated/torch.Tensor.mode", "generated/torch.Tensor.module_load", "generated/torch.Tensor.moveaxis", "generated/torch.Tensor.movedim", "generated/torch.Tensor.msort", "generated/torch.Tensor.mul", "generated/torch.Tensor.mul_", "generated/torch.Tensor.multinomial", "generated/torch.Tensor.multiply", "generated/torch.Tensor.multiply_", "generated/torch.Tensor.mv", "generated/torch.Tensor.mvlgamma", "generated/torch.Tensor.mvlgamma_", "generated/torch.Tensor.nan_to_num", "generated/torch.Tensor.nan_to_num_", "generated/torch.Tensor.nanmean", "generated/torch.Tensor.nanmedian", "generated/torch.Tensor.nanquantile", "generated/torch.Tensor.nansum", "generated/torch.Tensor.narrow", "generated/torch.Tensor.narrow_copy", "generated/torch.Tensor.nbytes", "generated/torch.Tensor.ndim", "generated/torch.Tensor.ndimension", "generated/torch.Tensor.ne", "generated/torch.Tensor.ne_", "generated/torch.Tensor.neg", "generated/torch.Tensor.neg_", "generated/torch.Tensor.negative", "generated/torch.Tensor.negative_", "generated/torch.Tensor.nelement", "generated/torch.Tensor.new_empty", "generated/torch.Tensor.new_full", "generated/torch.Tensor.new_ones", "generated/torch.Tensor.new_tensor", "generated/torch.Tensor.new_zeros", "generated/torch.Tensor.nextafter", "generated/torch.Tensor.nextafter_", "generated/torch.Tensor.nonzero", "generated/torch.Tensor.norm", "generated/torch.Tensor.normal_", "generated/torch.Tensor.not_equal", "generated/torch.Tensor.not_equal_", "generated/torch.Tensor.numel", "generated/torch.Tensor.numpy", "generated/torch.Tensor.orgqr", "generated/torch.Tensor.ormqr", "generated/torch.Tensor.outer", "generated/torch.Tensor.permute", "generated/torch.Tensor.pin_memory", "generated/torch.Tensor.pinverse", "generated/torch.Tensor.polygamma", "generated/torch.Tensor.polygamma_", "generated/torch.Tensor.positive", "generated/torch.Tensor.pow", "generated/torch.Tensor.pow_", "generated/torch.Tensor.prod", "generated/torch.Tensor.put_", "generated/torch.Tensor.q_per_channel_axis", "generated/torch.Tensor.q_per_channel_scales", "generated/torch.Tensor.q_per_channel_zero_points", "generated/torch.Tensor.q_scale", "generated/torch.Tensor.q_zero_point", "generated/torch.Tensor.qr", "generated/torch.Tensor.qscheme", "generated/torch.Tensor.quantile", "generated/torch.Tensor.rad2deg", "generated/torch.Tensor.random_", "generated/torch.Tensor.ravel", "generated/torch.Tensor.real", "generated/torch.Tensor.reciprocal", "generated/torch.Tensor.reciprocal_", "generated/torch.Tensor.record_stream", "generated/torch.Tensor.register_hook", "generated/torch.Tensor.register_post_accumulate_grad_hook", "generated/torch.Tensor.remainder", "generated/torch.Tensor.remainder_", "generated/torch.Tensor.renorm", "generated/torch.Tensor.renorm_", "generated/torch.Tensor.repeat", "generated/torch.Tensor.repeat_interleave", "generated/torch.Tensor.requires_grad", "generated/torch.Tensor.requires_grad_", "generated/torch.Tensor.reshape", "generated/torch.Tensor.reshape_as", "generated/torch.Tensor.resize_", "generated/torch.Tensor.resize_as_", "generated/torch.Tensor.resolve_conj", "generated/torch.Tensor.resolve_neg", "generated/torch.Tensor.retain_grad", "generated/torch.Tensor.retains_grad", "generated/torch.Tensor.roll", "generated/torch.Tensor.rot90", "generated/torch.Tensor.round", "generated/torch.Tensor.round_", "generated/torch.Tensor.row_indices", "generated/torch.Tensor.rsqrt", "generated/torch.Tensor.rsqrt_", "generated/torch.Tensor.scatter", "generated/torch.Tensor.scatter_", "generated/torch.Tensor.scatter_add", "generated/torch.Tensor.scatter_add_", "generated/torch.Tensor.scatter_reduce", "generated/torch.Tensor.scatter_reduce_", "generated/torch.Tensor.select", "generated/torch.Tensor.select_scatter", "generated/torch.Tensor.set_", "generated/torch.Tensor.sgn", "generated/torch.Tensor.sgn_", "generated/torch.Tensor.shape", "generated/torch.Tensor.share_memory_", "generated/torch.Tensor.short", "generated/torch.Tensor.sigmoid", "generated/torch.Tensor.sigmoid_", "generated/torch.Tensor.sign", "generated/torch.Tensor.sign_", "generated/torch.Tensor.signbit", "generated/torch.Tensor.sin", "generated/torch.Tensor.sin_", "generated/torch.Tensor.sinc", "generated/torch.Tensor.sinc_", "generated/torch.Tensor.sinh", "generated/torch.Tensor.sinh_", "generated/torch.Tensor.size", "generated/torch.Tensor.slice_scatter", "generated/torch.Tensor.slogdet", "generated/torch.Tensor.smm", "generated/torch.Tensor.softmax", "generated/torch.Tensor.sort", "generated/torch.Tensor.sparse_dim", "generated/torch.Tensor.sparse_mask", "generated/torch.Tensor.sparse_resize_", "generated/torch.Tensor.sparse_resize_and_clear_", "generated/torch.Tensor.split", "generated/torch.Tensor.sqrt", "generated/torch.Tensor.sqrt_", "generated/torch.Tensor.square", "generated/torch.Tensor.square_", "generated/torch.Tensor.squeeze", "generated/torch.Tensor.squeeze_", "generated/torch.Tensor.sspaddmm", "generated/torch.Tensor.std", "generated/torch.Tensor.stft", "generated/torch.Tensor.storage", "generated/torch.Tensor.storage_offset", "generated/torch.Tensor.storage_type", "generated/torch.Tensor.stride", "generated/torch.Tensor.sub", "generated/torch.Tensor.sub_", "generated/torch.Tensor.subtract", "generated/torch.Tensor.subtract_", "generated/torch.Tensor.sum", "generated/torch.Tensor.sum_to_size", "generated/torch.Tensor.svd", "generated/torch.Tensor.swapaxes", "generated/torch.Tensor.swapdims", "generated/torch.Tensor.t", "generated/torch.Tensor.t_", "generated/torch.Tensor.take", "generated/torch.Tensor.take_along_dim", "generated/torch.Tensor.tan", "generated/torch.Tensor.tan_", "generated/torch.Tensor.tanh", "generated/torch.Tensor.tanh_", "generated/torch.Tensor.tensor_split", "generated/torch.Tensor.tile", "generated/torch.Tensor.to", "generated/torch.Tensor.to_dense", "generated/torch.Tensor.to_mkldnn", "generated/torch.Tensor.to_sparse", "generated/torch.Tensor.to_sparse_bsc", "generated/torch.Tensor.to_sparse_bsr", "generated/torch.Tensor.to_sparse_coo", "generated/torch.Tensor.to_sparse_csc", "generated/torch.Tensor.to_sparse_csr", "generated/torch.Tensor.tolist", "generated/torch.Tensor.topk", "generated/torch.Tensor.trace", "generated/torch.Tensor.transpose", "generated/torch.Tensor.transpose_", "generated/torch.Tensor.triangular_solve", "generated/torch.Tensor.tril", "generated/torch.Tensor.tril_", "generated/torch.Tensor.triu", "generated/torch.Tensor.triu_", "generated/torch.Tensor.true_divide", "generated/torch.Tensor.true_divide_", "generated/torch.Tensor.trunc", "generated/torch.Tensor.trunc_", "generated/torch.Tensor.type", "generated/torch.Tensor.type_as", "generated/torch.Tensor.unbind", "generated/torch.Tensor.unflatten", "generated/torch.Tensor.unfold", "generated/torch.Tensor.uniform_", "generated/torch.Tensor.unique", "generated/torch.Tensor.unique_consecutive", "generated/torch.Tensor.unsqueeze", "generated/torch.Tensor.unsqueeze_", "generated/torch.Tensor.untyped_storage", "generated/torch.Tensor.values", "generated/torch.Tensor.var", "generated/torch.Tensor.vdot", "generated/torch.Tensor.view", "generated/torch.Tensor.view_as", "generated/torch.Tensor.vsplit", "generated/torch.Tensor.where", "generated/torch.Tensor.xlogy", "generated/torch.Tensor.xlogy_", "generated/torch.Tensor.xpu", "generated/torch.Tensor.zero_", "generated/torch._assert", "generated/torch._foreach_abs", "generated/torch._foreach_abs_", "generated/torch._foreach_acos", "generated/torch._foreach_acos_", "generated/torch._foreach_asin", "generated/torch._foreach_asin_", "generated/torch._foreach_atan", "generated/torch._foreach_atan_", "generated/torch._foreach_ceil", "generated/torch._foreach_ceil_", "generated/torch._foreach_cos", "generated/torch._foreach_cos_", "generated/torch._foreach_cosh", "generated/torch._foreach_cosh_", "generated/torch._foreach_erf", "generated/torch._foreach_erf_", "generated/torch._foreach_erfc", "generated/torch._foreach_erfc_", "generated/torch._foreach_exp", "generated/torch._foreach_exp_", "generated/torch._foreach_expm1", "generated/torch._foreach_expm1_", "generated/torch._foreach_floor", "generated/torch._foreach_floor_", "generated/torch._foreach_frac", "generated/torch._foreach_frac_", "generated/torch._foreach_lgamma", "generated/torch._foreach_lgamma_", "generated/torch._foreach_log", "generated/torch._foreach_log10", "generated/torch._foreach_log10_", "generated/torch._foreach_log1p", "generated/torch._foreach_log1p_", "generated/torch._foreach_log2", "generated/torch._foreach_log2_", "generated/torch._foreach_log_", "generated/torch._foreach_neg", "generated/torch._foreach_neg_", "generated/torch._foreach_reciprocal", "generated/torch._foreach_reciprocal_", "generated/torch._foreach_round", "generated/torch._foreach_round_", "generated/torch._foreach_sigmoid", "generated/torch._foreach_sigmoid_", "generated/torch._foreach_sin", "generated/torch._foreach_sin_", "generated/torch._foreach_sinh", "generated/torch._foreach_sinh_", "generated/torch._foreach_sqrt", "generated/torch._foreach_sqrt_", "generated/torch._foreach_tan", "generated/torch._foreach_tan_", "generated/torch._foreach_trunc", "generated/torch._foreach_trunc_", "generated/torch._foreach_zero_", "generated/torch._logging.set_logs", "generated/torch.abs", "generated/torch.absolute", "generated/torch.accelerator.current_accelerator", "generated/torch.accelerator.current_device_idx", "generated/torch.accelerator.current_device_index", "generated/torch.accelerator.current_stream", "generated/torch.accelerator.device_count", "generated/torch.accelerator.is_available", "generated/torch.accelerator.set_device_idx", "generated/torch.accelerator.set_device_index", "generated/torch.accelerator.set_stream", "generated/torch.accelerator.synchronize", "generated/torch.acos", "generated/torch.acosh", "generated/torch.add", "generated/torch.addbmm", "generated/torch.addcdiv", "generated/torch.addcmul", "generated/torch.addmm", "generated/torch.addmv", "generated/torch.addr", "generated/torch.adjoint", "generated/torch.all", "generated/torch.allclose", "generated/torch.amax", "generated/torch.amin", "generated/torch.aminmax", "generated/torch.angle", "generated/torch.any", "generated/torch.ao.nn.intrinsic.BNReLU2d", "generated/torch.ao.nn.intrinsic.BNReLU3d", "generated/torch.ao.nn.intrinsic.ConvBn1d", "generated/torch.ao.nn.intrinsic.ConvBn2d", "generated/torch.ao.nn.intrinsic.ConvBn3d", "generated/torch.ao.nn.intrinsic.ConvBnReLU1d", "generated/torch.ao.nn.intrinsic.ConvBnReLU2d", "generated/torch.ao.nn.intrinsic.ConvBnReLU3d", "generated/torch.ao.nn.intrinsic.ConvReLU1d", "generated/torch.ao.nn.intrinsic.ConvReLU2d", "generated/torch.ao.nn.intrinsic.ConvReLU3d", "generated/torch.ao.nn.intrinsic.LinearReLU", "generated/torch.ao.nn.intrinsic.qat.ConvBn1d", "generated/torch.ao.nn.intrinsic.qat.ConvBn2d", "generated/torch.ao.nn.intrinsic.qat.ConvBn3d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU1d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU2d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU3d", "generated/torch.ao.nn.intrinsic.qat.ConvReLU2d", "generated/torch.ao.nn.intrinsic.qat.ConvReLU3d", "generated/torch.ao.nn.intrinsic.qat.LinearReLU", "generated/torch.ao.nn.intrinsic.qat.freeze_bn_stats", "generated/torch.ao.nn.intrinsic.qat.update_bn_stats", "generated/torch.ao.nn.intrinsic.quantized.BNReLU2d", "generated/torch.ao.nn.intrinsic.quantized.BNReLU3d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU1d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU2d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU3d", "generated/torch.ao.nn.intrinsic.quantized.LinearReLU", "generated/torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU", "generated/torch.ao.nn.qat.Conv2d", "generated/torch.ao.nn.qat.Conv3d", "generated/torch.ao.nn.qat.Linear", "generated/torch.ao.nn.qat.dynamic.Linear", "generated/torch.ao.nn.quantizable.LSTM", "generated/torch.ao.nn.quantizable.MultiheadAttention", "generated/torch.ao.nn.quantized.BatchNorm2d", "generated/torch.ao.nn.quantized.BatchNorm3d", "generated/torch.ao.nn.quantized.Conv1d", "generated/torch.ao.nn.quantized.Conv2d", "generated/torch.ao.nn.quantized.Conv3d", "generated/torch.ao.nn.quantized.ConvTranspose1d", "generated/torch.ao.nn.quantized.ConvTranspose2d", "generated/torch.ao.nn.quantized.ConvTranspose3d", "generated/torch.ao.nn.quantized.ELU", "generated/torch.ao.nn.quantized.Embedding", "generated/torch.ao.nn.quantized.EmbeddingBag", "generated/torch.ao.nn.quantized.FXFloatFunctional", "generated/torch.ao.nn.quantized.FloatFunctional", "generated/torch.ao.nn.quantized.GroupNorm", "generated/torch.ao.nn.quantized.Hardswish", "generated/torch.ao.nn.quantized.InstanceNorm1d", "generated/torch.ao.nn.quantized.InstanceNorm2d", "generated/torch.ao.nn.quantized.InstanceNorm3d", "generated/torch.ao.nn.quantized.LayerNorm", "generated/torch.ao.nn.quantized.LeakyReLU", "generated/torch.ao.nn.quantized.Linear", "generated/torch.ao.nn.quantized.QFunctional", "generated/torch.ao.nn.quantized.ReLU6", "generated/torch.ao.nn.quantized.Sigmoid", "generated/torch.ao.nn.quantized.dynamic.GRU", "generated/torch.ao.nn.quantized.dynamic.GRUCell", "generated/torch.ao.nn.quantized.dynamic.LSTM", "generated/torch.ao.nn.quantized.dynamic.LSTMCell", "generated/torch.ao.nn.quantized.dynamic.Linear", "generated/torch.ao.nn.quantized.dynamic.RNNCell", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool2d", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool3d", "generated/torch.ao.nn.quantized.functional.avg_pool2d", "generated/torch.ao.nn.quantized.functional.avg_pool3d", "generated/torch.ao.nn.quantized.functional.celu", "generated/torch.ao.nn.quantized.functional.clamp", "generated/torch.ao.nn.quantized.functional.conv1d", "generated/torch.ao.nn.quantized.functional.conv2d", "generated/torch.ao.nn.quantized.functional.conv3d", "generated/torch.ao.nn.quantized.functional.elu", "generated/torch.ao.nn.quantized.functional.hardsigmoid", "generated/torch.ao.nn.quantized.functional.hardswish", "generated/torch.ao.nn.quantized.functional.hardtanh", "generated/torch.ao.nn.quantized.functional.interpolate", "generated/torch.ao.nn.quantized.functional.leaky_relu", "generated/torch.ao.nn.quantized.functional.linear", "generated/torch.ao.nn.quantized.functional.max_pool1d", "generated/torch.ao.nn.quantized.functional.max_pool2d", "generated/torch.ao.nn.quantized.functional.threshold", "generated/torch.ao.nn.quantized.functional.upsample", "generated/torch.ao.nn.quantized.functional.upsample_bilinear", "generated/torch.ao.nn.quantized.functional.upsample_nearest", "generated/torch.ao.quantization.CUSTOM_KEY", "generated/torch.ao.quantization.DeQuantStub", "generated/torch.ao.quantization.NUMERIC_DEBUG_HANDLE_KEY", "generated/torch.ao.quantization.QuantStub", "generated/torch.ao.quantization.QuantWrapper", "generated/torch.ao.quantization.add_quant_dequant", "generated/torch.ao.quantization.backend_config.BackendConfig", "generated/torch.ao.quantization.backend_config.BackendPatternConfig", "generated/torch.ao.quantization.backend_config.DTypeConfig", "generated/torch.ao.quantization.backend_config.DTypeWithConstraints", "generated/torch.ao.quantization.backend_config.ObservationType", "generated/torch.ao.quantization.compare_results", "generated/torch.ao.quantization.convert", "generated/torch.ao.quantization.default_eval_fn", "generated/torch.ao.quantization.extract_results_from_loggers", "generated/torch.ao.quantization.fake_quantize.FakeQuantize", "generated/torch.ao.quantization.fake_quantize.FakeQuantizeBase", "generated/torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize", "generated/torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize", "generated/torch.ao.quantization.fake_quantize.default_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_fused_act_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_histogram_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_weight_fake_quant", "generated/torch.ao.quantization.fake_quantize.disable_fake_quant", "generated/torch.ao.quantization.fake_quantize.disable_observer", "generated/torch.ao.quantization.fake_quantize.enable_fake_quant", "generated/torch.ao.quantization.fake_quantize.enable_observer", "generated/torch.ao.quantization.fuse_modules.fuse_modules", "generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig", "generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig", "generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig", "generated/torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry", "generated/torch.ao.quantization.generate_numeric_debug_handle", "generated/torch.ao.quantization.observer.AffineQuantizedObserverBase", "generated/torch.ao.quantization.observer.Granularity", "generated/torch.ao.quantization.observer.HistogramObserver", "generated/torch.ao.quantization.observer.MappingType", "generated/torch.ao.quantization.observer.MinMaxObserver", "generated/torch.ao.quantization.observer.MovingAverageMinMaxObserver", "generated/torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver", "generated/torch.ao.quantization.observer.NoopObserver", "generated/torch.ao.quantization.observer.ObserverBase", "generated/torch.ao.quantization.observer.PerAxis", "generated/torch.ao.quantization.observer.PerBlock", "generated/torch.ao.quantization.observer.PerChannelMinMaxObserver", "generated/torch.ao.quantization.observer.PerGroup", "generated/torch.ao.quantization.observer.PerRow", "generated/torch.ao.quantization.observer.PerTensor", "generated/torch.ao.quantization.observer.PerToken", "generated/torch.ao.quantization.observer.PlaceholderObserver", "generated/torch.ao.quantization.observer.RecordingObserver", "generated/torch.ao.quantization.observer.TorchAODType", "generated/torch.ao.quantization.observer.ZeroPointDomain", "generated/torch.ao.quantization.observer.default_debug_observer", "generated/torch.ao.quantization.observer.default_dynamic_quant_observer", "generated/torch.ao.quantization.observer.default_float_qparams_observer", "generated/torch.ao.quantization.observer.default_histogram_observer", "generated/torch.ao.quantization.observer.default_observer", "generated/torch.ao.quantization.observer.default_per_channel_weight_observer", "generated/torch.ao.quantization.observer.default_placeholder_observer", "generated/torch.ao.quantization.observer.default_weight_observer", "generated/torch.ao.quantization.observer.get_block_size", "generated/torch.ao.quantization.observer.get_observer_state_dict", "generated/torch.ao.quantization.observer.load_observer_state_dict", "generated/torch.ao.quantization.prepare", "generated/torch.ao.quantization.prepare_for_propagation_comparison", "generated/torch.ao.quantization.prepare_qat", "generated/torch.ao.quantization.propagate_qconfig_", "generated/torch.ao.quantization.pt2e.export_utils.model_is_exported", "generated/torch.ao.quantization.qconfig.QConfig", "generated/torch.ao.quantization.qconfig.default_activation_only_qconfig", "generated/torch.ao.quantization.qconfig.default_debug_qconfig", "generated/torch.ao.quantization.qconfig.default_dynamic_qconfig", "generated/torch.ao.quantization.qconfig.default_per_channel_qconfig", "generated/torch.ao.quantization.qconfig.default_qat_qconfig", "generated/torch.ao.quantization.qconfig.default_qat_qconfig_v2", "generated/torch.ao.quantization.qconfig.default_qconfig", "generated/torch.ao.quantization.qconfig.default_weight_only_qconfig", "generated/torch.ao.quantization.qconfig.float16_dynamic_qconfig", "generated/torch.ao.quantization.qconfig.float16_static_qconfig", "generated/torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig", "generated/torch.ao.quantization.qconfig.per_channel_dynamic_qconfig", "generated/torch.ao.quantization.qconfig_mapping.QConfigMapping", "generated/torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping", "generated/torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping", "generated/torch.ao.quantization.quantize", "generated/torch.ao.quantization.quantize_dynamic", "generated/torch.ao.quantization.quantize_fx.convert_fx", "generated/torch.ao.quantization.quantize_fx.fuse_fx", "generated/torch.ao.quantization.quantize_fx.prepare_fx", "generated/torch.ao.quantization.quantize_fx.prepare_qat_fx", "generated/torch.ao.quantization.quantize_qat", "generated/torch.ao.quantization.swap_module", "generated/torch.arange", "generated/torch.arccos", "generated/torch.arccosh", "generated/torch.arcsin", "generated/torch.arcsinh", "generated/torch.arctan", "generated/torch.arctan2", "generated/torch.arctanh", "generated/torch.are_deterministic_algorithms_enabled", "generated/torch.argmax", "generated/torch.argmin", "generated/torch.argsort", "generated/torch.argwhere", "generated/torch.as_strided", "generated/torch.as_tensor", "generated/torch.asarray", "generated/torch.asin", "generated/torch.asinh", "generated/torch.atan", "generated/torch.atan2", "generated/torch.atanh", "generated/torch.atleast_1d", "generated/torch.atleast_2d", "generated/torch.atleast_3d", "generated/torch.autograd.Function.backward", "generated/torch.autograd.Function.forward", "generated/torch.autograd.Function.jvp", "generated/torch.autograd.Function.vmap", "generated/torch.autograd.backward", "generated/torch.autograd.forward_ad.UnpackedDualTensor", "generated/torch.autograd.forward_ad.dual_level", "generated/torch.autograd.forward_ad.enter_dual_level", "generated/torch.autograd.forward_ad.exit_dual_level", "generated/torch.autograd.forward_ad.make_dual", "generated/torch.autograd.forward_ad.unpack_dual", "generated/torch.autograd.function.BackwardCFunction", "generated/torch.autograd.function.FunctionCtx.mark_dirty", "generated/torch.autograd.function.FunctionCtx.mark_non_differentiable", "generated/torch.autograd.function.FunctionCtx.save_for_backward", "generated/torch.autograd.function.FunctionCtx.set_materialize_grads", "generated/torch.autograd.function.InplaceFunction", "generated/torch.autograd.function.NestedIOFunction", "generated/torch.autograd.function.once_differentiable", "generated/torch.autograd.functional.hessian", "generated/torch.autograd.functional.hvp", "generated/torch.autograd.functional.jacobian", "generated/torch.autograd.functional.jvp", "generated/torch.autograd.functional.vhp", "generated/torch.autograd.functional.vjp", "generated/torch.autograd.grad", "generated/torch.autograd.grad_mode.inference_mode", "generated/torch.autograd.grad_mode.set_grad_enabled", "generated/torch.autograd.grad_mode.set_multithreading_enabled", "generated/torch.autograd.gradcheck.GradcheckError", "generated/torch.autograd.gradcheck.gradcheck", "generated/torch.autograd.gradcheck.gradgradcheck", "generated/torch.autograd.graph.Node.metadata", "generated/torch.autograd.graph.Node.name", "generated/torch.autograd.graph.Node.next_functions", "generated/torch.autograd.graph.Node.register_hook", "generated/torch.autograd.graph.Node.register_prehook", "generated/torch.autograd.graph.increment_version", "generated/torch.autograd.profiler.EnforceUnique", "generated/torch.autograd.profiler.KinetoStepTracker", "generated/torch.autograd.profiler.load_nvprof", "generated/torch.autograd.profiler.parse_nvprof_trace", "generated/torch.autograd.profiler.profile.export_chrome_trace", "generated/torch.autograd.profiler.profile.key_averages", "generated/torch.autograd.profiler.profile.self_cpu_time_total", "generated/torch.autograd.profiler.profile.total_average", "generated/torch.autograd.profiler.record_function", "generated/torch.autograd.profiler_util.Interval", "generated/torch.autograd.profiler_util.Kernel", "generated/torch.autograd.profiler_util.MemRecordsAcc", "generated/torch.autograd.profiler_util.StringTable", "generated/torch.baddbmm", "generated/torch.bartlett_window", "generated/torch.bernoulli", "generated/torch.bincount", "generated/torch.bitwise_and", "generated/torch.bitwise_left_shift", "generated/torch.bitwise_not", "generated/torch.bitwise_or", "generated/torch.bitwise_right_shift", "generated/torch.bitwise_xor", "generated/torch.blackman_window", "generated/torch.block_diag", "generated/torch.bmm", "generated/torch.broadcast_shapes", "generated/torch.broadcast_tensors", "generated/torch.broadcast_to", "generated/torch.bucketize", "generated/torch.can_cast", "generated/torch.cartesian_prod", "generated/torch.cat", "generated/torch.cdist", "generated/torch.ceil", "generated/torch.chain_matmul", "generated/torch.cholesky", "generated/torch.cholesky_inverse", "generated/torch.cholesky_solve", "generated/torch.chunk", "generated/torch.clamp", "generated/torch.clip", "generated/torch.clone", "generated/torch.column_stack", "generated/torch.combinations", "generated/torch.compile", "generated/torch.compiled_with_cxx11_abi", "generated/torch.compiler.allow_in_graph", "generated/torch.compiler.assume_constant_result", "generated/torch.compiler.compile", "generated/torch.compiler.cudagraph_mark_step_begin", "generated/torch.compiler.disable", "generated/torch.compiler.is_compiling", "generated/torch.compiler.is_dynamo_compiling", "generated/torch.compiler.is_exporting", "generated/torch.compiler.list_backends", "generated/torch.compiler.reset", "generated/torch.compiler.set_stance", "generated/torch.compiler.substitute_in_graph", "generated/torch.complex", "generated/torch.concat", "generated/torch.concatenate", "generated/torch.cond", "generated/torch.conj", "generated/torch.conj_physical", "generated/torch.copysign", "generated/torch.corrcoef", "generated/torch.cos", "generated/torch.cosh", "generated/torch.count_nonzero", "generated/torch.cov", "generated/torch.cpu.Stream", "generated/torch.cpu.StreamContext", "generated/torch.cpu.current_device", "generated/torch.cpu.current_stream", "generated/torch.cpu.device_count", "generated/torch.cpu.is_available", "generated/torch.cpu.set_device", "generated/torch.cpu.synchronize", "generated/torch.cross", "generated/torch.cuda.CUDAGraph", "generated/torch.cuda.CUDAPluggableAllocator", "generated/torch.cuda.Event", "generated/torch.cuda.ExternalStream", "generated/torch.cuda.MemPool", "generated/torch.cuda.MemPoolContext", "generated/torch.cuda.OutOfMemoryError", "generated/torch.cuda.Stream", "generated/torch.cuda.StreamContext", "generated/torch.cuda.caching_allocator_alloc", "generated/torch.cuda.caching_allocator_delete", "generated/torch.cuda.can_device_access_peer", "generated/torch.cuda.change_current_allocator", "generated/torch.cuda.clock_rate", "generated/torch.cuda.comm.broadcast", "generated/torch.cuda.comm.broadcast_coalesced", "generated/torch.cuda.comm.gather", "generated/torch.cuda.comm.reduce_add", "generated/torch.cuda.comm.reduce_add_coalesced", "generated/torch.cuda.comm.scatter", "generated/torch.cuda.cudart", "generated/torch.cuda.current_blas_handle", "generated/torch.cuda.current_device", "generated/torch.cuda.current_stream", "generated/torch.cuda.default_stream", "generated/torch.cuda.device", "generated/torch.cuda.device_count", "generated/torch.cuda.device_memory_used", "generated/torch.cuda.device_of", "generated/torch.cuda.empty_cache", "generated/torch.cuda.get_allocator_backend", "generated/torch.cuda.get_arch_list", "generated/torch.cuda.get_device_capability", "generated/torch.cuda.get_device_name", "generated/torch.cuda.get_device_properties", "generated/torch.cuda.get_gencode_flags", "generated/torch.cuda.get_per_process_memory_fraction", "generated/torch.cuda.get_rng_state", "generated/torch.cuda.get_rng_state_all", "generated/torch.cuda.get_stream_from_external", "generated/torch.cuda.get_sync_debug_mode", "generated/torch.cuda.graph", "generated/torch.cuda.graph_pool_handle", "generated/torch.cuda.init", "generated/torch.cuda.initial_seed", "generated/torch.cuda.ipc_collect", "generated/torch.cuda.is_available", "generated/torch.cuda.is_current_stream_capturing", "generated/torch.cuda.is_initialized", "generated/torch.cuda.jiterator._create_jit_fn", "generated/torch.cuda.jiterator._create_multi_output_jit_fn", "generated/torch.cuda.list_gpu_processes", "generated/torch.cuda.make_graphed_callables", "generated/torch.cuda.manual_seed", "generated/torch.cuda.manual_seed_all", "generated/torch.cuda.max_memory_allocated", "generated/torch.cuda.max_memory_cached", "generated/torch.cuda.max_memory_reserved", "generated/torch.cuda.mem_get_info", "generated/torch.cuda.memory.caching_allocator_enable", "generated/torch.cuda.memory_allocated", "generated/torch.cuda.memory_cached", "generated/torch.cuda.memory_reserved", "generated/torch.cuda.memory_snapshot", "generated/torch.cuda.memory_stats", "generated/torch.cuda.memory_summary", "generated/torch.cuda.memory_usage", "generated/torch.cuda.nvtx.mark", "generated/torch.cuda.nvtx.range", "generated/torch.cuda.nvtx.range_pop", "generated/torch.cuda.nvtx.range_push", "generated/torch.cuda.power_draw", "generated/torch.cuda.reset_max_memory_allocated", "generated/torch.cuda.reset_max_memory_cached", "generated/torch.cuda.reset_peak_memory_stats", "generated/torch.cuda.seed", "generated/torch.cuda.seed_all", "generated/torch.cuda.set_device", "generated/torch.cuda.set_per_process_memory_fraction", "generated/torch.cuda.set_rng_state", "generated/torch.cuda.set_rng_state_all", "generated/torch.cuda.set_stream", "generated/torch.cuda.set_sync_debug_mode", "generated/torch.cuda.synchronize", "generated/torch.cuda.temperature", "generated/torch.cuda.utilization", "generated/torch.cummax", "generated/torch.cummin", "generated/torch.cumprod", "generated/torch.cumsum", "generated/torch.cumulative_trapezoid", "generated/torch.deg2rad", "generated/torch.dequantize", "generated/torch.det", "generated/torch.diag", "generated/torch.diag_embed", "generated/torch.diagflat", "generated/torch.diagonal", "generated/torch.diagonal_scatter", "generated/torch.diff", "generated/torch.digamma", "generated/torch.dist", "generated/torch.div", "generated/torch.divide", "generated/torch.dot", "generated/torch.dsplit", "generated/torch.dstack", "generated/torch.einsum", "generated/torch.empty", "generated/torch.empty_like", "generated/torch.empty_strided", "generated/torch.enable_grad", "generated/torch.eq", "generated/torch.equal", "generated/torch.erf", "generated/torch.erfc", "generated/torch.erfinv", "generated/torch.exp", "generated/torch.exp2", "generated/torch.expm1", "generated/torch.eye", "generated/torch.fake_quantize_per_channel_affine", "generated/torch.fake_quantize_per_tensor_affine", "generated/torch.fft.fft", "generated/torch.fft.fft2", "generated/torch.fft.fftfreq", "generated/torch.fft.fftn", "generated/torch.fft.fftshift", "generated/torch.fft.hfft", "generated/torch.fft.hfft2", "generated/torch.fft.hfftn", "generated/torch.fft.ifft", "generated/torch.fft.ifft2", "generated/torch.fft.ifftn", "generated/torch.fft.ifftshift", "generated/torch.fft.ihfft", "generated/torch.fft.ihfft2", "generated/torch.fft.ihfftn", "generated/torch.fft.irfft", "generated/torch.fft.irfft2", "generated/torch.fft.irfftn", "generated/torch.fft.rfft", "generated/torch.fft.rfft2", "generated/torch.fft.rfftfreq", "generated/torch.fft.rfftn", "generated/torch.fix", "generated/torch.flatten", "generated/torch.flip", "generated/torch.fliplr", "generated/torch.flipud", "generated/torch.float_power", "generated/torch.floor", "generated/torch.floor_divide", "generated/torch.fmax", "generated/torch.fmin", "generated/torch.fmod", "generated/torch.frac", "generated/torch.frexp", "generated/torch.from_dlpack", "generated/torch.from_file", "generated/torch.from_numpy", "generated/torch.frombuffer", "generated/torch.full", "generated/torch.full_like", "generated/torch.func.functional_call", "generated/torch.func.functionalize", "generated/torch.func.grad", "generated/torch.func.grad_and_value", "generated/torch.func.hessian", "generated/torch.func.jacfwd", "generated/torch.func.jacrev", "generated/torch.func.jvp", "generated/torch.func.linearize", "generated/torch.func.replace_all_batch_norm_modules_", "generated/torch.func.stack_module_state", "generated/torch.func.vjp", "generated/torch.func.vmap", "generated/torch.fx.experimental.proxy_tensor.get_proxy_mode", "generated/torch.fx.experimental.proxy_tensor.handle_sym_dispatch", "generated/torch.fx.experimental.proxy_tensor.make_fx", "generated/torch.fx.experimental.proxy_tensor.maybe_disable_thunkify", "generated/torch.fx.experimental.proxy_tensor.maybe_enable_thunkify", "generated/torch.fx.experimental.symbolic_shapes.CallMethodKey", "generated/torch.fx.experimental.symbolic_shapes.ConvertIntKey", "generated/torch.fx.experimental.symbolic_shapes.DimConstraints", "generated/torch.fx.experimental.symbolic_shapes.DimDynamic", "generated/torch.fx.experimental.symbolic_shapes.DivideByKey", "generated/torch.fx.experimental.symbolic_shapes.EqualityConstraint", "generated/torch.fx.experimental.symbolic_shapes.InnerTensorKey", "generated/torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts", "generated/torch.fx.experimental.symbolic_shapes.RelaxedUnspecConstraint", "generated/torch.fx.experimental.symbolic_shapes.ShapeEnv", "generated/torch.fx.experimental.symbolic_shapes.ShapeEnvSettings", "generated/torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext", "generated/torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext", "generated/torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint", "generated/torch.fx.experimental.symbolic_shapes.SubclassSymbolicContext", "generated/torch.fx.experimental.symbolic_shapes.SymbolicContext", "generated/torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr", "generated/torch.fx.experimental.symbolic_shapes.check_consistent", "generated/torch.fx.experimental.symbolic_shapes.compute_unbacked_bindings", "generated/torch.fx.experimental.symbolic_shapes.constrain_range", "generated/torch.fx.experimental.symbolic_shapes.constrain_unify", "generated/torch.fx.experimental.symbolic_shapes.definitely_false", "generated/torch.fx.experimental.symbolic_shapes.definitely_true", "generated/torch.fx.experimental.symbolic_shapes.guard_size_oblivious", "generated/torch.fx.experimental.symbolic_shapes.has_free_symbols", "generated/torch.fx.experimental.symbolic_shapes.has_free_unbacked_symbols", "generated/torch.fx.experimental.symbolic_shapes.hint_int", "generated/torch.fx.experimental.symbolic_shapes.is_accessor_node", "generated/torch.fx.experimental.symbolic_shapes.is_concrete_bool", "generated/torch.fx.experimental.symbolic_shapes.is_concrete_float", "generated/torch.fx.experimental.symbolic_shapes.is_concrete_int", "generated/torch.fx.experimental.symbolic_shapes.lru_cache", "generated/torch.fx.experimental.symbolic_shapes.rebind_unbacked", "generated/torch.fx.experimental.symbolic_shapes.resolve_unbacked_bindings", "generated/torch.fx.experimental.symbolic_shapes.statically_known_true", "generated/torch.fx.experimental.symbolic_shapes.sym_eq", "generated/torch.gather", "generated/torch.gcd", "generated/torch.ge", "generated/torch.geqrf", "generated/torch.ger", "generated/torch.get_default_device", "generated/torch.get_default_dtype", "generated/torch.get_deterministic_debug_mode", "generated/torch.get_device_module", "generated/torch.get_float32_matmul_precision", "generated/torch.get_num_interop_threads", "generated/torch.get_num_threads", "generated/torch.get_rng_state", "generated/torch.gradient", "generated/torch.greater", "generated/torch.greater_equal", "generated/torch.gt", "generated/torch.hamming_window", "generated/torch.hann_window", "generated/torch.heaviside", "generated/torch.histc", "generated/torch.histogram", "generated/torch.histogramdd", "generated/torch.hsplit", "generated/torch.hspmm", "generated/torch.hstack", "generated/torch.hypot", "generated/torch.i0", "generated/torch.igamma", "generated/torch.igammac", "generated/torch.imag", "generated/torch.index_add", "generated/torch.index_copy", "generated/torch.index_reduce", "generated/torch.index_select", "generated/torch.initial_seed", "generated/torch.inner", "generated/torch.inverse", "generated/torch.is_complex", "generated/torch.is_conj", "generated/torch.is_deterministic_algorithms_warn_only_enabled", "generated/torch.is_floating_point", "generated/torch.is_grad_enabled", "generated/torch.is_inference_mode_enabled", "generated/torch.is_nonzero", "generated/torch.is_storage", "generated/torch.is_tensor", "generated/torch.is_warn_always_enabled", "generated/torch.isclose", "generated/torch.isfinite", "generated/torch.isin", "generated/torch.isinf", "generated/torch.isnan", "generated/torch.isneginf", "generated/torch.isposinf", "generated/torch.isreal", "generated/torch.istft", "generated/torch.jit.Attribute", "generated/torch.jit.ScriptFunction", "generated/torch.jit.ScriptModule", "generated/torch.jit.annotate", "generated/torch.jit.enable_onednn_fusion", "generated/torch.jit.fork", "generated/torch.jit.freeze", "generated/torch.jit.ignore", "generated/torch.jit.interface", "generated/torch.jit.isinstance", "generated/torch.jit.load", "generated/torch.jit.onednn_fusion_enabled", "generated/torch.jit.optimize_for_inference", "generated/torch.jit.save", "generated/torch.jit.script", "generated/torch.jit.script_if_tracing", "generated/torch.jit.set_fusion_strategy", "generated/torch.jit.strict_fusion", "generated/torch.jit.trace", "generated/torch.jit.trace_module", "generated/torch.jit.unused", "generated/torch.jit.wait", "generated/torch.kaiser_window", "generated/torch.kron", "generated/torch.kthvalue", "generated/torch.lcm", "generated/torch.ldexp", "generated/torch.le", "generated/torch.lerp", "generated/torch.less", "generated/torch.less_equal", "generated/torch.lgamma", "generated/torch.linalg.cholesky", "generated/torch.linalg.cholesky_ex", "generated/torch.linalg.cond", "generated/torch.linalg.cross", "generated/torch.linalg.det", "generated/torch.linalg.diagonal", "generated/torch.linalg.eig", "generated/torch.linalg.eigh", "generated/torch.linalg.eigvals", "generated/torch.linalg.eigvalsh", "generated/torch.linalg.householder_product", "generated/torch.linalg.inv", "generated/torch.linalg.inv_ex", "generated/torch.linalg.ldl_factor", "generated/torch.linalg.ldl_factor_ex", "generated/torch.linalg.ldl_solve", "generated/torch.linalg.lstsq", "generated/torch.linalg.lu", "generated/torch.linalg.lu_factor", "generated/torch.linalg.lu_factor_ex", "generated/torch.linalg.lu_solve", "generated/torch.linalg.matmul", "generated/torch.linalg.matrix_exp", "generated/torch.linalg.matrix_norm", "generated/torch.linalg.matrix_power", "generated/torch.linalg.matrix_rank", "generated/torch.linalg.multi_dot", "generated/torch.linalg.norm", "generated/torch.linalg.pinv", "generated/torch.linalg.qr", "generated/torch.linalg.slogdet", "generated/torch.linalg.solve", "generated/torch.linalg.solve_ex", "generated/torch.linalg.solve_triangular", "generated/torch.linalg.svd", "generated/torch.linalg.svdvals", "generated/torch.linalg.tensorinv", "generated/torch.linalg.tensorsolve", "generated/torch.linalg.vander", "generated/torch.linalg.vecdot", "generated/torch.linalg.vector_norm", "generated/torch.linspace", "generated/torch.load", "generated/torch.lobpcg", "generated/torch.log", "generated/torch.log10", "generated/torch.log1p", "generated/torch.log2", "generated/torch.logaddexp", "generated/torch.logaddexp2", "generated/torch.logcumsumexp", "generated/torch.logdet", "generated/torch.logical_and", "generated/torch.logical_not", "generated/torch.logical_or", "generated/torch.logical_xor", "generated/torch.logit", "generated/torch.logspace", "generated/torch.logsumexp", "generated/torch.lt", "generated/torch.lu", "generated/torch.lu_solve", "generated/torch.lu_unpack", "generated/torch.manual_seed", "generated/torch.masked_select", "generated/torch.matmul", "generated/torch.matrix_exp", "generated/torch.matrix_power", "generated/torch.max", "generated/torch.maximum", "generated/torch.mean", "generated/torch.median", "generated/torch.meshgrid", "generated/torch.min", "generated/torch.minimum", "generated/torch.mm", "generated/torch.mode", "generated/torch.moveaxis", "generated/torch.movedim", "generated/torch.mps.current_allocated_memory", "generated/torch.mps.device_count", "generated/torch.mps.driver_allocated_memory", "generated/torch.mps.empty_cache", "generated/torch.mps.event.Event", "generated/torch.mps.get_rng_state", "generated/torch.mps.manual_seed", "generated/torch.mps.profiler.is_capturing_metal", "generated/torch.mps.profiler.is_metal_capture_enabled", "generated/torch.mps.profiler.metal_capture", "generated/torch.mps.profiler.profile", "generated/torch.mps.profiler.start", "generated/torch.mps.profiler.stop", "generated/torch.mps.recommended_max_memory", "generated/torch.mps.seed", "generated/torch.mps.set_per_process_memory_fraction", "generated/torch.mps.set_rng_state", "generated/torch.mps.synchronize", "generated/torch.msort", "generated/torch.mtia.DeferredMtiaCallError", "generated/torch.mtia.Event", "generated/torch.mtia.Stream", "generated/torch.mtia.StreamContext", "generated/torch.mtia.current_device", "generated/torch.mtia.current_stream", "generated/torch.mtia.default_stream", "generated/torch.mtia.device", "generated/torch.mtia.device_count", "generated/torch.mtia.empty_cache", "generated/torch.mtia.get_device_capability", "generated/torch.mtia.get_rng_state", "generated/torch.mtia.init", "generated/torch.mtia.is_available", "generated/torch.mtia.is_initialized", "generated/torch.mtia.memory.memory_stats", "generated/torch.mtia.memory_stats", "generated/torch.mtia.record_memory_history", "generated/torch.mtia.set_device", "generated/torch.mtia.set_rng_state", "generated/torch.mtia.set_stream", "generated/torch.mtia.snapshot", "generated/torch.mtia.synchronize", "generated/torch.mul", "generated/torch.multinomial", "generated/torch.multiply", "generated/torch.mv", "generated/torch.mvlgamma", "generated/torch.nan_to_num", "generated/torch.nanmean", "generated/torch.nanmedian", "generated/torch.nanquantile", "generated/torch.nansum", "generated/torch.narrow", "generated/torch.narrow_copy", "generated/torch.ne", "generated/torch.neg", "generated/torch.negative", "generated/torch.nextafter", "generated/torch.nn.AdaptiveAvgPool1d", "generated/torch.nn.AdaptiveAvgPool2d", "generated/torch.nn.AdaptiveAvgPool3d", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss", "generated/torch.nn.AdaptiveMaxPool1d", "generated/torch.nn.AdaptiveMaxPool2d", "generated/torch.nn.AdaptiveMaxPool3d", "generated/torch.nn.AlphaDropout", "generated/torch.nn.AvgPool1d", "generated/torch.nn.AvgPool2d", "generated/torch.nn.AvgPool3d", "generated/torch.nn.BCELoss", "generated/torch.nn.BCEWithLogitsLoss", "generated/torch.nn.BatchNorm1d", "generated/torch.nn.BatchNorm2d", "generated/torch.nn.BatchNorm3d", "generated/torch.nn.Bilinear", "generated/torch.nn.CELU", "generated/torch.nn.CTCLoss", "generated/torch.nn.ChannelShuffle", "generated/torch.nn.CircularPad1d", "generated/torch.nn.CircularPad2d", "generated/torch.nn.CircularPad3d", "generated/torch.nn.ConstantPad1d", "generated/torch.nn.ConstantPad2d", "generated/torch.nn.ConstantPad3d", "generated/torch.nn.Conv1d", "generated/torch.nn.Conv2d", "generated/torch.nn.Conv3d", "generated/torch.nn.ConvTranspose1d", "generated/torch.nn.ConvTranspose2d", "generated/torch.nn.ConvTranspose3d", "generated/torch.nn.CosineEmbeddingLoss", "generated/torch.nn.CosineSimilarity", "generated/torch.nn.CrossEntropyLoss", "generated/torch.nn.DataParallel", "generated/torch.nn.Dropout", "generated/torch.nn.Dropout1d", "generated/torch.nn.Dropout2d", "generated/torch.nn.Dropout3d", "generated/torch.nn.ELU", "generated/torch.nn.Embedding", "generated/torch.nn.EmbeddingBag", "generated/torch.nn.FeatureAlphaDropout", "generated/torch.nn.Flatten", "generated/torch.nn.Fold", "generated/torch.nn.FractionalMaxPool2d", "generated/torch.nn.FractionalMaxPool3d", "generated/torch.nn.GELU", "generated/torch.nn.GLU", "generated/torch.nn.GRU", "generated/torch.nn.GRUCell", "generated/torch.nn.GaussianNLLLoss", "generated/torch.nn.GroupNorm", "generated/torch.nn.Hardshrink", "generated/torch.nn.Hardsigmoid", "generated/torch.nn.Hardswish", "generated/torch.nn.Hardtanh", "generated/torch.nn.HingeEmbeddingLoss", "generated/torch.nn.HuberLoss", "generated/torch.nn.Identity", "generated/torch.nn.InstanceNorm1d", "generated/torch.nn.InstanceNorm2d", "generated/torch.nn.InstanceNorm3d", "generated/torch.nn.KLDivLoss", "generated/torch.nn.L1Loss", "generated/torch.nn.LPPool1d", "generated/torch.nn.LPPool2d", "generated/torch.nn.LPPool3d", "generated/torch.nn.LSTM", "generated/torch.nn.LSTMCell", "generated/torch.nn.LayerNorm", "generated/torch.nn.LazyBatchNorm1d", "generated/torch.nn.LazyBatchNorm2d", "generated/torch.nn.LazyBatchNorm3d", "generated/torch.nn.LazyConv1d", "generated/torch.nn.LazyConv2d", "generated/torch.nn.LazyConv3d", "generated/torch.nn.LazyConvTranspose1d", "generated/torch.nn.LazyConvTranspose2d", "generated/torch.nn.LazyConvTranspose3d", "generated/torch.nn.LazyInstanceNorm1d", "generated/torch.nn.LazyInstanceNorm2d", "generated/torch.nn.LazyInstanceNorm3d", "generated/torch.nn.LazyLinear", "generated/torch.nn.LeakyReLU", "generated/torch.nn.Linear", "generated/torch.nn.LocalResponseNorm", "generated/torch.nn.LogSigmoid", "generated/torch.nn.LogSoftmax", "generated/torch.nn.MSELoss", "generated/torch.nn.MarginRankingLoss", "generated/torch.nn.MaxPool1d", "generated/torch.nn.MaxPool2d", "generated/torch.nn.MaxPool3d", "generated/torch.nn.MaxUnpool1d", "generated/torch.nn.MaxUnpool2d", "generated/torch.nn.MaxUnpool3d", "generated/torch.nn.Mish", "generated/torch.nn.Module", "generated/torch.nn.ModuleDict", "generated/torch.nn.ModuleList", "generated/torch.nn.MultiLabelMarginLoss", "generated/torch.nn.MultiLabelSoftMarginLoss", "generated/torch.nn.MultiMarginLoss", "generated/torch.nn.MultiheadAttention", "generated/torch.nn.NLLLoss", "generated/torch.nn.PReLU", "generated/torch.nn.PairwiseDistance", "generated/torch.nn.ParameterDict", "generated/torch.nn.ParameterList", "generated/torch.nn.PixelShuffle", "generated/torch.nn.PixelUnshuffle", "generated/torch.nn.PoissonNLLLoss", "generated/torch.nn.RMSNorm", "generated/torch.nn.RNN", "generated/torch.nn.RNNBase", "generated/torch.nn.RNNCell", "generated/torch.nn.RReLU", "generated/torch.nn.ReLU", "generated/torch.nn.ReLU6", "generated/torch.nn.ReflectionPad1d", "generated/torch.nn.ReflectionPad2d", "generated/torch.nn.ReflectionPad3d", "generated/torch.nn.ReplicationPad1d", "generated/torch.nn.ReplicationPad2d", "generated/torch.nn.ReplicationPad3d", "generated/torch.nn.SELU", "generated/torch.nn.Sequential", "generated/torch.nn.SiLU", "generated/torch.nn.Sigmoid", "generated/torch.nn.SmoothL1Loss", "generated/torch.nn.SoftMarginLoss", "generated/torch.nn.Softmax", "generated/torch.nn.Softmax2d", "generated/torch.nn.Softmin", "generated/torch.nn.Softplus", "generated/torch.nn.Softshrink", "generated/torch.nn.Softsign", "generated/torch.nn.SyncBatchNorm", "generated/torch.nn.Tanh", "generated/torch.nn.Tanhshrink", "generated/torch.nn.Threshold", "generated/torch.nn.Transformer", "generated/torch.nn.TransformerDecoder", "generated/torch.nn.TransformerDecoderLayer", "generated/torch.nn.TransformerEncoder", "generated/torch.nn.TransformerEncoderLayer", "generated/torch.nn.TripletMarginLoss", "generated/torch.nn.TripletMarginWithDistanceLoss", "generated/torch.nn.Unflatten", "generated/torch.nn.Unfold", "generated/torch.nn.Upsample", "generated/torch.nn.UpsamplingBilinear2d", "generated/torch.nn.UpsamplingNearest2d", "generated/torch.nn.ZeroPad1d", "generated/torch.nn.ZeroPad2d", "generated/torch.nn.ZeroPad3d", "generated/torch.nn.attention.SDPBackend", "generated/torch.nn.attention.bias.CausalBias", "generated/torch.nn.attention.bias.CausalVariant", "generated/torch.nn.attention.bias.causal_lower_right", "generated/torch.nn.attention.bias.causal_upper_left", "generated/torch.nn.attention.sdpa_kernel", "generated/torch.nn.functional.adaptive_avg_pool1d", "generated/torch.nn.functional.adaptive_avg_pool2d", "generated/torch.nn.functional.adaptive_avg_pool3d", "generated/torch.nn.functional.adaptive_max_pool1d", "generated/torch.nn.functional.adaptive_max_pool2d", "generated/torch.nn.functional.adaptive_max_pool3d", "generated/torch.nn.functional.affine_grid", "generated/torch.nn.functional.alpha_dropout", "generated/torch.nn.functional.avg_pool1d", "generated/torch.nn.functional.avg_pool2d", "generated/torch.nn.functional.avg_pool3d", "generated/torch.nn.functional.batch_norm", "generated/torch.nn.functional.bilinear", "generated/torch.nn.functional.binary_cross_entropy", "generated/torch.nn.functional.binary_cross_entropy_with_logits", "generated/torch.nn.functional.celu", "generated/torch.nn.functional.conv1d", "generated/torch.nn.functional.conv2d", "generated/torch.nn.functional.conv3d", "generated/torch.nn.functional.conv_transpose1d", "generated/torch.nn.functional.conv_transpose2d", "generated/torch.nn.functional.conv_transpose3d", "generated/torch.nn.functional.cosine_embedding_loss", "generated/torch.nn.functional.cosine_similarity", "generated/torch.nn.functional.cross_entropy", "generated/torch.nn.functional.ctc_loss", "generated/torch.nn.functional.dropout", "generated/torch.nn.functional.dropout1d", "generated/torch.nn.functional.dropout2d", "generated/torch.nn.functional.dropout3d", "generated/torch.nn.functional.elu", "generated/torch.nn.functional.elu_", "generated/torch.nn.functional.embedding", "generated/torch.nn.functional.embedding_bag", "generated/torch.nn.functional.feature_alpha_dropout", "generated/torch.nn.functional.fold", "generated/torch.nn.functional.fractional_max_pool2d", "generated/torch.nn.functional.fractional_max_pool3d", "generated/torch.nn.functional.gaussian_nll_loss", "generated/torch.nn.functional.gelu", "generated/torch.nn.functional.glu", "generated/torch.nn.functional.grid_sample", "generated/torch.nn.functional.group_norm", "generated/torch.nn.functional.gumbel_softmax", "generated/torch.nn.functional.hardshrink", "generated/torch.nn.functional.hardsigmoid", "generated/torch.nn.functional.hardswish", "generated/torch.nn.functional.hardtanh", "generated/torch.nn.functional.hardtanh_", "generated/torch.nn.functional.hinge_embedding_loss", "generated/torch.nn.functional.huber_loss", "generated/torch.nn.functional.instance_norm", "generated/torch.nn.functional.interpolate", "generated/torch.nn.functional.kl_div", "generated/torch.nn.functional.l1_loss", "generated/torch.nn.functional.layer_norm", "generated/torch.nn.functional.leaky_relu", "generated/torch.nn.functional.leaky_relu_", "generated/torch.nn.functional.linear", "generated/torch.nn.functional.local_response_norm", "generated/torch.nn.functional.log_softmax", "generated/torch.nn.functional.logsigmoid", "generated/torch.nn.functional.lp_pool1d", "generated/torch.nn.functional.lp_pool2d", "generated/torch.nn.functional.lp_pool3d", "generated/torch.nn.functional.margin_ranking_loss", "generated/torch.nn.functional.max_pool1d", "generated/torch.nn.functional.max_pool2d", "generated/torch.nn.functional.max_pool3d", "generated/torch.nn.functional.max_unpool1d", "generated/torch.nn.functional.max_unpool2d", "generated/torch.nn.functional.max_unpool3d", "generated/torch.nn.functional.mish", "generated/torch.nn.functional.mse_loss", "generated/torch.nn.functional.multi_margin_loss", "generated/torch.nn.functional.multilabel_margin_loss", "generated/torch.nn.functional.multilabel_soft_margin_loss", "generated/torch.nn.functional.nll_loss", "generated/torch.nn.functional.normalize", "generated/torch.nn.functional.one_hot", "generated/torch.nn.functional.pad", "generated/torch.nn.functional.pairwise_distance", "generated/torch.nn.functional.pdist", "generated/torch.nn.functional.pixel_shuffle", "generated/torch.nn.functional.pixel_unshuffle", "generated/torch.nn.functional.poisson_nll_loss", "generated/torch.nn.functional.prelu", "generated/torch.nn.functional.relu", "generated/torch.nn.functional.relu6", "generated/torch.nn.functional.relu_", "generated/torch.nn.functional.rms_norm", "generated/torch.nn.functional.rrelu", "generated/torch.nn.functional.rrelu_", "generated/torch.nn.functional.scaled_dot_product_attention", "generated/torch.nn.functional.selu", "generated/torch.nn.functional.sigmoid", "generated/torch.nn.functional.silu", "generated/torch.nn.functional.smooth_l1_loss", "generated/torch.nn.functional.soft_margin_loss", "generated/torch.nn.functional.softmax", "generated/torch.nn.functional.softmin", "generated/torch.nn.functional.softplus", "generated/torch.nn.functional.softshrink", "generated/torch.nn.functional.softsign", "generated/torch.nn.functional.tanh", "generated/torch.nn.functional.tanhshrink", "generated/torch.nn.functional.threshold", "generated/torch.nn.functional.threshold_", "generated/torch.nn.functional.torch.nn.parallel.data_parallel", "generated/torch.nn.functional.triplet_margin_loss", "generated/torch.nn.functional.triplet_margin_with_distance_loss", "generated/torch.nn.functional.unfold", "generated/torch.nn.functional.upsample", "generated/torch.nn.functional.upsample_bilinear", "generated/torch.nn.functional.upsample_nearest", "generated/torch.nn.modules.lazy.LazyModuleMixin", "generated/torch.nn.modules.module.register_module_backward_hook", "generated/torch.nn.modules.module.register_module_buffer_registration_hook", "generated/torch.nn.modules.module.register_module_forward_hook", "generated/torch.nn.modules.module.register_module_forward_pre_hook", "generated/torch.nn.modules.module.register_module_full_backward_hook", "generated/torch.nn.modules.module.register_module_full_backward_pre_hook", "generated/torch.nn.modules.module.register_module_module_registration_hook", "generated/torch.nn.modules.module.register_module_parameter_registration_hook", "generated/torch.nn.modules.normalization.RMSNorm", "generated/torch.nn.parallel.DistributedDataParallel", "generated/torch.nn.parameter.Buffer", "generated/torch.nn.parameter.Parameter", "generated/torch.nn.parameter.UninitializedBuffer", "generated/torch.nn.parameter.UninitializedParameter", "generated/torch.nn.utils.clip_grad_norm", "generated/torch.nn.utils.clip_grad_norm_", "generated/torch.nn.utils.clip_grad_value_", "generated/torch.nn.utils.clip_grads_with_norm_", "generated/torch.nn.utils.convert_conv2d_weight_memory_format", "generated/torch.nn.utils.convert_conv3d_weight_memory_format", "generated/torch.nn.utils.fuse_conv_bn_eval", "generated/torch.nn.utils.fuse_conv_bn_weights", "generated/torch.nn.utils.fuse_linear_bn_eval", "generated/torch.nn.utils.fuse_linear_bn_weights", "generated/torch.nn.utils.get_total_norm", "generated/torch.nn.utils.parameters_to_vector", "generated/torch.nn.utils.parametrizations.orthogonal", "generated/torch.nn.utils.parametrizations.spectral_norm", "generated/torch.nn.utils.parametrizations.weight_norm", "generated/torch.nn.utils.parametrize.ParametrizationList", "generated/torch.nn.utils.parametrize.cached", "generated/torch.nn.utils.parametrize.is_parametrized", "generated/torch.nn.utils.parametrize.register_parametrization", "generated/torch.nn.utils.parametrize.remove_parametrizations", "generated/torch.nn.utils.prune.BasePruningMethod", "generated/torch.nn.utils.prune.CustomFromMask", "generated/torch.nn.utils.prune.Identity", "generated/torch.nn.utils.prune.L1Unstructured", "generated/torch.nn.utils.prune.LnStructured", "generated/torch.nn.utils.prune.PruningContainer", "generated/torch.nn.utils.prune.RandomStructured", "generated/torch.nn.utils.prune.RandomUnstructured", "generated/torch.nn.utils.prune.custom_from_mask", "generated/torch.nn.utils.prune.global_unstructured", "generated/torch.nn.utils.prune.is_pruned", "generated/torch.nn.utils.prune.l1_unstructured", "generated/torch.nn.utils.prune.ln_structured", "generated/torch.nn.utils.prune.random_structured", "generated/torch.nn.utils.prune.random_unstructured", "generated/torch.nn.utils.prune.remove", "generated/torch.nn.utils.remove_spectral_norm", "generated/torch.nn.utils.remove_weight_norm", "generated/torch.nn.utils.rnn.PackedSequence", "generated/torch.nn.utils.rnn.pack_padded_sequence", "generated/torch.nn.utils.rnn.pack_sequence", "generated/torch.nn.utils.rnn.pad_packed_sequence", "generated/torch.nn.utils.rnn.pad_sequence", "generated/torch.nn.utils.rnn.unpack_sequence", "generated/torch.nn.utils.rnn.unpad_sequence", "generated/torch.nn.utils.skip_init", "generated/torch.nn.utils.spectral_norm", "generated/torch.nn.utils.stateless.functional_call", "generated/torch.nn.utils.vector_to_parameters", "generated/torch.nn.utils.weight_norm", "generated/torch.no_grad", "generated/torch.nonzero", "generated/torch.norm", "generated/torch.normal", "generated/torch.not_equal", "generated/torch.numel", "generated/torch.ones", "generated/torch.ones_like", "generated/torch.onnx.JitScalarType", "generated/torch.onnx.verification.GraphInfo", "generated/torch.onnx.verification.VerificationOptions", "generated/torch.optim.ASGD", "generated/torch.optim.Adadelta", "generated/torch.optim.Adafactor", "generated/torch.optim.Adagrad", "generated/torch.optim.Adam", "generated/torch.optim.AdamW", "generated/torch.optim.Adamax", "generated/torch.optim.LBFGS", "generated/torch.optim.NAdam", "generated/torch.optim.Optimizer.add_param_group", "generated/torch.optim.Optimizer.load_state_dict", "generated/torch.optim.Optimizer.register_load_state_dict_post_hook", "generated/torch.optim.Optimizer.register_load_state_dict_pre_hook", "generated/torch.optim.Optimizer.register_state_dict_post_hook", "generated/torch.optim.Optimizer.register_state_dict_pre_hook", "generated/torch.optim.Optimizer.register_step_post_hook", "generated/torch.optim.Optimizer.register_step_pre_hook", "generated/torch.optim.Optimizer.state_dict", "generated/torch.optim.Optimizer.step", "generated/torch.optim.Optimizer.zero_grad", "generated/torch.optim.RAdam", "generated/torch.optim.RMSprop", "generated/torch.optim.Rprop", "generated/torch.optim.SGD", "generated/torch.optim.SparseAdam", "generated/torch.optim.lr_scheduler.ChainedScheduler", "generated/torch.optim.lr_scheduler.ConstantLR", "generated/torch.optim.lr_scheduler.CosineAnnealingLR", "generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "generated/torch.optim.lr_scheduler.CyclicLR", "generated/torch.optim.lr_scheduler.ExponentialLR", "generated/torch.optim.lr_scheduler.LRScheduler", "generated/torch.optim.lr_scheduler.LambdaLR", "generated/torch.optim.lr_scheduler.LinearLR", "generated/torch.optim.lr_scheduler.MultiStepLR", "generated/torch.optim.lr_scheduler.MultiplicativeLR", "generated/torch.optim.lr_scheduler.OneCycleLR", "generated/torch.optim.lr_scheduler.PolynomialLR", "generated/torch.optim.lr_scheduler.ReduceLROnPlateau", "generated/torch.optim.lr_scheduler.SequentialLR", "generated/torch.optim.lr_scheduler.StepLR", "generated/torch.optim.swa_utils.AveragedModel", "generated/torch.optim.swa_utils.SWALR", "generated/torch.orgqr", "generated/torch.ormqr", "generated/torch.outer", "generated/torch.pca_lowrank", "generated/torch.permute", "generated/torch.pinverse", "generated/torch.poisson", "generated/torch.polar", "generated/torch.polygamma", "generated/torch.positive", "generated/torch.pow", "generated/torch.prod", "generated/torch.promote_types", "generated/torch.qr", "generated/torch.quantile", "generated/torch.quantize_per_channel", "generated/torch.quantize_per_tensor", "generated/torch.quantized_batch_norm", "generated/torch.quantized_max_pool1d", "generated/torch.quantized_max_pool2d", "generated/torch.quasirandom.SobolEngine", "generated/torch.rad2deg", "generated/torch.rand", "generated/torch.rand_like", "generated/torch.randint", "generated/torch.randint_like", "generated/torch.randn", "generated/torch.randn_like", "generated/torch.randperm", "generated/torch.range", "generated/torch.ravel", "generated/torch.real", "generated/torch.reciprocal", "generated/torch.remainder", "generated/torch.renorm", "generated/torch.repeat_interleave", "generated/torch.reshape", "generated/torch.resolve_conj", "generated/torch.resolve_neg", "generated/torch.result_type", "generated/torch.roll", "generated/torch.rot90", "generated/torch.round", "generated/torch.row_stack", "generated/torch.rsqrt", "generated/torch.save", "generated/torch.scatter", "generated/torch.scatter_add", "generated/torch.scatter_reduce", "generated/torch.searchsorted", "generated/torch.seed", "generated/torch.select", "generated/torch.select_scatter", "generated/torch.set_default_device", "generated/torch.set_default_dtype", "generated/torch.set_default_tensor_type", "generated/torch.set_deterministic_debug_mode", "generated/torch.set_float32_matmul_precision", "generated/torch.set_flush_denormal", "generated/torch.set_num_interop_threads", "generated/torch.set_num_threads", "generated/torch.set_printoptions", "generated/torch.set_rng_state", "generated/torch.set_warn_always", "generated/torch.sgn", "generated/torch.sigmoid", "generated/torch.sign", "generated/torch.signal.windows.bartlett", "generated/torch.signal.windows.blackman", "generated/torch.signal.windows.cosine", "generated/torch.signal.windows.exponential", "generated/torch.signal.windows.gaussian", "generated/torch.signal.windows.general_cosine", "generated/torch.signal.windows.general_hamming", "generated/torch.signal.windows.hamming", "generated/torch.signal.windows.hann", "generated/torch.signal.windows.kaiser", "generated/torch.signal.windows.nuttall", "generated/torch.signbit", "generated/torch.sin", "generated/torch.sinc", "generated/torch.sinh", "generated/torch.slice_scatter", "generated/torch.slogdet", "generated/torch.smm", "generated/torch.softmax", "generated/torch.sort", "generated/torch.sparse.addmm", "generated/torch.sparse.as_sparse_gradcheck", "generated/torch.sparse.check_sparse_tensor_invariants", "generated/torch.sparse.log_softmax", "generated/torch.sparse.mm", "generated/torch.sparse.sampled_addmm", "generated/torch.sparse.softmax", "generated/torch.sparse.spdiags", "generated/torch.sparse.spsolve", "generated/torch.sparse.sum", "generated/torch.sparse_bsc_tensor", "generated/torch.sparse_bsr_tensor", "generated/torch.sparse_compressed_tensor", "generated/torch.sparse_coo_tensor", "generated/torch.sparse_csc_tensor", "generated/torch.sparse_csr_tensor", "generated/torch.split", "generated/torch.sqrt", "generated/torch.square", "generated/torch.squeeze", "generated/torch.sspaddmm", "generated/torch.stack", "generated/torch.std", "generated/torch.std_mean", "generated/torch.stft", "generated/torch.sub", "generated/torch.subtract", "generated/torch.sum", "generated/torch.svd", "generated/torch.svd_lowrank", "generated/torch.swapaxes", "generated/torch.swapdims", "generated/torch.sym_float", "generated/torch.sym_fresh_size", "generated/torch.sym_int", "generated/torch.sym_ite", "generated/torch.sym_max", "generated/torch.sym_min", "generated/torch.sym_not", "generated/torch.sym_sum", "generated/torch.t", "generated/torch.take", "generated/torch.take_along_dim", "generated/torch.tan", "generated/torch.tanh", "generated/torch.tensor", "generated/torch.tensor_split", "generated/torch.tensordot", "generated/torch.tile", "generated/torch.topk", "generated/torch.trace", "generated/torch.transpose", "generated/torch.trapezoid", "generated/torch.trapz", "generated/torch.triangular_solve", "generated/torch.tril", "generated/torch.tril_indices", "generated/torch.triu", "generated/torch.triu_indices", "generated/torch.true_divide", "generated/torch.trunc", "generated/torch.unbind", "generated/torch.unflatten", "generated/torch.unique", "generated/torch.unique_consecutive", "generated/torch.unravel_index", "generated/torch.unsqueeze", "generated/torch.use_deterministic_algorithms", "generated/torch.utils.generate_methods_for_privateuse1_backend", "generated/torch.utils.get_cpp_backtrace", "generated/torch.utils.rename_privateuse1_backend", "generated/torch.utils.set_module", "generated/torch.utils.swap_tensors", "generated/torch.vander", "generated/torch.var", "generated/torch.var_mean", "generated/torch.vdot", "generated/torch.view_as_complex", "generated/torch.view_as_real", "generated/torch.vmap", "generated/torch.vsplit", "generated/torch.vstack", "generated/torch.where", "generated/torch.xlogy", "generated/torch.xpu.Event", "generated/torch.xpu.Stream", "generated/torch.xpu.StreamContext", "generated/torch.xpu.current_device", "generated/torch.xpu.current_stream", "generated/torch.xpu.device", "generated/torch.xpu.device_count", "generated/torch.xpu.device_of", "generated/torch.xpu.empty_cache", "generated/torch.xpu.get_arch_list", "generated/torch.xpu.get_device_capability", "generated/torch.xpu.get_device_name", "generated/torch.xpu.get_device_properties", "generated/torch.xpu.get_gencode_flags", "generated/torch.xpu.get_rng_state", "generated/torch.xpu.get_rng_state_all", "generated/torch.xpu.get_stream_from_external", "generated/torch.xpu.init", "generated/torch.xpu.initial_seed", "generated/torch.xpu.is_available", "generated/torch.xpu.is_initialized", "generated/torch.xpu.manual_seed", "generated/torch.xpu.manual_seed_all", "generated/torch.xpu.max_memory_allocated", "generated/torch.xpu.max_memory_reserved", "generated/torch.xpu.mem_get_info", "generated/torch.xpu.memory_allocated", "generated/torch.xpu.memory_reserved", "generated/torch.xpu.memory_stats", "generated/torch.xpu.memory_stats_as_nested_dict", "generated/torch.xpu.reset_accumulated_memory_stats", "generated/torch.xpu.reset_peak_memory_stats", "generated/torch.xpu.seed", "generated/torch.xpu.seed_all", "generated/torch.xpu.set_device", "generated/torch.xpu.set_rng_state", "generated/torch.xpu.set_rng_state_all", "generated/torch.xpu.set_stream", "generated/torch.xpu.synchronize", "generated/torch.zeros", "generated/torch.zeros_like", "hub", "index", "jit", "jit_builtin_functions", "jit_language_reference", "jit_language_reference_v2", "jit_python_reference", "jit_unsupported", "jit_utils", "library", "linalg", "logging", "masked", "meta", "miscellaneous_environment_variables", "mobile_optimizer", "model_zoo", "module_tracker", "monitor", "mps", "mps_environment_variables", "mtia", "mtia.memory", "multiprocessing", "name_inference", "named_tensor", "nested", "nn", "nn.attention", "nn.attention.bias", "nn.attention.experimental", "nn.attention.flex_attention", "nn.functional", "nn.init", "notes", "notes/amp_examples", "notes/autograd", "notes/broadcasting", "notes/cpu_threading_torchscript_inference", "notes/cuda", "notes/custom_operators", "notes/ddp", "notes/extending", "notes/extending.func", "notes/faq", "notes/fsdp", "notes/get_start_xpu", "notes/gradcheck", "notes/hip", "notes/large_scale_deployments", "notes/libtorch_stable_abi", "notes/modules", "notes/mps", "notes/multiprocessing", "notes/numerical_accuracy", "notes/randomness", "notes/serialization", "notes/windows", "onnx", "onnx_dynamo", "onnx_dynamo_memory_usage", "onnx_dynamo_onnxruntime_backend", "onnx_ops", "onnx_torchscript", "onnx_torchscript_supported_aten_ops", "onnx_verification", "optim", "package", "profiler", "pytorch-api", "quantization", "quantization-accuracy-debugging", "quantization-backend-configuration", "quantization-support", "random", "rpc", "rpc/distributed_autograd", "rpc/rref", "signal", "size", "sparse", "special", "storage", "tensor_attributes", "tensor_view", "tensorboard", "tensors", "testing", "threading_environment_variables", "torch", "torch.ao.ns._numeric_suite", "torch.ao.ns._numeric_suite_fx", "torch.compiler", "torch.compiler.config", "torch.compiler_aot_inductor", "torch.compiler_aot_inductor_minifier", "torch.compiler_api", "torch.compiler_best_practices_for_backends", "torch.compiler_cudagraph_trees", "torch.compiler_custom_backends", "torch.compiler_dynamic_shapes", "torch.compiler_dynamo_deepdive", "torch.compiler_dynamo_overview", "torch.compiler_fake_tensor", "torch.compiler_faq", "torch.compiler_fine_grain_apis", "torch.compiler_get_started", "torch.compiler_inductor_profiling", "torch.compiler_ir", "torch.compiler_nn_module", "torch.compiler_performance_dashboard", "torch.compiler_profiling_torch_compile", "torch.compiler_transformations", "torch.compiler_troubleshooting", "torch.compiler_troubleshooting_old", "torch.overrides", "torch_cuda_memory", "torch_environment_variables", "torch_nccl_environment_variables", "type_info", "utils", "xpu"], "filenames": ["accelerator.rst", "amp.rst", "autograd.rst", "backends.rst", "benchmark_utils.rst", "bottleneck.rst", "checkpoint.rst", "community/build_ci_governance.rst", "community/contribution_guide.rst", "community/design.rst", "community/governance.rst", "community/index.rst", "community/persons_of_interest.rst", "complex_numbers.rst", "cond.rst", "config_mod.rst", "cpp_extension.rst", "cpp_index.rst", "cpu.rst", "cuda.rst", "cuda._sanitizer.rst", "cuda.tunable.rst", "cuda_environment_variables.rst", "cudnn_persistent_rnn.rst", "cudnn_rnn_determinism.rst", "data.rst", "ddp_comm_hooks.rst", "debugging_environment_variables.rst", "deploy.rst", "deterministic.rst", "distributed.rst", "distributed.algorithms.join.rst", "distributed.checkpoint.rst", "distributed.elastic.rst", "distributed.fsdp.fully_shard.rst", "distributed.optim.rst", "distributed.pipelining.rst", "distributed.tensor.rst", "distributed.tensor.parallel.rst", "distributions.rst", "dlpack.rst", "elastic/agent.rst", "elastic/control_plane.rst", "elastic/customization.rst", "elastic/errors.rst", "elastic/events.rst", "elastic/examples.rst", "elastic/kubernetes.rst", "elastic/metrics.rst", "elastic/multiprocessing.rst", "elastic/quickstart.rst", "elastic/rendezvous.rst", "elastic/run.rst", "elastic/subprocess_handler.rst", "elastic/timer.rst", "elastic/train_script.rst", "export.rst", "export.ir_spec.rst", "export.programming_model.rst", "fft.rst", "fsdp.rst", "func.rst", "func.api.rst", "func.batch_norm.rst", "func.migrating.rst", "func.ux_limitations.rst", "func.whirlwind_tour.rst", "future_mod.rst", "futures.rst", "fx.rst", "fx.experimental.rst", "generated/exportdb/index.rst", "generated/exportdb/python.assert.rst", "generated/exportdb/python.builtin.rst", "generated/exportdb/python.closure.rst", "generated/exportdb/python.context-manager.rst", "generated/exportdb/python.control-flow.rst", "generated/exportdb/python.data-structure.rst", "generated/exportdb/python.object-model.rst", "generated/exportdb/torch.cond.rst", "generated/exportdb/torch.dynamic-shape.rst", "generated/exportdb/torch.dynamic-value.rst", "generated/exportdb/torch.escape-hatch.rst", "generated/exportdb/torch.map.rst", "generated/exportdb/torch.mutation.rst", "generated/exportdb/torch.operator.rst", "generated/torch.Event.rst", "generated/torch.Generator.rst", "generated/torch.Stream.rst", "generated/torch.Tensor.abs.rst", "generated/torch.Tensor.abs_.rst", "generated/torch.Tensor.absolute.rst", "generated/torch.Tensor.absolute_.rst", "generated/torch.Tensor.acos.rst", "generated/torch.Tensor.acos_.rst", "generated/torch.Tensor.acosh.rst", "generated/torch.Tensor.acosh_.rst", "generated/torch.Tensor.add.rst", "generated/torch.Tensor.add_.rst", "generated/torch.Tensor.addbmm.rst", "generated/torch.Tensor.addbmm_.rst", "generated/torch.Tensor.addcdiv.rst", "generated/torch.Tensor.addcdiv_.rst", "generated/torch.Tensor.addcmul.rst", "generated/torch.Tensor.addcmul_.rst", "generated/torch.Tensor.addmm.rst", "generated/torch.Tensor.addmm_.rst", "generated/torch.Tensor.addmv.rst", "generated/torch.Tensor.addmv_.rst", "generated/torch.Tensor.addr.rst", "generated/torch.Tensor.addr_.rst", "generated/torch.Tensor.adjoint.rst", "generated/torch.Tensor.all.rst", "generated/torch.Tensor.allclose.rst", "generated/torch.Tensor.amax.rst", "generated/torch.Tensor.amin.rst", "generated/torch.Tensor.aminmax.rst", "generated/torch.Tensor.angle.rst", "generated/torch.Tensor.any.rst", "generated/torch.Tensor.apply_.rst", "generated/torch.Tensor.arccos.rst", "generated/torch.Tensor.arccos_.rst", "generated/torch.Tensor.arccosh.rst", "generated/torch.Tensor.arccosh_.rst", "generated/torch.Tensor.arcsin.rst", "generated/torch.Tensor.arcsin_.rst", "generated/torch.Tensor.arcsinh.rst", "generated/torch.Tensor.arcsinh_.rst", "generated/torch.Tensor.arctan.rst", "generated/torch.Tensor.arctan2.rst", "generated/torch.Tensor.arctan2_.rst", "generated/torch.Tensor.arctan_.rst", "generated/torch.Tensor.arctanh.rst", "generated/torch.Tensor.arctanh_.rst", "generated/torch.Tensor.argmax.rst", "generated/torch.Tensor.argmin.rst", "generated/torch.Tensor.argsort.rst", "generated/torch.Tensor.argwhere.rst", "generated/torch.Tensor.as_strided.rst", "generated/torch.Tensor.as_subclass.rst", "generated/torch.Tensor.asin.rst", "generated/torch.Tensor.asin_.rst", "generated/torch.Tensor.asinh.rst", "generated/torch.Tensor.asinh_.rst", "generated/torch.Tensor.atan.rst", "generated/torch.Tensor.atan2.rst", "generated/torch.Tensor.atan2_.rst", "generated/torch.Tensor.atan_.rst", "generated/torch.Tensor.atanh.rst", "generated/torch.Tensor.atanh_.rst", "generated/torch.Tensor.backward.rst", "generated/torch.Tensor.baddbmm.rst", "generated/torch.Tensor.baddbmm_.rst", "generated/torch.Tensor.bernoulli.rst", "generated/torch.Tensor.bernoulli_.rst", "generated/torch.Tensor.bfloat16.rst", "generated/torch.Tensor.bincount.rst", "generated/torch.Tensor.bitwise_and.rst", "generated/torch.Tensor.bitwise_and_.rst", "generated/torch.Tensor.bitwise_left_shift.rst", "generated/torch.Tensor.bitwise_left_shift_.rst", "generated/torch.Tensor.bitwise_not.rst", "generated/torch.Tensor.bitwise_not_.rst", "generated/torch.Tensor.bitwise_or.rst", "generated/torch.Tensor.bitwise_or_.rst", "generated/torch.Tensor.bitwise_right_shift.rst", "generated/torch.Tensor.bitwise_right_shift_.rst", "generated/torch.Tensor.bitwise_xor.rst", "generated/torch.Tensor.bitwise_xor_.rst", "generated/torch.Tensor.bmm.rst", "generated/torch.Tensor.bool.rst", "generated/torch.Tensor.broadcast_to.rst", "generated/torch.Tensor.byte.rst", "generated/torch.Tensor.cauchy_.rst", "generated/torch.Tensor.ccol_indices.rst", "generated/torch.Tensor.cdouble.rst", "generated/torch.Tensor.ceil.rst", "generated/torch.Tensor.ceil_.rst", "generated/torch.Tensor.cfloat.rst", "generated/torch.Tensor.chalf.rst", "generated/torch.Tensor.char.rst", "generated/torch.Tensor.cholesky.rst", "generated/torch.Tensor.cholesky_inverse.rst", "generated/torch.Tensor.cholesky_solve.rst", "generated/torch.Tensor.chunk.rst", "generated/torch.Tensor.clamp.rst", "generated/torch.Tensor.clamp_.rst", "generated/torch.Tensor.clip.rst", "generated/torch.Tensor.clip_.rst", "generated/torch.Tensor.clone.rst", "generated/torch.Tensor.coalesce.rst", "generated/torch.Tensor.col_indices.rst", "generated/torch.Tensor.conj.rst", "generated/torch.Tensor.conj_physical.rst", "generated/torch.Tensor.conj_physical_.rst", "generated/torch.Tensor.contiguous.rst", "generated/torch.Tensor.copy_.rst", "generated/torch.Tensor.copysign.rst", "generated/torch.Tensor.copysign_.rst", "generated/torch.Tensor.corrcoef.rst", "generated/torch.Tensor.cos.rst", "generated/torch.Tensor.cos_.rst", "generated/torch.Tensor.cosh.rst", "generated/torch.Tensor.cosh_.rst", "generated/torch.Tensor.count_nonzero.rst", "generated/torch.Tensor.cov.rst", "generated/torch.Tensor.cpu.rst", "generated/torch.Tensor.cross.rst", "generated/torch.Tensor.crow_indices.rst", "generated/torch.Tensor.cuda.rst", "generated/torch.Tensor.cummax.rst", "generated/torch.Tensor.cummin.rst", "generated/torch.Tensor.cumprod.rst", "generated/torch.Tensor.cumprod_.rst", "generated/torch.Tensor.cumsum.rst", "generated/torch.Tensor.cumsum_.rst", "generated/torch.Tensor.data_ptr.rst", "generated/torch.Tensor.deg2rad.rst", "generated/torch.Tensor.dense_dim.rst", "generated/torch.Tensor.dequantize.rst", "generated/torch.Tensor.det.rst", "generated/torch.Tensor.detach.rst", "generated/torch.Tensor.detach_.rst", "generated/torch.Tensor.device.rst", "generated/torch.Tensor.diag.rst", "generated/torch.Tensor.diag_embed.rst", "generated/torch.Tensor.diagflat.rst", "generated/torch.Tensor.diagonal.rst", "generated/torch.Tensor.diagonal_scatter.rst", "generated/torch.Tensor.diff.rst", "generated/torch.Tensor.digamma.rst", "generated/torch.Tensor.digamma_.rst", "generated/torch.Tensor.dim.rst", "generated/torch.Tensor.dim_order.rst", "generated/torch.Tensor.dist.rst", "generated/torch.Tensor.div.rst", "generated/torch.Tensor.div_.rst", "generated/torch.Tensor.divide.rst", "generated/torch.Tensor.divide_.rst", "generated/torch.Tensor.dot.rst", "generated/torch.Tensor.double.rst", "generated/torch.Tensor.dsplit.rst", "generated/torch.Tensor.element_size.rst", "generated/torch.Tensor.eq.rst", "generated/torch.Tensor.eq_.rst", "generated/torch.Tensor.equal.rst", "generated/torch.Tensor.erf.rst", "generated/torch.Tensor.erf_.rst", "generated/torch.Tensor.erfc.rst", "generated/torch.Tensor.erfc_.rst", "generated/torch.Tensor.erfinv.rst", "generated/torch.Tensor.erfinv_.rst", "generated/torch.Tensor.exp.rst", "generated/torch.Tensor.exp_.rst", "generated/torch.Tensor.expand.rst", "generated/torch.Tensor.expand_as.rst", "generated/torch.Tensor.expm1.rst", "generated/torch.Tensor.expm1_.rst", "generated/torch.Tensor.exponential_.rst", "generated/torch.Tensor.fill_.rst", "generated/torch.Tensor.fill_diagonal_.rst", "generated/torch.Tensor.fix.rst", "generated/torch.Tensor.fix_.rst", "generated/torch.Tensor.flatten.rst", "generated/torch.Tensor.flip.rst", "generated/torch.Tensor.fliplr.rst", "generated/torch.Tensor.flipud.rst", "generated/torch.Tensor.float.rst", "generated/torch.Tensor.float_power.rst", "generated/torch.Tensor.float_power_.rst", "generated/torch.Tensor.floor.rst", "generated/torch.Tensor.floor_.rst", "generated/torch.Tensor.floor_divide.rst", "generated/torch.Tensor.floor_divide_.rst", "generated/torch.Tensor.fmax.rst", "generated/torch.Tensor.fmin.rst", "generated/torch.Tensor.fmod.rst", "generated/torch.Tensor.fmod_.rst", "generated/torch.Tensor.frac.rst", "generated/torch.Tensor.frac_.rst", "generated/torch.Tensor.frexp.rst", "generated/torch.Tensor.gather.rst", "generated/torch.Tensor.gcd.rst", "generated/torch.Tensor.gcd_.rst", "generated/torch.Tensor.ge.rst", "generated/torch.Tensor.ge_.rst", "generated/torch.Tensor.geometric_.rst", "generated/torch.Tensor.geqrf.rst", "generated/torch.Tensor.ger.rst", "generated/torch.Tensor.get_device.rst", "generated/torch.Tensor.grad.rst", "generated/torch.Tensor.greater.rst", "generated/torch.Tensor.greater_.rst", "generated/torch.Tensor.greater_equal.rst", "generated/torch.Tensor.greater_equal_.rst", "generated/torch.Tensor.gt.rst", "generated/torch.Tensor.gt_.rst", "generated/torch.Tensor.half.rst", "generated/torch.Tensor.hardshrink.rst", "generated/torch.Tensor.heaviside.rst", "generated/torch.Tensor.histc.rst", "generated/torch.Tensor.histogram.rst", "generated/torch.Tensor.hsplit.rst", "generated/torch.Tensor.hypot.rst", "generated/torch.Tensor.hypot_.rst", "generated/torch.Tensor.i0.rst", "generated/torch.Tensor.i0_.rst", "generated/torch.Tensor.igamma.rst", "generated/torch.Tensor.igamma_.rst", "generated/torch.Tensor.igammac.rst", "generated/torch.Tensor.igammac_.rst", "generated/torch.Tensor.imag.rst", "generated/torch.Tensor.index_add.rst", "generated/torch.Tensor.index_add_.rst", "generated/torch.Tensor.index_copy.rst", "generated/torch.Tensor.index_copy_.rst", "generated/torch.Tensor.index_fill.rst", "generated/torch.Tensor.index_fill_.rst", "generated/torch.Tensor.index_put.rst", "generated/torch.Tensor.index_put_.rst", "generated/torch.Tensor.index_reduce.rst", "generated/torch.Tensor.index_reduce_.rst", "generated/torch.Tensor.index_select.rst", "generated/torch.Tensor.indices.rst", "generated/torch.Tensor.inner.rst", "generated/torch.Tensor.int.rst", "generated/torch.Tensor.int_repr.rst", "generated/torch.Tensor.inverse.rst", "generated/torch.Tensor.is_coalesced.rst", "generated/torch.Tensor.is_complex.rst", "generated/torch.Tensor.is_conj.rst", "generated/torch.Tensor.is_contiguous.rst", "generated/torch.Tensor.is_cuda.rst", "generated/torch.Tensor.is_floating_point.rst", "generated/torch.Tensor.is_inference.rst", "generated/torch.Tensor.is_leaf.rst", "generated/torch.Tensor.is_meta.rst", "generated/torch.Tensor.is_pinned.rst", "generated/torch.Tensor.is_quantized.rst", "generated/torch.Tensor.is_set_to.rst", "generated/torch.Tensor.is_shared.rst", "generated/torch.Tensor.is_signed.rst", "generated/torch.Tensor.is_sparse.rst", "generated/torch.Tensor.is_sparse_csr.rst", "generated/torch.Tensor.isclose.rst", "generated/torch.Tensor.isfinite.rst", "generated/torch.Tensor.isinf.rst", "generated/torch.Tensor.isnan.rst", "generated/torch.Tensor.isneginf.rst", "generated/torch.Tensor.isposinf.rst", "generated/torch.Tensor.isreal.rst", "generated/torch.Tensor.istft.rst", "generated/torch.Tensor.item.rst", "generated/torch.Tensor.itemsize.rst", "generated/torch.Tensor.kthvalue.rst", "generated/torch.Tensor.lcm.rst", "generated/torch.Tensor.lcm_.rst", "generated/torch.Tensor.ldexp.rst", "generated/torch.Tensor.ldexp_.rst", "generated/torch.Tensor.le.rst", "generated/torch.Tensor.le_.rst", "generated/torch.Tensor.lerp.rst", "generated/torch.Tensor.lerp_.rst", "generated/torch.Tensor.less.rst", "generated/torch.Tensor.less_.rst", "generated/torch.Tensor.less_equal.rst", "generated/torch.Tensor.less_equal_.rst", "generated/torch.Tensor.lgamma.rst", "generated/torch.Tensor.lgamma_.rst", "generated/torch.Tensor.log.rst", "generated/torch.Tensor.log10.rst", "generated/torch.Tensor.log10_.rst", "generated/torch.Tensor.log1p.rst", "generated/torch.Tensor.log1p_.rst", "generated/torch.Tensor.log2.rst", "generated/torch.Tensor.log2_.rst", "generated/torch.Tensor.log_.rst", "generated/torch.Tensor.log_normal_.rst", "generated/torch.Tensor.logaddexp.rst", "generated/torch.Tensor.logaddexp2.rst", "generated/torch.Tensor.logcumsumexp.rst", "generated/torch.Tensor.logdet.rst", "generated/torch.Tensor.logical_and.rst", "generated/torch.Tensor.logical_and_.rst", "generated/torch.Tensor.logical_not.rst", "generated/torch.Tensor.logical_not_.rst", "generated/torch.Tensor.logical_or.rst", "generated/torch.Tensor.logical_or_.rst", "generated/torch.Tensor.logical_xor.rst", "generated/torch.Tensor.logical_xor_.rst", "generated/torch.Tensor.logit.rst", "generated/torch.Tensor.logit_.rst", "generated/torch.Tensor.logsumexp.rst", "generated/torch.Tensor.long.rst", "generated/torch.Tensor.lt.rst", "generated/torch.Tensor.lt_.rst", "generated/torch.Tensor.lu.rst", "generated/torch.Tensor.lu_solve.rst", "generated/torch.Tensor.map_.rst", "generated/torch.Tensor.masked_fill.rst", "generated/torch.Tensor.masked_fill_.rst", "generated/torch.Tensor.masked_scatter.rst", "generated/torch.Tensor.masked_scatter_.rst", "generated/torch.Tensor.masked_select.rst", "generated/torch.Tensor.matmul.rst", "generated/torch.Tensor.matrix_exp.rst", "generated/torch.Tensor.matrix_power.rst", "generated/torch.Tensor.max.rst", "generated/torch.Tensor.maximum.rst", "generated/torch.Tensor.mean.rst", "generated/torch.Tensor.median.rst", "generated/torch.Tensor.min.rst", "generated/torch.Tensor.minimum.rst", "generated/torch.Tensor.mm.rst", "generated/torch.Tensor.mode.rst", "generated/torch.Tensor.module_load.rst", "generated/torch.Tensor.moveaxis.rst", "generated/torch.Tensor.movedim.rst", "generated/torch.Tensor.msort.rst", "generated/torch.Tensor.mul.rst", "generated/torch.Tensor.mul_.rst", "generated/torch.Tensor.multinomial.rst", "generated/torch.Tensor.multiply.rst", "generated/torch.Tensor.multiply_.rst", "generated/torch.Tensor.mv.rst", "generated/torch.Tensor.mvlgamma.rst", "generated/torch.Tensor.mvlgamma_.rst", "generated/torch.Tensor.nan_to_num.rst", "generated/torch.Tensor.nan_to_num_.rst", "generated/torch.Tensor.nanmean.rst", "generated/torch.Tensor.nanmedian.rst", "generated/torch.Tensor.nanquantile.rst", "generated/torch.Tensor.nansum.rst", "generated/torch.Tensor.narrow.rst", "generated/torch.Tensor.narrow_copy.rst", "generated/torch.Tensor.nbytes.rst", "generated/torch.Tensor.ndim.rst", "generated/torch.Tensor.ndimension.rst", "generated/torch.Tensor.ne.rst", "generated/torch.Tensor.ne_.rst", "generated/torch.Tensor.neg.rst", "generated/torch.Tensor.neg_.rst", "generated/torch.Tensor.negative.rst", "generated/torch.Tensor.negative_.rst", "generated/torch.Tensor.nelement.rst", "generated/torch.Tensor.new_empty.rst", "generated/torch.Tensor.new_full.rst", "generated/torch.Tensor.new_ones.rst", "generated/torch.Tensor.new_tensor.rst", "generated/torch.Tensor.new_zeros.rst", "generated/torch.Tensor.nextafter.rst", "generated/torch.Tensor.nextafter_.rst", "generated/torch.Tensor.nonzero.rst", "generated/torch.Tensor.norm.rst", "generated/torch.Tensor.normal_.rst", "generated/torch.Tensor.not_equal.rst", "generated/torch.Tensor.not_equal_.rst", "generated/torch.Tensor.numel.rst", "generated/torch.Tensor.numpy.rst", "generated/torch.Tensor.orgqr.rst", "generated/torch.Tensor.ormqr.rst", "generated/torch.Tensor.outer.rst", "generated/torch.Tensor.permute.rst", "generated/torch.Tensor.pin_memory.rst", "generated/torch.Tensor.pinverse.rst", "generated/torch.Tensor.polygamma.rst", "generated/torch.Tensor.polygamma_.rst", "generated/torch.Tensor.positive.rst", "generated/torch.Tensor.pow.rst", "generated/torch.Tensor.pow_.rst", "generated/torch.Tensor.prod.rst", "generated/torch.Tensor.put_.rst", "generated/torch.Tensor.q_per_channel_axis.rst", "generated/torch.Tensor.q_per_channel_scales.rst", "generated/torch.Tensor.q_per_channel_zero_points.rst", "generated/torch.Tensor.q_scale.rst", "generated/torch.Tensor.q_zero_point.rst", "generated/torch.Tensor.qr.rst", "generated/torch.Tensor.qscheme.rst", "generated/torch.Tensor.quantile.rst", "generated/torch.Tensor.rad2deg.rst", "generated/torch.Tensor.random_.rst", "generated/torch.Tensor.ravel.rst", "generated/torch.Tensor.real.rst", "generated/torch.Tensor.reciprocal.rst", "generated/torch.Tensor.reciprocal_.rst", "generated/torch.Tensor.record_stream.rst", "generated/torch.Tensor.register_hook.rst", "generated/torch.Tensor.register_post_accumulate_grad_hook.rst", "generated/torch.Tensor.remainder.rst", "generated/torch.Tensor.remainder_.rst", "generated/torch.Tensor.renorm.rst", "generated/torch.Tensor.renorm_.rst", "generated/torch.Tensor.repeat.rst", "generated/torch.Tensor.repeat_interleave.rst", "generated/torch.Tensor.requires_grad.rst", "generated/torch.Tensor.requires_grad_.rst", "generated/torch.Tensor.reshape.rst", "generated/torch.Tensor.reshape_as.rst", "generated/torch.Tensor.resize_.rst", "generated/torch.Tensor.resize_as_.rst", "generated/torch.Tensor.resolve_conj.rst", "generated/torch.Tensor.resolve_neg.rst", "generated/torch.Tensor.retain_grad.rst", "generated/torch.Tensor.retains_grad.rst", "generated/torch.Tensor.roll.rst", "generated/torch.Tensor.rot90.rst", "generated/torch.Tensor.round.rst", "generated/torch.Tensor.round_.rst", "generated/torch.Tensor.row_indices.rst", "generated/torch.Tensor.rsqrt.rst", "generated/torch.Tensor.rsqrt_.rst", "generated/torch.Tensor.scatter.rst", "generated/torch.Tensor.scatter_.rst", "generated/torch.Tensor.scatter_add.rst", "generated/torch.Tensor.scatter_add_.rst", "generated/torch.Tensor.scatter_reduce.rst", "generated/torch.Tensor.scatter_reduce_.rst", "generated/torch.Tensor.select.rst", "generated/torch.Tensor.select_scatter.rst", "generated/torch.Tensor.set_.rst", "generated/torch.Tensor.sgn.rst", "generated/torch.Tensor.sgn_.rst", "generated/torch.Tensor.shape.rst", "generated/torch.Tensor.share_memory_.rst", "generated/torch.Tensor.short.rst", "generated/torch.Tensor.sigmoid.rst", "generated/torch.Tensor.sigmoid_.rst", "generated/torch.Tensor.sign.rst", "generated/torch.Tensor.sign_.rst", "generated/torch.Tensor.signbit.rst", "generated/torch.Tensor.sin.rst", "generated/torch.Tensor.sin_.rst", "generated/torch.Tensor.sinc.rst", "generated/torch.Tensor.sinc_.rst", "generated/torch.Tensor.sinh.rst", "generated/torch.Tensor.sinh_.rst", "generated/torch.Tensor.size.rst", "generated/torch.Tensor.slice_scatter.rst", "generated/torch.Tensor.slogdet.rst", "generated/torch.Tensor.smm.rst", "generated/torch.Tensor.softmax.rst", "generated/torch.Tensor.sort.rst", "generated/torch.Tensor.sparse_dim.rst", "generated/torch.Tensor.sparse_mask.rst", "generated/torch.Tensor.sparse_resize_.rst", "generated/torch.Tensor.sparse_resize_and_clear_.rst", "generated/torch.Tensor.split.rst", "generated/torch.Tensor.sqrt.rst", "generated/torch.Tensor.sqrt_.rst", "generated/torch.Tensor.square.rst", "generated/torch.Tensor.square_.rst", "generated/torch.Tensor.squeeze.rst", "generated/torch.Tensor.squeeze_.rst", "generated/torch.Tensor.sspaddmm.rst", "generated/torch.Tensor.std.rst", "generated/torch.Tensor.stft.rst", "generated/torch.Tensor.storage.rst", "generated/torch.Tensor.storage_offset.rst", "generated/torch.Tensor.storage_type.rst", "generated/torch.Tensor.stride.rst", "generated/torch.Tensor.sub.rst", "generated/torch.Tensor.sub_.rst", "generated/torch.Tensor.subtract.rst", "generated/torch.Tensor.subtract_.rst", "generated/torch.Tensor.sum.rst", "generated/torch.Tensor.sum_to_size.rst", "generated/torch.Tensor.svd.rst", "generated/torch.Tensor.swapaxes.rst", "generated/torch.Tensor.swapdims.rst", "generated/torch.Tensor.t.rst", "generated/torch.Tensor.t_.rst", "generated/torch.Tensor.take.rst", "generated/torch.Tensor.take_along_dim.rst", "generated/torch.Tensor.tan.rst", "generated/torch.Tensor.tan_.rst", "generated/torch.Tensor.tanh.rst", "generated/torch.Tensor.tanh_.rst", "generated/torch.Tensor.tensor_split.rst", "generated/torch.Tensor.tile.rst", "generated/torch.Tensor.to.rst", "generated/torch.Tensor.to_dense.rst", "generated/torch.Tensor.to_mkldnn.rst", "generated/torch.Tensor.to_sparse.rst", "generated/torch.Tensor.to_sparse_bsc.rst", "generated/torch.Tensor.to_sparse_bsr.rst", "generated/torch.Tensor.to_sparse_coo.rst", "generated/torch.Tensor.to_sparse_csc.rst", "generated/torch.Tensor.to_sparse_csr.rst", "generated/torch.Tensor.tolist.rst", "generated/torch.Tensor.topk.rst", "generated/torch.Tensor.trace.rst", "generated/torch.Tensor.transpose.rst", "generated/torch.Tensor.transpose_.rst", "generated/torch.Tensor.triangular_solve.rst", "generated/torch.Tensor.tril.rst", "generated/torch.Tensor.tril_.rst", "generated/torch.Tensor.triu.rst", "generated/torch.Tensor.triu_.rst", "generated/torch.Tensor.true_divide.rst", "generated/torch.Tensor.true_divide_.rst", "generated/torch.Tensor.trunc.rst", "generated/torch.Tensor.trunc_.rst", "generated/torch.Tensor.type.rst", "generated/torch.Tensor.type_as.rst", "generated/torch.Tensor.unbind.rst", "generated/torch.Tensor.unflatten.rst", "generated/torch.Tensor.unfold.rst", "generated/torch.Tensor.uniform_.rst", "generated/torch.Tensor.unique.rst", "generated/torch.Tensor.unique_consecutive.rst", "generated/torch.Tensor.unsqueeze.rst", "generated/torch.Tensor.unsqueeze_.rst", "generated/torch.Tensor.untyped_storage.rst", "generated/torch.Tensor.values.rst", "generated/torch.Tensor.var.rst", "generated/torch.Tensor.vdot.rst", "generated/torch.Tensor.view.rst", "generated/torch.Tensor.view_as.rst", "generated/torch.Tensor.vsplit.rst", "generated/torch.Tensor.where.rst", "generated/torch.Tensor.xlogy.rst", "generated/torch.Tensor.xlogy_.rst", "generated/torch.Tensor.xpu.rst", "generated/torch.Tensor.zero_.rst", "generated/torch._assert.rst", "generated/torch._foreach_abs.rst", "generated/torch._foreach_abs_.rst", "generated/torch._foreach_acos.rst", "generated/torch._foreach_acos_.rst", "generated/torch._foreach_asin.rst", "generated/torch._foreach_asin_.rst", "generated/torch._foreach_atan.rst", "generated/torch._foreach_atan_.rst", "generated/torch._foreach_ceil.rst", "generated/torch._foreach_ceil_.rst", "generated/torch._foreach_cos.rst", "generated/torch._foreach_cos_.rst", "generated/torch._foreach_cosh.rst", "generated/torch._foreach_cosh_.rst", "generated/torch._foreach_erf.rst", "generated/torch._foreach_erf_.rst", "generated/torch._foreach_erfc.rst", "generated/torch._foreach_erfc_.rst", "generated/torch._foreach_exp.rst", "generated/torch._foreach_exp_.rst", "generated/torch._foreach_expm1.rst", "generated/torch._foreach_expm1_.rst", "generated/torch._foreach_floor.rst", "generated/torch._foreach_floor_.rst", "generated/torch._foreach_frac.rst", "generated/torch._foreach_frac_.rst", "generated/torch._foreach_lgamma.rst", "generated/torch._foreach_lgamma_.rst", "generated/torch._foreach_log.rst", "generated/torch._foreach_log10.rst", "generated/torch._foreach_log10_.rst", "generated/torch._foreach_log1p.rst", "generated/torch._foreach_log1p_.rst", "generated/torch._foreach_log2.rst", "generated/torch._foreach_log2_.rst", "generated/torch._foreach_log_.rst", "generated/torch._foreach_neg.rst", "generated/torch._foreach_neg_.rst", "generated/torch._foreach_reciprocal.rst", "generated/torch._foreach_reciprocal_.rst", "generated/torch._foreach_round.rst", "generated/torch._foreach_round_.rst", "generated/torch._foreach_sigmoid.rst", "generated/torch._foreach_sigmoid_.rst", "generated/torch._foreach_sin.rst", "generated/torch._foreach_sin_.rst", "generated/torch._foreach_sinh.rst", "generated/torch._foreach_sinh_.rst", "generated/torch._foreach_sqrt.rst", "generated/torch._foreach_sqrt_.rst", "generated/torch._foreach_tan.rst", "generated/torch._foreach_tan_.rst", "generated/torch._foreach_trunc.rst", "generated/torch._foreach_trunc_.rst", "generated/torch._foreach_zero_.rst", "generated/torch._logging.set_logs.rst", "generated/torch.abs.rst", "generated/torch.absolute.rst", "generated/torch.accelerator.current_accelerator.rst", "generated/torch.accelerator.current_device_idx.rst", "generated/torch.accelerator.current_device_index.rst", "generated/torch.accelerator.current_stream.rst", "generated/torch.accelerator.device_count.rst", "generated/torch.accelerator.is_available.rst", "generated/torch.accelerator.set_device_idx.rst", "generated/torch.accelerator.set_device_index.rst", "generated/torch.accelerator.set_stream.rst", "generated/torch.accelerator.synchronize.rst", "generated/torch.acos.rst", "generated/torch.acosh.rst", "generated/torch.add.rst", "generated/torch.addbmm.rst", "generated/torch.addcdiv.rst", "generated/torch.addcmul.rst", "generated/torch.addmm.rst", "generated/torch.addmv.rst", "generated/torch.addr.rst", "generated/torch.adjoint.rst", "generated/torch.all.rst", "generated/torch.allclose.rst", "generated/torch.amax.rst", "generated/torch.amin.rst", "generated/torch.aminmax.rst", "generated/torch.angle.rst", "generated/torch.any.rst", "generated/torch.ao.nn.intrinsic.BNReLU2d.rst", "generated/torch.ao.nn.intrinsic.BNReLU3d.rst", "generated/torch.ao.nn.intrinsic.ConvBn1d.rst", "generated/torch.ao.nn.intrinsic.ConvBn2d.rst", "generated/torch.ao.nn.intrinsic.ConvBn3d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU1d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU2d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU3d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU1d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn1d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn3d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU1d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU3d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.qat.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.qat.freeze_bn_stats.rst", "generated/torch.ao.nn.intrinsic.qat.update_bn_stats.rst", "generated/torch.ao.nn.intrinsic.quantized.BNReLU2d.rst", "generated/torch.ao.nn.intrinsic.quantized.BNReLU3d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU1d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.quantized.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU.rst", "generated/torch.ao.nn.qat.Conv2d.rst", "generated/torch.ao.nn.qat.Conv3d.rst", "generated/torch.ao.nn.qat.Linear.rst", "generated/torch.ao.nn.qat.dynamic.Linear.rst", "generated/torch.ao.nn.quantizable.LSTM.rst", "generated/torch.ao.nn.quantizable.MultiheadAttention.rst", "generated/torch.ao.nn.quantized.BatchNorm2d.rst", "generated/torch.ao.nn.quantized.BatchNorm3d.rst", "generated/torch.ao.nn.quantized.Conv1d.rst", "generated/torch.ao.nn.quantized.Conv2d.rst", "generated/torch.ao.nn.quantized.Conv3d.rst", "generated/torch.ao.nn.quantized.ConvTranspose1d.rst", "generated/torch.ao.nn.quantized.ConvTranspose2d.rst", "generated/torch.ao.nn.quantized.ConvTranspose3d.rst", "generated/torch.ao.nn.quantized.ELU.rst", "generated/torch.ao.nn.quantized.Embedding.rst", "generated/torch.ao.nn.quantized.EmbeddingBag.rst", "generated/torch.ao.nn.quantized.FXFloatFunctional.rst", "generated/torch.ao.nn.quantized.FloatFunctional.rst", "generated/torch.ao.nn.quantized.GroupNorm.rst", "generated/torch.ao.nn.quantized.Hardswish.rst", "generated/torch.ao.nn.quantized.InstanceNorm1d.rst", "generated/torch.ao.nn.quantized.InstanceNorm2d.rst", "generated/torch.ao.nn.quantized.InstanceNorm3d.rst", "generated/torch.ao.nn.quantized.LayerNorm.rst", "generated/torch.ao.nn.quantized.LeakyReLU.rst", "generated/torch.ao.nn.quantized.Linear.rst", "generated/torch.ao.nn.quantized.QFunctional.rst", "generated/torch.ao.nn.quantized.ReLU6.rst", "generated/torch.ao.nn.quantized.Sigmoid.rst", "generated/torch.ao.nn.quantized.dynamic.GRU.rst", "generated/torch.ao.nn.quantized.dynamic.GRUCell.rst", "generated/torch.ao.nn.quantized.dynamic.LSTM.rst", "generated/torch.ao.nn.quantized.dynamic.LSTMCell.rst", "generated/torch.ao.nn.quantized.dynamic.Linear.rst", "generated/torch.ao.nn.quantized.dynamic.RNNCell.rst", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool2d.rst", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool3d.rst", "generated/torch.ao.nn.quantized.functional.avg_pool2d.rst", "generated/torch.ao.nn.quantized.functional.avg_pool3d.rst", "generated/torch.ao.nn.quantized.functional.celu.rst", "generated/torch.ao.nn.quantized.functional.clamp.rst", "generated/torch.ao.nn.quantized.functional.conv1d.rst", "generated/torch.ao.nn.quantized.functional.conv2d.rst", "generated/torch.ao.nn.quantized.functional.conv3d.rst", "generated/torch.ao.nn.quantized.functional.elu.rst", "generated/torch.ao.nn.quantized.functional.hardsigmoid.rst", "generated/torch.ao.nn.quantized.functional.hardswish.rst", "generated/torch.ao.nn.quantized.functional.hardtanh.rst", "generated/torch.ao.nn.quantized.functional.interpolate.rst", "generated/torch.ao.nn.quantized.functional.leaky_relu.rst", "generated/torch.ao.nn.quantized.functional.linear.rst", "generated/torch.ao.nn.quantized.functional.max_pool1d.rst", "generated/torch.ao.nn.quantized.functional.max_pool2d.rst", "generated/torch.ao.nn.quantized.functional.threshold.rst", "generated/torch.ao.nn.quantized.functional.upsample.rst", "generated/torch.ao.nn.quantized.functional.upsample_bilinear.rst", "generated/torch.ao.nn.quantized.functional.upsample_nearest.rst", "generated/torch.ao.quantization.CUSTOM_KEY.rst", "generated/torch.ao.quantization.DeQuantStub.rst", "generated/torch.ao.quantization.NUMERIC_DEBUG_HANDLE_KEY.rst", "generated/torch.ao.quantization.QuantStub.rst", "generated/torch.ao.quantization.QuantWrapper.rst", "generated/torch.ao.quantization.add_quant_dequant.rst", "generated/torch.ao.quantization.backend_config.BackendConfig.rst", "generated/torch.ao.quantization.backend_config.BackendPatternConfig.rst", "generated/torch.ao.quantization.backend_config.DTypeConfig.rst", "generated/torch.ao.quantization.backend_config.DTypeWithConstraints.rst", "generated/torch.ao.quantization.backend_config.ObservationType.rst", "generated/torch.ao.quantization.compare_results.rst", "generated/torch.ao.quantization.convert.rst", "generated/torch.ao.quantization.default_eval_fn.rst", "generated/torch.ao.quantization.extract_results_from_loggers.rst", "generated/torch.ao.quantization.fake_quantize.FakeQuantize.rst", "generated/torch.ao.quantization.fake_quantize.FakeQuantizeBase.rst", "generated/torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.rst", "generated/torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize.rst", "generated/torch.ao.quantization.fake_quantize.default_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_fused_act_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_histogram_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_weight_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.disable_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.disable_observer.rst", "generated/torch.ao.quantization.fake_quantize.enable_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.enable_observer.rst", "generated/torch.ao.quantization.fuse_modules.fuse_modules.rst", "generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry.rst", "generated/torch.ao.quantization.generate_numeric_debug_handle.rst", "generated/torch.ao.quantization.observer.AffineQuantizedObserverBase.rst", "generated/torch.ao.quantization.observer.Granularity.rst", "generated/torch.ao.quantization.observer.HistogramObserver.rst", "generated/torch.ao.quantization.observer.MappingType.rst", "generated/torch.ao.quantization.observer.MinMaxObserver.rst", "generated/torch.ao.quantization.observer.MovingAverageMinMaxObserver.rst", "generated/torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver.rst", "generated/torch.ao.quantization.observer.NoopObserver.rst", "generated/torch.ao.quantization.observer.ObserverBase.rst", "generated/torch.ao.quantization.observer.PerAxis.rst", "generated/torch.ao.quantization.observer.PerBlock.rst", "generated/torch.ao.quantization.observer.PerChannelMinMaxObserver.rst", "generated/torch.ao.quantization.observer.PerGroup.rst", "generated/torch.ao.quantization.observer.PerRow.rst", "generated/torch.ao.quantization.observer.PerTensor.rst", "generated/torch.ao.quantization.observer.PerToken.rst", "generated/torch.ao.quantization.observer.PlaceholderObserver.rst", "generated/torch.ao.quantization.observer.RecordingObserver.rst", "generated/torch.ao.quantization.observer.TorchAODType.rst", "generated/torch.ao.quantization.observer.ZeroPointDomain.rst", "generated/torch.ao.quantization.observer.default_debug_observer.rst", "generated/torch.ao.quantization.observer.default_dynamic_quant_observer.rst", "generated/torch.ao.quantization.observer.default_float_qparams_observer.rst", "generated/torch.ao.quantization.observer.default_histogram_observer.rst", "generated/torch.ao.quantization.observer.default_observer.rst", "generated/torch.ao.quantization.observer.default_per_channel_weight_observer.rst", "generated/torch.ao.quantization.observer.default_placeholder_observer.rst", "generated/torch.ao.quantization.observer.default_weight_observer.rst", "generated/torch.ao.quantization.observer.get_block_size.rst", "generated/torch.ao.quantization.observer.get_observer_state_dict.rst", "generated/torch.ao.quantization.observer.load_observer_state_dict.rst", "generated/torch.ao.quantization.prepare.rst", "generated/torch.ao.quantization.prepare_for_propagation_comparison.rst", "generated/torch.ao.quantization.prepare_qat.rst", "generated/torch.ao.quantization.propagate_qconfig_.rst", "generated/torch.ao.quantization.pt2e.export_utils.model_is_exported.rst", "generated/torch.ao.quantization.qconfig.QConfig.rst", "generated/torch.ao.quantization.qconfig.default_activation_only_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_debug_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_dynamic_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_per_channel_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_qat_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_qat_qconfig_v2.rst", "generated/torch.ao.quantization.qconfig.default_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_weight_only_qconfig.rst", "generated/torch.ao.quantization.qconfig.float16_dynamic_qconfig.rst", "generated/torch.ao.quantization.qconfig.float16_static_qconfig.rst", "generated/torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig.rst", "generated/torch.ao.quantization.qconfig.per_channel_dynamic_qconfig.rst", "generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.rst", "generated/torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping.rst", "generated/torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping.rst", "generated/torch.ao.quantization.quantize.rst", "generated/torch.ao.quantization.quantize_dynamic.rst", "generated/torch.ao.quantization.quantize_fx.convert_fx.rst", "generated/torch.ao.quantization.quantize_fx.fuse_fx.rst", "generated/torch.ao.quantization.quantize_fx.prepare_fx.rst", "generated/torch.ao.quantization.quantize_fx.prepare_qat_fx.rst", "generated/torch.ao.quantization.quantize_qat.rst", "generated/torch.ao.quantization.swap_module.rst", "generated/torch.arange.rst", "generated/torch.arccos.rst", "generated/torch.arccosh.rst", "generated/torch.arcsin.rst", "generated/torch.arcsinh.rst", "generated/torch.arctan.rst", "generated/torch.arctan2.rst", "generated/torch.arctanh.rst", "generated/torch.are_deterministic_algorithms_enabled.rst", "generated/torch.argmax.rst", "generated/torch.argmin.rst", "generated/torch.argsort.rst", "generated/torch.argwhere.rst", "generated/torch.as_strided.rst", "generated/torch.as_tensor.rst", "generated/torch.asarray.rst", "generated/torch.asin.rst", "generated/torch.asinh.rst", "generated/torch.atan.rst", "generated/torch.atan2.rst", "generated/torch.atanh.rst", "generated/torch.atleast_1d.rst", "generated/torch.atleast_2d.rst", "generated/torch.atleast_3d.rst", "generated/torch.autograd.Function.backward.rst", "generated/torch.autograd.Function.forward.rst", "generated/torch.autograd.Function.jvp.rst", "generated/torch.autograd.Function.vmap.rst", "generated/torch.autograd.backward.rst", "generated/torch.autograd.forward_ad.UnpackedDualTensor.rst", "generated/torch.autograd.forward_ad.dual_level.rst", "generated/torch.autograd.forward_ad.enter_dual_level.rst", "generated/torch.autograd.forward_ad.exit_dual_level.rst", "generated/torch.autograd.forward_ad.make_dual.rst", "generated/torch.autograd.forward_ad.unpack_dual.rst", "generated/torch.autograd.function.BackwardCFunction.rst", "generated/torch.autograd.function.FunctionCtx.mark_dirty.rst", "generated/torch.autograd.function.FunctionCtx.mark_non_differentiable.rst", "generated/torch.autograd.function.FunctionCtx.save_for_backward.rst", "generated/torch.autograd.function.FunctionCtx.set_materialize_grads.rst", "generated/torch.autograd.function.InplaceFunction.rst", "generated/torch.autograd.function.NestedIOFunction.rst", "generated/torch.autograd.function.once_differentiable.rst", "generated/torch.autograd.functional.hessian.rst", "generated/torch.autograd.functional.hvp.rst", "generated/torch.autograd.functional.jacobian.rst", "generated/torch.autograd.functional.jvp.rst", "generated/torch.autograd.functional.vhp.rst", "generated/torch.autograd.functional.vjp.rst", "generated/torch.autograd.grad.rst", "generated/torch.autograd.grad_mode.inference_mode.rst", "generated/torch.autograd.grad_mode.set_grad_enabled.rst", "generated/torch.autograd.grad_mode.set_multithreading_enabled.rst", "generated/torch.autograd.gradcheck.GradcheckError.rst", "generated/torch.autograd.gradcheck.gradcheck.rst", "generated/torch.autograd.gradcheck.gradgradcheck.rst", "generated/torch.autograd.graph.Node.metadata.rst", "generated/torch.autograd.graph.Node.name.rst", "generated/torch.autograd.graph.Node.next_functions.rst", "generated/torch.autograd.graph.Node.register_hook.rst", "generated/torch.autograd.graph.Node.register_prehook.rst", "generated/torch.autograd.graph.increment_version.rst", "generated/torch.autograd.profiler.EnforceUnique.rst", "generated/torch.autograd.profiler.KinetoStepTracker.rst", "generated/torch.autograd.profiler.load_nvprof.rst", "generated/torch.autograd.profiler.parse_nvprof_trace.rst", "generated/torch.autograd.profiler.profile.export_chrome_trace.rst", "generated/torch.autograd.profiler.profile.key_averages.rst", "generated/torch.autograd.profiler.profile.self_cpu_time_total.rst", "generated/torch.autograd.profiler.profile.total_average.rst", "generated/torch.autograd.profiler.record_function.rst", "generated/torch.autograd.profiler_util.Interval.rst", "generated/torch.autograd.profiler_util.Kernel.rst", "generated/torch.autograd.profiler_util.MemRecordsAcc.rst", "generated/torch.autograd.profiler_util.StringTable.rst", "generated/torch.baddbmm.rst", "generated/torch.bartlett_window.rst", "generated/torch.bernoulli.rst", "generated/torch.bincount.rst", "generated/torch.bitwise_and.rst", "generated/torch.bitwise_left_shift.rst", "generated/torch.bitwise_not.rst", "generated/torch.bitwise_or.rst", "generated/torch.bitwise_right_shift.rst", "generated/torch.bitwise_xor.rst", "generated/torch.blackman_window.rst", "generated/torch.block_diag.rst", "generated/torch.bmm.rst", "generated/torch.broadcast_shapes.rst", "generated/torch.broadcast_tensors.rst", "generated/torch.broadcast_to.rst", "generated/torch.bucketize.rst", "generated/torch.can_cast.rst", "generated/torch.cartesian_prod.rst", "generated/torch.cat.rst", "generated/torch.cdist.rst", "generated/torch.ceil.rst", "generated/torch.chain_matmul.rst", "generated/torch.cholesky.rst", "generated/torch.cholesky_inverse.rst", "generated/torch.cholesky_solve.rst", "generated/torch.chunk.rst", "generated/torch.clamp.rst", "generated/torch.clip.rst", "generated/torch.clone.rst", "generated/torch.column_stack.rst", "generated/torch.combinations.rst", "generated/torch.compile.rst", "generated/torch.compiled_with_cxx11_abi.rst", "generated/torch.compiler.allow_in_graph.rst", "generated/torch.compiler.assume_constant_result.rst", "generated/torch.compiler.compile.rst", "generated/torch.compiler.cudagraph_mark_step_begin.rst", "generated/torch.compiler.disable.rst", "generated/torch.compiler.is_compiling.rst", "generated/torch.compiler.is_dynamo_compiling.rst", "generated/torch.compiler.is_exporting.rst", "generated/torch.compiler.list_backends.rst", "generated/torch.compiler.reset.rst", "generated/torch.compiler.set_stance.rst", "generated/torch.compiler.substitute_in_graph.rst", "generated/torch.complex.rst", "generated/torch.concat.rst", "generated/torch.concatenate.rst", "generated/torch.cond.rst", "generated/torch.conj.rst", "generated/torch.conj_physical.rst", "generated/torch.copysign.rst", "generated/torch.corrcoef.rst", "generated/torch.cos.rst", "generated/torch.cosh.rst", "generated/torch.count_nonzero.rst", "generated/torch.cov.rst", "generated/torch.cpu.Stream.rst", "generated/torch.cpu.StreamContext.rst", "generated/torch.cpu.current_device.rst", "generated/torch.cpu.current_stream.rst", "generated/torch.cpu.device_count.rst", "generated/torch.cpu.is_available.rst", "generated/torch.cpu.set_device.rst", "generated/torch.cpu.synchronize.rst", "generated/torch.cross.rst", "generated/torch.cuda.CUDAGraph.rst", "generated/torch.cuda.CUDAPluggableAllocator.rst", "generated/torch.cuda.Event.rst", "generated/torch.cuda.ExternalStream.rst", "generated/torch.cuda.MemPool.rst", "generated/torch.cuda.MemPoolContext.rst", "generated/torch.cuda.OutOfMemoryError.rst", "generated/torch.cuda.Stream.rst", "generated/torch.cuda.StreamContext.rst", "generated/torch.cuda.caching_allocator_alloc.rst", "generated/torch.cuda.caching_allocator_delete.rst", "generated/torch.cuda.can_device_access_peer.rst", "generated/torch.cuda.change_current_allocator.rst", "generated/torch.cuda.clock_rate.rst", "generated/torch.cuda.comm.broadcast.rst", "generated/torch.cuda.comm.broadcast_coalesced.rst", "generated/torch.cuda.comm.gather.rst", "generated/torch.cuda.comm.reduce_add.rst", "generated/torch.cuda.comm.reduce_add_coalesced.rst", "generated/torch.cuda.comm.scatter.rst", "generated/torch.cuda.cudart.rst", "generated/torch.cuda.current_blas_handle.rst", "generated/torch.cuda.current_device.rst", "generated/torch.cuda.current_stream.rst", "generated/torch.cuda.default_stream.rst", "generated/torch.cuda.device.rst", "generated/torch.cuda.device_count.rst", "generated/torch.cuda.device_memory_used.rst", "generated/torch.cuda.device_of.rst", "generated/torch.cuda.empty_cache.rst", "generated/torch.cuda.get_allocator_backend.rst", "generated/torch.cuda.get_arch_list.rst", "generated/torch.cuda.get_device_capability.rst", "generated/torch.cuda.get_device_name.rst", "generated/torch.cuda.get_device_properties.rst", "generated/torch.cuda.get_gencode_flags.rst", "generated/torch.cuda.get_per_process_memory_fraction.rst", "generated/torch.cuda.get_rng_state.rst", "generated/torch.cuda.get_rng_state_all.rst", "generated/torch.cuda.get_stream_from_external.rst", "generated/torch.cuda.get_sync_debug_mode.rst", "generated/torch.cuda.graph.rst", "generated/torch.cuda.graph_pool_handle.rst", "generated/torch.cuda.init.rst", "generated/torch.cuda.initial_seed.rst", "generated/torch.cuda.ipc_collect.rst", "generated/torch.cuda.is_available.rst", "generated/torch.cuda.is_current_stream_capturing.rst", "generated/torch.cuda.is_initialized.rst", "generated/torch.cuda.jiterator._create_jit_fn.rst", "generated/torch.cuda.jiterator._create_multi_output_jit_fn.rst", "generated/torch.cuda.list_gpu_processes.rst", "generated/torch.cuda.make_graphed_callables.rst", "generated/torch.cuda.manual_seed.rst", "generated/torch.cuda.manual_seed_all.rst", "generated/torch.cuda.max_memory_allocated.rst", "generated/torch.cuda.max_memory_cached.rst", "generated/torch.cuda.max_memory_reserved.rst", "generated/torch.cuda.mem_get_info.rst", "generated/torch.cuda.memory.caching_allocator_enable.rst", "generated/torch.cuda.memory_allocated.rst", "generated/torch.cuda.memory_cached.rst", "generated/torch.cuda.memory_reserved.rst", "generated/torch.cuda.memory_snapshot.rst", "generated/torch.cuda.memory_stats.rst", "generated/torch.cuda.memory_summary.rst", "generated/torch.cuda.memory_usage.rst", "generated/torch.cuda.nvtx.mark.rst", "generated/torch.cuda.nvtx.range.rst", "generated/torch.cuda.nvtx.range_pop.rst", "generated/torch.cuda.nvtx.range_push.rst", "generated/torch.cuda.power_draw.rst", "generated/torch.cuda.reset_max_memory_allocated.rst", "generated/torch.cuda.reset_max_memory_cached.rst", "generated/torch.cuda.reset_peak_memory_stats.rst", "generated/torch.cuda.seed.rst", "generated/torch.cuda.seed_all.rst", "generated/torch.cuda.set_device.rst", "generated/torch.cuda.set_per_process_memory_fraction.rst", "generated/torch.cuda.set_rng_state.rst", "generated/torch.cuda.set_rng_state_all.rst", "generated/torch.cuda.set_stream.rst", "generated/torch.cuda.set_sync_debug_mode.rst", "generated/torch.cuda.synchronize.rst", "generated/torch.cuda.temperature.rst", "generated/torch.cuda.utilization.rst", "generated/torch.cummax.rst", "generated/torch.cummin.rst", "generated/torch.cumprod.rst", "generated/torch.cumsum.rst", "generated/torch.cumulative_trapezoid.rst", "generated/torch.deg2rad.rst", "generated/torch.dequantize.rst", "generated/torch.det.rst", "generated/torch.diag.rst", "generated/torch.diag_embed.rst", "generated/torch.diagflat.rst", "generated/torch.diagonal.rst", "generated/torch.diagonal_scatter.rst", "generated/torch.diff.rst", "generated/torch.digamma.rst", "generated/torch.dist.rst", "generated/torch.div.rst", "generated/torch.divide.rst", "generated/torch.dot.rst", "generated/torch.dsplit.rst", "generated/torch.dstack.rst", "generated/torch.einsum.rst", "generated/torch.empty.rst", "generated/torch.empty_like.rst", "generated/torch.empty_strided.rst", "generated/torch.enable_grad.rst", "generated/torch.eq.rst", "generated/torch.equal.rst", "generated/torch.erf.rst", "generated/torch.erfc.rst", "generated/torch.erfinv.rst", "generated/torch.exp.rst", "generated/torch.exp2.rst", "generated/torch.expm1.rst", "generated/torch.eye.rst", "generated/torch.fake_quantize_per_channel_affine.rst", "generated/torch.fake_quantize_per_tensor_affine.rst", "generated/torch.fft.fft.rst", "generated/torch.fft.fft2.rst", "generated/torch.fft.fftfreq.rst", "generated/torch.fft.fftn.rst", "generated/torch.fft.fftshift.rst", "generated/torch.fft.hfft.rst", "generated/torch.fft.hfft2.rst", "generated/torch.fft.hfftn.rst", "generated/torch.fft.ifft.rst", "generated/torch.fft.ifft2.rst", "generated/torch.fft.ifftn.rst", "generated/torch.fft.ifftshift.rst", "generated/torch.fft.ihfft.rst", "generated/torch.fft.ihfft2.rst", "generated/torch.fft.ihfftn.rst", "generated/torch.fft.irfft.rst", "generated/torch.fft.irfft2.rst", "generated/torch.fft.irfftn.rst", "generated/torch.fft.rfft.rst", "generated/torch.fft.rfft2.rst", "generated/torch.fft.rfftfreq.rst", "generated/torch.fft.rfftn.rst", "generated/torch.fix.rst", "generated/torch.flatten.rst", "generated/torch.flip.rst", "generated/torch.fliplr.rst", "generated/torch.flipud.rst", "generated/torch.float_power.rst", "generated/torch.floor.rst", "generated/torch.floor_divide.rst", "generated/torch.fmax.rst", "generated/torch.fmin.rst", "generated/torch.fmod.rst", "generated/torch.frac.rst", "generated/torch.frexp.rst", "generated/torch.from_dlpack.rst", "generated/torch.from_file.rst", "generated/torch.from_numpy.rst", "generated/torch.frombuffer.rst", "generated/torch.full.rst", "generated/torch.full_like.rst", "generated/torch.func.functional_call.rst", "generated/torch.func.functionalize.rst", "generated/torch.func.grad.rst", "generated/torch.func.grad_and_value.rst", "generated/torch.func.hessian.rst", "generated/torch.func.jacfwd.rst", "generated/torch.func.jacrev.rst", "generated/torch.func.jvp.rst", "generated/torch.func.linearize.rst", "generated/torch.func.replace_all_batch_norm_modules_.rst", "generated/torch.func.stack_module_state.rst", "generated/torch.func.vjp.rst", "generated/torch.func.vmap.rst", "generated/torch.fx.experimental.proxy_tensor.get_proxy_mode.rst", "generated/torch.fx.experimental.proxy_tensor.handle_sym_dispatch.rst", "generated/torch.fx.experimental.proxy_tensor.make_fx.rst", "generated/torch.fx.experimental.proxy_tensor.maybe_disable_thunkify.rst", "generated/torch.fx.experimental.proxy_tensor.maybe_enable_thunkify.rst", "generated/torch.fx.experimental.symbolic_shapes.CallMethodKey.rst", "generated/torch.fx.experimental.symbolic_shapes.ConvertIntKey.rst", "generated/torch.fx.experimental.symbolic_shapes.DimConstraints.rst", "generated/torch.fx.experimental.symbolic_shapes.DimDynamic.rst", "generated/torch.fx.experimental.symbolic_shapes.DivideByKey.rst", "generated/torch.fx.experimental.symbolic_shapes.EqualityConstraint.rst", "generated/torch.fx.experimental.symbolic_shapes.InnerTensorKey.rst", "generated/torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.rst", "generated/torch.fx.experimental.symbolic_shapes.RelaxedUnspecConstraint.rst", "generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.rst", "generated/torch.fx.experimental.symbolic_shapes.ShapeEnvSettings.rst", "generated/torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext.rst", "generated/torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext.rst", "generated/torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint.rst", "generated/torch.fx.experimental.symbolic_shapes.SubclassSymbolicContext.rst", "generated/torch.fx.experimental.symbolic_shapes.SymbolicContext.rst", "generated/torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr.rst", "generated/torch.fx.experimental.symbolic_shapes.check_consistent.rst", "generated/torch.fx.experimental.symbolic_shapes.compute_unbacked_bindings.rst", "generated/torch.fx.experimental.symbolic_shapes.constrain_range.rst", "generated/torch.fx.experimental.symbolic_shapes.constrain_unify.rst", "generated/torch.fx.experimental.symbolic_shapes.definitely_false.rst", "generated/torch.fx.experimental.symbolic_shapes.definitely_true.rst", "generated/torch.fx.experimental.symbolic_shapes.guard_size_oblivious.rst", "generated/torch.fx.experimental.symbolic_shapes.has_free_symbols.rst", "generated/torch.fx.experimental.symbolic_shapes.has_free_unbacked_symbols.rst", "generated/torch.fx.experimental.symbolic_shapes.hint_int.rst", "generated/torch.fx.experimental.symbolic_shapes.is_accessor_node.rst", "generated/torch.fx.experimental.symbolic_shapes.is_concrete_bool.rst", "generated/torch.fx.experimental.symbolic_shapes.is_concrete_float.rst", "generated/torch.fx.experimental.symbolic_shapes.is_concrete_int.rst", "generated/torch.fx.experimental.symbolic_shapes.lru_cache.rst", "generated/torch.fx.experimental.symbolic_shapes.rebind_unbacked.rst", "generated/torch.fx.experimental.symbolic_shapes.resolve_unbacked_bindings.rst", "generated/torch.fx.experimental.symbolic_shapes.statically_known_true.rst", "generated/torch.fx.experimental.symbolic_shapes.sym_eq.rst", "generated/torch.gather.rst", "generated/torch.gcd.rst", "generated/torch.ge.rst", "generated/torch.geqrf.rst", "generated/torch.ger.rst", "generated/torch.get_default_device.rst", "generated/torch.get_default_dtype.rst", "generated/torch.get_deterministic_debug_mode.rst", "generated/torch.get_device_module.rst", "generated/torch.get_float32_matmul_precision.rst", "generated/torch.get_num_interop_threads.rst", "generated/torch.get_num_threads.rst", "generated/torch.get_rng_state.rst", "generated/torch.gradient.rst", "generated/torch.greater.rst", "generated/torch.greater_equal.rst", "generated/torch.gt.rst", "generated/torch.hamming_window.rst", "generated/torch.hann_window.rst", "generated/torch.heaviside.rst", "generated/torch.histc.rst", "generated/torch.histogram.rst", "generated/torch.histogramdd.rst", "generated/torch.hsplit.rst", "generated/torch.hspmm.rst", "generated/torch.hstack.rst", "generated/torch.hypot.rst", "generated/torch.i0.rst", "generated/torch.igamma.rst", "generated/torch.igammac.rst", "generated/torch.imag.rst", "generated/torch.index_add.rst", "generated/torch.index_copy.rst", "generated/torch.index_reduce.rst", "generated/torch.index_select.rst", "generated/torch.initial_seed.rst", "generated/torch.inner.rst", "generated/torch.inverse.rst", "generated/torch.is_complex.rst", "generated/torch.is_conj.rst", "generated/torch.is_deterministic_algorithms_warn_only_enabled.rst", "generated/torch.is_floating_point.rst", "generated/torch.is_grad_enabled.rst", "generated/torch.is_inference_mode_enabled.rst", "generated/torch.is_nonzero.rst", "generated/torch.is_storage.rst", "generated/torch.is_tensor.rst", "generated/torch.is_warn_always_enabled.rst", "generated/torch.isclose.rst", "generated/torch.isfinite.rst", "generated/torch.isin.rst", "generated/torch.isinf.rst", "generated/torch.isnan.rst", "generated/torch.isneginf.rst", "generated/torch.isposinf.rst", "generated/torch.isreal.rst", "generated/torch.istft.rst", "generated/torch.jit.Attribute.rst", "generated/torch.jit.ScriptFunction.rst", "generated/torch.jit.ScriptModule.rst", "generated/torch.jit.annotate.rst", "generated/torch.jit.enable_onednn_fusion.rst", "generated/torch.jit.fork.rst", "generated/torch.jit.freeze.rst", "generated/torch.jit.ignore.rst", "generated/torch.jit.interface.rst", "generated/torch.jit.isinstance.rst", "generated/torch.jit.load.rst", "generated/torch.jit.onednn_fusion_enabled.rst", "generated/torch.jit.optimize_for_inference.rst", "generated/torch.jit.save.rst", "generated/torch.jit.script.rst", "generated/torch.jit.script_if_tracing.rst", "generated/torch.jit.set_fusion_strategy.rst", "generated/torch.jit.strict_fusion.rst", "generated/torch.jit.trace.rst", "generated/torch.jit.trace_module.rst", "generated/torch.jit.unused.rst", "generated/torch.jit.wait.rst", "generated/torch.kaiser_window.rst", "generated/torch.kron.rst", "generated/torch.kthvalue.rst", "generated/torch.lcm.rst", "generated/torch.ldexp.rst", "generated/torch.le.rst", "generated/torch.lerp.rst", "generated/torch.less.rst", "generated/torch.less_equal.rst", "generated/torch.lgamma.rst", "generated/torch.linalg.cholesky.rst", "generated/torch.linalg.cholesky_ex.rst", "generated/torch.linalg.cond.rst", "generated/torch.linalg.cross.rst", "generated/torch.linalg.det.rst", "generated/torch.linalg.diagonal.rst", "generated/torch.linalg.eig.rst", "generated/torch.linalg.eigh.rst", "generated/torch.linalg.eigvals.rst", "generated/torch.linalg.eigvalsh.rst", "generated/torch.linalg.householder_product.rst", "generated/torch.linalg.inv.rst", "generated/torch.linalg.inv_ex.rst", "generated/torch.linalg.ldl_factor.rst", "generated/torch.linalg.ldl_factor_ex.rst", "generated/torch.linalg.ldl_solve.rst", "generated/torch.linalg.lstsq.rst", "generated/torch.linalg.lu.rst", "generated/torch.linalg.lu_factor.rst", "generated/torch.linalg.lu_factor_ex.rst", "generated/torch.linalg.lu_solve.rst", "generated/torch.linalg.matmul.rst", "generated/torch.linalg.matrix_exp.rst", "generated/torch.linalg.matrix_norm.rst", "generated/torch.linalg.matrix_power.rst", "generated/torch.linalg.matrix_rank.rst", "generated/torch.linalg.multi_dot.rst", "generated/torch.linalg.norm.rst", "generated/torch.linalg.pinv.rst", "generated/torch.linalg.qr.rst", "generated/torch.linalg.slogdet.rst", "generated/torch.linalg.solve.rst", "generated/torch.linalg.solve_ex.rst", "generated/torch.linalg.solve_triangular.rst", "generated/torch.linalg.svd.rst", "generated/torch.linalg.svdvals.rst", "generated/torch.linalg.tensorinv.rst", "generated/torch.linalg.tensorsolve.rst", "generated/torch.linalg.vander.rst", "generated/torch.linalg.vecdot.rst", "generated/torch.linalg.vector_norm.rst", "generated/torch.linspace.rst", "generated/torch.load.rst", "generated/torch.lobpcg.rst", "generated/torch.log.rst", "generated/torch.log10.rst", "generated/torch.log1p.rst", "generated/torch.log2.rst", "generated/torch.logaddexp.rst", "generated/torch.logaddexp2.rst", "generated/torch.logcumsumexp.rst", "generated/torch.logdet.rst", "generated/torch.logical_and.rst", "generated/torch.logical_not.rst", "generated/torch.logical_or.rst", "generated/torch.logical_xor.rst", "generated/torch.logit.rst", "generated/torch.logspace.rst", "generated/torch.logsumexp.rst", "generated/torch.lt.rst", "generated/torch.lu.rst", "generated/torch.lu_solve.rst", "generated/torch.lu_unpack.rst", "generated/torch.manual_seed.rst", "generated/torch.masked_select.rst", "generated/torch.matmul.rst", "generated/torch.matrix_exp.rst", "generated/torch.matrix_power.rst", "generated/torch.max.rst", "generated/torch.maximum.rst", "generated/torch.mean.rst", "generated/torch.median.rst", "generated/torch.meshgrid.rst", "generated/torch.min.rst", "generated/torch.minimum.rst", "generated/torch.mm.rst", "generated/torch.mode.rst", "generated/torch.moveaxis.rst", "generated/torch.movedim.rst", "generated/torch.mps.current_allocated_memory.rst", "generated/torch.mps.device_count.rst", "generated/torch.mps.driver_allocated_memory.rst", "generated/torch.mps.empty_cache.rst", "generated/torch.mps.event.Event.rst", "generated/torch.mps.get_rng_state.rst", "generated/torch.mps.manual_seed.rst", "generated/torch.mps.profiler.is_capturing_metal.rst", "generated/torch.mps.profiler.is_metal_capture_enabled.rst", "generated/torch.mps.profiler.metal_capture.rst", "generated/torch.mps.profiler.profile.rst", "generated/torch.mps.profiler.start.rst", "generated/torch.mps.profiler.stop.rst", "generated/torch.mps.recommended_max_memory.rst", "generated/torch.mps.seed.rst", "generated/torch.mps.set_per_process_memory_fraction.rst", "generated/torch.mps.set_rng_state.rst", "generated/torch.mps.synchronize.rst", "generated/torch.msort.rst", "generated/torch.mtia.DeferredMtiaCallError.rst", "generated/torch.mtia.Event.rst", "generated/torch.mtia.Stream.rst", "generated/torch.mtia.StreamContext.rst", "generated/torch.mtia.current_device.rst", "generated/torch.mtia.current_stream.rst", "generated/torch.mtia.default_stream.rst", "generated/torch.mtia.device.rst", "generated/torch.mtia.device_count.rst", "generated/torch.mtia.empty_cache.rst", "generated/torch.mtia.get_device_capability.rst", "generated/torch.mtia.get_rng_state.rst", "generated/torch.mtia.init.rst", "generated/torch.mtia.is_available.rst", "generated/torch.mtia.is_initialized.rst", "generated/torch.mtia.memory.memory_stats.rst", "generated/torch.mtia.memory_stats.rst", "generated/torch.mtia.record_memory_history.rst", "generated/torch.mtia.set_device.rst", "generated/torch.mtia.set_rng_state.rst", "generated/torch.mtia.set_stream.rst", "generated/torch.mtia.snapshot.rst", "generated/torch.mtia.synchronize.rst", "generated/torch.mul.rst", "generated/torch.multinomial.rst", "generated/torch.multiply.rst", "generated/torch.mv.rst", "generated/torch.mvlgamma.rst", "generated/torch.nan_to_num.rst", "generated/torch.nanmean.rst", "generated/torch.nanmedian.rst", "generated/torch.nanquantile.rst", "generated/torch.nansum.rst", "generated/torch.narrow.rst", "generated/torch.narrow_copy.rst", "generated/torch.ne.rst", "generated/torch.neg.rst", "generated/torch.negative.rst", "generated/torch.nextafter.rst", "generated/torch.nn.AdaptiveAvgPool1d.rst", "generated/torch.nn.AdaptiveAvgPool2d.rst", "generated/torch.nn.AdaptiveAvgPool3d.rst", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss.rst", "generated/torch.nn.AdaptiveMaxPool1d.rst", "generated/torch.nn.AdaptiveMaxPool2d.rst", "generated/torch.nn.AdaptiveMaxPool3d.rst", "generated/torch.nn.AlphaDropout.rst", "generated/torch.nn.AvgPool1d.rst", "generated/torch.nn.AvgPool2d.rst", "generated/torch.nn.AvgPool3d.rst", "generated/torch.nn.BCELoss.rst", "generated/torch.nn.BCEWithLogitsLoss.rst", "generated/torch.nn.BatchNorm1d.rst", "generated/torch.nn.BatchNorm2d.rst", "generated/torch.nn.BatchNorm3d.rst", "generated/torch.nn.Bilinear.rst", "generated/torch.nn.CELU.rst", "generated/torch.nn.CTCLoss.rst", "generated/torch.nn.ChannelShuffle.rst", "generated/torch.nn.CircularPad1d.rst", "generated/torch.nn.CircularPad2d.rst", "generated/torch.nn.CircularPad3d.rst", "generated/torch.nn.ConstantPad1d.rst", "generated/torch.nn.ConstantPad2d.rst", "generated/torch.nn.ConstantPad3d.rst", "generated/torch.nn.Conv1d.rst", "generated/torch.nn.Conv2d.rst", "generated/torch.nn.Conv3d.rst", "generated/torch.nn.ConvTranspose1d.rst", "generated/torch.nn.ConvTranspose2d.rst", "generated/torch.nn.ConvTranspose3d.rst", "generated/torch.nn.CosineEmbeddingLoss.rst", "generated/torch.nn.CosineSimilarity.rst", "generated/torch.nn.CrossEntropyLoss.rst", "generated/torch.nn.DataParallel.rst", "generated/torch.nn.Dropout.rst", "generated/torch.nn.Dropout1d.rst", "generated/torch.nn.Dropout2d.rst", "generated/torch.nn.Dropout3d.rst", "generated/torch.nn.ELU.rst", "generated/torch.nn.Embedding.rst", "generated/torch.nn.EmbeddingBag.rst", "generated/torch.nn.FeatureAlphaDropout.rst", "generated/torch.nn.Flatten.rst", "generated/torch.nn.Fold.rst", "generated/torch.nn.FractionalMaxPool2d.rst", "generated/torch.nn.FractionalMaxPool3d.rst", "generated/torch.nn.GELU.rst", "generated/torch.nn.GLU.rst", "generated/torch.nn.GRU.rst", "generated/torch.nn.GRUCell.rst", "generated/torch.nn.GaussianNLLLoss.rst", "generated/torch.nn.GroupNorm.rst", "generated/torch.nn.Hardshrink.rst", "generated/torch.nn.Hardsigmoid.rst", "generated/torch.nn.Hardswish.rst", "generated/torch.nn.Hardtanh.rst", "generated/torch.nn.HingeEmbeddingLoss.rst", "generated/torch.nn.HuberLoss.rst", "generated/torch.nn.Identity.rst", "generated/torch.nn.InstanceNorm1d.rst", "generated/torch.nn.InstanceNorm2d.rst", "generated/torch.nn.InstanceNorm3d.rst", "generated/torch.nn.KLDivLoss.rst", "generated/torch.nn.L1Loss.rst", "generated/torch.nn.LPPool1d.rst", "generated/torch.nn.LPPool2d.rst", "generated/torch.nn.LPPool3d.rst", "generated/torch.nn.LSTM.rst", "generated/torch.nn.LSTMCell.rst", "generated/torch.nn.LayerNorm.rst", "generated/torch.nn.LazyBatchNorm1d.rst", "generated/torch.nn.LazyBatchNorm2d.rst", "generated/torch.nn.LazyBatchNorm3d.rst", "generated/torch.nn.LazyConv1d.rst", "generated/torch.nn.LazyConv2d.rst", "generated/torch.nn.LazyConv3d.rst", "generated/torch.nn.LazyConvTranspose1d.rst", "generated/torch.nn.LazyConvTranspose2d.rst", "generated/torch.nn.LazyConvTranspose3d.rst", "generated/torch.nn.LazyInstanceNorm1d.rst", "generated/torch.nn.LazyInstanceNorm2d.rst", "generated/torch.nn.LazyInstanceNorm3d.rst", "generated/torch.nn.LazyLinear.rst", "generated/torch.nn.LeakyReLU.rst", "generated/torch.nn.Linear.rst", "generated/torch.nn.LocalResponseNorm.rst", "generated/torch.nn.LogSigmoid.rst", "generated/torch.nn.LogSoftmax.rst", "generated/torch.nn.MSELoss.rst", "generated/torch.nn.MarginRankingLoss.rst", "generated/torch.nn.MaxPool1d.rst", "generated/torch.nn.MaxPool2d.rst", "generated/torch.nn.MaxPool3d.rst", "generated/torch.nn.MaxUnpool1d.rst", "generated/torch.nn.MaxUnpool2d.rst", "generated/torch.nn.MaxUnpool3d.rst", "generated/torch.nn.Mish.rst", "generated/torch.nn.Module.rst", "generated/torch.nn.ModuleDict.rst", "generated/torch.nn.ModuleList.rst", "generated/torch.nn.MultiLabelMarginLoss.rst", "generated/torch.nn.MultiLabelSoftMarginLoss.rst", "generated/torch.nn.MultiMarginLoss.rst", "generated/torch.nn.MultiheadAttention.rst", "generated/torch.nn.NLLLoss.rst", "generated/torch.nn.PReLU.rst", "generated/torch.nn.PairwiseDistance.rst", "generated/torch.nn.ParameterDict.rst", "generated/torch.nn.ParameterList.rst", "generated/torch.nn.PixelShuffle.rst", "generated/torch.nn.PixelUnshuffle.rst", "generated/torch.nn.PoissonNLLLoss.rst", "generated/torch.nn.RMSNorm.rst", "generated/torch.nn.RNN.rst", "generated/torch.nn.RNNBase.rst", "generated/torch.nn.RNNCell.rst", "generated/torch.nn.RReLU.rst", "generated/torch.nn.ReLU.rst", "generated/torch.nn.ReLU6.rst", "generated/torch.nn.ReflectionPad1d.rst", "generated/torch.nn.ReflectionPad2d.rst", "generated/torch.nn.ReflectionPad3d.rst", "generated/torch.nn.ReplicationPad1d.rst", "generated/torch.nn.ReplicationPad2d.rst", "generated/torch.nn.ReplicationPad3d.rst", "generated/torch.nn.SELU.rst", "generated/torch.nn.Sequential.rst", "generated/torch.nn.SiLU.rst", "generated/torch.nn.Sigmoid.rst", "generated/torch.nn.SmoothL1Loss.rst", "generated/torch.nn.SoftMarginLoss.rst", "generated/torch.nn.Softmax.rst", "generated/torch.nn.Softmax2d.rst", "generated/torch.nn.Softmin.rst", "generated/torch.nn.Softplus.rst", "generated/torch.nn.Softshrink.rst", "generated/torch.nn.Softsign.rst", "generated/torch.nn.SyncBatchNorm.rst", "generated/torch.nn.Tanh.rst", "generated/torch.nn.Tanhshrink.rst", "generated/torch.nn.Threshold.rst", "generated/torch.nn.Transformer.rst", "generated/torch.nn.TransformerDecoder.rst", "generated/torch.nn.TransformerDecoderLayer.rst", "generated/torch.nn.TransformerEncoder.rst", "generated/torch.nn.TransformerEncoderLayer.rst", "generated/torch.nn.TripletMarginLoss.rst", "generated/torch.nn.TripletMarginWithDistanceLoss.rst", "generated/torch.nn.Unflatten.rst", "generated/torch.nn.Unfold.rst", "generated/torch.nn.Upsample.rst", "generated/torch.nn.UpsamplingBilinear2d.rst", "generated/torch.nn.UpsamplingNearest2d.rst", "generated/torch.nn.ZeroPad1d.rst", "generated/torch.nn.ZeroPad2d.rst", "generated/torch.nn.ZeroPad3d.rst", "generated/torch.nn.attention.SDPBackend.rst", "generated/torch.nn.attention.bias.CausalBias.rst", "generated/torch.nn.attention.bias.CausalVariant.rst", "generated/torch.nn.attention.bias.causal_lower_right.rst", "generated/torch.nn.attention.bias.causal_upper_left.rst", "generated/torch.nn.attention.sdpa_kernel.rst", "generated/torch.nn.functional.adaptive_avg_pool1d.rst", "generated/torch.nn.functional.adaptive_avg_pool2d.rst", "generated/torch.nn.functional.adaptive_avg_pool3d.rst", "generated/torch.nn.functional.adaptive_max_pool1d.rst", "generated/torch.nn.functional.adaptive_max_pool2d.rst", "generated/torch.nn.functional.adaptive_max_pool3d.rst", "generated/torch.nn.functional.affine_grid.rst", "generated/torch.nn.functional.alpha_dropout.rst", "generated/torch.nn.functional.avg_pool1d.rst", "generated/torch.nn.functional.avg_pool2d.rst", "generated/torch.nn.functional.avg_pool3d.rst", "generated/torch.nn.functional.batch_norm.rst", "generated/torch.nn.functional.bilinear.rst", "generated/torch.nn.functional.binary_cross_entropy.rst", "generated/torch.nn.functional.binary_cross_entropy_with_logits.rst", "generated/torch.nn.functional.celu.rst", "generated/torch.nn.functional.conv1d.rst", "generated/torch.nn.functional.conv2d.rst", "generated/torch.nn.functional.conv3d.rst", "generated/torch.nn.functional.conv_transpose1d.rst", "generated/torch.nn.functional.conv_transpose2d.rst", "generated/torch.nn.functional.conv_transpose3d.rst", "generated/torch.nn.functional.cosine_embedding_loss.rst", "generated/torch.nn.functional.cosine_similarity.rst", "generated/torch.nn.functional.cross_entropy.rst", "generated/torch.nn.functional.ctc_loss.rst", "generated/torch.nn.functional.dropout.rst", "generated/torch.nn.functional.dropout1d.rst", "generated/torch.nn.functional.dropout2d.rst", "generated/torch.nn.functional.dropout3d.rst", "generated/torch.nn.functional.elu.rst", "generated/torch.nn.functional.elu_.rst", "generated/torch.nn.functional.embedding.rst", "generated/torch.nn.functional.embedding_bag.rst", "generated/torch.nn.functional.feature_alpha_dropout.rst", "generated/torch.nn.functional.fold.rst", "generated/torch.nn.functional.fractional_max_pool2d.rst", "generated/torch.nn.functional.fractional_max_pool3d.rst", "generated/torch.nn.functional.gaussian_nll_loss.rst", "generated/torch.nn.functional.gelu.rst", "generated/torch.nn.functional.glu.rst", "generated/torch.nn.functional.grid_sample.rst", "generated/torch.nn.functional.group_norm.rst", "generated/torch.nn.functional.gumbel_softmax.rst", "generated/torch.nn.functional.hardshrink.rst", "generated/torch.nn.functional.hardsigmoid.rst", "generated/torch.nn.functional.hardswish.rst", "generated/torch.nn.functional.hardtanh.rst", "generated/torch.nn.functional.hardtanh_.rst", "generated/torch.nn.functional.hinge_embedding_loss.rst", "generated/torch.nn.functional.huber_loss.rst", "generated/torch.nn.functional.instance_norm.rst", "generated/torch.nn.functional.interpolate.rst", "generated/torch.nn.functional.kl_div.rst", "generated/torch.nn.functional.l1_loss.rst", "generated/torch.nn.functional.layer_norm.rst", "generated/torch.nn.functional.leaky_relu.rst", "generated/torch.nn.functional.leaky_relu_.rst", "generated/torch.nn.functional.linear.rst", "generated/torch.nn.functional.local_response_norm.rst", "generated/torch.nn.functional.log_softmax.rst", "generated/torch.nn.functional.logsigmoid.rst", "generated/torch.nn.functional.lp_pool1d.rst", "generated/torch.nn.functional.lp_pool2d.rst", "generated/torch.nn.functional.lp_pool3d.rst", "generated/torch.nn.functional.margin_ranking_loss.rst", "generated/torch.nn.functional.max_pool1d.rst", "generated/torch.nn.functional.max_pool2d.rst", "generated/torch.nn.functional.max_pool3d.rst", "generated/torch.nn.functional.max_unpool1d.rst", "generated/torch.nn.functional.max_unpool2d.rst", "generated/torch.nn.functional.max_unpool3d.rst", "generated/torch.nn.functional.mish.rst", "generated/torch.nn.functional.mse_loss.rst", "generated/torch.nn.functional.multi_margin_loss.rst", "generated/torch.nn.functional.multilabel_margin_loss.rst", "generated/torch.nn.functional.multilabel_soft_margin_loss.rst", "generated/torch.nn.functional.nll_loss.rst", "generated/torch.nn.functional.normalize.rst", "generated/torch.nn.functional.one_hot.rst", "generated/torch.nn.functional.pad.rst", "generated/torch.nn.functional.pairwise_distance.rst", "generated/torch.nn.functional.pdist.rst", "generated/torch.nn.functional.pixel_shuffle.rst", "generated/torch.nn.functional.pixel_unshuffle.rst", "generated/torch.nn.functional.poisson_nll_loss.rst", "generated/torch.nn.functional.prelu.rst", "generated/torch.nn.functional.relu.rst", "generated/torch.nn.functional.relu6.rst", "generated/torch.nn.functional.relu_.rst", "generated/torch.nn.functional.rms_norm.rst", "generated/torch.nn.functional.rrelu.rst", "generated/torch.nn.functional.rrelu_.rst", "generated/torch.nn.functional.scaled_dot_product_attention.rst", "generated/torch.nn.functional.selu.rst", "generated/torch.nn.functional.sigmoid.rst", "generated/torch.nn.functional.silu.rst", "generated/torch.nn.functional.smooth_l1_loss.rst", "generated/torch.nn.functional.soft_margin_loss.rst", "generated/torch.nn.functional.softmax.rst", "generated/torch.nn.functional.softmin.rst", "generated/torch.nn.functional.softplus.rst", "generated/torch.nn.functional.softshrink.rst", "generated/torch.nn.functional.softsign.rst", "generated/torch.nn.functional.tanh.rst", "generated/torch.nn.functional.tanhshrink.rst", "generated/torch.nn.functional.threshold.rst", "generated/torch.nn.functional.threshold_.rst", "generated/torch.nn.functional.torch.nn.parallel.data_parallel.rst", "generated/torch.nn.functional.triplet_margin_loss.rst", "generated/torch.nn.functional.triplet_margin_with_distance_loss.rst", "generated/torch.nn.functional.unfold.rst", "generated/torch.nn.functional.upsample.rst", "generated/torch.nn.functional.upsample_bilinear.rst", "generated/torch.nn.functional.upsample_nearest.rst", "generated/torch.nn.modules.lazy.LazyModuleMixin.rst", "generated/torch.nn.modules.module.register_module_backward_hook.rst", "generated/torch.nn.modules.module.register_module_buffer_registration_hook.rst", "generated/torch.nn.modules.module.register_module_forward_hook.rst", "generated/torch.nn.modules.module.register_module_forward_pre_hook.rst", "generated/torch.nn.modules.module.register_module_full_backward_hook.rst", "generated/torch.nn.modules.module.register_module_full_backward_pre_hook.rst", "generated/torch.nn.modules.module.register_module_module_registration_hook.rst", "generated/torch.nn.modules.module.register_module_parameter_registration_hook.rst", "generated/torch.nn.modules.normalization.RMSNorm.rst", "generated/torch.nn.parallel.DistributedDataParallel.rst", "generated/torch.nn.parameter.Buffer.rst", "generated/torch.nn.parameter.Parameter.rst", "generated/torch.nn.parameter.UninitializedBuffer.rst", "generated/torch.nn.parameter.UninitializedParameter.rst", "generated/torch.nn.utils.clip_grad_norm.rst", "generated/torch.nn.utils.clip_grad_norm_.rst", "generated/torch.nn.utils.clip_grad_value_.rst", "generated/torch.nn.utils.clip_grads_with_norm_.rst", "generated/torch.nn.utils.convert_conv2d_weight_memory_format.rst", "generated/torch.nn.utils.convert_conv3d_weight_memory_format.rst", "generated/torch.nn.utils.fuse_conv_bn_eval.rst", "generated/torch.nn.utils.fuse_conv_bn_weights.rst", "generated/torch.nn.utils.fuse_linear_bn_eval.rst", "generated/torch.nn.utils.fuse_linear_bn_weights.rst", "generated/torch.nn.utils.get_total_norm.rst", "generated/torch.nn.utils.parameters_to_vector.rst", "generated/torch.nn.utils.parametrizations.orthogonal.rst", "generated/torch.nn.utils.parametrizations.spectral_norm.rst", "generated/torch.nn.utils.parametrizations.weight_norm.rst", "generated/torch.nn.utils.parametrize.ParametrizationList.rst", "generated/torch.nn.utils.parametrize.cached.rst", "generated/torch.nn.utils.parametrize.is_parametrized.rst", "generated/torch.nn.utils.parametrize.register_parametrization.rst", "generated/torch.nn.utils.parametrize.remove_parametrizations.rst", "generated/torch.nn.utils.prune.BasePruningMethod.rst", "generated/torch.nn.utils.prune.CustomFromMask.rst", "generated/torch.nn.utils.prune.Identity.rst", "generated/torch.nn.utils.prune.L1Unstructured.rst", "generated/torch.nn.utils.prune.LnStructured.rst", "generated/torch.nn.utils.prune.PruningContainer.rst", "generated/torch.nn.utils.prune.RandomStructured.rst", "generated/torch.nn.utils.prune.RandomUnstructured.rst", "generated/torch.nn.utils.prune.custom_from_mask.rst", "generated/torch.nn.utils.prune.global_unstructured.rst", "generated/torch.nn.utils.prune.is_pruned.rst", "generated/torch.nn.utils.prune.l1_unstructured.rst", "generated/torch.nn.utils.prune.ln_structured.rst", "generated/torch.nn.utils.prune.random_structured.rst", "generated/torch.nn.utils.prune.random_unstructured.rst", "generated/torch.nn.utils.prune.remove.rst", "generated/torch.nn.utils.remove_spectral_norm.rst", "generated/torch.nn.utils.remove_weight_norm.rst", "generated/torch.nn.utils.rnn.PackedSequence.rst", "generated/torch.nn.utils.rnn.pack_padded_sequence.rst", "generated/torch.nn.utils.rnn.pack_sequence.rst", "generated/torch.nn.utils.rnn.pad_packed_sequence.rst", "generated/torch.nn.utils.rnn.pad_sequence.rst", "generated/torch.nn.utils.rnn.unpack_sequence.rst", "generated/torch.nn.utils.rnn.unpad_sequence.rst", "generated/torch.nn.utils.skip_init.rst", "generated/torch.nn.utils.spectral_norm.rst", "generated/torch.nn.utils.stateless.functional_call.rst", "generated/torch.nn.utils.vector_to_parameters.rst", "generated/torch.nn.utils.weight_norm.rst", "generated/torch.no_grad.rst", "generated/torch.nonzero.rst", "generated/torch.norm.rst", "generated/torch.normal.rst", "generated/torch.not_equal.rst", "generated/torch.numel.rst", "generated/torch.ones.rst", "generated/torch.ones_like.rst", "generated/torch.onnx.JitScalarType.rst", "generated/torch.onnx.verification.GraphInfo.rst", "generated/torch.onnx.verification.VerificationOptions.rst", "generated/torch.optim.ASGD.rst", "generated/torch.optim.Adadelta.rst", "generated/torch.optim.Adafactor.rst", "generated/torch.optim.Adagrad.rst", "generated/torch.optim.Adam.rst", "generated/torch.optim.AdamW.rst", "generated/torch.optim.Adamax.rst", "generated/torch.optim.LBFGS.rst", "generated/torch.optim.NAdam.rst", "generated/torch.optim.Optimizer.add_param_group.rst", "generated/torch.optim.Optimizer.load_state_dict.rst", "generated/torch.optim.Optimizer.register_load_state_dict_post_hook.rst", "generated/torch.optim.Optimizer.register_load_state_dict_pre_hook.rst", "generated/torch.optim.Optimizer.register_state_dict_post_hook.rst", "generated/torch.optim.Optimizer.register_state_dict_pre_hook.rst", "generated/torch.optim.Optimizer.register_step_post_hook.rst", "generated/torch.optim.Optimizer.register_step_pre_hook.rst", "generated/torch.optim.Optimizer.state_dict.rst", "generated/torch.optim.Optimizer.step.rst", "generated/torch.optim.Optimizer.zero_grad.rst", "generated/torch.optim.RAdam.rst", "generated/torch.optim.RMSprop.rst", "generated/torch.optim.Rprop.rst", "generated/torch.optim.SGD.rst", "generated/torch.optim.SparseAdam.rst", "generated/torch.optim.lr_scheduler.ChainedScheduler.rst", "generated/torch.optim.lr_scheduler.ConstantLR.rst", "generated/torch.optim.lr_scheduler.CosineAnnealingLR.rst", "generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.rst", "generated/torch.optim.lr_scheduler.CyclicLR.rst", "generated/torch.optim.lr_scheduler.ExponentialLR.rst", "generated/torch.optim.lr_scheduler.LRScheduler.rst", "generated/torch.optim.lr_scheduler.LambdaLR.rst", "generated/torch.optim.lr_scheduler.LinearLR.rst", "generated/torch.optim.lr_scheduler.MultiStepLR.rst", "generated/torch.optim.lr_scheduler.MultiplicativeLR.rst", "generated/torch.optim.lr_scheduler.OneCycleLR.rst", "generated/torch.optim.lr_scheduler.PolynomialLR.rst", "generated/torch.optim.lr_scheduler.ReduceLROnPlateau.rst", "generated/torch.optim.lr_scheduler.SequentialLR.rst", "generated/torch.optim.lr_scheduler.StepLR.rst", "generated/torch.optim.swa_utils.AveragedModel.rst", "generated/torch.optim.swa_utils.SWALR.rst", "generated/torch.orgqr.rst", "generated/torch.ormqr.rst", "generated/torch.outer.rst", "generated/torch.pca_lowrank.rst", "generated/torch.permute.rst", "generated/torch.pinverse.rst", "generated/torch.poisson.rst", "generated/torch.polar.rst", "generated/torch.polygamma.rst", "generated/torch.positive.rst", "generated/torch.pow.rst", "generated/torch.prod.rst", "generated/torch.promote_types.rst", "generated/torch.qr.rst", "generated/torch.quantile.rst", "generated/torch.quantize_per_channel.rst", "generated/torch.quantize_per_tensor.rst", "generated/torch.quantized_batch_norm.rst", "generated/torch.quantized_max_pool1d.rst", "generated/torch.quantized_max_pool2d.rst", "generated/torch.quasirandom.SobolEngine.rst", "generated/torch.rad2deg.rst", "generated/torch.rand.rst", "generated/torch.rand_like.rst", "generated/torch.randint.rst", "generated/torch.randint_like.rst", "generated/torch.randn.rst", "generated/torch.randn_like.rst", "generated/torch.randperm.rst", "generated/torch.range.rst", "generated/torch.ravel.rst", "generated/torch.real.rst", "generated/torch.reciprocal.rst", "generated/torch.remainder.rst", "generated/torch.renorm.rst", "generated/torch.repeat_interleave.rst", "generated/torch.reshape.rst", "generated/torch.resolve_conj.rst", "generated/torch.resolve_neg.rst", "generated/torch.result_type.rst", "generated/torch.roll.rst", "generated/torch.rot90.rst", "generated/torch.round.rst", "generated/torch.row_stack.rst", "generated/torch.rsqrt.rst", "generated/torch.save.rst", "generated/torch.scatter.rst", "generated/torch.scatter_add.rst", "generated/torch.scatter_reduce.rst", "generated/torch.searchsorted.rst", "generated/torch.seed.rst", "generated/torch.select.rst", "generated/torch.select_scatter.rst", "generated/torch.set_default_device.rst", "generated/torch.set_default_dtype.rst", "generated/torch.set_default_tensor_type.rst", "generated/torch.set_deterministic_debug_mode.rst", "generated/torch.set_float32_matmul_precision.rst", "generated/torch.set_flush_denormal.rst", "generated/torch.set_num_interop_threads.rst", "generated/torch.set_num_threads.rst", "generated/torch.set_printoptions.rst", "generated/torch.set_rng_state.rst", "generated/torch.set_warn_always.rst", "generated/torch.sgn.rst", "generated/torch.sigmoid.rst", "generated/torch.sign.rst", "generated/torch.signal.windows.bartlett.rst", "generated/torch.signal.windows.blackman.rst", "generated/torch.signal.windows.cosine.rst", "generated/torch.signal.windows.exponential.rst", "generated/torch.signal.windows.gaussian.rst", "generated/torch.signal.windows.general_cosine.rst", "generated/torch.signal.windows.general_hamming.rst", "generated/torch.signal.windows.hamming.rst", "generated/torch.signal.windows.hann.rst", "generated/torch.signal.windows.kaiser.rst", "generated/torch.signal.windows.nuttall.rst", "generated/torch.signbit.rst", "generated/torch.sin.rst", "generated/torch.sinc.rst", "generated/torch.sinh.rst", "generated/torch.slice_scatter.rst", "generated/torch.slogdet.rst", "generated/torch.smm.rst", "generated/torch.softmax.rst", "generated/torch.sort.rst", "generated/torch.sparse.addmm.rst", "generated/torch.sparse.as_sparse_gradcheck.rst", "generated/torch.sparse.check_sparse_tensor_invariants.rst", "generated/torch.sparse.log_softmax.rst", "generated/torch.sparse.mm.rst", "generated/torch.sparse.sampled_addmm.rst", "generated/torch.sparse.softmax.rst", "generated/torch.sparse.spdiags.rst", "generated/torch.sparse.spsolve.rst", "generated/torch.sparse.sum.rst", "generated/torch.sparse_bsc_tensor.rst", "generated/torch.sparse_bsr_tensor.rst", "generated/torch.sparse_compressed_tensor.rst", "generated/torch.sparse_coo_tensor.rst", "generated/torch.sparse_csc_tensor.rst", "generated/torch.sparse_csr_tensor.rst", "generated/torch.split.rst", "generated/torch.sqrt.rst", "generated/torch.square.rst", "generated/torch.squeeze.rst", "generated/torch.sspaddmm.rst", "generated/torch.stack.rst", "generated/torch.std.rst", "generated/torch.std_mean.rst", "generated/torch.stft.rst", "generated/torch.sub.rst", "generated/torch.subtract.rst", "generated/torch.sum.rst", "generated/torch.svd.rst", "generated/torch.svd_lowrank.rst", "generated/torch.swapaxes.rst", "generated/torch.swapdims.rst", "generated/torch.sym_float.rst", "generated/torch.sym_fresh_size.rst", "generated/torch.sym_int.rst", "generated/torch.sym_ite.rst", "generated/torch.sym_max.rst", "generated/torch.sym_min.rst", "generated/torch.sym_not.rst", "generated/torch.sym_sum.rst", "generated/torch.t.rst", "generated/torch.take.rst", "generated/torch.take_along_dim.rst", "generated/torch.tan.rst", "generated/torch.tanh.rst", "generated/torch.tensor.rst", "generated/torch.tensor_split.rst", "generated/torch.tensordot.rst", "generated/torch.tile.rst", "generated/torch.topk.rst", "generated/torch.trace.rst", "generated/torch.transpose.rst", "generated/torch.trapezoid.rst", "generated/torch.trapz.rst", "generated/torch.triangular_solve.rst", "generated/torch.tril.rst", "generated/torch.tril_indices.rst", "generated/torch.triu.rst", "generated/torch.triu_indices.rst", "generated/torch.true_divide.rst", "generated/torch.trunc.rst", "generated/torch.unbind.rst", "generated/torch.unflatten.rst", "generated/torch.unique.rst", "generated/torch.unique_consecutive.rst", "generated/torch.unravel_index.rst", "generated/torch.unsqueeze.rst", "generated/torch.use_deterministic_algorithms.rst", "generated/torch.utils.generate_methods_for_privateuse1_backend.rst", "generated/torch.utils.get_cpp_backtrace.rst", "generated/torch.utils.rename_privateuse1_backend.rst", "generated/torch.utils.set_module.rst", "generated/torch.utils.swap_tensors.rst", "generated/torch.vander.rst", "generated/torch.var.rst", "generated/torch.var_mean.rst", "generated/torch.vdot.rst", "generated/torch.view_as_complex.rst", "generated/torch.view_as_real.rst", "generated/torch.vmap.rst", "generated/torch.vsplit.rst", "generated/torch.vstack.rst", "generated/torch.where.rst", "generated/torch.xlogy.rst", "generated/torch.xpu.Event.rst", "generated/torch.xpu.Stream.rst", "generated/torch.xpu.StreamContext.rst", "generated/torch.xpu.current_device.rst", "generated/torch.xpu.current_stream.rst", "generated/torch.xpu.device.rst", "generated/torch.xpu.device_count.rst", "generated/torch.xpu.device_of.rst", "generated/torch.xpu.empty_cache.rst", "generated/torch.xpu.get_arch_list.rst", "generated/torch.xpu.get_device_capability.rst", "generated/torch.xpu.get_device_name.rst", "generated/torch.xpu.get_device_properties.rst", "generated/torch.xpu.get_gencode_flags.rst", "generated/torch.xpu.get_rng_state.rst", "generated/torch.xpu.get_rng_state_all.rst", "generated/torch.xpu.get_stream_from_external.rst", "generated/torch.xpu.init.rst", "generated/torch.xpu.initial_seed.rst", "generated/torch.xpu.is_available.rst", "generated/torch.xpu.is_initialized.rst", "generated/torch.xpu.manual_seed.rst", "generated/torch.xpu.manual_seed_all.rst", "generated/torch.xpu.max_memory_allocated.rst", "generated/torch.xpu.max_memory_reserved.rst", "generated/torch.xpu.mem_get_info.rst", "generated/torch.xpu.memory_allocated.rst", "generated/torch.xpu.memory_reserved.rst", "generated/torch.xpu.memory_stats.rst", "generated/torch.xpu.memory_stats_as_nested_dict.rst", "generated/torch.xpu.reset_accumulated_memory_stats.rst", "generated/torch.xpu.reset_peak_memory_stats.rst", "generated/torch.xpu.seed.rst", "generated/torch.xpu.seed_all.rst", "generated/torch.xpu.set_device.rst", "generated/torch.xpu.set_rng_state.rst", "generated/torch.xpu.set_rng_state_all.rst", "generated/torch.xpu.set_stream.rst", "generated/torch.xpu.synchronize.rst", "generated/torch.zeros.rst", "generated/torch.zeros_like.rst", "hub.rst", "index.md", "jit.rst", "jit_builtin_functions.rst", "jit_language_reference.rst", "jit_language_reference_v2.rst", "jit_python_reference.rst", "jit_unsupported.rst", "jit_utils.rst", "library.rst", "linalg.rst", "logging.rst", "masked.rst", "meta.rst", "miscellaneous_environment_variables.rst", "mobile_optimizer.rst", "model_zoo.rst", "module_tracker.rst", "monitor.rst", "mps.rst", "mps_environment_variables.rst", "mtia.rst", "mtia.memory.rst", "multiprocessing.rst", "name_inference.rst", "named_tensor.rst", "nested.rst", "nn.rst", "nn.attention.rst", "nn.attention.bias.rst", "nn.attention.experimental.rst", "nn.attention.flex_attention.rst", "nn.functional.rst", "nn.init.rst", "notes.md", "notes/amp_examples.rst", "notes/autograd.rst", "notes/broadcasting.rst", "notes/cpu_threading_torchscript_inference.rst", "notes/cuda.rst", "notes/custom_operators.rst", "notes/ddp.rst", "notes/extending.rst", "notes/extending.func.rst", "notes/faq.rst", "notes/fsdp.rst", "notes/get_start_xpu.rst", "notes/gradcheck.rst", "notes/hip.rst", "notes/large_scale_deployments.rst", "notes/libtorch_stable_abi.md", "notes/modules.rst", "notes/mps.rst", "notes/multiprocessing.rst", "notes/numerical_accuracy.rst", "notes/randomness.rst", "notes/serialization.rst", "notes/windows.rst", "onnx.rst", "onnx_dynamo.rst", "onnx_dynamo_memory_usage.rst", "onnx_dynamo_onnxruntime_backend.rst", "onnx_ops.rst", "onnx_torchscript.rst", "onnx_torchscript_supported_aten_ops.rst", "onnx_verification.rst", "optim.rst", "package.rst", "profiler.rst", "pytorch-api.md", "quantization.rst", "quantization-accuracy-debugging.rst", "quantization-backend-configuration.rst", "quantization-support.rst", "random.rst", "rpc.rst", "rpc/distributed_autograd.rst", "rpc/rref.rst", "signal.rst", "size.rst", "sparse.rst", "special.rst", "storage.rst", "tensor_attributes.rst", "tensor_view.rst", "tensorboard.rst", "tensors.rst", "testing.rst", "threading_environment_variables.rst", "torch.rst", "torch.ao.ns._numeric_suite.rst", "torch.ao.ns._numeric_suite_fx.rst", "torch.compiler.rst", "torch.compiler.config.rst", "torch.compiler_aot_inductor.rst", "torch.compiler_aot_inductor_minifier.rst", "torch.compiler_api.rst", "torch.compiler_best_practices_for_backends.rst", "torch.compiler_cudagraph_trees.rst", "torch.compiler_custom_backends.rst", "torch.compiler_dynamic_shapes.rst", "torch.compiler_dynamo_deepdive.rst", "torch.compiler_dynamo_overview.rst", "torch.compiler_fake_tensor.rst", "torch.compiler_faq.rst", "torch.compiler_fine_grain_apis.rst", "torch.compiler_get_started.rst", "torch.compiler_inductor_profiling.rst", "torch.compiler_ir.rst", "torch.compiler_nn_module.rst", "torch.compiler_performance_dashboard.rst", "torch.compiler_profiling_torch_compile.rst", "torch.compiler_transformations.rst", "torch.compiler_troubleshooting.rst", "torch.compiler_troubleshooting_old.rst", "torch.overrides.rst", "torch_cuda_memory.rst", "torch_environment_variables.rst", "torch_nccl_environment_variables.rst", "type_info.rst", "utils.rst", "xpu.rst"], "titles": ["torch.accelerator", "Automatic Mixed Precision package - torch.amp", "Automatic differentiation package - torch.autograd", "torch.backends", "Benchmark Utils - torch.utils.benchmark", "torch.utils.bottleneck", "torch.utils.checkpoint", "PyTorch Governance | Build + CI", "PyTorch Contribution Guide", "PyTorch Design Philosophy", "PyTorch Governance | Mechanics", "Community", "PyTorch Governance | Maintainers", "Complex Numbers", "Control Flow - Cond", "torch.__config__", "torch.utils.cpp_extension", "C++", "torch.cpu", "torch.cuda", "CUDA Stream Sanitizer", "TunableOp", "CUDA Environment Variables", "&lt;no title&gt;", "&lt;no title&gt;", "torch.utils.data", "DDP Communication Hooks", "Debugging Environment Variables", "torch::deploy has been moved to pytorch/multipy", "torch.utils.deterministic", "Distributed communication package - torch.distributed", "Generic Join Context Manager", "Distributed Checkpoint - torch.distributed.checkpoint", "Torch Distributed Elastic", "torch.distributed.fsdp.fully_shard", "Distributed Optimizers", "Pipeline Parallelism", "torch.distributed.tensor", "Tensor Parallelism - torch.distributed.tensor.parallel", "Probability distributions - torch.distributions", "torch.utils.dlpack", "Elastic Agent", "Control Plane", "Customization", "Error Propagation", "Events", "Examples", "TorchElastic Kubernetes", "Metrics", "Multiprocessing", "Quickstart", "Rendezvous", "torchrun (Elastic Launch)", "Subprocess Handling", "Expiration Timers", "Train script", "torch.export", "torch.export IR Specification", "torch.export Programming Model", "torch.fft", "FullyShardedDataParallel", "torch.func", "torch.func API Reference", "Patching Batch Norm", "Migrating from functorch to torch.func", "UX Limitations", "torch.func Whirlwind Tour", "torch.__future__", "torch.futures", "torch.fx", "torch.fx.experimental", "ExportDB", "python.assert", "python.builtin", "python.closure", "python.context-manager", "python.control-flow", "python.data-structure", "python.object-model", "torch.cond", "torch.dynamic-shape", "torch.dynamic-value", "torch.escape-hatch", "torch.map", "torch.mutation", "torch.operator", "Event", "Generator", "Stream", "torch.Tensor.abs", "torch.Tensor.abs_", "torch.Tensor.absolute", "torch.Tensor.absolute_", "torch.Tensor.acos", "torch.Tensor.acos_", "torch.Tensor.acosh", "torch.Tensor.acosh_", "torch.Tensor.add", "torch.Tensor.add_", "torch.Tensor.addbmm", "torch.Tensor.addbmm_", "torch.Tensor.addcdiv", "torch.Tensor.addcdiv_", "torch.Tensor.addcmul", "torch.Tensor.addcmul_", "torch.Tensor.addmm", "torch.Tensor.addmm_", "torch.Tensor.addmv", "torch.Tensor.addmv_", "torch.Tensor.addr", "torch.Tensor.addr_", "torch.Tensor.adjoint", "torch.Tensor.all", "torch.Tensor.allclose", "torch.Tensor.amax", "torch.Tensor.amin", "torch.Tensor.aminmax", "torch.Tensor.angle", "torch.Tensor.any", "torch.Tensor.apply_", "torch.Tensor.arccos", "torch.Tensor.arccos_", "torch.Tensor.arccosh", "torch.Tensor.arccosh_", "torch.Tensor.arcsin", "torch.Tensor.arcsin_", "torch.Tensor.arcsinh", "torch.Tensor.arcsinh_", "torch.Tensor.arctan", "torch.Tensor.arctan2", "torch.Tensor.arctan2_", "torch.Tensor.arctan_", "torch.Tensor.arctanh", "torch.Tensor.arctanh_", "torch.Tensor.argmax", "torch.Tensor.argmin", "torch.Tensor.argsort", "torch.Tensor.argwhere", "torch.Tensor.as_strided", "torch.Tensor.as_subclass", "torch.Tensor.asin", "torch.Tensor.asin_", "torch.Tensor.asinh", "torch.Tensor.asinh_", "torch.Tensor.atan", "torch.Tensor.atan2", "torch.Tensor.atan2_", "torch.Tensor.atan_", "torch.Tensor.atanh", "torch.Tensor.atanh_", "torch.Tensor.backward", "torch.Tensor.baddbmm", "torch.Tensor.baddbmm_", "torch.Tensor.bernoulli", "torch.Tensor.bernoulli_", "torch.Tensor.bfloat16", "torch.Tensor.bincount", "torch.Tensor.bitwise_and", "torch.Tensor.bitwise_and_", "torch.Tensor.bitwise_left_shift", "torch.Tensor.bitwise_left_shift_", "torch.Tensor.bitwise_not", "torch.Tensor.bitwise_not_", "torch.Tensor.bitwise_or", "torch.Tensor.bitwise_or_", "torch.Tensor.bitwise_right_shift", "torch.Tensor.bitwise_right_shift_", "torch.Tensor.bitwise_xor", "torch.Tensor.bitwise_xor_", "torch.Tensor.bmm", "torch.Tensor.bool", "torch.Tensor.broadcast_to", "torch.Tensor.byte", "torch.Tensor.cauchy_", "torch.Tensor.ccol_indices", "torch.Tensor.cdouble", "torch.Tensor.ceil", "torch.Tensor.ceil_", "torch.Tensor.cfloat", "torch.Tensor.chalf", "torch.Tensor.char", "torch.Tensor.cholesky", "torch.Tensor.cholesky_inverse", "torch.Tensor.cholesky_solve", "torch.Tensor.chunk", "torch.Tensor.clamp", "torch.Tensor.clamp_", "torch.Tensor.clip", "torch.Tensor.clip_", "torch.Tensor.clone", "torch.Tensor.coalesce", "torch.Tensor.col_indices", "torch.Tensor.conj", "torch.Tensor.conj_physical", "torch.Tensor.conj_physical_", "torch.Tensor.contiguous", "torch.Tensor.copy_", "torch.Tensor.copysign", "torch.Tensor.copysign_", "torch.Tensor.corrcoef", "torch.Tensor.cos", "torch.Tensor.cos_", "torch.Tensor.cosh", "torch.Tensor.cosh_", "torch.Tensor.count_nonzero", "torch.Tensor.cov", "torch.Tensor.cpu", "torch.Tensor.cross", "torch.Tensor.crow_indices", "torch.Tensor.cuda", "torch.Tensor.cummax", "torch.Tensor.cummin", "torch.Tensor.cumprod", "torch.Tensor.cumprod_", "torch.Tensor.cumsum", "torch.Tensor.cumsum_", "torch.Tensor.data_ptr", "torch.Tensor.deg2rad", "torch.Tensor.dense_dim", "torch.Tensor.dequantize", "torch.Tensor.det", "torch.Tensor.detach", "torch.Tensor.detach_", "torch.Tensor.device", "torch.Tensor.diag", "torch.Tensor.diag_embed", "torch.Tensor.diagflat", "torch.Tensor.diagonal", "torch.Tensor.diagonal_scatter", "torch.Tensor.diff", "torch.Tensor.digamma", "torch.Tensor.digamma_", "torch.Tensor.dim", "torch.Tensor.dim_order", "torch.Tensor.dist", "torch.Tensor.div", "torch.Tensor.div_", "torch.Tensor.divide", "torch.Tensor.divide_", "torch.Tensor.dot", "torch.Tensor.double", "torch.Tensor.dsplit", "torch.Tensor.element_size", "torch.Tensor.eq", "torch.Tensor.eq_", "torch.Tensor.equal", "torch.Tensor.erf", "torch.Tensor.erf_", "torch.Tensor.erfc", "torch.Tensor.erfc_", "torch.Tensor.erfinv", "torch.Tensor.erfinv_", "torch.Tensor.exp", "torch.Tensor.exp_", "torch.Tensor.expand", "torch.Tensor.expand_as", "torch.Tensor.expm1", "torch.Tensor.expm1_", "torch.Tensor.exponential_", "torch.Tensor.fill_", "torch.Tensor.fill_diagonal_", "torch.Tensor.fix", "torch.Tensor.fix_", "torch.Tensor.flatten", "torch.Tensor.flip", "torch.Tensor.fliplr", "torch.Tensor.flipud", "torch.Tensor.float", "torch.Tensor.float_power", "torch.Tensor.float_power_", "torch.Tensor.floor", "torch.Tensor.floor_", "torch.Tensor.floor_divide", "torch.Tensor.floor_divide_", "torch.Tensor.fmax", "torch.Tensor.fmin", "torch.Tensor.fmod", "torch.Tensor.fmod_", "torch.Tensor.frac", "torch.Tensor.frac_", "torch.Tensor.frexp", "torch.Tensor.gather", "torch.Tensor.gcd", "torch.Tensor.gcd_", "torch.Tensor.ge", "torch.Tensor.ge_", "torch.Tensor.geometric_", "torch.Tensor.geqrf", "torch.Tensor.ger", "torch.Tensor.get_device", "torch.Tensor.grad", "torch.Tensor.greater", "torch.Tensor.greater_", "torch.Tensor.greater_equal", "torch.Tensor.greater_equal_", "torch.Tensor.gt", "torch.Tensor.gt_", "torch.Tensor.half", "torch.Tensor.hardshrink", "torch.Tensor.heaviside", "torch.Tensor.histc", "torch.Tensor.histogram", "torch.Tensor.hsplit", "torch.Tensor.hypot", "torch.Tensor.hypot_", "torch.Tensor.i0", "torch.Tensor.i0_", "torch.Tensor.igamma", "torch.Tensor.igamma_", "torch.Tensor.igammac", "torch.Tensor.igammac_", "torch.Tensor.imag", "torch.Tensor.index_add", "torch.Tensor.index_add_", "torch.Tensor.index_copy", "torch.Tensor.index_copy_", "torch.Tensor.index_fill", "torch.Tensor.index_fill_", "torch.Tensor.index_put", "torch.Tensor.index_put_", "torch.Tensor.index_reduce", "torch.Tensor.index_reduce_", "torch.Tensor.index_select", "torch.Tensor.indices", "torch.Tensor.inner", "torch.Tensor.int", "torch.Tensor.int_repr", "torch.Tensor.inverse", "torch.Tensor.is_coalesced", "torch.Tensor.is_complex", "torch.Tensor.is_conj", "torch.Tensor.is_contiguous", "torch.Tensor.is_cuda", "torch.Tensor.is_floating_point", "torch.Tensor.is_inference", "torch.Tensor.is_leaf", "torch.Tensor.is_meta", "torch.Tensor.is_pinned", "torch.Tensor.is_quantized", "torch.Tensor.is_set_to", "torch.Tensor.is_shared", "torch.Tensor.is_signed", "torch.Tensor.is_sparse", "torch.Tensor.is_sparse_csr", "torch.Tensor.isclose", "torch.Tensor.isfinite", "torch.Tensor.isinf", "torch.Tensor.isnan", "torch.Tensor.isneginf", "torch.Tensor.isposinf", "torch.Tensor.isreal", "torch.Tensor.istft", "torch.Tensor.item", "torch.Tensor.itemsize", "torch.Tensor.kthvalue", "torch.Tensor.lcm", "torch.Tensor.lcm_", "torch.Tensor.ldexp", "torch.Tensor.ldexp_", "torch.Tensor.le", "torch.Tensor.le_", "torch.Tensor.lerp", "torch.Tensor.lerp_", "torch.Tensor.less", "torch.Tensor.less_", "torch.Tensor.less_equal", "torch.Tensor.less_equal_", "torch.Tensor.lgamma", "torch.Tensor.lgamma_", "torch.Tensor.log", "torch.Tensor.log10", "torch.Tensor.log10_", "torch.Tensor.log1p", "torch.Tensor.log1p_", "torch.Tensor.log2", "torch.Tensor.log2_", "torch.Tensor.log_", "torch.Tensor.log_normal_", "torch.Tensor.logaddexp", "torch.Tensor.logaddexp2", "torch.Tensor.logcumsumexp", "torch.Tensor.logdet", "torch.Tensor.logical_and", "torch.Tensor.logical_and_", "torch.Tensor.logical_not", "torch.Tensor.logical_not_", "torch.Tensor.logical_or", "torch.Tensor.logical_or_", "torch.Tensor.logical_xor", "torch.Tensor.logical_xor_", "torch.Tensor.logit", "torch.Tensor.logit_", "torch.Tensor.logsumexp", "torch.Tensor.long", "torch.Tensor.lt", "torch.Tensor.lt_", "torch.Tensor.lu", "torch.Tensor.lu_solve", "torch.Tensor.map_", "torch.Tensor.masked_fill", "torch.Tensor.masked_fill_", "torch.Tensor.masked_scatter", "torch.Tensor.masked_scatter_", "torch.Tensor.masked_select", "torch.Tensor.matmul", "torch.Tensor.matrix_exp", "torch.Tensor.matrix_power", "torch.Tensor.max", "torch.Tensor.maximum", "torch.Tensor.mean", "torch.Tensor.median", "torch.Tensor.min", "torch.Tensor.minimum", "torch.Tensor.mm", "torch.Tensor.mode", "torch.Tensor.module_load", "torch.Tensor.moveaxis", "torch.Tensor.movedim", "torch.Tensor.msort", "torch.Tensor.mul", "torch.Tensor.mul_", "torch.Tensor.multinomial", "torch.Tensor.multiply", "torch.Tensor.multiply_", "torch.Tensor.mv", "torch.Tensor.mvlgamma", "torch.Tensor.mvlgamma_", "torch.Tensor.nan_to_num", "torch.Tensor.nan_to_num_", "torch.Tensor.nanmean", "torch.Tensor.nanmedian", "torch.Tensor.nanquantile", "torch.Tensor.nansum", "torch.Tensor.narrow", "torch.Tensor.narrow_copy", "torch.Tensor.nbytes", "torch.Tensor.ndim", "torch.Tensor.ndimension", "torch.Tensor.ne", "torch.Tensor.ne_", "torch.Tensor.neg", "torch.Tensor.neg_", "torch.Tensor.negative", "torch.Tensor.negative_", "torch.Tensor.nelement", "torch.Tensor.new_empty", "torch.Tensor.new_full", "torch.Tensor.new_ones", "torch.Tensor.new_tensor", "torch.Tensor.new_zeros", "torch.Tensor.nextafter", "torch.Tensor.nextafter_", "torch.Tensor.nonzero", "torch.Tensor.norm", "torch.Tensor.normal_", "torch.Tensor.not_equal", "torch.Tensor.not_equal_", "torch.Tensor.numel", "torch.Tensor.numpy", "torch.Tensor.orgqr", "torch.Tensor.ormqr", "torch.Tensor.outer", "torch.Tensor.permute", "torch.Tensor.pin_memory", "torch.Tensor.pinverse", "torch.Tensor.polygamma", "torch.Tensor.polygamma_", "torch.Tensor.positive", "torch.Tensor.pow", "torch.Tensor.pow_", "torch.Tensor.prod", "torch.Tensor.put_", "torch.Tensor.q_per_channel_axis", "torch.Tensor.q_per_channel_scales", "torch.Tensor.q_per_channel_zero_points", "torch.Tensor.q_scale", "torch.Tensor.q_zero_point", "torch.Tensor.qr", "torch.Tensor.qscheme", "torch.Tensor.quantile", "torch.Tensor.rad2deg", "torch.Tensor.random_", "torch.Tensor.ravel", "torch.Tensor.real", "torch.Tensor.reciprocal", "torch.Tensor.reciprocal_", "torch.Tensor.record_stream", "torch.Tensor.register_hook", "torch.Tensor.register_post_accumulate_grad_hook", "torch.Tensor.remainder", "torch.Tensor.remainder_", "torch.Tensor.renorm", "torch.Tensor.renorm_", "torch.Tensor.repeat", "torch.Tensor.repeat_interleave", "torch.Tensor.requires_grad", "torch.Tensor.requires_grad_", "torch.Tensor.reshape", "torch.Tensor.reshape_as", "torch.Tensor.resize_", "torch.Tensor.resize_as_", "torch.Tensor.resolve_conj", "torch.Tensor.resolve_neg", "torch.Tensor.retain_grad", "torch.Tensor.retains_grad", "torch.Tensor.roll", "torch.Tensor.rot90", "torch.Tensor.round", "torch.Tensor.round_", "torch.Tensor.row_indices", "torch.Tensor.rsqrt", "torch.Tensor.rsqrt_", "torch.Tensor.scatter", "torch.Tensor.scatter_", "torch.Tensor.scatter_add", "torch.Tensor.scatter_add_", "torch.Tensor.scatter_reduce", "torch.Tensor.scatter_reduce_", "torch.Tensor.select", "torch.Tensor.select_scatter", "torch.Tensor.set_", "torch.Tensor.sgn", "torch.Tensor.sgn_", "torch.Tensor.shape", "torch.Tensor.share_memory_", "torch.Tensor.short", "torch.Tensor.sigmoid", "torch.Tensor.sigmoid_", "torch.Tensor.sign", "torch.Tensor.sign_", "torch.Tensor.signbit", "torch.Tensor.sin", "torch.Tensor.sin_", "torch.Tensor.sinc", "torch.Tensor.sinc_", "torch.Tensor.sinh", "torch.Tensor.sinh_", "torch.Tensor.size", "torch.Tensor.slice_scatter", "torch.Tensor.slogdet", "torch.Tensor.smm", "torch.Tensor.softmax", "torch.Tensor.sort", "torch.Tensor.sparse_dim", "torch.Tensor.sparse_mask", "torch.Tensor.sparse_resize_", "torch.Tensor.sparse_resize_and_clear_", "torch.Tensor.split", "torch.Tensor.sqrt", "torch.Tensor.sqrt_", "torch.Tensor.square", "torch.Tensor.square_", "torch.Tensor.squeeze", "torch.Tensor.squeeze_", "torch.Tensor.sspaddmm", "torch.Tensor.std", "torch.Tensor.stft", "torch.Tensor.storage", "torch.Tensor.storage_offset", "torch.Tensor.storage_type", "torch.Tensor.stride", "torch.Tensor.sub", "torch.Tensor.sub_", "torch.Tensor.subtract", "torch.Tensor.subtract_", "torch.Tensor.sum", "torch.Tensor.sum_to_size", "torch.Tensor.svd", "torch.Tensor.swapaxes", "torch.Tensor.swapdims", "torch.Tensor.t", "torch.Tensor.t_", "torch.Tensor.take", "torch.Tensor.take_along_dim", "torch.Tensor.tan", "torch.Tensor.tan_", "torch.Tensor.tanh", "torch.Tensor.tanh_", "torch.Tensor.tensor_split", "torch.Tensor.tile", "torch.Tensor.to", "torch.Tensor.to_dense", "torch.Tensor.to_mkldnn", "torch.Tensor.to_sparse", "torch.Tensor.to_sparse_bsc", "torch.Tensor.to_sparse_bsr", "torch.Tensor.to_sparse_coo", "torch.Tensor.to_sparse_csc", "torch.Tensor.to_sparse_csr", "torch.Tensor.tolist", "torch.Tensor.topk", "torch.Tensor.trace", "torch.Tensor.transpose", "torch.Tensor.transpose_", "torch.Tensor.triangular_solve", "torch.Tensor.tril", "torch.Tensor.tril_", "torch.Tensor.triu", "torch.Tensor.triu_", "torch.Tensor.true_divide", "torch.Tensor.true_divide_", "torch.Tensor.trunc", "torch.Tensor.trunc_", "torch.Tensor.type", "torch.Tensor.type_as", "torch.Tensor.unbind", "torch.Tensor.unflatten", "torch.Tensor.unfold", "torch.Tensor.uniform_", "torch.Tensor.unique", "torch.Tensor.unique_consecutive", "torch.Tensor.unsqueeze", "torch.Tensor.unsqueeze_", "torch.Tensor.untyped_storage", "torch.Tensor.values", "torch.Tensor.var", "torch.Tensor.vdot", "torch.Tensor.view", "torch.Tensor.view_as", "torch.Tensor.vsplit", "torch.Tensor.where", "torch.Tensor.xlogy", "torch.Tensor.xlogy_", "torch.Tensor.xpu", "torch.Tensor.zero_", "torch._assert", "torch._foreach_abs", "torch._foreach_abs_", "torch._foreach_acos", "torch._foreach_acos_", "torch._foreach_asin", "torch._foreach_asin_", "torch._foreach_atan", "torch._foreach_atan_", "torch._foreach_ceil", "torch._foreach_ceil_", "torch._foreach_cos", "torch._foreach_cos_", "torch._foreach_cosh", "torch._foreach_cosh_", "torch._foreach_erf", "torch._foreach_erf_", "torch._foreach_erfc", "torch._foreach_erfc_", "torch._foreach_exp", "torch._foreach_exp_", "torch._foreach_expm1", "torch._foreach_expm1_", "torch._foreach_floor", "torch._foreach_floor_", "torch._foreach_frac", "torch._foreach_frac_", "torch._foreach_lgamma", "torch._foreach_lgamma_", "torch._foreach_log", "torch._foreach_log10", "torch._foreach_log10_", "torch._foreach_log1p", "torch._foreach_log1p_", "torch._foreach_log2", "torch._foreach_log2_", "torch._foreach_log_", "torch._foreach_neg", "torch._foreach_neg_", "torch._foreach_reciprocal", "torch._foreach_reciprocal_", "torch._foreach_round", "torch._foreach_round_", "torch._foreach_sigmoid", "torch._foreach_sigmoid_", "torch._foreach_sin", "torch._foreach_sin_", "torch._foreach_sinh", "torch._foreach_sinh_", "torch._foreach_sqrt", "torch._foreach_sqrt_", "torch._foreach_tan", "torch._foreach_tan_", "torch._foreach_trunc", "torch._foreach_trunc_", "torch._foreach_zero_", "torch._logging.set_logs", "torch.abs", "torch.absolute", "torch.accelerator.current_accelerator", "torch.accelerator.current_device_idx", "torch.accelerator.current_device_index", "torch.accelerator.current_stream", "torch.accelerator.device_count", "torch.accelerator.is_available", "torch.accelerator.set_device_idx", "torch.accelerator.set_device_index", "torch.accelerator.set_stream", "torch.accelerator.synchronize", "torch.acos", "torch.acosh", "torch.add", "torch.addbmm", "torch.addcdiv", "torch.addcmul", "torch.addmm", "torch.addmv", "torch.addr", "torch.adjoint", "torch.all", "torch.allclose", "torch.amax", "torch.amin", "torch.aminmax", "torch.angle", "torch.any", "BNReLU2d", "BNReLU3d", "ConvBn1d", "ConvBn2d", "ConvBn3d", "ConvBnReLU1d", "ConvBnReLU2d", "ConvBnReLU3d", "ConvReLU1d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "ConvBn1d", "ConvBn2d", "ConvBn3d", "ConvBnReLU1d", "ConvBnReLU2d", "ConvBnReLU3d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "freeze_bn_stats", "update_bn_stats", "BNReLU2d", "BNReLU3d", "ConvReLU1d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "LinearReLU", "Conv2d", "Conv3d", "Linear", "Linear", "LSTM", "MultiheadAttention", "BatchNorm2d", "BatchNorm3d", "Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d", "ELU", "Embedding", "EmbeddingBag", "FXFloatFunctional", "FloatFunctional", "GroupNorm", "Hardswish", "InstanceNorm1d", "InstanceNorm2d", "InstanceNorm3d", "LayerNorm", "LeakyReLU", "Linear", "QFunctional", "ReLU6", "Sigmoid", "GRU", "GRUCell", "LSTM", "LSTMCell", "Linear", "RNNCell", "adaptive_avg_pool2d", "adaptive_avg_pool3d", "avg_pool2d", "avg_pool3d", "celu", "clamp", "conv1d", "conv2d", "conv3d", "elu", "hardsigmoid", "hardswish", "hardtanh", "interpolate", "leaky_relu", "linear", "max_pool1d", "max_pool2d", "threshold", "upsample", "upsample_bilinear", "upsample_nearest", "CUSTOM_KEY", "DeQuantStub", "NUMERIC_DEBUG_HANDLE_KEY", "QuantStub", "QuantWrapper", "add_quant_dequant", "BackendConfig", "BackendPatternConfig", "DTypeConfig", "DTypeWithConstraints", "ObservationType", "compare_results", "convert", "default_eval_fn", "extract_results_from_loggers", "FakeQuantize", "FakeQuantizeBase", "FixedQParamsFakeQuantize", "FusedMovingAvgObsFakeQuantize", "default_fake_quant", "default_fused_act_fake_quant", "default_fused_per_channel_wt_fake_quant", "default_fused_wt_fake_quant", "default_histogram_fake_quant", "default_per_channel_weight_fake_quant", "default_weight_fake_quant", "disable_fake_quant", "disable_observer", "enable_fake_quant", "enable_observer", "fuse_modules", "ConvertCustomConfig", "FuseCustomConfig", "PrepareCustomConfig", "StandaloneModuleConfigEntry", "generate_numeric_debug_handle", "AffineQuantizedObserverBase", "Granularity", "HistogramObserver", "MappingType", "MinMaxObserver", "MovingAverageMinMaxObserver", "MovingAveragePerChannelMinMaxObserver", "NoopObserver", "ObserverBase", "PerAxis", "PerBlock", "PerChannelMinMaxObserver", "PerGroup", "PerRow", "PerTensor", "PerToken", "PlaceholderObserver", "RecordingObserver", "TorchAODType", "ZeroPointDomain", "default_debug_observer", "default_dynamic_quant_observer", "default_float_qparams_observer", "default_histogram_observer", "default_observer", "default_per_channel_weight_observer", "default_placeholder_observer", "default_weight_observer", "get_block_size", "get_observer_state_dict", "load_observer_state_dict", "prepare", "prepare_for_propagation_comparison", "prepare_qat", "propagate_qconfig", "model_is_exported", "QConfig", "default_activation_only_qconfig", "default_debug_qconfig", "default_dynamic_qconfig", "default_per_channel_qconfig", "default_qat_qconfig", "default_qat_qconfig_v2", "default_qconfig", "default_weight_only_qconfig", "float16_dynamic_qconfig", "float16_static_qconfig", "float_qparams_weight_only_qconfig", "per_channel_dynamic_qconfig", "QConfigMapping", "get_default_qat_qconfig_mapping", "get_default_qconfig_mapping", "quantize", "quantize_dynamic", "convert_fx", "fuse_fx", "prepare_fx", "prepare_qat_fx", "quantize_qat", "swap_module", "torch.arange", "torch.arccos", "torch.arccosh", "torch.arcsin", "torch.arcsinh", "torch.arctan", "torch.arctan2", "torch.arctanh", "torch.are_deterministic_algorithms_enabled", "torch.argmax", "torch.argmin", "torch.argsort", "torch.argwhere", "torch.as_strided", "torch.as_tensor", "torch.asarray", "torch.asin", "torch.asinh", "torch.atan", "torch.atan2", "torch.atanh", "torch.atleast_1d", "torch.atleast_2d", "torch.atleast_3d", "torch.autograd.Function.backward", "torch.autograd.Function.forward", "torch.autograd.Function.jvp", "torch.autograd.Function.vmap", "torch.autograd.backward", "UnpackedDualTensor", "dual_level", "torch.autograd.forward_ad.enter_dual_level", "torch.autograd.forward_ad.exit_dual_level", "torch.autograd.forward_ad.make_dual", "torch.autograd.forward_ad.unpack_dual", "BackwardCFunction", "torch.autograd.function.FunctionCtx.mark_dirty", "torch.autograd.function.FunctionCtx.mark_non_differentiable", "torch.autograd.function.FunctionCtx.save_for_backward", "torch.autograd.function.FunctionCtx.set_materialize_grads", "InplaceFunction", "NestedIOFunction", "torch.autograd.function.once_differentiable", "torch.autograd.functional.hessian", "torch.autograd.functional.hvp", "torch.autograd.functional.jacobian", "torch.autograd.functional.jvp", "torch.autograd.functional.vhp", "torch.autograd.functional.vjp", "torch.autograd.grad", "inference_mode", "set_grad_enabled", "set_multithreading_enabled", "torch.autograd.gradcheck.GradcheckError", "torch.autograd.gradcheck.gradcheck", "torch.autograd.gradcheck.gradgradcheck", "torch.autograd.graph.Node.metadata", "torch.autograd.graph.Node.name", "torch.autograd.graph.Node.next_functions", "torch.autograd.graph.Node.register_hook", "torch.autograd.graph.Node.register_prehook", "torch.autograd.graph.increment_version", "EnforceUnique", "KinetoStepTracker", "torch.autograd.profiler.load_nvprof", "torch.autograd.profiler.parse_nvprof_trace", "torch.autograd.profiler.profile.export_chrome_trace", "torch.autograd.profiler.profile.key_averages", "torch.autograd.profiler.profile.self_cpu_time_total", "torch.autograd.profiler.profile.total_average", "record_function", "Interval", "Kernel", "MemRecordsAcc", "StringTable", "torch.baddbmm", "torch.bartlett_window", "torch.bernoulli", "torch.bincount", "torch.bitwise_and", "torch.bitwise_left_shift", "torch.bitwise_not", "torch.bitwise_or", "torch.bitwise_right_shift", "torch.bitwise_xor", "torch.blackman_window", "torch.block_diag", "torch.bmm", "torch.broadcast_shapes", "torch.broadcast_tensors", "torch.broadcast_to", "torch.bucketize", "torch.can_cast", "torch.cartesian_prod", "torch.cat", "torch.cdist", "torch.ceil", "torch.chain_matmul", "torch.cholesky", "torch.cholesky_inverse", "torch.cholesky_solve", "torch.chunk", "torch.clamp", "torch.clip", "torch.clone", "torch.column_stack", "torch.combinations", "torch.compile", "torch.compiled_with_cxx11_abi", "torch.compiler.allow_in_graph", "torch.compiler.assume_constant_result", "torch.compiler.compile", "torch.compiler.cudagraph_mark_step_begin", "torch.compiler.disable", "torch.compiler.is_compiling", "torch.compiler.is_dynamo_compiling", "torch.compiler.is_exporting", "torch.compiler.list_backends", "torch.compiler.reset", "torch.compiler.set_stance", "torch.compiler.substitute_in_graph", "torch.complex", "torch.concat", "torch.concatenate", "torch.cond", "torch.conj", "torch.conj_physical", "torch.copysign", "torch.corrcoef", "torch.cos", "torch.cosh", "torch.count_nonzero", "torch.cov", "torch.cpu.stream", "StreamContext", "torch.cpu.current_device", "torch.cpu.current_stream", "torch.cpu.device_count", "torch.cpu.is_available", "torch.cpu.set_device", "torch.cpu.synchronize", "torch.cross", "CUDAGraph", "CUDAPluggableAllocator", "Event", "ExternalStream", "MemPool", "MemPoolContext", "torch.cuda.OutOfMemoryError", "torch.cuda.stream", "StreamContext", "torch.cuda.caching_allocator_alloc", "torch.cuda.caching_allocator_delete", "torch.cuda.can_device_access_peer", "torch.cuda.change_current_allocator", "torch.cuda.clock_rate", "torch.cuda.comm.broadcast", "torch.cuda.comm.broadcast_coalesced", "torch.cuda.comm.gather", "torch.cuda.comm.reduce_add", "torch.cuda.comm.reduce_add_coalesced", "torch.cuda.comm.scatter", "torch.cuda.cudart", "torch.cuda.current_blas_handle", "torch.cuda.current_device", "torch.cuda.current_stream", "torch.cuda.default_stream", "device", "torch.cuda.device_count", "torch.cuda.device_memory_used", "device_of", "torch.cuda.empty_cache", "torch.cuda.get_allocator_backend", "torch.cuda.get_arch_list", "torch.cuda.get_device_capability", "torch.cuda.get_device_name", "torch.cuda.get_device_properties", "torch.cuda.get_gencode_flags", "torch.cuda.get_per_process_memory_fraction", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state_all", "torch.cuda.get_stream_from_external", "torch.cuda.get_sync_debug_mode", "graph", "torch.cuda.graph_pool_handle", "torch.cuda.init", "torch.cuda.initial_seed", "torch.cuda.ipc_collect", "torch.cuda.is_available", "torch.cuda.is_current_stream_capturing", "torch.cuda.is_initialized", "torch.cuda.jiterator._create_jit_fn", "torch.cuda.jiterator._create_multi_output_jit_fn", "torch.cuda.list_gpu_processes", "torch.cuda.make_graphed_callables", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_cached", "torch.cuda.max_memory_reserved", "torch.cuda.mem_get_info", "torch.cuda.memory.caching_allocator_enable", "torch.cuda.memory_allocated", "torch.cuda.memory_cached", "torch.cuda.memory_reserved", "torch.cuda.memory_snapshot", "torch.cuda.memory_stats", "torch.cuda.memory_summary", "torch.cuda.memory_usage", "torch.cuda.nvtx.mark", "torch.cuda.nvtx.range", "torch.cuda.nvtx.range_pop", "torch.cuda.nvtx.range_push", "torch.cuda.power_draw", "torch.cuda.reset_max_memory_allocated", "torch.cuda.reset_max_memory_cached", "torch.cuda.reset_peak_memory_stats", "torch.cuda.seed", "torch.cuda.seed_all", "torch.cuda.set_device", "torch.cuda.set_per_process_memory_fraction", "torch.cuda.set_rng_state", "torch.cuda.set_rng_state_all", "torch.cuda.set_stream", "torch.cuda.set_sync_debug_mode", "torch.cuda.synchronize", "torch.cuda.temperature", "torch.cuda.utilization", "torch.cummax", "torch.cummin", "torch.cumprod", "torch.cumsum", "torch.cumulative_trapezoid", "torch.deg2rad", "torch.dequantize", "torch.det", "torch.diag", "torch.diag_embed", "torch.diagflat", "torch.diagonal", "torch.diagonal_scatter", "torch.diff", "torch.digamma", "torch.dist", "torch.div", "torch.divide", "torch.dot", "torch.dsplit", "torch.dstack", "torch.einsum", "torch.empty", "torch.empty_like", "torch.empty_strided", "enable_grad", "torch.eq", "torch.equal", "torch.erf", "torch.erfc", "torch.erfinv", "torch.exp", "torch.exp2", "torch.expm1", "torch.eye", "torch.fake_quantize_per_channel_affine", "torch.fake_quantize_per_tensor_affine", "torch.fft.fft", "torch.fft.fft2", "torch.fft.fftfreq", "torch.fft.fftn", "torch.fft.fftshift", "torch.fft.hfft", "torch.fft.hfft2", "torch.fft.hfftn", "torch.fft.ifft", "torch.fft.ifft2", "torch.fft.ifftn", "torch.fft.ifftshift", "torch.fft.ihfft", "torch.fft.ihfft2", "torch.fft.ihfftn", "torch.fft.irfft", "torch.fft.irfft2", "torch.fft.irfftn", "torch.fft.rfft", "torch.fft.rfft2", "torch.fft.rfftfreq", "torch.fft.rfftn", "torch.fix", "torch.flatten", "torch.flip", "torch.fliplr", "torch.flipud", "torch.float_power", "torch.floor", "torch.floor_divide", "torch.fmax", "torch.fmin", "torch.fmod", "torch.frac", "torch.frexp", "torch.from_dlpack", "torch.from_file", "torch.from_numpy", "torch.frombuffer", "torch.full", "torch.full_like", "torch.func.functional_call", "torch.func.functionalize", "torch.func.grad", "torch.func.grad_and_value", "torch.func.hessian", "torch.func.jacfwd", "torch.func.jacrev", "torch.func.jvp", "torch.func.linearize", "torch.func.replace_all_batch_norm_modules_", "torch.func.stack_module_state", "torch.func.vjp", "torch.func.vmap", "torch.fx.experimental.proxy_tensor.get_proxy_mode", "torch.fx.experimental.proxy_tensor.handle_sym_dispatch", "torch.fx.experimental.proxy_tensor.make_fx", "torch.fx.experimental.proxy_tensor.maybe_disable_thunkify", "torch.fx.experimental.proxy_tensor.maybe_enable_thunkify", "CallMethodKey", "ConvertIntKey", "DimConstraints", "DimDynamic", "DivideByKey", "EqualityConstraint", "InnerTensorKey", "PropagateUnbackedSymInts", "RelaxedUnspecConstraint", "ShapeEnv", "ShapeEnvSettings", "StatefulSymbolicContext", "StatelessSymbolicContext", "StrictMinMaxConstraint", "SubclassSymbolicContext", "SymbolicContext", "torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr", "torch.fx.experimental.symbolic_shapes.check_consistent", "torch.fx.experimental.symbolic_shapes.compute_unbacked_bindings", "torch.fx.experimental.symbolic_shapes.constrain_range", "torch.fx.experimental.symbolic_shapes.constrain_unify", "torch.fx.experimental.symbolic_shapes.definitely_false", "torch.fx.experimental.symbolic_shapes.definitely_true", "torch.fx.experimental.symbolic_shapes.guard_size_oblivious", "torch.fx.experimental.symbolic_shapes.has_free_symbols", "torch.fx.experimental.symbolic_shapes.has_free_unbacked_symbols", "torch.fx.experimental.symbolic_shapes.hint_int", "torch.fx.experimental.symbolic_shapes.is_accessor_node", "torch.fx.experimental.symbolic_shapes.is_concrete_bool", "torch.fx.experimental.symbolic_shapes.is_concrete_float", "torch.fx.experimental.symbolic_shapes.is_concrete_int", "torch.fx.experimental.symbolic_shapes.lru_cache", "torch.fx.experimental.symbolic_shapes.rebind_unbacked", "torch.fx.experimental.symbolic_shapes.resolve_unbacked_bindings", "torch.fx.experimental.symbolic_shapes.statically_known_true", "torch.fx.experimental.symbolic_shapes.sym_eq", "torch.gather", "torch.gcd", "torch.ge", "torch.geqrf", "torch.ger", "torch.get_default_device", "torch.get_default_dtype", "torch.get_deterministic_debug_mode", "torch.get_device_module", "torch.get_float32_matmul_precision", "torch.get_num_interop_threads", "torch.get_num_threads", "torch.get_rng_state", "torch.gradient", "torch.greater", "torch.greater_equal", "torch.gt", "torch.hamming_window", "torch.hann_window", "torch.heaviside", "torch.histc", "torch.histogram", "torch.histogramdd", "torch.hsplit", "torch.hspmm", "torch.hstack", "torch.hypot", "torch.i0", "torch.igamma", "torch.igammac", "torch.imag", "torch.index_add", "torch.index_copy", "torch.index_reduce", "torch.index_select", "torch.initial_seed", "torch.inner", "torch.inverse", "torch.is_complex", "torch.is_conj", "torch.is_deterministic_algorithms_warn_only_enabled", "torch.is_floating_point", "torch.is_grad_enabled", "torch.is_inference_mode_enabled", "torch.is_nonzero", "torch.is_storage", "torch.is_tensor", "torch.is_warn_always_enabled", "torch.isclose", "torch.isfinite", "torch.isin", "torch.isinf", "torch.isnan", "torch.isneginf", "torch.isposinf", "torch.isreal", "torch.istft", "Attribute", "ScriptFunction", "ScriptModule", "torch.jit.annotate", "torch.jit.enable_onednn_fusion", "torch.jit.fork", "torch.jit.freeze", "torch.jit.ignore", "torch.jit.interface", "torch.jit.isinstance", "torch.jit.load", "torch.jit.onednn_fusion_enabled", "torch.jit.optimize_for_inference", "torch.jit.save", "torch.jit.script", "torch.jit.script_if_tracing", "torch.jit.set_fusion_strategy", "strict_fusion", "torch.jit.trace", "torch.jit.trace_module", "torch.jit.unused", "torch.jit.wait", "torch.kaiser_window", "torch.kron", "torch.kthvalue", "torch.lcm", "torch.ldexp", "torch.le", "torch.lerp", "torch.less", "torch.less_equal", "torch.lgamma", "torch.linalg.cholesky", "torch.linalg.cholesky_ex", "torch.linalg.cond", "torch.linalg.cross", "torch.linalg.det", "torch.linalg.diagonal", "torch.linalg.eig", "torch.linalg.eigh", "torch.linalg.eigvals", "torch.linalg.eigvalsh", "torch.linalg.householder_product", "torch.linalg.inv", "torch.linalg.inv_ex", "torch.linalg.ldl_factor", "torch.linalg.ldl_factor_ex", "torch.linalg.ldl_solve", "torch.linalg.lstsq", "torch.linalg.lu", "torch.linalg.lu_factor", "torch.linalg.lu_factor_ex", "torch.linalg.lu_solve", "torch.linalg.matmul", "torch.linalg.matrix_exp", "torch.linalg.matrix_norm", "torch.linalg.matrix_power", "torch.linalg.matrix_rank", "torch.linalg.multi_dot", "torch.linalg.norm", "torch.linalg.pinv", "torch.linalg.qr", "torch.linalg.slogdet", "torch.linalg.solve", "torch.linalg.solve_ex", "torch.linalg.solve_triangular", "torch.linalg.svd", "torch.linalg.svdvals", "torch.linalg.tensorinv", "torch.linalg.tensorsolve", "torch.linalg.vander", "torch.linalg.vecdot", "torch.linalg.vector_norm", "torch.linspace", "torch.load", "torch.lobpcg", "torch.log", "torch.log10", "torch.log1p", "torch.log2", "torch.logaddexp", "torch.logaddexp2", "torch.logcumsumexp", "torch.logdet", "torch.logical_and", "torch.logical_not", "torch.logical_or", "torch.logical_xor", "torch.logit", "torch.logspace", "torch.logsumexp", "torch.lt", "torch.lu", "torch.lu_solve", "torch.lu_unpack", "torch.manual_seed", "torch.masked_select", "torch.matmul", "torch.matrix_exp", "torch.matrix_power", "torch.max", "torch.maximum", "torch.mean", "torch.median", "torch.meshgrid", "torch.min", "torch.minimum", "torch.mm", "torch.mode", "torch.moveaxis", "torch.movedim", "torch.mps.current_allocated_memory", "torch.mps.device_count", "torch.mps.driver_allocated_memory", "torch.mps.empty_cache", "Event", "torch.mps.get_rng_state", "torch.mps.manual_seed", "torch.mps.profiler.is_capturing_metal", "torch.mps.profiler.is_metal_capture_enabled", "torch.mps.profiler.metal_capture", "torch.mps.profiler.profile", "torch.mps.profiler.start", "torch.mps.profiler.stop", "torch.mps.recommended_max_memory", "torch.mps.seed", "torch.mps.set_per_process_memory_fraction", "torch.mps.set_rng_state", "torch.mps.synchronize", "torch.msort", "torch.mtia.DeferredMtiaCallError", "Event", "torch.mtia.stream", "StreamContext", "torch.mtia.current_device", "torch.mtia.current_stream", "torch.mtia.default_stream", "device", "torch.mtia.device_count", "torch.mtia.empty_cache", "torch.mtia.get_device_capability", "torch.mtia.get_rng_state", "torch.mtia.init", "torch.mtia.is_available", "torch.mtia.is_initialized", "torch.mtia.memory.memory_stats", "torch.mtia.memory_stats", "torch.mtia.record_memory_history", "torch.mtia.set_device", "torch.mtia.set_rng_state", "torch.mtia.set_stream", "torch.mtia.snapshot", "torch.mtia.synchronize", "torch.mul", "torch.multinomial", "torch.multiply", "torch.mv", "torch.mvlgamma", "torch.nan_to_num", "torch.nanmean", "torch.nanmedian", "torch.nanquantile", "torch.nansum", "torch.narrow", "torch.narrow_copy", "torch.ne", "torch.neg", "torch.negative", "torch.nextafter", "AdaptiveAvgPool1d", "AdaptiveAvgPool2d", "AdaptiveAvgPool3d", "AdaptiveLogSoftmaxWithLoss", "AdaptiveMaxPool1d", "AdaptiveMaxPool2d", "AdaptiveMaxPool3d", "AlphaDropout", "AvgPool1d", "AvgPool2d", "AvgPool3d", "BCELoss", "BCEWithLogitsLoss", "BatchNorm1d", "BatchNorm2d", "BatchNorm3d", "Bilinear", "CELU", "CTCLoss", "ChannelShuffle", "CircularPad1d", "CircularPad2d", "CircularPad3d", "ConstantPad1d", "ConstantPad2d", "ConstantPad3d", "Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d", "CosineEmbeddingLoss", "CosineSimilarity", "CrossEntropyLoss", "DataParallel", "Dropout", "Dropout1d", "Dropout2d", "Dropout3d", "ELU", "Embedding", "EmbeddingBag", "FeatureAlphaDropout", "Flatten", "Fold", "FractionalMaxPool2d", "FractionalMaxPool3d", "GELU", "GLU", "GRU", "GRUCell", "GaussianNLLLoss", "GroupNorm", "Hardshrink", "Hardsigmoid", "Hardswish", "Hardtanh", "HingeEmbeddingLoss", "HuberLoss", "Identity", "InstanceNorm1d", "InstanceNorm2d", "InstanceNorm3d", "KLDivLoss", "L1Loss", "LPPool1d", "LPPool2d", "LPPool3d", "LSTM", "LSTMCell", "LayerNorm", "LazyBatchNorm1d", "LazyBatchNorm2d", "LazyBatchNorm3d", "LazyConv1d", "LazyConv2d", "LazyConv3d", "LazyConvTranspose1d", "LazyConvTranspose2d", "LazyConvTranspose3d", "LazyInstanceNorm1d", "LazyInstanceNorm2d", "LazyInstanceNorm3d", "LazyLinear", "LeakyReLU", "Linear", "LocalResponseNorm", "LogSigmoid", "LogSoftmax", "MSELoss", "MarginRankingLoss", "MaxPool1d", "MaxPool2d", "MaxPool3d", "MaxUnpool1d", "MaxUnpool2d", "MaxUnpool3d", "Mish", "Module", "ModuleDict", "ModuleList", "MultiLabelMarginLoss", "MultiLabelSoftMarginLoss", "MultiMarginLoss", "MultiheadAttention", "NLLLoss", "PReLU", "PairwiseDistance", "ParameterDict", "ParameterList", "PixelShuffle", "PixelUnshuffle", "PoissonNLLLoss", "RMSNorm", "RNN", "RNNBase", "RNNCell", "RReLU", "ReLU", "ReLU6", "ReflectionPad1d", "ReflectionPad2d", "ReflectionPad3d", "ReplicationPad1d", "ReplicationPad2d", "ReplicationPad3d", "SELU", "Sequential", "SiLU", "Sigmoid", "SmoothL1Loss", "SoftMarginLoss", "Softmax", "Softmax2d", "Softmin", "Softplus", "Softshrink", "Softsign", "SyncBatchNorm", "Tanh", "Tanhshrink", "Threshold", "Transformer", "TransformerDecoder", "TransformerDecoderLayer", "TransformerEncoder", "TransformerEncoderLayer", "TripletMarginLoss", "TripletMarginWithDistanceLoss", "Unflatten", "Unfold", "Upsample", "UpsamplingBilinear2d", "UpsamplingNearest2d", "ZeroPad1d", "ZeroPad2d", "ZeroPad3d", "SDPBackend", "torch.nn.attention.bias.CausalBias", "CausalVariant", "torch.nn.attention.bias.causal_lower_right", "torch.nn.attention.bias.causal_upper_left", "torch.nn.attention.sdpa_kernel", "torch.nn.functional.adaptive_avg_pool1d", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool3d", "torch.nn.functional.adaptive_max_pool1d", "torch.nn.functional.adaptive_max_pool2d", "torch.nn.functional.adaptive_max_pool3d", "torch.nn.functional.affine_grid", "torch.nn.functional.alpha_dropout", "torch.nn.functional.avg_pool1d", "torch.nn.functional.avg_pool2d", "torch.nn.functional.avg_pool3d", "torch.nn.functional.batch_norm", "torch.nn.functional.bilinear", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.nn.functional.celu", "torch.nn.functional.conv1d", "torch.nn.functional.conv2d", "torch.nn.functional.conv3d", "torch.nn.functional.conv_transpose1d", "torch.nn.functional.conv_transpose2d", "torch.nn.functional.conv_transpose3d", "torch.nn.functional.cosine_embedding_loss", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cross_entropy", "torch.nn.functional.ctc_loss", "torch.nn.functional.dropout", "torch.nn.functional.dropout1d", "torch.nn.functional.dropout2d", "torch.nn.functional.dropout3d", "torch.nn.functional.elu", "torch.nn.functional.elu_", "torch.nn.functional.embedding", "torch.nn.functional.embedding_bag", "torch.nn.functional.feature_alpha_dropout", "torch.nn.functional.fold", "torch.nn.functional.fractional_max_pool2d", "torch.nn.functional.fractional_max_pool3d", "torch.nn.functional.gaussian_nll_loss", "torch.nn.functional.gelu", "torch.nn.functional.glu", "torch.nn.functional.grid_sample", "torch.nn.functional.group_norm", "torch.nn.functional.gumbel_softmax", "torch.nn.functional.hardshrink", "torch.nn.functional.hardsigmoid", "torch.nn.functional.hardswish", "torch.nn.functional.hardtanh", "torch.nn.functional.hardtanh_", "torch.nn.functional.hinge_embedding_loss", "torch.nn.functional.huber_loss", "torch.nn.functional.instance_norm", "torch.nn.functional.interpolate", "torch.nn.functional.kl_div", "torch.nn.functional.l1_loss", "torch.nn.functional.layer_norm", "torch.nn.functional.leaky_relu", "torch.nn.functional.leaky_relu_", "torch.nn.functional.linear", "torch.nn.functional.local_response_norm", "torch.nn.functional.log_softmax", "torch.nn.functional.logsigmoid", "torch.nn.functional.lp_pool1d", "torch.nn.functional.lp_pool2d", "torch.nn.functional.lp_pool3d", "torch.nn.functional.margin_ranking_loss", "torch.nn.functional.max_pool1d", "torch.nn.functional.max_pool2d", "torch.nn.functional.max_pool3d", "torch.nn.functional.max_unpool1d", "torch.nn.functional.max_unpool2d", "torch.nn.functional.max_unpool3d", "torch.nn.functional.mish", "torch.nn.functional.mse_loss", "torch.nn.functional.multi_margin_loss", "torch.nn.functional.multilabel_margin_loss", "torch.nn.functional.multilabel_soft_margin_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.normalize", "torch.nn.functional.one_hot", "torch.nn.functional.pad", "torch.nn.functional.pairwise_distance", "torch.nn.functional.pdist", "torch.nn.functional.pixel_shuffle", "torch.nn.functional.pixel_unshuffle", "torch.nn.functional.poisson_nll_loss", "torch.nn.functional.prelu", "torch.nn.functional.relu", "torch.nn.functional.relu6", "torch.nn.functional.relu_", "torch.nn.functional.rms_norm", "torch.nn.functional.rrelu", "torch.nn.functional.rrelu_", "torch.nn.functional.scaled_dot_product_attention", "torch.nn.functional.selu", "torch.nn.functional.sigmoid", "torch.nn.functional.silu", "torch.nn.functional.smooth_l1_loss", "torch.nn.functional.soft_margin_loss", "torch.nn.functional.softmax", "torch.nn.functional.softmin", "torch.nn.functional.softplus", "torch.nn.functional.softshrink", "torch.nn.functional.softsign", "torch.nn.functional.tanh", "torch.nn.functional.tanhshrink", "torch.nn.functional.threshold", "torch.nn.functional.threshold_", "torch.nn.functional.torch.nn.parallel.data_parallel", "torch.nn.functional.triplet_margin_loss", "torch.nn.functional.triplet_margin_with_distance_loss", "torch.nn.functional.unfold", "torch.nn.functional.upsample", "torch.nn.functional.upsample_bilinear", "torch.nn.functional.upsample_nearest", "LazyModuleMixin", "torch.nn.modules.module.register_module_backward_hook", "torch.nn.modules.module.register_module_buffer_registration_hook", "torch.nn.modules.module.register_module_forward_hook", "torch.nn.modules.module.register_module_forward_pre_hook", "torch.nn.modules.module.register_module_full_backward_hook", "torch.nn.modules.module.register_module_full_backward_pre_hook", "torch.nn.modules.module.register_module_module_registration_hook", "torch.nn.modules.module.register_module_parameter_registration_hook", "RMSNorm", "DistributedDataParallel", "Buffer", "Parameter", "UninitializedBuffer", "UninitializedParameter", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grads_with_norm_", "torch.nn.utils.convert_conv2d_weight_memory_format", "torch.nn.utils.convert_conv3d_weight_memory_format", "torch.nn.utils.fuse_conv_bn_eval", "torch.nn.utils.fuse_conv_bn_weights", "torch.nn.utils.fuse_linear_bn_eval", "torch.nn.utils.fuse_linear_bn_weights", "torch.nn.utils.get_total_norm", "torch.nn.utils.parameters_to_vector", "torch.nn.utils.parametrizations.orthogonal", "torch.nn.utils.parametrizations.spectral_norm", "torch.nn.utils.parametrizations.weight_norm", "ParametrizationList", "torch.nn.utils.parametrize.cached", "torch.nn.utils.parametrize.is_parametrized", "torch.nn.utils.parametrize.register_parametrization", "torch.nn.utils.parametrize.remove_parametrizations", "BasePruningMethod", "CustomFromMask", "torch.nn.utils.prune.identity", "L1Unstructured", "LnStructured", "PruningContainer", "RandomStructured", "RandomUnstructured", "torch.nn.utils.prune.custom_from_mask", "torch.nn.utils.prune.global_unstructured", "torch.nn.utils.prune.is_pruned", "torch.nn.utils.prune.l1_unstructured", "torch.nn.utils.prune.ln_structured", "torch.nn.utils.prune.random_structured", "torch.nn.utils.prune.random_unstructured", "torch.nn.utils.prune.remove", "torch.nn.utils.remove_spectral_norm", "torch.nn.utils.remove_weight_norm", "PackedSequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.unpack_sequence", "torch.nn.utils.rnn.unpad_sequence", "torch.nn.utils.skip_init", "torch.nn.utils.spectral_norm", "torch.nn.utils.stateless.functional_call", "torch.nn.utils.vector_to_parameters", "torch.nn.utils.weight_norm", "no_grad", "torch.nonzero", "torch.norm", "torch.normal", "torch.not_equal", "torch.numel", "torch.ones", "torch.ones_like", "JitScalarType", "GraphInfo", "VerificationOptions", "ASGD", "Adadelta", "Adafactor", "Adagrad", "Adam", "AdamW", "Adamax", "LBFGS", "NAdam", "torch.optim.Optimizer.add_param_group", "torch.optim.Optimizer.load_state_dict", "torch.optim.Optimizer.register_load_state_dict_post_hook", "torch.optim.Optimizer.register_load_state_dict_pre_hook", "torch.optim.Optimizer.register_state_dict_post_hook", "torch.optim.Optimizer.register_state_dict_pre_hook", "torch.optim.Optimizer.register_step_post_hook", "torch.optim.Optimizer.register_step_pre_hook", "torch.optim.Optimizer.state_dict", "torch.optim.Optimizer.step", "torch.optim.Optimizer.zero_grad", "RAdam", "RMSprop", "Rprop", "SGD", "SparseAdam", "ChainedScheduler", "ConstantLR", "CosineAnnealingLR", "CosineAnnealingWarmRestarts", "CyclicLR", "ExponentialLR", "LRScheduler", "LambdaLR", "LinearLR", "MultiStepLR", "MultiplicativeLR", "OneCycleLR", "PolynomialLR", "ReduceLROnPlateau", "SequentialLR", "StepLR", "AveragedModel", "SWALR", "torch.orgqr", "torch.ormqr", "torch.outer", "torch.pca_lowrank", "torch.permute", "torch.pinverse", "torch.poisson", "torch.polar", "torch.polygamma", "torch.positive", "torch.pow", "torch.prod", "torch.promote_types", "torch.qr", "torch.quantile", "torch.quantize_per_channel", "torch.quantize_per_tensor", "torch.quantized_batch_norm", "torch.quantized_max_pool1d", "torch.quantized_max_pool2d", "SobolEngine", "torch.rad2deg", "torch.rand", "torch.rand_like", "torch.randint", "torch.randint_like", "torch.randn", "torch.randn_like", "torch.randperm", "torch.range", "torch.ravel", "torch.real", "torch.reciprocal", "torch.remainder", "torch.renorm", "torch.repeat_interleave", "torch.reshape", "torch.resolve_conj", "torch.resolve_neg", "torch.result_type", "torch.roll", "torch.rot90", "torch.round", "torch.row_stack", "torch.rsqrt", "torch.save", "torch.scatter", "torch.scatter_add", "torch.scatter_reduce", "torch.searchsorted", "torch.seed", "torch.select", "torch.select_scatter", "torch.set_default_device", "torch.set_default_dtype", "torch.set_default_tensor_type", "torch.set_deterministic_debug_mode", "torch.set_float32_matmul_precision", "torch.set_flush_denormal", "torch.set_num_interop_threads", "torch.set_num_threads", "torch.set_printoptions", "torch.set_rng_state", "torch.set_warn_always", "torch.sgn", "torch.sigmoid", "torch.sign", "torch.signal.windows.bartlett", "torch.signal.windows.blackman", "torch.signal.windows.cosine", "torch.signal.windows.exponential", "torch.signal.windows.gaussian", "torch.signal.windows.general_cosine", "torch.signal.windows.general_hamming", "torch.signal.windows.hamming", "torch.signal.windows.hann", "torch.signal.windows.kaiser", "torch.signal.windows.nuttall", "torch.signbit", "torch.sin", "torch.sinc", "torch.sinh", "torch.slice_scatter", "torch.slogdet", "torch.smm", "torch.softmax", "torch.sort", "torch.sparse.addmm", "torch.sparse.as_sparse_gradcheck", "check_sparse_tensor_invariants", "torch.sparse.log_softmax", "torch.sparse.mm", "torch.sparse.sampled_addmm", "torch.sparse.softmax", "torch.sparse.spdiags", "torch.sparse.spsolve", "torch.sparse.sum", "torch.sparse_bsc_tensor", "torch.sparse_bsr_tensor", "torch.sparse_compressed_tensor", "torch.sparse_coo_tensor", "torch.sparse_csc_tensor", "torch.sparse_csr_tensor", "torch.split", "torch.sqrt", "torch.square", "torch.squeeze", "torch.sspaddmm", "torch.stack", "torch.std", "torch.std_mean", "torch.stft", "torch.sub", "torch.subtract", "torch.sum", "torch.svd", "torch.svd_lowrank", "torch.swapaxes", "torch.swapdims", "torch.sym_float", "torch.sym_fresh_size", "torch.sym_int", "torch.sym_ite", "torch.sym_max", "torch.sym_min", "torch.sym_not", "torch.sym_sum", "torch.t", "torch.take", "torch.take_along_dim", "torch.tan", "torch.tanh", "torch.tensor", "torch.tensor_split", "torch.tensordot", "torch.tile", "torch.topk", "torch.trace", "torch.transpose", "torch.trapezoid", "torch.trapz", "torch.triangular_solve", "torch.tril", "torch.tril_indices", "torch.triu", "torch.triu_indices", "torch.true_divide", "torch.trunc", "torch.unbind", "torch.unflatten", "torch.unique", "torch.unique_consecutive", "torch.unravel_index", "torch.unsqueeze", "torch.use_deterministic_algorithms", "torch.utils.generate_methods_for_privateuse1_backend", "torch.utils.get_cpp_backtrace", "torch.utils.rename_privateuse1_backend", "torch.utils.set_module", "torch.utils.swap_tensors", "torch.vander", "torch.var", "torch.var_mean", "torch.vdot", "torch.view_as_complex", "torch.view_as_real", "torch.vmap", "torch.vsplit", "torch.vstack", "torch.where", "torch.xlogy", "Event", "torch.xpu.stream", "StreamContext", "torch.xpu.current_device", "torch.xpu.current_stream", "device", "torch.xpu.device_count", "device_of", "torch.xpu.empty_cache", "torch.xpu.get_arch_list", "torch.xpu.get_device_capability", "torch.xpu.get_device_name", "torch.xpu.get_device_properties", "torch.xpu.get_gencode_flags", "torch.xpu.get_rng_state", "torch.xpu.get_rng_state_all", "torch.xpu.get_stream_from_external", "torch.xpu.init", "torch.xpu.initial_seed", "torch.xpu.is_available", "torch.xpu.is_initialized", "torch.xpu.manual_seed", "torch.xpu.manual_seed_all", "torch.xpu.max_memory_allocated", "torch.xpu.max_memory_reserved", "torch.xpu.mem_get_info", "torch.xpu.memory_allocated", "torch.xpu.memory_reserved", "torch.xpu.memory_stats", "torch.xpu.memory_stats_as_nested_dict", "torch.xpu.reset_accumulated_memory_stats", "torch.xpu.reset_peak_memory_stats", "torch.xpu.seed", "torch.xpu.seed_all", "torch.xpu.set_device", "torch.xpu.set_rng_state", "torch.xpu.set_rng_state_all", "torch.xpu.set_stream", "torch.xpu.synchronize", "torch.zeros", "torch.zeros_like", "torch.hub", "PyTorch documentation", "TorchScript", "TorchScript Builtins", "TorchScript Language Reference", "TorchScript Language Reference", "Python Language Reference Coverage", "TorchScript Unsupported PyTorch Constructs", "JIT Utils - torch.utils.jit", "torch.library", "torch.linalg", "torch._logging", "torch.masked", "Meta device", "Miscellaneous Environment Variables", "torch.utils.mobile_optimizer", "torch.utils.model_zoo", "torch.utils.module_tracker", "torch.monitor", "torch.mps", "MPS Environment Variables", "torch.mtia", "torch.mtia.memory", "Multiprocessing package - torch.multiprocessing", "Named Tensors operator coverage", "Named Tensors", "torch.nested", "torch.nn", "torch.nn.attention", "torch.nn.attention.bias", "torch.nn.attention.experimental", "torch.nn.attention.flex_attention", "torch.nn.functional", "torch.nn.init", "Developer Notes", "Automatic Mixed Precision examples", "Autograd mechanics", "Broadcasting semantics", "CPU threading and TorchScript inference", "CUDA semantics", "PyTorch Custom Operators Landing Page", "Distributed Data Parallel", "Extending PyTorch", "Extending torch.func with autograd.Function", "Frequently Asked Questions", "FSDP Notes", "Getting Started on Intel GPU", "Gradcheck mechanics", "HIP (ROCm) semantics", "Features for large-scale deployments", "LibTorch Stable ABI", "Modules", "MPS backend", "Multiprocessing best practices", "Numerical accuracy", "Reproducibility", "Serialization semantics", "Windows FAQ", "torch.onnx", "TorchDynamo-based ONNX Exporter", "Understanding TorchDynamo-based ONNX Exporter Memory Usage", "ONNX Backend for TorchDynamo", "torch.onnx.ops", "TorchScript-based ONNX Exporter", "ONNX supported TorchScript operators", "torch.onnx.verification", "torch.optim", "torch.package", "torch.profiler", "Python API", "Quantization", "Quantization Accuracy Debugging", "Quantization Backend Configuration", "Quantization API Reference", "torch.random", "Distributed RPC Framework", "Distributed Autograd Design", "Remote Reference Protocol", "torch.signal", "torch.Size", "torch.sparse", "torch.special", "torch.Storage", "Tensor Attributes", "Tensor Views", "torch.utils.tensorboard", "torch.Tensor", "torch.testing", "Threading Environment Variables", "torch", "torch.ao.ns._numeric_suite", "torch.ao.ns._numeric_suite_fx", "torch.compiler", "torch.compiler.config", "AOTInductor: Ahead-Of-Time Compilation for Torch.Export-ed Models", "AOTInductor Minifier", "torch.compiler API reference", "Best Practices for Backends", "CUDAGraph Trees", "Custom Backends", "Dynamic shapes", "Dynamo Deep-Dive", "Dynamo Overview", "Fake tensor", "Frequently Asked Questions", "TorchDynamo APIs for fine-grained tracing", "Getting Started", "TorchInductor GPU Profiling", "IRs", "PyTorch 2.0 NNModule Support", "PyTorch 2.0 Performance Dashboard", "Profiling to understand torch.compile performance", "Writing Graph Transformations on ATen IR", "torch.compile Troubleshooting", "PyTorch 2.0 Troubleshooting (old)", "torch.overrides", "Understanding CUDA Memory Usage", "Torch Environment Variables", "PYTORCH ProcessGroupNCCL Environment Variables", "Type Info", "torch.utils", "torch.xpu"], "terms": {"thi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 67, 68, 69, 71, 79, 80, 86, 87, 88, 119, 150, 154, 195, 196, 206, 209, 221, 222, 223, 233, 255, 260, 289, 290, 313, 321, 323, 335, 337, 340, 352, 415, 445, 446, 447, 448, 449, 458, 486, 487, 488, 493, 495, 496, 497, 498, 499, 500, 503, 504, 513, 515, 517, 524, 556, 566, 583, 584, 585, 587, 588, 589, 603, 604, 614, 617, 618, 623, 681, 684, 690, 691, 692, 693, 695, 697, 700, 704, 705, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 746, 747, 748, 755, 759, 760, 761, 762, 763, 764, 765, 766, 768, 770, 771, 786, 787, 788, 789, 790, 796, 797, 798, 800, 802, 803, 804, 805, 806, 807, 808, 809, 814, 815, 817, 825, 826, 827, 828, 830, 831, 832, 839, 840, 841, 842, 843, 846, 851, 884, 889, 891, 892, 904, 905, 906, 907, 908, 915, 919, 920, 921, 922, 923, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 954, 955, 956, 958, 962, 969, 970, 973, 975, 978, 982, 983, 986, 990, 992, 993, 996, 997, 999, 1002, 1004, 1005, 1006, 1007, 1008, 1013, 1014, 1020, 1021, 1023, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1040, 1041, 1042, 1044, 1045, 1046, 1049, 1057, 1062, 1065, 1068, 1069, 1070, 1072, 1074, 1078, 1079, 1080, 1081, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1094, 1097, 1100, 1101, 1102, 1109, 1110, 1112, 1113, 1114, 1118, 1119, 1125, 1126, 1127, 1132, 1134, 1135, 1139, 1142, 1143, 1144, 1148, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1183, 1184, 1185, 1186, 1187, 1190, 1191, 1192, 1195, 1198, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1209, 1211, 1212, 1213, 1214, 1217, 1218, 1221, 1222, 1226, 1227, 1228, 1230, 1231, 1232, 1233, 1234, 1237, 1238, 1239, 1241, 1242, 1251, 1253, 1256, 1258, 1259, 1268, 1272, 1278, 1280, 1301, 1311, 1312, 1314, 1315, 1317, 1319, 1320, 1322, 1324, 1325, 1326, 1330, 1331, 1332, 1334, 1335, 1336, 1337, 1338, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1369, 1370, 1371, 1372, 1373, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1386, 1387, 1390, 1392, 1395, 1404, 1405, 1409, 1412, 1414, 1415, 1416, 1417, 1419, 1420, 1421, 1427, 1433, 1434, 1443, 1444, 1445, 1449, 1460, 1462, 1468, 1471, 1472, 1473, 1474, 1476, 1484, 1488, 1492, 1493, 1494, 1495, 1496, 1499, 1500, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1527, 1528, 1531, 1532, 1534, 1539, 1540, 1542, 1543, 1544, 1545, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1565, 1567, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1586, 1587, 1590, 1592, 1595, 1596, 1597, 1609, 1612, 1614, 1617, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1632, 1633, 1634, 1635, 1639, 1640, 1641, 1642, 1643, 1644, 1651, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1682, 1686, 1688, 1690, 1695, 1697, 1703, 1705, 1711, 1712, 1713, 1723, 1725, 1727, 1738, 1744, 1745, 1753, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1775, 1776, 1778, 1779, 1780, 1787, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1813, 1814, 1815, 1816, 1817, 1820, 1821, 1822, 1824, 1825, 1827, 1828, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1869, 1870, 1872, 1874, 1876, 1877, 1878, 1880, 1881, 1882, 1886, 1890, 1892, 1899, 1903, 1905, 1908, 1912, 1914, 1921, 1928, 1930, 1931, 1932, 1934, 1935, 1936, 1940, 1941, 1942, 1943, 1948, 1961, 1966, 1969, 1970, 1971, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1986, 1988, 1989, 1990, 1993, 1994, 1995, 1996, 1997, 2002, 2006, 2008, 2012, 2014, 2018, 2020, 2028, 2029, 2030, 2032, 2033, 2034, 2036, 2038, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2050, 2051, 2052, 2055, 2057, 2059, 2060, 2061, 2063, 2064, 2067, 2068, 2071, 2072, 2073, 2074, 2076, 2078, 2082, 2083, 2084, 2087, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2102, 2103, 2104, 2105, 2106, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2119, 2122, 2124, 2126, 2127, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2154, 2155, 2157, 2158, 2159, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2170, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2212], "packag": [0, 3, 8, 9, 18, 19, 26, 36, 37, 39, 56, 64, 68, 1686, 2091, 2110, 2112, 2113, 2133, 2142, 2150, 2157, 2160, 2164, 2166, 2176, 2180, 2185, 2186, 2190, 2212], "introduc": [0, 20, 34, 39, 56, 58, 65, 771, 1228, 1238, 1240, 1241, 1253, 1387, 1531, 1550, 1596, 1697, 1919, 2091, 2096, 2128, 2132, 2133, 2143, 2149, 2154, 2158, 2159, 2166, 2171, 2177, 2183, 2192, 2195, 2200, 2202, 2205, 2212], "support": [0, 2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 25, 26, 27, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 51, 52, 56, 57, 58, 60, 63, 64, 65, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 258, 311, 321, 458, 583, 617, 696, 697, 698, 700, 704, 706, 707, 710, 740, 749, 750, 751, 783, 784, 785, 790, 796, 797, 798, 805, 806, 807, 808, 816, 832, 860, 889, 891, 892, 922, 925, 930, 933, 935, 936, 949, 950, 970, 971, 975, 978, 980, 982, 994, 995, 1002, 1014, 1019, 1022, 1036, 1057, 1086, 1087, 1089, 1108, 1139, 1141, 1144, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1189, 1190, 1191, 1192, 1194, 1195, 1197, 1208, 1212, 1272, 1273, 1285, 1311, 1318, 1326, 1330, 1334, 1335, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1387, 1405, 1409, 1413, 1418, 1419, 1444, 1465, 1507, 1508, 1509, 1510, 1511, 1512, 1519, 1522, 1523, 1526, 1546, 1567, 1585, 1586, 1620, 1628, 1630, 1632, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1678, 1680, 1686, 1697, 1703, 1738, 1756, 1757, 1759, 1770, 1779, 1780, 1827, 1832, 1839, 1840, 1841, 1843, 1859, 1880, 1892, 1911, 1912, 1933, 1936, 1937, 1966, 1967, 1970, 1973, 1974, 1991, 1994, 2020, 2022, 2024, 2034, 2036, 2042, 2043, 2044, 2090, 2091, 2093, 2095, 2097, 2098, 2100, 2106, 2109, 2111, 2113, 2114, 2118, 2127, 2128, 2129, 2130, 2133, 2137, 2139, 2141, 2142, 2144, 2145, 2147, 2148, 2149, 2150, 2152, 2156, 2157, 2158, 2159, 2164, 2165, 2166, 2170, 2172, 2174, 2175, 2176, 2177, 2178, 2180, 2181, 2183, 2185, 2188, 2190, 2191, 2193, 2194, 2196, 2197, 2203, 2204, 2205, 2206, 2212], "current": [0, 1, 2, 3, 4, 6, 7, 8, 10, 13, 14, 16, 19, 25, 30, 32, 34, 35, 36, 37, 38, 39, 44, 45, 51, 52, 56, 57, 58, 60, 61, 68, 69, 86, 87, 88, 150, 209, 221, 497, 498, 499, 623, 684, 685, 686, 687, 688, 690, 691, 692, 693, 752, 754, 792, 806, 808, 832, 889, 891, 892, 895, 909, 910, 920, 923, 925, 926, 927, 935, 938, 939, 940, 949, 971, 980, 1014, 1019, 1030, 1031, 1033, 1034, 1037, 1039, 1040, 1041, 1042, 1049, 1050, 1053, 1054, 1055, 1058, 1059, 1060, 1061, 1064, 1065, 1066, 1067, 1069, 1070, 1071, 1074, 1077, 1078, 1081, 1083, 1084, 1088, 1089, 1090, 1092, 1094, 1095, 1097, 1099, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1112, 1114, 1116, 1118, 1120, 1121, 1122, 1145, 1147, 1157, 1162, 1180, 1196, 1197, 1199, 1214, 1215, 1218, 1222, 1226, 1228, 1238, 1261, 1262, 1263, 1264, 1272, 1273, 1297, 1298, 1314, 1318, 1330, 1334, 1385, 1387, 1401, 1416, 1423, 1426, 1427, 1428, 1439, 1443, 1446, 1447, 1448, 1452, 1453, 1457, 1458, 1460, 1461, 1462, 1519, 1522, 1526, 1580, 1620, 1628, 1632, 1680, 1686, 1697, 1738, 1756, 1757, 1759, 1770, 1794, 1798, 1799, 1800, 1801, 1802, 1806, 1807, 1808, 1809, 1831, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1892, 1901, 1903, 1905, 1907, 1908, 1932, 1936, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1968, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 2011, 2022, 2024, 2029, 2035, 2036, 2050, 2053, 2054, 2057, 2058, 2060, 2061, 2064, 2068, 2069, 2071, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2082, 2084, 2085, 2087, 2088, 2089, 2093, 2095, 2096, 2097, 2098, 2100, 2103, 2108, 2109, 2114, 2117, 2122, 2126, 2127, 2130, 2136, 2139, 2140, 2142, 2143, 2144, 2147, 2148, 2154, 2156, 2157, 2158, 2159, 2161, 2164, 2166, 2167, 2171, 2173, 2174, 2176, 2177, 2180, 2181, 2189, 2192, 2194, 2195, 2200, 2201, 2202, 2204, 2205, 2206, 2207], "python": [0, 2, 4, 5, 10, 14, 16, 17, 20, 21, 25, 35, 38, 39, 40, 41, 44, 45, 48, 49, 52, 53, 57, 58, 60, 69, 71, 79, 80, 233, 352, 589, 625, 681, 792, 910, 938, 939, 940, 941, 942, 943, 945, 949, 950, 988, 989, 1001, 1002, 1004, 1019, 1057, 1080, 1086, 1087, 1089, 1139, 1144, 1162, 1164, 1192, 1198, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1290, 1312, 1314, 1315, 1317, 1318, 1319, 1325, 1326, 1330, 1386, 1581, 1582, 1590, 1591, 1644, 1738, 1770, 1886, 1908, 1912, 1932, 1933, 1968, 2036, 2037, 2045, 2067, 2091, 2102, 2104, 2110, 2112, 2114, 2116, 2117, 2127, 2128, 2129, 2130, 2132, 2134, 2135, 2140, 2144, 2147, 2148, 2149, 2150, 2158, 2161, 2165, 2166, 2167, 2168, 2174, 2177, 2178, 2183, 2186, 2188, 2190, 2191, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2201, 2204, 2205, 2206, 2207], "provid": [1, 2, 4, 6, 8, 9, 10, 13, 16, 17, 19, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 49, 51, 52, 54, 55, 56, 57, 58, 60, 64, 68, 69, 71, 81, 82, 150, 486, 603, 681, 700, 746, 749, 750, 751, 756, 757, 759, 767, 768, 771, 775, 800, 802, 814, 815, 829, 843, 871, 888, 923, 939, 941, 942, 943, 958, 969, 981, 986, 989, 1008, 1027, 1049, 1057, 1101, 1144, 1164, 1201, 1213, 1228, 1238, 1268, 1276, 1277, 1311, 1314, 1321, 1322, 1326, 1328, 1330, 1345, 1362, 1387, 1419, 1510, 1511, 1512, 1515, 1531, 1532, 1540, 1545, 1550, 1551, 1576, 1577, 1578, 1580, 1586, 1587, 1590, 1596, 1598, 1609, 1624, 1625, 1626, 1627, 1628, 1658, 1659, 1738, 1757, 1770, 1779, 1780, 1795, 1814, 1822, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1872, 1875, 1877, 1882, 1918, 1928, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 2022, 2024, 2034, 2045, 2091, 2093, 2095, 2096, 2100, 2102, 2103, 2106, 2109, 2114, 2115, 2116, 2117, 2122, 2130, 2132, 2133, 2134, 2138, 2142, 2143, 2145, 2147, 2150, 2154, 2156, 2157, 2158, 2161, 2162, 2164, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2185, 2188, 2189, 2190, 2191, 2192, 2193, 2195, 2197, 2198, 2202, 2203, 2204, 2205, 2207, 2210], "conveni": [1, 4, 8, 16, 30, 48, 51, 52, 53, 60, 66, 1213, 1228, 1372, 1760, 1936, 2034, 2036, 2045, 2091, 2095, 2104, 2117, 2126, 2127, 2130, 2133, 2139, 2140, 2142, 2158, 2165, 2186, 2189, 2191, 2192, 2193, 2198, 2204], "method": [1, 4, 8, 10, 16, 17, 20, 25, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 43, 49, 51, 56, 60, 67, 68, 69, 71, 79, 80, 87, 221, 222, 233, 323, 415, 486, 487, 488, 497, 498, 499, 520, 614, 806, 811, 814, 830, 831, 832, 866, 871, 884, 904, 905, 906, 922, 923, 930, 931, 932, 933, 934, 935, 936, 954, 955, 969, 1080, 1195, 1219, 1226, 1268, 1312, 1314, 1315, 1317, 1318, 1319, 1325, 1326, 1330, 1331, 1332, 1360, 1378, 1379, 1386, 1387, 1473, 1476, 1484, 1492, 1494, 1495, 1521, 1522, 1537, 1580, 1581, 1582, 1586, 1590, 1591, 1597, 1599, 1609, 1686, 1760, 1770, 1775, 1788, 1790, 1793, 1795, 1797, 1800, 1803, 1804, 1806, 1807, 1808, 1809, 1810, 1816, 1821, 1837, 1839, 1840, 1842, 1858, 1877, 1878, 1893, 1975, 1990, 1994, 1995, 2034, 2091, 2093, 2096, 2097, 2100, 2104, 2106, 2109, 2114, 2115, 2116, 2122, 2124, 2126, 2127, 2130, 2133, 2134, 2135, 2138, 2142, 2144, 2147, 2150, 2157, 2158, 2161, 2163, 2166, 2168, 2173, 2174, 2176, 2177, 2180, 2183, 2190, 2192, 2193, 2195, 2202, 2204, 2205, 2206], "where": [1, 2, 3, 4, 5, 8, 9, 10, 13, 16, 17, 25, 26, 30, 34, 35, 36, 37, 38, 39, 41, 44, 49, 51, 52, 54, 55, 56, 57, 58, 60, 62, 63, 65, 69, 86, 88, 153, 223, 254, 400, 402, 486, 681, 704, 706, 707, 710, 746, 769, 771, 792, 839, 840, 860, 907, 925, 929, 938, 940, 954, 961, 971, 980, 986, 993, 994, 995, 1002, 1014, 1023, 1027, 1040, 1053, 1056, 1123, 1124, 1127, 1131, 1149, 1160, 1161, 1163, 1166, 1167, 1169, 1170, 1172, 1173, 1174, 1176, 1177, 1179, 1181, 1206, 1207, 1208, 1212, 1213, 1226, 1227, 1257, 1271, 1272, 1273, 1274, 1303, 1304, 1306, 1307, 1310, 1311, 1312, 1315, 1328, 1334, 1335, 1336, 1339, 1344, 1345, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1382, 1383, 1384, 1386, 1387, 1392, 1395, 1402, 1403, 1404, 1405, 1409, 1412, 1414, 1415, 1416, 1417, 1420, 1443, 1466, 1471, 1472, 1474, 1477, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1521, 1522, 1523, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1610, 1611, 1612, 1613, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1657, 1659, 1669, 1670, 1677, 1682, 1684, 1685, 1703, 1704, 1722, 1724, 1725, 1728, 1729, 1731, 1738, 1741, 1769, 1770, 1773, 1774, 1779, 1780, 1787, 1814, 1815, 1816, 1817, 1826, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1880, 1890, 1892, 1893, 1913, 1914, 1949, 1955, 1956, 1961, 1965, 1970, 1971, 1972, 1976, 1977, 1978, 1979, 1980, 1981, 1988, 1989, 1990, 1993, 1994, 1995, 2011, 2020, 2021, 2022, 2023, 2024, 2029, 2030, 2040, 2041, 2042, 2043, 2044, 2045, 2093, 2094, 2096, 2097, 2100, 2102, 2103, 2104, 2107, 2114, 2117, 2122, 2124, 2126, 2127, 2128, 2130, 2133, 2134, 2135, 2136, 2138, 2142, 2144, 2145, 2146, 2147, 2154, 2155, 2157, 2158, 2159, 2161, 2164, 2166, 2168, 2171, 2172, 2173, 2174, 2176, 2182, 2186, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2199, 2202, 2205, 2206, 2207], "some": [1, 2, 4, 8, 9, 10, 16, 19, 21, 24, 25, 26, 30, 32, 34, 36, 37, 38, 39, 41, 44, 52, 54, 56, 57, 58, 60, 63, 65, 66, 68, 69, 477, 486, 496, 567, 700, 759, 895, 945, 965, 1002, 1014, 1037, 1078, 1097, 1101, 1104, 1144, 1165, 1167, 1175, 1176, 1177, 1192, 1202, 1213, 1217, 1224, 1228, 1240, 1241, 1311, 1312, 1314, 1315, 1325, 1328, 1330, 1360, 1378, 1384, 1409, 1416, 1419, 1484, 1488, 1492, 1493, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1539, 1542, 1543, 1544, 1545, 1546, 1550, 1571, 1572, 1580, 1583, 1584, 1585, 1587, 1594, 1596, 1597, 1612, 1613, 1629, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1671, 1698, 1703, 1722, 1725, 1730, 1738, 1760, 1770, 1772, 1773, 1774, 1787, 1820, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1877, 1892, 1912, 1936, 1942, 1956, 1994, 2036, 2045, 2076, 2091, 2093, 2094, 2095, 2096, 2097, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2114, 2115, 2116, 2117, 2126, 2127, 2130, 2133, 2134, 2135, 2136, 2138, 2140, 2142, 2144, 2145, 2146, 2147, 2148, 2154, 2157, 2158, 2159, 2161, 2162, 2164, 2166, 2167, 2168, 2171, 2173, 2176, 2180, 2183, 2184, 2185, 2186, 2191, 2192, 2193, 2194, 2196, 2197, 2200, 2201, 2202, 2203, 2204, 2205], "oper": [1, 3, 5, 6, 8, 9, 13, 14, 16, 17, 19, 20, 25, 29, 32, 36, 37, 38, 39, 40, 45, 48, 49, 51, 52, 57, 61, 66, 68, 69, 71, 254, 313, 321, 335, 352, 402, 445, 446, 447, 448, 449, 486, 488, 493, 496, 499, 513, 515, 517, 589, 681, 697, 700, 752, 753, 754, 758, 759, 768, 769, 779, 780, 790, 796, 805, 806, 808, 809, 814, 842, 851, 889, 891, 892, 895, 919, 921, 930, 931, 933, 935, 936, 945, 956, 970, 971, 973, 975, 978, 980, 982, 984, 989, 992, 999, 1002, 1004, 1013, 1015, 1019, 1021, 1040, 1057, 1077, 1086, 1119, 1123, 1124, 1125, 1126, 1139, 1144, 1145, 1146, 1147, 1157, 1162, 1180, 1192, 1195, 1198, 1199, 1200, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1213, 1215, 1216, 1221, 1262, 1266, 1272, 1273, 1314, 1325, 1326, 1330, 1331, 1334, 1344, 1357, 1367, 1370, 1371, 1384, 1385, 1394, 1401, 1409, 1414, 1419, 1433, 1434, 1471, 1474, 1488, 1493, 1498, 1499, 1500, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1526, 1527, 1528, 1534, 1536, 1537, 1538, 1539, 1541, 1542, 1543, 1544, 1546, 1552, 1566, 1571, 1576, 1577, 1578, 1580, 1593, 1595, 1599, 1600, 1601, 1608, 1623, 1624, 1626, 1628, 1632, 1654, 1655, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1671, 1672, 1673, 1674, 1678, 1679, 1681, 1682, 1686, 1690, 1697, 1703, 1705, 1712, 1713, 1723, 1725, 1729, 1738, 1744, 1745, 1756, 1757, 1758, 1759, 1769, 1770, 1773, 1774, 1814, 1816, 1822, 1827, 1831, 1832, 1857, 1863, 1874, 1877, 1880, 1889, 1890, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1912, 1918, 1935, 1936, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1967, 1969, 1970, 1971, 1972, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1993, 2011, 2029, 2033, 2034, 2036, 2045, 2048, 2089, 2090, 2092, 2093, 2097, 2100, 2104, 2111, 2122, 2125, 2126, 2128, 2129, 2130, 2132, 2134, 2135, 2141, 2142, 2143, 2144, 2145, 2146, 2149, 2150, 2157, 2159, 2160, 2162, 2164, 2165, 2166, 2167, 2170, 2172, 2173, 2174, 2175, 2178, 2189, 2191, 2192, 2193, 2195, 2196, 2197, 2198, 2199, 2203, 2205], "us": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 21, 22, 23, 25, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 43, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 71, 79, 80, 81, 82, 86, 87, 88, 97, 119, 150, 154, 173, 191, 208, 319, 321, 335, 342, 343, 406, 415, 435, 448, 458, 486, 487, 488, 496, 499, 513, 517, 520, 544, 557, 583, 584, 585, 587, 588, 617, 681, 684, 687, 693, 697, 700, 723, 724, 725, 726, 727, 728, 731, 740, 741, 742, 743, 744, 746, 759, 768, 771, 779, 780, 783, 784, 785, 790, 792, 796, 797, 798, 803, 806, 807, 808, 809, 811, 814, 817, 822, 830, 831, 832, 834, 837, 839, 840, 841, 842, 843, 846, 851, 852, 858, 859, 860, 861, 865, 884, 888, 889, 891, 892, 895, 908, 909, 910, 919, 920, 921, 923, 925, 926, 927, 928, 929, 930, 932, 933, 935, 936, 938, 939, 940, 941, 944, 945, 946, 947, 949, 950, 954, 955, 958, 962, 965, 970, 971, 972, 980, 982, 983, 990, 992, 1002, 1004, 1005, 1010, 1013, 1014, 1015, 1019, 1020, 1023, 1025, 1037, 1039, 1040, 1041, 1046, 1047, 1049, 1052, 1055, 1064, 1065, 1066, 1069, 1070, 1071, 1073, 1078, 1082, 1086, 1088, 1089, 1090, 1092, 1094, 1095, 1101, 1102, 1112, 1114, 1115, 1120, 1125, 1126, 1127, 1136, 1144, 1145, 1146, 1147, 1157, 1158, 1159, 1162, 1164, 1172, 1174, 1178, 1180, 1187, 1189, 1192, 1196, 1199, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1218, 1221, 1226, 1227, 1228, 1229, 1234, 1237, 1238, 1241, 1242, 1245, 1254, 1258, 1259, 1265, 1266, 1268, 1272, 1273, 1274, 1275, 1289, 1301, 1311, 1312, 1314, 1315, 1318, 1319, 1320, 1321, 1322, 1324, 1325, 1326, 1327, 1328, 1330, 1331, 1332, 1334, 1336, 1338, 1346, 1350, 1351, 1353, 1354, 1355, 1357, 1358, 1359, 1360, 1361, 1362, 1367, 1368, 1369, 1371, 1372, 1378, 1379, 1380, 1384, 1385, 1386, 1387, 1392, 1395, 1401, 1404, 1405, 1408, 1409, 1414, 1415, 1416, 1419, 1426, 1427, 1443, 1466, 1471, 1473, 1474, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1518, 1519, 1520, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1531, 1532, 1533, 1534, 1539, 1540, 1542, 1543, 1544, 1545, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1566, 1567, 1568, 1573, 1574, 1575, 1576, 1577, 1580, 1582, 1586, 1587, 1588, 1589, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1612, 1614, 1617, 1620, 1628, 1629, 1630, 1631, 1633, 1636, 1637, 1638, 1639, 1640, 1641, 1644, 1651, 1653, 1654, 1655, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1682, 1683, 1686, 1688, 1695, 1697, 1698, 1705, 1711, 1712, 1713, 1718, 1723, 1725, 1731, 1738, 1742, 1744, 1745, 1753, 1755, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1778, 1779, 1780, 1785, 1787, 1788, 1789, 1790, 1791, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1814, 1815, 1816, 1820, 1821, 1822, 1824, 1825, 1827, 1828, 1831, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1890, 1892, 1893, 1894, 1897, 1898, 1899, 1901, 1903, 1905, 1907, 1908, 1914, 1921, 1924, 1929, 1930, 1932, 1933, 1934, 1936, 1938, 1939, 1941, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1960, 1965, 1968, 1969, 1971, 1972, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 1993, 1994, 1995, 2011, 2015, 2018, 2022, 2024, 2029, 2032, 2033, 2034, 2036, 2042, 2045, 2050, 2057, 2058, 2060, 2061, 2071, 2073, 2074, 2082, 2088, 2089, 2091, 2092, 2093, 2094, 2096, 2097, 2098, 2100, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2114, 2115, 2116, 2117, 2118, 2122, 2123, 2124, 2126, 2129, 2132, 2134, 2135, 2136, 2137, 2139, 2140, 2141, 2142, 2144, 2145, 2146, 2147, 2148, 2149, 2151, 2156, 2159, 2160, 2162, 2164, 2165, 2166, 2167, 2168, 2172, 2173, 2174, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2198, 2199, 2200, 2201, 2203, 2204, 2206, 2209, 2212], "float": [1, 2, 4, 13, 21, 25, 26, 29, 30, 34, 35, 36, 39, 41, 45, 54, 56, 57, 58, 60, 67, 69, 86, 153, 154, 219, 313, 315, 317, 321, 333, 400, 475, 481, 499, 696, 698, 703, 705, 709, 743, 746, 749, 750, 751, 755, 756, 757, 759, 766, 767, 772, 773, 774, 775, 776, 781, 782, 783, 784, 785, 786, 788, 790, 791, 792, 796, 805, 806, 807, 814, 832, 837, 857, 866, 868, 882, 887, 888, 891, 892, 895, 910, 949, 950, 971, 972, 980, 987, 990, 994, 995, 1004, 1016, 1022, 1023, 1027, 1036, 1073, 1115, 1127, 1138, 1139, 1145, 1146, 1147, 1149, 1162, 1180, 1189, 1190, 1191, 1192, 1194, 1226, 1228, 1248, 1257, 1261, 1271, 1272, 1273, 1276, 1277, 1296, 1303, 1304, 1306, 1307, 1308, 1309, 1312, 1314, 1330, 1331, 1334, 1338, 1340, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1387, 1392, 1401, 1403, 1405, 1414, 1438, 1443, 1465, 1466, 1470, 1471, 1472, 1473, 1474, 1477, 1480, 1484, 1488, 1494, 1495, 1496, 1498, 1501, 1502, 1513, 1514, 1515, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1527, 1528, 1533, 1534, 1535, 1538, 1539, 1540, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1566, 1568, 1572, 1580, 1585, 1586, 1588, 1589, 1594, 1595, 1599, 1602, 1603, 1604, 1605, 1606, 1612, 1617, 1618, 1620, 1623, 1624, 1626, 1628, 1629, 1630, 1633, 1634, 1635, 1668, 1669, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1683, 1688, 1695, 1697, 1723, 1725, 1730, 1738, 1757, 1769, 1770, 1776, 1777, 1778, 1782, 1784, 1785, 1788, 1798, 1799, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1816, 1817, 1821, 1827, 1828, 1833, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1854, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1886, 1889, 1893, 1894, 1895, 1896, 1908, 1912, 1913, 1933, 1934, 1937, 1940, 1949, 1950, 1952, 1953, 1955, 1991, 1994, 1998, 2002, 2018, 2020, 2033, 2093, 2094, 2095, 2096, 2097, 2100, 2103, 2109, 2114, 2115, 2117, 2118, 2122, 2124, 2126, 2130, 2133, 2135, 2141, 2142, 2145, 2154, 2155, 2158, 2159, 2161, 2162, 2166, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2191, 2195, 2197, 2199, 2203, 2204, 2210], "datatyp": [1, 21, 69, 910, 1311, 1314, 1580, 1773, 1774, 1877, 1936, 2145, 2154, 2171], "other": [1, 2, 3, 4, 5, 6, 8, 9, 10, 16, 17, 20, 21, 25, 26, 31, 32, 34, 35, 36, 37, 39, 40, 41, 44, 48, 49, 51, 52, 56, 57, 58, 60, 61, 63, 65, 66, 68, 69, 88, 97, 98, 113, 129, 130, 133, 145, 146, 149, 150, 159, 160, 165, 166, 196, 197, 198, 207, 234, 239, 243, 244, 245, 255, 274, 275, 282, 283, 284, 285, 291, 292, 293, 294, 295, 296, 303, 304, 307, 308, 309, 310, 313, 315, 321, 324, 344, 352, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 378, 379, 394, 395, 408, 412, 415, 438, 439, 450, 451, 455, 456, 487, 488, 498, 520, 561, 562, 563, 564, 580, 583, 616, 617, 618, 621, 622, 681, 696, 705, 749, 750, 751, 752, 753, 754, 771, 829, 851, 891, 895, 901, 908, 909, 914, 920, 923, 925, 926, 927, 935, 944, 945, 946, 947, 949, 950, 954, 955, 974, 975, 977, 978, 979, 981, 986, 1002, 1009, 1022, 1036, 1037, 1040, 1046, 1053, 1066, 1078, 1089, 1132, 1138, 1139, 1140, 1148, 1149, 1150, 1164, 1171, 1189, 1190, 1191, 1192, 1195, 1202, 1203, 1204, 1205, 1208, 1212, 1227, 1228, 1230, 1255, 1256, 1257, 1269, 1270, 1271, 1280, 1281, 1283, 1284, 1289, 1291, 1303, 1312, 1314, 1318, 1326, 1335, 1337, 1338, 1339, 1341, 1342, 1347, 1351, 1365, 1367, 1370, 1371, 1384, 1392, 1393, 1394, 1396, 1398, 1399, 1402, 1403, 1409, 1412, 1413, 1417, 1418, 1422, 1426, 1465, 1467, 1477, 1480, 1507, 1508, 1509, 1510, 1511, 1512, 1514, 1516, 1526, 1531, 1533, 1545, 1580, 1581, 1590, 1609, 1624, 1628, 1632, 1641, 1661, 1662, 1663, 1688, 1697, 1738, 1757, 1760, 1770, 1776, 1777, 1778, 1779, 1780, 1785, 1804, 1813, 1825, 1829, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1869, 1870, 1876, 1877, 1878, 1880, 1908, 1912, 1928, 1933, 1936, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1974, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1991, 1992, 2011, 2017, 2021, 2023, 2029, 2042, 2043, 2048, 2049, 2058, 2091, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2106, 2108, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2142, 2143, 2144, 2145, 2147, 2150, 2154, 2157, 2161, 2162, 2166, 2167, 2168, 2172, 2173, 2176, 2177, 2178, 2185, 2189, 2191, 2192, 2193, 2195, 2196, 2197, 2199, 2202, 2203, 2204, 2205, 2206, 2209], "lower": [1, 2, 9, 14, 26, 30, 39, 56, 57, 806, 808, 889, 981, 986, 993, 994, 995, 997, 1158, 1159, 1228, 1232, 1275, 1276, 1344, 1351, 1353, 1361, 1362, 1369, 1372, 1377, 1415, 1466, 1473, 1484, 1599, 1640, 1641, 1642, 1661, 1662, 1663, 1736, 1737, 1738, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1874, 1891, 1893, 1913, 1928, 1936, 1973, 2020, 2021, 2022, 2093, 2094, 2096, 2104, 2111, 2118, 2124, 2127, 2142, 2147, 2151, 2155, 2161, 2172, 2178, 2199, 2204, 2205], "point": [1, 2, 8, 9, 10, 13, 25, 26, 29, 31, 32, 34, 35, 36, 41, 48, 51, 52, 57, 60, 69, 86, 87, 88, 153, 154, 321, 333, 339, 481, 486, 499, 709, 749, 750, 751, 752, 753, 754, 755, 760, 761, 762, 763, 764, 765, 766, 767, 770, 772, 773, 774, 775, 776, 786, 788, 790, 791, 792, 796, 808, 814, 837, 839, 840, 841, 846, 857, 882, 891, 892, 895, 910, 939, 941, 942, 943, 949, 950, 971, 972, 980, 1002, 1022, 1023, 1027, 1092, 1094, 1104, 1109, 1110, 1145, 1146, 1147, 1190, 1191, 1192, 1261, 1268, 1272, 1273, 1277, 1296, 1311, 1314, 1330, 1331, 1338, 1340, 1361, 1362, 1385, 1387, 1392, 1401, 1414, 1443, 1471, 1473, 1480, 1489, 1490, 1491, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1526, 1573, 1574, 1575, 1580, 1632, 1633, 1651, 1677, 1686, 1697, 1738, 1757, 1770, 1779, 1780, 1827, 1836, 1875, 1877, 1893, 1894, 1895, 1899, 1908, 1921, 1933, 1934, 1940, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2033, 2034, 2073, 2074, 2093, 2095, 2096, 2097, 2100, 2109, 2118, 2124, 2126, 2127, 2130, 2132, 2136, 2137, 2138, 2142, 2145, 2159, 2161, 2162, 2164, 2166, 2167, 2171, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2190, 2192, 2193, 2195, 2197, 2200, 2203, 2204, 2207, 2210], "lower_precision_fp": 1, "half": [1, 2, 12, 26, 39, 617, 1016, 1158, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1314, 1377, 1383, 1507, 1508, 1509, 1510, 1511, 1512, 1527, 1528, 1530, 1580, 1681, 1682, 1685, 1738, 1779, 1780, 1833, 1865, 1877, 1921, 1990, 2115, 2142, 2145, 2171, 2173, 2174, 2177], "like": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 21, 25, 26, 30, 32, 34, 36, 37, 38, 39, 49, 52, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 69, 336, 486, 589, 617, 771, 806, 810, 834, 871, 890, 895, 908, 930, 933, 935, 949, 950, 969, 971, 980, 1013, 1019, 1086, 1087, 1097, 1139, 1144, 1145, 1165, 1187, 1190, 1191, 1198, 1202, 1205, 1206, 1207, 1213, 1228, 1230, 1238, 1254, 1272, 1273, 1312, 1314, 1315, 1322, 1325, 1330, 1334, 1361, 1362, 1373, 1386, 1484, 1492, 1523, 1526, 1542, 1543, 1544, 1580, 1581, 1582, 1590, 1591, 1609, 1632, 1639, 1680, 1698, 1756, 1760, 1770, 1772, 1773, 1774, 1788, 1813, 1831, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1886, 1901, 1905, 1924, 1932, 1933, 1936, 1994, 2008, 2034, 2045, 2076, 2089, 2091, 2092, 2093, 2095, 2096, 2100, 2103, 2104, 2114, 2115, 2116, 2117, 2126, 2127, 2130, 2134, 2135, 2136, 2138, 2139, 2140, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2154, 2157, 2159, 2161, 2164, 2166, 2167, 2170, 2171, 2173, 2174, 2178, 2180, 2182, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2201, 2202, 2203, 2204, 2205, 2206, 2207], "linear": [1, 3, 10, 26, 30, 31, 34, 35, 36, 38, 39, 56, 57, 60, 62, 64, 66, 69, 71, 431, 472, 473, 474, 475, 476, 479, 722, 731, 739, 740, 776, 805, 806, 807, 809, 829, 884, 888, 889, 891, 892, 940, 995, 1144, 1201, 1203, 1211, 1213, 1268, 1314, 1318, 1326, 1340, 1346, 1351, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1375, 1377, 1405, 1473, 1492, 1498, 1521, 1529, 1530, 1538, 1565, 1580, 1582, 1596, 1598, 1599, 1600, 1608, 1610, 1617, 1620, 1624, 1626, 1628, 1631, 1633, 1675, 1684, 1685, 1697, 1732, 1741, 1746, 1757, 1760, 1770, 1783, 1784, 1787, 1788, 1789, 1793, 1797, 1803, 1804, 1805, 1806, 1808, 1809, 1810, 1811, 1812, 1820, 1821, 1824, 1869, 1872, 1877, 1878, 1882, 1893, 1974, 2033, 2045, 2094, 2095, 2101, 2104, 2106, 2108, 2124, 2130, 2132, 2133, 2135, 2136, 2142, 2147, 2150, 2154, 2155, 2157, 2161, 2162, 2163, 2164, 2166, 2185, 2186, 2192, 2202, 2204, 2205], "layer": [1, 9, 26, 30, 32, 34, 35, 36, 38, 60, 63, 745, 746, 771, 871, 888, 958, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1518, 1519, 1520, 1524, 1531, 1532, 1534, 1542, 1543, 1544, 1550, 1551, 1552, 1565, 1567, 1573, 1574, 1575, 1586, 1587, 1595, 1596, 1598, 1609, 1620, 1624, 1625, 1626, 1627, 1628, 1700, 1735, 1769, 1770, 1779, 1780, 1787, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 2124, 2130, 2133, 2135, 2136, 2140, 2142, 2147, 2157, 2161, 2162, 2164, 2171, 2182], "convolut": [1, 2, 3, 56, 749, 750, 751, 752, 753, 754, 783, 784, 785, 1002, 1324, 1507, 1508, 1509, 1510, 1511, 1512, 1518, 1519, 1520, 1524, 1556, 1557, 1558, 1559, 1560, 1561, 1592, 1593, 1599, 1629, 1630, 1632, 1661, 1662, 1663, 1664, 1665, 1666, 1685, 1686, 1779, 1780, 1781, 1782, 1936, 2094, 2106, 2124, 2129, 2130, 2138, 2142, 2155, 2159, 2161, 2164, 2199], "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 48, 49, 51, 52, 54, 56, 57, 60, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 74, 76, 77, 80, 86, 87, 88, 97, 150, 233, 254, 319, 321, 335, 336, 339, 377, 402, 448, 471, 481, 486, 499, 513, 517, 544, 580, 589, 617, 681, 700, 701, 702, 708, 746, 767, 771, 772, 774, 775, 776, 790, 793, 794, 796, 797, 798, 805, 806, 807, 808, 809, 813, 814, 829, 830, 831, 832, 834, 837, 839, 840, 841, 846, 869, 884, 888, 889, 890, 891, 892, 895, 904, 905, 916, 917, 918, 920, 923, 930, 933, 935, 936, 938, 939, 940, 941, 942, 943, 945, 949, 950, 956, 958, 969, 971, 980, 981, 983, 984, 986, 989, 1002, 1004, 1009, 1014, 1015, 1016, 1019, 1022, 1023, 1026, 1027, 1039, 1040, 1045, 1047, 1052, 1055, 1057, 1067, 1080, 1086, 1089, 1090, 1101, 1105, 1112, 1119, 1127, 1132, 1136, 1139, 1144, 1145, 1146, 1147, 1150, 1160, 1161, 1162, 1163, 1165, 1167, 1172, 1174, 1180, 1183, 1185, 1186, 1190, 1191, 1192, 1196, 1201, 1202, 1207, 1209, 1211, 1212, 1213, 1214, 1218, 1221, 1224, 1226, 1227, 1228, 1232, 1234, 1237, 1238, 1241, 1251, 1258, 1268, 1272, 1273, 1275, 1277, 1291, 1303, 1304, 1306, 1307, 1310, 1311, 1312, 1314, 1315, 1318, 1321, 1322, 1325, 1328, 1330, 1331, 1336, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1367, 1369, 1370, 1371, 1372, 1373, 1375, 1376, 1377, 1378, 1379, 1381, 1384, 1385, 1386, 1387, 1396, 1397, 1398, 1399, 1401, 1402, 1404, 1406, 1407, 1409, 1412, 1415, 1416, 1417, 1420, 1422, 1427, 1443, 1445, 1466, 1470, 1471, 1472, 1473, 1474, 1484, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1501, 1502, 1503, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1518, 1519, 1520, 1523, 1524, 1526, 1531, 1532, 1533, 1534, 1539, 1542, 1543, 1544, 1545, 1546, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1594, 1596, 1598, 1609, 1612, 1613, 1614, 1620, 1624, 1626, 1628, 1629, 1630, 1632, 1633, 1639, 1641, 1642, 1643, 1651, 1657, 1658, 1659, 1669, 1670, 1677, 1678, 1679, 1680, 1686, 1697, 1698, 1722, 1725, 1727, 1730, 1738, 1756, 1757, 1758, 1759, 1760, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1778, 1779, 1780, 1786, 1787, 1788, 1791, 1793, 1800, 1813, 1817, 1820, 1821, 1822, 1823, 1824, 1825, 1827, 1828, 1833, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1852, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1868, 1871, 1872, 1877, 1886, 1892, 1893, 1899, 1908, 1911, 1912, 1919, 1921, 1932, 1933, 1936, 1965, 1966, 1968, 1970, 1971, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1986, 1989, 1990, 1993, 1994, 2006, 2008, 2012, 2014, 2015, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2029, 2033, 2034, 2036, 2039, 2040, 2041, 2045, 2050, 2052, 2071, 2078, 2082, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2102, 2103, 2104, 2106, 2108, 2109, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2121, 2122, 2123, 2124, 2126, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2152, 2154, 2155, 2156, 2157, 2159, 2161, 2162, 2164, 2165, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2181, 2183, 2184, 2185, 2186, 2188, 2189, 2190, 2191, 2193, 2194, 2196, 2197, 2198, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2210], "much": [1, 5, 8, 10, 17, 25, 26, 56, 150, 923, 939, 944, 1101, 1218, 1227, 1350, 1351, 1378, 1387, 1523, 1770, 1804, 1872, 2078, 2093, 2127, 2130, 2136, 2138, 2142, 2147, 2158, 2166, 2167, 2171, 2180, 2191, 2192, 2195, 2209], "faster": [1, 3, 9, 13, 25, 26, 30, 939, 949, 950, 1004, 1201, 1243, 1244, 1344, 1345, 1350, 1351, 1355, 1360, 1368, 1370, 1372, 1375, 1378, 1380, 1384, 1387, 1597, 1614, 1727, 1738, 1744, 1770, 1776, 1777, 1778, 1785, 1787, 1838, 1840, 1841, 1858, 1859, 1936, 1976, 1977, 1978, 1980, 1981, 2005, 2104, 2106, 2127, 2130, 2138, 2157, 2161, 2171, 2173, 2176, 2183, 2193, 2195, 2200], "reduct": [1, 3, 13, 30, 34, 37, 38, 60, 321, 513, 517, 1002, 1360, 1392, 1473, 1492, 1493, 1499, 1513, 1515, 1523, 1533, 1539, 1540, 1545, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1630, 1658, 1659, 1667, 1669, 1670, 1678, 1683, 1694, 1695, 1698, 1699, 1710, 1718, 1719, 1720, 1721, 1722, 1730, 1742, 1743, 1754, 1755, 1770, 1893, 1970, 2094, 2115, 2122, 2132, 2138, 2158, 2161, 2198, 2205], "often": [1, 3, 5, 8, 9, 16, 25, 30, 36, 39, 52, 60, 63, 69, 150, 923, 944, 1232, 1241, 1330, 1361, 1362, 1371, 1420, 1522, 1542, 1543, 1544, 1651, 1659, 1677, 1686, 1760, 1787, 1874, 2096, 2104, 2127, 2130, 2135, 2140, 2142, 2144, 2145, 2146, 2158, 2166, 2176, 2192, 2194, 2195, 2202, 2205], "requir": [1, 2, 6, 9, 10, 13, 14, 16, 17, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 50, 51, 56, 57, 58, 60, 63, 65, 68, 69, 119, 150, 221, 335, 458, 486, 488, 496, 513, 515, 517, 560, 806, 808, 842, 851, 910, 919, 923, 930, 932, 935, 936, 938, 939, 940, 941, 942, 943, 944, 1002, 1004, 1019, 1037, 1041, 1100, 1144, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1185, 1186, 1209, 1213, 1255, 1311, 1328, 1354, 1385, 1387, 1401, 1515, 1522, 1523, 1624, 1625, 1626, 1627, 1628, 1630, 1678, 1738, 1760, 1770, 1772, 1791, 1793, 1795, 1838, 1843, 1880, 1978, 1990, 2033, 2045, 2091, 2093, 2096, 2098, 2100, 2103, 2106, 2114, 2116, 2117, 2122, 2126, 2127, 2129, 2130, 2132, 2133, 2135, 2136, 2137, 2138, 2139, 2140, 2142, 2144, 2146, 2147, 2150, 2151, 2152, 2154, 2156, 2157, 2158, 2161, 2162, 2166, 2167, 2168, 2171, 2173, 2174, 2176, 2178, 2182, 2183, 2184, 2185, 2189, 2190, 2192, 2193, 2194, 2195, 2200, 2202, 2204, 2206], "dynam": [1, 14, 16, 17, 25, 34, 57, 71, 72, 73, 76, 77, 79, 82, 83, 681, 740, 744, 771, 772, 773, 774, 775, 776, 807, 814, 830, 843, 851, 856, 874, 880, 881, 882, 883, 888, 889, 1002, 1221, 1222, 1224, 1227, 1234, 1322, 1328, 1330, 1386, 1787, 2095, 2096, 2097, 2117, 2124, 2130, 2142, 2145, 2147, 2149, 2150, 2154, 2157, 2158, 2162, 2183, 2184, 2185, 2192, 2193, 2195, 2201, 2205], "rang": [1, 2, 4, 13, 25, 30, 31, 35, 36, 37, 39, 41, 52, 55, 56, 57, 64, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 87, 301, 481, 695, 772, 774, 776, 808, 837, 839, 840, 841, 842, 846, 851, 852, 915, 972, 997, 1007, 1073, 1106, 1107, 1115, 1144, 1194, 1211, 1226, 1232, 1238, 1275, 1276, 1277, 1381, 1392, 1407, 1416, 1438, 1473, 1484, 1515, 1525, 1527, 1528, 1532, 1538, 1551, 1570, 1582, 1587, 1591, 1596, 1598, 1614, 1615, 1616, 1620, 1681, 1682, 1686, 1744, 1770, 1777, 1861, 1862, 1864, 1865, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1893, 1972, 2031, 2032, 2093, 2094, 2096, 2122, 2127, 2129, 2130, 2135, 2137, 2142, 2144, 2145, 2154, 2155, 2157, 2159, 2161, 2164, 2165, 2172, 2174, 2176, 2177, 2178, 2180, 2189, 2190, 2191, 2193, 2202, 2204, 2205], "tri": [1, 3, 4, 8, 25, 39, 44, 69, 580, 1314, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 2095, 2096, 2130, 2135, 2154, 2158, 2192, 2194, 2195, 2197, 2204], "match": [1, 2, 4, 14, 30, 32, 35, 36, 37, 39, 51, 56, 58, 60, 69, 71, 79, 80, 86, 150, 313, 315, 321, 473, 474, 499, 500, 580, 583, 687, 690, 691, 692, 693, 704, 710, 790, 806, 807, 808, 884, 908, 923, 944, 949, 950, 1019, 1036, 1039, 1053, 1054, 1056, 1089, 1136, 1144, 1201, 1213, 1228, 1291, 1314, 1328, 1330, 1347, 1386, 1408, 1443, 1514, 1523, 1580, 1586, 1633, 1658, 1659, 1697, 1724, 1731, 1738, 1757, 1770, 1793, 1822, 1828, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1894, 1928, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 2013, 2029, 2045, 2050, 2093, 2096, 2100, 2103, 2115, 2117, 2127, 2128, 2130, 2133, 2142, 2147, 2150, 2154, 2157, 2158, 2161, 2162, 2163, 2166, 2173, 2174, 2178, 2181, 2192, 2195, 2203, 2204, 2205], "each": [1, 2, 3, 6, 10, 16, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 49, 52, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 86, 97, 119, 153, 154, 398, 402, 493, 513, 515, 517, 545, 607, 617, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 694, 697, 704, 706, 707, 710, 746, 771, 805, 810, 813, 869, 871, 889, 891, 892, 895, 907, 916, 917, 918, 919, 921, 922, 923, 930, 932, 935, 936, 944, 970, 973, 982, 986, 990, 991, 993, 996, 1000, 1002, 1004, 1007, 1027, 1050, 1051, 1055, 1056, 1089, 1092, 1094, 1101, 1103, 1108, 1111, 1117, 1121, 1122, 1123, 1124, 1127, 1128, 1139, 1142, 1144, 1150, 1161, 1163, 1164, 1165, 1166, 1167, 1169, 1170, 1173, 1174, 1175, 1176, 1177, 1179, 1181, 1185, 1186, 1188, 1193, 1198, 1203, 1204, 1208, 1212, 1213, 1226, 1228, 1255, 1268, 1274, 1276, 1277, 1278, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1314, 1330, 1331, 1336, 1368, 1386, 1387, 1402, 1404, 1412, 1414, 1415, 1416, 1417, 1420, 1422, 1433, 1434, 1443, 1466, 1472, 1474, 1484, 1489, 1492, 1493, 1497, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1531, 1532, 1534, 1539, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1552, 1560, 1561, 1565, 1567, 1571, 1572, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1594, 1596, 1598, 1609, 1612, 1613, 1615, 1620, 1623, 1629, 1630, 1632, 1641, 1656, 1658, 1659, 1664, 1665, 1666, 1669, 1670, 1672, 1673, 1674, 1677, 1678, 1679, 1683, 1686, 1695, 1696, 1698, 1718, 1722, 1723, 1725, 1727, 1730, 1738, 1751, 1760, 1770, 1779, 1780, 1813, 1814, 1816, 1826, 1827, 1828, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1885, 1889, 1890, 1893, 1900, 1908, 1913, 1914, 1919, 1923, 1928, 1936, 1940, 1951, 1957, 1975, 1976, 1977, 1978, 1980, 1981, 1982, 1993, 1994, 2012, 2014, 2015, 2018, 2029, 2030, 2031, 2039, 2045, 2046, 2073, 2074, 2078, 2080, 2081, 2086, 2091, 2095, 2096, 2100, 2102, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2142, 2144, 2145, 2146, 2147, 2150, 2154, 2156, 2157, 2159, 2161, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2181, 2182, 2183, 2184, 2188, 2189, 2191, 2193, 2195, 2196, 2197, 2198, 2200, 2201, 2202, 2203, 2204, 2205, 2207], "its": [1, 2, 5, 6, 8, 9, 10, 14, 16, 17, 20, 21, 25, 26, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 45, 51, 52, 54, 57, 58, 60, 67, 68, 69, 71, 73, 150, 233, 258, 458, 487, 488, 504, 513, 515, 517, 583, 584, 585, 617, 681, 842, 851, 904, 905, 906, 908, 909, 910, 923, 928, 929, 946, 947, 954, 955, 956, 994, 995, 1002, 1013, 1015, 1016, 1023, 1027, 1045, 1078, 1080, 1089, 1105, 1127, 1131, 1134, 1144, 1147, 1192, 1198, 1202, 1203, 1204, 1207, 1212, 1228, 1276, 1277, 1281, 1294, 1314, 1325, 1350, 1351, 1355, 1360, 1367, 1369, 1372, 1373, 1378, 1384, 1409, 1419, 1441, 1445, 1492, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1542, 1543, 1544, 1580, 1581, 1590, 1612, 1620, 1628, 1686, 1697, 1725, 1731, 1760, 1765, 1766, 1771, 1772, 1773, 1774, 1779, 1780, 1781, 1783, 1788, 1789, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1814, 1820, 1824, 1828, 1834, 1838, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1877, 1883, 1908, 1912, 1916, 1917, 1933, 1934, 1957, 1967, 1995, 2017, 2018, 2020, 2028, 2038, 2043, 2052, 2093, 2095, 2096, 2100, 2106, 2108, 2109, 2114, 2117, 2126, 2127, 2128, 2130, 2132, 2133, 2135, 2136, 2138, 2142, 2144, 2146, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2166, 2167, 2168, 2171, 2173, 2174, 2175, 2177, 2181, 2182, 2183, 2185, 2189, 2191, 2192, 2193, 2194, 2195, 2198, 2200, 2204, 2207, 2208], "appropri": [1, 8, 9, 10, 19, 30, 31, 32, 39, 60, 68, 69, 486, 925, 956, 1027, 1089, 1241, 1330, 1936, 2096, 2097, 2100, 2116, 2130, 2138, 2144, 2147, 2161, 2164, 2166, 2167, 2168, 2173, 2192, 2195, 2200, 2206], "ordinarili": [1, 1238, 2126], "train": [1, 2, 14, 17, 25, 26, 30, 31, 32, 33, 35, 36, 41, 49, 50, 51, 52, 58, 60, 63, 64, 69, 723, 724, 725, 726, 727, 728, 729, 730, 731, 741, 742, 743, 744, 814, 816, 866, 868, 885, 886, 887, 889, 891, 892, 893, 945, 1007, 1019, 1088, 1089, 1092, 1094, 1102, 1211, 1314, 1319, 1326, 1329, 1330, 1484, 1488, 1494, 1495, 1496, 1515, 1516, 1517, 1522, 1523, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1586, 1587, 1599, 1620, 1628, 1652, 1656, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1736, 1737, 1738, 1770, 1788, 1791, 1793, 1821, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1865, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 2073, 2074, 2091, 2093, 2094, 2100, 2106, 2109, 2124, 2127, 2130, 2132, 2135, 2143, 2145, 2147, 2149, 2150, 2154, 2156, 2157, 2158, 2159, 2164, 2166, 2168, 2176, 2183, 2184, 2185, 2188, 2189, 2190, 2192, 2193, 2197, 2198, 2199, 2201, 2204, 2205], "gradscal": [1, 2126, 2130, 2137], "togeth": [1, 4, 10, 25, 30, 34, 36, 37, 38, 39, 56, 61, 66, 69, 771, 1086, 1144, 1201, 1203, 1207, 1211, 1212, 1254, 1258, 1354, 1531, 1550, 1596, 1697, 1770, 1878, 2018, 2100, 2106, 2126, 2133, 2134, 2135, 2136, 2140, 2142, 2161, 2166, 2167, 2168, 2171, 2173, 2176, 2190, 2192, 2194, 2195, 2200, 2209], "shown": [1, 14, 26, 43, 52, 56, 1086, 1097, 1552, 1793, 1834, 1872, 1877, 1940, 2076, 2093, 2096, 2126, 2130, 2133, 2135, 2142, 2161, 2171, 2173, 2185, 2190, 2192, 2193, 2196], "exampl": [1, 2, 3, 4, 6, 8, 9, 10, 16, 19, 20, 21, 22, 25, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 48, 49, 50, 51, 52, 54, 55, 57, 58, 60, 61, 62, 64, 65, 66, 68, 71, 79, 80, 86, 87, 88, 191, 208, 242, 254, 260, 289, 311, 313, 315, 317, 321, 335, 352, 401, 402, 415, 445, 446, 447, 448, 449, 471, 481, 483, 486, 487, 488, 493, 496, 499, 513, 515, 517, 523, 537, 544, 558, 560, 580, 581, 583, 584, 585, 586, 587, 588, 589, 607, 617, 681, 682, 684, 689, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 731, 739, 740, 745, 749, 750, 751, 752, 753, 754, 756, 757, 759, 767, 768, 769, 771, 772, 773, 774, 775, 776, 783, 784, 785, 796, 805, 806, 807, 809, 811, 825, 826, 827, 828, 829, 830, 831, 832, 834, 843, 866, 884, 889, 890, 891, 892, 895, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 925, 928, 929, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 945, 946, 952, 954, 955, 956, 958, 965, 970, 972, 973, 974, 975, 976, 977, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 1000, 1001, 1002, 1004, 1007, 1009, 1010, 1015, 1016, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1036, 1057, 1086, 1087, 1092, 1094, 1123, 1124, 1125, 1126, 1127, 1128, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1139, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1154, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1201, 1202, 1203, 1204, 1209, 1211, 1213, 1226, 1227, 1228, 1238, 1255, 1256, 1257, 1261, 1268, 1271, 1274, 1275, 1276, 1277, 1278, 1280, 1281, 1285, 1289, 1291, 1299, 1301, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1317, 1318, 1319, 1320, 1321, 1322, 1324, 1325, 1326, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1441, 1443, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1640, 1644, 1651, 1653, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1682, 1686, 1688, 1722, 1724, 1725, 1728, 1729, 1738, 1757, 1760, 1769, 1770, 1771, 1779, 1780, 1787, 1788, 1789, 1791, 1793, 1797, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1824, 1825, 1826, 1827, 1828, 1830, 1831, 1832, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1864, 1865, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1881, 1883, 1885, 1886, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1903, 1905, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1923, 1924, 1928, 1930, 1931, 1932, 1933, 1934, 1937, 1940, 1943, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1960, 1961, 1965, 1967, 1968, 1970, 1971, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1987, 1988, 1989, 1991, 1993, 1994, 1996, 1997, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2036, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2073, 2074, 2089, 2090, 2091, 2093, 2095, 2096, 2097, 2100, 2102, 2103, 2107, 2108, 2109, 2115, 2116, 2117, 2122, 2124, 2125, 2127, 2128, 2129, 2130, 2135, 2136, 2139, 2140, 2141, 2142, 2144, 2145, 2146, 2147, 2149, 2151, 2152, 2157, 2158, 2159, 2161, 2162, 2166, 2168, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2181, 2182, 2185, 2189, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2201, 2202, 2203, 2204, 2205, 2206, 2209], "recip": [1, 4, 35, 37, 60, 1580, 1770, 1795, 2126, 2142, 2194], "howev": [1, 3, 4, 5, 6, 8, 10, 16, 17, 25, 26, 30, 34, 35, 39, 41, 48, 51, 56, 57, 60, 61, 62, 64, 65, 68, 69, 71, 76, 80, 258, 481, 545, 925, 938, 1039, 1066, 1089, 1132, 1134, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1201, 1202, 1206, 1207, 1209, 1212, 1213, 1218, 1227, 1238, 1314, 1317, 1318, 1325, 1327, 1354, 1369, 1370, 1372, 1386, 1387, 1404, 1492, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1523, 1580, 1661, 1662, 1663, 1686, 1760, 1770, 1813, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1976, 1977, 1978, 1979, 1980, 1981, 2045, 2050, 2058, 2092, 2096, 2126, 2127, 2130, 2133, 2139, 2142, 2144, 2146, 2147, 2148, 2149, 2154, 2157, 2158, 2166, 2168, 2171, 2173, 2177, 2184, 2189, 2191, 2192, 2193, 2194, 2195, 2196, 2204], "modular": [1, 2126], "mai": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 16, 21, 24, 25, 26, 30, 32, 34, 35, 36, 39, 40, 41, 44, 48, 50, 52, 56, 58, 60, 61, 65, 68, 69, 196, 221, 233, 254, 313, 321, 458, 486, 515, 517, 556, 603, 617, 681, 700, 830, 831, 832, 891, 895, 922, 930, 933, 935, 936, 938, 940, 944, 949, 962, 973, 984, 996, 1002, 1014, 1020, 1021, 1023, 1025, 1037, 1039, 1040, 1050, 1066, 1078, 1079, 1080, 1086, 1087, 1089, 1101, 1103, 1108, 1121, 1122, 1144, 1183, 1187, 1192, 1195, 1198, 1205, 1206, 1208, 1227, 1228, 1233, 1238, 1240, 1241, 1242, 1253, 1277, 1311, 1314, 1317, 1318, 1324, 1325, 1327, 1328, 1330, 1336, 1345, 1346, 1350, 1351, 1352, 1354, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1370, 1372, 1373, 1376, 1377, 1378, 1384, 1386, 1387, 1392, 1409, 1419, 1438, 1484, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1545, 1550, 1576, 1577, 1578, 1580, 1587, 1596, 1626, 1628, 1633, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1678, 1686, 1688, 1697, 1703, 1725, 1738, 1756, 1757, 1758, 1759, 1760, 1770, 1787, 1790, 1791, 1793, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1848, 1849, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1877, 1892, 1912, 1915, 1936, 1942, 1960, 1973, 1990, 1993, 1994, 1995, 2020, 2033, 2050, 2058, 2091, 2092, 2093, 2095, 2096, 2100, 2102, 2103, 2104, 2109, 2111, 2116, 2117, 2122, 2126, 2127, 2128, 2129, 2130, 2133, 2134, 2135, 2142, 2145, 2146, 2147, 2148, 2150, 2154, 2157, 2158, 2159, 2161, 2162, 2164, 2166, 2168, 2171, 2173, 2180, 2184, 2185, 2189, 2191, 2192, 2194, 2195, 2198, 2202, 2204, 2205, 2206, 2207, 2209], "separ": [1, 2, 4, 10, 13, 16, 22, 25, 30, 32, 35, 51, 52, 60, 61, 63, 66, 68, 69, 746, 771, 920, 935, 1144, 1161, 1163, 1169, 1170, 1173, 1174, 1179, 1181, 1201, 1221, 1325, 1360, 1375, 1534, 1542, 1543, 1544, 1586, 1588, 1705, 1828, 1878, 1905, 2091, 2094, 2096, 2100, 2102, 2122, 2126, 2127, 2129, 2130, 2134, 2136, 2147, 2150, 2157, 2158, 2167, 2171, 2172, 2173, 2176, 2189, 2202, 2205], "desir": [1, 2, 4, 25, 30, 37, 38, 39, 56, 60, 69, 86, 87, 88, 155, 170, 172, 175, 178, 179, 180, 195, 206, 209, 240, 254, 267, 297, 325, 393, 445, 446, 447, 448, 449, 497, 499, 500, 520, 525, 544, 545, 546, 560, 580, 583, 603, 604, 617, 623, 806, 895, 909, 971, 980, 999, 1090, 1091, 1116, 1117, 1125, 1126, 1145, 1146, 1147, 1157, 1162, 1180, 1196, 1198, 1199, 1200, 1272, 1273, 1314, 1334, 1385, 1401, 1407, 1414, 1429, 1439, 1443, 1461, 1471, 1473, 1474, 1492, 1493, 1580, 1631, 1659, 1705, 1744, 1745, 1760, 1778, 1813, 1827, 1831, 1832, 1838, 1877, 1883, 1890, 1893, 1894, 1895, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1941, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1969, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1993, 2011, 2022, 2024, 2071, 2072, 2085, 2086, 2089, 2090, 2115, 2116, 2117, 2126, 2127, 2130, 2134, 2139, 2142, 2147, 2157, 2165, 2166, 2172, 2173, 2174, 2177, 2205], "As": [1, 2, 9, 22, 26, 30, 32, 36, 39, 56, 57, 58, 60, 63, 64, 69, 254, 486, 984, 1144, 1318, 1346, 1350, 1351, 1361, 1362, 1373, 1378, 1484, 1518, 1519, 1520, 1524, 1545, 1580, 1612, 1756, 1826, 1832, 1838, 1840, 1841, 1859, 2090, 2093, 2095, 2096, 2103, 2117, 2122, 2127, 2130, 2133, 2135, 2136, 2139, 2142, 2145, 2147, 2148, 2149, 2150, 2154, 2157, 2158, 2165, 2166, 2167, 2168, 2170, 2171, 2180, 2183, 2188, 2190, 2192, 2195, 2196, 2197, 2205], "section": [1, 2, 8, 25, 36, 37, 39, 41, 43, 57, 58, 64, 69, 119, 1101, 1144, 1268, 1516, 1531, 1550, 1578, 1596, 1669, 1816, 2012, 2093, 2094, 2095, 2096, 2097, 2111, 2114, 2116, 2117, 2126, 2127, 2130, 2132, 2133, 2134, 2137, 2138, 2139, 2142, 2144, 2149, 2159, 2167, 2176, 2189, 2190, 2192, 2193, 2195, 2196, 2197, 2198, 2202, 2204, 2205], "infer": [1, 2, 3, 4, 6, 13, 17, 32, 36, 37, 39, 51, 58, 60, 580, 617, 891, 892, 895, 909, 910, 945, 1007, 1056, 1198, 1199, 1227, 1277, 1298, 1312, 1315, 1324, 1329, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1586, 1633, 1697, 1724, 1760, 1825, 1860, 1872, 1908, 1915, 1933, 1934, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2028, 2093, 2095, 2096, 2100, 2106, 2115, 2117, 2125, 2130, 2142, 2150, 2154, 2159, 2161, 2162, 2164, 2171, 2173, 2183, 2188, 2189, 2191, 2192, 2195, 2197, 2201, 2204], "onli": [1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 16, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 49, 51, 52, 56, 57, 58, 60, 64, 65, 68, 69, 119, 254, 311, 321, 323, 335, 352, 445, 446, 447, 448, 449, 458, 481, 486, 488, 513, 515, 517, 557, 583, 584, 585, 587, 588, 614, 617, 681, 706, 707, 746, 749, 750, 751, 752, 754, 783, 784, 785, 790, 796, 797, 798, 804, 806, 816, 829, 832, 839, 840, 843, 855, 872, 879, 888, 908, 925, 927, 930, 933, 934, 935, 936, 938, 940, 949, 956, 958, 965, 971, 972, 980, 1002, 1010, 1014, 1015, 1019, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1037, 1039, 1040, 1051, 1053, 1056, 1057, 1078, 1086, 1087, 1089, 1112, 1141, 1145, 1147, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1190, 1191, 1195, 1196, 1197, 1202, 1213, 1226, 1228, 1240, 1241, 1267, 1268, 1272, 1273, 1277, 1285, 1290, 1295, 1303, 1312, 1314, 1317, 1318, 1326, 1330, 1331, 1334, 1345, 1350, 1351, 1353, 1354, 1355, 1356, 1358, 1360, 1361, 1362, 1363, 1373, 1375, 1376, 1378, 1379, 1386, 1387, 1404, 1409, 1484, 1510, 1511, 1512, 1515, 1516, 1522, 1523, 1526, 1550, 1552, 1580, 1583, 1585, 1586, 1588, 1597, 1620, 1628, 1632, 1633, 1644, 1669, 1678, 1680, 1686, 1697, 1725, 1738, 1756, 1757, 1760, 1763, 1764, 1765, 1766, 1770, 1773, 1774, 1779, 1780, 1794, 1813, 1814, 1815, 1827, 1835, 1839, 1843, 1859, 1860, 1863, 1868, 1871, 1872, 1874, 1877, 1880, 1892, 1901, 1905, 1907, 1909, 1932, 1936, 1938, 1941, 1942, 1967, 1970, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1990, 1994, 2002, 2005, 2011, 2022, 2024, 2029, 2030, 2033, 2034, 2036, 2042, 2043, 2044, 2045, 2050, 2082, 2091, 2094, 2095, 2096, 2100, 2102, 2103, 2104, 2106, 2107, 2109, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2142, 2144, 2145, 2146, 2147, 2148, 2150, 2151, 2154, 2156, 2157, 2158, 2159, 2161, 2164, 2165, 2166, 2167, 2168, 2171, 2172, 2174, 2175, 2176, 2177, 2178, 2180, 2183, 2184, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2202, 2203, 2204, 2205, 2207, 2209], "arg": [1, 2, 4, 5, 6, 16, 25, 26, 30, 32, 34, 35, 36, 37, 39, 41, 43, 49, 50, 52, 53, 54, 55, 56, 57, 60, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 580, 603, 681, 743, 758, 760, 762, 763, 764, 765, 771, 773, 774, 843, 891, 920, 922, 930, 931, 932, 935, 936, 965, 1006, 1041, 1042, 1089, 1105, 1201, 1205, 1206, 1207, 1213, 1215, 1226, 1228, 1314, 1317, 1404, 1492, 1493, 1513, 1515, 1539, 1541, 1546, 1569, 1571, 1572, 1580, 1583, 1584, 1585, 1587, 1594, 1609, 1611, 1612, 1613, 1615, 1619, 1620, 1621, 1622, 1629, 1658, 1659, 1669, 1698, 1722, 1730, 1760, 1770, 1795, 1800, 1813, 1820, 1822, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1995, 2005, 2030, 2042, 2045, 2091, 2094, 2096, 2097, 2100, 2114, 2116, 2117, 2122, 2127, 2130, 2132, 2133, 2134, 2144, 2150, 2154, 2156, 2158, 2166, 2167, 2168, 2173, 2177, 2182, 2190, 2192, 2193, 2194, 2195, 2203, 2204, 2205, 2206], "deprec": [1, 8, 30, 32, 41, 51, 52, 60, 64, 406, 513, 557, 603, 796, 797, 798, 806, 851, 944, 992, 993, 1009, 1036, 1093, 1098, 1259, 1314, 1369, 1372, 1404, 1405, 1492, 1493, 1513, 1515, 1538, 1539, 1545, 1546, 1571, 1572, 1580, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1634, 1635, 1658, 1659, 1669, 1698, 1718, 1722, 1730, 1757, 1758, 1759, 1761, 1770, 1775, 1821, 1822, 1824, 1827, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1892, 1908, 1934, 1990, 1994, 2020, 2093, 2098, 2114, 2128, 2154, 2159, 2164, 2173, 2177, 2178, 2195], "pleas": [1, 2, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 26, 30, 32, 37, 39, 43, 46, 47, 51, 52, 56, 60, 61, 62, 63, 64, 65, 66, 69, 71, 81, 82, 254, 255, 498, 513, 618, 684, 700, 741, 742, 743, 744, 745, 746, 752, 753, 754, 756, 757, 767, 772, 773, 774, 775, 776, 891, 892, 922, 925, 928, 929, 935, 936, 938, 940, 941, 944, 958, 984, 1004, 1019, 1127, 1144, 1201, 1205, 1206, 1207, 1208, 1209, 1213, 1311, 1314, 1378, 1409, 1419, 1499, 1510, 1545, 1580, 1686, 1697, 1698, 1703, 1725, 1738, 1756, 1770, 1821, 1822, 1824, 1839, 1840, 1841, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1906, 1932, 1934, 1941, 1979, 2045, 2098, 2100, 2103, 2106, 2108, 2115, 2116, 2117, 2118, 2122, 2126, 2127, 2133, 2134, 2136, 2137, 2139, 2145, 2146, 2147, 2148, 2151, 2154, 2157, 2158, 2161, 2164, 2165, 2166, 2167, 2171, 2172, 2173, 2174, 2175, 2176, 2178, 2185, 2186, 2189, 2190, 2193, 2194, 2195, 2201, 2204, 2205, 2208], "instead": [1, 2, 4, 6, 9, 10, 16, 21, 22, 25, 26, 30, 32, 34, 37, 38, 39, 41, 48, 51, 52, 56, 57, 58, 60, 63, 64, 65, 67, 69, 71, 80, 406, 458, 486, 499, 513, 759, 768, 779, 780, 806, 832, 851, 895, 910, 920, 935, 936, 938, 939, 940, 941, 944, 949, 986, 992, 1004, 1179, 1181, 1206, 1207, 1208, 1209, 1212, 1213, 1241, 1245, 1259, 1301, 1312, 1314, 1315, 1319, 1344, 1345, 1351, 1353, 1369, 1372, 1378, 1384, 1386, 1415, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1513, 1515, 1516, 1518, 1519, 1520, 1524, 1531, 1539, 1545, 1546, 1547, 1548, 1549, 1550, 1571, 1572, 1573, 1574, 1575, 1580, 1583, 1584, 1585, 1587, 1594, 1596, 1608, 1612, 1613, 1614, 1620, 1629, 1653, 1654, 1655, 1658, 1659, 1669, 1679, 1686, 1698, 1711, 1712, 1713, 1722, 1730, 1744, 1770, 1822, 1824, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1864, 1865, 1872, 1877, 1897, 1898, 1908, 1928, 1932, 1975, 1990, 1994, 2033, 2045, 2093, 2095, 2096, 2100, 2103, 2104, 2111, 2116, 2122, 2124, 2126, 2127, 2132, 2133, 2134, 2135, 2138, 2139, 2144, 2146, 2147, 2148, 2149, 2150, 2154, 2157, 2158, 2159, 2161, 2164, 2167, 2170, 2171, 2177, 2178, 2180, 2182, 2186, 2189, 2190, 2191, 2192, 2194, 2195, 2200, 2202, 2203, 2204, 2205, 2206], "new": [1, 2, 6, 9, 16, 20, 21, 25, 28, 30, 32, 34, 37, 39, 41, 42, 51, 52, 56, 60, 61, 64, 65, 66, 67, 68, 69, 87, 88, 221, 254, 311, 415, 448, 483, 486, 487, 496, 499, 544, 580, 583, 617, 681, 695, 771, 804, 829, 837, 884, 909, 911, 912, 913, 914, 915, 926, 928, 935, 936, 954, 955, 969, 985, 986, 989, 991, 1000, 1004, 1007, 1022, 1024, 1025, 1040, 1128, 1132, 1154, 1158, 1159, 1185, 1186, 1188, 1202, 1211, 1213, 1216, 1226, 1228, 1236, 1251, 1253, 1285, 1289, 1303, 1304, 1307, 1310, 1314, 1321, 1326, 1328, 1388, 1389, 1390, 1391, 1408, 1475, 1478, 1494, 1495, 1496, 1531, 1542, 1543, 1544, 1580, 1581, 1586, 1590, 1620, 1631, 1633, 1697, 1762, 1763, 1767, 1768, 1770, 1781, 1782, 1783, 1784, 1788, 1793, 1795, 1797, 1799, 1800, 1801, 1803, 1804, 1806, 1807, 1808, 1809, 1817, 1821, 1824, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1848, 1849, 1856, 1857, 1858, 1859, 1860, 1874, 1877, 1900, 1910, 1911, 1915, 1916, 1917, 1923, 1924, 1928, 1933, 1934, 1943, 1945, 1956, 1958, 1960, 1983, 1984, 1987, 2007, 2009, 2010, 2026, 2028, 2032, 2043, 2044, 2045, 2091, 2093, 2095, 2096, 2103, 2104, 2106, 2114, 2115, 2116, 2117, 2118, 2122, 2127, 2130, 2131, 2134, 2139, 2140, 2142, 2143, 2144, 2146, 2147, 2148, 2151, 2154, 2157, 2158, 2159, 2161, 2164, 2168, 2171, 2172, 2173, 2175, 2176, 2177, 2178, 2182, 2189, 2191, 2192, 2193, 2195, 2203, 2204, 2205], "version": [1, 2, 3, 6, 9, 14, 16, 19, 21, 24, 26, 30, 32, 36, 39, 52, 56, 60, 63, 64, 69, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 121, 123, 125, 127, 130, 131, 133, 141, 143, 146, 147, 149, 152, 158, 160, 162, 164, 166, 168, 177, 186, 194, 198, 201, 203, 213, 215, 231, 236, 238, 244, 247, 249, 251, 253, 257, 262, 269, 271, 273, 277, 279, 283, 285, 292, 294, 296, 304, 306, 308, 310, 312, 314, 316, 318, 356, 358, 360, 362, 364, 366, 368, 371, 373, 375, 376, 383, 385, 387, 389, 391, 395, 399, 401, 420, 423, 426, 428, 439, 441, 443, 451, 456, 466, 469, 485, 490, 492, 508, 511, 512, 513, 514, 516, 522, 527, 529, 532, 534, 536, 549, 551, 553, 556, 562, 564, 571, 575, 577, 593, 596, 598, 600, 602, 612, 622, 746, 747, 748, 760, 761, 762, 763, 764, 765, 786, 787, 788, 789, 791, 795, 796, 819, 820, 821, 868, 877, 885, 886, 888, 945, 956, 1019, 1089, 1201, 1232, 1234, 1243, 1244, 1272, 1311, 1314, 1317, 1318, 1322, 1325, 1344, 1351, 1355, 1357, 1358, 1362, 1363, 1375, 1376, 1409, 1452, 1475, 1493, 1550, 1580, 1581, 1596, 1633, 1651, 1676, 1686, 1693, 1702, 1734, 1737, 1752, 1753, 1757, 1761, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1821, 1822, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1925, 1926, 1927, 1985, 1988, 1989, 1990, 1994, 2017, 2031, 2033, 2040, 2041, 2091, 2100, 2115, 2116, 2122, 2127, 2128, 2130, 2133, 2134, 2136, 2138, 2139, 2140, 2142, 2143, 2146, 2148, 2149, 2150, 2154, 2157, 2158, 2159, 2164, 2171, 2178, 2180, 2185, 2186, 2189, 2191, 2195, 2196, 2202, 2204, 2205, 2207], "1": [1, 2, 3, 4, 13, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 43, 44, 48, 49, 55, 56, 57, 58, 60, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 136, 151, 152, 173, 191, 205, 208, 225, 227, 228, 229, 233, 242, 254, 258, 263, 286, 289, 311, 312, 313, 315, 317, 321, 352, 377, 401, 402, 445, 447, 448, 454, 471, 481, 483, 487, 488, 493, 496, 499, 513, 515, 517, 537, 538, 542, 544, 554, 555, 556, 558, 560, 561, 562, 563, 564, 581, 583, 584, 585, 587, 588, 607, 608, 615, 617, 681, 682, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 723, 724, 725, 726, 727, 728, 729, 730, 734, 735, 736, 737, 738, 741, 742, 745, 747, 748, 749, 750, 751, 752, 753, 754, 755, 757, 762, 763, 764, 767, 768, 769, 771, 781, 783, 784, 785, 786, 789, 793, 794, 796, 809, 823, 824, 837, 839, 840, 841, 846, 852, 885, 891, 892, 895, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 920, 924, 925, 930, 931, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 945, 946, 954, 955, 958, 965, 967, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 983, 984, 985, 986, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 1000, 1001, 1003, 1004, 1015, 1016, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1032, 1036, 1050, 1057, 1073, 1086, 1087, 1103, 1108, 1115, 1119, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1139, 1141, 1142, 1143, 1144, 1147, 1148, 1149, 1150, 1154, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1197, 1198, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1228, 1232, 1238, 1255, 1256, 1257, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1285, 1286, 1289, 1291, 1299, 1301, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1318, 1320, 1325, 1326, 1330, 1331, 1334, 1335, 1336, 1338, 1339, 1340, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1358, 1360, 1361, 1362, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1390, 1392, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1404, 1405, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1420, 1421, 1422, 1438, 1441, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1521, 1522, 1523, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1536, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1619, 1620, 1623, 1624, 1626, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1641, 1642, 1643, 1651, 1653, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1684, 1685, 1686, 1688, 1690, 1692, 1693, 1694, 1695, 1696, 1704, 1706, 1711, 1712, 1713, 1719, 1722, 1723, 1724, 1725, 1727, 1728, 1729, 1731, 1736, 1737, 1738, 1739, 1740, 1742, 1744, 1745, 1746, 1748, 1753, 1754, 1755, 1756, 1757, 1760, 1769, 1770, 1779, 1780, 1787, 1788, 1789, 1793, 1797, 1798, 1799, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1813, 1814, 1815, 1816, 1818, 1819, 1820, 1821, 1822, 1824, 1825, 1826, 1827, 1828, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1881, 1882, 1883, 1885, 1886, 1889, 1890, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1923, 1924, 1928, 1931, 1932, 1933, 1934, 1935, 1937, 1940, 1943, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1960, 1961, 1965, 1966, 1967, 1968, 1970, 1971, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2094, 2095, 2096, 2097, 2100, 2103, 2104, 2105, 2106, 2111, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2129, 2130, 2133, 2135, 2136, 2137, 2138, 2139, 2142, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2163, 2166, 2167, 2168, 2170, 2171, 2172, 2174, 2175, 2176, 2177, 2178, 2180, 2182, 2185, 2186, 2189, 2190, 2191, 2193, 2195, 2197, 2198, 2199, 2202, 2203, 2204, 2205, 2206, 2209, 2210], "10": [1, 2, 4, 6, 14, 24, 25, 26, 30, 31, 36, 39, 40, 54, 56, 58, 71, 76, 79, 80, 313, 321, 335, 471, 513, 560, 581, 583, 584, 585, 696, 697, 708, 745, 756, 757, 771, 772, 773, 774, 776, 970, 982, 992, 995, 996, 1000, 1019, 1027, 1123, 1124, 1125, 1126, 1127, 1142, 1144, 1161, 1163, 1166, 1167, 1169, 1170, 1173, 1174, 1176, 1177, 1179, 1181, 1187, 1195, 1196, 1256, 1268, 1278, 1303, 1319, 1325, 1326, 1332, 1337, 1340, 1367, 1369, 1370, 1385, 1387, 1389, 1394, 1396, 1397, 1398, 1399, 1401, 1409, 1466, 1482, 1483, 1484, 1486, 1487, 1493, 1496, 1499, 1500, 1506, 1509, 1512, 1522, 1523, 1531, 1532, 1533, 1534, 1544, 1550, 1551, 1552, 1577, 1581, 1582, 1587, 1590, 1591, 1596, 1598, 1620, 1624, 1625, 1626, 1627, 1628, 1632, 1638, 1663, 1666, 1670, 1677, 1678, 1688, 1760, 1770, 1779, 1780, 1804, 1811, 1825, 1828, 1834, 1839, 1865, 1872, 1874, 1878, 1894, 1895, 1903, 1928, 1936, 1940, 1946, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1956, 1965, 1982, 1994, 1995, 2008, 2012, 2013, 2016, 2018, 2031, 2033, 2046, 2091, 2093, 2094, 2095, 2096, 2097, 2100, 2103, 2105, 2117, 2127, 2130, 2132, 2133, 2136, 2137, 2142, 2145, 2146, 2147, 2148, 2152, 2154, 2155, 2159, 2161, 2170, 2171, 2172, 2174, 2176, 2177, 2178, 2185, 2186, 2189, 2190, 2192, 2193, 2195, 2197, 2202, 2204, 2205, 2210], "autocast_mod": 1, "is_autocast_avail": 1, "device_typ": [1, 2, 16, 30, 37, 2094, 2100, 2126, 2137, 2165, 2180], "sourc": [1, 2, 3, 4, 5, 6, 10, 14, 15, 16, 19, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 53, 54, 56, 57, 60, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 150, 196, 209, 233, 312, 313, 321, 340, 351, 396, 401, 402, 415, 416, 417, 453, 471, 487, 488, 513, 515, 517, 520, 524, 547, 556, 557, 559, 586, 603, 606, 609, 610, 623, 625, 681, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 706, 707, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 800, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 839, 840, 841, 842, 843, 846, 851, 852, 855, 861, 864, 865, 866, 867, 868, 869, 870, 871, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 903, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 954, 955, 956, 957, 958, 959, 960, 961, 962, 964, 965, 966, 968, 969, 981, 983, 984, 988, 990, 992, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1012, 1013, 1014, 1015, 1019, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1037, 1038, 1039, 1040, 1041, 1042, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1144, 1148, 1195, 1198, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1260, 1262, 1263, 1264, 1267, 1286, 1287, 1288, 1290, 1295, 1300, 1301, 1302, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1386, 1387, 1404, 1407, 1416, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1442, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1462, 1464, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1640, 1641, 1642, 1643, 1644, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1656, 1658, 1659, 1660, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1685, 1686, 1687, 1688, 1690, 1691, 1692, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1704, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1725, 1730, 1732, 1733, 1735, 1736, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1748, 1749, 1750, 1751, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1827, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1882, 1899, 1924, 1929, 1932, 1933, 1934, 1935, 1936, 1940, 1941, 1942, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1967, 1968, 1975, 1982, 1990, 1995, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2013, 2029, 2030, 2031, 2033, 2034, 2035, 2036, 2037, 2038, 2045, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2091, 2093, 2094, 2095, 2100, 2102, 2103, 2106, 2107, 2108, 2109, 2114, 2116, 2117, 2122, 2124, 2130, 2135, 2139, 2140, 2141, 2145, 2147, 2150, 2152, 2154, 2156, 2157, 2159, 2161, 2165, 2166, 2167, 2173, 2176, 2178, 2180, 2181, 2182, 2185, 2192, 2193, 2195, 2196, 2199, 2204, 2205, 2206, 2207], "return": [1, 2, 3, 4, 6, 13, 14, 15, 16, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 51, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 119, 153, 155, 170, 172, 175, 178, 179, 180, 190, 191, 195, 196, 206, 208, 209, 216, 218, 219, 221, 232, 233, 240, 242, 254, 260, 267, 289, 297, 311, 319, 323, 325, 326, 328, 329, 330, 331, 333, 337, 339, 341, 352, 377, 393, 415, 435, 445, 446, 447, 448, 449, 458, 472, 473, 474, 475, 476, 478, 483, 487, 488, 496, 497, 498, 513, 515, 523, 525, 537, 543, 544, 556, 557, 558, 559, 560, 580, 581, 582, 583, 589, 603, 604, 607, 609, 613, 614, 617, 623, 684, 685, 686, 687, 688, 689, 695, 703, 704, 706, 707, 708, 709, 710, 746, 777, 778, 781, 782, 786, 787, 788, 789, 792, 795, 804, 805, 806, 807, 810, 813, 829, 830, 831, 832, 864, 867, 869, 870, 871, 884, 885, 886, 887, 889, 890, 891, 892, 893, 894, 895, 903, 904, 905, 906, 907, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 924, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 951, 952, 954, 955, 958, 962, 963, 964, 966, 967, 968, 969, 971, 972, 973, 980, 981, 983, 986, 988, 990, 991, 992, 993, 995, 996, 997, 999, 1001, 1002, 1003, 1004, 1005, 1007, 1009, 1010, 1012, 1015, 1019, 1020, 1021, 1023, 1024, 1025, 1027, 1028, 1030, 1031, 1032, 1033, 1036, 1037, 1039, 1040, 1041, 1042, 1044, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1063, 1064, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1077, 1078, 1079, 1081, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1092, 1093, 1094, 1095, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1106, 1107, 1108, 1109, 1110, 1111, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1131, 1132, 1133, 1134, 1135, 1138, 1144, 1145, 1146, 1147, 1148, 1149, 1154, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1180, 1183, 1184, 1185, 1186, 1187, 1188, 1192, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1223, 1225, 1226, 1228, 1232, 1235, 1237, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1257, 1258, 1260, 1262, 1263, 1264, 1265, 1266, 1267, 1271, 1272, 1273, 1275, 1276, 1277, 1281, 1285, 1289, 1290, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1310, 1311, 1312, 1314, 1315, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1331, 1332, 1333, 1334, 1336, 1339, 1340, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1356, 1357, 1358, 1360, 1361, 1362, 1363, 1364, 1367, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1381, 1382, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1394, 1395, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1420, 1423, 1424, 1425, 1427, 1428, 1436, 1438, 1443, 1444, 1446, 1447, 1448, 1450, 1452, 1453, 1455, 1456, 1457, 1458, 1466, 1471, 1472, 1474, 1475, 1476, 1477, 1478, 1480, 1484, 1485, 1486, 1487, 1492, 1493, 1513, 1514, 1515, 1516, 1523, 1527, 1528, 1539, 1545, 1546, 1570, 1571, 1572, 1573, 1574, 1575, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1590, 1591, 1594, 1595, 1596, 1609, 1612, 1613, 1614, 1615, 1616, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1642, 1643, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1656, 1658, 1659, 1660, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1685, 1686, 1687, 1688, 1690, 1691, 1692, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1704, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1730, 1732, 1733, 1735, 1736, 1738, 1739, 1741, 1742, 1743, 1744, 1745, 1751, 1753, 1754, 1755, 1756, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1775, 1776, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1805, 1806, 1807, 1808, 1809, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1824, 1825, 1826, 1827, 1828, 1830, 1831, 1832, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1882, 1883, 1885, 1888, 1889, 1890, 1891, 1892, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1913, 1914, 1915, 1916, 1917, 1918, 1921, 1923, 1928, 1929, 1930, 1931, 1937, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1960, 1961, 1965, 1967, 1968, 1969, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1989, 1990, 1993, 1994, 1995, 2006, 2007, 2008, 2009, 2010, 2011, 2013, 2015, 2016, 2017, 2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2035, 2036, 2039, 2041, 2043, 2044, 2045, 2048, 2050, 2051, 2053, 2054, 2056, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2068, 2069, 2070, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2089, 2090, 2091, 2093, 2097, 2100, 2106, 2107, 2108, 2109, 2114, 2116, 2117, 2122, 2124, 2126, 2127, 2129, 2130, 2133, 2134, 2138, 2139, 2140, 2142, 2145, 2146, 2147, 2148, 2149, 2150, 2152, 2154, 2157, 2158, 2159, 2161, 2165, 2166, 2167, 2170, 2171, 2172, 2173, 2174, 2175, 2177, 2178, 2180, 2181, 2182, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2197, 2202, 2203, 2204, 2205, 2206, 2207, 2210], "bool": [1, 2, 3, 4, 6, 14, 16, 21, 25, 26, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 45, 51, 54, 56, 57, 58, 60, 67, 68, 69, 86, 88, 150, 196, 209, 233, 245, 260, 319, 321, 328, 329, 330, 331, 333, 334, 339, 341, 401, 402, 415, 445, 446, 447, 448, 449, 458, 471, 496, 517, 581, 603, 623, 681, 689, 704, 705, 706, 707, 708, 710, 746, 767, 769, 790, 791, 796, 807, 829, 843, 870, 895, 903, 904, 905, 906, 910, 923, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 958, 971, 974, 976, 977, 979, 980, 986, 987, 993, 994, 995, 1001, 1002, 1003, 1004, 1009, 1010, 1015, 1019, 1033, 1039, 1040, 1048, 1083, 1089, 1102, 1145, 1146, 1147, 1150, 1157, 1162, 1180, 1196, 1197, 1198, 1199, 1200, 1201, 1203, 1204, 1206, 1207, 1208, 1212, 1220, 1221, 1226, 1228, 1240, 1241, 1242, 1243, 1244, 1246, 1247, 1248, 1249, 1253, 1254, 1255, 1272, 1273, 1276, 1277, 1288, 1295, 1299, 1302, 1303, 1305, 1311, 1314, 1318, 1321, 1322, 1330, 1331, 1334, 1336, 1344, 1345, 1356, 1357, 1358, 1359, 1361, 1362, 1363, 1364, 1367, 1369, 1371, 1372, 1375, 1376, 1377, 1378, 1384, 1385, 1386, 1387, 1396, 1397, 1398, 1399, 1401, 1402, 1404, 1406, 1412, 1414, 1415, 1417, 1420, 1427, 1433, 1434, 1443, 1455, 1466, 1471, 1472, 1473, 1474, 1475, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1527, 1528, 1532, 1533, 1534, 1536, 1537, 1538, 1539, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1566, 1567, 1571, 1572, 1573, 1574, 1575, 1580, 1583, 1584, 1585, 1586, 1587, 1589, 1594, 1595, 1598, 1599, 1600, 1601, 1608, 1612, 1613, 1620, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1633, 1641, 1642, 1643, 1644, 1651, 1658, 1659, 1669, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1683, 1686, 1688, 1690, 1697, 1698, 1718, 1722, 1730, 1738, 1757, 1763, 1769, 1770, 1771, 1772, 1776, 1777, 1778, 1781, 1782, 1785, 1787, 1790, 1792, 1793, 1794, 1813, 1814, 1815, 1816, 1817, 1819, 1822, 1827, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1880, 1882, 1888, 1890, 1892, 1893, 1897, 1898, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1928, 1933, 1937, 1942, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1965, 1974, 1976, 1977, 1978, 1979, 1980, 1981, 1988, 1989, 1990, 1993, 1994, 2004, 2011, 2015, 2020, 2029, 2030, 2033, 2034, 2036, 2039, 2040, 2041, 2050, 2069, 2089, 2090, 2091, 2093, 2094, 2095, 2096, 2100, 2107, 2109, 2114, 2115, 2116, 2117, 2122, 2139, 2141, 2147, 2150, 2152, 2154, 2155, 2156, 2158, 2159, 2165, 2166, 2171, 2173, 2174, 2176, 2177, 2178, 2180, 2182, 2191, 2195, 2199, 2203, 2206], "indic": [1, 2, 3, 4, 6, 14, 21, 25, 26, 30, 31, 32, 37, 38, 39, 51, 56, 57, 86, 88, 191, 208, 313, 315, 317, 318, 319, 321, 471, 513, 515, 517, 544, 572, 573, 583, 614, 689, 706, 707, 746, 756, 757, 814, 843, 904, 905, 906, 907, 908, 930, 932, 935, 949, 950, 986, 993, 994, 995, 1007, 1008, 1009, 1010, 1019, 1033, 1037, 1039, 1040, 1083, 1089, 1123, 1124, 1147, 1203, 1204, 1206, 1207, 1208, 1212, 1213, 1228, 1255, 1268, 1289, 1312, 1314, 1319, 1328, 1331, 1332, 1336, 1345, 1356, 1358, 1369, 1372, 1386, 1394, 1402, 1404, 1406, 1412, 1415, 1417, 1420, 1427, 1443, 1466, 1472, 1476, 1484, 1485, 1486, 1487, 1515, 1522, 1523, 1527, 1528, 1574, 1575, 1576, 1577, 1578, 1583, 1585, 1586, 1648, 1649, 1650, 1669, 1677, 1678, 1681, 1682, 1698, 1714, 1715, 1716, 1724, 1738, 1753, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1806, 1807, 1826, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1870, 1872, 1893, 1928, 1965, 1970, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 2007, 2008, 2012, 2015, 2021, 2022, 2023, 2024, 2029, 2030, 2031, 2033, 2034, 2036, 2045, 2048, 2050, 2069, 2093, 2094, 2096, 2100, 2115, 2116, 2117, 2122, 2133, 2144, 2147, 2150, 2154, 2155, 2166, 2171, 2173, 2175, 2176, 2178, 2186, 2196, 2199, 2205], "i": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25, 26, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 76, 78, 79, 80, 81, 82, 85, 86, 87, 97, 150, 153, 154, 155, 170, 172, 173, 175, 178, 179, 180, 190, 191, 195, 196, 206, 208, 209, 218, 223, 233, 240, 254, 255, 258, 267, 286, 290, 297, 311, 313, 315, 319, 321, 323, 325, 328, 329, 330, 331, 332, 333, 335, 336, 338, 340, 341, 342, 343, 352, 393, 400, 402, 406, 415, 448, 458, 471, 472, 481, 483, 486, 487, 488, 493, 495, 496, 497, 498, 499, 500, 503, 504, 513, 515, 517, 520, 524, 525, 537, 543, 544, 545, 557, 560, 580, 581, 583, 584, 585, 587, 588, 589, 603, 604, 607, 614, 617, 618, 620, 623, 625, 681, 682, 684, 688, 689, 690, 691, 693, 694, 695, 697, 698, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 734, 735, 736, 737, 738, 745, 746, 747, 748, 749, 750, 751, 752, 754, 755, 760, 761, 762, 763, 764, 765, 766, 767, 769, 770, 771, 772, 774, 775, 776, 779, 780, 783, 784, 785, 786, 787, 788, 789, 790, 796, 797, 798, 800, 802, 803, 804, 805, 806, 807, 808, 811, 813, 814, 816, 817, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 837, 839, 840, 843, 851, 852, 860, 866, 868, 869, 887, 888, 889, 891, 892, 895, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 954, 955, 956, 957, 958, 962, 963, 965, 967, 969, 970, 971, 972, 973, 975, 978, 980, 982, 983, 986, 987, 988, 990, 991, 992, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1004, 1005, 1007, 1009, 1010, 1013, 1014, 1015, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1033, 1036, 1037, 1039, 1040, 1041, 1043, 1044, 1045, 1046, 1047, 1048, 1050, 1051, 1053, 1056, 1057, 1060, 1061, 1062, 1064, 1065, 1069, 1070, 1071, 1073, 1074, 1078, 1079, 1080, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1094, 1095, 1097, 1099, 1101, 1102, 1103, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1131, 1132, 1133, 1134, 1135, 1136, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1154, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1183, 1184, 1185, 1186, 1187, 1188, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1211, 1212, 1213, 1217, 1218, 1221, 1222, 1224, 1226, 1227, 1228, 1230, 1232, 1234, 1235, 1237, 1238, 1240, 1241, 1242, 1245, 1247, 1248, 1249, 1253, 1255, 1257, 1258, 1259, 1261, 1263, 1267, 1268, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1285, 1289, 1290, 1291, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1330, 1331, 1332, 1334, 1335, 1336, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1394, 1395, 1397, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1428, 1439, 1441, 1443, 1444, 1445, 1447, 1448, 1449, 1452, 1453, 1455, 1457, 1458, 1460, 1461, 1462, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1602, 1603, 1604, 1605, 1606, 1607, 1609, 1610, 1612, 1613, 1614, 1616, 1617, 1620, 1621, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1651, 1654, 1655, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1682, 1683, 1684, 1685, 1686, 1688, 1695, 1697, 1698, 1703, 1704, 1705, 1707, 1708, 1709, 1711, 1712, 1713, 1718, 1722, 1723, 1725, 1727, 1728, 1729, 1730, 1731, 1738, 1741, 1744, 1745, 1753, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1778, 1779, 1780, 1785, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1813, 1814, 1815, 1816, 1817, 1820, 1821, 1822, 1824, 1825, 1826, 1827, 1828, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1881, 1882, 1885, 1886, 1888, 1889, 1890, 1891, 1892, 1893, 1899, 1901, 1902, 1903, 1905, 1906, 1908, 1909, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1919, 1920, 1921, 1923, 1924, 1928, 1930, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1942, 1943, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1958, 1960, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1985, 1986, 1988, 1989, 1990, 1993, 1994, 1995, 1996, 1997, 2002, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2028, 2029, 2030, 2031, 2033, 2036, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2050, 2051, 2052, 2054, 2055, 2057, 2060, 2061, 2064, 2067, 2069, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2082, 2083, 2084, 2085, 2087, 2088, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2102, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2154, 2156, 2157, 2159, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2196, 2197, 2198, 2199, 2200, 2202, 2203, 2205, 2206, 2207, 2208, 2209, 2210, 2212], "avail": [1, 2, 3, 6, 9, 10, 16, 17, 21, 22, 25, 30, 32, 36, 41, 51, 52, 57, 684, 688, 689, 693, 1033, 1063, 1066, 1067, 1080, 1083, 1090, 1091, 1112, 1113, 1115, 1144, 1245, 1321, 1378, 1379, 1404, 1424, 1450, 1455, 1624, 1633, 1639, 1697, 1738, 1757, 1882, 1936, 1990, 1995, 2033, 2036, 2056, 2058, 2069, 2071, 2072, 2075, 2082, 2083, 2091, 2092, 2093, 2095, 2096, 2100, 2103, 2111, 2114, 2117, 2127, 2130, 2133, 2139, 2142, 2143, 2144, 2146, 2147, 2148, 2149, 2150, 2151, 2157, 2158, 2159, 2161, 2162, 2166, 2180, 2182, 2183, 2184, 2193, 2197, 2205, 2206], "paramet": [1, 2, 3, 4, 6, 13, 14, 16, 19, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 45, 49, 51, 54, 56, 57, 58, 60, 62, 64, 67, 68, 69, 71, 86, 87, 88, 150, 155, 170, 172, 173, 175, 178, 179, 180, 195, 196, 206, 209, 233, 240, 254, 255, 260, 267, 297, 313, 315, 317, 319, 321, 325, 331, 393, 400, 402, 415, 445, 446, 447, 448, 449, 458, 471, 493, 496, 497, 498, 499, 500, 513, 515, 517, 520, 525, 537, 544, 545, 546, 560, 566, 583, 584, 585, 587, 588, 603, 604, 607, 617, 618, 623, 682, 687, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 746, 749, 750, 751, 752, 753, 754, 755, 756, 757, 761, 766, 767, 769, 770, 771, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 788, 790, 791, 792, 793, 794, 796, 797, 798, 800, 802, 804, 806, 808, 810, 811, 814, 815, 816, 829, 837, 839, 840, 841, 842, 843, 846, 851, 852, 866, 867, 868, 869, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 923, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 959, 961, 962, 965, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1004, 1005, 1008, 1012, 1014, 1015, 1016, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1031, 1035, 1036, 1037, 1039, 1040, 1041, 1042, 1044, 1045, 1046, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1060, 1061, 1062, 1064, 1065, 1069, 1070, 1071, 1073, 1074, 1078, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1094, 1095, 1097, 1099, 1101, 1102, 1103, 1104, 1105, 1107, 1108, 1109, 1110, 1111, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1139, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1149, 1154, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1194, 1195, 1196, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1211, 1212, 1213, 1226, 1228, 1235, 1237, 1247, 1248, 1249, 1253, 1255, 1256, 1257, 1258, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1285, 1289, 1291, 1293, 1294, 1296, 1299, 1300, 1301, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1321, 1322, 1325, 1326, 1327, 1328, 1330, 1331, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1427, 1428, 1429, 1433, 1434, 1438, 1439, 1441, 1443, 1444, 1445, 1447, 1448, 1449, 1452, 1453, 1457, 1458, 1460, 1461, 1462, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1612, 1613, 1614, 1616, 1617, 1618, 1620, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1653, 1654, 1655, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1682, 1683, 1685, 1686, 1688, 1690, 1695, 1697, 1698, 1705, 1711, 1712, 1713, 1718, 1722, 1723, 1724, 1725, 1727, 1728, 1729, 1730, 1731, 1738, 1744, 1745, 1753, 1757, 1758, 1759, 1760, 1763, 1768, 1769, 1770, 1771, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1881, 1882, 1883, 1885, 1886, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1923, 1924, 1928, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1940, 1941, 1942, 1943, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1960, 1961, 1963, 1965, 1966, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1993, 1994, 1998, 2000, 2004, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2050, 2051, 2052, 2054, 2055, 2057, 2060, 2061, 2062, 2064, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2093, 2096, 2098, 2100, 2104, 2106, 2107, 2114, 2116, 2117, 2118, 2122, 2124, 2126, 2127, 2130, 2132, 2133, 2136, 2137, 2139, 2140, 2142, 2144, 2146, 2147, 2150, 2154, 2156, 2158, 2159, 2161, 2165, 2166, 2167, 2171, 2172, 2173, 2176, 2178, 2181, 2182, 2185, 2186, 2189, 2195, 2203, 2204, 2206, 2207], "str": [1, 2, 3, 4, 6, 16, 21, 25, 26, 30, 32, 34, 35, 36, 37, 38, 39, 41, 45, 49, 51, 54, 56, 57, 58, 60, 69, 321, 513, 517, 603, 687, 690, 691, 693, 790, 796, 805, 806, 807, 810, 813, 830, 831, 832, 884, 938, 940, 952, 959, 961, 965, 990, 1002, 1012, 1014, 1030, 1037, 1051, 1052, 1053, 1056, 1067, 1068, 1069, 1070, 1071, 1072, 1078, 1086, 1087, 1088, 1095, 1101, 1102, 1104, 1105, 1107, 1119, 1139, 1144, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1196, 1201, 1202, 1206, 1211, 1213, 1219, 1221, 1225, 1226, 1228, 1232, 1264, 1288, 1312, 1313, 1314, 1315, 1317, 1318, 1321, 1324, 1360, 1373, 1378, 1379, 1386, 1387, 1416, 1433, 1434, 1457, 1458, 1473, 1492, 1493, 1499, 1507, 1508, 1509, 1513, 1515, 1523, 1529, 1533, 1539, 1540, 1545, 1546, 1556, 1557, 1558, 1571, 1572, 1580, 1581, 1583, 1584, 1585, 1587, 1590, 1594, 1595, 1598, 1609, 1612, 1613, 1624, 1626, 1628, 1629, 1630, 1631, 1633, 1658, 1659, 1669, 1670, 1678, 1683, 1686, 1695, 1697, 1698, 1718, 1722, 1725, 1730, 1757, 1769, 1770, 1787, 1788, 1789, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1817, 1821, 1822, 1824, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1893, 1924, 1928, 1935, 1936, 1970, 1990, 2035, 2036, 2045, 2055, 2059, 2060, 2061, 2062, 2063, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2084, 2091, 2093, 2094, 2095, 2096, 2097, 2100, 2106, 2107, 2109, 2114, 2116, 2122, 2124, 2127, 2141, 2147, 2150, 2154, 2155, 2157, 2158, 2159, 2165, 2166, 2173, 2176, 2178, 2180, 2181, 2182, 2184, 2185, 2192, 2199, 2203, 2206, 2207], "devic": [1, 2, 3, 6, 9, 16, 18, 19, 20, 21, 22, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 52, 54, 56, 57, 58, 60, 64, 67, 68, 69, 71, 73, 76, 80, 81, 82, 86, 87, 88, 196, 206, 209, 289, 313, 321, 335, 445, 446, 447, 448, 449, 515, 517, 580, 623, 684, 685, 686, 687, 690, 691, 692, 693, 697, 700, 734, 735, 736, 737, 738, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 760, 761, 762, 763, 764, 765, 766, 895, 907, 909, 910, 938, 940, 967, 970, 971, 973, 980, 982, 1002, 1004, 1007, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1039, 1040, 1041, 1043, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1059, 1060, 1061, 1064, 1065, 1069, 1070, 1071, 1073, 1074, 1075, 1084, 1086, 1087, 1088, 1092, 1093, 1094, 1095, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1114, 1115, 1116, 1117, 1120, 1121, 1122, 1145, 1146, 1147, 1157, 1162, 1180, 1196, 1199, 1200, 1226, 1260, 1263, 1272, 1273, 1314, 1318, 1322, 1325, 1328, 1334, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1355, 1356, 1357, 1358, 1361, 1362, 1363, 1369, 1372, 1373, 1375, 1376, 1378, 1379, 1385, 1386, 1401, 1404, 1407, 1409, 1415, 1419, 1424, 1427, 1428, 1436, 1438, 1439, 1440, 1443, 1445, 1446, 1447, 1448, 1450, 1451, 1452, 1453, 1455, 1457, 1458, 1460, 1461, 1464, 1484, 1494, 1495, 1496, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1522, 1523, 1531, 1532, 1534, 1542, 1543, 1544, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1580, 1586, 1588, 1595, 1596, 1597, 1598, 1620, 1624, 1626, 1628, 1640, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1678, 1697, 1703, 1738, 1753, 1757, 1758, 1759, 1760, 1769, 1770, 1773, 1774, 1776, 1777, 1778, 1779, 1780, 1785, 1813, 1820, 1826, 1828, 1831, 1832, 1843, 1877, 1892, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1929, 1932, 1936, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1970, 1971, 1976, 1977, 1978, 1979, 1980, 1981, 1994, 2011, 2013, 2022, 2024, 2033, 2034, 2036, 2050, 2052, 2053, 2054, 2056, 2057, 2060, 2061, 2062, 2064, 2065, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2084, 2085, 2086, 2088, 2089, 2090, 2093, 2094, 2095, 2096, 2098, 2100, 2106, 2111, 2113, 2115, 2117, 2122, 2126, 2132, 2133, 2134, 2135, 2136, 2137, 2139, 2141, 2142, 2143, 2144, 2146, 2147, 2150, 2154, 2155, 2157, 2158, 2159, 2160, 2161, 2165, 2166, 2171, 2173, 2177, 2178, 2180, 2185, 2186, 2189, 2192, 2193, 2194, 2195, 2197, 2199, 2201, 2202, 2204, 2205, 2207], "possibl": [1, 3, 10, 16, 17, 20, 21, 30, 32, 36, 39, 56, 58, 64, 65, 69, 497, 498, 580, 617, 888, 909, 910, 996, 1002, 1048, 1145, 1146, 1147, 1192, 1205, 1218, 1227, 1238, 1240, 1241, 1314, 1328, 1355, 1368, 1371, 1372, 1375, 1380, 1386, 1493, 1499, 1580, 1586, 1677, 1678, 1697, 1731, 1757, 1793, 1794, 1877, 1912, 1915, 1930, 1982, 1990, 2011, 2093, 2095, 2096, 2100, 2108, 2114, 2115, 2117, 2124, 2127, 2129, 2130, 2132, 2133, 2136, 2138, 2144, 2145, 2146, 2148, 2158, 2161, 2166, 2168, 2174, 2178, 2180, 2183, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2200, 2204, 2205], "valu": [1, 2, 3, 4, 6, 8, 9, 10, 13, 14, 16, 20, 21, 22, 25, 26, 27, 29, 31, 32, 34, 35, 36, 37, 39, 41, 43, 45, 48, 49, 51, 52, 56, 57, 60, 62, 65, 67, 68, 69, 71, 73, 76, 80, 82, 87, 101, 102, 103, 104, 119, 150, 154, 235, 236, 237, 238, 254, 259, 260, 272, 273, 299, 311, 313, 315, 316, 317, 318, 319, 321, 323, 326, 352, 399, 400, 415, 419, 420, 422, 423, 471, 481, 483, 499, 513, 515, 517, 537, 544, 560, 583, 584, 585, 587, 588, 599, 600, 681, 682, 695, 698, 699, 702, 706, 707, 708, 746, 767, 775, 781, 782, 790, 795, 796, 798, 806, 808, 809, 813, 814, 817, 837, 839, 840, 841, 846, 851, 852, 884, 889, 895, 904, 905, 906, 910, 915, 919, 921, 923, 924, 928, 929, 930, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 958, 967, 969, 971, 972, 973, 978, 980, 986, 990, 994, 995, 997, 1008, 1014, 1022, 1023, 1026, 1040, 1077, 1086, 1087, 1096, 1101, 1115, 1123, 1124, 1127, 1135, 1136, 1145, 1146, 1147, 1149, 1158, 1159, 1161, 1163, 1165, 1166, 1167, 1172, 1174, 1175, 1176, 1177, 1178, 1187, 1192, 1199, 1201, 1202, 1203, 1204, 1208, 1209, 1211, 1212, 1220, 1221, 1222, 1226, 1227, 1228, 1230, 1232, 1236, 1238, 1240, 1241, 1242, 1245, 1247, 1248, 1249, 1255, 1257, 1262, 1264, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1285, 1299, 1304, 1305, 1306, 1307, 1310, 1311, 1312, 1314, 1315, 1317, 1321, 1322, 1330, 1333, 1335, 1336, 1339, 1343, 1344, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1357, 1358, 1359, 1360, 1364, 1367, 1369, 1371, 1372, 1374, 1378, 1379, 1384, 1385, 1386, 1387, 1390, 1395, 1401, 1403, 1404, 1407, 1412, 1414, 1415, 1417, 1420, 1438, 1441, 1466, 1470, 1471, 1472, 1473, 1476, 1477, 1480, 1484, 1489, 1490, 1491, 1492, 1494, 1495, 1496, 1497, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1521, 1522, 1523, 1524, 1526, 1533, 1534, 1535, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1565, 1566, 1567, 1570, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1594, 1595, 1609, 1612, 1614, 1615, 1616, 1617, 1618, 1620, 1623, 1624, 1626, 1628, 1629, 1630, 1632, 1633, 1641, 1642, 1643, 1658, 1659, 1661, 1662, 1663, 1668, 1669, 1678, 1679, 1683, 1686, 1688, 1695, 1697, 1698, 1699, 1711, 1712, 1713, 1718, 1722, 1723, 1724, 1725, 1727, 1730, 1738, 1751, 1752, 1757, 1759, 1760, 1762, 1763, 1764, 1767, 1768, 1769, 1770, 1777, 1787, 1788, 1790, 1791, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1806, 1807, 1813, 1816, 1817, 1820, 1822, 1826, 1827, 1831, 1832, 1833, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1852, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1877, 1878, 1882, 1886, 1889, 1893, 1895, 1896, 1908, 1910, 1912, 1913, 1914, 1919, 1920, 1921, 1928, 1931, 1940, 1943, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1961, 1965, 1970, 1971, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 1994, 1995, 2008, 2012, 2015, 2018, 2021, 2022, 2023, 2024, 2026, 2029, 2030, 2032, 2048, 2078, 2089, 2090, 2091, 2093, 2094, 2097, 2100, 2103, 2104, 2107, 2109, 2111, 2114, 2117, 2122, 2124, 2126, 2127, 2129, 2130, 2133, 2134, 2135, 2138, 2139, 2142, 2144, 2146, 2147, 2150, 2154, 2155, 2157, 2158, 2159, 2161, 2164, 2165, 2166, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2182, 2189, 2191, 2192, 2193, 2195, 2198, 2199, 2203, 2204, 2205, 2209], "so": [1, 2, 3, 4, 8, 10, 16, 19, 21, 25, 26, 29, 30, 31, 32, 34, 35, 36, 39, 40, 43, 44, 51, 52, 55, 56, 57, 58, 60, 63, 64, 65, 68, 69, 71, 81, 82, 335, 458, 486, 496, 681, 889, 925, 930, 933, 935, 938, 939, 944, 956, 999, 1002, 1004, 1007, 1038, 1042, 1066, 1132, 1134, 1144, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1169, 1170, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1195, 1198, 1201, 1205, 1206, 1208, 1209, 1224, 1226, 1228, 1239, 1241, 1253, 1301, 1311, 1314, 1317, 1318, 1324, 1326, 1328, 1370, 1372, 1382, 1387, 1392, 1404, 1426, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1523, 1526, 1533, 1580, 1597, 1614, 1616, 1632, 1642, 1643, 1651, 1661, 1662, 1663, 1686, 1744, 1745, 1760, 1770, 1826, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1877, 1957, 1972, 1985, 1990, 1994, 2017, 2029, 2034, 2039, 2058, 2093, 2095, 2096, 2102, 2104, 2106, 2108, 2109, 2114, 2115, 2116, 2117, 2124, 2126, 2127, 2130, 2132, 2133, 2134, 2136, 2138, 2139, 2140, 2141, 2142, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2154, 2157, 2158, 2161, 2165, 2166, 2171, 2172, 2174, 2176, 2177, 2180, 2184, 2186, 2189, 2191, 2192, 2194, 2195, 2196, 2198, 2200, 2202, 2203, 2204, 2205, 2207, 2212], "The": [1, 2, 3, 4, 6, 8, 9, 13, 14, 16, 17, 19, 20, 21, 22, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 64, 65, 66, 67, 68, 71, 79, 80, 86, 87, 150, 191, 196, 208, 209, 221, 233, 255, 290, 311, 313, 315, 319, 321, 398, 400, 401, 402, 448, 458, 483, 486, 487, 488, 493, 495, 498, 499, 513, 515, 517, 537, 544, 583, 603, 617, 618, 623, 681, 684, 695, 698, 699, 700, 701, 705, 706, 707, 708, 746, 759, 768, 771, 777, 778, 779, 780, 783, 784, 785, 790, 791, 793, 794, 796, 797, 798, 805, 806, 807, 808, 814, 817, 830, 832, 834, 837, 839, 840, 841, 846, 852, 865, 866, 884, 889, 894, 907, 908, 910, 914, 915, 919, 920, 922, 923, 925, 928, 929, 935, 936, 938, 939, 941, 942, 943, 944, 949, 950, 954, 955, 958, 961, 963, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 987, 988, 1001, 1004, 1005, 1008, 1014, 1015, 1016, 1019, 1023, 1027, 1039, 1047, 1054, 1057, 1074, 1086, 1087, 1089, 1090, 1091, 1101, 1115, 1116, 1117, 1121, 1127, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1144, 1145, 1149, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1192, 1194, 1195, 1197, 1198, 1199, 1202, 1205, 1208, 1211, 1212, 1213, 1222, 1224, 1226, 1232, 1233, 1237, 1253, 1257, 1258, 1267, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1279, 1281, 1285, 1289, 1290, 1291, 1311, 1314, 1317, 1319, 1322, 1325, 1326, 1328, 1330, 1331, 1334, 1335, 1339, 1340, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1360, 1361, 1362, 1364, 1367, 1369, 1370, 1371, 1372, 1373, 1374, 1377, 1378, 1379, 1381, 1384, 1386, 1387, 1402, 1403, 1404, 1405, 1407, 1408, 1409, 1415, 1423, 1425, 1428, 1429, 1433, 1434, 1438, 1439, 1443, 1453, 1461, 1466, 1472, 1475, 1477, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1522, 1523, 1524, 1526, 1527, 1528, 1531, 1532, 1533, 1534, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1568, 1570, 1571, 1572, 1573, 1574, 1575, 1580, 1583, 1585, 1587, 1594, 1595, 1596, 1597, 1598, 1599, 1609, 1610, 1612, 1620, 1623, 1624, 1629, 1630, 1632, 1633, 1639, 1641, 1642, 1643, 1651, 1654, 1655, 1669, 1670, 1677, 1678, 1679, 1681, 1682, 1685, 1686, 1688, 1695, 1697, 1698, 1704, 1711, 1712, 1713, 1725, 1738, 1741, 1757, 1760, 1762, 1763, 1764, 1767, 1768, 1769, 1770, 1773, 1774, 1776, 1777, 1778, 1779, 1780, 1781, 1783, 1785, 1786, 1787, 1788, 1789, 1791, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1810, 1816, 1820, 1821, 1824, 1826, 1827, 1828, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1882, 1883, 1886, 1889, 1892, 1897, 1898, 1899, 1901, 1903, 1905, 1910, 1912, 1914, 1916, 1917, 1919, 1921, 1924, 1931, 1932, 1933, 1934, 1936, 1940, 1941, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1961, 1967, 1968, 1970, 1971, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1988, 1989, 1990, 1994, 1995, 2007, 2013, 2014, 2015, 2017, 2018, 2021, 2022, 2023, 2024, 2031, 2032, 2033, 2036, 2039, 2040, 2041, 2043, 2045, 2048, 2050, 2064, 2071, 2072, 2078, 2085, 2086, 2091, 2093, 2094, 2095, 2097, 2098, 2100, 2102, 2103, 2104, 2106, 2107, 2108, 2109, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2122, 2123, 2124, 2126, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2154, 2156, 2157, 2158, 2159, 2161, 2164, 2165, 2166, 2167, 2168, 2169, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2183, 2185, 2186, 2188, 2189, 2190, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2201, 2202, 2203, 2204, 2205, 2207, 2209, 2210], "same": [1, 2, 4, 8, 13, 14, 16, 17, 19, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 63, 65, 68, 69, 71, 79, 80, 139, 153, 195, 221, 255, 311, 313, 315, 319, 321, 339, 445, 446, 447, 448, 449, 471, 483, 486, 497, 498, 500, 513, 515, 517, 520, 544, 580, 617, 618, 697, 700, 704, 706, 707, 708, 710, 731, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 756, 757, 767, 769, 772, 773, 774, 775, 776, 790, 796, 800, 802, 806, 807, 809, 815, 817, 829, 837, 841, 843, 846, 889, 891, 908, 909, 910, 922, 928, 930, 932, 935, 936, 938, 939, 940, 941, 942, 943, 949, 950, 970, 972, 973, 982, 984, 986, 989, 994, 995, 996, 1002, 1005, 1015, 1016, 1019, 1036, 1037, 1039, 1052, 1054, 1078, 1089, 1127, 1132, 1134, 1135, 1141, 1144, 1146, 1147, 1150, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1192, 1197, 1198, 1200, 1201, 1202, 1205, 1206, 1207, 1208, 1211, 1212, 1213, 1236, 1255, 1258, 1268, 1276, 1277, 1285, 1289, 1305, 1311, 1314, 1320, 1325, 1326, 1330, 1331, 1335, 1336, 1344, 1345, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1382, 1402, 1406, 1408, 1409, 1412, 1414, 1415, 1416, 1417, 1420, 1471, 1474, 1475, 1476, 1482, 1483, 1486, 1487, 1488, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1517, 1518, 1519, 1520, 1521, 1523, 1524, 1526, 1529, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1548, 1549, 1552, 1562, 1563, 1564, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1583, 1584, 1585, 1586, 1588, 1589, 1594, 1595, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1632, 1633, 1636, 1637, 1638, 1651, 1657, 1658, 1659, 1661, 1662, 1663, 1669, 1678, 1686, 1688, 1697, 1698, 1738, 1757, 1765, 1766, 1769, 1770, 1779, 1780, 1787, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1813, 1817, 1822, 1827, 1828, 1832, 1835, 1874, 1877, 1880, 1885, 1886, 1889, 1890, 1902, 1904, 1906, 1910, 1912, 1914, 1915, 1919, 1921, 1928, 1931, 1932, 1936, 1943, 1948, 1966, 1976, 1977, 1978, 1980, 1981, 1987, 1988, 1989, 1993, 1994, 2007, 2018, 2029, 2030, 2031, 2032, 2033, 2040, 2041, 2042, 2045, 2050, 2090, 2091, 2093, 2095, 2096, 2100, 2104, 2109, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2128, 2129, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2144, 2145, 2146, 2147, 2154, 2157, 2158, 2159, 2161, 2164, 2166, 2167, 2168, 2171, 2173, 2174, 2175, 2176, 2177, 2178, 2181, 2182, 2184, 2185, 2188, 2189, 2190, 2191, 2192, 2194, 2195, 2200, 2202, 2203, 2204, 2205, 2206], "attribut": [1, 2, 13, 14, 25, 26, 30, 31, 37, 40, 57, 58, 69, 71, 73, 78, 150, 290, 495, 496, 738, 749, 750, 751, 752, 753, 754, 756, 757, 767, 775, 804, 816, 817, 830, 831, 832, 866, 868, 869, 888, 889, 919, 923, 928, 930, 933, 935, 936, 1195, 1225, 1226, 1311, 1313, 1314, 1315, 1317, 1318, 1320, 1325, 1326, 1387, 1516, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1580, 1624, 1770, 1771, 1772, 1793, 1794, 1814, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1990, 2033, 2034, 2037, 2094, 2097, 2100, 2108, 2122, 2126, 2127, 2130, 2133, 2134, 2142, 2147, 2150, 2154, 2158, 2160, 2161, 2166, 2173, 2177, 2178, 2195, 2203, 2206, 2210], "thu": [1, 2, 13, 25, 30, 36, 39, 52, 57, 58, 60, 69, 796, 841, 846, 884, 1144, 1165, 1378, 1409, 1519, 1633, 1757, 1770, 1857, 1979, 2093, 2096, 2103, 2106, 2117, 2127, 2129, 2133, 2135, 2138, 2140, 2142, 2161, 2166, 2171, 2175, 2177, 2178, 2180, 2204], "you": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 16, 17, 19, 21, 24, 25, 26, 30, 34, 35, 36, 37, 38, 39, 41, 43, 48, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 68, 69, 71, 81, 82, 150, 254, 335, 448, 486, 488, 499, 681, 700, 745, 746, 759, 768, 792, 919, 920, 921, 922, 923, 930, 932, 933, 935, 936, 938, 939, 940, 944, 945, 956, 984, 1002, 1004, 1014, 1037, 1065, 1078, 1080, 1089, 1090, 1112, 1144, 1201, 1202, 1205, 1206, 1207, 1208, 1213, 1217, 1218, 1222, 1226, 1227, 1228, 1237, 1241, 1314, 1318, 1319, 1327, 1330, 1331, 1332, 1360, 1378, 1386, 1409, 1416, 1419, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1550, 1576, 1577, 1578, 1580, 1585, 1586, 1587, 1596, 1615, 1624, 1626, 1628, 1633, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1697, 1703, 1738, 1756, 1757, 1760, 1763, 1770, 1788, 1814, 1822, 1824, 1825, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1872, 1877, 1892, 1915, 1924, 1932, 1976, 1977, 1978, 1980, 1981, 1985, 1993, 2034, 2036, 2045, 2057, 2071, 2082, 2091, 2093, 2095, 2096, 2098, 2100, 2103, 2104, 2106, 2108, 2109, 2114, 2115, 2117, 2124, 2126, 2127, 2128, 2130, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2146, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2162, 2164, 2165, 2166, 2167, 2168, 2171, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2183, 2184, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2198, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2212], "obtain": [1, 4, 25, 30, 39, 44, 68, 69, 87, 496, 1258, 1438, 1499, 1587, 1670, 1770, 1844, 1856, 1882, 1899, 1995, 2096, 2114, 2115, 2129, 2146, 2154, 2157, 2159, 2161, 2173, 2202], "tensor": [1, 3, 6, 8, 9, 14, 16, 19, 20, 25, 26, 29, 30, 31, 32, 34, 35, 36, 39, 40, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 87, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 731, 743, 745, 746, 749, 750, 751, 752, 753, 754, 755, 756, 757, 759, 761, 766, 767, 768, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 795, 796, 797, 798, 800, 802, 803, 807, 810, 812, 813, 814, 815, 816, 817, 837, 839, 840, 841, 843, 846, 852, 895, 896, 897, 898, 899, 900, 901, 902, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 928, 929, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 949, 950, 952, 954, 955, 956, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1004, 1007, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1036, 1051, 1052, 1053, 1054, 1055, 1056, 1065, 1074, 1075, 1082, 1086, 1089, 1092, 1097, 1109, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1225, 1226, 1228, 1233, 1236, 1237, 1251, 1255, 1256, 1257, 1258, 1259, 1260, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1291, 1292, 1293, 1294, 1296, 1299, 1301, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1317, 1318, 1320, 1321, 1322, 1325, 1326, 1328, 1330, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1428, 1441, 1453, 1465, 1466, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1484, 1488, 1489, 1492, 1493, 1497, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1525, 1526, 1531, 1532, 1533, 1539, 1545, 1546, 1550, 1551, 1567, 1570, 1571, 1572, 1573, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1590, 1591, 1592, 1593, 1595, 1596, 1598, 1602, 1603, 1604, 1605, 1606, 1607, 1613, 1614, 1615, 1616, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1641, 1642, 1643, 1645, 1646, 1647, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1769, 1770, 1771, 1772, 1773, 1775, 1776, 1777, 1778, 1779, 1780, 1782, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1810, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1930, 1931, 1932, 1933, 1934, 1937, 1940, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 2006, 2007, 2008, 2009, 2010, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2036, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2057, 2064, 2065, 2073, 2076, 2089, 2090, 2092, 2093, 2095, 2096, 2100, 2103, 2118, 2122, 2124, 2126, 2128, 2129, 2130, 2132, 2134, 2135, 2136, 2137, 2139, 2141, 2142, 2143, 2144, 2145, 2146, 2148, 2150, 2151, 2155, 2157, 2158, 2159, 2160, 2162, 2165, 2166, 2167, 2170, 2172, 2173, 2176, 2178, 2181, 2182, 2183, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2195, 2197, 2199, 2202, 2203, 2205, 2206, 2207], "class": [1, 2, 3, 4, 6, 14, 17, 19, 25, 26, 30, 31, 32, 34, 35, 36, 38, 39, 41, 43, 45, 48, 49, 51, 53, 54, 56, 57, 58, 60, 65, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 557, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 800, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 839, 840, 841, 842, 843, 846, 851, 852, 864, 865, 866, 867, 868, 869, 870, 871, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 924, 925, 930, 931, 932, 933, 934, 935, 936, 945, 946, 947, 957, 958, 965, 966, 967, 968, 969, 1029, 1037, 1038, 1039, 1040, 1041, 1042, 1044, 1045, 1062, 1065, 1078, 1148, 1211, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1312, 1313, 1314, 1317, 1319, 1320, 1321, 1325, 1326, 1329, 1330, 1331, 1332, 1427, 1443, 1444, 1445, 1449, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1659, 1669, 1677, 1722, 1724, 1738, 1760, 1769, 1770, 1771, 1772, 1773, 1774, 1790, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1813, 1820, 1825, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1899, 1968, 2034, 2050, 2052, 2055, 2057, 2094, 2097, 2100, 2103, 2108, 2109, 2114, 2116, 2118, 2119, 2122, 2126, 2127, 2130, 2133, 2134, 2135, 2136, 2142, 2144, 2147, 2149, 2150, 2156, 2159, 2161, 2163, 2164, 2166, 2167, 2170, 2171, 2173, 2174, 2176, 2178, 2180, 2181, 2182, 2185, 2186, 2190, 2191, 2192, 2193, 2195, 2200, 2202, 2203, 2204, 2205, 2206, 2207, 2210], "dtype": [1, 2, 6, 13, 14, 20, 23, 25, 26, 30, 32, 34, 36, 37, 56, 57, 58, 60, 67, 69, 71, 79, 80, 153, 154, 191, 208, 212, 213, 214, 215, 242, 311, 313, 315, 317, 319, 321, 401, 402, 409, 429, 432, 445, 446, 447, 448, 449, 453, 458, 470, 481, 483, 513, 515, 565, 580, 581, 603, 617, 698, 700, 703, 704, 708, 710, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 756, 757, 760, 761, 762, 763, 764, 765, 766, 767, 769, 771, 772, 775, 776, 783, 784, 785, 807, 808, 814, 837, 839, 840, 841, 842, 843, 846, 851, 852, 871, 888, 889, 891, 892, 895, 909, 910, 930, 931, 933, 935, 936, 938, 940, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 987, 994, 995, 1004, 1016, 1019, 1020, 1021, 1027, 1036, 1054, 1125, 1126, 1145, 1146, 1147, 1157, 1161, 1162, 1163, 1169, 1170, 1180, 1187, 1192, 1194, 1196, 1197, 1198, 1199, 1200, 1226, 1261, 1272, 1273, 1285, 1314, 1318, 1328, 1334, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1396, 1397, 1398, 1399, 1401, 1404, 1405, 1409, 1413, 1414, 1415, 1418, 1419, 1466, 1470, 1471, 1472, 1474, 1484, 1493, 1494, 1495, 1496, 1497, 1499, 1500, 1501, 1502, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1522, 1523, 1526, 1531, 1532, 1534, 1542, 1543, 1544, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1580, 1586, 1587, 1588, 1595, 1596, 1597, 1598, 1602, 1603, 1604, 1605, 1606, 1620, 1624, 1626, 1628, 1632, 1633, 1634, 1635, 1640, 1641, 1642, 1643, 1653, 1669, 1670, 1697, 1703, 1705, 1738, 1744, 1745, 1760, 1769, 1773, 1774, 1779, 1780, 1790, 1793, 1794, 1813, 1827, 1831, 1832, 1833, 1835, 1877, 1880, 1886, 1890, 1891, 1894, 1895, 1896, 1897, 1898, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1910, 1918, 1921, 1933, 1934, 1936, 1937, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1964, 1967, 1969, 1972, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1993, 1994, 2008, 2011, 2022, 2024, 2029, 2033, 2034, 2036, 2043, 2044, 2048, 2089, 2090, 2093, 2094, 2095, 2096, 2098, 2100, 2103, 2116, 2117, 2122, 2130, 2133, 2137, 2142, 2145, 2149, 2150, 2151, 2154, 2155, 2161, 2162, 2163, 2171, 2172, 2173, 2176, 2177, 2178, 2185, 2193, 2194, 2195, 2199, 2204, 2205, 2210], "none": [1, 2, 3, 4, 6, 14, 16, 19, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 48, 49, 51, 54, 56, 57, 58, 60, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 112, 114, 115, 116, 118, 134, 135, 138, 150, 153, 154, 156, 173, 185, 186, 187, 188, 204, 205, 207, 209, 212, 213, 214, 215, 229, 235, 236, 237, 238, 258, 286, 290, 301, 335, 351, 354, 377, 407, 409, 410, 411, 414, 421, 427, 428, 429, 430, 431, 432, 445, 446, 447, 448, 449, 453, 454, 470, 479, 481, 487, 488, 494, 503, 513, 520, 537, 538, 552, 553, 555, 556, 565, 580, 581, 583, 588, 590, 603, 608, 609, 610, 615, 623, 627, 629, 631, 633, 635, 637, 639, 641, 643, 645, 647, 649, 651, 653, 656, 658, 660, 661, 663, 665, 667, 669, 671, 673, 675, 677, 679, 680, 681, 684, 687, 693, 696, 697, 698, 699, 700, 701, 702, 704, 706, 707, 708, 710, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 738, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 756, 757, 760, 761, 762, 763, 764, 765, 766, 777, 778, 779, 780, 790, 791, 792, 793, 794, 796, 797, 798, 800, 802, 806, 807, 808, 811, 814, 829, 832, 837, 839, 840, 841, 846, 851, 866, 868, 869, 887, 888, 889, 890, 891, 892, 895, 904, 905, 908, 909, 910, 919, 920, 921, 922, 923, 925, 927, 928, 929, 930, 933, 934, 935, 936, 939, 941, 942, 943, 944, 949, 950, 954, 955, 965, 969, 970, 971, 973, 974, 975, 976, 978, 979, 980, 982, 986, 989, 991, 992, 993, 994, 995, 997, 998, 1000, 1002, 1004, 1008, 1014, 1016, 1017, 1018, 1021, 1022, 1024, 1025, 1026, 1027, 1031, 1035, 1036, 1037, 1039, 1040, 1041, 1044, 1045, 1046, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1060, 1061, 1062, 1064, 1069, 1070, 1071, 1073, 1078, 1088, 1089, 1092, 1093, 1094, 1095, 1097, 1098, 1099, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1115, 1118, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1131, 1136, 1137, 1139, 1140, 1141, 1143, 1145, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1196, 1199, 1200, 1201, 1202, 1203, 1207, 1210, 1211, 1213, 1214, 1216, 1217, 1218, 1226, 1228, 1230, 1231, 1233, 1237, 1238, 1245, 1255, 1256, 1257, 1258, 1259, 1263, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1279, 1280, 1281, 1282, 1283, 1284, 1289, 1291, 1292, 1308, 1309, 1311, 1312, 1313, 1314, 1317, 1318, 1320, 1321, 1322, 1324, 1325, 1326, 1328, 1330, 1331, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1390, 1392, 1393, 1394, 1396, 1397, 1398, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1443, 1444, 1445, 1447, 1448, 1449, 1452, 1457, 1458, 1462, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1476, 1477, 1478, 1479, 1480, 1482, 1483, 1484, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1522, 1523, 1525, 1527, 1528, 1529, 1531, 1532, 1533, 1534, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1590, 1591, 1594, 1595, 1596, 1597, 1598, 1612, 1613, 1614, 1615, 1616, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1633, 1634, 1635, 1646, 1647, 1651, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1669, 1670, 1677, 1678, 1681, 1682, 1683, 1684, 1686, 1687, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1703, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1718, 1719, 1720, 1721, 1722, 1723, 1725, 1727, 1730, 1735, 1738, 1742, 1743, 1744, 1745, 1753, 1754, 1755, 1757, 1758, 1759, 1760, 1762, 1763, 1764, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1785, 1787, 1788, 1789, 1792, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1813, 1815, 1816, 1818, 1821, 1822, 1824, 1825, 1826, 1827, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1881, 1882, 1885, 1886, 1887, 1889, 1890, 1892, 1893, 1896, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1912, 1913, 1914, 1919, 1921, 1922, 1923, 1928, 1940, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1964, 1965, 1969, 1971, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1983, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 2008, 2009, 2010, 2011, 2013, 2015, 2018, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2029, 2030, 2034, 2036, 2039, 2040, 2041, 2042, 2045, 2047, 2048, 2049, 2050, 2051, 2052, 2054, 2055, 2060, 2061, 2062, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2087, 2088, 2089, 2090, 2091, 2093, 2094, 2095, 2096, 2097, 2100, 2106, 2107, 2109, 2114, 2115, 2116, 2117, 2122, 2124, 2127, 2130, 2133, 2134, 2141, 2142, 2144, 2147, 2150, 2154, 2156, 2157, 2158, 2159, 2161, 2163, 2165, 2166, 2172, 2173, 2174, 2176, 2177, 2178, 2181, 2182, 2184, 2185, 2186, 2190, 2192, 2193, 2194, 2195, 2199, 2204, 2205, 2206, 2207], "enabl": [1, 2, 3, 4, 6, 9, 14, 20, 22, 23, 25, 26, 30, 31, 32, 35, 36, 37, 38, 39, 41, 52, 56, 60, 67, 488, 503, 504, 681, 771, 811, 827, 828, 930, 933, 935, 945, 946, 947, 956, 965, 1002, 1014, 1019, 1037, 1089, 1096, 1144, 1148, 1217, 1297, 1298, 1316, 1323, 1433, 1434, 1531, 1550, 1596, 1597, 1627, 1644, 1738, 1770, 1790, 1791, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1825, 1859, 1937, 1940, 1968, 2033, 2096, 2100, 2102, 2103, 2106, 2110, 2111, 2112, 2117, 2122, 2126, 2127, 2128, 2129, 2130, 2133, 2136, 2137, 2140, 2143, 2145, 2146, 2150, 2154, 2157, 2159, 2165, 2166, 2167, 2171, 2180, 2182, 2183, 2184, 2185, 2188, 2189, 2190, 2192, 2193, 2194, 2195, 2198, 2202, 2205, 2206, 2207, 2209], "true": [1, 2, 3, 4, 6, 14, 16, 21, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 54, 56, 58, 60, 65, 66, 68, 69, 71, 74, 79, 86, 88, 150, 196, 209, 233, 260, 319, 321, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 343, 351, 396, 400, 402, 415, 448, 458, 460, 471, 477, 487, 488, 495, 496, 499, 504, 516, 517, 556, 567, 580, 581, 590, 594, 603, 609, 617, 623, 681, 684, 693, 698, 703, 704, 705, 706, 707, 708, 710, 729, 730, 731, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 749, 750, 751, 752, 753, 754, 757, 760, 765, 767, 771, 772, 775, 776, 779, 780, 790, 796, 797, 811, 829, 851, 870, 889, 903, 905, 906, 910, 919, 922, 923, 925, 930, 931, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 952, 954, 955, 965, 971, 974, 977, 979, 980, 986, 987, 993, 1001, 1002, 1005, 1008, 1010, 1015, 1019, 1020, 1039, 1084, 1096, 1139, 1145, 1146, 1147, 1148, 1149, 1150, 1166, 1167, 1173, 1174, 1196, 1198, 1201, 1202, 1203, 1204, 1206, 1207, 1208, 1212, 1213, 1216, 1226, 1228, 1238, 1240, 1241, 1247, 1248, 1249, 1253, 1255, 1257, 1271, 1272, 1273, 1276, 1277, 1288, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1318, 1319, 1321, 1324, 1330, 1331, 1332, 1334, 1336, 1339, 1344, 1345, 1356, 1357, 1358, 1361, 1362, 1363, 1364, 1367, 1369, 1371, 1372, 1373, 1375, 1376, 1377, 1378, 1380, 1381, 1384, 1386, 1387, 1396, 1397, 1398, 1399, 1402, 1403, 1404, 1406, 1408, 1412, 1414, 1415, 1416, 1417, 1420, 1427, 1443, 1455, 1466, 1471, 1474, 1477, 1480, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1527, 1528, 1531, 1532, 1533, 1534, 1539, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1589, 1594, 1595, 1596, 1597, 1598, 1612, 1613, 1620, 1624, 1626, 1627, 1628, 1629, 1630, 1633, 1634, 1643, 1651, 1653, 1654, 1655, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1682, 1686, 1688, 1690, 1696, 1697, 1698, 1711, 1712, 1713, 1722, 1730, 1738, 1757, 1758, 1760, 1763, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1781, 1782, 1785, 1787, 1788, 1789, 1792, 1793, 1794, 1805, 1813, 1814, 1815, 1816, 1817, 1819, 1820, 1821, 1822, 1824, 1825, 1826, 1827, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876, 1877, 1880, 1882, 1890, 1892, 1893, 1897, 1898, 1899, 1916, 1917, 1924, 1927, 1928, 1936, 1937, 1940, 1942, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1965, 1967, 1968, 1970, 1974, 1979, 1988, 1989, 1990, 1993, 1994, 2011, 2015, 2020, 2029, 2030, 2033, 2034, 2036, 2039, 2040, 2041, 2045, 2048, 2091, 2094, 2095, 2096, 2100, 2103, 2104, 2105, 2107, 2108, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2142, 2145, 2146, 2149, 2150, 2151, 2152, 2154, 2156, 2158, 2159, 2161, 2162, 2163, 2165, 2166, 2167, 2170, 2171, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2186, 2189, 2191, 2192, 2193, 2195, 2196, 2197, 2199, 2200, 2202, 2203, 2204, 2205, 2206], "cache_en": [1, 1089], "instanc": [1, 3, 4, 25, 26, 30, 31, 32, 35, 36, 38, 39, 40, 41, 48, 51, 52, 54, 56, 60, 65, 69, 139, 617, 681, 745, 759, 768, 806, 809, 843, 851, 871, 888, 1037, 1144, 1195, 1312, 1314, 1326, 1330, 1387, 1522, 1523, 1526, 1542, 1543, 1544, 1552, 1580, 1590, 1625, 1627, 1628, 1632, 1641, 1642, 1643, 1696, 1770, 1788, 1800, 1813, 1821, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1979, 2012, 2093, 2095, 2097, 2102, 2106, 2108, 2114, 2116, 2122, 2126, 2127, 2130, 2132, 2133, 2135, 2136, 2142, 2146, 2150, 2157, 2158, 2161, 2166, 2167, 2168, 2171, 2173, 2178, 2189, 2203, 2204, 2206], "serv": [1, 8, 9, 17, 30, 37, 2103, 2117, 2130, 2157, 2166, 2167, 2173, 2190, 2195, 2199], "context": [1, 3, 6, 19, 25, 30, 32, 35, 37, 38, 41, 42, 51, 52, 56, 60, 69, 71, 150, 805, 919, 920, 921, 923, 925, 935, 936, 944, 945, 946, 947, 949, 965, 1014, 1028, 1029, 1044, 1045, 1062, 1065, 1078, 1084, 1089, 1097, 1105, 1118, 1148, 1203, 1207, 1212, 1217, 1218, 1228, 1233, 1314, 1433, 1444, 1445, 1449, 1462, 1580, 1639, 1644, 1738, 1760, 1770, 1772, 1791, 1793, 1825, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1877, 1968, 2051, 2052, 2055, 2057, 2076, 2087, 2096, 2097, 2104, 2108, 2114, 2126, 2127, 2130, 2133, 2139, 2140, 2144, 2147, 2150, 2154, 2158, 2159, 2165, 2166, 2168, 2171, 2173, 2174, 2180, 2191, 2192, 2194, 2195, 2202, 2204, 2207], "manag": [1, 2, 3, 6, 8, 22, 30, 32, 34, 35, 36, 37, 38, 39, 41, 42, 49, 51, 52, 54, 56, 60, 69, 71, 87, 486, 925, 945, 946, 947, 965, 1014, 1028, 1029, 1037, 1040, 1041, 1044, 1045, 1046, 1047, 1049, 1062, 1065, 1066, 1067, 1078, 1079, 1089, 1092, 1094, 1095, 1097, 1099, 1100, 1101, 1102, 1105, 1109, 1110, 1111, 1118, 1148, 1203, 1207, 1212, 1218, 1228, 1433, 1444, 1445, 1449, 1462, 1597, 1639, 1644, 1738, 1770, 1790, 1791, 1793, 1825, 1968, 2051, 2052, 2055, 2057, 2074, 2077, 2087, 2096, 2097, 2104, 2108, 2113, 2127, 2133, 2135, 2136, 2140, 2147, 2150, 2154, 2159, 2165, 2166, 2167, 2171, 2174, 2180, 2189, 2191, 2194, 2195, 2204, 2208], "decor": [1, 2, 37, 39, 44, 48, 52, 69, 82, 930, 933, 935, 945, 965, 1004, 1008, 1014, 1015, 1105, 1148, 1319, 1320, 1326, 1332, 1825, 1967, 1968, 2093, 2095, 2096, 2100, 2126, 2127, 2133, 2166, 2190, 2192, 2193, 2195, 2196, 2204, 2206], "allow": [1, 2, 3, 4, 6, 8, 9, 10, 13, 14, 16, 17, 19, 21, 25, 26, 30, 31, 32, 34, 36, 37, 39, 41, 43, 51, 52, 56, 60, 61, 63, 64, 65, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 150, 513, 681, 746, 806, 811, 814, 843, 923, 927, 928, 944, 987, 1001, 1005, 1019, 1073, 1086, 1089, 1115, 1144, 1206, 1228, 1233, 1314, 1319, 1332, 1370, 1375, 1392, 1438, 1475, 1489, 1490, 1491, 1515, 1516, 1533, 1573, 1574, 1575, 1580, 1583, 1586, 1609, 1624, 1770, 1777, 1826, 1835, 1838, 1858, 1874, 1877, 1970, 2033, 2091, 2095, 2096, 2100, 2103, 2104, 2111, 2115, 2116, 2117, 2122, 2126, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2139, 2140, 2142, 2144, 2145, 2147, 2150, 2154, 2157, 2158, 2159, 2161, 2163, 2166, 2171, 2173, 2174, 2175, 2176, 2178, 2180, 2189, 2191, 2192, 2193, 2194, 2195, 2200, 2203, 2204, 2205, 2208], "region": [1, 4, 6, 39, 48, 681, 779, 780, 1002, 1014, 1489, 1490, 1491, 1527, 1528, 1538, 1540, 1573, 1574, 1575, 1654, 1655, 1681, 1682, 1712, 1713, 2093, 2114, 2126, 2130, 2179, 2194, 2195, 2204], "your": [1, 2, 3, 5, 8, 9, 10, 13, 16, 17, 19, 21, 25, 29, 30, 34, 35, 38, 39, 42, 43, 44, 48, 50, 51, 52, 54, 55, 56, 58, 60, 64, 65, 68, 69, 486, 923, 930, 933, 935, 938, 939, 944, 945, 956, 1002, 1004, 1005, 1014, 1222, 1227, 1228, 1314, 1318, 1319, 1324, 1327, 1330, 1331, 1332, 1580, 1586, 1587, 1624, 1625, 1626, 1627, 1628, 1770, 1790, 1793, 1825, 1860, 1877, 1937, 2029, 2034, 2036, 2093, 2095, 2096, 2100, 2102, 2104, 2114, 2115, 2116, 2117, 2118, 2126, 2127, 2128, 2130, 2133, 2134, 2135, 2137, 2139, 2140, 2141, 2142, 2143, 2145, 2146, 2148, 2151, 2154, 2157, 2162, 2165, 2167, 2171, 2176, 2177, 2180, 2183, 2184, 2185, 2188, 2189, 2190, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2201, 2202, 2204, 2205, 2206, 2207, 2212], "script": [1, 3, 5, 20, 25, 30, 33, 41, 44, 50, 52, 54, 56, 1057, 1315, 1317, 1318, 1319, 1320, 1321, 1324, 1325, 1327, 1329, 1330, 1332, 2091, 2095, 2096, 2106, 2129, 2140, 2143, 2147, 2149, 2150, 2158, 2161, 2166, 2183, 2185, 2186, 2188, 2190, 2192, 2197, 2198, 2201, 2204], "run": [1, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16, 17, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 68, 69, 71, 73, 80, 150, 486, 488, 681, 805, 812, 832, 837, 839, 840, 841, 846, 887, 891, 892, 893, 923, 944, 945, 949, 950, 965, 1002, 1004, 1014, 1057, 1088, 1089, 1202, 1207, 1213, 1226, 1237, 1254, 1314, 1315, 1317, 1318, 1320, 1322, 1324, 1326, 1328, 1330, 1331, 1351, 1360, 1386, 1387, 1415, 1494, 1495, 1496, 1516, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1595, 1609, 1620, 1738, 1760, 1763, 1769, 1770, 1779, 1780, 1781, 1782, 1783, 1784, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1877, 1936, 1939, 1972, 2022, 2024, 2033, 2045, 2092, 2093, 2096, 2100, 2105, 2106, 2108, 2109, 2110, 2114, 2117, 2122, 2124, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2140, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2150, 2151, 2154, 2157, 2158, 2161, 2164, 2165, 2166, 2167, 2168, 2171, 2176, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2202, 2203, 2204, 2205, 2207], "In": [1, 3, 4, 5, 6, 8, 10, 17, 19, 20, 21, 25, 30, 32, 34, 35, 36, 37, 38, 39, 44, 51, 52, 54, 56, 57, 58, 60, 62, 63, 64, 65, 68, 69, 87, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 121, 123, 125, 127, 130, 131, 133, 141, 143, 146, 147, 149, 152, 154, 158, 160, 162, 164, 166, 168, 177, 186, 194, 198, 201, 203, 213, 215, 221, 231, 236, 238, 244, 247, 249, 251, 253, 257, 258, 262, 269, 271, 273, 277, 279, 283, 285, 292, 294, 296, 304, 306, 308, 310, 356, 358, 360, 362, 364, 366, 368, 371, 373, 375, 376, 383, 385, 387, 389, 391, 395, 420, 423, 426, 428, 439, 441, 443, 451, 456, 466, 469, 485, 486, 490, 492, 508, 511, 522, 527, 529, 532, 534, 536, 549, 551, 553, 562, 564, 571, 575, 577, 593, 596, 598, 600, 602, 612, 622, 681, 771, 815, 843, 884, 930, 933, 935, 936, 954, 969, 978, 986, 1015, 1020, 1021, 1036, 1044, 1089, 1101, 1114, 1115, 1119, 1144, 1165, 1167, 1175, 1176, 1177, 1192, 1203, 1207, 1210, 1212, 1222, 1224, 1227, 1238, 1311, 1312, 1314, 1324, 1327, 1328, 1330, 1346, 1355, 1360, 1361, 1362, 1370, 1373, 1378, 1383, 1387, 1392, 1395, 1404, 1409, 1415, 1416, 1444, 1471, 1489, 1490, 1491, 1493, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1518, 1519, 1520, 1524, 1526, 1531, 1540, 1550, 1565, 1573, 1574, 1575, 1580, 1586, 1624, 1626, 1628, 1632, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1676, 1686, 1693, 1695, 1702, 1731, 1734, 1737, 1738, 1752, 1770, 1779, 1780, 1787, 1793, 1794, 1825, 1860, 1872, 1874, 1877, 1912, 1928, 1930, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1990, 1994, 1995, 2020, 2033, 2034, 2036, 2042, 2043, 2091, 2093, 2095, 2096, 2100, 2102, 2103, 2104, 2114, 2115, 2116, 2117, 2124, 2126, 2129, 2130, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2142, 2144, 2145, 2146, 2147, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2162, 2163, 2166, 2167, 2168, 2171, 2173, 2176, 2178, 2183, 2184, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2201, 2202, 2203, 2204, 2205, 2207], "an": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 48, 49, 50, 51, 52, 54, 55, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 86, 87, 88, 150, 154, 190, 242, 254, 313, 315, 321, 323, 328, 335, 415, 486, 499, 513, 515, 517, 537, 545, 560, 607, 614, 617, 681, 684, 689, 698, 699, 746, 752, 753, 754, 767, 771, 776, 790, 796, 798, 802, 805, 809, 830, 832, 834, 842, 851, 884, 891, 892, 894, 908, 909, 910, 919, 921, 922, 923, 928, 930, 931, 933, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 957, 958, 959, 961, 962, 969, 973, 989, 999, 1002, 1004, 1014, 1020, 1021, 1023, 1037, 1039, 1040, 1044, 1051, 1052, 1053, 1054, 1055, 1056, 1078, 1079, 1086, 1087, 1089, 1102, 1104, 1105, 1115, 1119, 1129, 1142, 1144, 1145, 1146, 1147, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1184, 1187, 1195, 1198, 1201, 1202, 1205, 1206, 1207, 1209, 1211, 1213, 1216, 1221, 1222, 1224, 1226, 1227, 1228, 1232, 1234, 1237, 1238, 1245, 1255, 1258, 1268, 1276, 1277, 1278, 1311, 1312, 1314, 1317, 1318, 1320, 1322, 1325, 1326, 1328, 1330, 1331, 1332, 1333, 1344, 1345, 1350, 1351, 1356, 1358, 1360, 1363, 1364, 1368, 1371, 1373, 1376, 1377, 1384, 1386, 1387, 1404, 1406, 1409, 1414, 1415, 1427, 1438, 1443, 1466, 1475, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1495, 1496, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1527, 1528, 1531, 1539, 1543, 1544, 1547, 1548, 1549, 1550, 1552, 1562, 1563, 1564, 1565, 1567, 1568, 1570, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1582, 1586, 1587, 1588, 1590, 1591, 1592, 1593, 1595, 1596, 1598, 1600, 1609, 1612, 1614, 1615, 1616, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1632, 1634, 1635, 1639, 1640, 1643, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1653, 1661, 1662, 1663, 1664, 1665, 1666, 1671, 1677, 1678, 1680, 1681, 1682, 1686, 1697, 1704, 1705, 1707, 1708, 1709, 1711, 1712, 1713, 1738, 1742, 1757, 1759, 1760, 1763, 1769, 1770, 1775, 1776, 1777, 1778, 1779, 1780, 1785, 1786, 1787, 1791, 1793, 1800, 1814, 1816, 1823, 1825, 1827, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1892, 1897, 1898, 1899, 1918, 1920, 1924, 1932, 1933, 1935, 1943, 1949, 1970, 1973, 1975, 1979, 1982, 1987, 1990, 1994, 1995, 2011, 2012, 2028, 2029, 2030, 2031, 2033, 2036, 2043, 2044, 2045, 2046, 2090, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2102, 2103, 2104, 2106, 2108, 2109, 2110, 2112, 2114, 2115, 2116, 2117, 2118, 2122, 2124, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2159, 2161, 2162, 2163, 2164, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210], "chosen": [1, 19, 21, 56, 65, 1132, 1336, 1517, 1738, 1940, 1965, 2015, 2117, 2126, 2130, 2133, 2144, 2161, 2205], "improv": [1, 2, 4, 10, 16, 23, 26, 30, 32, 34, 56, 60, 69, 771, 819, 820, 821, 938, 940, 944, 1023, 1268, 1517, 1531, 1550, 1596, 1627, 1738, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1874, 2092, 2093, 2117, 2126, 2132, 2133, 2134, 2145, 2146, 2161, 2162, 2166, 2198, 2200, 2202, 2204, 2205, 2207, 2208], "perform": [1, 2, 3, 4, 5, 6, 13, 16, 23, 24, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 45, 51, 52, 56, 58, 60, 64, 68, 69, 119, 206, 209, 458, 486, 580, 603, 617, 623, 697, 698, 699, 700, 701, 702, 771, 792, 819, 820, 821, 877, 888, 891, 930, 933, 935, 938, 940, 941, 944, 945, 949, 970, 982, 1002, 1014, 1015, 1020, 1021, 1046, 1101, 1125, 1126, 1139, 1144, 1164, 1187, 1189, 1201, 1202, 1205, 1222, 1242, 1279, 1314, 1324, 1325, 1330, 1358, 1360, 1363, 1367, 1370, 1371, 1375, 1376, 1384, 1385, 1387, 1392, 1401, 1414, 1419, 1433, 1434, 1468, 1471, 1474, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1519, 1522, 1523, 1531, 1550, 1580, 1586, 1588, 1596, 1609, 1624, 1625, 1626, 1627, 1628, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1705, 1723, 1738, 1744, 1745, 1760, 1770, 1773, 1774, 1788, 1793, 1813, 1820, 1822, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1882, 1890, 1918, 1932, 1936, 1963, 1969, 1970, 1971, 1972, 1993, 1995, 2033, 2092, 2093, 2096, 2100, 2104, 2109, 2110, 2114, 2115, 2116, 2117, 2118, 2122, 2124, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2139, 2143, 2144, 2145, 2146, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2162, 2164, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2183, 2184, 2185, 2188, 2189, 2190, 2191, 2192, 2193, 2195, 2196, 2197, 2198, 2200, 2204, 2206, 2207, 2208, 2209], "while": [1, 3, 4, 6, 8, 9, 13, 16, 25, 26, 30, 31, 32, 34, 36, 39, 54, 56, 57, 58, 60, 65, 68, 69, 706, 707, 746, 884, 914, 922, 935, 936, 954, 1040, 1044, 1202, 1221, 1277, 1314, 1317, 1330, 1331, 1387, 1444, 1472, 1484, 1500, 1540, 1542, 1543, 1544, 1550, 1580, 1586, 1599, 1612, 1620, 1624, 1628, 1705, 1763, 1770, 1797, 1803, 1804, 1806, 1807, 1808, 1809, 1827, 1877, 1928, 1936, 2038, 2097, 2100, 2102, 2103, 2116, 2117, 2126, 2127, 2130, 2133, 2134, 2135, 2136, 2138, 2142, 2144, 2146, 2147, 2150, 2154, 2157, 2161, 2164, 2166, 2168, 2171, 2172, 2173, 2175, 2176, 2177, 2186, 2189, 2192, 2194, 2195, 2196, 2198, 2205, 2208], "maintain": [1, 8, 9, 11, 25, 26, 30, 39, 56, 60, 64, 69, 958, 968, 1041, 1226, 1230, 1488, 1519, 1524, 1679, 1770, 1813, 1827, 2092, 2117, 2126, 2127, 2130, 2133, 2142, 2157, 2191, 2194], "accuraci": [1, 21, 26, 37, 1002, 1228, 1378, 1738, 1877, 1936, 2109, 2125, 2126, 2142, 2176, 2181, 2186, 2195, 2204], "see": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 16, 17, 19, 21, 22, 24, 25, 27, 30, 31, 32, 34, 36, 37, 39, 43, 45, 51, 52, 55, 56, 58, 60, 65, 66, 67, 68, 69, 88, 89, 93, 95, 97, 99, 101, 103, 105, 107, 109, 112, 113, 114, 115, 116, 117, 118, 120, 122, 124, 126, 128, 129, 132, 134, 135, 136, 137, 138, 140, 142, 144, 145, 148, 150, 151, 153, 154, 155, 156, 157, 159, 161, 163, 165, 167, 169, 170, 171, 172, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 189, 192, 193, 197, 199, 200, 202, 204, 205, 207, 210, 211, 212, 214, 217, 218, 220, 224, 225, 226, 227, 228, 229, 230, 234, 235, 237, 239, 240, 241, 243, 245, 246, 248, 250, 252, 255, 256, 261, 263, 264, 265, 266, 267, 268, 270, 272, 274, 275, 276, 278, 280, 281, 282, 284, 287, 288, 291, 293, 295, 297, 298, 299, 300, 301, 302, 303, 305, 307, 309, 313, 321, 322, 323, 324, 325, 327, 328, 334, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 357, 359, 361, 363, 365, 367, 369, 370, 372, 374, 378, 379, 380, 381, 382, 384, 386, 388, 390, 392, 393, 394, 396, 397, 403, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 416, 417, 418, 419, 421, 422, 424, 425, 427, 429, 430, 431, 432, 433, 434, 438, 440, 442, 450, 452, 453, 455, 457, 459, 460, 461, 462, 464, 465, 467, 468, 470, 477, 479, 480, 482, 484, 486, 487, 488, 489, 491, 493, 494, 495, 497, 498, 499, 501, 502, 505, 506, 507, 510, 515, 517, 518, 519, 521, 523, 524, 525, 526, 528, 530, 531, 533, 535, 538, 539, 540, 542, 543, 547, 548, 550, 552, 554, 555, 556, 561, 563, 565, 567, 568, 569, 570, 572, 573, 574, 576, 578, 579, 590, 591, 592, 594, 595, 597, 599, 601, 605, 606, 609, 610, 611, 614, 615, 616, 618, 619, 620, 621, 681, 704, 706, 707, 710, 741, 742, 743, 744, 745, 746, 749, 750, 751, 752, 753, 754, 756, 757, 759, 767, 768, 771, 772, 773, 774, 775, 776, 777, 778, 779, 782, 783, 784, 785, 790, 791, 792, 793, 794, 795, 796, 806, 869, 889, 890, 891, 892, 895, 904, 905, 906, 909, 920, 922, 923, 924, 925, 928, 929, 930, 932, 933, 935, 936, 940, 944, 945, 946, 949, 954, 955, 957, 962, 971, 973, 980, 982, 985, 999, 1002, 1004, 1006, 1007, 1025, 1037, 1039, 1040, 1041, 1046, 1047, 1049, 1066, 1067, 1078, 1079, 1089, 1092, 1093, 1094, 1095, 1097, 1098, 1099, 1100, 1101, 1102, 1109, 1110, 1111, 1139, 1142, 1144, 1145, 1147, 1148, 1157, 1162, 1180, 1183, 1196, 1199, 1204, 1205, 1206, 1208, 1217, 1221, 1226, 1228, 1232, 1240, 1242, 1258, 1267, 1268, 1272, 1273, 1277, 1278, 1286, 1287, 1288, 1314, 1318, 1326, 1330, 1331, 1333, 1334, 1336, 1344, 1346, 1351, 1354, 1355, 1357, 1360, 1362, 1369, 1371, 1372, 1375, 1380, 1384, 1385, 1386, 1387, 1393, 1395, 1401, 1402, 1404, 1412, 1414, 1415, 1416, 1417, 1419, 1420, 1433, 1434, 1441, 1471, 1473, 1474, 1484, 1492, 1493, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1522, 1523, 1525, 1531, 1533, 1539, 1540, 1545, 1546, 1550, 1571, 1572, 1576, 1577, 1578, 1579, 1580, 1583, 1584, 1585, 1586, 1587, 1592, 1593, 1594, 1596, 1608, 1610, 1612, 1613, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1633, 1639, 1640, 1645, 1646, 1647, 1648, 1649, 1650, 1652, 1653, 1654, 1655, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1683, 1684, 1685, 1686, 1687, 1689, 1690, 1691, 1692, 1694, 1696, 1697, 1698, 1699, 1700, 1701, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1719, 1720, 1721, 1722, 1724, 1725, 1726, 1728, 1729, 1730, 1731, 1732, 1733, 1735, 1736, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1754, 1755, 1756, 1757, 1758, 1759, 1770, 1772, 1787, 1788, 1789, 1793, 1799, 1807, 1816, 1821, 1824, 1825, 1826, 1827, 1831, 1838, 1877, 1878, 1880, 1890, 1891, 1901, 1903, 1905, 1907, 1908, 1912, 1915, 1918, 1924, 1933, 1936, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1960, 1968, 1969, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1988, 1989, 1990, 1993, 2006, 2008, 2011, 2017, 2018, 2022, 2024, 2029, 2033, 2036, 2040, 2041, 2046, 2048, 2080, 2081, 2089, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2100, 2101, 2102, 2103, 2105, 2107, 2110, 2111, 2114, 2115, 2116, 2117, 2118, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2138, 2140, 2142, 2144, 2145, 2146, 2147, 2148, 2150, 2151, 2152, 2154, 2156, 2159, 2161, 2162, 2165, 2166, 2167, 2171, 2172, 2173, 2174, 2175, 2177, 2178, 2180, 2183, 2186, 2187, 2189, 2190, 2191, 2192, 2193, 2196, 2197, 2198, 2202, 2203, 2204, 2205, 2206, 2207, 2209, 2210], "detail": [1, 2, 3, 4, 8, 9, 13, 15, 16, 17, 19, 20, 25, 30, 31, 32, 34, 36, 37, 39, 41, 51, 52, 56, 57, 58, 60, 66, 69, 88, 150, 323, 495, 524, 614, 681, 746, 749, 750, 751, 752, 753, 754, 771, 777, 778, 779, 782, 783, 784, 785, 790, 791, 793, 794, 795, 796, 806, 889, 890, 891, 892, 903, 920, 922, 923, 924, 925, 928, 929, 930, 933, 935, 936, 949, 985, 1006, 1007, 1025, 1041, 1046, 1047, 1049, 1066, 1067, 1078, 1089, 1092, 1094, 1095, 1097, 1099, 1100, 1101, 1102, 1109, 1110, 1111, 1127, 1144, 1183, 1206, 1217, 1226, 1258, 1262, 1264, 1268, 1295, 1302, 1314, 1318, 1330, 1351, 1354, 1372, 1379, 1386, 1387, 1393, 1395, 1415, 1466, 1484, 1488, 1498, 1510, 1511, 1512, 1516, 1522, 1523, 1524, 1525, 1527, 1528, 1531, 1550, 1580, 1586, 1592, 1593, 1596, 1608, 1629, 1639, 1645, 1646, 1647, 1648, 1649, 1650, 1652, 1653, 1654, 1655, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1687, 1689, 1690, 1691, 1692, 1694, 1696, 1697, 1698, 1699, 1700, 1701, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1719, 1720, 1721, 1722, 1726, 1728, 1729, 1730, 1731, 1732, 1733, 1735, 1736, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1754, 1755, 1756, 1760, 1765, 1766, 1770, 1772, 1816, 1826, 1834, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1860, 1865, 1877, 1880, 1892, 1924, 1935, 1960, 1969, 2018, 2029, 2033, 2036, 2080, 2081, 2091, 2093, 2094, 2095, 2096, 2100, 2103, 2107, 2110, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2140, 2141, 2142, 2145, 2146, 2147, 2150, 2151, 2154, 2158, 2159, 2161, 2163, 2165, 2166, 2167, 2168, 2171, 2173, 2175, 2176, 2177, 2178, 2180, 2189, 2192, 2201, 2204, 2205, 2206, 2207], "when": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16, 20, 21, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 63, 65, 66, 67, 68, 69, 86, 97, 150, 191, 208, 233, 260, 313, 321, 415, 448, 486, 487, 488, 497, 498, 513, 515, 517, 544, 560, 580, 617, 681, 697, 700, 746, 779, 780, 790, 796, 804, 806, 843, 869, 888, 895, 907, 910, 923, 930, 938, 939, 940, 941, 942, 943, 944, 945, 949, 950, 954, 955, 956, 958, 965, 970, 973, 982, 990, 993, 994, 995, 1001, 1002, 1004, 1010, 1014, 1015, 1020, 1021, 1025, 1039, 1043, 1053, 1056, 1082, 1088, 1089, 1102, 1127, 1144, 1183, 1187, 1192, 1198, 1202, 1203, 1208, 1211, 1212, 1213, 1216, 1228, 1229, 1237, 1238, 1241, 1242, 1251, 1254, 1268, 1303, 1304, 1306, 1307, 1310, 1314, 1315, 1317, 1326, 1327, 1328, 1330, 1331, 1335, 1336, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1360, 1361, 1362, 1363, 1364, 1367, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1378, 1379, 1380, 1384, 1385, 1386, 1387, 1395, 1401, 1404, 1409, 1415, 1416, 1419, 1443, 1466, 1471, 1472, 1473, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1522, 1523, 1526, 1529, 1531, 1532, 1534, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1567, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1594, 1595, 1596, 1608, 1609, 1612, 1613, 1614, 1615, 1617, 1620, 1626, 1627, 1628, 1629, 1631, 1632, 1633, 1634, 1635, 1639, 1641, 1651, 1653, 1654, 1655, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1678, 1684, 1686, 1695, 1697, 1698, 1722, 1725, 1727, 1730, 1731, 1738, 1746, 1757, 1758, 1759, 1760, 1769, 1770, 1771, 1772, 1773, 1774, 1779, 1780, 1787, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1816, 1821, 1825, 1826, 1827, 1828, 1833, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876, 1877, 1880, 1882, 1889, 1892, 1893, 1915, 1921, 1928, 1933, 1936, 1942, 1960, 1966, 1970, 1972, 1973, 1975, 1979, 1985, 1990, 1994, 2006, 2011, 2013, 2018, 2022, 2024, 2033, 2034, 2045, 2048, 2050, 2091, 2093, 2095, 2100, 2102, 2105, 2106, 2109, 2111, 2114, 2115, 2116, 2117, 2124, 2128, 2129, 2130, 2132, 2135, 2136, 2138, 2139, 2140, 2142, 2144, 2145, 2146, 2147, 2148, 2157, 2158, 2159, 2165, 2166, 2167, 2168, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2198, 2200, 2202, 2203, 2204, 2205, 2207, 2209], "enter": [1, 30, 925, 926, 927, 945, 2133, 2192], "ani": [1, 2, 3, 4, 5, 6, 8, 10, 13, 14, 16, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 45, 49, 50, 51, 52, 55, 56, 57, 58, 60, 65, 68, 69, 87, 150, 254, 486, 499, 545, 617, 708, 769, 792, 805, 806, 807, 815, 825, 826, 827, 828, 830, 831, 832, 833, 842, 843, 851, 884, 895, 909, 910, 919, 920, 921, 923, 930, 933, 935, 936, 938, 944, 949, 950, 954, 958, 978, 984, 988, 989, 1019, 1020, 1039, 1082, 1089, 1101, 1145, 1146, 1147, 1160, 1161, 1163, 1164, 1165, 1167, 1171, 1175, 1176, 1177, 1192, 1201, 1202, 1209, 1210, 1211, 1213, 1219, 1224, 1225, 1226, 1228, 1232, 1238, 1277, 1313, 1314, 1318, 1321, 1325, 1326, 1328, 1330, 1336, 1344, 1346, 1350, 1351, 1352, 1355, 1360, 1361, 1362, 1367, 1368, 1371, 1375, 1378, 1384, 1386, 1457, 1458, 1481, 1482, 1483, 1485, 1486, 1487, 1488, 1492, 1493, 1497, 1498, 1507, 1508, 1509, 1516, 1517, 1521, 1525, 1526, 1529, 1530, 1533, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1545, 1546, 1566, 1567, 1569, 1570, 1571, 1579, 1580, 1588, 1590, 1591, 1594, 1599, 1600, 1601, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1630, 1631, 1632, 1657, 1661, 1662, 1663, 1703, 1723, 1724, 1738, 1760, 1770, 1779, 1780, 1792, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1814, 1815, 1817, 1820, 1822, 1827, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1875, 1877, 1908, 1924, 1938, 1940, 1994, 2002, 2045, 2050, 2060, 2078, 2079, 2091, 2093, 2094, 2095, 2100, 2103, 2104, 2106, 2107, 2109, 2114, 2115, 2116, 2122, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2146, 2147, 2149, 2150, 2154, 2155, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2171, 2173, 2176, 2178, 2180, 2181, 2182, 2185, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2197, 2199, 2200, 2202, 2203, 2204, 2205, 2206, 2207], "should": [1, 2, 4, 5, 6, 10, 16, 17, 19, 20, 21, 22, 25, 26, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 43, 44, 49, 50, 51, 52, 54, 56, 57, 60, 64, 65, 68, 69, 71, 76, 77, 80, 86, 88, 119, 150, 154, 313, 321, 398, 402, 415, 445, 446, 447, 448, 449, 487, 488, 496, 513, 515, 517, 583, 584, 585, 587, 588, 697, 700, 701, 746, 771, 783, 784, 785, 806, 809, 815, 832, 843, 866, 868, 884, 885, 886, 889, 895, 919, 920, 921, 922, 923, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 944, 954, 955, 970, 971, 972, 973, 980, 993, 1008, 1009, 1014, 1015, 1027, 1039, 1054, 1056, 1078, 1080, 1089, 1135, 1145, 1146, 1147, 1157, 1162, 1165, 1166, 1167, 1175, 1176, 1177, 1180, 1195, 1198, 1199, 1200, 1202, 1203, 1207, 1211, 1212, 1213, 1218, 1226, 1227, 1232, 1234, 1272, 1273, 1276, 1277, 1311, 1312, 1314, 1315, 1319, 1324, 1326, 1327, 1330, 1331, 1332, 1334, 1359, 1384, 1385, 1386, 1392, 1401, 1404, 1405, 1406, 1427, 1443, 1484, 1492, 1493, 1497, 1513, 1515, 1516, 1518, 1519, 1520, 1523, 1524, 1545, 1550, 1572, 1580, 1586, 1587, 1588, 1603, 1608, 1629, 1633, 1651, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1678, 1686, 1738, 1760, 1762, 1763, 1764, 1767, 1768, 1770, 1771, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1813, 1814, 1815, 1818, 1820, 1831, 1832, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1892, 1894, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1915, 1931, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1976, 1977, 1978, 1979, 1980, 1981, 1994, 2011, 2020, 2045, 2050, 2089, 2090, 2091, 2092, 2093, 2095, 2096, 2100, 2102, 2103, 2104, 2107, 2109, 2114, 2116, 2117, 2122, 2124, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2142, 2144, 2145, 2146, 2147, 2148, 2150, 2154, 2157, 2158, 2159, 2161, 2162, 2166, 2168, 2171, 2173, 2175, 2176, 2178, 2180, 2184, 2185, 2188, 2190, 2192, 2193, 2194, 2195, 2197, 2198, 2200, 2202, 2203, 2204, 2205, 2206], "call": [1, 2, 3, 4, 9, 13, 16, 17, 20, 21, 22, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 51, 54, 56, 57, 58, 60, 61, 62, 64, 65, 66, 68, 69, 71, 73, 80, 150, 290, 323, 335, 458, 486, 487, 488, 556, 580, 614, 617, 681, 708, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 792, 803, 811, 843, 887, 891, 892, 923, 930, 931, 932, 933, 934, 935, 936, 938, 940, 941, 944, 945, 954, 955, 956, 958, 965, 969, 985, 1002, 1007, 1008, 1013, 1015, 1037, 1040, 1057, 1078, 1080, 1090, 1091, 1101, 1109, 1110, 1112, 1113, 1142, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1196, 1201, 1202, 1213, 1215, 1219, 1226, 1237, 1258, 1278, 1299, 1311, 1314, 1317, 1319, 1325, 1326, 1327, 1334, 1370, 1378, 1382, 1384, 1386, 1387, 1416, 1488, 1494, 1495, 1496, 1516, 1517, 1518, 1519, 1520, 1522, 1524, 1526, 1565, 1576, 1577, 1578, 1580, 1587, 1588, 1609, 1620, 1632, 1664, 1665, 1666, 1672, 1673, 1674, 1679, 1697, 1738, 1757, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1779, 1780, 1790, 1793, 1797, 1800, 1803, 1804, 1806, 1807, 1808, 1809, 1815, 1821, 1822, 1824, 1825, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1905, 1932, 1938, 1939, 1968, 1988, 1989, 1990, 2013, 2029, 2033, 2034, 2036, 2040, 2041, 2045, 2046, 2071, 2072, 2082, 2083, 2091, 2093, 2097, 2100, 2104, 2109, 2114, 2116, 2117, 2118, 2126, 2127, 2129, 2130, 2132, 2135, 2136, 2138, 2139, 2140, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2154, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2181, 2183, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2198, 2200, 2202, 2203, 2204, 2205, 2206, 2207, 2209, 2210], "model": [1, 2, 3, 4, 5, 6, 9, 10, 14, 26, 30, 31, 32, 34, 35, 37, 38, 39, 50, 52, 55, 57, 60, 61, 62, 63, 64, 65, 66, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 805, 806, 807, 811, 812, 813, 825, 826, 827, 828, 829, 830, 831, 832, 837, 839, 840, 843, 846, 851, 864, 865, 866, 867, 868, 870, 884, 887, 888, 889, 890, 891, 892, 893, 945, 958, 1002, 1004, 1014, 1090, 1112, 1201, 1202, 1203, 1211, 1213, 1314, 1318, 1319, 1324, 1326, 1330, 1332, 1386, 1484, 1516, 1533, 1544, 1545, 1580, 1586, 1609, 1620, 1624, 1626, 1627, 1628, 1685, 1770, 1771, 1772, 1779, 1780, 1786, 1788, 1791, 1804, 1822, 1823, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1854, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1874, 1877, 1878, 1990, 2045, 2071, 2082, 2093, 2095, 2096, 2097, 2104, 2106, 2107, 2117, 2127, 2129, 2130, 2132, 2133, 2136, 2137, 2139, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2149, 2151, 2154, 2156, 2159, 2162, 2166, 2167, 2169, 2171, 2172, 2176, 2181, 2182, 2183, 2186, 2188, 2189, 2190, 2192, 2194, 2195, 2196, 2200, 2202, 2204, 2205], "": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 25, 26, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 44, 47, 48, 49, 51, 52, 53, 56, 57, 58, 60, 62, 64, 65, 68, 69, 86, 87, 233, 463, 481, 493, 496, 513, 544, 558, 581, 625, 681, 700, 704, 705, 706, 707, 710, 746, 771, 806, 807, 808, 816, 830, 831, 832, 834, 839, 842, 851, 884, 891, 892, 905, 907, 908, 909, 910, 929, 930, 931, 932, 935, 939, 940, 942, 950, 969, 986, 988, 1001, 1010, 1019, 1020, 1021, 1022, 1027, 1035, 1037, 1039, 1041, 1044, 1045, 1062, 1067, 1078, 1080, 1085, 1086, 1089, 1090, 1091, 1112, 1113, 1114, 1136, 1139, 1141, 1142, 1144, 1158, 1159, 1161, 1162, 1163, 1166, 1167, 1169, 1170, 1173, 1174, 1176, 1177, 1178, 1179, 1181, 1183, 1184, 1185, 1186, 1187, 1190, 1191, 1192, 1198, 1199, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1211, 1213, 1221, 1226, 1228, 1258, 1268, 1276, 1277, 1278, 1301, 1303, 1311, 1312, 1314, 1318, 1325, 1326, 1330, 1345, 1346, 1356, 1357, 1358, 1360, 1363, 1367, 1369, 1371, 1372, 1376, 1377, 1378, 1379, 1384, 1386, 1387, 1402, 1409, 1414, 1416, 1419, 1421, 1422, 1427, 1433, 1434, 1438, 1443, 1444, 1445, 1449, 1456, 1470, 1471, 1474, 1476, 1482, 1483, 1484, 1492, 1493, 1494, 1495, 1496, 1499, 1516, 1522, 1533, 1580, 1581, 1586, 1590, 1597, 1609, 1612, 1614, 1620, 1624, 1626, 1628, 1634, 1635, 1658, 1659, 1670, 1683, 1686, 1697, 1698, 1703, 1738, 1744, 1757, 1760, 1770, 1771, 1772, 1779, 1780, 1793, 1804, 1816, 1820, 1827, 1828, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1882, 1886, 1893, 1908, 1911, 1912, 1915, 1916, 1917, 1919, 1921, 1928, 1935, 1936, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1988, 1989, 1990, 1993, 1994, 1995, 1996, 1997, 2008, 2012, 2014, 2020, 2036, 2040, 2041, 2042, 2045, 2046, 2050, 2051, 2052, 2055, 2067, 2070, 2071, 2072, 2082, 2083, 2091, 2093, 2094, 2095, 2096, 2097, 2100, 2102, 2103, 2106, 2107, 2109, 2110, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2141, 2142, 2144, 2145, 2147, 2148, 2149, 2150, 2151, 2154, 2155, 2157, 2159, 2161, 2163, 2164, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2182, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2198, 2199, 2200, 2202, 2203, 2204, 2205, 2206, 2209], "wrap": [1, 2, 17, 21, 25, 26, 30, 35, 36, 37, 42, 44, 54, 56, 58, 60, 64, 65, 67, 69, 71, 260, 803, 804, 1040, 1044, 1202, 1228, 1314, 1330, 1444, 1516, 1580, 1620, 1764, 1770, 1791, 1816, 1861, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 2051, 2093, 2094, 2096, 2100, 2103, 2126, 2127, 2130, 2132, 2133, 2134, 2142, 2148, 2154, 2159, 2161, 2166, 2167, 2180, 2182, 2190, 2192, 2193, 2195, 2205, 2206], "forward": [1, 6, 8, 9, 14, 16, 26, 30, 31, 32, 34, 35, 36, 37, 39, 56, 57, 58, 60, 61, 62, 64, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 150, 221, 222, 681, 746, 759, 768, 771, 815, 830, 831, 832, 839, 843, 891, 892, 919, 921, 922, 923, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 938, 940, 941, 944, 945, 946, 947, 949, 1009, 1010, 1019, 1089, 1136, 1148, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1202, 1204, 1205, 1206, 1208, 1211, 1314, 1317, 1318, 1319, 1321, 1325, 1326, 1330, 1331, 1332, 1488, 1492, 1494, 1495, 1496, 1516, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1531, 1550, 1565, 1576, 1577, 1578, 1580, 1581, 1582, 1586, 1587, 1590, 1591, 1595, 1596, 1597, 1609, 1624, 1625, 1626, 1627, 1628, 1672, 1673, 1674, 1679, 1725, 1738, 1760, 1763, 1764, 1769, 1770, 1791, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 1821, 1824, 1825, 1877, 1899, 1966, 2033, 2093, 2095, 2096, 2100, 2102, 2106, 2108, 2114, 2116, 2122, 2124, 2126, 2127, 2129, 2130, 2132, 2134, 2135, 2136, 2138, 2140, 2142, 2145, 2147, 2149, 2150, 2154, 2157, 2158, 2159, 2161, 2166, 2180, 2181, 2182, 2183, 2185, 2186, 2189, 2190, 2192, 2193, 2195, 2198, 2199, 2200, 2202, 2203, 2204, 2205], "pass": [1, 2, 4, 6, 7, 8, 16, 22, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 64, 65, 68, 69, 71, 79, 80, 150, 254, 415, 448, 488, 513, 515, 517, 544, 560, 681, 806, 807, 842, 851, 889, 891, 910, 919, 920, 921, 922, 923, 930, 933, 935, 936, 944, 956, 986, 1002, 1004, 1009, 1010, 1012, 1037, 1078, 1089, 1105, 1134, 1165, 1166, 1167, 1175, 1176, 1177, 1183, 1196, 1198, 1201, 1202, 1206, 1207, 1208, 1211, 1212, 1222, 1226, 1228, 1238, 1247, 1248, 1249, 1251, 1277, 1312, 1314, 1315, 1318, 1320, 1324, 1326, 1330, 1331, 1359, 1375, 1377, 1386, 1438, 1484, 1485, 1486, 1487, 1494, 1495, 1496, 1516, 1522, 1523, 1527, 1528, 1580, 1585, 1586, 1595, 1609, 1625, 1626, 1627, 1628, 1633, 1651, 1681, 1682, 1686, 1697, 1698, 1725, 1738, 1760, 1763, 1764, 1769, 1770, 1791, 1793, 1795, 1800, 1813, 1816, 1820, 1822, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1848, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1924, 1928, 1932, 1994, 2091, 2093, 2097, 2100, 2104, 2105, 2106, 2108, 2109, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2129, 2132, 2133, 2134, 2136, 2138, 2140, 2141, 2142, 2145, 2147, 2154, 2157, 2158, 2159, 2166, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2182, 2183, 2190, 2191, 2192, 2193, 2194, 2195, 2201, 2202, 2204, 2205, 2206], "e": [1, 2, 3, 4, 6, 8, 13, 14, 16, 17, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 63, 65, 67, 68, 69, 71, 79, 80, 150, 233, 258, 335, 377, 486, 580, 617, 746, 759, 768, 771, 806, 807, 830, 832, 870, 884, 888, 889, 891, 892, 910, 919, 923, 930, 932, 935, 936, 945, 949, 950, 969, 981, 983, 986, 1004, 1019, 1074, 1089, 1116, 1144, 1154, 1195, 1202, 1207, 1211, 1221, 1228, 1234, 1236, 1241, 1245, 1263, 1265, 1293, 1294, 1296, 1299, 1311, 1314, 1321, 1322, 1330, 1350, 1351, 1366, 1378, 1386, 1387, 1388, 1390, 1392, 1409, 1420, 1428, 1439, 1453, 1461, 1492, 1493, 1494, 1495, 1496, 1499, 1507, 1508, 1509, 1515, 1516, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1531, 1534, 1539, 1542, 1543, 1544, 1545, 1546, 1550, 1552, 1553, 1554, 1555, 1571, 1580, 1581, 1586, 1587, 1589, 1590, 1594, 1596, 1612, 1620, 1624, 1628, 1629, 1630, 1632, 1661, 1662, 1663, 1670, 1677, 1678, 1686, 1697, 1730, 1738, 1757, 1759, 1760, 1770, 1771, 1772, 1773, 1774, 1779, 1780, 1788, 1797, 1803, 1804, 1806, 1807, 1808, 1809, 1813, 1814, 1820, 1824, 1827, 1840, 1841, 1859, 1877, 1885, 1896, 1914, 1921, 1928, 1932, 1936, 1938, 1943, 1979, 1990, 1993, 1994, 2064, 2085, 2091, 2093, 2095, 2096, 2097, 2100, 2103, 2104, 2106, 2111, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2129, 2130, 2133, 2134, 2135, 2136, 2139, 2140, 2142, 2145, 2147, 2150, 2154, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2171, 2172, 2174, 2175, 2176, 2178, 2184, 2185, 2189, 2191, 2192, 2194, 2195, 2202, 2205, 2206, 2209, 2210], "network": [1, 2, 8, 9, 17, 35, 39, 51, 871, 1089, 1314, 1330, 1331, 1488, 1494, 1495, 1496, 1499, 1510, 1511, 1512, 1516, 1517, 1518, 1519, 1520, 1521, 1524, 1533, 1545, 1550, 1580, 1587, 1592, 1593, 1599, 1608, 1610, 1620, 1624, 1626, 1628, 1651, 1685, 1686, 1741, 1760, 1788, 1791, 1816, 1821, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1877, 2093, 2095, 2096, 2124, 2126, 2133, 2145, 2146, 2147, 2149, 2151, 2154, 2157, 2161, 2166, 2167, 2168, 2191], "includ": [1, 2, 3, 4, 5, 6, 8, 10, 16, 17, 25, 26, 30, 32, 34, 36, 37, 48, 51, 52, 56, 57, 58, 60, 69, 321, 488, 517, 583, 779, 780, 889, 891, 1004, 1101, 1172, 1174, 1214, 1276, 1312, 1314, 1315, 1344, 1423, 1425, 1489, 1490, 1491, 1497, 1499, 1516, 1525, 1533, 1567, 1576, 1577, 1578, 1580, 1586, 1624, 1625, 1626, 1627, 1628, 1631, 1641, 1653, 1654, 1655, 1670, 1683, 1703, 1770, 1779, 1780, 1814, 1815, 1817, 1877, 1956, 2021, 2022, 2023, 2024, 2091, 2093, 2095, 2096, 2100, 2103, 2106, 2109, 2114, 2117, 2127, 2129, 2130, 2135, 2136, 2140, 2142, 2147, 2149, 2150, 2154, 2157, 2159, 2161, 2166, 2168, 2176, 2180, 2183, 2185, 2188, 2190, 2193, 2194, 2195, 2196, 2200, 2201, 2202, 2204, 2205, 2206, 2207], "loss": [1, 2, 26, 30, 31, 35, 36, 38, 39, 60, 1203, 1311, 1350, 1351, 1360, 1378, 1484, 1492, 1493, 1499, 1513, 1515, 1522, 1533, 1539, 1540, 1545, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1630, 1658, 1659, 1669, 1670, 1683, 1695, 1698, 1718, 1722, 1730, 1742, 1754, 1755, 1770, 1814, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1854, 1856, 1857, 1858, 1859, 1860, 1864, 1936, 2091, 2109, 2116, 2127, 2130, 2132, 2135, 2137, 2138, 2142, 2157, 2161, 2162, 2166, 2167, 2176, 2204], "comput": [1, 4, 6, 8, 9, 13, 16, 19, 25, 26, 30, 32, 34, 36, 37, 38, 39, 41, 44, 56, 57, 58, 60, 61, 62, 64, 150, 290, 486, 487, 495, 681, 682, 694, 708, 709, 771, 779, 780, 815, 817, 837, 839, 840, 841, 843, 846, 919, 923, 925, 926, 928, 930, 931, 932, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 954, 955, 974, 975, 976, 977, 978, 979, 990, 992, 993, 994, 995, 1001, 1021, 1023, 1036, 1086, 1089, 1121, 1127, 1136, 1138, 1141, 1144, 1148, 1149, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1187, 1189, 1190, 1191, 1193, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1218, 1228, 1256, 1257, 1258, 1268, 1271, 1274, 1275, 1276, 1277, 1291, 1314, 1317, 1326, 1334, 1335, 1337, 1339, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1383, 1384, 1385, 1387, 1395, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1404, 1413, 1414, 1415, 1418, 1471, 1473, 1477, 1484, 1488, 1489, 1490, 1491, 1494, 1495, 1496, 1510, 1511, 1512, 1514, 1515, 1517, 1522, 1523, 1531, 1534, 1542, 1543, 1544, 1545, 1547, 1548, 1549, 1550, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1570, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1586, 1587, 1589, 1594, 1595, 1596, 1614, 1616, 1620, 1629, 1630, 1633, 1653, 1654, 1655, 1668, 1669, 1677, 1678, 1685, 1686, 1688, 1695, 1697, 1698, 1705, 1711, 1712, 1713, 1714, 1715, 1716, 1722, 1727, 1730, 1738, 1742, 1744, 1745, 1754, 1755, 1760, 1763, 1769, 1770, 1772, 1776, 1779, 1780, 1781, 1783, 1785, 1787, 1789, 1791, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1814, 1820, 1824, 1825, 1827, 1837, 1838, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1886, 1892, 1893, 1897, 1898, 1912, 1913, 1936, 1943, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1966, 1969, 1970, 1971, 1972, 1974, 1990, 1994, 1995, 2005, 2013, 2018, 2042, 2045, 2093, 2096, 2100, 2103, 2104, 2109, 2115, 2116, 2117, 2118, 2122, 2126, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2142, 2143, 2147, 2149, 2150, 2151, 2154, 2157, 2161, 2164, 2166, 2171, 2172, 2177, 2181, 2184, 2185, 2188, 2189, 2191, 2192, 2193, 2194, 2197, 2202, 2203, 2204, 2207, 2208, 2209], "backward": [1, 2, 6, 10, 30, 31, 32, 34, 35, 36, 37, 38, 39, 52, 56, 60, 64, 65, 69, 71, 290, 335, 487, 488, 496, 503, 504, 513, 515, 517, 581, 681, 697, 700, 771, 830, 831, 832, 920, 928, 929, 930, 931, 932, 933, 934, 935, 936, 939, 941, 944, 947, 949, 954, 955, 965, 968, 970, 982, 1007, 1089, 1148, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1201, 1202, 1226, 1314, 1387, 1395, 1409, 1419, 1492, 1493, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1522, 1531, 1532, 1533, 1546, 1550, 1551, 1567, 1571, 1572, 1580, 1586, 1587, 1594, 1596, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1658, 1659, 1669, 1670, 1686, 1697, 1722, 1725, 1761, 1765, 1766, 1770, 1793, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1864, 1877, 1878, 1880, 1892, 1966, 1970, 1975, 1994, 2033, 2091, 2092, 2094, 2096, 2100, 2102, 2108, 2116, 2117, 2122, 2124, 2126, 2132, 2133, 2134, 2135, 2136, 2137, 2140, 2142, 2144, 2145, 2150, 2157, 2158, 2159, 2161, 2166, 2171, 2172, 2173, 2177, 2183, 2185, 2189, 2190, 2195, 2198, 2200, 2202, 2203, 2204, 2205], "under": [1, 2, 4, 5, 6, 10, 25, 30, 34, 36, 37, 38, 56, 60, 61, 63, 65, 68, 945, 949, 956, 961, 987, 1227, 1314, 1499, 1580, 1651, 1677, 1678, 1787, 1790, 1793, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1877, 1913, 2100, 2105, 2114, 2126, 2127, 2130, 2132, 2134, 2136, 2138, 2144, 2158, 2161, 2164, 2165, 2168, 2172, 2176, 2180, 2182, 2191, 2193, 2194, 2199, 2202, 2204], "recommend": [1, 2, 6, 21, 25, 26, 30, 32, 34, 37, 38, 39, 41, 51, 52, 58, 60, 64, 68, 69, 71, 448, 895, 923, 1013, 1020, 1021, 1165, 1166, 1167, 1175, 1176, 1177, 1301, 1317, 1360, 1387, 1436, 1438, 1484, 1516, 1698, 1770, 1899, 2029, 2034, 2091, 2093, 2100, 2107, 2111, 2114, 2116, 2117, 2124, 2126, 2127, 2129, 2130, 2133, 2134, 2142, 2144, 2145, 2147, 2150, 2154, 2158, 2161, 2173, 2177, 2196, 2204], "correspond": [1, 2, 8, 16, 20, 22, 25, 26, 30, 32, 35, 37, 38, 39, 51, 56, 58, 60, 67, 69, 415, 473, 474, 513, 515, 517, 544, 545, 681, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 746, 806, 811, 864, 866, 887, 888, 889, 894, 910, 919, 921, 922, 923, 930, 932, 935, 936, 938, 940, 949, 969, 1022, 1089, 1111, 1139, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1224, 1228, 1268, 1277, 1303, 1314, 1331, 1345, 1350, 1351, 1356, 1359, 1378, 1385, 1387, 1401, 1416, 1466, 1493, 1516, 1522, 1550, 1580, 1586, 1603, 1627, 1677, 1686, 1724, 1770, 1788, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1821, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1877, 1885, 1886, 1896, 1919, 1928, 1933, 1943, 1979, 1988, 1989, 1994, 2028, 2031, 2032, 2040, 2041, 2080, 2081, 2091, 2093, 2094, 2096, 2100, 2109, 2115, 2116, 2117, 2126, 2127, 2130, 2132, 2133, 2134, 2136, 2138, 2140, 2142, 2146, 2147, 2150, 2154, 2157, 2158, 2159, 2161, 2166, 2167, 2171, 2172, 2173, 2176, 2178, 2181, 2182, 2192, 2196, 2201, 2202, 2204, 2205], "creat": [1, 2, 4, 6, 7, 8, 10, 16, 21, 25, 26, 30, 32, 35, 36, 38, 39, 41, 43, 49, 51, 52, 54, 55, 56, 57, 58, 60, 68, 69, 71, 87, 150, 222, 254, 335, 486, 580, 581, 583, 584, 585, 587, 588, 681, 743, 749, 750, 751, 756, 757, 767, 775, 805, 806, 807, 829, 830, 831, 832, 837, 843, 884, 908, 909, 910, 923, 928, 944, 945, 946, 947, 969, 981, 983, 994, 995, 999, 1000, 1002, 1004, 1022, 1049, 1086, 1087, 1097, 1132, 1147, 1196, 1197, 1198, 1199, 1228, 1229, 1230, 1231, 1234, 1311, 1314, 1317, 1327, 1333, 1338, 1344, 1345, 1351, 1353, 1372, 1385, 1401, 1416, 1466, 1492, 1513, 1522, 1523, 1526, 1540, 1546, 1571, 1572, 1580, 1583, 1584, 1585, 1609, 1612, 1613, 1620, 1629, 1630, 1632, 1640, 1642, 1643, 1770, 1793, 1813, 1820, 1825, 1833, 1834, 1860, 1877, 1931, 1932, 1961, 1973, 1979, 2011, 2018, 2076, 2096, 2097, 2106, 2114, 2117, 2122, 2126, 2127, 2130, 2132, 2133, 2134, 2136, 2138, 2142, 2143, 2144, 2147, 2150, 2154, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2171, 2173, 2175, 2176, 2177, 2178, 2180, 2181, 2182, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2203, 2205, 2207, 2210], "optim": [1, 2, 3, 8, 9, 16, 17, 26, 30, 31, 32, 34, 36, 39, 57, 60, 69, 837, 949, 958, 962, 1002, 1005, 1014, 1144, 1211, 1228, 1314, 1318, 1324, 1326, 1330, 1331, 1370, 1387, 1494, 1495, 1496, 1515, 1522, 1542, 1543, 1544, 1580, 1583, 1584, 1585, 1586, 1613, 1620, 1628, 1738, 1760, 1770, 1779, 1780, 1787, 1793, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1882, 2092, 2093, 2095, 2100, 2106, 2116, 2117, 2122, 2124, 2129, 2132, 2133, 2135, 2137, 2138, 2142, 2144, 2150, 2154, 2159, 2160, 2161, 2171, 2183, 2184, 2185, 2188, 2189, 2190, 2191, 2192, 2193, 2195, 2197, 2204, 2205, 2208, 2212], "default": [1, 3, 4, 6, 10, 13, 14, 16, 19, 20, 21, 22, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 48, 49, 50, 51, 52, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 69, 71, 73, 75, 76, 79, 80, 81, 82, 84, 86, 88, 150, 155, 170, 172, 175, 178, 179, 180, 195, 206, 209, 240, 267, 290, 297, 325, 331, 393, 415, 445, 446, 447, 448, 449, 458, 496, 499, 500, 520, 525, 580, 581, 583, 623, 681, 687, 693, 705, 708, 723, 724, 725, 726, 727, 728, 731, 741, 742, 743, 744, 746, 766, 769, 771, 779, 780, 781, 783, 784, 785, 790, 796, 806, 812, 818, 823, 824, 829, 832, 837, 839, 840, 841, 846, 855, 856, 857, 858, 859, 860, 861, 862, 871, 872, 873, 874, 875, 876, 878, 879, 884, 885, 886, 888, 895, 909, 910, 923, 925, 926, 927, 930, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 969, 971, 980, 986, 990, 993, 994, 995, 999, 1002, 1004, 1014, 1015, 1019, 1027, 1036, 1039, 1041, 1046, 1050, 1053, 1054, 1055, 1056, 1060, 1061, 1064, 1069, 1070, 1071, 1073, 1074, 1086, 1088, 1089, 1092, 1094, 1095, 1096, 1097, 1099, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1115, 1116, 1119, 1120, 1121, 1122, 1125, 1126, 1127, 1132, 1133, 1134, 1135, 1136, 1139, 1144, 1145, 1146, 1147, 1157, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1196, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1212, 1213, 1222, 1258, 1260, 1261, 1267, 1268, 1272, 1273, 1276, 1277, 1290, 1303, 1305, 1311, 1314, 1315, 1318, 1326, 1330, 1331, 1334, 1335, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1401, 1404, 1406, 1412, 1414, 1415, 1416, 1420, 1427, 1428, 1439, 1443, 1447, 1448, 1452, 1453, 1457, 1458, 1461, 1470, 1471, 1473, 1474, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1608, 1612, 1613, 1617, 1618, 1620, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1632, 1633, 1648, 1649, 1650, 1651, 1653, 1654, 1655, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1683, 1685, 1686, 1688, 1690, 1695, 1697, 1698, 1705, 1711, 1712, 1713, 1718, 1722, 1723, 1725, 1730, 1738, 1744, 1745, 1753, 1757, 1763, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1778, 1781, 1782, 1785, 1787, 1788, 1789, 1790, 1792, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1814, 1815, 1817, 1819, 1820, 1821, 1822, 1824, 1826, 1827, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1882, 1890, 1892, 1893, 1897, 1898, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1914, 1920, 1921, 1924, 1928, 1932, 1933, 1934, 1935, 1936, 1940, 1942, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1987, 1988, 1989, 1990, 1993, 1994, 1995, 2011, 2012, 2018, 2020, 2022, 2024, 2029, 2030, 2033, 2034, 2039, 2040, 2041, 2045, 2050, 2054, 2060, 2061, 2064, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2085, 2088, 2089, 2090, 2091, 2093, 2096, 2100, 2102, 2105, 2106, 2107, 2111, 2114, 2117, 2122, 2124, 2126, 2129, 2132, 2133, 2134, 2135, 2136, 2137, 2139, 2141, 2142, 2145, 2146, 2147, 2148, 2150, 2154, 2157, 2158, 2159, 2161, 2165, 2166, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2183, 2185, 2186, 2189, 2190, 2191, 2194, 2195, 2198, 2200, 2201, 2203, 2204, 2205, 2207, 2209, 2210], "net": [1, 7, 17, 41, 63, 69, 1314, 1330, 1331, 1516, 1580, 1770, 1804, 1864, 1877, 2095, 2096, 2126, 2127, 2130, 2142, 2151, 2176], "sgd": [1, 25, 26, 35, 488, 958, 1522, 1760, 1770, 1865, 1872, 1874, 2126, 2130, 2132, 2137, 2142, 2144, 2157, 2166, 2167], "target": [1, 16, 34, 35, 36, 38, 56, 57, 60, 64, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 499, 746, 777, 778, 805, 811, 889, 891, 892, 987, 1203, 1226, 1314, 1324, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1492, 1493, 1499, 1513, 1515, 1527, 1528, 1533, 1539, 1540, 1545, 1546, 1571, 1572, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1594, 1612, 1613, 1624, 1633, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1658, 1659, 1667, 1669, 1670, 1681, 1682, 1683, 1694, 1695, 1698, 1699, 1710, 1718, 1719, 1720, 1721, 1722, 1730, 1738, 1742, 1743, 1770, 1859, 1877, 1878, 2033, 2094, 2096, 2122, 2126, 2127, 2130, 2137, 2144, 2150, 2154, 2157, 2158, 2161, 2162, 2166, 2176, 2181, 2185, 2190, 2191, 2193, 2203, 2205], "data": [1, 2, 3, 4, 8, 13, 14, 20, 23, 26, 30, 32, 34, 35, 36, 37, 39, 40, 41, 45, 48, 51, 54, 57, 60, 64, 67, 69, 71, 72, 76, 80, 139, 150, 195, 196, 326, 329, 333, 336, 341, 445, 448, 481, 493, 497, 499, 617, 749, 750, 751, 771, 783, 784, 785, 792, 805, 806, 807, 812, 837, 839, 840, 841, 842, 846, 852, 895, 909, 910, 920, 923, 935, 956, 971, 980, 986, 1040, 1125, 1126, 1145, 1146, 1147, 1157, 1158, 1159, 1162, 1164, 1165, 1167, 1175, 1176, 1177, 1180, 1183, 1184, 1185, 1186, 1195, 1196, 1198, 1199, 1200, 1202, 1211, 1226, 1234, 1238, 1242, 1245, 1272, 1273, 1275, 1293, 1296, 1322, 1326, 1330, 1334, 1385, 1386, 1387, 1401, 1406, 1414, 1416, 1433, 1434, 1471, 1473, 1474, 1497, 1499, 1507, 1508, 1509, 1516, 1531, 1534, 1542, 1543, 1544, 1550, 1552, 1567, 1587, 1596, 1597, 1633, 1651, 1656, 1657, 1661, 1662, 1663, 1696, 1703, 1705, 1744, 1745, 1770, 1771, 1772, 1773, 1774, 1779, 1780, 1813, 1814, 1815, 1816, 1818, 1827, 1831, 1832, 1833, 1834, 1865, 1872, 1877, 1882, 1890, 1893, 1894, 1895, 1899, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1915, 1928, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1969, 1972, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1993, 1994, 2011, 2020, 2022, 2024, 2032, 2033, 2034, 2089, 2090, 2093, 2094, 2097, 2100, 2103, 2104, 2106, 2109, 2114, 2122, 2125, 2126, 2127, 2128, 2130, 2133, 2134, 2137, 2140, 2144, 2146, 2147, 2148, 2149, 2150, 2151, 2155, 2156, 2157, 2158, 2160, 2161, 2164, 2166, 2168, 2171, 2172, 2173, 2174, 2175, 2176, 2178, 2180, 2181, 2182, 2185, 2186, 2188, 2191, 2192, 2194, 2195, 2197, 2202, 2207], "zero_grad": [1, 2, 35, 1314, 1580, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 1864, 1877, 1878, 2126, 2130, 2135, 2137, 2142, 2144, 2157, 2204], "output": [1, 2, 5, 6, 8, 14, 20, 25, 26, 30, 32, 34, 35, 36, 37, 38, 39, 41, 48, 49, 56, 58, 64, 65, 66, 69, 71, 80, 139, 313, 321, 445, 446, 447, 449, 513, 517, 566, 617, 681, 682, 694, 695, 696, 697, 698, 699, 700, 701, 702, 704, 706, 707, 708, 709, 710, 731, 739, 740, 745, 746, 749, 750, 751, 752, 753, 754, 755, 756, 757, 760, 761, 762, 763, 764, 765, 766, 767, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 783, 784, 785, 786, 788, 790, 791, 792, 793, 794, 796, 797, 798, 805, 806, 807, 809, 814, 817, 829, 832, 867, 888, 891, 892, 893, 895, 904, 905, 908, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 930, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 970, 972, 973, 974, 975, 976, 977, 978, 979, 982, 986, 989, 990, 991, 992, 993, 994, 995, 997, 1000, 1004, 1019, 1021, 1022, 1024, 1025, 1036, 1041, 1051, 1053, 1054, 1055, 1056, 1057, 1086, 1087, 1089, 1100, 1101, 1123, 1124, 1125, 1126, 1128, 1131, 1132, 1134, 1136, 1139, 1141, 1143, 1144, 1145, 1146, 1147, 1149, 1154, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1187, 1188, 1189, 1190, 1191, 1192, 1194, 1199, 1200, 1202, 1203, 1204, 1206, 1207, 1208, 1209, 1211, 1212, 1213, 1226, 1228, 1237, 1255, 1256, 1257, 1258, 1268, 1271, 1274, 1275, 1276, 1277, 1279, 1280, 1281, 1289, 1291, 1308, 1309, 1311, 1314, 1318, 1326, 1330, 1331, 1335, 1336, 1337, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1441, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1476, 1477, 1478, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1653, 1654, 1655, 1657, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1677, 1678, 1680, 1681, 1682, 1683, 1686, 1688, 1695, 1697, 1698, 1703, 1705, 1711, 1712, 1713, 1718, 1722, 1723, 1727, 1728, 1729, 1730, 1738, 1753, 1757, 1758, 1759, 1763, 1769, 1770, 1788, 1789, 1790, 1791, 1794, 1814, 1816, 1817, 1821, 1824, 1826, 1827, 1828, 1831, 1832, 1834, 1835, 1860, 1864, 1877, 1880, 1881, 1889, 1890, 1893, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1912, 1913, 1914, 1916, 1917, 1921, 1923, 1928, 1936, 1940, 1943, 1945, 1957, 1958, 1960, 1965, 1970, 1971, 1973, 1975, 1983, 1984, 1986, 1987, 1988, 1989, 1990, 1991, 1993, 1994, 2008, 2009, 2010, 2015, 2018, 2020, 2021, 2023, 2026, 2028, 2029, 2030, 2031, 2033, 2039, 2040, 2041, 2042, 2045, 2047, 2048, 2089, 2090, 2091, 2093, 2094, 2096, 2100, 2102, 2104, 2106, 2115, 2116, 2117, 2122, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2142, 2145, 2146, 2147, 2150, 2154, 2156, 2157, 2158, 2159, 2161, 2163, 2167, 2171, 2172, 2174, 2175, 2176, 2178, 2181, 2182, 2185, 2186, 2189, 2190, 2191, 2193, 2194, 2195, 2197, 2198, 2203, 2204, 2205], "loss_fn": [1, 35, 36, 1587, 1859, 1877, 1878, 2126, 2130, 2132, 2144, 2157], "exit": [1, 2, 3, 5, 20, 30, 37, 41, 51, 60, 68, 69, 925, 927, 1644, 1770, 2096, 2114, 2127, 2130, 2133, 2144, 2154, 2168, 2173, 2209], "befor": [1, 2, 4, 7, 8, 16, 20, 22, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 43, 48, 50, 51, 52, 54, 56, 57, 60, 69, 97, 150, 415, 486, 758, 771, 800, 802, 803, 923, 930, 931, 933, 935, 958, 1000, 1013, 1039, 1125, 1126, 1127, 1136, 1144, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1185, 1186, 1189, 1198, 1201, 1226, 1314, 1326, 1328, 1351, 1367, 1371, 1384, 1414, 1427, 1471, 1474, 1516, 1522, 1523, 1526, 1531, 1580, 1581, 1582, 1620, 1624, 1632, 1686, 1705, 1744, 1745, 1760, 1763, 1764, 1765, 1766, 1770, 1779, 1780, 1788, 1821, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1852, 1856, 1857, 1858, 1859, 1860, 1874, 1877, 1890, 1893, 1919, 1928, 1938, 1939, 1969, 1972, 1976, 1977, 1978, 1980, 1981, 1990, 1993, 2018, 2029, 2050, 2093, 2095, 2096, 2100, 2104, 2114, 2126, 2127, 2130, 2132, 2133, 2136, 2137, 2138, 2140, 2142, 2145, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2171, 2172, 2176, 2178, 2184, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2200, 2209], "step": [1, 2, 3, 5, 10, 13, 16, 21, 25, 26, 30, 31, 32, 34, 35, 37, 39, 52, 56, 60, 64, 69, 538, 607, 681, 697, 779, 780, 887, 895, 925, 928, 929, 958, 973, 997, 1274, 1362, 1385, 1386, 1387, 1401, 1404, 1416, 1527, 1528, 1550, 1654, 1655, 1681, 1682, 1770, 1813, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1851, 1852, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1899, 1908, 1936, 1961, 2036, 2093, 2094, 2100, 2116, 2117, 2126, 2127, 2130, 2132, 2133, 2135, 2137, 2142, 2144, 2146, 2147, 2148, 2150, 2154, 2158, 2159, 2161, 2166, 2167, 2171, 2173, 2176, 2186, 2195, 2198, 2199, 2202, 2204, 2205], "usag": [1, 2, 5, 8, 10, 14, 17, 25, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 45, 48, 49, 51, 54, 60, 69, 71, 72, 759, 768, 805, 806, 807, 825, 826, 827, 828, 830, 831, 832, 884, 888, 920, 935, 1002, 1004, 1092, 1114, 1118, 1195, 1201, 1205, 1206, 1207, 1240, 1328, 1387, 1462, 1770, 2073, 2087, 2093, 2096, 2100, 2108, 2109, 2116, 2122, 2126, 2127, 2133, 2135, 2136, 2137, 2145, 2150, 2154, 2159, 2160, 2168, 2173, 2176, 2177, 2180, 2181, 2182, 2191, 2192, 2194, 2195, 2196, 2205], "along": [1, 3, 16, 20, 25, 30, 37, 39, 44, 51, 56, 58, 71, 77, 313, 315, 317, 321, 493, 513, 515, 517, 697, 708, 837, 905, 906, 989, 996, 1026, 1036, 1053, 1056, 1127, 1135, 1136, 1143, 1144, 1160, 1165, 1168, 1172, 1175, 1178, 1184, 1213, 1255, 1280, 1289, 1291, 1336, 1347, 1383, 1441, 1471, 1475, 1476, 1485, 1486, 1487, 1493, 1514, 1527, 1528, 1570, 1573, 1574, 1575, 1614, 1616, 1651, 1659, 1668, 1681, 1682, 1685, 1688, 1705, 1711, 1712, 1713, 1723, 1744, 1745, 1799, 1801, 1807, 1808, 1817, 1826, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 1872, 1893, 1913, 1914, 1919, 1930, 1965, 1969, 1972, 1973, 1982, 1987, 2008, 2012, 2015, 2018, 2027, 2042, 2045, 2047, 2091, 2095, 2100, 2117, 2122, 2128, 2130, 2133, 2135, 2140, 2142, 2150, 2158, 2161, 2172], "more": [1, 2, 3, 4, 5, 6, 9, 10, 13, 14, 16, 17, 19, 21, 22, 24, 25, 26, 27, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 43, 47, 50, 51, 52, 54, 57, 58, 60, 63, 64, 65, 66, 67, 69, 71, 73, 80, 150, 254, 255, 313, 321, 486, 487, 488, 493, 495, 498, 513, 515, 517, 524, 545, 618, 681, 746, 782, 791, 795, 806, 884, 889, 890, 891, 903, 916, 917, 918, 920, 922, 923, 924, 930, 933, 935, 936, 938, 940, 944, 945, 946, 949, 950, 954, 955, 956, 957, 958, 973, 981, 984, 986, 992, 993, 994, 995, 1002, 1007, 1019, 1039, 1040, 1041, 1046, 1047, 1066, 1087, 1092, 1094, 1095, 1097, 1099, 1100, 1101, 1102, 1109, 1110, 1111, 1115, 1122, 1127, 1133, 1142, 1144, 1148, 1160, 1161, 1163, 1165, 1184, 1185, 1186, 1187, 1198, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1217, 1222, 1240, 1241, 1242, 1262, 1264, 1268, 1277, 1278, 1295, 1299, 1301, 1302, 1314, 1328, 1331, 1344, 1345, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1382, 1384, 1386, 1387, 1390, 1393, 1395, 1405, 1406, 1433, 1434, 1438, 1466, 1472, 1484, 1488, 1493, 1498, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1522, 1523, 1524, 1540, 1550, 1576, 1577, 1578, 1580, 1586, 1592, 1593, 1594, 1596, 1608, 1620, 1628, 1639, 1651, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1675, 1677, 1678, 1686, 1689, 1690, 1691, 1692, 1697, 1701, 1705, 1706, 1717, 1724, 1731, 1732, 1733, 1736, 1738, 1739, 1740, 1741, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1756, 1757, 1758, 1759, 1760, 1765, 1766, 1770, 1772, 1779, 1780, 1787, 1790, 1791, 1825, 1826, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1877, 1880, 1891, 1892, 1918, 1924, 1928, 1936, 1968, 1969, 1994, 2018, 2020, 2029, 2033, 2036, 2045, 2046, 2091, 2093, 2095, 2096, 2100, 2102, 2103, 2105, 2107, 2108, 2109, 2110, 2111, 2114, 2115, 2116, 2117, 2118, 2122, 2124, 2127, 2129, 2130, 2132, 2133, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2145, 2147, 2149, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2162, 2167, 2168, 2170, 2171, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2202, 2204, 2205, 2206, 2207, 2208, 2209, 2210], "complex": [1, 2, 4, 8, 9, 25, 26, 29, 30, 34, 36, 38, 41, 69, 311, 329, 483, 499, 696, 703, 949, 950, 994, 995, 1020, 1021, 1139, 1145, 1146, 1147, 1165, 1187, 1192, 1226, 1268, 1285, 1293, 1304, 1306, 1307, 1310, 1311, 1314, 1335, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1364, 1367, 1369, 1371, 1372, 1373, 1374, 1378, 1379, 1383, 1384, 1385, 1387, 1395, 1401, 1413, 1414, 1418, 1465, 1471, 1507, 1508, 1509, 1546, 1580, 1661, 1662, 1663, 1787, 1827, 1839, 1877, 1886, 1899, 1905, 1906, 1912, 1933, 1943, 1990, 1991, 1994, 2033, 2042, 2043, 2044, 2091, 2094, 2096, 2097, 2107, 2141, 2144, 2155, 2160, 2173, 2174, 2177, 2178, 2180, 2192, 2195, 2196, 2197, 2204], "scenario": [1, 25, 30, 36, 51, 1014, 1493, 1833, 2034, 2130, 2137, 2138, 2144, 2145, 2154, 2159, 2166, 2195, 2196, 2204], "g": [1, 2, 3, 4, 6, 8, 13, 14, 16, 17, 25, 26, 30, 32, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 49, 50, 51, 52, 53, 55, 56, 58, 60, 63, 65, 67, 68, 69, 71, 79, 80, 486, 580, 617, 759, 768, 771, 806, 807, 830, 832, 870, 884, 889, 891, 892, 919, 930, 932, 935, 936, 945, 949, 950, 983, 1004, 1019, 1089, 1144, 1195, 1202, 1206, 1207, 1234, 1236, 1241, 1245, 1263, 1265, 1268, 1311, 1314, 1321, 1322, 1330, 1386, 1499, 1500, 1516, 1518, 1519, 1520, 1524, 1526, 1531, 1539, 1545, 1550, 1551, 1580, 1581, 1590, 1596, 1612, 1670, 1686, 1770, 1771, 1772, 1773, 1774, 1779, 1780, 1789, 1824, 1827, 1837, 1839, 1840, 1841, 1844, 1856, 1857, 1858, 1859, 1877, 1914, 1921, 1932, 1936, 1938, 1956, 1979, 1990, 1993, 2091, 2093, 2095, 2096, 2097, 2100, 2103, 2104, 2111, 2114, 2117, 2122, 2126, 2127, 2130, 2133, 2134, 2135, 2136, 2138, 2140, 2142, 2145, 2146, 2150, 2154, 2157, 2158, 2159, 2161, 2166, 2171, 2174, 2175, 2176, 2184, 2185, 2189, 2190, 2191, 2194, 2195, 2202, 2204, 2205, 2206, 2209], "penalti": [1, 792, 1101, 1836, 1837, 1839, 1840, 1842, 1844, 1856, 1857, 1859, 2162, 2200], "multipl": [1, 2, 3, 4, 6, 19, 21, 25, 26, 30, 31, 32, 34, 36, 37, 39, 40, 44, 52, 54, 56, 60, 65, 68, 69, 191, 208, 315, 513, 697, 699, 700, 706, 707, 771, 871, 904, 905, 908, 944, 956, 957, 958, 990, 992, 1002, 1023, 1027, 1053, 1054, 1055, 1056, 1086, 1142, 1144, 1147, 1198, 1201, 1206, 1207, 1208, 1209, 1212, 1213, 1258, 1264, 1278, 1279, 1328, 1331, 1336, 1337, 1352, 1353, 1354, 1370, 1375, 1380, 1381, 1409, 1412, 1417, 1419, 1492, 1493, 1510, 1511, 1512, 1513, 1515, 1523, 1526, 1531, 1539, 1545, 1546, 1568, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1632, 1658, 1659, 1669, 1678, 1698, 1722, 1730, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1858, 1862, 1866, 1868, 1869, 1870, 1871, 1876, 1880, 1936, 1963, 1970, 1971, 1976, 1977, 1978, 1980, 1981, 2012, 2013, 2020, 2028, 2033, 2045, 2046, 2091, 2095, 2096, 2100, 2114, 2115, 2116, 2117, 2127, 2129, 2132, 2134, 2136, 2138, 2140, 2142, 2144, 2145, 2146, 2147, 2148, 2154, 2157, 2158, 2159, 2161, 2162, 2166, 2167, 2168, 2171, 2173, 2182, 2183, 2184, 2185, 2188, 2189, 2192, 2194, 2195, 2203, 2204], "custom": [1, 4, 6, 16, 17, 25, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 44, 47, 48, 50, 56, 57, 60, 71, 73, 499, 799, 806, 811, 829, 830, 831, 832, 866, 869, 889, 890, 891, 892, 920, 930, 933, 935, 956, 1002, 1004, 1044, 1049, 1221, 1314, 1580, 1624, 1628, 1629, 1630, 1755, 1795, 1804, 1820, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1865, 1877, 2034, 2036, 2097, 2102, 2114, 2115, 2125, 2127, 2133, 2140, 2141, 2146, 2147, 2148, 2150, 2164, 2165, 2181, 2183, 2192, 2194, 2196, 2202], "autograd": [1, 5, 6, 8, 9, 30, 35, 37, 39, 56, 60, 61, 64, 71, 139, 335, 445, 446, 447, 448, 449, 486, 488, 496, 681, 700, 895, 909, 910, 924, 925, 930, 935, 936, 945, 946, 947, 957, 958, 965, 966, 967, 968, 969, 971, 980, 999, 1057, 1089, 1145, 1146, 1147, 1157, 1162, 1180, 1198, 1199, 1200, 1201, 1202, 1211, 1213, 1272, 1273, 1314, 1334, 1354, 1385, 1401, 1409, 1419, 1533, 1580, 1586, 1628, 1688, 1703, 1770, 1831, 1832, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1877, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1939, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1967, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2045, 2089, 2090, 2094, 2098, 2100, 2103, 2105, 2117, 2124, 2125, 2130, 2132, 2135, 2136, 2138, 2140, 2142, 2150, 2159, 2160, 2177, 2178, 2183, 2195, 2196, 2200, 2202, 2204, 2205, 2206], "function": [1, 3, 4, 6, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 24, 25, 31, 32, 34, 35, 36, 40, 41, 42, 44, 48, 49, 51, 52, 56, 57, 60, 63, 65, 67, 68, 71, 74, 79, 80, 83, 85, 86, 87, 119, 150, 195, 233, 258, 260, 289, 298, 321, 486, 487, 488, 493, 496, 517, 541, 556, 681, 684, 690, 691, 692, 693, 700, 704, 705, 709, 710, 759, 768, 769, 771, 775, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 803, 804, 805, 806, 811, 812, 815, 829, 830, 831, 832, 843, 851, 866, 871, 884, 887, 889, 891, 892, 893, 907, 908, 923, 925, 926, 927, 928, 929, 930, 935, 936, 944, 945, 946, 947, 949, 950, 954, 955, 956, 958, 962, 965, 968, 971, 980, 982, 990, 992, 996, 999, 1002, 1004, 1005, 1006, 1008, 1009, 1010, 1013, 1014, 1015, 1019, 1020, 1021, 1028, 1030, 1031, 1032, 1033, 1034, 1035, 1037, 1040, 1041, 1046, 1049, 1057, 1069, 1070, 1074, 1080, 1081, 1086, 1087, 1089, 1090, 1091, 1092, 1094, 1100, 1101, 1109, 1110, 1112, 1113, 1114, 1118, 1127, 1132, 1134, 1135, 1142, 1144, 1148, 1160, 1161, 1163, 1183, 1187, 1190, 1191, 1192, 1195, 1198, 1201, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1215, 1216, 1217, 1226, 1228, 1237, 1253, 1258, 1259, 1268, 1272, 1273, 1274, 1276, 1278, 1286, 1287, 1288, 1301, 1311, 1312, 1313, 1314, 1315, 1317, 1319, 1320, 1325, 1326, 1327, 1328, 1330, 1332, 1334, 1335, 1336, 1338, 1343, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1362, 1363, 1364, 1366, 1369, 1370, 1371, 1372, 1373, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1386, 1387, 1390, 1392, 1401, 1404, 1405, 1409, 1412, 1415, 1417, 1419, 1420, 1421, 1443, 1460, 1462, 1468, 1471, 1472, 1488, 1492, 1493, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1513, 1517, 1521, 1524, 1529, 1530, 1531, 1532, 1533, 1535, 1536, 1537, 1538, 1539, 1545, 1547, 1548, 1549, 1550, 1551, 1566, 1569, 1570, 1572, 1579, 1580, 1585, 1586, 1588, 1596, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1614, 1616, 1617, 1618, 1619, 1621, 1622, 1624, 1626, 1628, 1629, 1630, 1632, 1634, 1636, 1637, 1638, 1640, 1642, 1643, 1644, 1761, 1763, 1765, 1766, 1770, 1771, 1776, 1778, 1779, 1780, 1787, 1788, 1793, 1804, 1813, 1814, 1815, 1817, 1820, 1821, 1822, 1824, 1825, 1827, 1828, 1832, 1836, 1837, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1861, 1864, 1865, 1868, 1871, 1872, 1873, 1877, 1880, 1881, 1882, 1886, 1892, 1899, 1903, 1908, 1921, 1930, 1931, 1932, 1934, 1935, 1941, 1943, 1951, 1955, 1956, 1961, 1964, 1966, 1967, 1968, 1969, 1970, 1972, 1979, 1986, 1990, 1995, 1996, 1997, 2008, 2012, 2014, 2018, 2028, 2029, 2030, 2033, 2034, 2038, 2042, 2043, 2044, 2045, 2046, 2060, 2061, 2064, 2068, 2071, 2072, 2073, 2074, 2078, 2082, 2083, 2084, 2087, 2090, 2091, 2097, 2100, 2102, 2104, 2107, 2108, 2109, 2114, 2116, 2119, 2122, 2124, 2125, 2128, 2130, 2132, 2133, 2135, 2139, 2140, 2142, 2144, 2145, 2149, 2150, 2151, 2156, 2157, 2158, 2159, 2160, 2161, 2163, 2165, 2166, 2167, 2168, 2170, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2182, 2183, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2208], "also": [1, 2, 3, 4, 6, 8, 9, 10, 13, 14, 16, 17, 20, 21, 25, 26, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 48, 51, 56, 57, 58, 60, 64, 65, 66, 68, 69, 71, 79, 80, 154, 218, 221, 222, 254, 323, 513, 515, 517, 523, 543, 614, 752, 753, 754, 771, 815, 829, 891, 910, 919, 920, 926, 927, 930, 933, 935, 936, 945, 958, 971, 980, 994, 995, 1002, 1008, 1014, 1036, 1086, 1089, 1101, 1125, 1126, 1144, 1148, 1164, 1195, 1202, 1208, 1212, 1213, 1228, 1238, 1247, 1248, 1249, 1255, 1258, 1267, 1272, 1273, 1277, 1314, 1317, 1318, 1321, 1324, 1328, 1330, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1382, 1383, 1384, 1416, 1422, 1441, 1472, 1484, 1492, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1523, 1526, 1531, 1545, 1550, 1580, 1587, 1596, 1610, 1612, 1620, 1629, 1630, 1632, 1664, 1665, 1666, 1686, 1724, 1741, 1760, 1770, 1791, 1793, 1797, 1803, 1806, 1807, 1808, 1809, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1868, 1872, 1875, 1877, 1880, 1905, 1912, 1924, 1934, 1948, 1949, 1966, 1970, 1985, 1994, 2006, 2008, 2011, 2017, 2018, 2029, 2030, 2045, 2048, 2091, 2092, 2093, 2095, 2096, 2100, 2102, 2103, 2106, 2108, 2114, 2115, 2116, 2117, 2124, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2141, 2142, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2154, 2157, 2158, 2159, 2161, 2165, 2166, 2167, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2182, 2183, 2184, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208], "autocastmodel": 1, "nn": [1, 4, 6, 14, 17, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 52, 56, 57, 58, 60, 61, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 298, 415, 541, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 805, 806, 829, 870, 884, 889, 890, 891, 892, 894, 1002, 1086, 1089, 1144, 1201, 1210, 1211, 1312, 1314, 1315, 1317, 1318, 1319, 1320, 1321, 1324, 1325, 1326, 1330, 1331, 1332, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1641, 1760, 1769, 1770, 1771, 1772, 1773, 1774, 1790, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1813, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1964, 1990, 2033, 2034, 2091, 2093, 2094, 2098, 2104, 2108, 2116, 2126, 2132, 2135, 2136, 2137, 2142, 2144, 2145, 2146, 2149, 2150, 2154, 2156, 2157, 2158, 2160, 2161, 2163, 2166, 2176, 2178, 2182, 2185, 2186, 2189, 2190, 2194, 2195, 2202, 2203, 2204, 2205], "modul": [1, 2, 4, 6, 7, 9, 13, 14, 16, 20, 21, 22, 26, 30, 32, 34, 35, 36, 37, 38, 42, 43, 45, 48, 52, 56, 57, 60, 61, 63, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 415, 487, 488, 681, 697, 700, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 749, 750, 751, 756, 757, 758, 767, 772, 773, 774, 775, 776, 800, 802, 803, 804, 805, 806, 811, 814, 815, 817, 825, 826, 827, 828, 829, 830, 831, 832, 834, 837, 839, 840, 841, 842, 843, 846, 851, 852, 866, 868, 869, 870, 884, 887, 888, 889, 890, 891, 892, 894, 945, 954, 955, 958, 970, 982, 1002, 1057, 1089, 1201, 1210, 1211, 1213, 1226, 1263, 1312, 1314, 1315, 1317, 1318, 1319, 1320, 1321, 1322, 1324, 1325, 1326, 1330, 1331, 1332, 1386, 1409, 1419, 1484, 1488, 1494, 1495, 1496, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1532, 1534, 1542, 1543, 1544, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1581, 1582, 1590, 1591, 1595, 1597, 1609, 1614, 1620, 1624, 1625, 1627, 1628, 1677, 1678, 1738, 1753, 1760, 1769, 1770, 1771, 1772, 1779, 1780, 1781, 1782, 1783, 1784, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1816, 1820, 1821, 1822, 1824, 1860, 1877, 1924, 1968, 2034, 2036, 2037, 2045, 2091, 2097, 2100, 2102, 2104, 2106, 2108, 2109, 2114, 2116, 2117, 2119, 2123, 2124, 2125, 2129, 2130, 2132, 2135, 2136, 2140, 2143, 2144, 2146, 2148, 2149, 2150, 2154, 2156, 2157, 2159, 2163, 2164, 2166, 2169, 2171, 2172, 2176, 2180, 2181, 2182, 2184, 2185, 2186, 2190, 2192, 2193, 2194, 2195, 2198, 2202, 2203, 2204, 2205, 2206], "def": [1, 2, 6, 14, 25, 26, 30, 31, 32, 36, 37, 39, 41, 42, 43, 44, 45, 48, 49, 52, 54, 55, 56, 57, 58, 60, 62, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 398, 805, 806, 891, 892, 920, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 945, 1002, 1004, 1007, 1009, 1010, 1014, 1015, 1019, 1057, 1148, 1201, 1202, 1203, 1205, 1206, 1207, 1209, 1211, 1212, 1213, 1312, 1314, 1315, 1317, 1318, 1319, 1320, 1321, 1325, 1326, 1329, 1330, 1331, 1332, 1580, 1581, 1582, 1590, 1591, 1596, 1630, 1738, 1760, 1770, 1793, 1825, 1877, 1968, 2045, 2091, 2093, 2095, 2096, 2100, 2108, 2116, 2117, 2122, 2126, 2127, 2129, 2132, 2133, 2134, 2135, 2142, 2144, 2146, 2147, 2148, 2149, 2150, 2152, 2154, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2195, 2197, 2202, 2203, 2204, 2205, 2206], "self": [1, 2, 10, 14, 20, 25, 26, 30, 32, 36, 41, 43, 45, 48, 54, 56, 57, 58, 60, 65, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 97, 139, 150, 153, 154, 155, 170, 172, 175, 178, 179, 180, 190, 191, 195, 196, 208, 216, 218, 232, 233, 240, 254, 255, 258, 259, 267, 286, 290, 297, 311, 313, 315, 317, 319, 321, 323, 325, 326, 328, 329, 330, 331, 333, 341, 377, 393, 398, 400, 401, 402, 415, 454, 471, 481, 483, 497, 498, 499, 500, 513, 515, 517, 520, 523, 525, 537, 543, 544, 545, 546, 558, 560, 580, 581, 583, 584, 585, 587, 588, 604, 607, 608, 614, 617, 618, 620, 624, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 891, 892, 963, 965, 1009, 1010, 1201, 1202, 1211, 1226, 1228, 1285, 1312, 1313, 1314, 1317, 1318, 1319, 1320, 1321, 1325, 1326, 1330, 1331, 1332, 1443, 1484, 1488, 1524, 1579, 1580, 1581, 1582, 1586, 1590, 1591, 1608, 1610, 1620, 1626, 1628, 1717, 1738, 1741, 1760, 1790, 1791, 1793, 1799, 1801, 1813, 1822, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1889, 1910, 2093, 2094, 2095, 2096, 2100, 2109, 2115, 2116, 2124, 2127, 2128, 2129, 2133, 2135, 2142, 2147, 2149, 2150, 2154, 2157, 2158, 2161, 2166, 2173, 2177, 2185, 2186, 2190, 2192, 2193, 2199, 2202, 2203, 2204, 2205], "produc": [1, 8, 16, 21, 25, 30, 32, 37, 40, 43, 45, 48, 54, 56, 57, 65, 66, 68, 69, 87, 486, 743, 749, 750, 751, 756, 757, 767, 775, 805, 806, 973, 993, 1014, 1082, 1175, 1176, 1177, 1195, 1206, 1207, 1213, 1228, 1232, 1237, 1238, 1268, 1326, 1330, 1331, 1334, 1350, 1351, 1354, 1361, 1362, 1373, 1378, 1412, 1415, 1416, 1417, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1556, 1557, 1558, 1559, 1560, 1561, 1586, 1670, 1678, 1686, 1697, 1757, 1758, 1759, 1827, 1860, 1892, 1899, 1908, 1994, 2033, 2045, 2093, 2095, 2096, 2104, 2114, 2115, 2117, 2126, 2127, 2128, 2130, 2133, 2136, 2139, 2140, 2142, 2145, 2146, 2147, 2148, 2150, 2154, 2171, 2173, 2175, 2185, 2186, 2190, 2191, 2200, 2204, 2205], "after": [1, 2, 8, 10, 14, 16, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 51, 54, 56, 58, 60, 68, 69, 71, 76, 77, 260, 486, 488, 681, 771, 803, 887, 889, 891, 892, 923, 925, 930, 931, 935, 1002, 1013, 1014, 1037, 1039, 1057, 1082, 1089, 1143, 1202, 1236, 1237, 1299, 1314, 1318, 1370, 1386, 1409, 1427, 1480, 1516, 1531, 1565, 1580, 1583, 1624, 1626, 1628, 1651, 1686, 1760, 1763, 1770, 1793, 1795, 1799, 1801, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1856, 1857, 1858, 1859, 1860, 1864, 1865, 1872, 1874, 1877, 1932, 1990, 2018, 2034, 2036, 2047, 2050, 2091, 2095, 2096, 2108, 2109, 2114, 2117, 2122, 2124, 2126, 2127, 2130, 2132, 2133, 2135, 2136, 2137, 2138, 2140, 2142, 2144, 2145, 2147, 2150, 2154, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2169, 2172, 2173, 2174, 2176, 2185, 2189, 2192, 2193, 2195, 2196, 2198, 2200, 2202, 2203, 2204, 2205, 2209], "disabl": [1, 3, 6, 22, 31, 34, 39, 60, 69, 825, 826, 945, 946, 947, 1002, 1014, 1089, 1096, 1144, 1148, 1201, 1217, 1314, 1316, 1330, 1331, 1580, 1586, 1620, 1628, 1738, 1770, 1772, 1822, 1825, 1877, 1937, 1940, 1968, 2095, 2100, 2102, 2111, 2126, 2129, 2130, 2132, 2133, 2137, 2139, 2145, 2146, 2165, 2171, 2178, 2194, 2198, 2201, 2202, 2205, 2207, 2209], "them": [1, 2, 4, 6, 8, 9, 10, 13, 16, 17, 25, 30, 32, 34, 36, 37, 41, 43, 48, 51, 54, 56, 58, 60, 64, 65, 68, 69, 150, 221, 254, 486, 745, 923, 930, 933, 935, 940, 984, 1089, 1129, 1132, 1144, 1218, 1226, 1228, 1239, 1336, 1345, 1356, 1370, 1382, 1386, 1414, 1474, 1500, 1522, 1580, 1614, 1616, 1744, 1800, 1814, 1817, 1972, 1975, 1993, 2029, 2034, 2036, 2091, 2095, 2096, 2100, 2103, 2105, 2106, 2109, 2111, 2114, 2115, 2116, 2117, 2126, 2127, 2128, 2130, 2133, 2134, 2135, 2136, 2139, 2140, 2142, 2146, 2148, 2157, 2159, 2161, 2162, 2166, 2167, 2168, 2171, 2172, 2173, 2176, 2177, 2181, 2185, 2191, 2192, 2193, 2194, 2195, 2200, 2201, 2202, 2203, 2204, 2205], "differ": [1, 2, 3, 4, 6, 9, 16, 20, 25, 30, 32, 34, 35, 36, 38, 39, 41, 43, 44, 48, 49, 51, 52, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 196, 486, 493, 617, 681, 697, 700, 706, 707, 746, 771, 806, 809, 811, 841, 843, 846, 891, 892, 895, 909, 910, 949, 950, 970, 982, 983, 1027, 1127, 1132, 1134, 1136, 1144, 1184, 1185, 1186, 1190, 1191, 1198, 1201, 1206, 1207, 1213, 1228, 1230, 1233, 1268, 1289, 1314, 1320, 1325, 1330, 1344, 1350, 1351, 1361, 1362, 1370, 1373, 1378, 1382, 1409, 1419, 1484, 1493, 1494, 1495, 1496, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1531, 1532, 1540, 1542, 1543, 1544, 1545, 1550, 1551, 1567, 1580, 1583, 1586, 1602, 1603, 1605, 1606, 1607, 1609, 1612, 1620, 1626, 1628, 1630, 1633, 1636, 1637, 1638, 1639, 1651, 1659, 1677, 1686, 1695, 1697, 1699, 1711, 1712, 1713, 1738, 1760, 1770, 1773, 1774, 1787, 1822, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1865, 1874, 1877, 1882, 1892, 1914, 1948, 1988, 1989, 1994, 2018, 2029, 2030, 2033, 2038, 2040, 2041, 2045, 2091, 2093, 2095, 2096, 2098, 2100, 2102, 2103, 2114, 2115, 2117, 2126, 2128, 2129, 2132, 2133, 2134, 2138, 2142, 2144, 2145, 2146, 2148, 2151, 2157, 2158, 2159, 2161, 2162, 2166, 2168, 2171, 2173, 2174, 2176, 2177, 2178, 2182, 2183, 2184, 2185, 2188, 2189, 2192, 2193, 2194, 2196, 2197, 2198, 2200, 2201, 2202, 2204, 2205], "caus": [1, 2, 3, 4, 6, 13, 16, 20, 25, 29, 30, 32, 35, 44, 50, 51, 52, 56, 58, 65, 69, 556, 617, 907, 910, 923, 1005, 1198, 1231, 1240, 1241, 1326, 1330, 1350, 1351, 1378, 1438, 1697, 1698, 1757, 1760, 1770, 1826, 1835, 1932, 1933, 1942, 1990, 2033, 2093, 2096, 2111, 2114, 2128, 2130, 2133, 2135, 2144, 2145, 2146, 2148, 2151, 2154, 2157, 2158, 2161, 2162, 2168, 2171, 2174, 2189, 2192, 2194, 2196, 2204], "mismatch": [1, 30, 69, 910, 1315, 1834, 1835, 2095, 2126, 2132, 2133, 2135, 2154, 2178, 2204], "error": [1, 2, 6, 9, 16, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 39, 42, 49, 51, 52, 56, 58, 60, 63, 65, 68, 69, 71, 72, 190, 221, 313, 315, 321, 323, 328, 488, 545, 556, 614, 617, 681, 837, 895, 908, 910, 930, 933, 935, 938, 939, 940, 941, 942, 943, 944, 948, 956, 957, 1002, 1014, 1037, 1049, 1078, 1089, 1101, 1115, 1119, 1142, 1201, 1205, 1206, 1208, 1213, 1218, 1226, 1228, 1237, 1241, 1245, 1278, 1314, 1319, 1329, 1344, 1345, 1354, 1356, 1358, 1361, 1362, 1363, 1373, 1376, 1386, 1404, 1438, 1466, 1492, 1493, 1529, 1540, 1546, 1571, 1580, 1610, 1612, 1639, 1684, 1695, 1718, 1738, 1741, 1742, 1770, 1773, 1774, 1776, 1785, 1822, 1827, 1834, 1835, 1877, 1888, 1928, 1935, 1979, 1985, 1990, 2033, 2036, 2045, 2046, 2091, 2093, 2095, 2096, 2100, 2102, 2103, 2111, 2114, 2115, 2116, 2117, 2126, 2127, 2130, 2133, 2134, 2138, 2139, 2145, 2146, 2147, 2150, 2154, 2158, 2164, 2166, 2172, 2177, 2178, 2181, 2182, 2186, 2189, 2191, 2192, 2194, 2195, 2207, 2208, 2209], "If": [1, 2, 3, 4, 5, 6, 8, 10, 13, 14, 16, 17, 21, 22, 23, 25, 26, 27, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 44, 48, 49, 50, 51, 52, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 79, 80, 81, 82, 86, 88, 97, 150, 154, 195, 206, 209, 233, 254, 315, 319, 321, 445, 446, 447, 448, 449, 458, 471, 481, 486, 496, 499, 517, 520, 537, 545, 580, 581, 583, 584, 585, 587, 588, 603, 607, 617, 623, 681, 684, 687, 688, 693, 697, 700, 701, 702, 704, 706, 707, 708, 710, 746, 767, 771, 775, 790, 792, 796, 807, 808, 832, 839, 840, 841, 846, 884, 888, 891, 895, 904, 905, 906, 907, 908, 909, 910, 919, 921, 922, 923, 930, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 958, 969, 970, 971, 973, 980, 982, 983, 984, 986, 990, 992, 993, 996, 997, 1002, 1004, 1007, 1014, 1016, 1020, 1021, 1022, 1026, 1027, 1036, 1039, 1040, 1041, 1046, 1049, 1051, 1053, 1056, 1057, 1065, 1073, 1078, 1084, 1089, 1090, 1105, 1112, 1115, 1125, 1126, 1127, 1131, 1132, 1133, 1134, 1135, 1144, 1145, 1146, 1147, 1157, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1187, 1195, 1196, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1212, 1213, 1222, 1226, 1227, 1228, 1236, 1238, 1240, 1241, 1245, 1255, 1263, 1268, 1272, 1273, 1275, 1276, 1277, 1278, 1289, 1291, 1305, 1311, 1314, 1317, 1318, 1319, 1322, 1324, 1326, 1327, 1330, 1331, 1334, 1335, 1336, 1340, 1344, 1345, 1350, 1351, 1353, 1354, 1356, 1357, 1358, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1375, 1377, 1378, 1380, 1381, 1382, 1384, 1385, 1386, 1387, 1397, 1401, 1402, 1404, 1406, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1438, 1443, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1475, 1484, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1527, 1528, 1531, 1532, 1533, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1556, 1557, 1558, 1559, 1560, 1561, 1565, 1567, 1571, 1572, 1573, 1574, 1575, 1580, 1581, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1594, 1595, 1596, 1598, 1602, 1603, 1604, 1605, 1606, 1607, 1612, 1613, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1632, 1633, 1636, 1637, 1638, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1682, 1686, 1688, 1690, 1697, 1698, 1703, 1705, 1707, 1708, 1709, 1711, 1712, 1713, 1722, 1723, 1724, 1727, 1730, 1731, 1738, 1744, 1745, 1756, 1757, 1763, 1769, 1770, 1772, 1776, 1777, 1778, 1781, 1782, 1785, 1787, 1788, 1790, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1813, 1814, 1815, 1817, 1820, 1821, 1822, 1824, 1825, 1826, 1827, 1831, 1832, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1847, 1848, 1849, 1850, 1852, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876, 1877, 1880, 1881, 1886, 1890, 1892, 1893, 1897, 1898, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1913, 1914, 1919, 1921, 1924, 1928, 1930, 1932, 1935, 1936, 1940, 1942, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1965, 1969, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1985, 1988, 1989, 1990, 1993, 1994, 1995, 2008, 2011, 2012, 2014, 2015, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2029, 2030, 2033, 2036, 2039, 2040, 2041, 2045, 2057, 2071, 2082, 2089, 2090, 2091, 2093, 2096, 2098, 2100, 2104, 2105, 2106, 2107, 2108, 2109, 2111, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2130, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2144, 2145, 2146, 2147, 2148, 2150, 2154, 2157, 2158, 2159, 2161, 2162, 2164, 2165, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2184, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209], "cast": [1, 4, 7, 26, 34, 49, 60, 335, 603, 604, 987, 1125, 1126, 1314, 1367, 1371, 1384, 1414, 1471, 1474, 1580, 1705, 1744, 1745, 1827, 1877, 1890, 1969, 1972, 1979, 1993, 1998, 2000, 2093, 2126, 2145, 2154, 2172, 2173, 2174, 2195], "back": [1, 2, 3, 16, 21, 22, 25, 26, 30, 32, 37, 39, 51, 56, 60, 65, 69, 71, 76, 80, 486, 746, 865, 949, 999, 1002, 1164, 1196, 1202, 1315, 1328, 1380, 1386, 1627, 1776, 1777, 1778, 1779, 1780, 1785, 1975, 2091, 2093, 2096, 2100, 2111, 2117, 2127, 2130, 2133, 2134, 2136, 2144, 2145, 2146, 2154, 2157, 2158, 2161, 2166, 2171, 2173, 2185, 2189, 2192, 2195, 2197, 2202, 2206], "from": [1, 2, 4, 6, 7, 8, 9, 10, 16, 17, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 44, 45, 48, 49, 51, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 68, 71, 73, 74, 76, 77, 78, 79, 80, 83, 85, 86, 87, 88, 153, 154, 173, 196, 221, 222, 233, 258, 286, 313, 315, 319, 321, 377, 402, 448, 454, 471, 473, 474, 481, 486, 487, 488, 493, 499, 513, 515, 517, 544, 546, 560, 580, 607, 608, 610, 617, 681, 723, 724, 725, 726, 727, 728, 731, 739, 740, 743, 746, 749, 750, 751, 752, 753, 754, 756, 757, 767, 771, 775, 783, 784, 785, 792, 800, 802, 805, 806, 807, 810, 811, 815, 830, 831, 832, 843, 851, 869, 884, 888, 890, 891, 892, 894, 895, 909, 910, 921, 930, 932, 934, 935, 936, 938, 939, 940, 941, 942, 943, 949, 950, 954, 955, 969, 971, 972, 980, 981, 986, 999, 1004, 1015, 1038, 1039, 1053, 1054, 1055, 1056, 1057, 1078, 1082, 1101, 1128, 1144, 1145, 1146, 1147, 1164, 1166, 1167, 1172, 1173, 1174, 1178, 1179, 1180, 1181, 1184, 1185, 1186, 1195, 1197, 1198, 1199, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1209, 1220, 1226, 1227, 1228, 1233, 1242, 1251, 1272, 1273, 1277, 1291, 1311, 1312, 1314, 1315, 1317, 1319, 1320, 1321, 1322, 1325, 1326, 1338, 1354, 1358, 1367, 1370, 1371, 1384, 1385, 1386, 1387, 1401, 1405, 1406, 1419, 1425, 1427, 1433, 1434, 1435, 1436, 1438, 1443, 1466, 1475, 1476, 1484, 1488, 1494, 1495, 1496, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1516, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1531, 1532, 1533, 1534, 1540, 1542, 1543, 1544, 1545, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1580, 1581, 1582, 1586, 1590, 1591, 1595, 1596, 1598, 1599, 1620, 1625, 1626, 1628, 1630, 1632, 1633, 1640, 1644, 1651, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1683, 1686, 1688, 1695, 1697, 1711, 1712, 1713, 1725, 1756, 1760, 1763, 1769, 1770, 1776, 1779, 1780, 1789, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1807, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1824, 1828, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1880, 1882, 1885, 1893, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1914, 1915, 1918, 1920, 1921, 1928, 1940, 1948, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 1991, 1993, 1995, 2008, 2011, 2020, 2022, 2024, 2029, 2030, 2033, 2035, 2039, 2048, 2050, 2093, 2094, 2095, 2096, 2098, 2102, 2103, 2104, 2106, 2107, 2108, 2109, 2114, 2116, 2118, 2122, 2124, 2127, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2142, 2144, 2145, 2146, 2147, 2149, 2150, 2151, 2156, 2157, 2159, 2161, 2162, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2182, 2183, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2209], "alreadi": [1, 2, 4, 13, 21, 25, 26, 30, 31, 34, 37, 38, 51, 52, 58, 60, 68, 69, 86, 88, 195, 206, 209, 463, 486, 524, 580, 603, 604, 623, 805, 869, 884, 888, 909, 954, 956, 958, 1049, 1057, 1080, 1224, 1228, 1314, 1324, 1386, 1443, 1580, 1764, 1770, 1813, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1877, 2027, 2029, 2036, 2067, 2091, 2093, 2100, 2103, 2107, 2115, 2116, 2126, 2127, 2130, 2133, 2136, 2138, 2144, 2147, 2154, 2157, 2158, 2161, 2167, 2168, 2171, 2173, 2175, 2189, 2192, 2193, 2194, 2204], "incur": [1, 6, 26, 30, 32, 34, 60, 992, 2117, 2144, 2166], "addit": [1, 2, 4, 6, 8, 10, 16, 17, 25, 30, 31, 36, 37, 39, 45, 51, 52, 57, 58, 60, 68, 69, 71, 80, 335, 513, 607, 760, 762, 763, 764, 765, 769, 771, 792, 808, 829, 889, 1101, 1311, 1314, 1318, 1324, 1329, 1484, 1495, 1496, 1497, 1510, 1511, 1512, 1523, 1530, 1531, 1533, 1540, 1543, 1544, 1552, 1559, 1560, 1561, 1565, 1566, 1567, 1568, 1570, 1576, 1577, 1578, 1580, 1586, 1588, 1614, 1616, 1620, 1624, 1626, 1628, 1630, 1657, 1664, 1665, 1666, 1703, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1936, 2005, 2029, 2030, 2033, 2043, 2093, 2095, 2096, 2100, 2102, 2109, 2115, 2116, 2117, 2127, 2129, 2130, 2133, 2134, 2136, 2140, 2144, 2145, 2148, 2150, 2159, 2161, 2162, 2164, 2166, 2167, 2168, 2171, 2175, 2178, 2186, 2189, 2191, 2195, 2200, 2201, 2204, 2205, 2207], "overhead": [1, 2, 4, 5, 9, 26, 30, 60, 792, 1002, 1007, 1014, 1101, 1326, 1770, 1779, 1780, 2078, 2117, 2127, 2129, 2130, 2132, 2139, 2140, 2144, 2159, 2167, 2171, 2177, 2189, 2194, 2195, 2197, 2198, 2204], "here": [1, 2, 8, 9, 10, 14, 17, 20, 25, 26, 30, 31, 32, 34, 36, 37, 38, 39, 50, 52, 56, 57, 58, 62, 63, 64, 65, 68, 69, 580, 806, 807, 834, 935, 936, 1025, 1047, 1144, 1161, 1163, 1164, 1169, 1170, 1171, 1173, 1174, 1179, 1181, 1201, 1211, 1312, 1326, 1494, 1495, 1496, 1510, 1511, 1512, 1542, 1543, 1544, 1588, 1620, 1686, 1688, 1779, 1780, 1790, 1857, 1860, 1872, 1936, 1960, 2091, 2093, 2095, 2096, 2098, 2100, 2112, 2113, 2115, 2116, 2117, 2126, 2127, 2130, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2142, 2147, 2148, 2154, 2157, 2158, 2161, 2164, 2171, 2175, 2176, 2178, 2180, 2186, 2189, 2191, 2192, 2194, 2195, 2196, 2197, 2198, 2201, 2202, 2204, 2205], "assum": [1, 13, 14, 21, 22, 25, 30, 32, 36, 37, 38, 39, 41, 44, 52, 56, 57, 58, 60, 63, 66, 69, 832, 1014, 1019, 1127, 1162, 1165, 1167, 1175, 1176, 1177, 1180, 1228, 1232, 1238, 1305, 1311, 1312, 1315, 1330, 1350, 1351, 1353, 1360, 1369, 1372, 1375, 1377, 1387, 1499, 1572, 1633, 1670, 1770, 1790, 1793, 1817, 1861, 1862, 1868, 1869, 1870, 1873, 1875, 1876, 1882, 2018, 2020, 2036, 2091, 2093, 2095, 2096, 2100, 2115, 2124, 2127, 2130, 2133, 2134, 2138, 2140, 2144, 2145, 2157, 2158, 2166, 2167, 2168, 2171, 2173, 2180, 2185, 2189, 2191, 2192, 2193, 2200, 2204], "a_float32": 1, "rand": [1, 2, 6, 13, 20, 37, 39, 56, 69, 335, 704, 710, 938, 939, 940, 941, 942, 943, 1007, 1027, 1086, 1087, 1161, 1163, 1166, 1167, 1169, 1170, 1173, 1174, 1176, 1177, 1179, 1181, 1203, 1320, 1321, 1326, 1330, 1331, 1332, 1388, 1389, 1391, 1492, 1545, 1624, 1625, 1626, 1627, 1628, 1658, 1677, 1678, 1738, 1770, 1793, 1825, 1885, 1896, 1897, 1898, 1902, 2093, 2094, 2095, 2096, 2098, 2108, 2115, 2116, 2133, 2137, 2149, 2150, 2154, 2155, 2161, 2166, 2167, 2171, 2172, 2175, 2176, 2180, 2189, 2199, 2202], "8": [1, 2, 16, 22, 24, 25, 26, 30, 37, 38, 39, 41, 56, 71, 76, 313, 315, 317, 321, 401, 402, 471, 513, 517, 560, 607, 617, 696, 697, 708, 709, 756, 757, 772, 774, 776, 784, 785, 839, 840, 841, 846, 941, 973, 981, 992, 995, 996, 1000, 1002, 1086, 1087, 1123, 1127, 1142, 1147, 1160, 1176, 1177, 1183, 1184, 1187, 1194, 1268, 1277, 1278, 1338, 1367, 1370, 1371, 1372, 1380, 1382, 1385, 1386, 1475, 1476, 1481, 1482, 1483, 1485, 1486, 1487, 1500, 1501, 1502, 1503, 1514, 1550, 1576, 1577, 1583, 1585, 1587, 1594, 1596, 1599, 1602, 1603, 1604, 1605, 1606, 1607, 1620, 1624, 1625, 1626, 1627, 1628, 1632, 1640, 1662, 1665, 1668, 1725, 1730, 1736, 1737, 1738, 1779, 1780, 1827, 1828, 1838, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1865, 1874, 1881, 1885, 1889, 1909, 1919, 1920, 1921, 1928, 1936, 1940, 1947, 1950, 1955, 1961, 1965, 1973, 1976, 1977, 1982, 1990, 1994, 2007, 2012, 2013, 2014, 2016, 2018, 2027, 2031, 2033, 2039, 2046, 2093, 2097, 2103, 2122, 2130, 2133, 2136, 2139, 2147, 2150, 2154, 2155, 2158, 2159, 2161, 2164, 2166, 2171, 2172, 2174, 2175, 2177, 2185, 2186, 2192, 2193, 2204, 2205], "b_float32": 1, "c_float32": 1, "d_float32": 1, "mm": [1, 6, 36, 37, 1318, 1370, 1409, 1590, 1591, 1892, 1994, 2033, 2094, 2095, 2108, 2115, 2126, 2129, 2133, 2145, 2155, 2171, 2198, 2199], "list": [1, 2, 4, 6, 7, 8, 10, 14, 16, 17, 20, 21, 22, 25, 26, 30, 31, 32, 34, 35, 36, 37, 39, 41, 51, 54, 56, 57, 58, 60, 65, 68, 69, 71, 72, 76, 77, 79, 80, 184, 233, 241, 302, 445, 447, 449, 493, 578, 583, 584, 585, 589, 619, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 805, 806, 810, 812, 813, 829, 830, 831, 832, 866, 884, 891, 909, 916, 917, 918, 956, 984, 985, 988, 992, 1001, 1002, 1004, 1012, 1019, 1068, 1075, 1129, 1142, 1144, 1145, 1184, 1199, 1211, 1226, 1228, 1237, 1254, 1268, 1278, 1314, 1318, 1320, 1321, 1326, 1328, 1330, 1331, 1414, 1416, 1474, 1516, 1522, 1552, 1580, 1582, 1591, 1595, 1609, 1620, 1631, 1644, 1677, 1753, 1769, 1770, 1771, 1772, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1827, 1831, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1892, 1895, 1897, 1898, 1901, 1905, 1920, 1956, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1985, 1988, 1989, 1993, 2005, 2011, 2012, 2013, 2029, 2030, 2033, 2034, 2036, 2040, 2041, 2046, 2059, 2065, 2089, 2091, 2093, 2094, 2097, 2098, 2100, 2102, 2106, 2109, 2115, 2116, 2117, 2133, 2139, 2141, 2142, 2145, 2146, 2147, 2149, 2150, 2155, 2156, 2157, 2158, 2159, 2161, 2166, 2167, 2171, 2173, 2174, 2175, 2176, 2177, 2180, 2181, 2182, 2183, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2198, 2202, 2203, 2204, 2205, 2206, 2207], "No": [1, 10, 14, 32, 37, 41, 55, 57, 68, 689, 693, 930, 934, 935, 936, 1770, 1779, 1780, 1825, 2095, 2117, 2130, 2154, 2164, 2175, 2178, 2189], "manual": [1, 21, 25, 30, 34, 38, 49, 51, 52, 55, 60, 69, 486, 811, 866, 908, 944, 1007, 1228, 1277, 1318, 1492, 1493, 1515, 1584, 1585, 1587, 1609, 1628, 1658, 1659, 1669, 1722, 1793, 1813, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 2093, 2096, 2100, 2104, 2114, 2126, 2130, 2133, 2134, 2135, 2138, 2142, 2148, 2150, 2154, 2161, 2162, 2176, 2191, 2201, 2202, 2204, 2205, 2209], "e_float16": 1, "handl": [1, 2, 6, 10, 13, 16, 22, 25, 26, 30, 31, 32, 33, 34, 35, 36, 37, 41, 43, 44, 51, 52, 56, 58, 60, 68, 69, 487, 488, 813, 834, 869, 920, 930, 934, 935, 936, 954, 955, 1004, 1022, 1039, 1058, 1088, 1102, 1144, 1190, 1191, 1213, 1221, 1314, 1345, 1516, 1580, 1628, 1630, 1686, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1912, 1957, 1995, 2045, 2091, 2100, 2109, 2114, 2116, 2117, 2130, 2133, 2134, 2135, 2138, 2139, 2144, 2149, 2154, 2157, 2158, 2161, 2166, 2168, 2178, 2180, 2189, 2192, 2194, 2196, 2200, 2204, 2209], "f_float16": 1, "g_float32": 1, "epoch": [1, 25, 44, 55, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878, 2109, 2126, 2144, 2157, 2176], "eval": [1, 69, 829, 890, 891, 1211, 1314, 1318, 1324, 1330, 1494, 1495, 1496, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1586, 1620, 1628, 1781, 1783, 1788, 1877, 2096, 2106, 2137, 2142, 2149, 2150, 2151, 2154, 2156, 2161, 2182, 2191, 2192, 2204, 2206], "jit": [1, 3, 13, 16, 56, 1044, 1086, 1087, 1265, 1312, 1313, 1314, 1329, 1444, 1833, 1834, 1938, 1939, 2095, 2098, 2100, 2106, 2116, 2129, 2140, 2147, 2149, 2150, 2154, 2156, 2160, 2161, 2166, 2176, 2186, 2190, 2191, 2192, 2193, 2195, 2197], "trace": [1, 2, 6, 14, 17, 20, 25, 26, 27, 30, 36, 37, 44, 56, 57, 71, 74, 75, 76, 77, 78, 81, 82, 486, 681, 870, 959, 961, 962, 965, 1002, 1004, 1009, 1010, 1019, 1144, 1214, 1215, 1218, 1222, 1227, 1232, 1317, 1326, 1327, 1331, 1387, 1433, 1434, 1435, 1835, 2035, 2094, 2095, 2096, 2098, 2100, 2102, 2127, 2130, 2136, 2147, 2149, 2150, 2151, 2155, 2158, 2176, 2183, 2190, 2191, 2192, 2194, 2197, 2198, 2200, 2205, 2207, 2208, 2209], "testmodel": 1, "__init__": [1, 2, 14, 25, 26, 30, 36, 39, 56, 69, 71, 78, 79, 80, 891, 892, 1211, 1312, 1315, 1317, 1320, 1321, 1326, 1330, 1331, 1332, 1580, 1581, 1582, 1590, 1591, 1595, 1738, 1760, 1769, 2093, 2095, 2096, 2109, 2127, 2133, 2135, 2142, 2147, 2149, 2150, 2154, 2157, 2158, 2161, 2176, 2177, 2185, 2186, 2190, 2191, 2202, 2203, 2204, 2205], "input_s": [1, 745, 771, 772, 776, 1531, 1532, 1550, 1551, 1596, 1597, 1598, 2094], "num_class": [1, 1724, 2094, 2197], "super": [1, 10, 14, 25, 26, 30, 32, 36, 56, 69, 71, 78, 79, 80, 891, 892, 1211, 1312, 1317, 1320, 1321, 1326, 1330, 1331, 1332, 1580, 1581, 1582, 1590, 1591, 1592, 1593, 1738, 1760, 1872, 2093, 2095, 2096, 2097, 2127, 2133, 2142, 2147, 2149, 2150, 2154, 2157, 2158, 2161, 2185, 2186, 2190, 2202, 2203, 2205], "fc1": [1, 26, 1760, 2150, 2157, 2185, 2186], "x": [1, 2, 4, 6, 13, 14, 16, 25, 26, 30, 36, 37, 39, 41, 48, 56, 57, 58, 60, 62, 63, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 173, 254, 258, 286, 289, 311, 313, 315, 317, 321, 352, 377, 448, 483, 486, 493, 499, 558, 560, 583, 607, 608, 617, 703, 769, 771, 781, 790, 791, 795, 796, 809, 814, 817, 839, 840, 891, 892, 908, 914, 916, 917, 918, 925, 928, 929, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 945, 946, 965, 984, 985, 986, 989, 990, 995, 1002, 1004, 1009, 1010, 1014, 1015, 1019, 1020, 1023, 1026, 1027, 1057, 1086, 1087, 1127, 1134, 1138, 1139, 1144, 1148, 1158, 1159, 1160, 1161, 1163, 1164, 1169, 1170, 1172, 1174, 1178, 1179, 1181, 1184, 1185, 1186, 1194, 1201, 1203, 1205, 1206, 1207, 1208, 1209, 1211, 1212, 1213, 1238, 1244, 1253, 1254, 1268, 1285, 1289, 1301, 1319, 1320, 1321, 1325, 1326, 1329, 1330, 1331, 1332, 1336, 1346, 1359, 1360, 1364, 1367, 1371, 1375, 1377, 1380, 1381, 1382, 1383, 1384, 1387, 1392, 1393, 1394, 1402, 1405, 1408, 1409, 1416, 1470, 1471, 1475, 1476, 1482, 1483, 1492, 1493, 1494, 1495, 1496, 1498, 1513, 1515, 1521, 1527, 1528, 1529, 1531, 1532, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1542, 1543, 1544, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1566, 1569, 1570, 1571, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1587, 1588, 1589, 1590, 1591, 1595, 1596, 1598, 1599, 1600, 1601, 1608, 1610, 1611, 1612, 1613, 1615, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1629, 1630, 1633, 1660, 1684, 1686, 1690, 1691, 1697, 1701, 1705, 1717, 1722, 1727, 1731, 1733, 1739, 1740, 1741, 1745, 1746, 1748, 1749, 1750, 1757, 1760, 1769, 1788, 1791, 1793, 1813, 1814, 1815, 1816, 1817, 1822, 1825, 1826, 1827, 1834, 1837, 1865, 1882, 1883, 1894, 1896, 1910, 1913, 1914, 1916, 1917, 1919, 1920, 1924, 1928, 1965, 1967, 1970, 1985, 1987, 1988, 1989, 1990, 1996, 1997, 2006, 2012, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2030, 2032, 2039, 2040, 2041, 2043, 2044, 2045, 2048, 2091, 2093, 2094, 2095, 2096, 2097, 2100, 2114, 2115, 2116, 2117, 2122, 2124, 2127, 2128, 2129, 2130, 2133, 2134, 2135, 2138, 2139, 2142, 2143, 2148, 2149, 2150, 2152, 2154, 2157, 2158, 2161, 2166, 2170, 2171, 2172, 2174, 2176, 2177, 2180, 2181, 2182, 2183, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2197, 2202, 2204, 2205], "2": [1, 2, 4, 6, 13, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 35, 37, 38, 39, 40, 41, 44, 49, 51, 52, 56, 57, 60, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 173, 191, 208, 225, 233, 234, 254, 260, 286, 313, 315, 317, 321, 335, 377, 401, 402, 445, 446, 447, 448, 449, 481, 487, 488, 493, 496, 499, 513, 515, 517, 544, 558, 560, 580, 581, 583, 584, 585, 587, 588, 589, 607, 617, 681, 682, 694, 695, 696, 697, 700, 701, 702, 703, 704, 706, 708, 709, 710, 745, 749, 750, 751, 752, 753, 754, 756, 757, 766, 769, 771, 773, 806, 809, 839, 895, 904, 905, 906, 907, 908, 909, 910, 914, 916, 917, 918, 920, 930, 933, 935, 936, 938, 939, 940, 941, 942, 943, 945, 946, 954, 955, 958, 965, 967, 969, 971, 973, 974, 975, 976, 977, 978, 979, 980, 981, 983, 984, 985, 986, 988, 989, 990, 992, 993, 994, 995, 996, 1000, 1001, 1009, 1015, 1016, 1020, 1021, 1022, 1023, 1026, 1027, 1036, 1119, 1123, 1127, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1139, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1154, 1157, 1158, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1184, 1185, 1186, 1187, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1201, 1202, 1203, 1206, 1207, 1208, 1212, 1213, 1228, 1238, 1255, 1256, 1257, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1280, 1281, 1289, 1291, 1301, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1314, 1317, 1318, 1324, 1326, 1328, 1330, 1334, 1335, 1336, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1391, 1392, 1393, 1394, 1401, 1403, 1404, 1405, 1406, 1408, 1409, 1412, 1413, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1438, 1441, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1480, 1483, 1488, 1489, 1490, 1491, 1492, 1493, 1498, 1499, 1500, 1501, 1502, 1504, 1505, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1529, 1530, 1531, 1533, 1535, 1536, 1537, 1538, 1540, 1547, 1548, 1549, 1550, 1551, 1552, 1566, 1568, 1569, 1570, 1571, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1582, 1583, 1585, 1586, 1588, 1589, 1591, 1592, 1593, 1594, 1595, 1596, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1608, 1610, 1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1629, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1651, 1653, 1658, 1659, 1670, 1677, 1678, 1684, 1686, 1688, 1690, 1697, 1703, 1711, 1712, 1713, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1738, 1754, 1760, 1769, 1770, 1775, 1776, 1779, 1780, 1785, 1787, 1788, 1793, 1797, 1805, 1806, 1807, 1809, 1810, 1813, 1815, 1816, 1818, 1819, 1820, 1821, 1822, 1825, 1826, 1827, 1828, 1830, 1831, 1832, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1885, 1886, 1889, 1890, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1901, 1903, 1905, 1907, 1908, 1909, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1924, 1928, 1930, 1931, 1933, 1934, 1935, 1936, 1940, 1945, 1946, 1947, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1961, 1965, 1966, 1967, 1968, 1970, 1971, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1987, 1988, 1989, 1990, 1991, 1993, 1994, 1995, 1996, 1997, 2006, 2007, 2009, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2036, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2089, 2090, 2094, 2095, 2096, 2097, 2100, 2103, 2104, 2106, 2108, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2129, 2132, 2133, 2136, 2137, 2138, 2139, 2142, 2143, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2159, 2163, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2182, 2183, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2197, 2198, 2199, 2202, 2203, 2204, 2209], "For": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 34, 36, 37, 38, 39, 41, 48, 49, 51, 52, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 73, 80, 196, 254, 289, 313, 315, 321, 335, 352, 415, 471, 481, 486, 493, 499, 513, 515, 517, 583, 589, 603, 617, 697, 698, 699, 700, 701, 704, 710, 745, 749, 750, 751, 752, 753, 754, 771, 805, 806, 807, 813, 829, 888, 889, 895, 922, 935, 936, 949, 956, 970, 974, 976, 977, 979, 982, 991, 1002, 1007, 1078, 1092, 1094, 1101, 1125, 1126, 1127, 1144, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1188, 1196, 1211, 1213, 1227, 1228, 1232, 1242, 1255, 1268, 1277, 1291, 1314, 1325, 1326, 1328, 1330, 1331, 1344, 1346, 1350, 1351, 1354, 1355, 1357, 1358, 1359, 1360, 1362, 1371, 1372, 1374, 1375, 1378, 1387, 1394, 1402, 1409, 1415, 1419, 1484, 1488, 1492, 1493, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1522, 1523, 1525, 1526, 1531, 1533, 1540, 1545, 1550, 1552, 1580, 1583, 1584, 1585, 1586, 1594, 1595, 1596, 1602, 1603, 1604, 1605, 1606, 1607, 1612, 1617, 1631, 1632, 1636, 1637, 1638, 1640, 1641, 1642, 1643, 1659, 1661, 1662, 1663, 1672, 1673, 1674, 1679, 1686, 1697, 1723, 1725, 1738, 1746, 1760, 1769, 1770, 1771, 1791, 1813, 1814, 1815, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1874, 1877, 1905, 1921, 1930, 1933, 1941, 1967, 1968, 1979, 1985, 1994, 1995, 2012, 2014, 2018, 2026, 2029, 2034, 2036, 2043, 2044, 2045, 2073, 2074, 2078, 2091, 2092, 2093, 2096, 2098, 2100, 2102, 2103, 2105, 2106, 2109, 2111, 2115, 2116, 2117, 2118, 2122, 2126, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2141, 2142, 2144, 2145, 2146, 2147, 2150, 2152, 2154, 2157, 2158, 2159, 2161, 2162, 2165, 2166, 2167, 2168, 2171, 2173, 2174, 2175, 2176, 2177, 2178, 2183, 2185, 2187, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2198, 2200, 2201, 2203, 2204, 2205, 2206, 2209], "now": [1, 2, 21, 30, 34, 36, 40, 48, 52, 54, 56, 58, 60, 65, 69, 496, 930, 934, 935, 936, 944, 958, 1053, 1086, 1109, 1110, 1195, 1196, 1261, 1311, 1312, 1318, 1330, 1364, 1577, 1597, 1633, 1760, 1775, 1793, 1804, 1824, 1843, 1933, 1985, 1990, 2036, 2093, 2103, 2111, 2115, 2116, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2136, 2137, 2142, 2143, 2145, 2147, 2154, 2158, 2161, 2167, 2168, 2171, 2173, 2189, 2191, 2192, 2194, 2195, 2196, 2198, 2203, 2204, 2205, 2206, 2207], "we": [1, 2, 3, 6, 8, 9, 10, 13, 14, 16, 17, 25, 26, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 51, 52, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 68, 69, 71, 81, 82, 486, 496, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 790, 796, 800, 802, 804, 806, 807, 866, 887, 889, 891, 892, 895, 923, 925, 930, 931, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 956, 958, 971, 980, 1002, 1004, 1034, 1101, 1144, 1162, 1164, 1165, 1166, 1167, 1174, 1179, 1180, 1181, 1195, 1205, 1206, 1208, 1213, 1214, 1218, 1221, 1222, 1224, 1226, 1227, 1228, 1230, 1232, 1234, 1235, 1236, 1237, 1238, 1240, 1241, 1242, 1251, 1268, 1272, 1273, 1289, 1312, 1314, 1317, 1318, 1326, 1328, 1330, 1370, 1373, 1378, 1386, 1387, 1406, 1466, 1484, 1489, 1490, 1491, 1492, 1493, 1527, 1545, 1580, 1633, 1686, 1688, 1697, 1757, 1764, 1770, 1779, 1780, 1787, 1790, 1799, 1801, 1804, 1807, 1808, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1862, 1869, 1874, 1877, 1893, 1936, 2029, 2034, 2045, 2091, 2092, 2093, 2095, 2096, 2098, 2100, 2103, 2104, 2105, 2106, 2111, 2114, 2115, 2116, 2117, 2122, 2127, 2130, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2141, 2142, 2144, 2145, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2161, 2162, 2164, 2166, 2167, 2168, 2171, 2173, 2174, 2176, 2177, 2180, 2181, 2182, 2184, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2201, 2202, 2203, 2204, 2205, 2209], "suggest": [1, 10, 26, 56, 58, 61, 1513, 1838, 2091, 2098, 2117, 2126, 2127, 2135, 2171, 2185, 2189, 2198, 2204, 2205], "issu": [1, 3, 4, 6, 10, 12, 13, 16, 24, 25, 30, 32, 34, 37, 39, 40, 56, 60, 61, 63, 65, 69, 71, 938, 944, 1002, 1004, 1005, 1195, 1207, 1209, 1213, 1360, 1404, 1416, 1545, 1550, 1596, 1633, 1697, 1698, 2045, 2091, 2096, 2098, 2103, 2108, 2114, 2115, 2116, 2117, 2126, 2127, 2130, 2133, 2136, 2144, 2145, 2146, 2147, 2148, 2150, 2151, 2154, 2157, 2158, 2161, 2162, 2166, 2171, 2172, 2173, 2189, 2192, 2193, 2195, 2196, 2205, 2207, 2208], "http": [1, 3, 4, 5, 8, 10, 13, 14, 16, 17, 26, 30, 36, 39, 41, 52, 56, 60, 681, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 806, 1002, 1019, 1144, 1387, 1499, 1550, 1600, 1627, 1630, 1789, 1824, 1882, 1899, 1936, 1956, 2033, 2036, 2091, 2097, 2100, 2107, 2110, 2111, 2122, 2127, 2128, 2137, 2138, 2139, 2142, 2146, 2148, 2158, 2176, 2177, 2193, 2197, 2198, 2204, 2210], "github": [1, 8, 10, 30, 47, 56, 61, 65, 806, 944, 1865, 2091, 2098, 2103, 2138, 2154, 2161, 2171, 2172, 2192, 2193, 2195, 2198, 2204], "com": [1, 16, 30, 50, 52, 806, 2033, 2091, 2100, 2107, 2110, 2111, 2138, 2139, 2146, 2148, 2193, 2198], "pytorch": [1, 2, 3, 4, 5, 11, 13, 14, 15, 16, 19, 20, 21, 22, 25, 26, 27, 32, 33, 35, 36, 38, 39, 40, 41, 44, 51, 52, 57, 60, 61, 64, 66, 69, 71, 150, 513, 583, 681, 709, 741, 742, 743, 744, 756, 757, 767, 771, 772, 773, 774, 775, 776, 805, 806, 825, 826, 827, 828, 910, 923, 956, 958, 987, 992, 993, 1002, 1003, 1004, 1019, 1057, 1066, 1067, 1080, 1085, 1144, 1189, 1195, 1202, 1203, 1207, 1212, 1213, 1242, 1259, 1300, 1301, 1325, 1345, 1351, 1356, 1358, 1359, 1360, 1363, 1376, 1385, 1401, 1404, 1405, 1416, 1456, 1492, 1493, 1499, 1531, 1545, 1576, 1577, 1578, 1586, 1624, 1625, 1626, 1627, 1628, 1641, 1642, 1643, 1659, 1738, 1770, 1779, 1780, 1813, 1821, 1822, 1824, 1827, 1835, 1892, 1924, 1932, 1933, 1934, 1942, 1990, 1994, 2020, 2033, 2036, 2045, 2058, 2067, 2070, 2091, 2095, 2096, 2100, 2102, 2103, 2106, 2107, 2109, 2111, 2116, 2117, 2118, 2122, 2125, 2128, 2129, 2134, 2135, 2137, 2138, 2139, 2140, 2142, 2143, 2144, 2145, 2148, 2149, 2150, 2151, 2156, 2157, 2158, 2159, 2162, 2163, 2166, 2167, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2180, 2184, 2185, 2186, 2188, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2202, 2203, 2204, 2206, 2207, 2208, 2210], "75956": 1, "_c": [1, 25, 26, 30, 68, 938, 944, 1041, 1313, 1326, 1833, 2094, 2096, 2109, 2130, 2139, 2140, 2145, 2148, 2154, 2166], "_jit_set_autocast_mod": 1, "fals": [1, 2, 3, 4, 6, 14, 16, 21, 25, 26, 30, 31, 32, 34, 35, 37, 38, 39, 41, 56, 58, 60, 63, 67, 69, 71, 73, 76, 80, 81, 82, 86, 112, 113, 114, 115, 116, 118, 134, 135, 136, 150, 181, 182, 183, 196, 209, 233, 260, 301, 318, 319, 321, 328, 332, 335, 336, 338, 342, 343, 344, 351, 354, 392, 396, 407, 409, 410, 411, 414, 415, 421, 429, 430, 431, 432, 445, 446, 447, 448, 449, 453, 458, 460, 470, 471, 479, 495, 496, 504, 517, 542, 555, 556, 565, 580, 594, 603, 609, 610, 615, 617, 623, 681, 704, 705, 706, 707, 708, 710, 723, 724, 725, 726, 727, 728, 743, 745, 746, 749, 750, 751, 756, 757, 762, 763, 764, 766, 767, 769, 771, 775, 779, 780, 787, 789, 790, 791, 793, 794, 796, 811, 814, 829, 837, 839, 840, 841, 843, 846, 851, 866, 868, 870, 887, 888, 893, 894, 895, 904, 905, 906, 910, 923, 925, 930, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 962, 971, 974, 977, 979, 980, 986, 987, 993, 994, 995, 1001, 1002, 1014, 1015, 1019, 1020, 1039, 1084, 1089, 1102, 1144, 1145, 1146, 1147, 1149, 1150, 1157, 1161, 1162, 1163, 1164, 1169, 1170, 1175, 1176, 1177, 1179, 1180, 1181, 1196, 1198, 1199, 1200, 1201, 1203, 1204, 1206, 1207, 1208, 1210, 1212, 1216, 1228, 1237, 1240, 1241, 1253, 1255, 1257, 1271, 1272, 1273, 1276, 1277, 1299, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1319, 1321, 1322, 1330, 1331, 1332, 1334, 1336, 1339, 1344, 1345, 1356, 1357, 1358, 1359, 1361, 1362, 1363, 1364, 1367, 1369, 1371, 1372, 1375, 1376, 1377, 1378, 1379, 1384, 1385, 1386, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1404, 1406, 1408, 1412, 1414, 1415, 1417, 1420, 1427, 1433, 1434, 1443, 1466, 1471, 1472, 1473, 1474, 1477, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1513, 1515, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1527, 1528, 1531, 1532, 1533, 1534, 1536, 1537, 1538, 1539, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1565, 1566, 1567, 1571, 1572, 1573, 1574, 1575, 1579, 1580, 1583, 1584, 1585, 1586, 1587, 1589, 1594, 1596, 1597, 1598, 1599, 1600, 1601, 1608, 1610, 1612, 1613, 1620, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1633, 1644, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1658, 1659, 1660, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1681, 1682, 1683, 1686, 1688, 1690, 1691, 1692, 1697, 1698, 1701, 1707, 1708, 1709, 1711, 1712, 1713, 1717, 1722, 1726, 1730, 1732, 1733, 1736, 1737, 1738, 1739, 1741, 1751, 1754, 1755, 1757, 1763, 1770, 1773, 1775, 1776, 1781, 1782, 1785, 1787, 1790, 1792, 1793, 1794, 1805, 1814, 1815, 1816, 1817, 1819, 1822, 1825, 1826, 1827, 1831, 1832, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876, 1877, 1880, 1890, 1892, 1893, 1897, 1898, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1916, 1917, 1924, 1928, 1936, 1937, 1940, 1942, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1965, 1976, 1977, 1978, 1979, 1980, 1981, 1988, 1989, 1990, 1993, 1994, 2011, 2015, 2020, 2029, 2033, 2034, 2036, 2039, 2040, 2041, 2048, 2050, 2089, 2090, 2091, 2093, 2094, 2095, 2096, 2100, 2102, 2103, 2105, 2106, 2107, 2114, 2116, 2117, 2122, 2126, 2127, 2130, 2132, 2133, 2135, 2136, 2137, 2142, 2145, 2146, 2147, 2149, 2150, 2151, 2152, 2154, 2156, 2157, 2158, 2159, 2162, 2165, 2166, 2171, 2172, 2173, 2175, 2176, 2178, 2180, 2182, 2186, 2189, 2191, 2192, 2193, 2195, 2199, 2200, 2203, 2204, 2205, 2206, 2209], "randn": [1, 2, 13, 14, 30, 36, 37, 38, 39, 56, 57, 58, 62, 64, 65, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 289, 311, 483, 544, 580, 584, 585, 586, 587, 588, 589, 617, 693, 694, 695, 696, 697, 698, 699, 700, 701, 706, 707, 710, 731, 739, 740, 745, 749, 750, 751, 752, 753, 754, 767, 769, 771, 772, 773, 774, 775, 776, 783, 784, 785, 891, 892, 904, 905, 906, 908, 911, 912, 913, 914, 915, 965, 970, 982, 989, 991, 992, 993, 994, 995, 997, 1022, 1023, 1024, 1025, 1026, 1036, 1057, 1123, 1124, 1125, 1131, 1132, 1133, 1134, 1138, 1144, 1158, 1159, 1188, 1196, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1211, 1212, 1213, 1285, 1289, 1291, 1326, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1368, 1369, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1383, 1390, 1394, 1395, 1402, 1404, 1405, 1406, 1408, 1409, 1412, 1414, 1415, 1417, 1419, 1421, 1422, 1441, 1465, 1468, 1478, 1481, 1482, 1483, 1485, 1486, 1487, 1488, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1512, 1513, 1514, 1515, 1517, 1518, 1519, 1520, 1521, 1522, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1578, 1579, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1607, 1608, 1610, 1611, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1629, 1631, 1632, 1636, 1637, 1638, 1640, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1681, 1682, 1688, 1722, 1728, 1729, 1769, 1830, 1883, 1888, 1889, 1890, 1892, 1893, 1906, 1910, 1911, 1923, 1958, 1960, 1965, 1971, 1975, 1983, 1984, 1987, 1993, 1994, 2006, 2009, 2010, 2013, 2017, 2020, 2021, 2023, 2026, 2028, 2033, 2043, 2044, 2045, 2048, 2094, 2095, 2096, 2098, 2100, 2104, 2115, 2116, 2117, 2122, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2139, 2142, 2146, 2147, 2150, 2151, 2152, 2154, 2155, 2158, 2161, 2166, 2171, 2172, 2174, 2176, 2180, 2182, 2185, 2186, 2189, 2190, 2192, 2193, 2195, 2197, 2199, 2202, 2204, 2205], "freez": [1, 60, 1228, 1314, 1324, 1522, 1523, 1580, 1877, 2127, 2185, 2189], "_": [1, 2, 4, 13, 25, 26, 30, 31, 35, 36, 44, 58, 66, 69, 682, 694, 695, 709, 895, 911, 912, 913, 914, 915, 925, 930, 934, 935, 936, 946, 972, 991, 1007, 1021, 1022, 1024, 1025, 1027, 1144, 1188, 1193, 1208, 1212, 1281, 1335, 1343, 1394, 1402, 1494, 1495, 1496, 1542, 1543, 1544, 1596, 1620, 1770, 1788, 1821, 1838, 1857, 1859, 1882, 1905, 1908, 1911, 1923, 1943, 1945, 1951, 1958, 1960, 1983, 1994, 2009, 2010, 2100, 2127, 2130, 2134, 2135, 2142, 2148, 2150, 2154, 2157, 2158, 2159, 2172, 2190, 2193, 2198, 2202, 2204, 2205], "3": [1, 2, 4, 5, 7, 10, 13, 14, 20, 21, 23, 25, 26, 27, 30, 32, 35, 36, 37, 39, 40, 41, 44, 49, 51, 56, 58, 60, 62, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 191, 208, 233, 254, 260, 289, 313, 315, 317, 321, 401, 402, 445, 446, 447, 448, 449, 471, 487, 488, 493, 496, 499, 513, 515, 517, 523, 537, 544, 558, 560, 581, 583, 584, 585, 587, 588, 607, 617, 681, 682, 696, 697, 698, 699, 700, 701, 702, 703, 704, 708, 709, 710, 745, 749, 750, 751, 752, 753, 754, 757, 759, 768, 771, 772, 773, 774, 776, 783, 784, 785, 796, 806, 843, 891, 892, 895, 905, 906, 908, 909, 910, 917, 918, 938, 939, 940, 941, 942, 943, 945, 965, 970, 972, 973, 974, 975, 976, 977, 978, 979, 981, 982, 983, 984, 985, 986, 988, 989, 990, 992, 993, 994, 995, 996, 1000, 1001, 1015, 1016, 1020, 1021, 1026, 1027, 1036, 1086, 1087, 1089, 1126, 1127, 1128, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1139, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1157, 1160, 1165, 1168, 1172, 1178, 1183, 1184, 1185, 1186, 1187, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1197, 1198, 1199, 1201, 1203, 1208, 1209, 1211, 1213, 1255, 1256, 1257, 1268, 1271, 1274, 1275, 1276, 1277, 1278, 1280, 1281, 1289, 1291, 1299, 1301, 1303, 1305, 1314, 1318, 1321, 1324, 1326, 1330, 1331, 1335, 1336, 1337, 1338, 1339, 1340, 1344, 1346, 1347, 1348, 1350, 1351, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1392, 1395, 1397, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1441, 1465, 1466, 1468, 1470, 1471, 1472, 1474, 1475, 1476, 1477, 1489, 1490, 1491, 1492, 1493, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1512, 1513, 1515, 1522, 1523, 1526, 1527, 1528, 1529, 1531, 1532, 1534, 1536, 1537, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1583, 1585, 1587, 1592, 1593, 1595, 1596, 1598, 1599, 1602, 1603, 1604, 1605, 1606, 1607, 1614, 1615, 1616, 1620, 1628, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1641, 1642, 1643, 1651, 1653, 1658, 1659, 1662, 1663, 1665, 1666, 1669, 1677, 1678, 1681, 1682, 1684, 1686, 1690, 1691, 1697, 1705, 1722, 1724, 1725, 1728, 1729, 1736, 1737, 1738, 1744, 1745, 1757, 1769, 1770, 1779, 1780, 1788, 1797, 1803, 1806, 1807, 1808, 1809, 1813, 1815, 1816, 1817, 1818, 1821, 1825, 1826, 1827, 1828, 1830, 1831, 1832, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1869, 1872, 1873, 1875, 1877, 1881, 1883, 1885, 1889, 1890, 1892, 1893, 1896, 1897, 1898, 1899, 1900, 1901, 1903, 1905, 1907, 1908, 1909, 1912, 1913, 1914, 1915, 1916, 1917, 1919, 1920, 1921, 1924, 1928, 1933, 1934, 1940, 1943, 1945, 1947, 1949, 1950, 1951, 1955, 1956, 1957, 1965, 1967, 1968, 1970, 1971, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1985, 1987, 1993, 1994, 1996, 1997, 2006, 2007, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2039, 2042, 2045, 2046, 2047, 2048, 2089, 2090, 2093, 2094, 2095, 2096, 2097, 2100, 2103, 2111, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2136, 2137, 2138, 2142, 2143, 2147, 2148, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2163, 2166, 2167, 2168, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2185, 2186, 2189, 2192, 2193, 2195, 2197, 2198, 2199, 2201, 2202, 2203, 2204, 2205, 2209], "bug": [1, 16, 20, 30, 56, 69, 1004, 1205, 1206, 1208, 1404, 2126, 2144, 2171, 2186, 2195, 2204, 2205], "what": [1, 2, 4, 6, 8, 9, 10, 19, 21, 30, 32, 34, 37, 39, 44, 48, 49, 56, 60, 62, 64, 65, 69, 71, 922, 935, 936, 1206, 1227, 1228, 1237, 1238, 1330, 1331, 1404, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1574, 1575, 1609, 1632, 1711, 1712, 1713, 1738, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 1874, 1893, 2091, 2093, 2095, 2096, 2100, 2104, 2115, 2130, 2133, 2134, 2136, 2138, 2142, 2144, 2154, 2157, 2159, 2161, 2166, 2167, 2171, 2177, 2184, 2189, 2190, 2191, 2192, 2194, 2196, 2197, 2205, 2207], "observ": [1, 26, 32, 41, 51, 58, 486, 767, 802, 803, 805, 806, 807, 808, 809, 811, 814, 815, 816, 817, 823, 824, 826, 828, 830, 832, 837, 839, 840, 841, 842, 843, 846, 851, 852, 855, 856, 857, 858, 859, 860, 861, 862, 864, 865, 866, 871, 889, 891, 892, 894, 957, 1023, 1027, 1245, 1328, 1416, 1492, 1493, 1494, 1495, 1496, 1513, 1515, 1539, 1542, 1543, 1544, 1545, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1620, 1629, 1658, 1659, 1669, 1698, 1722, 1730, 2126, 2127, 2130, 2140, 2144, 2159, 2162, 2182, 2188, 2189, 2195, 2202, 2207, 2209], "file": [1, 2, 4, 7, 8, 10, 13, 16, 20, 22, 25, 32, 37, 41, 44, 49, 51, 54, 56, 57, 58, 63, 65, 69, 938, 944, 945, 959, 961, 1038, 1057, 1082, 1196, 1205, 1206, 1208, 1209, 1314, 1322, 1325, 1386, 1834, 1924, 1968, 2091, 2093, 2096, 2097, 2098, 2104, 2107, 2115, 2116, 2117, 2127, 2130, 2133, 2140, 2144, 2146, 2148, 2150, 2151, 2154, 2159, 2164, 2167, 2171, 2173, 2176, 2185, 2186, 2190, 2191, 2192, 2195, 2197, 2198, 2201, 2202, 2204, 2205, 2207, 2208, 2209], "subregion": 1, "nest": [1, 2, 6, 14, 16, 32, 49, 56, 60, 69, 71, 74, 79, 80, 589, 806, 830, 832, 925, 940, 1019, 1106, 1107, 1203, 1213, 1314, 1317, 1330, 1580, 1586, 1627, 1628, 1738, 1779, 1780, 1835, 1877, 2045, 2079, 2122, 2134, 2136, 2154, 2159, 2160, 2166, 2177, 2202], "local": [1, 6, 30, 32, 35, 36, 37, 38, 41, 49, 51, 52, 54, 55, 60, 69, 945, 946, 947, 1086, 1148, 1202, 1314, 1387, 1518, 1519, 1520, 1524, 1526, 1568, 1580, 1632, 1680, 1704, 1756, 1770, 1772, 1825, 1877, 1968, 2091, 2095, 2114, 2126, 2130, 2132, 2135, 2147, 2150, 2154, 2158, 2163, 2166, 2167, 2168, 2176, 2192, 2193, 2195, 2204, 2205, 2207], "want": [1, 2, 8, 9, 10, 16, 25, 30, 36, 37, 38, 39, 48, 56, 58, 60, 62, 63, 64, 65, 68, 69, 71, 448, 486, 496, 499, 792, 804, 866, 1004, 1082, 1201, 1202, 1217, 1227, 1228, 1327, 1330, 1331, 1416, 1527, 1528, 1633, 1681, 1682, 1697, 1757, 1770, 1772, 1822, 1825, 1840, 1841, 1859, 1860, 1924, 2036, 2091, 2100, 2103, 2126, 2127, 2129, 2130, 2133, 2134, 2136, 2138, 2142, 2150, 2154, 2157, 2158, 2159, 2161, 2171, 2176, 2177, 2181, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2203, 2204], "forc": [1, 2, 16, 20, 22, 60, 458, 910, 1002, 1014, 1057, 1082, 1222, 1317, 1329, 1333, 1840, 1841, 1859, 1942, 1979, 2091, 2093, 2096, 2100, 2111, 2126, 2130, 2139, 2176, 2180, 2189, 2192, 2193], "particular": [1, 2, 4, 8, 16, 25, 32, 36, 41, 48, 51, 52, 56, 57, 58, 69, 71, 76, 80, 87, 486, 560, 681, 891, 892, 1119, 1213, 1221, 1314, 1409, 1516, 1580, 1877, 2045, 2093, 2095, 2103, 2108, 2117, 2130, 2133, 2135, 2136, 2140, 2142, 2145, 2150, 2154, 2157, 2171, 2173, 2180, 2189, 2192, 2194, 2195, 2196, 2204, 2205, 2206, 2207], "give": [1, 4, 5, 8, 10, 14, 16, 20, 25, 26, 32, 34, 35, 37, 50, 56, 60, 69, 949, 950, 1027, 1162, 1164, 1165, 1167, 1171, 1180, 1205, 1206, 1207, 1228, 1315, 1328, 1329, 1344, 1351, 1507, 1508, 1509, 1585, 1632, 1633, 1787, 1826, 1840, 1841, 1859, 1990, 2033, 2091, 2093, 2114, 2116, 2124, 2127, 2130, 2133, 2134, 2136, 2138, 2139, 2142, 2146, 2154, 2157, 2171, 2189, 2191, 2192, 2194, 2201, 2205, 2206], "explicit": [1, 9, 14, 30, 56, 58, 60, 64, 69, 1078, 1227, 1268, 1301, 1698, 1932, 2013, 2091, 2096, 2097, 2115, 2126, 2130, 2133, 2136, 2158, 2174, 2175, 2199], "control": [1, 2, 3, 6, 16, 21, 25, 26, 30, 31, 32, 33, 34, 37, 39, 41, 47, 50, 51, 57, 71, 77, 80, 86, 88, 766, 814, 888, 891, 906, 910, 925, 971, 980, 1019, 1131, 1132, 1133, 1134, 1135, 1222, 1272, 1273, 1326, 1327, 1328, 1330, 1345, 1351, 1353, 1356, 1358, 1361, 1363, 1367, 1373, 1376, 1378, 1384, 1404, 1443, 1484, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1566, 1574, 1575, 1632, 1738, 1770, 1880, 1936, 1937, 1950, 1965, 1968, 1973, 1990, 1994, 2015, 2021, 2022, 2023, 2024, 2093, 2100, 2102, 2122, 2127, 2129, 2130, 2132, 2142, 2144, 2145, 2147, 2149, 2150, 2154, 2156, 2157, 2159, 2161, 2168, 2171, 2184, 2185, 2189, 2190, 2191, 2192, 2195, 2204, 2208, 2209], "execut": [1, 2, 3, 4, 5, 6, 8, 16, 17, 21, 25, 30, 32, 35, 37, 41, 43, 45, 52, 56, 57, 58, 60, 65, 68, 69, 88, 487, 488, 930, 954, 955, 1002, 1004, 1009, 1056, 1057, 1122, 1202, 1216, 1226, 1314, 1315, 1317, 1330, 1331, 1386, 1433, 1434, 1516, 1580, 1586, 1624, 1625, 1626, 1627, 1628, 1763, 1770, 1877, 1938, 2093, 2095, 2097, 2106, 2108, 2126, 2128, 2129, 2135, 2136, 2137, 2139, 2140, 2142, 2144, 2146, 2147, 2148, 2150, 2151, 2154, 2159, 2161, 2166, 2167, 2171, 2180, 2185, 2189, 2191, 2192, 2193, 2194, 2196, 2197, 2198, 2200, 2203, 2205, 2208], "surround": [1, 69, 803, 2095, 2126, 2130], "ensur": [1, 2, 5, 6, 7, 8, 10, 16, 19, 21, 25, 30, 31, 32, 34, 35, 36, 37, 38, 41, 51, 52, 55, 56, 60, 68, 69, 87, 88, 481, 486, 684, 746, 837, 930, 931, 933, 935, 1013, 1057, 1202, 1226, 1237, 1314, 1488, 1493, 1573, 1580, 1583, 1624, 1686, 1711, 1712, 1713, 1738, 1770, 1779, 1780, 1877, 1939, 2091, 2093, 2095, 2103, 2107, 2114, 2126, 2127, 2130, 2133, 2134, 2138, 2144, 2146, 2147, 2157, 2158, 2161, 2162, 2166, 2167, 2173, 2184, 2189, 2194, 2195, 2205], "necessari": [1, 2, 4, 10, 16, 25, 30, 32, 34, 36, 37, 38, 41, 51, 52, 56, 58, 60, 67, 68, 87, 191, 208, 486, 560, 589, 930, 934, 935, 936, 1014, 1202, 1218, 1289, 1326, 1586, 1814, 1815, 2093, 2096, 2100, 2116, 2117, 2124, 2127, 2128, 2130, 2132, 2139, 2142, 2145, 2148, 2158, 2161, 2166, 2167, 2168, 2174, 2177, 2189, 2192, 2195, 2204, 2205, 2209], "becaus": [1, 2, 4, 5, 6, 8, 9, 16, 21, 25, 26, 30, 32, 35, 36, 37, 39, 44, 56, 57, 58, 60, 64, 65, 68, 69, 71, 79, 80, 486, 496, 940, 949, 950, 956, 1004, 1165, 1166, 1167, 1175, 1176, 1177, 1203, 1207, 1212, 1213, 1227, 1228, 1234, 1238, 1245, 1311, 1315, 1318, 1322, 1361, 1362, 1386, 1404, 1494, 1495, 1496, 1516, 1620, 1760, 1770, 1772, 1863, 1908, 1933, 1936, 1990, 2045, 2092, 2093, 2096, 2098, 2100, 2104, 2114, 2115, 2116, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2142, 2143, 2145, 2146, 2150, 2154, 2158, 2161, 2162, 2166, 2168, 2171, 2176, 2178, 2182, 2184, 2185, 2186, 2189, 2191, 2192, 2194, 2195, 2196, 2197, 2198, 2202, 2204, 2205, 2206, 2207], "wa": [1, 2, 3, 4, 8, 20, 26, 30, 36, 37, 49, 50, 51, 52, 56, 57, 60, 68, 69, 86, 335, 486, 496, 681, 796, 805, 870, 884, 956, 992, 1003, 1039, 1040, 1068, 1072, 1089, 1103, 1122, 1164, 1213, 1226, 1311, 1321, 1330, 1345, 1356, 1358, 1362, 1386, 1404, 1427, 1443, 1466, 1550, 1576, 1577, 1578, 1610, 1633, 1651, 1686, 1741, 1757, 1770, 1772, 1816, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1877, 1988, 1989, 2029, 2030, 2040, 2041, 2045, 2050, 2059, 2063, 2091, 2093, 2095, 2096, 2097, 2100, 2102, 2103, 2105, 2109, 2114, 2126, 2127, 2128, 2130, 2133, 2134, 2135, 2136, 2140, 2143, 2147, 2154, 2157, 2161, 2165, 2166, 2171, 2173, 2178, 2184, 2191, 2192, 2194, 2195, 2202, 2203, 2204, 2205, 2207], "f_float32": 1, "re": [1, 2, 5, 6, 8, 16, 25, 30, 34, 35, 37, 38, 40, 48, 51, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 488, 982, 1004, 1037, 1057, 1078, 1195, 1251, 1314, 1318, 1580, 1744, 1771, 1772, 1816, 1877, 1905, 1919, 1972, 2093, 2096, 2100, 2103, 2114, 2117, 2126, 2127, 2130, 2133, 2134, 2138, 2144, 2147, 2161, 2167, 2168, 2172, 2189, 2191, 2193, 2194, 2195, 2203, 2204, 2205, 2206], "again": [1, 20, 25, 30, 35, 41, 56, 63, 1228, 1466, 2100, 2127, 2133, 2134, 2142, 2189, 2192, 2194, 2198, 2204], "regardless": [1, 4, 25, 30, 50, 56, 60, 1021, 1232, 1314, 1318, 1324, 1580, 1763, 1877, 2029, 2126, 2130, 2147, 2166, 2178, 2192, 2195, 2204], "g_float16": 1, "state": [1, 2, 3, 6, 10, 25, 30, 32, 34, 35, 36, 37, 39, 41, 44, 45, 51, 55, 56, 57, 60, 67, 69, 87, 415, 681, 759, 771, 864, 1013, 1041, 1074, 1075, 1080, 1085, 1089, 1100, 1116, 1117, 1202, 1211, 1226, 1267, 1314, 1317, 1330, 1387, 1428, 1439, 1453, 1456, 1461, 1531, 1532, 1550, 1551, 1580, 1596, 1598, 1628, 1644, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1772, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1849, 1850, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1899, 1941, 1968, 2036, 2064, 2065, 2067, 2070, 2085, 2086, 2100, 2106, 2117, 2126, 2127, 2130, 2132, 2133, 2139, 2144, 2147, 2150, 2151, 2154, 2165, 2181, 2184, 2189, 2191, 2192, 2193, 2194, 2195, 2200, 2204], "thread": [1, 2, 4, 25, 30, 32, 41, 54, 60, 68, 86, 88, 945, 946, 947, 1037, 1039, 1078, 1148, 1265, 1266, 1427, 1443, 1516, 1825, 1938, 1939, 2035, 2050, 2093, 2105, 2109, 2125, 2126, 2130, 2136, 2140, 2144, 2166, 2168, 2173, 2180, 2193, 2195, 2208, 2209], "must": [1, 3, 4, 6, 7, 10, 14, 16, 19, 25, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 49, 52, 54, 56, 57, 58, 60, 63, 65, 68, 69, 71, 79, 80, 86, 87, 97, 139, 153, 154, 196, 233, 260, 313, 315, 321, 398, 400, 402, 486, 513, 544, 545, 566, 583, 584, 585, 587, 588, 617, 687, 690, 691, 692, 693, 697, 698, 699, 700, 701, 702, 708, 759, 768, 783, 784, 785, 806, 830, 832, 889, 890, 908, 914, 919, 920, 921, 922, 925, 930, 934, 935, 936, 939, 941, 942, 943, 949, 950, 970, 972, 974, 975, 976, 977, 978, 979, 982, 986, 989, 1004, 1016, 1019, 1027, 1039, 1051, 1052, 1053, 1056, 1086, 1087, 1089, 1132, 1134, 1135, 1136, 1138, 1141, 1142, 1144, 1165, 1166, 1167, 1172, 1174, 1175, 1176, 1177, 1178, 1185, 1186, 1195, 1196, 1198, 1201, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1211, 1212, 1213, 1227, 1232, 1237, 1238, 1239, 1255, 1256, 1268, 1277, 1278, 1281, 1291, 1311, 1314, 1325, 1330, 1337, 1340, 1369, 1370, 1371, 1372, 1378, 1380, 1381, 1384, 1385, 1387, 1401, 1405, 1407, 1408, 1409, 1414, 1415, 1422, 1443, 1466, 1471, 1472, 1475, 1476, 1480, 1493, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1522, 1523, 1526, 1527, 1528, 1533, 1534, 1540, 1573, 1580, 1583, 1584, 1586, 1587, 1612, 1618, 1633, 1659, 1668, 1670, 1678, 1697, 1711, 1712, 1713, 1731, 1738, 1770, 1781, 1783, 1804, 1813, 1814, 1820, 1822, 1827, 1843, 1870, 1872, 1877, 1881, 1882, 1885, 1886, 1889, 1897, 1898, 1919, 1928, 1931, 1939, 1955, 1966, 1970, 1971, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 1995, 2008, 2012, 2013, 2017, 2022, 2024, 2028, 2031, 2033, 2036, 2042, 2043, 2045, 2046, 2048, 2050, 2093, 2094, 2095, 2096, 2100, 2103, 2114, 2115, 2116, 2117, 2124, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2136, 2139, 2144, 2147, 2148, 2150, 2154, 2157, 2158, 2161, 2165, 2166, 2167, 2168, 2171, 2172, 2173, 2176, 2178, 2189, 2190, 2191, 2195, 2196, 2203, 2204, 2205, 2206, 2209], "invok": [1, 3, 9, 17, 20, 21, 25, 30, 49, 52, 68, 69, 938, 940, 1086, 1087, 1314, 1317, 1324, 1516, 1580, 1762, 1764, 1767, 1768, 1824, 1865, 1872, 1877, 2093, 2096, 2097, 2106, 2117, 2126, 2129, 2130, 2132, 2133, 2134, 2140, 2142, 2158, 2166, 2167, 2185, 2189, 2194, 2195, 2196], "affect": [1, 2, 3, 8, 10, 20, 21, 24, 36, 40, 56, 60, 221, 222, 796, 895, 945, 946, 947, 1040, 1148, 1195, 1196, 1229, 1237, 1314, 1433, 1434, 1550, 1580, 1596, 1633, 1757, 1772, 1779, 1780, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1877, 1932, 1935, 1936, 2126, 2127, 2130, 2136, 2138, 2142, 2145, 2146, 2157, 2173, 2184, 2200, 2202, 2204], "dataparallel": [1, 30, 1753, 1770, 1816, 2127, 2135, 2144, 2166], "parallel": [1, 15, 16, 25, 26, 30, 31, 32, 34, 35, 37, 51, 52, 60, 1265, 1266, 1317, 1516, 1586, 1620, 1686, 1738, 1770, 1938, 1939, 2096, 2125, 2126, 2127, 2129, 2144, 2148, 2160, 2166, 2168, 2179, 2188, 2195, 2208], "distributeddataparallel": [1, 25, 26, 30, 31, 32, 35, 36, 52, 60, 681, 1516, 1620, 2144, 2166, 2195, 2204], "than": [1, 4, 5, 6, 7, 9, 10, 13, 16, 19, 21, 25, 26, 30, 31, 32, 34, 37, 39, 40, 41, 44, 48, 51, 52, 54, 56, 58, 60, 65, 69, 71, 72, 80, 150, 254, 486, 499, 545, 617, 681, 790, 796, 923, 939, 940, 957, 962, 973, 984, 991, 992, 996, 997, 1010, 1015, 1053, 1097, 1101, 1115, 1132, 1133, 1184, 1185, 1186, 1188, 1192, 1198, 1209, 1241, 1257, 1271, 1275, 1289, 1299, 1311, 1312, 1315, 1326, 1335, 1336, 1339, 1344, 1345, 1351, 1355, 1360, 1368, 1369, 1371, 1372, 1375, 1380, 1386, 1390, 1403, 1406, 1412, 1415, 1417, 1420, 1438, 1466, 1476, 1492, 1493, 1507, 1508, 1509, 1516, 1522, 1523, 1540, 1550, 1572, 1586, 1594, 1603, 1612, 1618, 1628, 1629, 1630, 1651, 1661, 1662, 1663, 1677, 1678, 1686, 1697, 1724, 1738, 1754, 1756, 1757, 1760, 1770, 1779, 1780, 1787, 1788, 1790, 1791, 1816, 1821, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1872, 1874, 1890, 1891, 1912, 1913, 1936, 1940, 1975, 1976, 1977, 1978, 1980, 1981, 2005, 2014, 2022, 2024, 2033, 2076, 2091, 2093, 2095, 2096, 2098, 2104, 2116, 2117, 2118, 2124, 2127, 2128, 2130, 2133, 2134, 2135, 2136, 2138, 2142, 2144, 2145, 2146, 2147, 2150, 2154, 2157, 2158, 2159, 2161, 2162, 2166, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2189, 2190, 2192, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2202, 2204, 2205, 2207, 2209], "one": [1, 2, 3, 4, 5, 6, 7, 8, 9, 13, 14, 16, 17, 19, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 48, 51, 54, 55, 56, 57, 58, 60, 64, 65, 66, 68, 69, 71, 76, 79, 80, 88, 150, 221, 233, 254, 352, 402, 486, 513, 520, 545, 560, 708, 759, 768, 806, 884, 885, 886, 910, 916, 922, 923, 925, 928, 930, 931, 935, 936, 940, 945, 946, 956, 958, 973, 984, 986, 996, 1000, 1004, 1019, 1035, 1040, 1049, 1051, 1056, 1087, 1112, 1122, 1133, 1144, 1148, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1174, 1175, 1176, 1177, 1178, 1180, 1183, 1187, 1190, 1191, 1192, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1228, 1268, 1277, 1278, 1293, 1296, 1299, 1318, 1324, 1328, 1334, 1335, 1345, 1346, 1356, 1359, 1360, 1362, 1367, 1371, 1373, 1375, 1378, 1384, 1385, 1401, 1409, 1413, 1418, 1466, 1472, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1499, 1507, 1510, 1511, 1512, 1523, 1527, 1528, 1533, 1542, 1543, 1544, 1546, 1547, 1548, 1549, 1559, 1560, 1561, 1571, 1580, 1584, 1586, 1620, 1628, 1633, 1651, 1661, 1664, 1665, 1666, 1681, 1682, 1683, 1688, 1724, 1738, 1756, 1760, 1770, 1772, 1788, 1789, 1790, 1794, 1804, 1814, 1824, 1825, 1826, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1848, 1849, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1868, 1870, 1871, 1872, 1894, 1895, 1912, 1928, 1936, 1940, 1943, 1985, 1994, 2012, 2017, 2018, 2020, 2028, 2029, 2031, 2032, 2033, 2036, 2045, 2082, 2092, 2093, 2096, 2100, 2102, 2106, 2109, 2114, 2115, 2116, 2117, 2122, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2140, 2142, 2144, 2146, 2147, 2148, 2154, 2157, 2158, 2159, 2161, 2162, 2166, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2197, 2198, 2201, 2203, 2204, 2205, 2207], "gpu": [1, 2, 3, 4, 5, 8, 16, 19, 21, 22, 23, 25, 26, 32, 37, 41, 52, 54, 60, 68, 196, 209, 289, 332, 603, 771, 1002, 1041, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1063, 1065, 1066, 1074, 1081, 1082, 1088, 1090, 1091, 1092, 1094, 1095, 1097, 1099, 1100, 1101, 1102, 1108, 1109, 1110, 1111, 1112, 1113, 1116, 1121, 1122, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1192, 1314, 1324, 1361, 1386, 1415, 1423, 1425, 1426, 1433, 1434, 1436, 1484, 1516, 1531, 1550, 1580, 1596, 1597, 1620, 1753, 1770, 1813, 1877, 1994, 2064, 2068, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2082, 2083, 2085, 2092, 2093, 2106, 2110, 2117, 2125, 2130, 2133, 2136, 2139, 2142, 2143, 2145, 2146, 2148, 2151, 2161, 2166, 2171, 2173, 2174, 2177, 2180, 2183, 2185, 2186, 2189, 2193, 2194, 2197, 2201, 2202, 2205, 2207, 2212], "per": [1, 13, 16, 19, 21, 22, 25, 26, 30, 31, 32, 34, 35, 36, 38, 40, 41, 44, 50, 52, 54, 60, 61, 66, 472, 473, 474, 681, 745, 746, 816, 823, 837, 841, 846, 860, 875, 883, 922, 935, 936, 938, 940, 958, 1002, 1045, 1127, 1158, 1203, 1213, 1387, 1445, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1513, 1515, 1516, 1523, 1534, 1539, 1542, 1543, 1544, 1545, 1546, 1552, 1571, 1572, 1580, 1583, 1584, 1585, 1586, 1587, 1594, 1595, 1612, 1613, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1658, 1659, 1669, 1698, 1722, 1730, 1769, 1770, 1789, 1824, 1828, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1882, 1894, 1940, 1942, 1995, 2014, 2018, 2036, 2045, 2052, 2100, 2109, 2116, 2118, 2129, 2130, 2132, 2134, 2136, 2139, 2140, 2147, 2161, 2162, 2164, 2167, 2171, 2176, 2184, 2189, 2191, 2192, 2195, 2204, 2205, 2207, 2209], "process": [1, 2, 4, 13, 16, 21, 22, 26, 30, 31, 32, 34, 35, 36, 37, 39, 41, 43, 44, 45, 51, 52, 53, 54, 55, 56, 60, 69, 1014, 1039, 1073, 1082, 1088, 1115, 1196, 1226, 1240, 1241, 1314, 1325, 1387, 1425, 1438, 1492, 1493, 1513, 1515, 1522, 1523, 1539, 1546, 1571, 1572, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1620, 1624, 1626, 1628, 1629, 1658, 1659, 1669, 1698, 1722, 1730, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1869, 1875, 1877, 1906, 1942, 1956, 2036, 2091, 2093, 2100, 2109, 2114, 2115, 2116, 2117, 2127, 2129, 2130, 2132, 2133, 2136, 2140, 2142, 2144, 2146, 2147, 2148, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2164, 2166, 2168, 2171, 2173, 2181, 2185, 2188, 2191, 2192, 2195, 2202, 2204, 2205, 2208, 2209], "work": [1, 2, 3, 4, 6, 8, 9, 10, 13, 16, 17, 19, 21, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 51, 52, 54, 55, 56, 60, 61, 65, 69, 71, 79, 80, 86, 88, 119, 150, 352, 445, 446, 447, 448, 449, 486, 587, 588, 840, 891, 892, 923, 930, 944, 1002, 1004, 1037, 1039, 1040, 1078, 1089, 1090, 1112, 1145, 1147, 1164, 1184, 1185, 1186, 1196, 1202, 1232, 1239, 1314, 1318, 1326, 1327, 1350, 1351, 1378, 1379, 1387, 1427, 1436, 1443, 1516, 1577, 1580, 1597, 1614, 1725, 1738, 1744, 1770, 1834, 1872, 1877, 1901, 1905, 1907, 1938, 1941, 1976, 1977, 1978, 1979, 1980, 1981, 2002, 2008, 2011, 2036, 2038, 2050, 2071, 2082, 2091, 2093, 2096, 2097, 2100, 2110, 2114, 2115, 2116, 2117, 2120, 2124, 2127, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2139, 2141, 2142, 2144, 2147, 2148, 2154, 2158, 2161, 2164, 2165, 2166, 2167, 2177, 2180, 2185, 2190, 2191, 2192, 2193, 2196, 2197, 2200, 2201, 2204, 2205, 2206, 2207], "hpu": [1, 2173, 2180], "option": [1, 2, 3, 4, 6, 16, 19, 21, 25, 30, 32, 34, 35, 37, 38, 39, 41, 42, 45, 49, 50, 51, 54, 55, 56, 60, 69, 71, 78, 86, 87, 88, 150, 155, 170, 172, 175, 178, 179, 180, 195, 206, 209, 240, 267, 297, 325, 331, 393, 445, 446, 447, 448, 449, 487, 499, 500, 513, 520, 525, 537, 560, 580, 581, 583, 584, 585, 587, 588, 623, 681, 682, 683, 687, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 704, 705, 706, 707, 708, 709, 710, 746, 769, 790, 791, 796, 805, 807, 813, 814, 833, 884, 889, 892, 895, 896, 897, 898, 899, 900, 901, 902, 906, 908, 909, 910, 911, 912, 913, 914, 915, 922, 923, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 953, 954, 955, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 982, 986, 989, 991, 992, 993, 994, 995, 997, 999, 1000, 1001, 1002, 1008, 1012, 1015, 1021, 1022, 1024, 1025, 1026, 1027, 1031, 1035, 1036, 1037, 1039, 1040, 1041, 1042, 1046, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1060, 1061, 1064, 1069, 1070, 1071, 1073, 1074, 1078, 1086, 1087, 1088, 1089, 1092, 1094, 1095, 1097, 1099, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1115, 1116, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1128, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1139, 1141, 1143, 1144, 1145, 1146, 1147, 1149, 1154, 1157, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1187, 1188, 1189, 1190, 1191, 1192, 1194, 1196, 1198, 1199, 1200, 1201, 1202, 1205, 1206, 1207, 1214, 1226, 1228, 1237, 1252, 1255, 1256, 1257, 1258, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1279, 1280, 1281, 1286, 1287, 1288, 1289, 1291, 1303, 1305, 1308, 1309, 1311, 1312, 1314, 1315, 1318, 1321, 1328, 1330, 1331, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1427, 1428, 1433, 1434, 1439, 1441, 1443, 1447, 1448, 1452, 1453, 1457, 1458, 1461, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1476, 1477, 1478, 1480, 1482, 1483, 1484, 1486, 1487, 1488, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1498, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1526, 1527, 1528, 1529, 1533, 1536, 1537, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1566, 1571, 1572, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1589, 1590, 1591, 1594, 1595, 1599, 1600, 1601, 1608, 1612, 1613, 1620, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1632, 1633, 1634, 1635, 1651, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1677, 1678, 1681, 1682, 1683, 1686, 1688, 1695, 1697, 1698, 1705, 1711, 1712, 1713, 1718, 1722, 1723, 1725, 1730, 1738, 1744, 1745, 1757, 1763, 1769, 1770, 1771, 1772, 1781, 1782, 1784, 1787, 1788, 1789, 1792, 1793, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1819, 1821, 1822, 1824, 1826, 1827, 1828, 1831, 1832, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1848, 1849, 1853, 1854, 1856, 1857, 1858, 1859, 1860, 1861, 1864, 1877, 1880, 1881, 1882, 1885, 1889, 1890, 1892, 1893, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1912, 1913, 1914, 1921, 1923, 1928, 1940, 1943, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1960, 1961, 1965, 1966, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1993, 1994, 1995, 2008, 2009, 2010, 2011, 2012, 2015, 2017, 2020, 2021, 2022, 2023, 2024, 2026, 2029, 2030, 2033, 2039, 2040, 2041, 2042, 2047, 2048, 2050, 2054, 2060, 2061, 2064, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2085, 2088, 2089, 2090, 2091, 2093, 2094, 2096, 2098, 2100, 2102, 2106, 2107, 2109, 2111, 2114, 2117, 2122, 2124, 2130, 2133, 2134, 2135, 2136, 2140, 2141, 2142, 2146, 2147, 2150, 2154, 2156, 2158, 2159, 2161, 2166, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2182, 2183, 2184, 2185, 2186, 2195, 2201, 2203, 2205, 2207], "whether": [1, 2, 3, 6, 8, 16, 21, 22, 25, 26, 30, 31, 32, 34, 36, 37, 38, 39, 41, 50, 51, 58, 60, 67, 69, 319, 321, 471, 517, 617, 681, 704, 706, 707, 710, 814, 843, 904, 905, 910, 919, 930, 931, 934, 935, 936, 938, 940, 945, 946, 947, 949, 950, 956, 971, 980, 993, 994, 995, 1001, 1003, 1005, 1008, 1009, 1010, 1015, 1085, 1102, 1196, 1201, 1213, 1221, 1224, 1272, 1273, 1311, 1314, 1322, 1323, 1331, 1336, 1344, 1345, 1351, 1353, 1356, 1357, 1358, 1359, 1361, 1362, 1363, 1364, 1369, 1371, 1372, 1375, 1376, 1377, 1378, 1386, 1402, 1404, 1412, 1414, 1415, 1417, 1420, 1456, 1466, 1471, 1472, 1473, 1474, 1499, 1539, 1545, 1580, 1589, 1594, 1630, 1644, 1648, 1649, 1650, 1670, 1698, 1730, 1763, 1770, 1771, 1787, 1790, 1793, 1805, 1819, 1822, 1827, 1833, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1865, 1877, 1880, 1890, 1893, 1937, 1974, 1988, 1989, 1990, 1993, 1994, 2015, 2020, 2029, 2030, 2033, 2034, 2040, 2041, 2045, 2070, 2091, 2096, 2100, 2102, 2103, 2107, 2117, 2122, 2126, 2130, 2133, 2136, 2139, 2147, 2150, 2154, 2156, 2159, 2161, 2166, 2171, 2173, 2175, 2176, 2182, 2189, 2192, 2193, 2195, 2196, 2202, 2205, 2209], "torch_dtyp": 1, "It": [1, 2, 3, 4, 5, 6, 8, 9, 14, 19, 20, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 48, 49, 50, 51, 52, 54, 56, 57, 58, 60, 62, 64, 65, 66, 68, 69, 71, 88, 150, 196, 233, 415, 473, 474, 513, 515, 517, 544, 557, 693, 919, 920, 921, 922, 923, 930, 931, 935, 936, 946, 947, 956, 965, 1002, 1008, 1010, 1013, 1015, 1019, 1020, 1021, 1056, 1062, 1069, 1070, 1071, 1090, 1091, 1112, 1113, 1120, 1167, 1197, 1202, 1205, 1213, 1222, 1228, 1230, 1237, 1241, 1255, 1276, 1311, 1314, 1315, 1320, 1321, 1325, 1347, 1351, 1355, 1358, 1360, 1362, 1363, 1368, 1372, 1373, 1375, 1376, 1378, 1380, 1383, 1384, 1386, 1387, 1395, 1449, 1484, 1493, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1516, 1526, 1574, 1575, 1576, 1577, 1578, 1580, 1587, 1609, 1612, 1632, 1634, 1688, 1698, 1738, 1744, 1762, 1763, 1764, 1767, 1768, 1770, 1788, 1790, 1793, 1813, 1814, 1816, 1825, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1880, 1899, 1912, 1928, 1943, 1950, 1972, 2028, 2045, 2055, 2060, 2061, 2071, 2072, 2082, 2083, 2088, 2091, 2095, 2096, 2100, 2108, 2109, 2114, 2116, 2117, 2122, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2142, 2143, 2144, 2145, 2146, 2148, 2149, 2150, 2154, 2157, 2158, 2161, 2166, 2167, 2168, 2170, 2171, 2172, 2173, 2175, 2180, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2198, 2203, 2204, 2205, 2207, 2209], "given": [1, 2, 3, 4, 8, 10, 16, 19, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 49, 51, 54, 56, 58, 60, 66, 68, 69, 86, 88, 150, 219, 233, 313, 315, 317, 321, 326, 377, 398, 402, 472, 473, 474, 475, 476, 478, 513, 515, 517, 584, 585, 604, 607, 681, 687, 690, 691, 692, 693, 704, 706, 707, 709, 710, 746, 771, 790, 796, 805, 806, 807, 808, 810, 813, 814, 815, 817, 834, 839, 843, 865, 869, 884, 888, 895, 906, 919, 921, 923, 928, 930, 931, 933, 935, 936, 938, 940, 941, 942, 943, 950, 956, 958, 968, 969, 972, 973, 976, 984, 988, 989, 994, 995, 996, 1001, 1002, 1004, 1021, 1023, 1026, 1027, 1028, 1029, 1031, 1036, 1039, 1040, 1044, 1045, 1046, 1050, 1060, 1061, 1064, 1065, 1069, 1070, 1071, 1088, 1092, 1094, 1095, 1097, 1099, 1101, 1102, 1103, 1105, 1108, 1109, 1110, 1111, 1120, 1121, 1122, 1129, 1131, 1136, 1144, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1184, 1201, 1211, 1212, 1216, 1224, 1228, 1230, 1231, 1232, 1233, 1239, 1263, 1281, 1311, 1314, 1322, 1330, 1331, 1336, 1340, 1350, 1352, 1353, 1362, 1364, 1370, 1378, 1387, 1394, 1396, 1397, 1398, 1399, 1402, 1412, 1414, 1416, 1417, 1420, 1443, 1444, 1445, 1447, 1448, 1452, 1457, 1458, 1474, 1484, 1492, 1493, 1499, 1507, 1508, 1509, 1511, 1512, 1513, 1515, 1516, 1522, 1523, 1527, 1528, 1531, 1539, 1550, 1572, 1576, 1577, 1578, 1580, 1582, 1584, 1585, 1587, 1589, 1591, 1596, 1609, 1615, 1629, 1630, 1633, 1634, 1635, 1651, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1677, 1678, 1681, 1682, 1686, 1697, 1722, 1738, 1753, 1754, 1757, 1758, 1759, 1763, 1764, 1778, 1788, 1789, 1813, 1820, 1821, 1824, 1827, 1828, 1834, 1868, 1871, 1873, 1875, 1877, 1880, 1885, 1890, 1893, 1894, 1895, 1908, 1914, 1919, 1930, 1931, 1936, 1961, 1965, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1985, 1987, 1990, 1993, 1995, 2007, 2008, 2013, 2015, 2017, 2027, 2029, 2031, 2033, 2037, 2050, 2051, 2052, 2054, 2057, 2060, 2061, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2088, 2091, 2092, 2093, 2096, 2100, 2102, 2103, 2107, 2114, 2117, 2118, 2124, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2140, 2142, 2146, 2147, 2150, 2154, 2157, 2159, 2161, 2166, 2167, 2170, 2171, 2172, 2173, 2176, 2178, 2180, 2182, 2185, 2188, 2192, 2194, 2195, 2203, 2204, 2205, 2206], "get_autocast_dtyp": [1, 2094, 2155], "weight": [1, 25, 30, 32, 36, 37, 38, 39, 56, 57, 66, 69, 71, 156, 301, 361, 362, 496, 723, 724, 725, 726, 727, 728, 729, 730, 731, 741, 742, 743, 744, 745, 746, 749, 750, 751, 752, 753, 754, 756, 757, 760, 762, 763, 764, 765, 767, 771, 772, 774, 775, 776, 783, 784, 785, 792, 805, 806, 807, 823, 824, 860, 862, 871, 875, 879, 880, 881, 882, 883, 888, 889, 891, 892, 973, 1027, 1201, 1203, 1211, 1213, 1276, 1277, 1314, 1318, 1324, 1326, 1331, 1340, 1466, 1492, 1493, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1522, 1523, 1531, 1532, 1534, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1580, 1584, 1585, 1586, 1587, 1588, 1595, 1596, 1598, 1610, 1624, 1656, 1657, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1677, 1678, 1687, 1695, 1696, 1700, 1703, 1718, 1719, 1721, 1722, 1731, 1735, 1738, 1741, 1760, 1769, 1770, 1779, 1780, 1781, 1782, 1784, 1787, 1788, 1789, 1791, 1793, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1820, 1821, 1822, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1878, 1896, 2033, 2045, 2091, 2094, 2095, 2096, 2100, 2106, 2107, 2116, 2124, 2133, 2135, 2136, 2137, 2142, 2147, 2150, 2154, 2161, 2162, 2163, 2164, 2171, 2176, 2181, 2182, 2195, 2199, 2204], "cach": [1, 3, 4, 6, 22, 39, 69, 486, 1002, 1013, 1014, 1041, 1066, 1067, 1086, 1089, 1094, 1097, 1099, 1101, 1110, 1115, 1229, 1230, 1423, 1425, 1426, 1451, 1772, 1793, 1824, 2058, 2074, 2076, 2077, 2114, 2117, 2135, 2189, 2192, 2193, 2195, 2198, 2202, 2207], "insid": [1, 2, 8, 25, 34, 37, 57, 60, 65, 68, 69, 935, 936, 1004, 1014, 1047, 1089, 1203, 1207, 1212, 1217, 1228, 1326, 1770, 2093, 2095, 2096, 2100, 2106, 2108, 2126, 2130, 2133, 2134, 2140, 2150, 2154, 2171, 2181, 2192, 2194, 2205, 2209], "custom_fwd": [1, 2126], "fwd": [1, 2198, 2202], "cast_input": [1, 2126], "helper": [1, 4, 6, 30, 36, 42, 64, 69, 2091, 2095, 2130, 2132, 2154, 2158, 2166, 2203, 2206], "subclass": [1, 2, 16, 25, 32, 34, 36, 37, 39, 44, 65, 69, 139, 537, 919, 920, 921, 935, 936, 1233, 1312, 1315, 1325, 1580, 1771, 1772, 1795, 1800, 1820, 2093, 2096, 2097, 2100, 2103, 2117, 2120, 2126, 2142, 2147, 2166, 2170, 2171, 2173, 2192, 2193, 2195, 2204, 2206], "page": [1, 7, 8, 10, 25, 31, 52, 55, 1004, 1387, 1624, 1626, 1628, 2100, 2125, 2130, 2132, 2133, 2142, 2155, 2166, 2201], "incom": [1, 30, 54, 792, 837, 839, 840, 841, 846, 1497, 1567, 1657, 1703, 2114, 2127], "non": [1, 2, 3, 4, 6, 16, 22, 24, 26, 30, 31, 32, 34, 36, 37, 39, 41, 44, 51, 54, 55, 57, 60, 68, 71, 82, 85, 87, 150, 335, 486, 488, 504, 513, 517, 545, 709, 745, 750, 751, 752, 753, 754, 756, 757, 767, 771, 775, 776, 783, 784, 785, 866, 895, 907, 919, 921, 923, 930, 932, 934, 935, 936, 949, 950, 965, 973, 986, 989, 1002, 1020, 1021, 1026, 1101, 1190, 1191, 1198, 1202, 1207, 1213, 1228, 1232, 1235, 1242, 1291, 1314, 1317, 1327, 1330, 1331, 1350, 1351, 1358, 1362, 1363, 1375, 1376, 1378, 1387, 1397, 1404, 1409, 1414, 1466, 1471, 1472, 1476, 1489, 1490, 1491, 1508, 1509, 1511, 1512, 1515, 1525, 1531, 1548, 1549, 1550, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1583, 1585, 1587, 1596, 1598, 1612, 1669, 1688, 1717, 1722, 1738, 1770, 1826, 1859, 1860, 1877, 1885, 1928, 1929, 1943, 1948, 1955, 1970, 1971, 1976, 1977, 1978, 1979, 1980, 1981, 2013, 2029, 2031, 2045, 2078, 2091, 2093, 2095, 2096, 2098, 2100, 2114, 2117, 2122, 2124, 2128, 2133, 2134, 2135, 2136, 2142, 2146, 2150, 2154, 2157, 2159, 2165, 2166, 2168, 2171, 2172, 2173, 2174, 2175, 2176, 2178, 2185, 2189, 2191, 2192, 2194, 2195, 2196, 2202, 2203, 2204, 2206, 2209], "intern": [1, 4, 9, 10, 16, 21, 25, 26, 30, 32, 34, 37, 39, 41, 48, 56, 60, 65, 69, 930, 1037, 1041, 1078, 1100, 1202, 1226, 1314, 1351, 1353, 1369, 1372, 1395, 1494, 1495, 1496, 1533, 1620, 1661, 1662, 1663, 1686, 1790, 1833, 1936, 1979, 2033, 2097, 2126, 2127, 2129, 2130, 2136, 2138, 2141, 2145, 2146, 2150, 2167, 2168, 2173, 2175, 2183, 2192, 2195, 2204, 2205], "outsid": [1, 6, 10, 25, 44, 56, 57, 60, 65, 695, 808, 915, 1201, 1203, 1207, 1212, 1315, 1686, 1770, 1862, 1863, 1869, 1870, 1876, 2095, 2096, 2124, 2127, 2130, 2134, 2135, 2178, 2189, 2195, 2200, 2204], "ha": [1, 2, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 21, 23, 25, 26, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 44, 48, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 86, 88, 150, 196, 209, 255, 260, 335, 445, 446, 447, 448, 449, 473, 474, 486, 488, 496, 498, 544, 580, 581, 603, 604, 618, 623, 681, 700, 704, 706, 707, 708, 710, 746, 771, 790, 792, 796, 798, 804, 811, 866, 867, 869, 877, 888, 894, 904, 905, 907, 919, 922, 923, 928, 930, 931, 935, 936, 940, 949, 950, 954, 958, 969, 972, 990, 993, 994, 995, 1002, 1007, 1019, 1020, 1021, 1022, 1036, 1039, 1040, 1049, 1082, 1085, 1086, 1132, 1134, 1148, 1180, 1192, 1201, 1202, 1205, 1206, 1209, 1213, 1251, 1268, 1277, 1278, 1289, 1311, 1314, 1318, 1322, 1325, 1326, 1327, 1330, 1335, 1336, 1344, 1345, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1366, 1368, 1369, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1381, 1382, 1386, 1395, 1402, 1404, 1409, 1412, 1414, 1415, 1416, 1417, 1419, 1420, 1427, 1443, 1456, 1471, 1472, 1473, 1474, 1492, 1493, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1516, 1517, 1523, 1526, 1527, 1528, 1531, 1534, 1539, 1542, 1543, 1544, 1550, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1584, 1585, 1586, 1587, 1588, 1595, 1596, 1612, 1614, 1620, 1628, 1632, 1633, 1651, 1661, 1662, 1663, 1669, 1678, 1681, 1682, 1686, 1697, 1722, 1724, 1725, 1727, 1731, 1738, 1744, 1757, 1759, 1760, 1763, 1764, 1769, 1770, 1787, 1790, 1792, 1795, 1799, 1801, 1804, 1813, 1814, 1821, 1822, 1826, 1828, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1856, 1857, 1858, 1859, 1860, 1863, 1864, 1865, 1868, 1872, 1874, 1877, 1880, 1890, 1892, 1893, 1894, 1895, 1912, 1914, 1924, 1936, 1957, 1971, 1972, 1973, 1979, 1985, 1987, 1988, 1989, 1990, 1993, 1994, 2008, 2014, 2020, 2031, 2040, 2041, 2045, 2050, 2070, 2093, 2095, 2096, 2100, 2102, 2103, 2109, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2139, 2140, 2142, 2144, 2145, 2147, 2148, 2149, 2151, 2154, 2157, 2158, 2159, 2161, 2162, 2165, 2166, 2167, 2168, 2171, 2173, 2174, 2176, 2177, 2178, 2180, 2183, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2198, 2200, 2204, 2205], "effect": [1, 4, 6, 8, 16, 25, 26, 30, 36, 39, 54, 56, 57, 60, 65, 69, 71, 74, 196, 209, 603, 623, 746, 790, 796, 1078, 1127, 1213, 1314, 1357, 1358, 1359, 1360, 1416, 1484, 1499, 1510, 1511, 1512, 1517, 1518, 1519, 1520, 1524, 1580, 1586, 1633, 1697, 1725, 1757, 1770, 1771, 1772, 1800, 1857, 1865, 1877, 1968, 1973, 1994, 2018, 2034, 2045, 2091, 2093, 2100, 2106, 2124, 2126, 2127, 2130, 2133, 2136, 2161, 2164, 2173, 2174, 2176, 2180, 2184, 2189, 2192], "custom_bwd": [1, 2126], "bwd": [1, 2202], "small": [1, 4, 8, 10, 25, 26, 30, 39, 51, 895, 949, 950, 1002, 1052, 1055, 1101, 1377, 1378, 1390, 1392, 1484, 1514, 1589, 1594, 1609, 1629, 1633, 1668, 1723, 1730, 1770, 1838, 1862, 1869, 1880, 1994, 1995, 2078, 2093, 2095, 2096, 2104, 2130, 2133, 2135, 2142, 2145, 2147, 2154, 2158, 2161, 2162, 2171, 2172, 2178, 2189, 2191, 2192, 2194, 2195, 2196, 2198, 2202, 2204, 2205, 2207], "magnitud": [1, 1022, 1789, 1824, 1943, 2124, 2126, 2130], "represent": [1, 4, 16, 25, 30, 32, 34, 36, 37, 49, 56, 57, 69, 481, 769, 816, 851, 895, 1040, 1160, 1161, 1163, 1187, 1258, 1314, 1354, 1357, 1359, 1362, 1470, 1580, 1586, 1877, 1880, 2093, 2096, 2104, 2117, 2122, 2133, 2141, 2145, 2150, 2154, 2158, 2159, 2161, 2171, 2178, 2180, 2191, 2195, 2204, 2205, 2210], "These": [1, 2, 3, 4, 9, 16, 17, 19, 25, 30, 31, 37, 39, 56, 58, 61, 63, 66, 69, 70, 486, 807, 910, 1014, 1027, 1144, 1209, 1311, 1314, 1357, 1422, 1484, 1760, 1788, 2092, 2093, 2094, 2095, 2096, 2100, 2104, 2109, 2115, 2116, 2117, 2118, 2121, 2122, 2126, 2127, 2130, 2132, 2133, 2142, 2145, 2147, 2154, 2158, 2164, 2166, 2167, 2173, 2174, 2180, 2185, 2189, 2191, 2192, 2193, 2195, 2200, 2204, 2205, 2206, 2208], "flush": [1, 2, 21, 32, 56, 1101, 1325, 1924, 1937, 2145, 2176], "zero": [1, 2, 3, 26, 30, 31, 35, 36, 37, 39, 54, 57, 58, 60, 65, 69, 71, 78, 80, 81, 82, 150, 258, 260, 315, 486, 513, 515, 544, 545, 584, 585, 587, 588, 624, 680, 702, 709, 723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 749, 750, 751, 752, 753, 754, 755, 760, 761, 762, 763, 764, 765, 766, 767, 770, 771, 775, 779, 780, 783, 784, 785, 786, 788, 791, 792, 808, 814, 837, 839, 840, 841, 846, 857, 907, 916, 917, 918, 923, 930, 932, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 972, 973, 993, 994, 995, 1000, 1022, 1026, 1089, 1101, 1106, 1107, 1135, 1139, 1157, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1183, 1192, 1198, 1201, 1209, 1228, 1274, 1275, 1278, 1299, 1311, 1314, 1326, 1344, 1345, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1382, 1387, 1395, 1396, 1397, 1398, 1399, 1404, 1405, 1466, 1470, 1474, 1488, 1489, 1490, 1491, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1514, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1531, 1532, 1534, 1547, 1548, 1549, 1550, 1551, 1552, 1556, 1557, 1558, 1559, 1560, 1561, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1586, 1589, 1592, 1593, 1594, 1596, 1598, 1618, 1632, 1633, 1636, 1637, 1638, 1653, 1654, 1655, 1664, 1665, 1666, 1668, 1670, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1686, 1707, 1708, 1709, 1723, 1724, 1725, 1738, 1798, 1799, 1800, 1801, 1815, 1822, 1826, 1830, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1880, 1892, 1894, 1895, 1896, 1905, 1912, 1921, 1931, 1948, 1957, 1961, 1971, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1994, 2011, 2012, 2014, 2020, 2090, 2093, 2094, 2096, 2098, 2100, 2109, 2114, 2115, 2116, 2122, 2124, 2127, 2130, 2133, 2142, 2145, 2148, 2154, 2155, 2158, 2159, 2161, 2164, 2166, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2192, 2194, 2197], "underflow": [1, 1545, 2126], "updat": [1, 10, 13, 25, 26, 32, 35, 41, 51, 56, 60, 63, 64, 69, 488, 513, 515, 771, 814, 815, 843, 926, 927, 956, 969, 1201, 1210, 1314, 1351, 1494, 1495, 1496, 1516, 1522, 1523, 1531, 1542, 1543, 1544, 1580, 1581, 1590, 1620, 1677, 1678, 1779, 1780, 1788, 1793, 1822, 1836, 1838, 1843, 1854, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876, 1877, 2091, 2093, 2106, 2126, 2127, 2130, 2132, 2133, 2137, 2142, 2144, 2147, 2148, 2154, 2155, 2157, 2161, 2166, 2167, 2168, 2176, 2189, 2203, 2205], "lost": [1, 41, 52, 55, 1516, 1576, 1577, 1578, 2195, 2204], "To": [1, 2, 3, 4, 5, 6, 7, 10, 16, 17, 21, 22, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 49, 50, 52, 54, 56, 57, 58, 60, 65, 69, 335, 499, 557, 745, 925, 944, 958, 968, 999, 1002, 1057, 1090, 1112, 1132, 1134, 1144, 1172, 1174, 1178, 1189, 1228, 1314, 1315, 1317, 1318, 1325, 1326, 1360, 1382, 1387, 1415, 1484, 1493, 1519, 1545, 1576, 1577, 1578, 1580, 1634, 1635, 1659, 1738, 1770, 1789, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1872, 1877, 1882, 1893, 1932, 1936, 1939, 1979, 1995, 2071, 2082, 2091, 2093, 2095, 2096, 2100, 2114, 2115, 2116, 2117, 2118, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2142, 2143, 2144, 2145, 2147, 2150, 2154, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2171, 2174, 2175, 2176, 2177, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2202, 2203, 2204, 2205, 2207], "prevent": [1, 8, 9, 25, 26, 30, 31, 32, 41, 60, 69, 86, 486, 499, 746, 930, 933, 935, 1004, 1039, 1125, 1126, 1145, 1146, 1147, 1311, 1414, 1427, 1443, 1471, 1474, 1517, 1586, 1612, 1705, 1744, 1745, 1760, 1770, 1837, 1890, 1969, 1972, 1993, 2022, 2024, 2033, 2050, 2100, 2114, 2126, 2127, 2130, 2132, 2135, 2136, 2142, 2146, 2158, 2159, 2168, 2171, 2172, 2180, 2189, 2194, 2195, 2204, 2209], "multipli": [1, 30, 34, 313, 321, 423, 513, 696, 697, 698, 699, 700, 701, 702, 771, 790, 796, 797, 798, 970, 982, 1115, 1127, 1144, 1268, 1279, 1338, 1350, 1351, 1355, 1368, 1370, 1372, 1378, 1380, 1409, 1419, 1438, 1465, 1468, 1492, 1507, 1508, 1509, 1512, 1531, 1550, 1633, 1634, 1635, 1697, 1757, 1758, 1759, 1793, 1862, 1869, 1871, 1880, 1936, 1963, 1966, 1970, 1971, 1986, 1990, 1991, 1994, 2018, 2094, 2115, 2130, 2138, 2142, 2145, 2155, 2171, 2172, 2195], "factor": [1, 4, 26, 34, 39, 69, 700, 701, 702, 814, 954, 970, 993, 1357, 1358, 1359, 1362, 1364, 1404, 1405, 1406, 1517, 1540, 1568, 1592, 1593, 1695, 1728, 1729, 1738, 1838, 1857, 1858, 1859, 1861, 1862, 1864, 1866, 1868, 1869, 1870, 1871, 1874, 1875, 1876, 1892, 1949, 1971, 1994, 2122, 2124, 2126, 2161, 2171, 2195], "flow": [1, 36, 57, 71, 77, 80, 834, 999, 1019, 1327, 1330, 1651, 1686, 1770, 2093, 2117, 2124, 2127, 2130, 2133, 2147, 2149, 2154, 2168, 2189, 2190, 2191, 2192, 2195, 2202, 2204], "through": [1, 6, 8, 10, 13, 16, 17, 21, 25, 30, 32, 36, 37, 39, 44, 56, 57, 58, 60, 65, 68, 69, 71, 74, 76, 78, 496, 805, 869, 884, 891, 892, 930, 933, 935, 936, 949, 950, 1004, 1015, 1046, 1089, 1144, 1171, 1205, 1213, 1226, 1312, 1315, 1317, 1330, 1331, 1333, 1350, 1351, 1372, 1378, 1395, 1587, 1625, 1626, 1627, 1628, 1688, 1760, 1770, 1779, 1780, 1793, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1877, 1892, 2045, 2091, 2092, 2095, 2096, 2100, 2102, 2109, 2114, 2115, 2116, 2117, 2127, 2130, 2133, 2135, 2138, 2140, 2141, 2142, 2148, 2149, 2150, 2154, 2158, 2161, 2164, 2166, 2167, 2168, 2171, 2173, 2175, 2180, 2182, 2183, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2203, 2204, 2205, 2210], "word": [1, 2, 9, 30, 34, 51, 52, 57, 63, 68, 69, 986, 1227, 1484, 1507, 1508, 1509, 1522, 1523, 1624, 1677, 1678, 1697, 1757, 1770, 1787, 1928, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2095, 2127, 2135, 2136, 2158, 2167, 2192], "have": [1, 2, 4, 6, 7, 8, 9, 10, 13, 14, 16, 19, 25, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 69, 71, 79, 80, 88, 153, 154, 221, 222, 233, 313, 315, 321, 335, 398, 402, 448, 458, 471, 486, 487, 488, 503, 513, 515, 517, 520, 544, 617, 681, 700, 704, 706, 707, 708, 710, 830, 832, 871, 910, 919, 923, 935, 936, 938, 940, 945, 954, 955, 956, 958, 971, 972, 980, 989, 990, 1002, 1005, 1014, 1015, 1019, 1027, 1053, 1054, 1089, 1101, 1135, 1143, 1150, 1164, 1174, 1179, 1181, 1195, 1201, 1202, 1213, 1217, 1228, 1236, 1237, 1238, 1255, 1256, 1272, 1273, 1276, 1277, 1289, 1311, 1313, 1314, 1317, 1318, 1320, 1322, 1324, 1326, 1327, 1328, 1329, 1330, 1331, 1336, 1337, 1346, 1350, 1351, 1367, 1374, 1375, 1378, 1380, 1386, 1395, 1397, 1402, 1409, 1412, 1414, 1415, 1416, 1417, 1419, 1420, 1466, 1471, 1472, 1474, 1476, 1484, 1488, 1492, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1516, 1522, 1523, 1527, 1528, 1533, 1538, 1542, 1543, 1544, 1572, 1580, 1583, 1584, 1585, 1586, 1587, 1628, 1630, 1668, 1677, 1678, 1681, 1682, 1686, 1703, 1722, 1724, 1727, 1762, 1763, 1764, 1767, 1768, 1770, 1771, 1772, 1776, 1777, 1778, 1779, 1780, 1781, 1783, 1787, 1790, 1793, 1816, 1820, 1825, 1827, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1855, 1856, 1857, 1858, 1859, 1860, 1874, 1877, 1890, 1916, 1917, 1931, 1936, 1943, 1966, 1970, 1975, 1976, 1977, 1978, 1980, 1981, 1988, 1989, 1990, 1993, 1994, 2008, 2012, 2018, 2020, 2033, 2036, 2038, 2040, 2041, 2043, 2045, 2047, 2091, 2093, 2094, 2095, 2096, 2098, 2100, 2102, 2103, 2104, 2106, 2109, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2150, 2154, 2157, 2158, 2161, 2162, 2165, 2166, 2167, 2168, 2171, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2184, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207], "larger": [1, 10, 30, 39, 69, 254, 499, 950, 973, 1101, 1202, 1369, 1372, 1484, 1516, 1522, 1523, 1572, 1630, 1633, 1677, 1678, 1838, 2127, 2130, 2135, 2138, 2140, 2145, 2147, 2150, 2171, 2176, 2198, 2201, 2202, 2203, 2204, 2209], "thei": [1, 2, 4, 6, 8, 10, 13, 14, 19, 20, 25, 30, 32, 34, 37, 38, 39, 40, 51, 56, 57, 58, 60, 63, 64, 68, 69, 321, 335, 336, 486, 697, 700, 701, 708, 815, 830, 831, 832, 834, 843, 871, 884, 889, 920, 930, 933, 935, 945, 946, 950, 970, 1002, 1089, 1105, 1148, 1195, 1201, 1211, 1222, 1234, 1239, 1241, 1303, 1304, 1311, 1314, 1322, 1327, 1336, 1350, 1351, 1357, 1378, 1386, 1408, 1412, 1415, 1417, 1420, 1466, 1489, 1490, 1491, 1510, 1511, 1512, 1526, 1565, 1573, 1574, 1575, 1580, 1586, 1597, 1609, 1632, 1686, 1688, 1760, 1770, 1771, 1772, 1787, 1791, 1813, 1816, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1868, 1871, 1877, 1932, 1990, 1994, 2033, 2034, 2039, 2091, 2093, 2095, 2096, 2098, 2100, 2102, 2103, 2106, 2109, 2114, 2115, 2116, 2117, 2118, 2124, 2126, 2127, 2130, 2132, 2133, 2134, 2136, 2139, 2142, 2144, 2145, 2147, 2148, 2150, 2154, 2157, 2158, 2161, 2166, 2171, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2184, 2189, 2191, 2192, 2194, 2195, 2196, 2197, 2200, 2204, 2205, 2206], "don": [1, 2, 5, 8, 10, 13, 30, 32, 37, 50, 56, 60, 61, 63, 65, 69, 71, 81, 82, 796, 808, 923, 925, 944, 1004, 1119, 1201, 1227, 1228, 1234, 1236, 1238, 1242, 1330, 1408, 1542, 1543, 1544, 1633, 1757, 1760, 1770, 1828, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1935, 2091, 2093, 2097, 2114, 2115, 2116, 2117, 2122, 2127, 2130, 2133, 2135, 2142, 2144, 2148, 2154, 2157, 2158, 2161, 2166, 2167, 2171, 2189, 2191, 2193, 2194, 2195, 2196, 2202, 2204, 2206], "t": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 21, 25, 26, 30, 32, 37, 39, 40, 41, 44, 48, 49, 50, 51, 56, 57, 60, 61, 63, 65, 66, 68, 69, 71, 81, 82, 150, 313, 315, 321, 458, 486, 523, 537, 571, 698, 699, 708, 771, 792, 796, 808, 842, 851, 907, 908, 909, 910, 919, 921, 923, 925, 930, 931, 933, 935, 936, 939, 944, 956, 993, 994, 995, 1000, 1004, 1019, 1027, 1037, 1040, 1066, 1086, 1087, 1119, 1142, 1160, 1165, 1166, 1167, 1168, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1183, 1195, 1196, 1197, 1198, 1201, 1202, 1203, 1213, 1227, 1228, 1230, 1234, 1236, 1238, 1241, 1242, 1253, 1255, 1268, 1278, 1311, 1312, 1314, 1315, 1317, 1321, 1322, 1326, 1328, 1330, 1333, 1335, 1344, 1345, 1351, 1353, 1354, 1357, 1364, 1372, 1373, 1378, 1386, 1387, 1395, 1408, 1421, 1422, 1441, 1444, 1473, 1493, 1497, 1499, 1507, 1508, 1509, 1516, 1522, 1523, 1531, 1540, 1542, 1543, 1544, 1545, 1550, 1567, 1580, 1596, 1612, 1614, 1624, 1632, 1633, 1657, 1661, 1662, 1663, 1670, 1677, 1678, 1698, 1703, 1723, 1744, 1757, 1760, 1763, 1764, 1770, 1771, 1772, 1787, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1814, 1816, 1817, 1828, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1863, 1877, 1882, 1888, 1892, 1909, 1932, 1934, 1935, 1943, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1966, 1970, 1990, 1994, 2001, 2008, 2011, 2017, 2020, 2045, 2046, 2058, 2091, 2093, 2094, 2095, 2097, 2100, 2108, 2109, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2129, 2130, 2133, 2134, 2136, 2138, 2140, 2141, 2142, 2144, 2147, 2148, 2154, 2155, 2157, 2158, 2161, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2189, 2191, 2192, 2193, 2194, 2196, 2199, 2202, 2204, 2205, 2206], "grad": [1, 2, 6, 30, 39, 61, 64, 65, 69, 150, 335, 458, 487, 488, 495, 496, 503, 504, 581, 681, 910, 919, 923, 925, 926, 927, 930, 934, 935, 936, 938, 940, 945, 946, 949, 950, 954, 955, 1089, 1148, 1201, 1202, 1204, 1208, 1212, 1213, 1297, 1314, 1387, 1580, 1770, 1778, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1970, 2033, 2045, 2093, 2094, 2100, 2115, 2116, 2117, 2126, 2132, 2133, 2134, 2138, 2142, 2144, 2155, 2166, 2167, 2171, 2173, 2177, 2200, 2202], "unscal": 1, "doe": [1, 2, 4, 5, 6, 8, 9, 10, 16, 19, 21, 29, 30, 34, 35, 37, 39, 41, 44, 48, 50, 51, 54, 56, 57, 58, 60, 63, 64, 65, 68, 69, 71, 233, 254, 258, 335, 435, 458, 583, 617, 681, 706, 707, 759, 768, 771, 803, 807, 891, 910, 946, 947, 956, 969, 982, 1004, 1080, 1084, 1135, 1144, 1148, 1198, 1201, 1213, 1224, 1228, 1289, 1313, 1315, 1318, 1325, 1330, 1340, 1344, 1345, 1355, 1357, 1358, 1362, 1363, 1370, 1375, 1376, 1378, 1384, 1387, 1404, 1408, 1409, 1415, 1419, 1423, 1468, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1519, 1522, 1523, 1526, 1531, 1532, 1542, 1543, 1544, 1550, 1551, 1553, 1554, 1555, 1562, 1563, 1564, 1574, 1575, 1581, 1587, 1590, 1596, 1598, 1620, 1632, 1669, 1722, 1738, 1770, 1772, 1779, 1780, 1790, 1793, 1822, 1825, 1827, 1832, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1875, 1877, 1881, 1886, 1928, 1931, 1932, 1936, 1961, 1966, 1994, 2005, 2017, 2020, 2033, 2034, 2045, 2067, 2090, 2091, 2093, 2095, 2096, 2098, 2100, 2106, 2111, 2114, 2115, 2116, 2117, 2122, 2126, 2128, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2142, 2144, 2145, 2146, 2147, 2149, 2154, 2158, 2161, 2166, 2168, 2170, 2171, 2173, 2174, 2177, 2178, 2184, 2189, 2191, 2192, 2204, 2205, 2207], "interfer": [1, 2109, 2130, 2195], "learn": [1, 8, 9, 17, 36, 39, 50, 56, 60, 69, 1497, 1513, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1539, 1552, 1565, 1567, 1588, 1610, 1624, 1626, 1628, 1629, 1630, 1741, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878, 2092, 2100, 2118, 2124, 2130, 2137, 2139, 2142, 2143, 2149, 2154, 2158, 2161, 2166, 2168, 2183, 2188, 2190, 2191, 2192, 2193], "rate": [1, 3, 9, 26, 39, 60, 1518, 1519, 1520, 1524, 1627, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878, 1885, 2140, 2176, 2195, 2201], "fp16": [1, 3, 740, 1770, 1779, 1780, 2137, 2161, 2162], "everi": [1, 2, 3, 6, 9, 10, 21, 25, 26, 30, 32, 35, 37, 39, 41, 57, 60, 65, 69, 481, 487, 610, 681, 792, 837, 930, 931, 935, 954, 955, 958, 1002, 1127, 1144, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1202, 1268, 1277, 1314, 1346, 1360, 1370, 1373, 1404, 1488, 1517, 1518, 1519, 1520, 1524, 1573, 1580, 1614, 1616, 1620, 1672, 1673, 1674, 1679, 1696, 1711, 1712, 1713, 1727, 1745, 1762, 1763, 1764, 1767, 1768, 1770, 1788, 1821, 1824, 1825, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1932, 1994, 2030, 2096, 2102, 2109, 2122, 2126, 2127, 2130, 2132, 2133, 2134, 2136, 2138, 2143, 2154, 2157, 2158, 2159, 2161, 2162, 2166, 2167, 2168, 2171, 2173, 2174, 2176, 2178, 2189, 2191, 2192, 2194, 2201, 2202, 2203, 2204, 2205], "most": [1, 2, 4, 5, 8, 9, 17, 25, 30, 32, 35, 37, 39, 40, 41, 43, 50, 51, 54, 55, 56, 58, 60, 65, 66, 68, 69, 71, 486, 499, 806, 930, 931, 932, 933, 935, 936, 941, 945, 949, 962, 1002, 1015, 1114, 1127, 1144, 1202, 1299, 1312, 1315, 1420, 1484, 1628, 1686, 1738, 1770, 1779, 1780, 1793, 1854, 1936, 1968, 2018, 2091, 2093, 2095, 2096, 2098, 2103, 2104, 2114, 2116, 2117, 2127, 2130, 2133, 2136, 2144, 2145, 2146, 2150, 2157, 2159, 2161, 2167, 2168, 2171, 2173, 2174, 2176, 2178, 2180, 2183, 2188, 2191, 2193, 2194, 2195, 2196, 2197, 2198, 2203, 2204, 2205], "bf16": [1, 3, 2137], "pretrain": [1, 32, 892, 1522, 1523, 2091, 2127, 2154], "cannot": [1, 4, 9, 10, 14, 16, 25, 26, 30, 32, 34, 36, 39, 40, 44, 51, 56, 58, 60, 61, 65, 66, 68, 69, 222, 233, 254, 524, 545, 910, 1004, 1019, 1057, 1165, 1167, 1175, 1176, 1177, 1183, 1196, 1201, 1237, 1311, 1319, 1466, 1499, 1522, 1633, 1670, 1738, 1770, 1833, 1995, 2091, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2104, 2109, 2116, 2117, 2127, 2132, 2133, 2147, 2148, 2154, 2161, 2166, 2168, 2171, 2173, 2174, 2176, 2189, 2192, 2193, 2195, 2196, 2204, 2206], "numer": [1, 13, 25, 27, 37, 39, 57, 61, 66, 698, 806, 949, 950, 986, 1318, 1330, 1331, 1346, 1350, 1351, 1355, 1360, 1368, 1369, 1372, 1375, 1378, 1380, 1402, 1404, 1493, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1595, 1614, 1617, 1620, 1629, 1677, 1698, 1705, 1738, 1744, 1746, 1769, 1788, 1821, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1896, 1928, 1948, 1994, 2096, 2097, 2101, 2106, 2125, 2130, 2133, 2134, 2154, 2161, 2172, 2176, 2177, 2195, 2205, 2210], "max": [1, 21, 25, 30, 36, 37, 41, 44, 50, 51, 54, 56, 60, 69, 116, 185, 186, 187, 188, 300, 706, 707, 708, 767, 769, 781, 782, 791, 793, 794, 817, 837, 839, 840, 841, 846, 904, 958, 973, 990, 997, 998, 1002, 1027, 1123, 1158, 1159, 1238, 1275, 1326, 1346, 1360, 1367, 1369, 1371, 1372, 1384, 1436, 1485, 1486, 1487, 1498, 1499, 1513, 1514, 1523, 1527, 1528, 1533, 1538, 1539, 1547, 1548, 1549, 1566, 1568, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1583, 1584, 1585, 1588, 1600, 1601, 1608, 1629, 1630, 1632, 1648, 1649, 1650, 1660, 1668, 1678, 1681, 1682, 1697, 1701, 1711, 1712, 1713, 1723, 1727, 1731, 1733, 1739, 1757, 1776, 1778, 1816, 1838, 1840, 1841, 1842, 1858, 1863, 1864, 1874, 1897, 1898, 1970, 1988, 1989, 2002, 2033, 2040, 2041, 2093, 2094, 2103, 2109, 2117, 2128, 2130, 2135, 2137, 2155, 2161, 2164, 2185, 2191, 2194, 2198, 2199, 2204, 2210], "65504": 1, "overflow": [1, 1125, 1126, 1218, 1414, 1471, 1474, 1705, 1744, 1745, 1890, 1921, 1969, 1972, 1993, 2022, 2024, 2130, 2145, 2172], "case": [1, 2, 4, 5, 9, 10, 13, 16, 17, 21, 25, 26, 30, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 51, 52, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 68, 69, 71, 73, 78, 80, 85, 150, 154, 196, 352, 486, 496, 499, 681, 771, 795, 804, 807, 839, 840, 842, 851, 888, 895, 923, 935, 936, 938, 940, 944, 954, 965, 969, 971, 973, 978, 1004, 1022, 1036, 1066, 1090, 1091, 1112, 1113, 1114, 1144, 1165, 1167, 1175, 1176, 1177, 1192, 1203, 1207, 1212, 1228, 1238, 1241, 1274, 1299, 1312, 1315, 1324, 1327, 1328, 1330, 1344, 1346, 1350, 1351, 1355, 1360, 1361, 1362, 1364, 1370, 1373, 1378, 1380, 1384, 1386, 1387, 1392, 1395, 1404, 1415, 1466, 1484, 1489, 1490, 1491, 1492, 1493, 1507, 1508, 1509, 1511, 1512, 1513, 1515, 1518, 1519, 1520, 1521, 1523, 1524, 1526, 1535, 1536, 1537, 1538, 1539, 1540, 1546, 1547, 1548, 1549, 1566, 1571, 1573, 1574, 1575, 1586, 1587, 1588, 1599, 1612, 1618, 1623, 1628, 1630, 1632, 1651, 1669, 1678, 1686, 1690, 1691, 1722, 1724, 1731, 1770, 1773, 1774, 1779, 1780, 1787, 1790, 1793, 1794, 1826, 1827, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1855, 1856, 1857, 1858, 1859, 1860, 1872, 1874, 1912, 1915, 1928, 1930, 1943, 1946, 1979, 1994, 1995, 2028, 2029, 2033, 2048, 2058, 2071, 2072, 2082, 2083, 2091, 2096, 2101, 2104, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2129, 2130, 2133, 2134, 2135, 2136, 2138, 2141, 2142, 2144, 2145, 2147, 2154, 2156, 2157, 2158, 2161, 2162, 2164, 2165, 2166, 2167, 2168, 2171, 2172, 2175, 2176, 2177, 2178, 2183, 2185, 2191, 2192, 2194, 2195, 2196, 2200, 2202, 2203, 2205, 2206, 2210], "decreas": [1, 39, 1101, 1360, 1518, 1519, 1520, 1524, 1593, 1814, 1815, 1858, 1865, 1874, 2078, 2102, 2106, 2144, 2146, 2171, 2174], "attempt": [1, 2, 9, 16, 21, 30, 32, 49, 51, 52, 65, 996, 1002, 1005, 1023, 1318, 1325, 1404, 1738, 1773, 1774, 1838, 1840, 1841, 1859, 2033, 2036, 2093, 2096, 2111, 2114, 2115, 2116, 2126, 2130, 2133, 2148, 2149, 2157, 2158, 2166, 2184, 2191, 2194, 2195, 2204, 2205], "bring": [1, 61, 69, 1165, 1651, 1686, 2130, 2133, 2137, 2198, 2201], "number": [1, 2, 3, 4, 5, 6, 8, 16, 21, 25, 26, 30, 32, 35, 36, 37, 39, 41, 49, 50, 51, 55, 56, 61, 63, 66, 69, 71, 76, 87, 88, 154, 173, 218, 232, 254, 313, 352, 377, 398, 402, 435, 446, 471, 473, 474, 481, 493, 497, 499, 513, 515, 517, 543, 545, 546, 558, 583, 584, 585, 587, 588, 589, 608, 617, 688, 696, 697, 698, 699, 700, 701, 702, 709, 769, 771, 779, 780, 783, 784, 785, 792, 837, 895, 907, 920, 924, 935, 949, 965, 967, 970, 972, 973, 978, 982, 984, 988, 996, 997, 1001, 1022, 1026, 1027, 1032, 1046, 1052, 1055, 1063, 1074, 1075, 1087, 1089, 1090, 1091, 1101, 1112, 1113, 1116, 1117, 1136, 1139, 1141, 1144, 1145, 1149, 1157, 1187, 1189, 1192, 1196, 1198, 1200, 1222, 1255, 1257, 1265, 1266, 1267, 1271, 1275, 1276, 1277, 1286, 1289, 1290, 1311, 1312, 1314, 1328, 1335, 1338, 1339, 1346, 1360, 1369, 1378, 1382, 1387, 1392, 1403, 1407, 1415, 1424, 1428, 1429, 1437, 1439, 1450, 1453, 1461, 1465, 1466, 1470, 1474, 1477, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1497, 1498, 1499, 1500, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1521, 1522, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1545, 1546, 1550, 1551, 1556, 1557, 1558, 1559, 1560, 1561, 1566, 1567, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1579, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1594, 1596, 1598, 1599, 1600, 1601, 1608, 1610, 1611, 1612, 1613, 1614, 1616, 1617, 1618, 1619, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1653, 1654, 1655, 1657, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1677, 1678, 1681, 1682, 1687, 1697, 1698, 1700, 1703, 1711, 1712, 1713, 1722, 1724, 1730, 1731, 1738, 1760, 1770, 1788, 1793, 1798, 1799, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1813, 1814, 1815, 1817, 1821, 1826, 1827, 1828, 1830, 1831, 1834, 1843, 1862, 1863, 1864, 1865, 1869, 1870, 1872, 1873, 1874, 1877, 1878, 1882, 1885, 1889, 1899, 1901, 1902, 1903, 1905, 1906, 1907, 1912, 1914, 1915, 1918, 1919, 1920, 1921, 1929, 1933, 1936, 1937, 1938, 1939, 1940, 1941, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1966, 1971, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 1986, 1987, 1988, 1989, 1990, 1991, 1995, 2012, 2013, 2014, 2022, 2024, 2029, 2030, 2035, 2036, 2039, 2040, 2041, 2042, 2043, 2044, 2056, 2064, 2065, 2071, 2072, 2082, 2083, 2085, 2086, 2089, 2094, 2095, 2096, 2097, 2098, 2100, 2103, 2109, 2114, 2117, 2122, 2124, 2128, 2130, 2133, 2138, 2142, 2144, 2145, 2147, 2154, 2157, 2158, 2159, 2160, 2162, 2165, 2166, 2167, 2170, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2179, 2189, 2191, 2194, 2195, 2201, 2204, 2205, 2207, 2208, 2209, 2210], "expect": [1, 2, 4, 6, 8, 10, 14, 25, 26, 30, 32, 34, 35, 36, 41, 49, 51, 54, 56, 57, 58, 60, 65, 66, 69, 415, 486, 681, 708, 771, 884, 938, 939, 940, 941, 942, 943, 1089, 1165, 1167, 1184, 1185, 1186, 1206, 1207, 1228, 1238, 1289, 1311, 1314, 1330, 1331, 1359, 1380, 1381, 1415, 1495, 1496, 1515, 1531, 1532, 1533, 1534, 1543, 1544, 1545, 1550, 1551, 1552, 1562, 1563, 1564, 1580, 1586, 1587, 1595, 1596, 1598, 1614, 1620, 1624, 1626, 1628, 1633, 1677, 1683, 1697, 1722, 1730, 1731, 1744, 1757, 1758, 1759, 1760, 1769, 1770, 1814, 1875, 1877, 2006, 2043, 2091, 2092, 2098, 2100, 2104, 2117, 2122, 2127, 2132, 2135, 2136, 2138, 2142, 2154, 2157, 2158, 2161, 2162, 2163, 2166, 2171, 2173, 2176, 2178, 2190, 2192, 2194, 2195, 2198, 2200, 2202], "alwai": [1, 6, 8, 16, 19, 21, 25, 26, 30, 39, 49, 54, 56, 57, 58, 60, 64, 69, 86, 233, 340, 415, 448, 458, 807, 910, 930, 932, 935, 938, 944, 971, 980, 990, 996, 1002, 1030, 1032, 1089, 1101, 1131, 1139, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1175, 1176, 1177, 1178, 1180, 1183, 1187, 1222, 1241, 1272, 1273, 1314, 1325, 1330, 1345, 1350, 1351, 1352, 1353, 1355, 1356, 1368, 1371, 1372, 1373, 1374, 1378, 1380, 1443, 1472, 1492, 1494, 1495, 1496, 1516, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1617, 1620, 1738, 1760, 1770, 1813, 1874, 1877, 1916, 1917, 1942, 1990, 1994, 2002, 2029, 2033, 2096, 2097, 2104, 2108, 2114, 2117, 2122, 2127, 2128, 2129, 2130, 2132, 2133, 2136, 2138, 2140, 2142, 2158, 2165, 2166, 2168, 2171, 2174, 2177, 2178, 2180, 2184, 2189, 2191, 2194, 2202, 2204, 2212], "abov": [1, 2, 4, 14, 17, 30, 32, 34, 36, 37, 38, 39, 44, 51, 54, 56, 57, 58, 60, 61, 66, 69, 617, 681, 805, 806, 910, 971, 980, 1101, 1127, 1131, 1132, 1133, 1134, 1135, 1144, 1258, 1272, 1273, 1314, 1315, 1335, 1346, 1350, 1351, 1369, 1371, 1372, 1375, 1378, 1381, 1384, 1387, 1489, 1490, 1491, 1492, 1493, 1526, 1580, 1609, 1617, 1632, 1738, 1760, 1828, 1865, 1877, 1892, 1903, 1904, 1936, 1940, 1953, 1973, 2018, 2021, 2022, 2023, 2024, 2091, 2093, 2095, 2096, 2100, 2103, 2117, 2122, 2127, 2128, 2129, 2130, 2133, 2134, 2138, 2142, 2144, 2146, 2147, 2150, 2151, 2154, 2158, 2161, 2166, 2167, 2168, 2171, 2172, 2178, 2183, 2186, 2190, 2191, 2192, 2193, 2195, 2196, 2197, 2198, 2204, 2205], "our": [1, 4, 8, 9, 13, 36, 47, 50, 51, 52, 55, 64, 65, 66, 69, 930, 931, 935, 1144, 1164, 1202, 1221, 1228, 1492, 1779, 1780, 1840, 1841, 1936, 2100, 2122, 2127, 2133, 2136, 2138, 2141, 2144, 2149, 2154, 2157, 2161, 2167, 2171, 2183, 2189, 2191, 2192, 2194, 2195, 2197, 2198, 2203, 2204, 2205], "NOT": [1, 6, 25, 30, 41, 51, 52, 54, 56, 69, 976, 1037, 1078, 1314, 1397, 1519, 1770, 1772, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 1825, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 2127, 2150, 2168, 2171, 2173, 2192, 2202, 2204], "make": [1, 2, 3, 4, 5, 6, 9, 16, 17, 22, 25, 26, 27, 30, 32, 33, 34, 36, 39, 41, 43, 48, 51, 52, 54, 55, 56, 64, 65, 69, 71, 82, 86, 88, 139, 222, 486, 496, 790, 796, 891, 892, 923, 926, 993, 1004, 1039, 1040, 1042, 1132, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1184, 1185, 1186, 1222, 1227, 1228, 1314, 1318, 1324, 1325, 1344, 1345, 1357, 1358, 1359, 1387, 1427, 1443, 1492, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1540, 1580, 1590, 1628, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1686, 1688, 1697, 1738, 1757, 1770, 1787, 1804, 1820, 1868, 1877, 1933, 1965, 1976, 1977, 1978, 1980, 1981, 2015, 2033, 2036, 2038, 2050, 2091, 2093, 2095, 2096, 2100, 2104, 2109, 2114, 2115, 2122, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2138, 2142, 2144, 2146, 2147, 2148, 2154, 2157, 2158, 2159, 2161, 2162, 2166, 2167, 2168, 2171, 2173, 2174, 2176, 2180, 2181, 2183, 2185, 2191, 2193, 2194, 2195, 2197, 2198, 2200, 2203, 2204, 2205, 2206], "guarante": [1, 2, 6, 10, 25, 30, 32, 35, 39, 54, 56, 57, 58, 65, 68, 69, 71, 486, 906, 954, 1002, 1226, 1228, 1238, 1314, 1324, 1350, 1352, 1516, 1580, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1965, 1967, 2033, 2127, 2129, 2130, 2145, 2146, 2158, 2159, 2162, 2166, 2168, 2173, 2185, 2191], "encount": [1, 6, 21, 30, 56, 58, 65, 68, 69, 681, 1004, 1770, 1779, 1780, 2093, 2096, 2098, 2102, 2129, 2145, 2147, 2158, 2161, 2173, 2186, 2190, 2192, 2195, 2200, 2202, 2204, 2205, 2208], "nan": [1, 2, 29, 39, 427, 428, 499, 695, 697, 700, 701, 702, 705, 708, 709, 911, 915, 970, 986, 1145, 1146, 1147, 1150, 1190, 1191, 1192, 1275, 1303, 1304, 1306, 1307, 1354, 1361, 1374, 1377, 1390, 1395, 1413, 1414, 1418, 1470, 1471, 1472, 1473, 1474, 1686, 1776, 1785, 1886, 1923, 1928, 1983, 2020, 2094, 2103, 2126, 2127, 2134, 2145, 2172, 2178, 2180, 2209], "verifi": [1, 30, 56, 58, 69, 949, 1127, 1834, 1835, 1860, 2018, 2091, 2093, 2107, 2133, 2138, 2150, 2154, 2156, 2197], "compat": [1, 2, 16, 25, 30, 32, 37, 38, 39, 41, 52, 56, 60, 64, 65, 69, 71, 497, 498, 603, 617, 681, 830, 831, 832, 920, 935, 936, 968, 983, 1020, 1021, 1226, 1314, 1319, 1332, 1345, 1356, 1369, 1372, 1580, 1586, 1624, 1625, 1626, 1627, 1628, 1697, 1779, 1780, 1824, 1833, 1877, 1915, 2091, 2092, 2095, 2096, 2102, 2114, 2115, 2117, 2122, 2126, 2130, 2133, 2147, 2150, 2157, 2158, 2159, 2161, 2164, 2166, 2171, 2173, 2177, 2180, 2185, 2204], "init_scal": 1, "65536": 1, "0": [1, 2, 4, 13, 14, 16, 20, 21, 22, 25, 26, 27, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 49, 51, 52, 54, 56, 57, 58, 60, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 88, 154, 156, 173, 184, 191, 208, 224, 225, 226, 227, 228, 233, 254, 258, 260, 263, 286, 289, 298, 300, 311, 313, 315, 317, 321, 352, 401, 402, 427, 428, 445, 448, 449, 454, 481, 483, 487, 488, 496, 507, 508, 513, 515, 517, 520, 538, 543, 544, 547, 556, 558, 560, 578, 580, 581, 583, 584, 585, 587, 588, 589, 595, 596, 597, 598, 605, 607, 608, 617, 688, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 710, 723, 724, 725, 726, 727, 728, 729, 730, 734, 735, 736, 737, 738, 741, 742, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 759, 762, 763, 764, 766, 767, 768, 769, 771, 779, 780, 781, 783, 784, 785, 786, 789, 791, 793, 794, 796, 807, 809, 814, 817, 832, 839, 840, 841, 846, 884, 886, 895, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 924, 930, 932, 935, 936, 938, 939, 940, 942, 949, 950, 952, 954, 955, 962, 965, 967, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 983, 984, 986, 989, 990, 991, 992, 993, 994, 996, 997, 1000, 1017, 1018, 1019, 1022, 1023, 1024, 1025, 1026, 1027, 1036, 1053, 1056, 1073, 1086, 1087, 1115, 1119, 1123, 1124, 1125, 1126, 1127, 1128, 1131, 1132, 1133, 1134, 1135, 1136, 1138, 1139, 1141, 1142, 1144, 1146, 1147, 1154, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1178, 1179, 1180, 1181, 1183, 1184, 1185, 1186, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1201, 1203, 1204, 1205, 1206, 1207, 1211, 1212, 1213, 1228, 1232, 1238, 1255, 1256, 1263, 1268, 1272, 1274, 1275, 1276, 1277, 1278, 1281, 1285, 1289, 1291, 1299, 1310, 1311, 1312, 1314, 1318, 1320, 1321, 1322, 1326, 1334, 1335, 1336, 1337, 1338, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1356, 1357, 1358, 1359, 1360, 1361, 1366, 1367, 1368, 1369, 1371, 1372, 1373, 1374, 1376, 1381, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1394, 1395, 1396, 1397, 1398, 1399, 1401, 1404, 1408, 1412, 1413, 1414, 1415, 1417, 1418, 1419, 1420, 1421, 1422, 1438, 1441, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1478, 1480, 1482, 1483, 1484, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1498, 1499, 1501, 1502, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1531, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1566, 1568, 1570, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1594, 1595, 1596, 1597, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1608, 1612, 1614, 1615, 1616, 1617, 1618, 1620, 1623, 1624, 1626, 1628, 1629, 1630, 1632, 1633, 1636, 1637, 1638, 1641, 1642, 1643, 1651, 1652, 1653, 1654, 1655, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1686, 1689, 1690, 1691, 1694, 1695, 1696, 1697, 1701, 1702, 1704, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1722, 1723, 1724, 1725, 1726, 1727, 1730, 1731, 1733, 1738, 1739, 1742, 1744, 1747, 1753, 1754, 1755, 1756, 1757, 1760, 1769, 1770, 1775, 1776, 1779, 1780, 1785, 1787, 1788, 1789, 1793, 1798, 1799, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1813, 1814, 1816, 1817, 1819, 1820, 1821, 1822, 1824, 1826, 1827, 1828, 1832, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1883, 1885, 1886, 1888, 1889, 1890, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1910, 1911, 1912, 1913, 1914, 1915, 1918, 1919, 1920, 1921, 1923, 1924, 1928, 1930, 1931, 1932, 1935, 1937, 1940, 1943, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1960, 1961, 1965, 1967, 1968, 1970, 1971, 1972, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1987, 1988, 1989, 1990, 1991, 1993, 1994, 1995, 1996, 1997, 2006, 2007, 2009, 2010, 2011, 2012, 2013, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2026, 2027, 2029, 2030, 2031, 2032, 2035, 2039, 2040, 2041, 2043, 2044, 2045, 2046, 2048, 2089, 2090, 2091, 2093, 2094, 2095, 2096, 2100, 2103, 2111, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2142, 2145, 2146, 2147, 2148, 2149, 2150, 2154, 2156, 2157, 2158, 2159, 2161, 2163, 2166, 2167, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2181, 2183, 2185, 2186, 2189, 2190, 2191, 2193, 2195, 2197, 2198, 2199, 2202, 2203, 2204, 2206, 2209, 2210], "growth_factor": 1, "backoff_factor": 1, "5": [1, 2, 6, 12, 13, 14, 16, 20, 23, 25, 26, 30, 36, 39, 49, 56, 64, 65, 66, 68, 69, 71, 72, 76, 77, 79, 80, 81, 82, 154, 191, 208, 260, 289, 298, 313, 315, 317, 321, 401, 402, 445, 471, 499, 513, 515, 517, 523, 537, 544, 558, 560, 584, 585, 586, 587, 588, 607, 696, 697, 701, 708, 745, 750, 751, 752, 753, 754, 756, 757, 771, 773, 784, 785, 891, 892, 895, 910, 916, 917, 918, 938, 941, 943, 970, 973, 980, 981, 982, 986, 988, 992, 994, 995, 996, 997, 1000, 1007, 1015, 1022, 1026, 1123, 1125, 1127, 1134, 1136, 1138, 1139, 1142, 1143, 1144, 1147, 1160, 1162, 1164, 1165, 1171, 1172, 1175, 1180, 1183, 1184, 1187, 1190, 1192, 1193, 1194, 1196, 1203, 1205, 1206, 1207, 1208, 1211, 1212, 1213, 1256, 1268, 1274, 1276, 1278, 1280, 1281, 1291, 1299, 1303, 1321, 1325, 1326, 1335, 1336, 1337, 1340, 1343, 1344, 1361, 1364, 1367, 1370, 1371, 1372, 1373, 1378, 1379, 1382, 1384, 1385, 1387, 1388, 1389, 1390, 1391, 1397, 1401, 1408, 1409, 1415, 1416, 1466, 1473, 1475, 1476, 1478, 1481, 1482, 1483, 1485, 1486, 1487, 1488, 1489, 1493, 1494, 1495, 1496, 1500, 1501, 1502, 1504, 1505, 1506, 1508, 1509, 1511, 1512, 1513, 1515, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1531, 1533, 1534, 1535, 1540, 1542, 1543, 1544, 1545, 1546, 1550, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1568, 1571, 1576, 1577, 1580, 1587, 1590, 1594, 1595, 1596, 1602, 1603, 1604, 1605, 1606, 1609, 1612, 1618, 1620, 1624, 1626, 1628, 1630, 1631, 1632, 1633, 1634, 1635, 1652, 1653, 1661, 1662, 1664, 1665, 1669, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1681, 1682, 1684, 1686, 1689, 1697, 1722, 1724, 1730, 1738, 1747, 1757, 1758, 1759, 1769, 1770, 1793, 1803, 1805, 1807, 1808, 1810, 1815, 1816, 1818, 1820, 1826, 1827, 1828, 1830, 1831, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1862, 1869, 1873, 1881, 1883, 1885, 1886, 1888, 1889, 1892, 1893, 1896, 1897, 1898, 1899, 1903, 1908, 1909, 1912, 1913, 1919, 1920, 1921, 1928, 1940, 1947, 1948, 1949, 1950, 1951, 1952, 1955, 1956, 1965, 1971, 1973, 1975, 1976, 1977, 1979, 1982, 1990, 1993, 1994, 1995, 1996, 1997, 2007, 2009, 2011, 2012, 2013, 2015, 2016, 2018, 2027, 2028, 2031, 2033, 2039, 2045, 2046, 2047, 2089, 2093, 2094, 2095, 2096, 2097, 2103, 2104, 2116, 2117, 2124, 2126, 2127, 2128, 2130, 2133, 2135, 2137, 2138, 2142, 2143, 2147, 2148, 2149, 2154, 2157, 2161, 2166, 2171, 2172, 2174, 2176, 2177, 2178, 2192, 2193, 2195, 2202, 2203, 2204, 2205], "growth_interv": 1, "2000": [1, 30, 35, 1162, 1164, 1171, 1180, 1193, 1392, 1633, 1865, 1896, 1945, 1946, 2011, 2117], "float64": [1, 13, 240, 446, 449, 580, 910, 1016, 1187, 1196, 1197, 1261, 1296, 1314, 1344, 1350, 1351, 1353, 1355, 1371, 1580, 1738, 1839, 1840, 1841, 1859, 1877, 1886, 1894, 1933, 1934, 1937, 1967, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2043, 2048, 2142, 2145, 2171, 2173, 2174, 2177, 2178, 2210], "out": [1, 2, 3, 4, 6, 8, 9, 10, 13, 17, 20, 21, 25, 27, 30, 32, 34, 37, 39, 48, 49, 52, 56, 61, 64, 69, 71, 75, 77, 88, 233, 312, 314, 316, 318, 399, 401, 448, 496, 512, 514, 516, 682, 683, 694, 695, 696, 697, 698, 699, 700, 701, 702, 704, 706, 707, 708, 709, 710, 767, 771, 775, 783, 784, 785, 790, 792, 796, 811, 834, 864, 866, 868, 887, 888, 895, 896, 897, 898, 899, 900, 901, 902, 907, 911, 912, 913, 914, 915, 925, 928, 929, 930, 933, 935, 945, 949, 958, 969, 970, 972, 973, 974, 975, 976, 977, 978, 979, 982, 986, 989, 991, 992, 993, 994, 995, 997, 998, 1000, 1002, 1016, 1017, 1018, 1021, 1022, 1024, 1025, 1036, 1043, 1051, 1053, 1056, 1087, 1088, 1101, 1102, 1115, 1119, 1123, 1124, 1125, 1126, 1128, 1131, 1136, 1137, 1139, 1140, 1141, 1143, 1144, 1145, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1198, 1199, 1202, 1203, 1205, 1206, 1208, 1213, 1237, 1251, 1255, 1256, 1257, 1258, 1259, 1269, 1270, 1271, 1274, 1275, 1276, 1277, 1279, 1280, 1281, 1282, 1283, 1284, 1286, 1287, 1288, 1289, 1291, 1292, 1308, 1309, 1314, 1320, 1326, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1361, 1362, 1363, 1364, 1365, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1383, 1384, 1385, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1417, 1418, 1419, 1420, 1438, 1441, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1476, 1477, 1478, 1479, 1480, 1481, 1485, 1486, 1487, 1489, 1490, 1491, 1497, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1517, 1518, 1519, 1520, 1522, 1524, 1527, 1528, 1531, 1532, 1547, 1548, 1549, 1550, 1565, 1567, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1592, 1593, 1596, 1598, 1602, 1603, 1604, 1605, 1606, 1607, 1624, 1625, 1626, 1627, 1628, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1640, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1672, 1673, 1674, 1679, 1682, 1686, 1697, 1703, 1723, 1725, 1757, 1770, 1779, 1780, 1798, 1799, 1800, 1801, 1826, 1827, 1828, 1829, 1831, 1832, 1860, 1877, 1880, 1881, 1885, 1886, 1887, 1889, 1892, 1893, 1899, 1900, 1901, 1903, 1905, 1907, 1908, 1911, 1912, 1913, 1917, 1921, 1922, 1923, 1925, 1926, 1927, 1928, 1943, 1944, 1945, 1957, 1958, 1959, 1960, 1965, 1970, 1971, 1974, 1983, 1984, 1986, 1987, 1988, 1989, 1991, 1992, 1994, 2008, 2009, 2010, 2013, 2015, 2017, 2020, 2021, 2023, 2025, 2026, 2033, 2040, 2041, 2042, 2045, 2047, 2048, 2049, 2089, 2090, 2091, 2093, 2094, 2096, 2100, 2103, 2104, 2105, 2106, 2109, 2112, 2113, 2114, 2116, 2117, 2122, 2127, 2128, 2130, 2132, 2133, 2134, 2136, 2142, 2144, 2150, 2151, 2154, 2157, 2158, 2161, 2162, 2164, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2182, 2186, 2191, 2192, 2193, 2194, 2195, 2197, 2198, 2199, 2202, 2203, 2204, 2205, 2206, 2207, 2209], "place": [1, 4, 8, 13, 14, 21, 25, 26, 30, 32, 37, 40, 41, 56, 58, 60, 63, 64, 67, 69, 87, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 121, 123, 125, 127, 130, 131, 133, 141, 143, 146, 147, 149, 152, 158, 160, 162, 164, 166, 168, 177, 186, 194, 198, 201, 203, 213, 215, 221, 222, 231, 236, 238, 244, 247, 249, 251, 253, 254, 257, 260, 262, 269, 271, 273, 277, 279, 283, 285, 292, 294, 296, 304, 306, 308, 310, 312, 314, 316, 318, 356, 358, 360, 362, 364, 366, 368, 371, 373, 375, 376, 383, 385, 387, 389, 391, 395, 399, 401, 420, 423, 426, 428, 439, 441, 443, 451, 456, 466, 469, 485, 486, 487, 488, 490, 492, 496, 499, 508, 511, 512, 514, 516, 522, 527, 529, 532, 534, 536, 549, 551, 553, 562, 564, 571, 575, 577, 593, 596, 598, 600, 602, 603, 612, 622, 769, 806, 811, 829, 866, 868, 887, 888, 930, 931, 933, 935, 954, 955, 956, 958, 984, 1015, 1019, 1051, 1052, 1054, 1055, 1056, 1080, 1144, 1195, 1201, 1202, 1210, 1314, 1359, 1377, 1466, 1488, 1498, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1524, 1536, 1537, 1538, 1566, 1580, 1598, 1599, 1600, 1601, 1608, 1623, 1671, 1672, 1673, 1674, 1676, 1677, 1678, 1679, 1690, 1693, 1702, 1734, 1737, 1752, 1756, 1760, 1770, 1776, 1777, 1778, 1779, 1780, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1822, 1860, 1877, 1919, 1921, 1925, 1926, 1927, 1973, 2013, 2093, 2095, 2096, 2103, 2116, 2122, 2126, 2130, 2133, 2140, 2149, 2150, 2157, 2158, 2166, 2167, 2173, 2175, 2177, 2189, 2191, 2192, 2194, 2195, 2201, 2203, 2204], "variant": [1, 6, 26, 30, 36, 56, 58, 888, 1345, 1356, 1369, 1372, 1473, 1476, 1640, 1641, 1642, 1643, 1840, 1841, 1842, 1860, 1967, 2020, 2140, 2164, 2177, 2199, 2200, 2203], "explicitli": [1, 6, 9, 16, 30, 34, 44, 58, 60, 956, 1080, 1132, 1134, 1144, 1277, 1355, 1368, 1372, 1380, 1422, 1697, 1757, 1771, 1838, 1872, 1936, 1990, 2093, 2095, 2096, 2097, 2102, 2104, 2117, 2130, 2133, 2136, 2138, 2140, 2147, 2154, 2156, 2158, 2165, 2166, 2171, 2177, 2184, 2195, 2204], "suppli": [1, 6, 8, 16, 17, 30, 69, 1078, 1586, 1835, 2096, 2130, 2150, 2154, 2171, 2195, 2205], "won": [1, 9, 26, 32, 37, 51, 56, 63, 458, 1228, 1314, 1326, 1580, 1723, 1763, 1764, 1877, 2091, 2117, 2127, 2133, 2166, 2180, 2192, 2194, 2195, 2202, 2205], "go": [1, 2, 8, 17, 25, 30, 32, 36, 48, 54, 56, 64, 69, 499, 500, 560, 930, 932, 935, 954, 958, 1234, 1387, 1489, 1490, 1491, 1573, 1574, 1575, 1779, 1780, 2095, 2096, 2103, 2114, 2115, 2116, 2127, 2129, 2130, 2133, 2134, 2140, 2142, 2144, 2148, 2154, 2158, 2174, 2176, 2190, 2191, 2192, 2193, 2194, 2195, 2204], "addmm": [1, 57, 106, 1986, 2094, 2115, 2145, 2155, 2171, 2199, 2203], "b": [1, 2, 4, 13, 14, 25, 30, 32, 39, 49, 56, 69, 71, 74, 260, 335, 398, 617, 696, 697, 759, 768, 792, 843, 910, 930, 931, 933, 934, 935, 936, 952, 954, 955, 970, 981, 982, 984, 988, 990, 992, 995, 1000, 1015, 1019, 1022, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1086, 1087, 1136, 1139, 1143, 1144, 1189, 1190, 1191, 1192, 1198, 1202, 1220, 1221, 1239, 1256, 1280, 1291, 1311, 1317, 1325, 1326, 1334, 1335, 1337, 1346, 1347, 1354, 1355, 1359, 1360, 1364, 1367, 1368, 1369, 1370, 1371, 1372, 1375, 1376, 1377, 1380, 1381, 1384, 1387, 1396, 1398, 1399, 1405, 1413, 1418, 1420, 1465, 1493, 1497, 1522, 1523, 1530, 1567, 1657, 1659, 1678, 1685, 1703, 1787, 1814, 1815, 1816, 1817, 1818, 1819, 1827, 1857, 1859, 1893, 1899, 1912, 1915, 1931, 1942, 1961, 1970, 1976, 1977, 1978, 1980, 1981, 1985, 1990, 1991, 1993, 2001, 2002, 2003, 2013, 2020, 2021, 2023, 2042, 2047, 2093, 2094, 2095, 2096, 2100, 2115, 2116, 2117, 2122, 2124, 2126, 2128, 2130, 2133, 2135, 2138, 2139, 2145, 2147, 2159, 2161, 2167, 2168, 2171, 2172, 2175, 2176, 2182, 2190, 2192, 2193, 2195, 2197, 2199, 2203, 2205, 2207], "c": [1, 2, 4, 9, 10, 16, 21, 25, 27, 30, 39, 49, 57, 63, 69, 260, 335, 499, 520, 617, 696, 840, 907, 910, 930, 933, 935, 936, 981, 992, 1004, 1015, 1023, 1080, 1086, 1121, 1136, 1139, 1144, 1190, 1191, 1192, 1202, 1203, 1207, 1212, 1256, 1268, 1314, 1325, 1337, 1344, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1360, 1361, 1364, 1366, 1370, 1371, 1373, 1375, 1377, 1378, 1465, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1515, 1518, 1519, 1520, 1524, 1526, 1527, 1528, 1534, 1542, 1543, 1544, 1547, 1548, 1549, 1551, 1552, 1562, 1563, 1564, 1568, 1573, 1574, 1575, 1576, 1577, 1578, 1583, 1584, 1585, 1587, 1592, 1593, 1602, 1603, 1604, 1605, 1606, 1607, 1615, 1620, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1651, 1659, 1669, 1670, 1682, 1686, 1722, 1728, 1729, 1738, 1787, 1815, 1817, 1818, 1819, 1826, 1827, 1880, 1896, 1912, 1949, 1970, 1985, 1990, 2013, 2030, 2035, 2036, 2093, 2094, 2095, 2096, 2104, 2115, 2116, 2117, 2129, 2130, 2132, 2133, 2134, 2138, 2140, 2148, 2158, 2167, 2168, 2171, 2172, 2175, 2176, 2183, 2186, 2191, 2192, 2193, 2194, 2195, 2197, 2199, 2203, 2204, 2205, 2206, 2207, 2208], "addmm_": [1, 2094, 2115, 2171], "d": [1, 2, 13, 25, 26, 30, 37, 38, 39, 61, 69, 313, 321, 335, 471, 513, 515, 517, 544, 583, 617, 697, 701, 895, 910, 930, 933, 935, 936, 969, 970, 971, 973, 980, 981, 982, 986, 989, 992, 1131, 1133, 1143, 1144, 1157, 1161, 1162, 1163, 1164, 1169, 1170, 1173, 1174, 1179, 1180, 1181, 1184, 1185, 1186, 1213, 1221, 1255, 1272, 1273, 1280, 1289, 1311, 1315, 1319, 1357, 1358, 1408, 1419, 1468, 1483, 1491, 1492, 1496, 1509, 1513, 1514, 1518, 1519, 1520, 1522, 1524, 1526, 1531, 1533, 1544, 1550, 1552, 1564, 1575, 1589, 1595, 1596, 1620, 1629, 1630, 1632, 1651, 1686, 1697, 1703, 1731, 1756, 1757, 1769, 1788, 1821, 1826, 1827, 1838, 1858, 1881, 1899, 1905, 1908, 1920, 1928, 1933, 1985, 1990, 2006, 2007, 2013, 2016, 2021, 2022, 2023, 2024, 2039, 2045, 2047, 2091, 2094, 2103, 2115, 2116, 2117, 2122, 2124, 2127, 2130, 2133, 2134, 2136, 2137, 2138, 2139, 2147, 2154, 2157, 2166, 2167, 2171, 2172, 2176, 2177, 2194, 2195, 2197, 2202, 2204, 2205, 2207], "best": [1, 2, 8, 17, 20, 25, 30, 39, 52, 60, 63, 891, 892, 962, 989, 1002, 1228, 1330, 1331, 1360, 1586, 1860, 1874, 1877, 2093, 2095, 2100, 2114, 2124, 2125, 2126, 2127, 2133, 2135, 2147, 2158, 2166, 2171, 2173, 2183, 2192, 2193, 2195, 2198, 2204], "stabil": [1, 1346, 1351, 1402, 1493, 1494, 1495, 1496, 1533, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1595, 1617, 1620, 1629, 1683, 1746, 1769, 1788, 1821, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1896, 2134, 2157, 2195, 2205], "argument": [1, 2, 4, 5, 6, 9, 10, 14, 16, 20, 21, 25, 30, 31, 32, 35, 36, 37, 38, 39, 41, 49, 52, 55, 56, 57, 58, 60, 64, 65, 68, 69, 71, 77, 79, 80, 87, 150, 196, 209, 233, 313, 321, 415, 445, 446, 447, 448, 449, 487, 488, 513, 517, 560, 580, 581, 583, 584, 585, 587, 588, 603, 623, 681, 682, 694, 695, 696, 697, 698, 699, 700, 701, 702, 704, 706, 707, 708, 709, 710, 745, 749, 750, 751, 752, 753, 754, 806, 807, 814, 837, 839, 840, 843, 846, 851, 871, 887, 888, 891, 893, 895, 910, 911, 912, 913, 914, 915, 919, 920, 921, 922, 923, 930, 931, 932, 933, 935, 936, 939, 941, 942, 943, 944, 946, 947, 954, 955, 970, 971, 972, 974, 975, 976, 977, 978, 979, 980, 982, 986, 989, 991, 992, 993, 994, 995, 997, 999, 1000, 1006, 1014, 1015, 1016, 1019, 1021, 1022, 1024, 1025, 1027, 1036, 1062, 1065, 1069, 1070, 1078, 1086, 1087, 1089, 1105, 1114, 1118, 1123, 1124, 1125, 1126, 1127, 1128, 1131, 1132, 1133, 1134, 1135, 1136, 1139, 1141, 1142, 1143, 1145, 1146, 1147, 1149, 1154, 1157, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1187, 1188, 1189, 1190, 1191, 1192, 1194, 1196, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1215, 1216, 1226, 1228, 1255, 1256, 1257, 1258, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1289, 1291, 1308, 1309, 1311, 1314, 1317, 1326, 1330, 1331, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1405, 1406, 1408, 1409, 1412, 1413, 1414, 1415, 1417, 1418, 1419, 1420, 1441, 1449, 1460, 1462, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1476, 1477, 1478, 1480, 1494, 1495, 1496, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1523, 1526, 1529, 1531, 1538, 1541, 1542, 1543, 1544, 1545, 1550, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1576, 1577, 1578, 1580, 1581, 1586, 1587, 1588, 1596, 1620, 1624, 1628, 1632, 1634, 1635, 1643, 1684, 1686, 1723, 1738, 1760, 1763, 1764, 1770, 1793, 1795, 1799, 1800, 1804, 1807, 1813, 1822, 1826, 1828, 1831, 1832, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1865, 1877, 1880, 1881, 1885, 1886, 1889, 1890, 1892, 1893, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1912, 1913, 1914, 1921, 1923, 1928, 1932, 1943, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1960, 1965, 1968, 1970, 1971, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 1983, 1984, 1986, 1987, 1988, 1989, 1990, 1991, 1993, 1994, 2002, 2008, 2009, 2010, 2011, 2013, 2014, 2015, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2026, 2029, 2033, 2040, 2041, 2045, 2046, 2047, 2048, 2055, 2057, 2060, 2061, 2084, 2087, 2089, 2090, 2091, 2094, 2095, 2096, 2098, 2100, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2141, 2146, 2147, 2150, 2154, 2156, 2157, 2158, 2159, 2161, 2162, 2164, 2165, 2166, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2189, 2192, 2193, 2194, 2198, 2203, 2204, 2206, 2210], "respect": [1, 2, 6, 9, 19, 30, 31, 32, 34, 35, 36, 39, 41, 49, 51, 58, 60, 66, 68, 69, 88, 196, 209, 487, 580, 603, 623, 700, 701, 702, 771, 808, 837, 871, 915, 921, 923, 935, 936, 944, 950, 954, 955, 997, 1027, 1057, 1132, 1134, 1135, 1201, 1203, 1204, 1205, 1206, 1207, 1208, 1212, 1268, 1314, 1346, 1350, 1351, 1360, 1370, 1373, 1375, 1378, 1387, 1419, 1470, 1492, 1493, 1499, 1510, 1511, 1512, 1516, 1531, 1533, 1550, 1580, 1581, 1596, 1626, 1628, 1629, 1630, 1631, 1633, 1677, 1686, 1795, 1799, 1801, 1822, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1874, 1877, 1966, 1970, 1994, 2013, 2116, 2122, 2126, 2127, 2130, 2133, 2138, 2142, 2143, 2164, 2171, 2172, 2173, 2178, 2194, 2198], "follow": [1, 2, 3, 4, 6, 8, 10, 13, 14, 16, 17, 20, 23, 24, 25, 26, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 48, 49, 50, 51, 52, 56, 57, 58, 60, 62, 64, 65, 67, 69, 71, 73, 79, 80, 487, 488, 617, 681, 771, 790, 796, 805, 806, 807, 815, 829, 830, 831, 832, 837, 839, 840, 841, 843, 846, 884, 891, 892, 919, 920, 921, 928, 935, 936, 954, 955, 969, 986, 991, 995, 1004, 1007, 1014, 1019, 1041, 1086, 1101, 1144, 1162, 1164, 1188, 1198, 1211, 1228, 1238, 1268, 1314, 1315, 1324, 1328, 1335, 1346, 1357, 1367, 1370, 1371, 1384, 1387, 1406, 1409, 1414, 1484, 1493, 1499, 1515, 1523, 1526, 1531, 1550, 1580, 1596, 1612, 1628, 1632, 1639, 1691, 1705, 1738, 1762, 1763, 1764, 1767, 1768, 1770, 1776, 1778, 1779, 1780, 1787, 1827, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1855, 1856, 1857, 1858, 1859, 1860, 1869, 1872, 1877, 1882, 1893, 1921, 1928, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1968, 1969, 1970, 1971, 1979, 1990, 1995, 2018, 2026, 2033, 2036, 2078, 2091, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2102, 2103, 2106, 2107, 2114, 2115, 2116, 2117, 2118, 2122, 2124, 2126, 2127, 2128, 2129, 2130, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2142, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2154, 2156, 2157, 2158, 2159, 2161, 2162, 2164, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2175, 2177, 2178, 2183, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2202, 2204, 2205, 2206, 2207, 2210], "describ": [1, 6, 8, 9, 10, 25, 26, 30, 32, 35, 37, 38, 41, 43, 45, 49, 51, 56, 57, 58, 69, 233, 513, 805, 806, 807, 830, 831, 832, 871, 889, 987, 1067, 1086, 1104, 1144, 1268, 1335, 1375, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1517, 1518, 1519, 1520, 1521, 1524, 1526, 1527, 1528, 1534, 1537, 1540, 1542, 1543, 1544, 1546, 1552, 1571, 1573, 1574, 1575, 1586, 1587, 1594, 1595, 1599, 1612, 1620, 1628, 1629, 1630, 1632, 1669, 1681, 1682, 1691, 1725, 1769, 1872, 2018, 2092, 2093, 2095, 2096, 2104, 2117, 2122, 2124, 2126, 2127, 2130, 2132, 2133, 2135, 2138, 2140, 2141, 2142, 2147, 2151, 2154, 2158, 2159, 2161, 2164, 2167, 2168, 2170, 2178, 2192, 2195, 2196, 2200, 2204], "part": [1, 2, 4, 5, 6, 7, 8, 10, 16, 17, 20, 25, 26, 30, 32, 36, 39, 51, 52, 56, 57, 58, 60, 64, 65, 69, 871, 944, 1009, 1016, 1144, 1218, 1304, 1306, 1307, 1310, 1314, 1325, 1327, 1330, 1331, 1345, 1351, 1353, 1362, 1369, 1372, 1580, 1620, 1738, 1770, 1771, 1791, 1863, 1877, 1893, 1905, 1975, 2018, 2021, 2022, 2023, 2024, 2091, 2092, 2093, 2095, 2096, 2106, 2107, 2126, 2127, 2130, 2133, 2135, 2136, 2138, 2142, 2147, 2154, 2158, 2161, 2166, 2167, 2168, 2171, 2176, 2178, 2184, 2190, 2192, 2194, 2195, 2196, 2202, 2203, 2204, 2205], "expos": [1, 2, 9, 21, 30, 34, 35, 37, 42, 60, 68, 69, 808, 1198, 2117, 2127, 2130, 2140, 2158, 2161, 2192, 2206], "namespac": [1, 69, 1119, 2093, 2097, 2100, 2133, 2142, 2164, 2183, 2193, 2204, 2206], "below": [1, 2, 6, 10, 14, 16, 25, 26, 30, 32, 34, 36, 38, 39, 41, 43, 48, 51, 52, 54, 55, 57, 58, 69, 71, 79, 80, 681, 745, 759, 768, 808, 829, 1086, 1131, 1132, 1133, 1134, 1135, 1144, 1172, 1174, 1178, 1221, 1232, 1258, 1268, 1314, 1331, 1371, 1372, 1377, 1384, 1416, 1510, 1511, 1512, 1531, 1533, 1540, 1550, 1552, 1576, 1577, 1578, 1580, 1596, 1612, 1633, 1669, 1695, 1742, 1770, 1793, 1826, 1838, 1860, 1877, 1878, 1933, 1936, 1973, 2008, 2018, 2021, 2022, 2023, 2024, 2093, 2095, 2096, 2098, 2102, 2103, 2114, 2115, 2117, 2126, 2127, 2130, 2132, 2133, 2138, 2139, 2142, 2144, 2146, 2147, 2149, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2163, 2166, 2167, 2168, 2172, 2173, 2175, 2178, 2185, 2186, 2189, 2190, 2191, 2193, 2195, 2196, 2197, 2198, 2200, 2202, 2204, 2205], "do": [1, 2, 5, 8, 9, 10, 13, 16, 17, 25, 26, 30, 32, 34, 35, 36, 37, 38, 40, 41, 44, 51, 52, 54, 56, 58, 60, 61, 62, 65, 66, 68, 69, 495, 513, 515, 517, 769, 842, 851, 893, 922, 925, 930, 933, 935, 936, 945, 949, 956, 958, 988, 1001, 1002, 1004, 1014, 1034, 1037, 1078, 1089, 1123, 1124, 1125, 1126, 1195, 1196, 1198, 1207, 1215, 1218, 1226, 1228, 1238, 1255, 1277, 1301, 1311, 1314, 1317, 1326, 1330, 1360, 1378, 1387, 1394, 1404, 1406, 1415, 1466, 1476, 1488, 1498, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1536, 1537, 1538, 1566, 1599, 1600, 1601, 1608, 1623, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1688, 1690, 1705, 1760, 1770, 1779, 1780, 1828, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1880, 1886, 1936, 2033, 2091, 2093, 2094, 2096, 2098, 2100, 2104, 2105, 2114, 2115, 2116, 2117, 2126, 2127, 2128, 2130, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2150, 2154, 2157, 2159, 2161, 2162, 2166, 2168, 2171, 2172, 2173, 2174, 2175, 2176, 2178, 2185, 2189, 2191, 2192, 2194, 2197, 2200, 2201, 2203, 2204, 2205, 2207], "defin": [1, 2, 4, 6, 10, 13, 16, 17, 25, 26, 30, 31, 32, 34, 36, 37, 38, 39, 41, 43, 45, 49, 51, 52, 56, 57, 58, 60, 65, 69, 415, 435, 445, 447, 449, 517, 566, 805, 811, 812, 814, 816, 817, 866, 889, 890, 891, 892, 919, 920, 921, 922, 935, 936, 1041, 1101, 1127, 1144, 1145, 1164, 1192, 1199, 1228, 1256, 1258, 1274, 1276, 1277, 1303, 1314, 1320, 1337, 1344, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1360, 1361, 1364, 1366, 1367, 1371, 1372, 1373, 1375, 1377, 1378, 1384, 1386, 1420, 1516, 1521, 1527, 1528, 1535, 1536, 1537, 1538, 1545, 1547, 1548, 1549, 1580, 1586, 1599, 1614, 1616, 1621, 1623, 1640, 1641, 1651, 1686, 1738, 1744, 1760, 1763, 1770, 1799, 1801, 1807, 1808, 1828, 1831, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1865, 1869, 1872, 1877, 1892, 1901, 1903, 1905, 1912, 1940, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1970, 1972, 1974, 2018, 2021, 2022, 2023, 2024, 2048, 2089, 2091, 2093, 2096, 2098, 2100, 2112, 2113, 2114, 2115, 2117, 2120, 2122, 2127, 2130, 2132, 2136, 2138, 2139, 2141, 2142, 2144, 2148, 2154, 2157, 2158, 2159, 2161, 2164, 2166, 2171, 2172, 2173, 2177, 2178, 2180, 2189, 2190, 2192, 2194, 2196, 2201, 2206], "still": [1, 2, 3, 8, 9, 25, 29, 30, 36, 39, 41, 56, 60, 68, 69, 486, 807, 814, 930, 932, 935, 940, 954, 1004, 1014, 1227, 1228, 1318, 1324, 1332, 1546, 1571, 1770, 1771, 1772, 1773, 1774, 1924, 2093, 2096, 2114, 2115, 2116, 2117, 2126, 2127, 2130, 2132, 2133, 2135, 2136, 2139, 2147, 2148, 2154, 2157, 2158, 2161, 2166, 2167, 2168, 2171, 2189, 2192, 2194, 2199, 2200, 2204, 2205, 2207], "chang": [1, 2, 3, 4, 8, 13, 14, 20, 21, 26, 30, 32, 34, 35, 36, 37, 38, 39, 41, 50, 56, 57, 58, 60, 61, 64, 65, 67, 68, 69, 70, 139, 233, 254, 321, 458, 496, 499, 517, 520, 556, 617, 681, 837, 907, 949, 950, 1002, 1004, 1019, 1020, 1021, 1036, 1037, 1049, 1062, 1065, 1078, 1079, 1086, 1087, 1089, 1132, 1180, 1196, 1201, 1222, 1237, 1241, 1261, 1268, 1289, 1311, 1314, 1325, 1326, 1345, 1356, 1358, 1359, 1360, 1363, 1376, 1416, 1449, 1519, 1522, 1540, 1550, 1580, 1612, 1633, 1639, 1640, 1641, 1644, 1651, 1686, 1695, 1711, 1712, 1713, 1738, 1760, 1761, 1770, 1773, 1774, 1779, 1780, 1790, 1793, 1794, 1822, 1826, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1865, 1869, 1870, 1872, 1874, 1876, 1877, 1892, 1932, 1936, 1973, 1985, 1988, 1989, 1990, 2017, 2036, 2040, 2041, 2055, 2057, 2091, 2092, 2093, 2100, 2102, 2103, 2104, 2109, 2114, 2115, 2116, 2117, 2121, 2122, 2126, 2127, 2128, 2129, 2130, 2133, 2134, 2136, 2138, 2139, 2142, 2144, 2145, 2147, 2154, 2157, 2158, 2159, 2161, 2162, 2166, 2168, 2171, 2173, 2174, 2175, 2176, 2177, 2180, 2181, 2182, 2185, 2189, 2191, 2192, 2194, 2196, 2197, 2200, 2201, 2205], "which": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 25, 26, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 44, 49, 50, 51, 52, 54, 56, 57, 60, 64, 65, 68, 69, 71, 79, 80, 87, 150, 258, 289, 313, 315, 317, 319, 321, 335, 472, 486, 487, 499, 513, 515, 517, 537, 560, 604, 607, 617, 625, 693, 695, 708, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 771, 775, 792, 803, 804, 811, 814, 842, 851, 866, 884, 887, 888, 889, 891, 895, 906, 910, 915, 922, 923, 925, 935, 936, 938, 939, 940, 941, 942, 943, 944, 954, 955, 962, 973, 986, 989, 992, 996, 1002, 1004, 1014, 1019, 1025, 1026, 1027, 1036, 1037, 1051, 1052, 1053, 1054, 1055, 1056, 1069, 1070, 1071, 1101, 1103, 1109, 1110, 1120, 1122, 1127, 1131, 1132, 1133, 1134, 1135, 1144, 1160, 1165, 1168, 1172, 1175, 1178, 1183, 1184, 1185, 1186, 1187, 1192, 1195, 1201, 1202, 1205, 1206, 1207, 1208, 1209, 1213, 1216, 1217, 1218, 1226, 1227, 1228, 1232, 1238, 1242, 1251, 1255, 1258, 1277, 1289, 1299, 1305, 1311, 1312, 1314, 1315, 1317, 1320, 1324, 1325, 1326, 1330, 1347, 1350, 1351, 1360, 1364, 1366, 1367, 1370, 1371, 1375, 1377, 1378, 1380, 1383, 1384, 1386, 1392, 1408, 1415, 1420, 1466, 1472, 1475, 1476, 1482, 1483, 1484, 1486, 1487, 1488, 1490, 1491, 1494, 1495, 1496, 1499, 1508, 1509, 1511, 1512, 1515, 1516, 1523, 1530, 1531, 1540, 1542, 1543, 1544, 1545, 1547, 1548, 1549, 1550, 1552, 1566, 1570, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1585, 1586, 1595, 1609, 1612, 1614, 1616, 1620, 1624, 1629, 1630, 1644, 1668, 1685, 1686, 1688, 1695, 1698, 1705, 1724, 1725, 1738, 1744, 1745, 1753, 1760, 1769, 1770, 1779, 1780, 1787, 1789, 1790, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1810, 1822, 1824, 1827, 1833, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1882, 1894, 1908, 1912, 1914, 1915, 1919, 1921, 1928, 1932, 1936, 1940, 1941, 1942, 1948, 1960, 1965, 1969, 1970, 1972, 1973, 1982, 1985, 1990, 1995, 2002, 2005, 2012, 2017, 2018, 2021, 2022, 2023, 2024, 2028, 2029, 2032, 2033, 2045, 2060, 2061, 2062, 2078, 2088, 2091, 2093, 2095, 2096, 2098, 2100, 2102, 2103, 2104, 2106, 2107, 2108, 2109, 2114, 2116, 2117, 2122, 2124, 2126, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2144, 2146, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2162, 2164, 2165, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2181, 2182, 2183, 2184, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2198, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210], "unlist": 1, "downstream": [1, 4, 1004, 2109, 2195, 2196, 2205], "stabl": [1, 2, 3, 13, 14, 30, 39, 51, 52, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 906, 1019, 1144, 1350, 1351, 1355, 1360, 1368, 1372, 1375, 1378, 1380, 1387, 1493, 1965, 2092, 2094, 2100, 2122, 2124, 2125, 2128, 2146, 2157, 2166, 2189], "believ": [1, 9, 2195, 2204], "unstabl": [1, 39, 1350, 1351, 1378, 1395, 1404, 1705, 1994, 2172], "__matmul__": 1, "addbmm": [1, 100, 970, 2094, 2145, 2155], "addmv": [1, 108, 2094, 2115, 2155], "addr": [1, 30, 45, 51, 110, 2094, 2155, 2207], "baddbmm": [1, 152, 2094, 2145, 2155], "bmm": [1, 2033, 2094, 2115, 2145, 2146, 2155, 2171, 2199], "chain_matmul": [1, 2094, 2155], "multi_dot": [1, 992], "conv1d": [1, 719, 723, 726, 736, 752, 834, 1510, 1518, 1556, 2033, 2094, 2155, 2161, 2163], "conv2d": [1, 56, 720, 724, 727, 729, 737, 753, 805, 829, 834, 1314, 1324, 1326, 1330, 1331, 1511, 1519, 1557, 1580, 1581, 1587, 1609, 1632, 1779, 1807, 1877, 2033, 2093, 2094, 2106, 2149, 2154, 2155, 2161, 2163, 2164, 2176, 2182], "conv3d": [1, 721, 725, 728, 730, 738, 754, 1512, 1520, 1558, 1780, 2033, 2094, 2155, 2161, 2163], "conv_transpose1d": [1, 2094, 2155, 2163], "conv_transpose2d": [1, 2094, 2155, 2163], "conv_transpose3d": [1, 2094, 2155, 2163], "grucel": [1, 2145, 2161, 2163, 2164], "lstmcell": [1, 2145, 2161, 2163, 2164], "matmul": [1, 3, 6, 13, 982, 1002, 1212, 1419, 1632, 1882, 1892, 1936, 1994, 2094, 2111, 2115, 2130, 2145, 2155, 2163, 2171, 2189], "mv": [1, 13, 1326, 2033, 2094, 2115, 2155, 2171], "prelu": [1, 1581, 2094, 2155, 2163], "rnncell": [1, 2161, 2163, 2164], "__pow__": 1, "__rdiv__": 1, "__rpow__": 1, "__rtruediv__": 1, "aco": [1, 94, 628, 629, 896, 2094, 2115, 2155, 2178, 2199], "asin": [1, 141, 630, 631, 898, 2094, 2115, 2155, 2171, 2199], "cosh": [1, 203, 638, 639, 695, 2094, 2115, 2155, 2199], "cosine_embedding_loss": [1, 2094, 2155], "cdist": [1, 2130, 2155], "cosine_similar": [1, 1630, 2094, 2155], "cross_entropi": [1, 38, 2094], "cumprod": [1, 213, 2094, 2115, 2155], "cumsum": [1, 215, 1127, 2033, 2094, 2115, 2155, 2199], "dist": [1, 26, 30, 31, 35, 36, 39, 52, 60, 993, 994, 995, 1344, 1350, 1351, 1352, 1354, 1355, 1356, 1360, 1361, 1372, 1373, 1376, 1378, 1379, 1402, 1405, 1589, 1620, 1770, 1787, 1994, 2094, 2130, 2132, 2155, 2166, 2168], "erfinv": [1, 251, 2094, 2115, 2155, 2171, 2172], "exp": [1, 2, 39, 253, 644, 645, 781, 940, 941, 943, 1187, 1374, 1394, 1402, 1493, 1498, 1515, 1521, 1545, 1569, 1570, 1584, 1594, 1608, 1611, 1613, 1614, 1616, 1617, 1621, 1660, 1706, 1730, 1739, 1740, 1744, 1746, 1749, 1787, 1889, 1949, 1950, 1972, 1990, 2094, 2115, 2127, 2154, 2155, 2172, 2199], "expm1": [1, 257, 646, 647, 2094, 2115, 2155, 2171, 2172, 2199], "group_norm": [1, 2094, 2155, 2163], "hinge_embedding_loss": [1, 2094, 2155], "kl_div": [1, 2094, 2155], "l1_loss": [1, 2094, 2155], "layer_norm": [1, 1552, 2094, 2155, 2163], "log": [1, 3, 16, 25, 26, 27, 39, 41, 44, 45, 48, 49, 376, 377, 654, 661, 681, 1154, 1390, 1392, 1394, 1395, 1402, 1434, 1484, 1492, 1493, 1515, 1533, 1545, 1569, 1570, 1584, 1587, 1594, 1613, 1614, 1617, 1683, 1688, 1698, 1705, 1706, 1722, 1730, 1744, 1746, 1770, 2094, 2102, 2109, 2111, 2115, 2127, 2130, 2132, 2133, 2150, 2154, 2155, 2159, 2172, 2176, 2180, 2181, 2182, 2189, 2197, 2198, 2199, 2201, 2202, 2205], "log_softmax": [1, 1499, 1545, 1587, 1670, 1722, 1744, 2094, 2116, 2155, 2172], "log10": [1, 371, 655, 656, 2094, 2115, 2155, 2199], "log1p": [1, 373, 657, 658, 2094, 2115, 2155, 2171, 2172, 2199], "log2": [1, 375, 659, 660, 2094, 2115, 2155, 2172, 2199], "margin_ranking_loss": [1, 2094, 2155], "mse_loss": [1, 64, 1201, 2094, 2155], "multilabel_margin_loss": [1, 2094, 2155], "multi_margin_loss": [1, 2094, 2155], "nll_loss": [1, 2094, 2155], "norm": [1, 36, 38, 39, 60, 62, 69, 713, 714, 715, 716, 717, 718, 990, 1138, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1346, 1350, 1359, 1360, 1367, 1372, 1384, 1522, 1523, 1571, 1589, 1625, 1626, 1627, 1628, 1629, 1677, 1678, 1723, 1727, 1775, 1776, 1778, 1785, 1788, 1789, 1798, 1799, 1804, 1806, 1807, 1821, 1824, 1842, 1913, 2094, 2098, 2126, 2127, 2138, 2142, 2145, 2155], "normal": [1, 2, 21, 26, 30, 35, 37, 51, 56, 58, 60, 69, 336, 351, 377, 454, 556, 1014, 1027, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1228, 1276, 1311, 1314, 1319, 1350, 1392, 1488, 1494, 1495, 1496, 1518, 1519, 1520, 1524, 1534, 1542, 1543, 1544, 1552, 1562, 1563, 1564, 1568, 1595, 1608, 1620, 1624, 1625, 1626, 1627, 1628, 1656, 1686, 1687, 1696, 1700, 1704, 1731, 1735, 1769, 1776, 1777, 1778, 1785, 1788, 1789, 1804, 1811, 1812, 1821, 1824, 1857, 1874, 1877, 1896, 1905, 1906, 1913, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1990, 2033, 2091, 2093, 2094, 2098, 2100, 2115, 2124, 2127, 2130, 2133, 2134, 2137, 2154, 2155, 2158, 2163, 2166, 2172, 2176, 2178, 2180, 2188, 2199, 2204, 2210], "pdist": [1, 1589, 2094, 2155], "poisson_nll_loss": [1, 2094, 2155], "pow": [1, 2, 469, 496, 938, 939, 942, 965, 1187, 2094, 2096, 2115, 2126, 2127, 2155, 2171, 2177, 2199], "prod": [1, 48, 321, 517, 1161, 1163, 1166, 1167, 1169, 1170, 1173, 1174, 1176, 1177, 1179, 1181, 1380, 1381, 1522, 1526, 1632, 2031, 2033, 2094, 2115, 2155, 2171, 2195, 2199], "reciproc": [1, 485, 664, 665, 1923, 2094, 2115, 2155, 2199], "rsqrt": [1, 511, 2094, 2115, 2155, 2199], "sinh": [1, 536, 672, 673, 912, 2094, 2115, 2155, 2171, 2199], "smooth_l1_loss": [1, 2094, 2155], "soft_margin_loss": [1, 2094, 2155], "softmax": [1, 39, 809, 1484, 1515, 1545, 1570, 1615, 1669, 1688, 1698, 1705, 1738, 1745, 1969, 2094, 2115, 2116, 2122, 2130, 2155, 2163, 2171, 2172], "softmin": [1, 2094], "softplu": [1, 39, 1579, 1717, 2094, 2155], "sum": [1, 2, 4, 14, 25, 30, 31, 35, 37, 39, 41, 58, 60, 65, 66, 69, 71, 78, 85, 496, 517, 566, 693, 757, 923, 938, 939, 940, 941, 942, 943, 944, 954, 955, 963, 1027, 1053, 1054, 1055, 1056, 1126, 1127, 1144, 1205, 1206, 1207, 1212, 1291, 1346, 1367, 1371, 1384, 1392, 1393, 1394, 1402, 1466, 1474, 1492, 1493, 1499, 1512, 1513, 1515, 1516, 1523, 1526, 1533, 1539, 1540, 1545, 1546, 1547, 1548, 1549, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1614, 1616, 1629, 1630, 1632, 1658, 1659, 1669, 1670, 1678, 1683, 1688, 1695, 1698, 1707, 1708, 1709, 1718, 1722, 1730, 1744, 1745, 1770, 1804, 1808, 1809, 1827, 1839, 1865, 1914, 1936, 1951, 1970, 1972, 2016, 2018, 2033, 2094, 2096, 2100, 2109, 2115, 2117, 2122, 2126, 2127, 2130, 2132, 2133, 2134, 2142, 2145, 2150, 2154, 2155, 2166, 2167, 2171, 2172, 2173, 2177, 2189, 2190, 2192, 2193, 2195, 2199, 2202, 2204, 2205, 2207], "renorm": [1, 492, 1522, 1523, 1677, 1678, 2094, 2155], "tan": [1, 575, 676, 677, 913, 2094, 2115, 2155, 2171, 2176, 2199], "triplet_margin_loss": [1, 2094, 2155], "take": [1, 2, 3, 4, 5, 6, 8, 10, 16, 21, 25, 26, 30, 32, 35, 36, 37, 39, 41, 50, 51, 52, 54, 56, 60, 62, 63, 65, 66, 67, 68, 69, 71, 79, 80, 771, 806, 812, 829, 839, 851, 892, 938, 939, 940, 941, 942, 943, 949, 950, 958, 1036, 1080, 1132, 1134, 1135, 1160, 1162, 1165, 1168, 1172, 1173, 1175, 1178, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1238, 1347, 1369, 1372, 1484, 1493, 1523, 1527, 1528, 1531, 1550, 1574, 1575, 1576, 1577, 1578, 1580, 1588, 1596, 1624, 1634, 1635, 1681, 1682, 1699, 1724, 1738, 1770, 1825, 1857, 1861, 1877, 1889, 1995, 2020, 2034, 2045, 2091, 2093, 2094, 2096, 2100, 2103, 2104, 2106, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2139, 2141, 2142, 2146, 2147, 2148, 2150, 2154, 2155, 2158, 2159, 2161, 2166, 2167, 2168, 2171, 2174, 2175, 2176, 2179, 2181, 2185, 2189, 2190, 2191, 2193, 2194, 2195, 2196, 2198, 2202, 2203, 2204], "all": [1, 2, 3, 4, 6, 7, 8, 10, 13, 14, 16, 17, 19, 20, 21, 22, 25, 26, 30, 31, 32, 34, 35, 36, 37, 39, 41, 44, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 63, 65, 66, 68, 69, 86, 87, 88, 150, 260, 313, 315, 321, 335, 486, 488, 513, 515, 517, 546, 560, 607, 610, 617, 681, 693, 697, 698, 703, 705, 709, 710, 746, 771, 804, 806, 807, 829, 834, 867, 869, 870, 884, 888, 891, 904, 907, 919, 920, 921, 923, 925, 927, 930, 931, 932, 933, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 958, 962, 963, 964, 968, 969, 972, 981, 983, 988, 989, 993, 996, 997, 1001, 1002, 1004, 1013, 1014, 1019, 1026, 1035, 1039, 1040, 1041, 1045, 1053, 1054, 1066, 1075, 1080, 1086, 1090, 1091, 1100, 1101, 1109, 1110, 1112, 1113, 1117, 1119, 1120, 1161, 1162, 1163, 1164, 1167, 1170, 1171, 1174, 1177, 1179, 1181, 1196, 1198, 1201, 1202, 1208, 1209, 1211, 1212, 1218, 1228, 1229, 1235, 1255, 1277, 1280, 1310, 1311, 1314, 1322, 1325, 1326, 1329, 1330, 1350, 1377, 1386, 1402, 1404, 1407, 1412, 1414, 1417, 1426, 1427, 1440, 1443, 1445, 1464, 1471, 1472, 1473, 1474, 1484, 1491, 1493, 1497, 1499, 1501, 1502, 1503, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1522, 1523, 1526, 1531, 1532, 1533, 1534, 1539, 1545, 1546, 1550, 1551, 1567, 1571, 1575, 1576, 1577, 1578, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1590, 1591, 1596, 1598, 1602, 1603, 1604, 1605, 1606, 1607, 1620, 1624, 1626, 1628, 1629, 1632, 1637, 1638, 1644, 1651, 1657, 1659, 1677, 1678, 1683, 1688, 1707, 1708, 1709, 1738, 1744, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1776, 1787, 1793, 1800, 1804, 1813, 1817, 1825, 1826, 1827, 1828, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1865, 1869, 1870, 1873, 1874, 1875, 1876, 1877, 1878, 1890, 1929, 1936, 1968, 1972, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1987, 1988, 1989, 1990, 1993, 2012, 2014, 2021, 2022, 2023, 2024, 2027, 2029, 2030, 2031, 2036, 2040, 2041, 2043, 2047, 2050, 2052, 2058, 2065, 2071, 2072, 2078, 2082, 2083, 2086, 2088, 2091, 2093, 2094, 2095, 2096, 2100, 2102, 2103, 2104, 2106, 2108, 2109, 2114, 2115, 2116, 2117, 2122, 2124, 2126, 2127, 2129, 2130, 2132, 2134, 2135, 2136, 2137, 2138, 2139, 2142, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2155, 2158, 2159, 2161, 2165, 2166, 2167, 2168, 2170, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2182, 2184, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2209], "addcdiv": [1, 102, 2094, 2155], "addcmul": [1, 104, 2094, 2155], "atan2": [1, 146, 901, 2094, 2115, 2155, 2199], "bilinear": [1, 790, 796, 797, 1144, 1633, 1634, 1686, 1697, 1757, 1758, 2033, 2094, 2155], "cross": [1, 8, 9, 30, 32, 36, 38, 39, 41, 1492, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1658, 1659, 1669, 2094, 2122, 2130, 2148, 2155, 2184, 2189], "dot": [1, 3, 16, 65, 66, 617, 939, 941, 942, 943, 1123, 1124, 1125, 1126, 1203, 1213, 1291, 1335, 1382, 1383, 1409, 1492, 1493, 1515, 1526, 1539, 1546, 1571, 1586, 1587, 1630, 1639, 1644, 1738, 1990, 2042, 2043, 2044, 2045, 2094, 2115, 2117, 2122, 2138, 2155, 2158], "grid_sampl": [1, 1651, 2033, 2094, 2155], "index_put": [1, 2033, 2094, 2155, 2199], "scatter_add": [1, 2094, 2155, 2199], "tensordot": [1, 1291, 1380, 1381, 2098, 2130, 2155], "binari": [1, 3, 16, 17, 26, 39, 41, 44, 49, 51, 69, 154, 746, 972, 1408, 1492, 1493, 1586, 1658, 1659, 1797, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1834, 2005, 2092, 2097, 2115, 2116, 2117, 2140, 2141, 2154, 2158, 2176, 2185], "add": [1, 2, 4, 8, 14, 17, 19, 25, 30, 32, 35, 36, 42, 48, 56, 57, 58, 60, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 98, 290, 313, 513, 515, 697, 698, 699, 702, 758, 759, 768, 803, 806, 866, 867, 889, 891, 892, 958, 965, 1004, 1014, 1054, 1089, 1101, 1144, 1202, 1221, 1227, 1228, 1234, 1314, 1326, 1484, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1556, 1557, 1558, 1559, 1560, 1561, 1580, 1582, 1586, 1587, 1591, 1594, 1688, 1730, 1760, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 1877, 1936, 1986, 2005, 2078, 2091, 2093, 2094, 2095, 2096, 2100, 2106, 2109, 2113, 2115, 2117, 2126, 2128, 2129, 2132, 2133, 2134, 2139, 2140, 2142, 2144, 2147, 2149, 2154, 2155, 2157, 2158, 2159, 2161, 2162, 2163, 2164, 2166, 2167, 2168, 2171, 2174, 2175, 2176, 2181, 2182, 2189, 2190, 2191, 2192, 2193, 2195, 2196, 2198, 2199, 2202, 2203, 2204, 2205, 2206, 2207], "nativ": [1, 13, 26, 37, 60, 69, 1067, 1325, 1776, 1777, 1778, 1785, 1936, 2093, 2096, 2114, 2117, 2130, 2137, 2147, 2149, 2157, 2158, 2166, 2195], "without": [1, 2, 4, 6, 8, 9, 10, 16, 20, 25, 26, 30, 31, 32, 34, 35, 36, 38, 39, 44, 56, 58, 60, 61, 66, 68, 69, 70, 71, 72, 233, 254, 486, 488, 617, 999, 1002, 1040, 1084, 1165, 1166, 1167, 1175, 1176, 1177, 1228, 1237, 1238, 1254, 1311, 1312, 1314, 1315, 1361, 1362, 1377, 1384, 1466, 1494, 1495, 1496, 1519, 1523, 1542, 1543, 1544, 1577, 1580, 1588, 1620, 1628, 1678, 1760, 1770, 1797, 1820, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1877, 1899, 1915, 1932, 2027, 2091, 2095, 2096, 2100, 2103, 2104, 2106, 2109, 2114, 2116, 2117, 2121, 2126, 2127, 2128, 2130, 2132, 2133, 2138, 2139, 2142, 2144, 2146, 2147, 2150, 2158, 2161, 2165, 2166, 2171, 2173, 2176, 2182, 2186, 2189, 2191, 2192, 2193, 2194, 2195, 2204, 2205, 2209, 2210], "intervent": [1, 9, 36, 2166], "mixtur": [1, 39, 1515, 1669], "bceloss": [1, 1493, 1658], "aren": [1, 9, 56, 65, 69, 1202, 1228, 2115, 2127, 2136, 2167, 2206], "mean": [1, 3, 4, 6, 8, 9, 14, 17, 20, 21, 25, 26, 30, 32, 34, 35, 37, 38, 39, 51, 52, 54, 56, 57, 58, 60, 61, 63, 66, 68, 69, 254, 258, 321, 335, 377, 454, 488, 495, 517, 769, 771, 792, 807, 809, 891, 892, 958, 970, 983, 1014, 1019, 1027, 1201, 1203, 1237, 1238, 1325, 1415, 1438, 1466, 1471, 1475, 1476, 1482, 1483, 1484, 1486, 1487, 1488, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1513, 1515, 1517, 1521, 1523, 1524, 1525, 1529, 1530, 1531, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1550, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1566, 1567, 1569, 1570, 1571, 1572, 1579, 1583, 1584, 1585, 1587, 1588, 1594, 1595, 1596, 1599, 1600, 1601, 1608, 1610, 1611, 1612, 1613, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1629, 1630, 1631, 1657, 1658, 1659, 1667, 1669, 1670, 1678, 1679, 1683, 1694, 1695, 1698, 1699, 1703, 1710, 1718, 1719, 1720, 1721, 1722, 1730, 1735, 1742, 1743, 1754, 1755, 1769, 1770, 1782, 1784, 1828, 1860, 1896, 1905, 1906, 1936, 1949, 1970, 1988, 1989, 1995, 2033, 2040, 2041, 2091, 2093, 2094, 2095, 2109, 2110, 2111, 2114, 2115, 2116, 2122, 2124, 2126, 2127, 2130, 2132, 2133, 2135, 2136, 2138, 2142, 2148, 2150, 2154, 2155, 2157, 2158, 2159, 2161, 2162, 2163, 2166, 2167, 2168, 2171, 2173, 2186, 2189, 2191, 2192, 2194, 2195, 2198, 2199, 2200, 2201, 2204], "doesn": [1, 2, 3, 6, 8, 9, 13, 14, 21, 25, 30, 32, 37, 41, 49, 57, 63, 65, 68, 69, 842, 851, 910, 930, 931, 935, 944, 956, 1019, 1040, 1066, 1202, 1213, 1227, 1228, 1238, 1241, 1253, 1322, 1328, 1354, 1378, 1386, 1395, 1444, 1507, 1508, 1509, 1516, 1545, 1614, 1661, 1662, 1663, 1698, 1744, 1770, 1771, 1772, 1804, 1843, 1932, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1966, 1970, 2045, 2058, 2093, 2096, 2097, 2115, 2127, 2128, 2130, 2133, 2134, 2140, 2144, 2148, 2157, 2167, 2171, 2194, 2199, 2202, 2204, 2205], "help": [1, 2, 5, 8, 9, 13, 16, 22, 25, 26, 30, 34, 36, 48, 51, 58, 60, 65, 69, 949, 950, 962, 1066, 1101, 1202, 1203, 1213, 1217, 1227, 1228, 1314, 1315, 1334, 1416, 1433, 1434, 1518, 1519, 1520, 1524, 1580, 1787, 1837, 1877, 1942, 2045, 2058, 2091, 2096, 2100, 2103, 2104, 2115, 2116, 2117, 2126, 2127, 2128, 2130, 2132, 2134, 2139, 2142, 2145, 2147, 2150, 2158, 2166, 2167, 2171, 2180, 2192, 2194, 2197, 2198, 2202, 2204, 2205, 2209], "revers": [1, 34, 39, 66, 69, 513, 745, 806, 938, 940, 1162, 1164, 1184, 1205, 1207, 1212, 1382, 1550, 1593, 1729, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 2020, 2039, 2094, 2095, 2096, 2117, 2127, 2132, 2134, 2155, 2177], "therefor": [1, 4, 6, 25, 26, 30, 39, 40, 49, 60, 63, 71, 76, 77, 448, 544, 944, 971, 980, 1004, 1089, 1178, 1195, 1198, 1201, 1251, 1272, 1273, 1327, 1330, 1360, 1373, 1522, 1523, 1632, 1677, 1678, 1686, 1822, 1865, 2096, 2105, 2126, 2127, 2130, 2133, 2135, 2136, 2140, 2154, 2168, 2171, 2193, 2196], "rais": [1, 2, 6, 8, 16, 30, 32, 35, 36, 37, 39, 41, 44, 51, 56, 58, 60, 65, 68, 69, 71, 87, 233, 313, 315, 321, 684, 708, 924, 930, 933, 935, 938, 939, 940, 941, 942, 943, 944, 948, 949, 950, 957, 967, 969, 983, 992, 1002, 1014, 1015, 1043, 1057, 1115, 1187, 1192, 1245, 1312, 1314, 1319, 1322, 1330, 1332, 1344, 1346, 1354, 1355, 1358, 1362, 1363, 1368, 1375, 1376, 1380, 1381, 1386, 1407, 1438, 1580, 1738, 1763, 1793, 1794, 1799, 1801, 1804, 1813, 1833, 1834, 1877, 1930, 1933, 1979, 2033, 2091, 2097, 2100, 2103, 2114, 2122, 2127, 2130, 2133, 2135, 2145, 2150, 2156, 2158, 2165, 2166, 2170, 2178, 2185, 2186, 2191, 2194, 2195, 2203, 2204, 2205, 2206], "mani": [1, 4, 8, 13, 16, 21, 25, 26, 30, 39, 51, 60, 64, 65, 69, 87, 402, 681, 919, 921, 935, 936, 938, 940, 1144, 1238, 1327, 1499, 1860, 1961, 2014, 2021, 2022, 2023, 2024, 2093, 2095, 2104, 2115, 2124, 2127, 2128, 2129, 2130, 2133, 2134, 2140, 2142, 2145, 2149, 2154, 2157, 2161, 2168, 2171, 2173, 2174, 2176, 2177, 2180, 2189, 2190, 2191, 2192, 2194, 2195, 2197, 2198, 2200, 2203, 2204, 2205, 2207, 2208], "sigmoid": [1, 6, 39, 69, 527, 668, 669, 771, 808, 1492, 1493, 1522, 1531, 1532, 1550, 1551, 1610, 1658, 1685, 1741, 2094, 2115, 2116, 2124, 2150, 2155, 2163, 2172, 2185, 2186, 2199], "right": [1, 3, 8, 10, 16, 30, 32, 39, 56, 58, 60, 69, 839, 895, 971, 978, 980, 981, 986, 991, 995, 1138, 1144, 1185, 1188, 1189, 1193, 1268, 1272, 1273, 1277, 1281, 1311, 1334, 1359, 1364, 1375, 1377, 1378, 1386, 1392, 1393, 1466, 1484, 1489, 1490, 1491, 1492, 1493, 1507, 1508, 1509, 1526, 1533, 1546, 1547, 1548, 1549, 1568, 1569, 1570, 1571, 1573, 1574, 1575, 1583, 1584, 1585, 1589, 1590, 1597, 1629, 1632, 1633, 1634, 1635, 1640, 1641, 1642, 1686, 1706, 1725, 1777, 1793, 1817, 1843, 1863, 1864, 1908, 1928, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1974, 1990, 2013, 2018, 2020, 2036, 2039, 2091, 2094, 2096, 2114, 2115, 2116, 2127, 2133, 2138, 2154, 2157, 2164, 2168, 2172, 2192, 2193, 2194, 2202], "entropi": [1, 38, 39, 1492, 1515, 1584, 1658, 1659, 1669, 2172], "combin": [1, 4, 25, 26, 30, 32, 42, 51, 56, 66, 68, 617, 700, 723, 724, 725, 726, 727, 728, 729, 730, 806, 884, 920, 935, 1101, 1173, 1174, 1179, 1181, 1241, 1277, 1409, 1419, 1493, 1526, 1540, 1586, 1628, 1632, 1680, 1703, 1800, 2078, 2093, 2094, 2095, 2126, 2130, 2134, 2139, 2154, 2155, 2157, 2161, 2164, 2166, 2190, 2204], "two": [1, 2, 4, 5, 6, 7, 9, 13, 14, 16, 17, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 39, 48, 49, 52, 56, 57, 58, 60, 64, 65, 69, 583, 584, 585, 587, 588, 607, 617, 681, 703, 705, 771, 806, 810, 917, 920, 935, 936, 940, 949, 990, 992, 1041, 1048, 1092, 1094, 1123, 1124, 1132, 1141, 1144, 1150, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1190, 1191, 1201, 1211, 1224, 1227, 1236, 1239, 1276, 1278, 1303, 1312, 1314, 1325, 1328, 1335, 1338, 1340, 1345, 1347, 1350, 1351, 1356, 1357, 1362, 1367, 1370, 1371, 1373, 1374, 1376, 1378, 1383, 1386, 1409, 1412, 1415, 1417, 1420, 1473, 1490, 1492, 1493, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1526, 1531, 1539, 1540, 1546, 1548, 1550, 1571, 1572, 1574, 1580, 1583, 1584, 1585, 1587, 1588, 1594, 1596, 1612, 1613, 1628, 1629, 1630, 1632, 1640, 1641, 1658, 1659, 1669, 1688, 1698, 1705, 1722, 1730, 1738, 1787, 1789, 1793, 1814, 1824, 1826, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1864, 1865, 1868, 1872, 1877, 1893, 1908, 1921, 1936, 1973, 1979, 1994, 2013, 2017, 2018, 2020, 2029, 2038, 2042, 2046, 2073, 2074, 2091, 2093, 2095, 2096, 2100, 2102, 2103, 2104, 2115, 2116, 2117, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2142, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2161, 2162, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2181, 2182, 2184, 2186, 2189, 2190, 2191, 2192, 2194, 2199, 2202, 2204, 2205], "bcewithlogitsloss": [1, 1659], "bcewithlogit": 1, "safe": [1, 30, 32, 51, 56, 68, 69, 87, 486, 1090, 1091, 1112, 1113, 1241, 1770, 1836, 1837, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 2071, 2072, 2082, 2083, 2093, 2096, 2126, 2127, 2130, 2134, 2136, 2140, 2147, 2166, 2173, 2180, 2183, 2189, 2195, 2196, 2205], "share": [1, 8, 12, 16, 25, 31, 32, 35, 36, 39, 40, 51, 52, 57, 60, 65, 221, 311, 340, 458, 483, 520, 524, 617, 889, 909, 910, 930, 931, 935, 936, 949, 950, 1002, 1037, 1039, 1078, 1082, 1089, 1195, 1196, 1197, 1198, 1285, 1362, 1475, 1476, 1516, 1597, 1770, 1791, 1828, 1910, 1924, 1932, 1985, 2011, 2017, 2032, 2094, 2117, 2126, 2127, 2129, 2144, 2147, 2148, 2154, 2166, 2171, 2173, 2175, 2181, 2185, 2189, 2204], "linalg_vecdot": [1, 2094, 2155], "_convolut": [1, 2155], "conv_tbc": [1, 2094, 2155], "mkldnn_rnn_layer": [1, 2094, 2155], "scaled_dot_product_attent": [1, 3, 37, 1586, 1624, 1640, 1643, 1644, 2094, 2119, 2120, 2123, 2155], "_native_multi_head_attent": [1, 2155], "avg_pool3d": [1, 2094, 2155, 2163, 2199], "grid_sampler_2d": [1, 2094, 2155, 2199], "_grid_sampler_2d_cpu_fallback": [1, 2155], "grid_sampler_3d": [1, 2094, 2155], "polar": [1, 39, 1374, 2094, 2155], "quantil": [1, 1415, 1473, 2094, 2155, 2172], "nanquantil": [1, 2094, 2155], "stft": [1, 971, 980, 1272, 1273, 1311, 1334, 2094, 2150, 2154, 2155], "view_as_complex": [1, 13, 2094, 2155], "choleski": [1, 3, 39, 994, 995, 1345, 1351, 1387, 2094, 2155], "cholesky_invers": [1, 3, 2094, 2155], "cholesky_solv": [1, 3, 2094, 2155], "invers": [1, 39, 694, 695, 912, 915, 989, 994, 995, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1311, 1355, 1356, 1368, 1372, 1375, 1380, 1381, 1510, 1511, 1512, 1522, 1523, 1526, 1576, 1577, 1578, 1632, 1677, 1678, 1714, 1715, 1716, 1790, 1793, 1814, 1816, 1865, 1872, 2028, 2094, 2096, 2145, 2155, 2172], "lu_solv": [1, 3, 1362, 2094, 2155], "orgqr": [1, 2094, 2155], "ormqr": [1, 1258, 1354, 2094, 2155], "pinvers": [1, 1360, 2094, 2155], "max_pool3d": [1, 2094, 2155, 2163], "max_unpool2d": [1, 1681, 1712, 2094, 2155], "max_unpool3d": [1, 1682, 1713, 2094, 2155], "adaptive_avg_pool3d": [1, 2094, 2133, 2155, 2163], "reflection_pad1d": [1, 2094, 2155, 2199], "reflection_pad2d": [1, 2094, 2155, 2199], "replication_pad1d": [1, 2094, 2155], "replication_pad2d": [1, 2094, 2155, 2199], "replication_pad3d": [1, 2094, 2155, 2199], "nll_loss2d": [1, 2094, 2155], "cross_entropy_loss": [1, 2094, 2155], "huber_loss": [1, 2094, 2155], "ctc_loss": [1, 1499, 2094, 2155], "fft_fft": [1, 2094, 2155], "fft_ifft": [1, 2094, 2155], "fft_fft2": [1, 2094, 2155], "fft_ifft2": [1, 2094, 2155], "fft_fftn": [1, 2094, 2155], "fft_ifftn": [1, 2094, 2155], "fft_rfft": [1, 2094, 2155], "fft_irfft": [1, 2094, 2155], "fft_rfft2": [1, 2094, 2155], "fft_irfft2": [1, 2094, 2155], "fft_rfftn": [1, 2094, 2155], "fft_irfftn": [1, 2094, 2155], "fft_hfft": [1, 2094, 2155], "fft_ihfft": [1, 2094, 2155], "linalg_cond": [1, 2094, 2155], "linalg_matrix_rank": [1, 2094, 2155], "linalg_solv": [1, 2094, 2155], "linalg_choleski": [1, 2094, 2155], "linalg_svdv": [1, 2094, 2155], "linalg_eigv": [1, 2094, 2155], "linalg_eigvalsh": [1, 2094, 2155], "linalg_inv": [1, 2094, 2155], "linalg_householder_product": [1, 2094, 2155], "linalg_tensorinv": [1, 2094, 2155], "linalg_tensorsolv": [1, 2094, 2155], "fake_quantize_per_tensor_affin": [1, 2094, 2155], "geqrf": [1, 1354, 1880, 2094, 2155], "_lu_with_info": [1, 2155], "qr": [1, 3, 1258, 1350, 1351, 1354, 1360, 1378, 1787, 1880, 2094, 2155], "svd": [1, 3, 13, 1350, 1351, 1360, 1372, 1379, 1395, 1793, 1882, 1995, 2094, 2145, 2155, 2171, 2199], "triangular_solv": [1, 2094, 2155], "fractional_max_pool2d": [1, 2094, 2155], "fractional_max_pool3d": [1, 2094, 2155], "adaptive_max_pool3d": [1, 2094, 2155], "multilabel_margin_loss_forward": [1, 2155], "linalg_qr": [1, 2094, 2155], "linalg_cholesky_ex": [1, 2094, 2155], "linalg_svd": [1, 2094, 2155], "linalg_eig": [1, 2094, 2155], "linalg_eigh": [1, 2094, 2155], "linalg_lstsq": [1, 2094, 2155], "linalg_inv_ex": [1, 2094, 2155], "cat": [1, 30, 39, 58, 69, 544, 758, 759, 768, 806, 809, 1017, 1018, 1416, 1600, 1975, 1987, 2093, 2094, 2115, 2117, 2154, 2155, 2158, 2161, 2163, 2171, 2181, 2191, 2199], "stack": [1, 9, 20, 25, 26, 27, 30, 39, 44, 51, 56, 57, 64, 65, 69, 681, 771, 962, 989, 1000, 1004, 1106, 1107, 1143, 1211, 1213, 1218, 1228, 1280, 1416, 1499, 1531, 1550, 1551, 1596, 1625, 1627, 1817, 2035, 2045, 2047, 2094, 2100, 2117, 2122, 2130, 2132, 2135, 2137, 2147, 2155, 2158, 2159, 2163, 2171, 2184, 2192, 2193, 2194, 2195, 2202, 2204, 2205, 2207, 2208, 2209], "index_copi": [1, 2033, 2094, 2155], "implement": [2, 3, 6, 9, 13, 14, 18, 19, 21, 25, 26, 30, 31, 32, 34, 35, 37, 38, 39, 43, 48, 49, 52, 56, 60, 65, 69, 150, 415, 513, 515, 517, 698, 749, 750, 751, 752, 753, 754, 771, 790, 792, 796, 806, 815, 837, 839, 840, 843, 846, 851, 908, 910, 923, 939, 949, 950, 1019, 1025, 1144, 1187, 1192, 1198, 1205, 1206, 1208, 1209, 1314, 1320, 1322, 1324, 1325, 1328, 1370, 1373, 1386, 1387, 1415, 1484, 1499, 1516, 1531, 1534, 1547, 1548, 1549, 1552, 1580, 1586, 1592, 1595, 1596, 1597, 1600, 1617, 1626, 1628, 1686, 1691, 1725, 1738, 1746, 1769, 1770, 1776, 1777, 1778, 1785, 1787, 1788, 1793, 1804, 1816, 1820, 1821, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1863, 1865, 1872, 1877, 1892, 1899, 1912, 1921, 1924, 1948, 1960, 1970, 1994, 1995, 2013, 2029, 2033, 2034, 2036, 2095, 2096, 2097, 2100, 2103, 2104, 2112, 2113, 2114, 2117, 2118, 2122, 2124, 2126, 2127, 2129, 2130, 2133, 2134, 2135, 2140, 2142, 2144, 2145, 2146, 2147, 2148, 2157, 2158, 2161, 2166, 2167, 2171, 2172, 2175, 2177, 2189, 2191, 2193, 2195, 2200, 2202, 2206], "arbitrari": [2, 4, 30, 35, 36, 56, 71, 74, 79, 254, 920, 935, 1127, 1228, 1378, 1386, 1516, 1522, 1546, 1571, 1632, 1658, 1659, 1677, 1698, 1725, 1813, 1994, 2018, 2031, 2096, 2102, 2104, 2122, 2127, 2134, 2140, 2142, 2147, 2157, 2161, 2171, 2180, 2192, 2195, 2200, 2205, 2206], "scalar": [2, 14, 30, 37, 39, 57, 71, 80, 97, 150, 154, 260, 313, 446, 513, 589, 698, 699, 749, 750, 751, 752, 753, 754, 909, 910, 923, 938, 939, 942, 944, 975, 978, 986, 1023, 1027, 1139, 1144, 1159, 1192, 1199, 1268, 1275, 1291, 1305, 1339, 1340, 1409, 1416, 1473, 1484, 1492, 1493, 1499, 1513, 1515, 1516, 1533, 1539, 1540, 1545, 1546, 1552, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1630, 1683, 1688, 1731, 1826, 1831, 1832, 1833, 1874, 1889, 1891, 1893, 1911, 1912, 1928, 1977, 1978, 1979, 1980, 1981, 2011, 2029, 2030, 2048, 2089, 2090, 2094, 2095, 2096, 2109, 2122, 2124, 2127, 2133, 2138, 2141, 2154, 2166, 2171, 2174, 2176, 2178, 2192, 2194, 2195, 2199, 2203], "minim": [2, 8, 9, 837, 905, 1014, 1417, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1874, 2091, 2109, 2126, 2130, 2142, 2144, 2147, 2150, 2161, 2186, 2195, 2202, 2204, 2205], "exist": [2, 8, 9, 10, 13, 16, 25, 30, 31, 32, 37, 39, 41, 42, 44, 49, 51, 52, 57, 60, 64, 67, 69, 71, 254, 499, 805, 884, 908, 938, 939, 940, 941, 942, 943, 944, 949, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1057, 1084, 1227, 1240, 1241, 1251, 1314, 1318, 1330, 1350, 1355, 1361, 1362, 1387, 1473, 1580, 1581, 1590, 1640, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1877, 1968, 1987, 2036, 2091, 2093, 2100, 2103, 2114, 2115, 2117, 2118, 2127, 2128, 2130, 2133, 2134, 2136, 2139, 2140, 2142, 2143, 2145, 2147, 2154, 2157, 2158, 2159, 2161, 2166, 2168, 2171, 2173, 2175, 2177, 2189, 2190, 2192, 2194, 2196, 2199, 2202, 2207], "code": [2, 4, 5, 9, 10, 13, 16, 17, 18, 21, 25, 26, 30, 32, 36, 37, 39, 41, 52, 54, 56, 57, 58, 65, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 119, 681, 945, 965, 1002, 1004, 1014, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1086, 1087, 1101, 1202, 1228, 1314, 1318, 1319, 1325, 1326, 1327, 1330, 1331, 1332, 1345, 1356, 1358, 1386, 1597, 1609, 1641, 1642, 1643, 1770, 1939, 2078, 2091, 2095, 2096, 2100, 2102, 2104, 2116, 2127, 2128, 2132, 2133, 2134, 2135, 2136, 2138, 2139, 2140, 2141, 2142, 2144, 2146, 2147, 2148, 2150, 2151, 2154, 2157, 2159, 2165, 2166, 2167, 2168, 2171, 2174, 2175, 2183, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2198, 2200, 2202, 2203, 2205, 2206, 2207], "need": [2, 4, 6, 7, 8, 9, 10, 16, 17, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 43, 44, 49, 51, 52, 55, 56, 57, 58, 60, 62, 63, 65, 69, 71, 81, 82, 150, 254, 471, 488, 495, 499, 583, 681, 745, 746, 837, 839, 840, 843, 846, 851, 871, 888, 919, 923, 930, 931, 932, 935, 936, 944, 956, 983, 984, 992, 1009, 1010, 1014, 1080, 1089, 1097, 1132, 1134, 1144, 1165, 1167, 1187, 1196, 1201, 1217, 1218, 1228, 1251, 1314, 1408, 1466, 1515, 1522, 1576, 1577, 1578, 1580, 1586, 1624, 1626, 1628, 1661, 1662, 1663, 1756, 1770, 1779, 1780, 1793, 1795, 1799, 1801, 1828, 1860, 1877, 1909, 1914, 1928, 1987, 1993, 2018, 2034, 2036, 2076, 2092, 2093, 2095, 2096, 2100, 2103, 2104, 2106, 2108, 2114, 2116, 2117, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2140, 2144, 2145, 2146, 2147, 2148, 2150, 2154, 2157, 2158, 2161, 2164, 2166, 2167, 2168, 2171, 2173, 2174, 2177, 2178, 2182, 2183, 2184, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2200, 2202, 2204, 2205, 2206], "declar": [2, 10, 16, 25, 52, 1238, 2095, 2096, 2097, 2133, 2154, 2158], "requires_grad": [2, 6, 32, 37, 38, 39, 66, 335, 445, 446, 447, 448, 449, 487, 488, 496, 895, 910, 930, 931, 933, 934, 935, 936, 945, 946, 949, 950, 952, 954, 955, 965, 971, 980, 1089, 1145, 1146, 1147, 1148, 1157, 1162, 1180, 1198, 1199, 1200, 1203, 1213, 1272, 1273, 1314, 1334, 1385, 1401, 1492, 1493, 1513, 1515, 1522, 1523, 1533, 1545, 1546, 1571, 1572, 1580, 1586, 1587, 1594, 1628, 1629, 1658, 1659, 1669, 1722, 1770, 1772, 1773, 1774, 1820, 1825, 1831, 1832, 1877, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1970, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2033, 2045, 2089, 2090, 2094, 2098, 2100, 2115, 2116, 2117, 2130, 2133, 2134, 2142, 2147, 2154, 2155, 2166, 2167, 2173, 2177, 2178, 2180, 2192, 2193, 2194, 2195, 2199, 2202, 2204], "keyword": [2, 6, 25, 30, 31, 35, 36, 37, 38, 56, 57, 65, 69, 71, 77, 87, 313, 321, 445, 446, 447, 448, 449, 513, 581, 681, 682, 694, 695, 696, 697, 698, 699, 700, 701, 702, 704, 706, 707, 708, 709, 710, 891, 895, 910, 911, 912, 913, 914, 915, 970, 971, 972, 974, 975, 976, 977, 978, 979, 980, 982, 986, 989, 991, 993, 994, 995, 997, 999, 1000, 1016, 1021, 1022, 1024, 1025, 1027, 1036, 1051, 1053, 1056, 1086, 1087, 1123, 1124, 1125, 1126, 1127, 1128, 1131, 1136, 1139, 1141, 1143, 1145, 1146, 1147, 1149, 1154, 1157, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1187, 1188, 1189, 1190, 1191, 1192, 1194, 1196, 1198, 1199, 1200, 1201, 1226, 1255, 1256, 1257, 1258, 1268, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1279, 1280, 1281, 1289, 1291, 1308, 1309, 1314, 1317, 1330, 1331, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1396, 1397, 1398, 1399, 1401, 1402, 1403, 1405, 1406, 1408, 1409, 1412, 1413, 1414, 1415, 1417, 1418, 1419, 1420, 1441, 1465, 1466, 1468, 1470, 1471, 1472, 1473, 1474, 1476, 1477, 1478, 1480, 1516, 1538, 1541, 1580, 1738, 1763, 1764, 1770, 1793, 1795, 1800, 1804, 1822, 1826, 1828, 1831, 1832, 1877, 1880, 1881, 1885, 1886, 1889, 1890, 1892, 1893, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1912, 1913, 1914, 1921, 1923, 1928, 1943, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1960, 1965, 1968, 1971, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 1983, 1984, 1986, 1987, 1988, 1989, 1991, 1993, 1994, 2008, 2009, 2010, 2011, 2015, 2018, 2020, 2021, 2022, 2023, 2024, 2026, 2033, 2040, 2041, 2042, 2047, 2048, 2089, 2090, 2091, 2096, 2097, 2100, 2116, 2117, 2133, 2145, 2150, 2154, 2157, 2166, 2171, 2172, 2176, 2177, 2206], "type": [2, 3, 4, 6, 14, 16, 17, 19, 21, 26, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 49, 51, 52, 54, 56, 60, 65, 67, 68, 69, 71, 73, 76, 77, 80, 81, 82, 86, 87, 88, 150, 191, 196, 208, 326, 329, 333, 341, 445, 446, 447, 448, 449, 481, 559, 604, 681, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 696, 697, 698, 699, 700, 701, 745, 746, 749, 750, 751, 760, 762, 763, 764, 765, 767, 775, 777, 778, 781, 782, 783, 784, 785, 786, 787, 788, 789, 792, 795, 805, 806, 807, 810, 811, 813, 830, 831, 832, 837, 839, 840, 841, 842, 846, 852, 867, 869, 870, 884, 885, 886, 887, 888, 889, 890, 891, 892, 895, 903, 909, 919, 920, 921, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 951, 952, 954, 955, 958, 970, 971, 973, 974, 975, 976, 977, 978, 979, 980, 981, 983, 984, 986, 987, 988, 989, 990, 992, 1001, 1003, 1004, 1009, 1010, 1012, 1015, 1019, 1028, 1030, 1031, 1032, 1033, 1040, 1041, 1042, 1044, 1048, 1050, 1057, 1059, 1060, 1061, 1063, 1064, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1077, 1081, 1083, 1086, 1087, 1088, 1089, 1092, 1093, 1094, 1095, 1097, 1098, 1099, 1101, 1102, 1103, 1108, 1121, 1122, 1125, 1126, 1139, 1144, 1145, 1146, 1147, 1157, 1158, 1159, 1162, 1180, 1187, 1189, 1190, 1191, 1192, 1195, 1196, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1206, 1209, 1210, 1211, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1223, 1225, 1226, 1228, 1232, 1235, 1237, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1256, 1260, 1262, 1264, 1267, 1272, 1273, 1275, 1276, 1277, 1290, 1293, 1295, 1296, 1299, 1300, 1301, 1302, 1310, 1311, 1312, 1314, 1315, 1317, 1320, 1321, 1324, 1326, 1328, 1330, 1331, 1333, 1334, 1337, 1346, 1350, 1367, 1371, 1378, 1384, 1385, 1386, 1387, 1401, 1404, 1407, 1414, 1416, 1423, 1424, 1425, 1428, 1436, 1443, 1444, 1446, 1447, 1448, 1450, 1452, 1453, 1455, 1457, 1458, 1465, 1471, 1474, 1484, 1488, 1507, 1508, 1509, 1516, 1523, 1570, 1580, 1581, 1582, 1586, 1590, 1591, 1595, 1609, 1614, 1615, 1616, 1624, 1625, 1626, 1627, 1628, 1641, 1642, 1643, 1646, 1647, 1651, 1652, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1683, 1685, 1686, 1687, 1688, 1690, 1691, 1692, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1704, 1705, 1707, 1708, 1709, 1710, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1725, 1730, 1732, 1733, 1735, 1736, 1738, 1739, 1741, 1742, 1743, 1744, 1745, 1751, 1753, 1754, 1755, 1756, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1775, 1776, 1777, 1778, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1790, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1821, 1822, 1824, 1826, 1827, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1882, 1890, 1891, 1892, 1894, 1895, 1896, 1897, 1898, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1912, 1914, 1918, 1921, 1928, 1929, 1932, 1933, 1934, 1936, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1969, 1972, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1990, 1991, 1993, 1994, 1995, 2002, 2011, 2020, 2022, 2024, 2029, 2030, 2031, 2033, 2034, 2035, 2039, 2045, 2048, 2050, 2051, 2053, 2054, 2056, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2068, 2069, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2089, 2090, 2091, 2093, 2094, 2097, 2100, 2104, 2106, 2107, 2109, 2115, 2117, 2122, 2124, 2126, 2127, 2129, 2130, 2137, 2138, 2139, 2140, 2141, 2142, 2145, 2147, 2148, 2150, 2152, 2155, 2159, 2160, 2161, 2163, 2164, 2165, 2166, 2170, 2171, 2172, 2174, 2176, 2178, 2180, 2181, 2182, 2185, 2189, 2190, 2191, 2192, 2193, 2195, 2199, 2202, 2203, 2204, 2206], "doubl": [2, 4, 39, 41, 56, 57, 60, 481, 487, 617, 760, 762, 763, 764, 765, 767, 777, 778, 792, 930, 931, 933, 935, 936, 941, 949, 950, 958, 987, 994, 995, 1016, 1036, 1089, 1159, 1187, 1268, 1314, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1395, 1396, 1397, 1398, 1399, 1405, 1523, 1580, 1646, 1649, 1678, 1760, 1833, 1877, 1880, 1886, 1976, 1977, 1978, 1980, 1981, 1994, 2011, 2020, 2048, 2096, 2115, 2130, 2133, 2134, 2136, 2137, 2141, 2145, 2154, 2158, 2173, 2174, 2177, 2204], "bfloat16": [2, 26, 60, 895, 1296, 1314, 1366, 1383, 1580, 1738, 1833, 1839, 1840, 1841, 1859, 1877, 1933, 1936, 2115, 2130, 2137, 2171, 2173, 2174, 2177, 2178, 2210], "cfloat": [2, 13, 30, 311, 483, 617, 994, 995, 1036, 1285, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1405, 1880, 1910, 1994, 2020, 2044, 2174, 2177], "cdoubl": [2, 13, 994, 995, 1036, 1314, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1405, 1580, 1877, 1880, 1994, 2020, 2174, 2177], "beta": [2, 3, 13, 61, 68, 99, 100, 105, 106, 107, 108, 109, 110, 151, 152, 321, 517, 554, 697, 700, 701, 702, 970, 1037, 1078, 1079, 1086, 1087, 1089, 1272, 1334, 1409, 1419, 1494, 1495, 1496, 1534, 1540, 1542, 1543, 1544, 1552, 1568, 1612, 1617, 1620, 1639, 1644, 1695, 1703, 1704, 1738, 1742, 1746, 1838, 1840, 1841, 1842, 1844, 1856, 1860, 1896, 1953, 1955, 1966, 1971, 1986, 2092, 2094, 2102, 2117, 2130, 2149, 2152, 2154, 2157, 2161, 2166, 2171, 2174, 2180, 2199], "even": [2, 3, 9, 21, 25, 26, 30, 32, 34, 37, 41, 56, 60, 68, 69, 486, 544, 580, 681, 830, 831, 832, 923, 1027, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1175, 1176, 1177, 1180, 1212, 1227, 1232, 1238, 1240, 1241, 1253, 1299, 1327, 1344, 1346, 1350, 1351, 1352, 1353, 1367, 1371, 1373, 1374, 1378, 1379, 1384, 1409, 1415, 1516, 1620, 1661, 1662, 1663, 1725, 1770, 1779, 1780, 1787, 1825, 1827, 1872, 1921, 1932, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1994, 2043, 2093, 2096, 2097, 2105, 2109, 2117, 2126, 2127, 2130, 2133, 2135, 2136, 2139, 2141, 2142, 2144, 2145, 2146, 2147, 2150, 2154, 2157, 2158, 2168, 2173, 2174, 2177, 2184, 2189, 2191, 2192, 2194, 2195, 2197, 2204, 2207], "though": [2, 13, 30, 69, 71, 74, 150, 486, 807, 920, 923, 935, 940, 1014, 1160, 1161, 1163, 1228, 1232, 1238, 1240, 1241, 1312, 1315, 1409, 1827, 2093, 2097, 2116, 2117, 2127, 2130, 2133, 2134, 2136, 2144, 2145, 2157, 2161, 2173, 2192, 2194, 2204, 2207], "signatur": [2, 14, 25, 32, 44, 56, 57, 60, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 398, 487, 488, 556, 935, 936, 954, 955, 1015, 1019, 1314, 1580, 1762, 1763, 1764, 1767, 1768, 1770, 1793, 1813, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1990, 2100, 2117, 2122, 2130, 2133, 2134, 2154, 2158, 2166, 2171, 2193, 2197, 2206], "veri": [2, 5, 8, 9, 20, 25, 26, 37, 64, 66, 69, 1025, 1203, 1211, 1213, 1227, 1377, 1542, 1543, 1544, 1770, 1771, 1772, 1787, 1843, 1872, 1880, 1956, 1960, 2020, 2045, 2095, 2114, 2127, 2133, 2135, 2138, 2139, 2142, 2144, 2145, 2148, 2157, 2158, 2165, 2166, 2167, 2171, 2177, 2192, 2194, 2195, 2197, 2203, 2204, 2205], "unlik": [2, 4, 8, 30, 34, 39, 57, 60, 66, 488, 493, 945, 1141, 1180, 1183, 1187, 1350, 1351, 1370, 1373, 1378, 1382, 1412, 1415, 1417, 1552, 1773, 1774, 1838, 1911, 2002, 2042, 2095, 2096, 2114, 2117, 2130, 2144, 2146, 2147, 2174, 2177, 2180, 2191, 2195, 2204], "coverag": [2, 8, 56, 61, 69, 1205, 1206, 2092, 2093, 2098, 2116, 2117, 2160, 2161, 2171, 2206], "plan": [2, 3, 8, 10, 30, 32, 38, 925, 1770, 1892, 2124, 2127, 2133, 2158, 2171, 2177, 2203, 2205], "consid": [2, 6, 9, 26, 30, 34, 36, 41, 51, 56, 57, 58, 60, 65, 68, 69, 486, 705, 790, 796, 807, 938, 940, 941, 949, 1027, 1131, 1132, 1133, 1134, 1135, 1165, 1201, 1303, 1307, 1310, 1314, 1355, 1357, 1358, 1359, 1360, 1368, 1369, 1372, 1377, 1380, 1515, 1526, 1580, 1583, 1632, 1651, 1686, 1697, 1757, 1771, 1772, 1787, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1822, 1859, 1874, 1877, 1930, 1949, 1985, 1990, 2021, 2022, 2023, 2024, 2091, 2093, 2096, 2103, 2117, 2122, 2126, 2127, 2128, 2133, 2135, 2136, 2138, 2142, 2145, 2150, 2157, 2158, 2159, 2162, 2167, 2168, 2171, 2174, 2177, 2178, 2191, 2192, 2195, 2203, 2204, 2206, 2207], "ad": [2, 4, 10, 16, 21, 25, 26, 30, 35, 36, 39, 41, 48, 58, 60, 63, 65, 66, 68, 69, 221, 222, 313, 319, 471, 515, 681, 697, 698, 699, 700, 701, 702, 746, 925, 928, 929, 930, 938, 939, 940, 941, 945, 946, 947, 949, 958, 970, 1144, 1148, 1205, 1206, 1208, 1221, 1228, 1314, 1328, 1386, 1392, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1586, 1587, 1589, 1594, 1595, 1609, 1620, 1624, 1629, 1632, 1664, 1665, 1666, 1683, 1711, 1712, 1713, 1738, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1793, 1797, 1800, 1803, 1804, 1806, 1807, 1808, 1809, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1896, 1897, 1898, 1966, 1971, 1986, 2091, 2093, 2095, 2108, 2109, 2116, 2117, 2126, 2134, 2136, 2138, 2140, 2142, 2147, 2150, 2158, 2159, 2161, 2164, 2171, 2176, 2180, 2190, 2191, 2194, 2195, 2199, 2200, 2202, 2203, 2207], "tutori": [2, 4, 10, 17, 30, 31, 35, 60, 69, 925, 928, 929, 930, 933, 935, 1586, 1624, 1625, 1626, 1627, 1628, 2036, 2093, 2100, 2103, 2118, 2133, 2140, 2142, 2144, 2147, 2154, 2161, 2185, 2194, 2195, 2197, 2204], "how": [2, 4, 6, 8, 9, 10, 14, 17, 19, 21, 25, 30, 32, 37, 38, 43, 51, 52, 54, 58, 60, 61, 62, 64, 65, 69, 71, 79, 80, 233, 415, 486, 487, 488, 796, 805, 806, 809, 871, 889, 891, 892, 925, 928, 929, 930, 933, 935, 936, 945, 946, 954, 955, 1041, 1127, 1148, 1202, 1211, 1222, 1234, 1242, 1268, 1314, 1325, 1386, 1526, 1580, 1632, 1633, 1725, 1757, 1770, 1813, 1825, 1838, 1877, 1912, 1936, 1950, 1961, 2093, 2095, 2096, 2100, 2103, 2104, 2107, 2114, 2115, 2116, 2117, 2118, 2126, 2129, 2130, 2132, 2134, 2135, 2136, 2138, 2141, 2142, 2144, 2146, 2147, 2149, 2154, 2159, 2161, 2164, 2166, 2167, 2168, 2171, 2176, 2184, 2191, 2192, 2197, 2198, 2202, 2204, 2205, 2207, 2209], "major": [2, 7, 8, 9, 10, 1069, 1452, 1994, 2092, 2096, 2136, 2157, 2191, 2195, 2197, 2198], "contain": [2, 3, 4, 6, 13, 16, 17, 25, 30, 31, 32, 34, 35, 37, 38, 39, 41, 42, 44, 45, 49, 52, 57, 58, 60, 68, 69, 71, 72, 77, 80, 87, 154, 191, 195, 208, 290, 311, 313, 315, 319, 321, 471, 483, 544, 603, 607, 697, 708, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 771, 810, 829, 865, 871, 907, 922, 923, 924, 935, 936, 938, 939, 940, 941, 942, 943, 944, 962, 970, 971, 972, 980, 982, 986, 1004, 1022, 1023, 1027, 1051, 1052, 1053, 1054, 1055, 1056, 1089, 1144, 1150, 1178, 1179, 1181, 1187, 1196, 1208, 1209, 1212, 1213, 1272, 1273, 1276, 1277, 1285, 1289, 1305, 1312, 1314, 1315, 1321, 1322, 1325, 1330, 1331, 1334, 1345, 1351, 1352, 1353, 1354, 1356, 1358, 1360, 1361, 1377, 1386, 1404, 1408, 1415, 1466, 1472, 1484, 1493, 1515, 1516, 1522, 1523, 1526, 1531, 1532, 1534, 1539, 1550, 1551, 1572, 1580, 1581, 1582, 1587, 1590, 1596, 1598, 1609, 1613, 1620, 1632, 1639, 1669, 1677, 1678, 1680, 1753, 1760, 1763, 1764, 1770, 1779, 1780, 1788, 1789, 1790, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1820, 1821, 1824, 1826, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1852, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1882, 1885, 1910, 1924, 1928, 1989, 1990, 1994, 2013, 2020, 2022, 2024, 2029, 2030, 2031, 2035, 2041, 2045, 2093, 2095, 2096, 2097, 2100, 2103, 2104, 2108, 2109, 2116, 2117, 2119, 2122, 2123, 2126, 2127, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2140, 2141, 2142, 2145, 2146, 2147, 2150, 2154, 2157, 2158, 2159, 2161, 2163, 2164, 2166, 2168, 2170, 2171, 2173, 2174, 2176, 2177, 2180, 2181, 2182, 2184, 2186, 2188, 2189, 2190, 2192, 2193, 2194, 2195, 2197, 2198, 2201, 2202, 2203, 2204, 2205, 2206, 2207], "build": [2, 3, 4, 9, 10, 11, 16, 17, 21, 30, 32, 37, 39, 49, 51, 56, 58, 69, 1314, 1324, 1580, 1586, 1624, 1625, 1626, 1627, 1628, 1651, 1686, 1877, 2063, 2093, 2103, 2118, 2127, 2137, 2147, 2150, 2154, 2161, 2167, 2176, 2177, 2183, 2185, 2186, 2189, 2192, 2205], "basic": [2, 4, 8, 10, 14, 32, 37, 69, 71, 72, 1205, 1206, 1207, 1228, 1321, 1387, 1770, 1865, 2097, 2118, 2128, 2130, 2132, 2138, 2158, 2167, 2175, 2176, 2193, 2195, 2197], "jacobian": [2, 39, 61, 62, 64, 65, 923, 928, 938, 941, 943, 944, 949, 950, 1206, 1207, 1208, 1212, 1213, 2045, 2127, 2133, 2138], "hessian": [2, 61, 64, 65, 939, 942, 1206, 1207, 2124, 2134], "etc": [2, 4, 6, 13, 14, 25, 26, 30, 36, 37, 39, 41, 51, 52, 56, 57, 60, 810, 834, 889, 890, 891, 958, 1004, 1019, 1230, 1311, 1314, 1515, 1580, 1770, 1877, 1914, 2091, 2095, 2096, 2100, 2103, 2117, 2133, 2134, 2135, 2142, 2144, 2154, 2157, 2158, 2161, 2166, 2171, 2173, 2176, 2180, 2189, 2193, 2202, 2204], "user": [2, 3, 6, 8, 9, 10, 12, 13, 14, 16, 17, 21, 25, 26, 30, 31, 32, 34, 36, 37, 38, 39, 40, 41, 44, 48, 51, 52, 55, 57, 58, 60, 61, 64, 65, 68, 69, 71, 84, 150, 335, 486, 743, 749, 750, 751, 756, 757, 767, 775, 807, 811, 814, 866, 884, 891, 892, 923, 930, 933, 935, 936, 944, 1004, 1040, 1080, 1195, 1201, 1202, 1217, 1228, 1314, 1351, 1386, 1580, 1624, 1626, 1627, 1628, 1738, 1763, 1764, 1770, 1779, 1780, 1790, 1804, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 2091, 2092, 2093, 2095, 2096, 2100, 2103, 2108, 2114, 2116, 2122, 2126, 2127, 2128, 2130, 2133, 2137, 2138, 2139, 2140, 2141, 2142, 2144, 2147, 2150, 2154, 2157, 2159, 2161, 2163, 2166, 2167, 2171, 2173, 2174, 2175, 2176, 2178, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2200, 2202, 2204, 2205, 2206], "input": [2, 3, 4, 6, 10, 13, 14, 17, 23, 25, 26, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 44, 57, 60, 61, 62, 63, 64, 65, 66, 69, 71, 78, 79, 80, 84, 87, 150, 260, 280, 301, 401, 483, 499, 517, 609, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 731, 739, 740, 745, 746, 749, 750, 751, 752, 753, 754, 756, 757, 767, 769, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 803, 804, 805, 806, 807, 809, 811, 812, 814, 815, 817, 829, 832, 834, 837, 865, 866, 868, 869, 887, 888, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 904, 905, 906, 907, 908, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 923, 930, 931, 933, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 962, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 985, 986, 988, 990, 991, 993, 994, 995, 996, 997, 998, 999, 1001, 1002, 1004, 1014, 1016, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1036, 1054, 1055, 1086, 1087, 1089, 1123, 1124, 1125, 1126, 1128, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1144, 1145, 1146, 1147, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1213, 1224, 1226, 1228, 1255, 1256, 1257, 1258, 1259, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1291, 1292, 1293, 1294, 1296, 1299, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1314, 1317, 1318, 1321, 1322, 1326, 1328, 1330, 1331, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1402, 1403, 1405, 1407, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1441, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1762, 1763, 1764, 1767, 1768, 1769, 1770, 1779, 1780, 1791, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1806, 1807, 1808, 1809, 1813, 1814, 1815, 1822, 1825, 1826, 1827, 1829, 1830, 1832, 1834, 1835, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1864, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1900, 1902, 1904, 1906, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1923, 1925, 1926, 1927, 1930, 1931, 1932, 1933, 1936, 1943, 1944, 1945, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1969, 1970, 1971, 1972, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1983, 1984, 1985, 1986, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 2002, 2006, 2007, 2008, 2009, 2010, 2012, 2014, 2015, 2016, 2017, 2020, 2021, 2023, 2026, 2027, 2028, 2029, 2030, 2032, 2033, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2048, 2049, 2090, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2103, 2106, 2116, 2117, 2118, 2122, 2124, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2136, 2140, 2142, 2145, 2146, 2147, 2149, 2150, 2154, 2156, 2157, 2159, 2161, 2162, 2164, 2165, 2166, 2167, 2171, 2172, 2174, 2175, 2177, 2178, 2181, 2182, 2184, 2185, 2186, 2191, 2192, 2193, 2194, 2195, 2199, 2202, 2203, 2204, 2205, 2206, 2209], "set": [2, 3, 4, 6, 9, 10, 15, 16, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 39, 41, 44, 49, 51, 52, 54, 55, 56, 57, 58, 60, 63, 64, 67, 68, 69, 71, 87, 150, 154, 254, 330, 445, 446, 447, 448, 449, 458, 496, 499, 520, 580, 581, 681, 690, 691, 692, 746, 752, 754, 771, 790, 796, 805, 806, 807, 811, 830, 831, 832, 839, 840, 841, 846, 851, 871, 884, 888, 889, 891, 892, 895, 908, 920, 922, 923, 930, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 946, 947, 969, 981, 986, 997, 1001, 1002, 1010, 1014, 1021, 1034, 1037, 1049, 1067, 1078, 1090, 1091, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1145, 1146, 1147, 1196, 1201, 1210, 1216, 1221, 1229, 1277, 1294, 1295, 1314, 1318, 1322, 1324, 1326, 1328, 1330, 1331, 1350, 1351, 1354, 1360, 1367, 1369, 1371, 1372, 1384, 1385, 1386, 1387, 1401, 1404, 1407, 1414, 1429, 1436, 1437, 1438, 1439, 1460, 1461, 1462, 1484, 1488, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1518, 1519, 1520, 1524, 1531, 1534, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1565, 1567, 1571, 1572, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1590, 1594, 1595, 1596, 1612, 1613, 1620, 1624, 1626, 1628, 1629, 1630, 1642, 1643, 1651, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1671, 1672, 1673, 1674, 1679, 1686, 1690, 1697, 1698, 1707, 1708, 1709, 1722, 1724, 1730, 1738, 1757, 1769, 1770, 1773, 1774, 1788, 1794, 1822, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1876, 1877, 1892, 1899, 1901, 1905, 1907, 1908, 1916, 1917, 1928, 1929, 1932, 1933, 1934, 1935, 1936, 1938, 1939, 1940, 1941, 1942, 1957, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 1988, 1989, 1995, 2011, 2021, 2022, 2023, 2024, 2033, 2036, 2037, 2040, 2041, 2071, 2072, 2082, 2083, 2084, 2085, 2086, 2087, 2091, 2093, 2095, 2096, 2097, 2100, 2102, 2105, 2106, 2107, 2108, 2109, 2111, 2114, 2117, 2122, 2124, 2126, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2137, 2138, 2139, 2140, 2141, 2142, 2144, 2145, 2146, 2147, 2148, 2150, 2155, 2157, 2158, 2159, 2161, 2162, 2164, 2165, 2166, 2173, 2176, 2178, 2179, 2181, 2182, 2184, 2185, 2186, 2188, 2189, 2192, 2194, 2195, 2196, 2197, 2199, 2200, 2201, 2203, 2205, 2206, 2208, 2209], "can": [2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 77, 79, 80, 81, 82, 87, 88, 150, 154, 233, 254, 258, 323, 335, 458, 486, 487, 488, 513, 515, 545, 614, 617, 681, 698, 740, 752, 753, 754, 759, 768, 769, 771, 779, 780, 783, 784, 785, 796, 804, 805, 806, 807, 811, 814, 829, 839, 842, 843, 851, 865, 871, 884, 888, 889, 891, 892, 893, 895, 909, 910, 919, 920, 921, 923, 925, 926, 928, 929, 930, 933, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 949, 950, 954, 955, 956, 958, 961, 972, 989, 1002, 1004, 1005, 1012, 1014, 1015, 1019, 1020, 1027, 1037, 1039, 1041, 1051, 1053, 1056, 1065, 1066, 1078, 1086, 1088, 1092, 1094, 1097, 1101, 1102, 1127, 1144, 1145, 1148, 1149, 1162, 1164, 1165, 1166, 1167, 1180, 1183, 1196, 1201, 1202, 1203, 1204, 1206, 1207, 1208, 1211, 1212, 1213, 1218, 1221, 1222, 1224, 1226, 1227, 1228, 1232, 1238, 1240, 1241, 1251, 1253, 1257, 1258, 1268, 1271, 1276, 1277, 1305, 1311, 1312, 1314, 1315, 1317, 1318, 1320, 1321, 1325, 1326, 1328, 1330, 1331, 1336, 1339, 1346, 1354, 1357, 1361, 1362, 1367, 1370, 1373, 1374, 1378, 1384, 1386, 1403, 1404, 1406, 1416, 1426, 1427, 1473, 1475, 1476, 1477, 1482, 1483, 1484, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1498, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1516, 1517, 1521, 1522, 1523, 1524, 1527, 1528, 1531, 1536, 1537, 1538, 1540, 1546, 1548, 1549, 1550, 1553, 1554, 1555, 1566, 1570, 1571, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1582, 1585, 1586, 1587, 1589, 1590, 1591, 1594, 1596, 1597, 1598, 1599, 1600, 1601, 1608, 1609, 1612, 1617, 1620, 1623, 1624, 1625, 1626, 1627, 1628, 1630, 1631, 1633, 1644, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1681, 1682, 1697, 1711, 1712, 1713, 1731, 1738, 1757, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1773, 1774, 1776, 1785, 1793, 1813, 1814, 1817, 1820, 1825, 1827, 1831, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1847, 1848, 1849, 1850, 1851, 1852, 1855, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1869, 1870, 1872, 1876, 1877, 1878, 1880, 1889, 1893, 1901, 1905, 1915, 1921, 1924, 1936, 1938, 1940, 1965, 1968, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1988, 1989, 1990, 1994, 1995, 2011, 2015, 2018, 2020, 2028, 2029, 2032, 2034, 2036, 2040, 2041, 2045, 2050, 2057, 2058, 2073, 2074, 2076, 2089, 2091, 2092, 2093, 2094, 2095, 2096, 2100, 2102, 2103, 2104, 2105, 2106, 2108, 2109, 2110, 2114, 2115, 2116, 2117, 2118, 2122, 2126, 2128, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2139, 2140, 2141, 2142, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2162, 2164, 2166, 2167, 2168, 2171, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2196, 2197, 2198, 2199, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2212], "lambda": [2, 14, 25, 39, 58, 63, 66, 68, 69, 71, 79, 80, 258, 487, 488, 954, 955, 990, 1203, 1208, 1212, 1213, 1228, 1350, 1351, 1352, 1353, 1386, 1535, 1618, 1630, 1727, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1859, 1865, 1868, 1871, 1878, 1967, 2045, 2097, 2127, 2133, 2134, 2157, 2158, 2166, 2178, 2195, 2204, 2206], "captur": [2, 13, 14, 17, 36, 56, 57, 58, 69, 71, 74, 79, 80, 86, 87, 681, 1002, 1004, 1019, 1037, 1039, 1078, 1084, 1089, 1317, 1427, 1443, 1836, 1837, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 2050, 2093, 2097, 2100, 2102, 2133, 2134, 2139, 2149, 2150, 2151, 2154, 2158, 2161, 2182, 2183, 2185, 2189, 2191, 2193, 2195, 2202, 2204, 2205], "f": [2, 12, 26, 30, 38, 39, 41, 43, 45, 48, 49, 56, 57, 58, 61, 62, 65, 66, 68, 69, 71, 72, 173, 258, 335, 377, 608, 928, 929, 969, 1027, 1057, 1162, 1164, 1171, 1180, 1202, 1203, 1205, 1206, 1207, 1208, 1212, 1213, 1216, 1268, 1314, 1322, 1325, 1326, 1386, 1545, 1547, 1548, 1549, 1551, 1580, 1630, 1640, 1653, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1670, 1677, 1678, 1681, 1682, 1688, 1722, 1724, 1725, 1738, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1924, 2001, 2045, 2093, 2095, 2096, 2100, 2108, 2115, 2116, 2117, 2127, 2130, 2133, 2135, 2137, 2138, 2139, 2142, 2147, 2148, 2150, 2151, 2152, 2154, 2158, 2166, 2171, 2176, 2178, 2190, 2191, 2195, 2203, 2204, 2206], "three": [2, 3, 7, 10, 30, 35, 37, 60, 62, 65, 69, 918, 1142, 1144, 1268, 1277, 1358, 1361, 1362, 1363, 1378, 1406, 1491, 1509, 1512, 1549, 1552, 1575, 1738, 1787, 1827, 1865, 1936, 2096, 2127, 2130, 2132, 2133, 2154, 2158, 2161, 2166, 2168, 2171, 2176, 2189, 2192, 2201, 2204], "anoth": [2, 6, 8, 14, 25, 26, 30, 32, 36, 39, 40, 41, 54, 56, 60, 69, 88, 486, 1013, 1037, 1039, 1040, 1195, 1224, 1228, 1234, 1324, 1350, 1351, 1354, 1378, 1522, 1523, 1581, 1590, 1760, 1779, 1780, 1788, 1932, 2093, 2095, 2096, 2102, 2104, 2108, 2114, 2126, 2127, 2129, 2130, 2133, 2136, 2142, 2144, 2146, 2148, 2158, 2167, 2168, 2171, 2173, 2177, 2180, 2189, 2190, 2192, 2195, 2197, 2200, 2203, 2207], "constant": [2, 14, 25, 56, 57, 58, 69, 71, 72, 76, 77, 80, 82, 755, 786, 840, 841, 1005, 1015, 1127, 1184, 1185, 1186, 1235, 1253, 1311, 1314, 1318, 1330, 1362, 1387, 1504, 1505, 1506, 1523, 1526, 1533, 1589, 1612, 1629, 1632, 1683, 1686, 1725, 1788, 1834, 1838, 1857, 1862, 1865, 1878, 2018, 2094, 2096, 2126, 2133, 2142, 2146, 2150, 2154, 2157, 2171, 2192, 2194, 2195, 2197, 2205], "boolean": [2, 14, 16, 39, 51, 58, 69, 71, 79, 80, 86, 88, 400, 402, 689, 919, 935, 936, 945, 974, 976, 977, 979, 1008, 1019, 1039, 1040, 1149, 1228, 1235, 1242, 1257, 1271, 1303, 1304, 1305, 1306, 1307, 1310, 1339, 1387, 1403, 1408, 1443, 1477, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1595, 1620, 1624, 1738, 1769, 1790, 1793, 1892, 1988, 1989, 2015, 2040, 2041, 2050, 2095, 2097, 2122, 2130, 2133, 2173, 2174, 2176, 2177, 2178, 2180, 2192, 2195], "flag": [2, 3, 6, 16, 30, 31, 40, 52, 55, 56, 60, 63, 65, 69, 746, 811, 903, 938, 940, 945, 946, 947, 971, 980, 993, 994, 995, 1002, 1009, 1010, 1014, 1072, 1195, 1201, 1203, 1204, 1206, 1207, 1208, 1212, 1213, 1272, 1273, 1295, 1302, 1386, 1406, 1586, 1644, 1697, 1698, 1770, 1790, 1793, 1822, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1936, 1942, 1968, 1979, 2020, 2033, 2045, 2063, 2092, 2093, 2096, 2100, 2108, 2114, 2117, 2127, 2130, 2133, 2145, 2146, 2147, 2150, 2154, 2158, 2161, 2176, 2177, 2180, 2195, 2196, 2203, 2205], "inform": [2, 3, 4, 5, 6, 8, 9, 10, 19, 20, 22, 24, 25, 26, 30, 31, 32, 35, 36, 37, 38, 41, 43, 44, 47, 51, 52, 56, 57, 58, 60, 62, 67, 69, 71, 73, 80, 191, 208, 255, 313, 321, 487, 488, 498, 515, 517, 618, 681, 746, 810, 813, 940, 945, 946, 949, 950, 954, 955, 973, 1057, 1148, 1179, 1181, 1202, 1242, 1251, 1311, 1314, 1331, 1344, 1351, 1360, 1507, 1508, 1509, 1510, 1511, 1512, 1540, 1550, 1576, 1577, 1578, 1580, 1586, 1595, 1596, 1608, 1624, 1626, 1628, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1678, 1697, 1738, 1757, 1758, 1759, 1769, 1770, 1813, 1825, 1834, 1856, 1877, 1891, 1918, 1936, 1942, 1968, 2033, 2093, 2096, 2100, 2102, 2103, 2117, 2118, 2122, 2127, 2129, 2130, 2132, 2133, 2140, 2142, 2145, 2150, 2158, 2159, 2161, 2173, 2174, 2176, 2177, 2178, 2182, 2184, 2188, 2191, 2192, 2194, 2195, 2198, 2202, 2204, 2205, 2207, 2209, 2210], "between": [2, 3, 4, 8, 13, 19, 20, 26, 30, 34, 36, 39, 40, 51, 52, 54, 56, 57, 58, 60, 67, 68, 69, 86, 196, 486, 513, 583, 584, 585, 587, 588, 607, 617, 700, 701, 702, 706, 707, 771, 783, 784, 785, 817, 887, 895, 914, 923, 928, 939, 941, 942, 943, 949, 950, 990, 1002, 1015, 1027, 1039, 1048, 1050, 1103, 1108, 1121, 1122, 1127, 1144, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1195, 1196, 1224, 1227, 1238, 1268, 1275, 1311, 1314, 1326, 1350, 1351, 1373, 1378, 1443, 1473, 1492, 1493, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1514, 1515, 1518, 1519, 1520, 1524, 1526, 1531, 1540, 1546, 1556, 1557, 1558, 1559, 1560, 1561, 1571, 1573, 1574, 1575, 1580, 1583, 1584, 1585, 1589, 1609, 1612, 1613, 1614, 1629, 1630, 1632, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1685, 1695, 1711, 1712, 1713, 1727, 1744, 1754, 1770, 1779, 1780, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1864, 1865, 1872, 1874, 1877, 1885, 1893, 1897, 1898, 1903, 1904, 1908, 1933, 1987, 1988, 1989, 1990, 1994, 2017, 2018, 2040, 2041, 2093, 2095, 2096, 2097, 2100, 2103, 2111, 2114, 2122, 2126, 2127, 2129, 2130, 2132, 2138, 2139, 2141, 2142, 2144, 2146, 2147, 2149, 2151, 2157, 2159, 2161, 2162, 2166, 2168, 2171, 2173, 2174, 2176, 2181, 2189, 2192, 2202, 2204, 2205], "well": [2, 4, 6, 8, 10, 16, 21, 26, 30, 34, 42, 51, 56, 60, 65, 66, 69, 617, 804, 841, 846, 891, 1086, 1206, 1207, 1314, 1318, 1325, 1330, 1350, 1351, 1352, 1354, 1360, 1373, 1378, 1425, 1494, 1495, 1496, 1515, 1550, 1580, 1620, 1707, 1708, 1709, 1770, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1892, 2029, 2093, 2096, 2103, 2115, 2117, 2122, 2126, 2127, 2130, 2133, 2134, 2136, 2138, 2142, 2144, 2146, 2147, 2154, 2158, 2161, 2164, 2166, 2168, 2171, 2175, 2176, 2180, 2185, 2190, 2192, 2194, 2195, 2196, 2200, 2204, 2205], "relat": [2, 7, 8, 10, 25, 30, 36, 41, 56, 57, 58, 59, 60, 65, 71, 72, 77, 80, 681, 813, 1009, 1224, 1268, 1354, 1526, 1612, 1632, 1770, 1882, 2034, 2127, 2147, 2157, 2158, 2166, 2171, 2172, 2178, 2184, 2185, 2195, 2206], "mechan": [2, 9, 11, 30, 32, 45, 49, 51, 57, 69, 909, 945, 946, 1004, 1148, 1314, 1580, 1641, 1738, 1825, 1877, 2011, 2114, 2122, 2125, 2130, 2133, 2136, 2140, 2142, 2164, 2166, 2167, 2189, 2192], "confus": [2, 9, 71, 1144, 1314, 1580, 1877, 2127, 2130, 2158, 2171, 2196], "spars": [2, 13, 190, 191, 208, 218, 323, 328, 342, 343, 435, 543, 544, 545, 546, 581, 583, 584, 585, 586, 587, 588, 614, 700, 756, 757, 949, 950, 1119, 1255, 1279, 1299, 1387, 1409, 1419, 1476, 1522, 1523, 1614, 1677, 1678, 1703, 1839, 1860, 1882, 1930, 1963, 1968, 1976, 1977, 1978, 1979, 1980, 1981, 1986, 1995, 2017, 2033, 2034, 2094, 2098, 2103, 2122, 2124, 2145, 2146, 2155, 2160, 2163, 2174, 2175, 2178, 2191, 2199, 2204], "param": [2, 3, 13, 32, 35, 39, 43, 51, 60, 62, 64, 67, 69, 488, 775, 808, 1201, 1211, 1314, 1333, 1580, 1586, 1590, 1591, 1768, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1874, 1877, 1878, 2094, 2106, 2124, 2126, 2130, 2132, 2157, 2206], "receiv": [2, 8, 10, 25, 30, 32, 35, 36, 39, 57, 65, 68, 1101, 1314, 1580, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 2096, 2109, 2114, 2117, 2126, 2127, 2144, 2166, 2167, 2168, 2171, 2191, 2205, 2207], "dure": [2, 6, 16, 20, 21, 26, 30, 32, 34, 36, 37, 41, 43, 45, 51, 56, 58, 60, 68, 69, 71, 78, 335, 488, 503, 504, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 806, 852, 919, 920, 930, 933, 935, 936, 1015, 1037, 1078, 1088, 1089, 1102, 1103, 1122, 1216, 1325, 1327, 1328, 1330, 1386, 1488, 1494, 1495, 1496, 1516, 1517, 1522, 1523, 1542, 1543, 1544, 1599, 1620, 1626, 1628, 1671, 1677, 1678, 1738, 1760, 1770, 1773, 1774, 1820, 1834, 1867, 1875, 1877, 1975, 2022, 2024, 2095, 2100, 2102, 2103, 2106, 2108, 2109, 2115, 2117, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2140, 2142, 2145, 2146, 2147, 2150, 2151, 2154, 2157, 2158, 2159, 2161, 2164, 2166, 2168, 2178, 2185, 2189, 2190, 2192, 2195, 2201, 2202, 2203, 2204, 2205, 2207], "accumul": [2, 3, 34, 60, 150, 290, 313, 318, 319, 321, 471, 488, 697, 923, 944, 1228, 1384, 1770, 1837, 1839, 2033, 2080, 2093, 2094, 2109, 2127, 2130, 2132, 2135, 2145, 2157, 2159, 2162, 2166, 2167, 2171, 2191, 2192, 2195, 2199], "initi": [2, 3, 4, 5, 9, 19, 20, 22, 25, 26, 32, 34, 35, 36, 37, 38, 41, 44, 45, 51, 52, 55, 56, 58, 60, 87, 496, 499, 580, 693, 723, 724, 725, 726, 727, 728, 731, 741, 742, 743, 744, 756, 757, 767, 771, 775, 891, 892, 909, 958, 1013, 1039, 1049, 1057, 1074, 1080, 1081, 1084, 1085, 1112, 1145, 1146, 1147, 1261, 1290, 1312, 1314, 1327, 1328, 1386, 1387, 1404, 1456, 1494, 1495, 1496, 1497, 1499, 1510, 1511, 1512, 1516, 1522, 1523, 1531, 1532, 1534, 1542, 1543, 1544, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1580, 1588, 1595, 1596, 1597, 1598, 1620, 1630, 1677, 1760, 1769, 1770, 1773, 1774, 1787, 1790, 1793, 1820, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1876, 1877, 1932, 1933, 1934, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2050, 2064, 2067, 2068, 2070, 2082, 2094, 2095, 2096, 2104, 2109, 2124, 2127, 2130, 2132, 2133, 2136, 2137, 2140, 2148, 2150, 2154, 2157, 2158, 2161, 2165, 2166, 2167, 2180, 2189, 2192, 2202, 2203, 2204, 2212], "memori": [2, 3, 4, 6, 13, 22, 26, 29, 32, 34, 35, 37, 39, 40, 57, 60, 64, 69, 150, 155, 170, 172, 175, 178, 179, 180, 195, 206, 209, 233, 240, 254, 267, 297, 325, 331, 337, 339, 340, 393, 445, 446, 447, 448, 449, 458, 463, 486, 499, 500, 524, 525, 580, 603, 617, 623, 745, 774, 908, 910, 923, 930, 933, 935, 949, 950, 956, 984, 999, 1002, 1037, 1038, 1041, 1043, 1046, 1047, 1049, 1064, 1066, 1067, 1073, 1078, 1079, 1082, 1086, 1088, 1089, 1092, 1094, 1095, 1097, 1099, 1100, 1101, 1102, 1103, 1109, 1110, 1111, 1115, 1144, 1145, 1146, 1147, 1195, 1196, 1197, 1198, 1200, 1201, 1202, 1207, 1209, 1213, 1314, 1332, 1360, 1386, 1423, 1425, 1426, 1436, 1438, 1458, 1523, 1550, 1551, 1580, 1624, 1625, 1626, 1628, 1738, 1756, 1770, 1779, 1780, 1787, 1813, 1825, 1832, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1901, 1902, 1904, 1905, 1906, 1907, 1932, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2033, 2045, 2058, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2090, 2093, 2104, 2106, 2111, 2114, 2116, 2117, 2118, 2127, 2133, 2136, 2144, 2145, 2147, 2150, 2154, 2159, 2160, 2161, 2166, 2171, 2173, 2174, 2175, 2177, 2178, 2180, 2189, 2194, 2195, 2197, 2201, 2203], "overlap": [2, 25, 26, 30, 32, 34, 35, 60, 69, 486, 681, 908, 949, 950, 1147, 1202, 1311, 1526, 1632, 1770, 1990, 2033, 2130, 2132, 2136, 2174, 2191, 2195, 2203], "dens": [2, 35, 218, 545, 546, 583, 584, 585, 586, 587, 588, 971, 980, 1272, 1273, 1334, 1387, 1860, 1963, 1966, 1970, 1971, 1974, 1975, 1976, 1977, 1978, 1980, 1981, 1986, 1995, 2033, 2117, 2122, 2146, 2171, 2174, 2191], "stride": [2, 13, 37, 56, 57, 138, 254, 339, 445, 446, 447, 448, 449, 499, 520, 544, 581, 583, 584, 585, 587, 588, 617, 723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 749, 750, 751, 752, 753, 754, 779, 780, 783, 784, 785, 793, 794, 895, 908, 971, 980, 1145, 1147, 1157, 1162, 1180, 1196, 1199, 1200, 1228, 1241, 1272, 1273, 1279, 1314, 1324, 1328, 1334, 1385, 1401, 1419, 1489, 1490, 1491, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1547, 1548, 1549, 1556, 1557, 1558, 1559, 1560, 1561, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1592, 1632, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1680, 1707, 1708, 1709, 1711, 1712, 1713, 1714, 1715, 1716, 1756, 1770, 1831, 1877, 1897, 1898, 1901, 1903, 1904, 1905, 1907, 1908, 1915, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1967, 1970, 2017, 2022, 2024, 2043, 2089, 2094, 2097, 2100, 2115, 2117, 2154, 2155, 2166, 2171, 2173, 2174, 2176, 2177, 2178, 2185, 2191, 2192, 2193, 2194, 2195, 2199, 2204, 2205], "otherwis": [2, 3, 4, 6, 8, 10, 13, 16, 21, 25, 30, 31, 34, 37, 39, 40, 44, 56, 58, 60, 61, 65, 69, 87, 209, 233, 321, 328, 332, 336, 338, 342, 343, 495, 504, 560, 580, 581, 583, 603, 617, 623, 681, 697, 698, 699, 700, 701, 704, 706, 707, 708, 710, 746, 771, 779, 780, 795, 807, 832, 839, 840, 870, 891, 892, 895, 922, 928, 935, 936, 940, 949, 969, 970, 986, 1014, 1084, 1144, 1150, 1183, 1195, 1227, 1228, 1241, 1245, 1305, 1311, 1314, 1317, 1321, 1327, 1336, 1360, 1375, 1384, 1386, 1387, 1402, 1407, 1412, 1414, 1415, 1417, 1419, 1420, 1471, 1474, 1490, 1491, 1513, 1515, 1518, 1519, 1520, 1524, 1531, 1535, 1536, 1537, 1538, 1540, 1550, 1566, 1580, 1584, 1585, 1586, 1587, 1588, 1590, 1596, 1597, 1599, 1612, 1618, 1620, 1623, 1624, 1626, 1628, 1629, 1630, 1654, 1655, 1688, 1690, 1691, 1695, 1731, 1742, 1770, 1787, 1792, 1793, 1813, 1814, 1816, 1817, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1877, 1880, 1882, 1890, 1892, 1899, 1908, 1915, 1928, 1936, 1943, 1988, 1989, 1990, 1993, 2028, 2029, 2030, 2040, 2041, 2048, 2091, 2093, 2095, 2096, 2100, 2103, 2106, 2115, 2117, 2126, 2130, 2133, 2134, 2144, 2147, 2150, 2152, 2154, 2161, 2162, 2164, 2165, 2166, 2168, 2172, 2173, 2174, 2175, 2176, 2178, 2185, 2204, 2206], "rowmajor": [2, 1770], "contigu": [2, 13, 26, 32, 233, 331, 499, 520, 617, 1525, 1583, 1727, 1770, 1779, 1780, 1909, 1915, 1994, 2094, 2116, 2117, 2122, 2155, 2163, 2171, 2173, 2175, 2192], "create_graph": [2, 150, 488, 923, 938, 939, 940, 941, 942, 943, 944, 2094, 2126, 2133], "preserv": [2, 6, 14, 25, 34, 36, 37, 39, 56, 60, 69, 87, 499, 790, 796, 884, 906, 909, 1185, 1186, 1202, 1241, 1314, 1318, 1325, 1580, 1581, 1590, 1633, 1697, 1757, 1835, 1877, 1924, 1928, 1965, 2002, 2011, 2038, 2093, 2100, 2106, 2115, 2117, 2124, 2130, 2134, 2146, 2149, 2150, 2154, 2166, 2173, 2174, 2189, 2194], "replac": [2, 16, 21, 25, 26, 30, 32, 37, 50, 52, 56, 58, 60, 62, 63, 64, 65, 66, 69, 119, 421, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 758, 829, 868, 888, 993, 1089, 1144, 1201, 1202, 1228, 1319, 1322, 1332, 1404, 1405, 1466, 1470, 1612, 1623, 1760, 1763, 1789, 1797, 1803, 1804, 1806, 1807, 1808, 1809, 1822, 1824, 1892, 1990, 1994, 2020, 2093, 2094, 2096, 2100, 2106, 2130, 2133, 2134, 2138, 2140, 2144, 2148, 2150, 2154, 2155, 2158, 2161, 2178, 2189, 2190, 2191, 2195, 2197, 2203], "preexist": [2, 2159, 2191, 2194], "behavior": [2, 3, 8, 13, 16, 22, 24, 26, 30, 31, 32, 34, 35, 36, 37, 39, 40, 44, 49, 52, 56, 57, 58, 60, 64, 65, 68, 69, 88, 254, 319, 471, 499, 513, 544, 617, 698, 796, 806, 851, 895, 908, 922, 935, 936, 978, 984, 986, 988, 1001, 1004, 1015, 1036, 1139, 1144, 1145, 1146, 1147, 1189, 1197, 1198, 1202, 1242, 1314, 1325, 1328, 1330, 1360, 1367, 1371, 1384, 1385, 1386, 1401, 1409, 1414, 1416, 1516, 1519, 1540, 1550, 1580, 1596, 1620, 1633, 1651, 1686, 1756, 1757, 1760, 1761, 1770, 1772, 1824, 1826, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1886, 1892, 1908, 1915, 1956, 1994, 2018, 2033, 2091, 2093, 2097, 2098, 2100, 2102, 2104, 2115, 2117, 2119, 2128, 2130, 2133, 2134, 2145, 2146, 2147, 2150, 2154, 2156, 2157, 2158, 2162, 2163, 2166, 2172, 2175, 2185, 2191, 2192, 2194, 2196, 2208], "let": [2, 8, 9, 25, 26, 30, 36, 39, 52, 65, 69, 486, 496, 994, 995, 997, 1228, 1237, 1268, 1314, 1334, 1344, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1360, 1361, 1364, 1366, 1373, 1375, 1377, 1378, 1580, 1770, 1787, 1877, 2011, 2100, 2115, 2116, 2127, 2130, 2132, 2133, 2134, 2136, 2142, 2144, 2145, 2146, 2147, 2148, 2157, 2158, 2167, 2168, 2171, 2176, 2189, 2190, 2192, 2194, 2195, 2196, 2197, 2198, 2203, 2205, 2208], "first": [2, 5, 6, 8, 10, 16, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 48, 51, 52, 56, 57, 58, 60, 66, 69, 71, 80, 83, 88, 216, 254, 286, 290, 589, 610, 697, 700, 702, 705, 771, 806, 807, 829, 884, 887, 889, 904, 905, 914, 919, 920, 921, 922, 924, 935, 936, 944, 949, 958, 967, 969, 970, 974, 975, 977, 978, 979, 982, 984, 986, 1000, 1036, 1039, 1052, 1055, 1132, 1134, 1135, 1136, 1141, 1144, 1149, 1162, 1164, 1183, 1198, 1203, 1204, 1206, 1207, 1208, 1212, 1213, 1226, 1241, 1257, 1268, 1271, 1279, 1280, 1281, 1291, 1303, 1312, 1322, 1327, 1328, 1334, 1339, 1344, 1347, 1354, 1370, 1373, 1380, 1381, 1383, 1386, 1387, 1403, 1409, 1412, 1415, 1416, 1417, 1419, 1441, 1466, 1472, 1477, 1480, 1484, 1490, 1491, 1497, 1508, 1509, 1511, 1512, 1522, 1523, 1525, 1530, 1531, 1545, 1548, 1549, 1550, 1565, 1572, 1574, 1575, 1596, 1609, 1668, 1756, 1760, 1770, 1779, 1780, 1790, 1791, 1793, 1804, 1813, 1819, 1840, 1841, 1842, 1843, 1844, 1856, 1859, 1860, 1864, 1869, 1872, 1874, 1877, 1882, 1892, 1893, 1919, 1920, 1928, 1936, 1955, 1970, 1973, 1979, 2012, 2013, 2017, 2022, 2024, 2030, 2039, 2042, 2045, 2047, 2050, 2067, 2091, 2093, 2095, 2096, 2100, 2103, 2107, 2114, 2115, 2117, 2126, 2127, 2130, 2133, 2135, 2136, 2137, 2138, 2142, 2144, 2145, 2146, 2147, 2148, 2154, 2157, 2159, 2161, 2166, 2167, 2168, 2170, 2171, 2172, 2176, 2181, 2184, 2185, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2202, 2203, 2204, 2205, 2206], "accord": [2, 10, 32, 34, 36, 37, 38, 41, 811, 891, 892, 910, 972, 984, 1142, 1278, 1375, 1408, 1466, 1484, 1523, 1592, 1738, 1760, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1865, 1872, 1875, 1893, 1956, 1982, 1995, 2012, 2046, 2096, 2109, 2116, 2117, 2142, 2146, 2148, 2157, 2158, 2168, 2178], "retain": [2, 10, 30, 704, 706, 707, 710, 904, 905, 910, 1318, 1336, 1367, 1371, 1384, 1402, 1412, 1414, 1415, 1417, 1420, 1471, 1472, 1473, 1474, 1500, 1827, 1890, 1893, 1924, 1988, 1989, 1993, 2021, 2022, 2023, 2024, 2040, 2041, 2114, 2117, 2144, 2171], "over": [2, 6, 10, 13, 14, 21, 25, 26, 30, 31, 34, 36, 37, 39, 41, 49, 52, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 74, 79, 80, 83, 481, 681, 708, 749, 750, 751, 752, 753, 754, 777, 778, 783, 784, 785, 793, 794, 922, 935, 936, 958, 962, 989, 1050, 1101, 1103, 1108, 1122, 1123, 1124, 1125, 1126, 1144, 1201, 1205, 1207, 1211, 1213, 1224, 1226, 1268, 1276, 1314, 1330, 1347, 1367, 1371, 1383, 1384, 1386, 1394, 1414, 1416, 1474, 1481, 1482, 1483, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1523, 1526, 1527, 1528, 1534, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1552, 1568, 1571, 1572, 1573, 1574, 1575, 1580, 1583, 1584, 1585, 1587, 1594, 1595, 1609, 1612, 1613, 1615, 1620, 1629, 1632, 1645, 1646, 1647, 1648, 1649, 1650, 1653, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1681, 1682, 1698, 1704, 1707, 1708, 1709, 1711, 1712, 1713, 1722, 1723, 1730, 1738, 1764, 1769, 1776, 1785, 1789, 1824, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1877, 1897, 1898, 1913, 1972, 1975, 1988, 1989, 1990, 1993, 2013, 2028, 2040, 2041, 2045, 2096, 2100, 2109, 2114, 2115, 2116, 2117, 2126, 2128, 2129, 2130, 2132, 2133, 2134, 2136, 2138, 2142, 2144, 2145, 2147, 2157, 2161, 2166, 2167, 2171, 2173, 2179, 2180, 2189, 2191, 2192, 2193, 2194, 2195, 2207, 2208], "time": [2, 4, 5, 8, 9, 10, 16, 21, 25, 26, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 48, 51, 52, 54, 56, 57, 58, 60, 65, 68, 69, 71, 81, 82, 86, 87, 290, 313, 486, 487, 493, 617, 681, 696, 697, 698, 699, 700, 701, 702, 705, 756, 757, 767, 771, 775, 779, 780, 814, 816, 843, 871, 907, 944, 954, 955, 956, 957, 963, 965, 970, 982, 990, 992, 1002, 1014, 1020, 1027, 1039, 1040, 1089, 1103, 1122, 1125, 1136, 1158, 1159, 1165, 1166, 1167, 1173, 1184, 1185, 1186, 1194, 1198, 1207, 1208, 1209, 1212, 1213, 1222, 1232, 1242, 1303, 1311, 1314, 1322, 1327, 1330, 1331, 1335, 1340, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1360, 1361, 1364, 1366, 1370, 1373, 1375, 1377, 1378, 1386, 1387, 1409, 1419, 1427, 1443, 1465, 1466, 1468, 1478, 1486, 1487, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1523, 1526, 1527, 1528, 1531, 1542, 1543, 1544, 1550, 1552, 1566, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1592, 1593, 1595, 1596, 1617, 1620, 1632, 1633, 1634, 1635, 1651, 1654, 1655, 1681, 1682, 1727, 1728, 1729, 1746, 1762, 1763, 1764, 1767, 1768, 1769, 1770, 1787, 1788, 1791, 1793, 1826, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1868, 1877, 1880, 1881, 1892, 1914, 1920, 1970, 1985, 1990, 1991, 2013, 2045, 2050, 2063, 2067, 2092, 2095, 2096, 2097, 2100, 2102, 2104, 2106, 2114, 2117, 2124, 2127, 2129, 2132, 2133, 2135, 2136, 2137, 2138, 2140, 2142, 2144, 2146, 2147, 2148, 2150, 2154, 2157, 2158, 2159, 2161, 2162, 2166, 2167, 2168, 2171, 2176, 2180, 2182, 2183, 2184, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2200, 2201, 2203, 2207, 2209], "4": [2, 4, 6, 13, 14, 20, 21, 23, 25, 26, 30, 32, 35, 36, 38, 39, 40, 41, 49, 51, 56, 57, 58, 65, 69, 71, 72, 73, 76, 77, 79, 80, 81, 82, 191, 208, 242, 254, 289, 311, 313, 315, 317, 321, 401, 402, 445, 446, 471, 483, 487, 493, 496, 499, 513, 517, 523, 537, 544, 556, 558, 560, 584, 585, 607, 617, 694, 695, 696, 697, 700, 702, 703, 704, 706, 707, 708, 710, 750, 752, 753, 754, 757, 759, 768, 771, 784, 785, 843, 895, 904, 905, 906, 910, 911, 912, 913, 914, 915, 917, 918, 930, 933, 935, 936, 938, 941, 942, 943, 970, 973, 976, 980, 981, 982, 986, 988, 991, 992, 995, 996, 997, 1000, 1007, 1015, 1016, 1019, 1022, 1023, 1024, 1025, 1036, 1124, 1127, 1134, 1136, 1138, 1139, 1142, 1143, 1144, 1147, 1149, 1159, 1160, 1162, 1164, 1172, 1178, 1180, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1192, 1194, 1195, 1198, 1201, 1203, 1211, 1212, 1213, 1228, 1255, 1256, 1257, 1268, 1271, 1275, 1276, 1277, 1278, 1280, 1281, 1285, 1289, 1291, 1303, 1305, 1311, 1320, 1321, 1326, 1328, 1335, 1336, 1337, 1338, 1339, 1340, 1344, 1346, 1347, 1353, 1355, 1357, 1358, 1359, 1362, 1364, 1367, 1369, 1371, 1373, 1375, 1377, 1380, 1381, 1382, 1384, 1385, 1388, 1390, 1391, 1396, 1398, 1399, 1401, 1403, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1420, 1441, 1465, 1466, 1474, 1475, 1476, 1477, 1484, 1489, 1500, 1501, 1502, 1504, 1505, 1508, 1509, 1511, 1512, 1520, 1522, 1523, 1524, 1526, 1530, 1531, 1550, 1551, 1576, 1577, 1583, 1585, 1587, 1592, 1593, 1596, 1602, 1603, 1604, 1605, 1606, 1620, 1632, 1633, 1634, 1635, 1636, 1637, 1640, 1641, 1642, 1643, 1651, 1653, 1662, 1665, 1677, 1678, 1686, 1697, 1722, 1725, 1728, 1729, 1756, 1757, 1758, 1759, 1760, 1770, 1779, 1780, 1787, 1793, 1804, 1815, 1816, 1818, 1820, 1826, 1827, 1828, 1830, 1832, 1836, 1856, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878, 1881, 1885, 1886, 1889, 1890, 1892, 1893, 1895, 1899, 1901, 1903, 1905, 1907, 1908, 1909, 1910, 1911, 1912, 1914, 1915, 1919, 1920, 1921, 1923, 1924, 1928, 1940, 1947, 1949, 1950, 1955, 1956, 1958, 1960, 1965, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1990, 1993, 1996, 1997, 2007, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2018, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2030, 2031, 2032, 2033, 2039, 2042, 2043, 2044, 2045, 2046, 2047, 2090, 2093, 2094, 2095, 2096, 2097, 2100, 2103, 2111, 2114, 2116, 2117, 2122, 2124, 2127, 2128, 2130, 2132, 2133, 2136, 2142, 2144, 2147, 2148, 2150, 2154, 2157, 2158, 2161, 2163, 2166, 2171, 2172, 2174, 2175, 2176, 2177, 2178, 2189, 2191, 2192, 2193, 2195, 2199, 2202, 2204, 2205], "fact": [2, 4, 9, 60, 495, 971, 980, 1021, 1238, 1268, 1272, 1273, 1350, 1351, 1378, 2093, 2133, 2136, 2138, 2154, 2167, 2171, 2189, 2192, 2194, 2198, 2204], "reset": [2, 30, 32, 771, 839, 846, 923, 1037, 1092, 1094, 1109, 1110, 1111, 1314, 1531, 1580, 1595, 1597, 1769, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1882, 1899, 2073, 2074, 2080, 2081, 2109, 2154, 2165], "phase": [2, 21, 26, 806, 1014, 1350, 1351, 1872, 1877, 1878, 1994, 2094, 2148, 2195, 2205], "iter": [2, 3, 4, 8, 21, 26, 30, 31, 32, 34, 35, 36, 39, 52, 55, 56, 60, 69, 71, 76, 958, 969, 1007, 1051, 1052, 1053, 1054, 1055, 1056, 1089, 1092, 1094, 1117, 1226, 1228, 1314, 1387, 1580, 1581, 1582, 1590, 1591, 1770, 1771, 1772, 1775, 1776, 1777, 1778, 1785, 1786, 1788, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1821, 1823, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 1863, 1864, 1865, 1869, 1877, 1882, 1951, 1995, 2005, 2073, 2074, 2086, 2094, 2096, 2097, 2100, 2114, 2116, 2122, 2126, 2127, 2128, 2130, 2132, 2133, 2136, 2137, 2138, 2142, 2157, 2159, 2165, 2170, 2176, 2189, 2192, 2195, 2203, 2204, 2205, 2206], "recreat": [2, 2127, 2203, 2204], "valid": [2, 21, 27, 29, 30, 32, 36, 39, 49, 56, 57, 69, 87, 758, 759, 768, 804, 993, 1004, 1005, 1012, 1014, 1086, 1144, 1216, 1228, 1238, 1312, 1314, 1315, 1336, 1350, 1351, 1360, 1361, 1362, 1373, 1378, 1409, 1507, 1508, 1509, 1661, 1662, 1663, 1686, 1760, 1799, 1804, 1807, 1833, 1834, 1861, 1862, 1868, 1869, 1870, 1871, 1873, 1874, 1875, 1876, 1892, 2093, 2094, 2095, 2096, 2100, 2116, 2117, 2127, 2130, 2133, 2137, 2139, 2146, 2150, 2154, 2157, 2159, 2166, 2167, 2184, 2186, 2191, 2192, 2193, 2200, 2205], "altern": [2, 10, 25, 30, 36, 37, 69, 681, 829, 1205, 1206, 1277, 1322, 1386, 1609, 1626, 1628, 1705, 1770, 1832, 1860, 1934, 1935, 2033, 2090, 2091, 2097, 2117, 2127, 2139, 2142, 2145, 2146, 2147, 2148, 2177, 2186, 2195, 2202, 2204], "assign": [2, 8, 10, 12, 25, 30, 34, 36, 41, 51, 52, 56, 65, 67, 69, 415, 681, 866, 868, 869, 965, 1312, 1314, 1315, 1484, 1515, 1580, 1587, 1590, 1591, 1771, 1772, 1793, 1877, 2093, 2097, 2100, 2126, 2133, 2134, 2135, 2136, 2150, 2154, 2161, 2167, 2168, 2175, 2176], "never": [2, 6, 8, 26, 30, 51, 52, 56, 57, 58, 221, 222, 809, 909, 990, 1002, 1150, 1311, 1361, 1362, 1373, 1386, 1770, 1813, 2100, 2108, 2127, 2130, 2133, 2158, 2166, 2174, 2178, 2191, 2204], "long": [2, 8, 10, 25, 36, 58, 68, 745, 760, 762, 763, 764, 765, 767, 774, 792, 1007, 1015, 1202, 1218, 1241, 1290, 1415, 1472, 1499, 1515, 1523, 1550, 1551, 1587, 1670, 1833, 1891, 2005, 2008, 2012, 2022, 2024, 2029, 2092, 2096, 2103, 2114, 2115, 2116, 2117, 2127, 2128, 2130, 2133, 2135, 2144, 2146, 2154, 2158, 2159, 2165, 2173, 2174, 2176, 2177, 2189, 2192, 2195, 2199, 2202, 2204], "hard": [2, 8, 9, 30, 36, 52, 56, 58, 1144, 1387, 1535, 1688, 1689, 2093, 2094, 2095, 2111, 2117, 2127, 2136, 2150, 2154, 2158, 2195, 2196], "matter": [2, 5, 30, 60, 930, 931, 935, 1132, 1144, 1241, 1322, 1325, 1330, 1770, 2127, 2133, 2157, 2158], "discourag": [2, 1114, 1118, 1462, 2087, 2127, 2166, 2173, 2177], "aggress": [2, 34, 60, 1311, 1779, 1780, 2127, 2166, 2195], "buffer": [2, 5, 19, 25, 26, 30, 36, 37, 56, 57, 58, 60, 64, 67, 415, 910, 1052, 1055, 1089, 1198, 1201, 1211, 1314, 1322, 1325, 1336, 1386, 1494, 1495, 1496, 1516, 1553, 1554, 1555, 1580, 1620, 1762, 1770, 1773, 1781, 1783, 1790, 1793, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1810, 1820, 1822, 1857, 1859, 1877, 1924, 1965, 2015, 2095, 2111, 2117, 2118, 2127, 2132, 2133, 2142, 2145, 2147, 2154, 2157, 2189, 2195, 2209], "free": [2, 8, 30, 32, 34, 39, 41, 51, 52, 60, 69, 71, 79, 80, 1007, 1095, 1101, 1115, 1317, 1330, 1387, 2075, 2106, 2117, 2124, 2127, 2130, 2133, 2135, 2136, 2144, 2148, 2154, 2171, 2174, 2189, 2191, 2195, 2207], "reus": [2, 21, 30, 69, 486, 767, 1230, 2127, 2130, 2166, 2184, 2189, 2191, 2192, 2195, 2199, 2204, 2205, 2207], "effici": [2, 3, 4, 9, 13, 25, 34, 38, 39, 41, 60, 61, 66, 150, 771, 923, 930, 932, 935, 944, 992, 1014, 1209, 1224, 1258, 1332, 1370, 1387, 1406, 1484, 1518, 1519, 1520, 1523, 1524, 1531, 1586, 1592, 1593, 1596, 1628, 1639, 1644, 1738, 2106, 2117, 2122, 2127, 2132, 2133, 2138, 2143, 2144, 2145, 2157, 2161, 2166, 2167, 2171, 2173, 2174, 2175, 2180, 2192, 2208], "few": [2, 8, 9, 26, 32, 36, 37, 41, 1144, 1202, 1523, 1770, 2091, 2096, 2127, 2130, 2133, 2135, 2137, 2139, 2145, 2148, 2154, 2157, 2161, 2164, 2171, 2175, 2177, 2180, 2189, 2191, 2192, 2195, 2197, 2198, 2202, 2204, 2205], "occas": [2, 8, 2127], "actual": [2, 6, 9, 32, 41, 44, 56, 57, 58, 60, 65, 69, 258, 681, 803, 810, 1020, 1162, 1180, 1218, 1238, 1326, 1330, 1510, 1511, 1512, 1686, 1770, 1797, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 2091, 2095, 2096, 2100, 2104, 2115, 2127, 2130, 2132, 2133, 2136, 2138, 2144, 2146, 2148, 2150, 2151, 2161, 2166, 2173, 2178, 2191, 2192, 2194, 2195, 2197, 2204], "signific": [2, 4, 32, 1874, 1936, 2127, 2130, 2145, 2171, 2189, 2197, 2200, 2204], "amount": [2, 3, 4, 5, 8, 25, 30, 32, 37, 41, 51, 69, 950, 1066, 1094, 1097, 1101, 1311, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1526, 1568, 1583, 1632, 1669, 1798, 1799, 1801, 1802, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 2058, 2074, 2076, 2078, 2116, 2127, 2129, 2130, 2134, 2135, 2139, 2166, 2171, 2191, 2198, 2202, 2205, 2207], "unless": [2, 3, 5, 8, 21, 26, 30, 54, 56, 60, 61, 69, 488, 499, 869, 888, 909, 930, 931, 935, 973, 1037, 1078, 1201, 1218, 1314, 1358, 1363, 1376, 1386, 1415, 1533, 1580, 1628, 1764, 1804, 1822, 1838, 1860, 1877, 1928, 2033, 2096, 2100, 2102, 2117, 2127, 2130, 2136, 2139, 2146, 2147, 2158, 2162, 2184, 2191, 2202], "heavi": [2, 30, 2117, 2127, 2148, 2194], "pressur": [2, 60, 2127], "might": [2, 3, 4, 5, 10, 16, 17, 20, 21, 30, 32, 35, 37, 38, 39, 51, 56, 58, 65, 68, 69, 150, 486, 544, 895, 923, 954, 1036, 1330, 1331, 1686, 1770, 1772, 1779, 1780, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 2091, 2093, 2109, 2117, 2127, 2129, 2130, 2132, 2133, 2138, 2140, 2146, 2147, 2149, 2154, 2157, 2158, 2161, 2166, 2167, 2168, 2171, 2175, 2177, 2178, 2183, 2184, 2189, 2191, 2192, 2194, 2195, 2196, 2197, 2203, 2204, 2205], "keep": [2, 4, 6, 8, 25, 26, 32, 34, 35, 38, 41, 51, 53, 56, 57, 60, 71, 486, 1040, 1228, 1386, 1494, 1495, 1496, 1522, 1542, 1543, 1544, 1589, 1620, 1686, 1697, 1770, 1800, 1835, 1913, 1936, 2091, 2093, 2100, 2114, 2116, 2127, 2130, 2132, 2134, 2135, 2138, 2144, 2150, 2157, 2161, 2166, 2167, 2168, 2173, 2180, 2191, 2192, 2193, 2194, 2195, 2202, 2204, 2207], "track": [2, 38, 41, 53, 56, 57, 58, 71, 335, 945, 956, 1047, 1092, 1094, 1109, 1110, 1111, 1201, 1202, 1218, 1228, 1416, 1494, 1495, 1496, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1620, 1770, 1800, 2073, 2074, 2080, 2081, 2108, 2109, 2114, 2116, 2127, 2130, 2133, 2134, 2135, 2140, 2142, 2157, 2159, 2167, 2168, 2171, 2177, 2191, 2192, 2194, 2195, 2201, 2204], "appli": [2, 4, 6, 9, 14, 25, 26, 32, 34, 35, 36, 37, 38, 39, 41, 44, 51, 58, 60, 64, 65, 66, 69, 71, 82, 88, 119, 321, 398, 472, 486, 513, 517, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 746, 749, 750, 751, 752, 753, 754, 769, 771, 777, 778, 779, 780, 781, 782, 783, 784, 785, 791, 792, 793, 794, 795, 825, 826, 827, 828, 869, 888, 930, 931, 933, 934, 935, 936, 946, 947, 949, 975, 978, 1004, 1019, 1022, 1132, 1134, 1139, 1148, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1192, 1201, 1202, 1209, 1212, 1213, 1222, 1228, 1238, 1314, 1318, 1364, 1387, 1404, 1481, 1482, 1483, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1501, 1502, 1503, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1521, 1527, 1528, 1529, 1530, 1531, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1552, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1579, 1580, 1583, 1584, 1585, 1586, 1587, 1588, 1594, 1595, 1596, 1599, 1600, 1601, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1634, 1635, 1645, 1646, 1647, 1648, 1649, 1650, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1679, 1681, 1682, 1683, 1684, 1687, 1689, 1690, 1691, 1692, 1695, 1696, 1697, 1698, 1700, 1701, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1711, 1712, 1713, 1717, 1718, 1722, 1730, 1731, 1732, 1733, 1735, 1738, 1739, 1740, 1741, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1760, 1769, 1770, 1779, 1780, 1787, 1788, 1789, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1813, 1814, 1821, 1822, 1824, 1825, 1827, 1837, 1838, 1856, 1860, 1874, 1877, 1889, 1894, 1895, 1896, 1897, 1898, 1969, 1970, 1972, 1990, 2029, 2030, 2032, 2045, 2093, 2096, 2100, 2103, 2114, 2116, 2117, 2118, 2122, 2126, 2127, 2130, 2132, 2133, 2134, 2136, 2138, 2142, 2145, 2150, 2157, 2158, 2161, 2164, 2167, 2171, 2172, 2188, 2189, 2192, 2193, 2195, 2196, 2202, 2203], "save": [2, 6, 8, 13, 17, 26, 30, 32, 34, 35, 36, 56, 60, 496, 865, 919, 920, 930, 933, 935, 936, 1057, 1209, 1313, 1314, 1319, 1322, 1330, 1332, 1386, 1580, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1868, 1871, 1875, 1877, 2093, 2094, 2100, 2104, 2107, 2116, 2133, 2134, 2136, 2137, 2142, 2144, 2146, 2150, 2154, 2155, 2157, 2158, 2159, 2166, 2171, 2176, 2181, 2184, 2185, 2189, 2192, 2195, 2197, 2207], "modifi": [2, 20, 21, 25, 26, 30, 31, 32, 34, 35, 36, 60, 69, 71, 260, 487, 488, 804, 834, 866, 868, 869, 930, 931, 933, 934, 935, 936, 954, 955, 956, 1004, 1020, 1021, 1268, 1311, 1314, 1317, 1318, 1334, 1522, 1580, 1624, 1626, 1628, 1677, 1678, 1762, 1763, 1764, 1767, 1768, 1770, 1776, 1777, 1778, 1797, 1803, 1804, 1806, 1807, 1808, 1809, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1848, 1849, 1852, 1856, 1857, 1858, 1859, 1860, 1863, 1872, 1877, 1955, 2093, 2096, 2100, 2115, 2122, 2126, 2130, 2133, 2134, 2142, 2147, 2158, 2161, 2166, 2172, 2173, 2175, 2177, 2182, 2191, 2192, 2193, 2194, 2195, 2200, 2204, 2205, 2208], "afterward": [2, 32, 56, 1580, 1760, 1770, 2136, 2171], "onc": [2, 8, 10, 17, 25, 26, 30, 31, 32, 35, 36, 37, 39, 40, 43, 44, 51, 58, 60, 63, 65, 68, 69, 930, 931, 932, 933, 935, 936, 938, 940, 957, 1144, 1314, 1318, 1386, 1516, 1580, 1770, 1791, 1793, 1824, 1870, 1874, 1877, 1892, 1938, 1942, 2036, 2093, 2096, 2100, 2106, 2109, 2114, 2126, 2127, 2129, 2130, 2133, 2136, 2138, 2140, 2142, 2151, 2157, 2158, 2171, 2176, 2180, 2184, 2189, 2192, 2193, 2195, 2201, 2204], "start": [2, 4, 5, 9, 10, 25, 26, 30, 32, 34, 39, 41, 48, 50, 51, 52, 54, 60, 64, 68, 69, 86, 233, 402, 433, 434, 496, 538, 709, 895, 924, 966, 967, 1007, 1057, 1092, 1094, 1107, 1109, 1110, 1166, 1167, 1183, 1198, 1226, 1312, 1327, 1340, 1385, 1401, 1443, 1475, 1476, 1484, 1489, 1490, 1491, 1523, 1525, 1573, 1574, 1575, 1581, 1583, 1678, 1725, 1770, 1795, 1799, 1801, 1813, 1836, 1865, 1872, 1908, 1938, 1948, 1961, 1976, 1977, 1978, 1980, 1981, 2073, 2074, 2091, 2094, 2095, 2100, 2103, 2114, 2116, 2117, 2125, 2127, 2128, 2130, 2132, 2133, 2135, 2136, 2142, 2143, 2144, 2147, 2148, 2154, 2157, 2159, 2161, 2166, 2167, 2168, 2170, 2171, 2173, 2188, 2189, 2191, 2192, 2195, 2199, 2201, 2204, 2209], "sure": [2, 8, 10, 16, 25, 30, 32, 36, 40, 43, 52, 55, 63, 69, 891, 892, 923, 1195, 1318, 1330, 1331, 1387, 1738, 1770, 1825, 1868, 2015, 2096, 2115, 2127, 2132, 2135, 2138, 2147, 2148, 2154, 2159, 2161, 2166, 2167, 2168, 2171, 2173, 2176, 2189, 2195, 2197, 2204], "been": [2, 6, 8, 10, 13, 19, 21, 25, 26, 30, 31, 34, 35, 36, 38, 39, 41, 44, 51, 55, 56, 58, 63, 64, 69, 86, 88, 486, 488, 681, 771, 930, 931, 935, 1007, 1040, 1049, 1082, 1085, 1143, 1148, 1202, 1317, 1318, 1324, 1329, 1386, 1443, 1456, 1531, 1538, 1550, 1596, 1651, 1686, 1770, 1779, 1780, 1790, 1795, 1799, 1801, 1820, 1821, 1836, 1863, 1864, 1865, 1872, 1874, 1892, 1990, 2008, 2036, 2047, 2070, 2100, 2102, 2104, 2109, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2129, 2130, 2136, 2138, 2139, 2142, 2144, 2146, 2148, 2151, 2157, 2158, 2166, 2168, 2171, 2176, 2185, 2186, 2189, 2190, 2192, 2195, 2200, 2204, 2205], "longer": [2, 30, 54, 64, 65, 486, 698, 920, 935, 949, 950, 954, 1311, 1318, 1770, 1824, 1827, 2106, 2109, 2127, 2130, 2159, 2166, 2168, 2189, 2204, 2205], "find": [2, 8, 16, 30, 51, 65, 69, 1144, 1221, 1224, 1268, 1336, 1387, 1510, 1511, 1512, 1550, 1834, 1882, 1893, 1928, 1995, 2091, 2104, 2106, 2114, 2116, 2117, 2127, 2129, 2130, 2132, 2133, 2135, 2138, 2144, 2146, 2151, 2154, 2155, 2161, 2166, 2171, 2174, 2176, 2178, 2181, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2203, 2204, 2205, 2206, 2208], "quick": [2, 8, 63, 2103, 2142, 2152, 2187, 2202], "guid": [2, 9, 11, 25, 30, 1326, 1824, 2100, 2130, 2134, 2137, 2158, 2161, 2184, 2202], "var": [2, 44, 49, 51, 55, 1494, 1495, 1496, 1533, 1534, 1542, 1543, 1544, 1552, 1620, 1683, 1896, 2041, 2094, 2096, 2115, 2155, 2191, 2199, 2205], "thing": [2, 4, 8, 9, 30, 36, 56, 58, 65, 69, 1202, 1324, 1416, 1492, 1688, 1966, 2095, 2100, 2127, 2130, 2133, 2134, 2135, 2138, 2144, 2154, 2158, 2161, 2162, 2168, 2189, 2192, 2194, 2195, 2202, 2204, 2205], "detach": [2, 6, 222, 415, 448, 458, 999, 1201, 1314, 1499, 1580, 1670, 1688, 1877, 1970, 2011, 2093, 2094, 2115, 2133, 2135, 2154, 2155, 2163, 2171, 2175, 2177, 2203], "register_hook": [2, 2115, 2127], "name": [2, 3, 4, 16, 21, 26, 30, 32, 34, 36, 38, 39, 41, 44, 45, 48, 49, 51, 54, 56, 57, 60, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 681, 708, 758, 759, 768, 805, 829, 830, 831, 832, 843, 869, 884, 888, 962, 965, 967, 1012, 1014, 1057, 1070, 1196, 1201, 1211, 1219, 1221, 1226, 1228, 1312, 1314, 1315, 1322, 1325, 1330, 1331, 1345, 1350, 1351, 1357, 1358, 1360, 1361, 1362, 1363, 1373, 1374, 1376, 1378, 1379, 1386, 1580, 1631, 1639, 1762, 1767, 1768, 1770, 1787, 1788, 1789, 1790, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1821, 1822, 1824, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1924, 1934, 2034, 2036, 2039, 2061, 2091, 2093, 2094, 2096, 2097, 2100, 2102, 2107, 2108, 2109, 2114, 2117, 2124, 2127, 2130, 2132, 2133, 2138, 2140, 2142, 2147, 2150, 2154, 2155, 2158, 2159, 2160, 2166, 2167, 2173, 2176, 2177, 2178, 2180, 2181, 2182, 2185, 2186, 2190, 2192, 2193, 2195, 2198, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2210], "factori": [2, 3, 13, 39, 41, 45, 49, 51, 65, 843, 969, 1144, 1640, 1825, 1834, 1932, 2094, 2100, 2104, 2116, 2130, 2133, 2155, 2174, 2177, 2191, 2194], "ones": [2, 4, 6, 21, 25, 30, 35, 37, 38, 39, 56, 58, 60, 65, 66, 68, 69, 71, 76, 254, 313, 402, 445, 446, 448, 515, 807, 889, 923, 939, 941, 942, 943, 944, 945, 949, 972, 984, 1002, 1127, 1135, 1157, 1201, 1208, 1209, 1212, 1311, 1314, 1326, 1335, 1361, 1377, 1386, 1493, 1513, 1522, 1526, 1533, 1534, 1552, 1580, 1584, 1585, 1587, 1589, 1595, 1632, 1641, 1642, 1643, 1677, 1738, 1756, 1760, 1769, 1770, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1804, 1817, 1819, 1822, 1832, 1833, 1877, 1896, 1913, 1931, 1936, 1961, 2014, 2018, 2036, 2048, 2094, 2096, 2098, 2100, 2104, 2115, 2116, 2127, 2128, 2130, 2133, 2141, 2143, 2145, 2146, 2150, 2154, 2155, 2157, 2158, 2161, 2166, 2168, 2170, 2172, 2173, 2174, 2177, 2198, 2203, 2204, 2205], "autograd_tensor": 2, "kwarg": [2, 6, 16, 25, 30, 31, 32, 34, 35, 36, 38, 51, 56, 57, 60, 69, 71, 580, 603, 758, 771, 773, 774, 837, 839, 840, 841, 843, 846, 920, 935, 936, 1006, 1040, 1041, 1042, 1086, 1087, 1105, 1201, 1212, 1213, 1215, 1226, 1228, 1314, 1317, 1319, 1378, 1404, 1541, 1569, 1580, 1611, 1615, 1619, 1621, 1622, 1760, 1770, 1795, 1800, 1804, 1813, 1820, 1822, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1924, 2030, 2045, 2091, 2096, 2097, 2100, 2133, 2134, 2142, 2150, 2154, 2157, 2166, 2173, 2177, 2182, 2190, 2193, 2203, 2204, 2205, 2206], "base": [2, 4, 8, 10, 14, 16, 17, 22, 25, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 44, 49, 51, 52, 54, 56, 57, 58, 60, 65, 69, 681, 804, 809, 815, 817, 839, 840, 841, 843, 846, 891, 892, 930, 933, 935, 946, 947, 956, 1002, 1027, 1106, 1107, 1121, 1142, 1144, 1187, 1234, 1245, 1268, 1278, 1316, 1328, 1340, 1378, 1389, 1391, 1393, 1401, 1493, 1516, 1553, 1580, 1583, 1584, 1585, 1589, 1595, 1597, 1624, 1626, 1628, 1703, 1738, 1769, 1770, 1776, 1777, 1778, 1785, 1787, 1795, 1799, 1801, 1842, 1859, 1860, 1889, 1899, 1924, 1936, 1994, 1995, 2012, 2022, 2024, 2046, 2092, 2094, 2096, 2100, 2117, 2129, 2130, 2132, 2133, 2136, 2142, 2159, 2161, 2166, 2167, 2171, 2172, 2173, 2175, 2176, 2178, 2181, 2182, 2184, 2191, 2192, 2193, 2195, 2197, 2204], "static": [2, 4, 9, 16, 30, 31, 36, 37, 39, 41, 51, 56, 57, 60, 71, 76, 77, 80, 681, 807, 814, 830, 832, 843, 851, 859, 887, 889, 919, 920, 921, 922, 935, 936, 1042, 1221, 1222, 1228, 1234, 1253, 1328, 1624, 1770, 1968, 2093, 2094, 2095, 2096, 2130, 2136, 2140, 2147, 2149, 2150, 2162, 2166, 2173, 2189, 2191, 2193, 2204], "Then": [2, 31, 36, 52, 69, 958, 1526, 1632, 1790, 1834, 2034, 2127, 2128, 2130, 2132, 2133, 2134, 2145, 2146, 2154, 2157, 2158, 2166, 2167, 2181, 2186, 2189, 2192, 2193, 2196], "op": [2, 5, 6, 16, 26, 30, 32, 34, 36, 37, 56, 57, 58, 60, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 150, 503, 524, 604, 690, 691, 693, 768, 805, 806, 807, 842, 851, 884, 891, 892, 923, 930, 933, 935, 936, 944, 992, 1002, 1004, 1044, 1045, 1062, 1065, 1069, 1070, 1086, 1087, 1114, 1118, 1202, 1265, 1315, 1328, 1330, 1331, 1386, 1392, 1444, 1445, 1449, 1460, 1462, 1597, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1880, 1938, 2020, 2051, 2052, 2055, 2057, 2060, 2061, 2084, 2087, 2096, 2102, 2103, 2106, 2109, 2111, 2115, 2116, 2129, 2130, 2132, 2133, 2141, 2144, 2150, 2158, 2159, 2161, 2162, 2163, 2164, 2171, 2173, 2175, 2177, 2182, 2186, 2189, 2190, 2194, 2195, 2196, 2197, 2199, 2202, 2203, 2205], "directli": [2, 4, 8, 10, 16, 17, 25, 26, 30, 32, 34, 36, 37, 38, 39, 40, 41, 50, 56, 57, 58, 60, 64, 69, 71, 84, 557, 743, 758, 920, 930, 933, 935, 1004, 1015, 1127, 1195, 1202, 1209, 1211, 1224, 1258, 1345, 1586, 1614, 1633, 1697, 1744, 1814, 2018, 2093, 2095, 2096, 2100, 2104, 2109, 2117, 2127, 2130, 2132, 2133, 2134, 2136, 2138, 2140, 2141, 2142, 2143, 2144, 2147, 2158, 2159, 2161, 2166, 2171, 2173, 2176, 2178, 2185, 2191, 2193, 2194, 2195, 2197, 2198, 2203, 2205], "ctx": [2, 6, 49, 71, 75, 919, 920, 921, 930, 931, 932, 933, 934, 935, 936, 2100, 2126, 2133, 2134, 2154, 2204], "gradcheck": [2, 1967, 2100, 2125, 2133, 2171], "extend": [2, 25, 30, 32, 36, 39, 43, 54, 69, 891, 920, 922, 930, 933, 935, 936, 1582, 1591, 1967, 2034, 2125, 2127, 2130, 2140, 2143, 2144, 2154, 2155, 2158, 2164, 2171, 2191, 2192, 2206], "staticmethod": [2, 71, 920, 922, 930, 931, 932, 933, 934, 935, 936, 2096, 2126, 2133, 2154, 2166], "result": [2, 4, 5, 6, 8, 9, 10, 14, 16, 20, 21, 25, 26, 30, 32, 36, 37, 39, 41, 44, 49, 52, 56, 57, 58, 60, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 153, 221, 222, 254, 255, 315, 335, 398, 496, 498, 499, 556, 583, 584, 585, 587, 588, 618, 697, 698, 699, 700, 701, 704, 706, 707, 708, 710, 771, 806, 810, 895, 907, 909, 928, 929, 938, 939, 940, 941, 942, 943, 949, 950, 958, 970, 973, 984, 988, 993, 999, 1001, 1002, 1004, 1005, 1014, 1015, 1019, 1023, 1025, 1051, 1053, 1056, 1057, 1086, 1087, 1101, 1123, 1124, 1125, 1126, 1127, 1139, 1144, 1162, 1165, 1171, 1180, 1187, 1189, 1192, 1197, 1198, 1201, 1202, 1203, 1206, 1207, 1212, 1213, 1222, 1226, 1237, 1242, 1251, 1254, 1258, 1276, 1277, 1279, 1291, 1305, 1314, 1317, 1318, 1326, 1330, 1331, 1333, 1335, 1336, 1340, 1354, 1356, 1358, 1359, 1367, 1371, 1373, 1375, 1376, 1377, 1384, 1394, 1395, 1402, 1412, 1414, 1415, 1416, 1417, 1419, 1420, 1471, 1474, 1489, 1490, 1491, 1516, 1518, 1519, 1520, 1524, 1526, 1531, 1545, 1550, 1580, 1586, 1596, 1624, 1625, 1626, 1627, 1628, 1632, 1668, 1686, 1697, 1753, 1756, 1757, 1770, 1787, 1790, 1822, 1825, 1826, 1827, 1828, 1834, 1837, 1872, 1877, 1880, 1882, 1889, 1890, 1893, 1899, 1912, 1918, 1933, 1948, 1960, 1971, 1973, 1975, 1979, 1986, 1988, 1989, 1990, 1993, 1994, 1995, 2007, 2011, 2012, 2017, 2018, 2020, 2021, 2023, 2033, 2036, 2040, 2041, 2045, 2079, 2093, 2094, 2095, 2096, 2100, 2103, 2104, 2106, 2115, 2116, 2117, 2124, 2126, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2135, 2138, 2139, 2142, 2144, 2145, 2146, 2147, 2149, 2150, 2151, 2154, 2157, 2159, 2161, 2162, 2163, 2166, 2167, 2170, 2171, 2173, 2174, 2176, 2177, 2178, 2182, 2183, 2185, 2190, 2191, 2192, 2194, 2198, 2201, 2202, 2203, 2204, 2205, 2206], "save_for_backward": [2, 920, 930, 932, 934, 935, 936, 2100, 2126, 2127, 2133, 2134, 2154], "grad_output": [2, 71, 919, 930, 931, 935, 936, 944, 950, 954, 955, 1314, 1580, 1877, 2094, 2127, 2130, 2133, 2134, 2142, 2199], "saved_tensor": [2, 930, 932, 933, 934, 935, 936, 2100, 2126, 2127, 2133, 2134], "inspect": [2, 30, 56, 60, 69, 961, 1314, 1326, 2126, 2133, 2140, 2158, 2162, 2174, 2195, 2197, 2198, 2204, 2206], "cost": [2, 4, 5, 9, 10, 26, 32, 34, 36, 37, 60, 486, 992, 1002, 1370, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1738, 1838, 1932, 2130, 2136, 2146, 2162, 2167, 2174, 2189, 2200, 2204, 2205], "both": [2, 3, 4, 16, 21, 25, 26, 27, 30, 31, 32, 34, 39, 44, 49, 50, 52, 56, 57, 58, 60, 68, 69, 71, 79, 80, 97, 339, 499, 740, 779, 780, 783, 784, 785, 806, 881, 922, 929, 935, 936, 939, 940, 941, 942, 943, 970, 1027, 1065, 1101, 1139, 1145, 1146, 1147, 1160, 1190, 1191, 1192, 1201, 1256, 1258, 1268, 1275, 1291, 1304, 1305, 1311, 1314, 1328, 1336, 1337, 1385, 1401, 1409, 1415, 1433, 1434, 1489, 1490, 1494, 1495, 1496, 1504, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1534, 1540, 1542, 1543, 1544, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1573, 1574, 1575, 1580, 1586, 1620, 1628, 1632, 1633, 1636, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1711, 1712, 1713, 1738, 1770, 1781, 1783, 1793, 1822, 1838, 1840, 1841, 1859, 1872, 1877, 1897, 1898, 1936, 1941, 1966, 1968, 1970, 1990, 1994, 2017, 2018, 2057, 2093, 2095, 2096, 2100, 2103, 2115, 2116, 2117, 2118, 2122, 2126, 2127, 2128, 2133, 2134, 2136, 2137, 2138, 2141, 2142, 2145, 2146, 2147, 2149, 2154, 2157, 2158, 2161, 2164, 2165, 2166, 2168, 2171, 2172, 2173, 2178, 2181, 2182, 2183, 2189, 2191, 2193, 2194, 2195, 2196, 2197, 2201, 2204, 2205], "cpu": [2, 5, 6, 16, 19, 25, 30, 32, 34, 37, 57, 60, 71, 73, 76, 80, 81, 82, 86, 87, 119, 196, 289, 326, 335, 445, 446, 447, 448, 449, 458, 486, 580, 589, 684, 895, 910, 963, 965, 971, 980, 1025, 1029, 1039, 1051, 1052, 1053, 1056, 1145, 1147, 1157, 1162, 1180, 1192, 1196, 1198, 1199, 1263, 1265, 1266, 1267, 1272, 1273, 1290, 1314, 1322, 1324, 1325, 1334, 1344, 1346, 1350, 1351, 1352, 1353, 1355, 1357, 1360, 1362, 1363, 1369, 1372, 1375, 1378, 1379, 1385, 1386, 1401, 1404, 1415, 1427, 1443, 1516, 1522, 1580, 1753, 1770, 1776, 1777, 1778, 1785, 1813, 1814, 1828, 1831, 1839, 1877, 1892, 1901, 1903, 1905, 1907, 1908, 1932, 1937, 1938, 1939, 1941, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1960, 1970, 1976, 1977, 1978, 1979, 1980, 1981, 1994, 2011, 2012, 2013, 2022, 2024, 2029, 2033, 2050, 2089, 2092, 2093, 2094, 2096, 2100, 2104, 2106, 2111, 2114, 2115, 2117, 2122, 2125, 2130, 2133, 2134, 2136, 2139, 2142, 2145, 2146, 2147, 2148, 2154, 2155, 2157, 2159, 2160, 2162, 2165, 2166, 2171, 2173, 2174, 2177, 2178, 2180, 2183, 2185, 2189, 2193, 2194, 2195, 2197, 2198, 2201, 2202, 2204, 2205], "There": [2, 6, 7, 8, 10, 14, 16, 21, 24, 30, 32, 37, 51, 56, 57, 58, 60, 61, 65, 66, 69, 681, 745, 806, 920, 935, 936, 1002, 1202, 1516, 1550, 1596, 1738, 1770, 1779, 1780, 1820, 1825, 2091, 2093, 2095, 2096, 2102, 2103, 2116, 2117, 2127, 2130, 2133, 2134, 2135, 2140, 2144, 2147, 2148, 2149, 2150, 2154, 2158, 2159, 2161, 2162, 2166, 2168, 2173, 2177, 2180, 2185, 2189, 2191, 2192, 2194, 2195, 2202, 2203, 2204, 2205], "moment": [2, 38, 71, 77, 783, 784, 785, 1023, 1838, 1840, 1841, 1842, 1844, 1856, 1860, 2106, 2114, 2141, 2159, 2166, 2201], "nvprof": [2, 5, 959, 1057, 2130], "regist": [2, 16, 17, 21, 26, 30, 34, 35, 37, 39, 51, 54, 56, 57, 58, 60, 69, 487, 488, 681, 805, 806, 884, 954, 955, 1002, 1015, 1089, 1228, 1314, 1386, 1580, 1581, 1582, 1590, 1591, 1609, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1772, 1787, 1788, 1790, 1791, 1793, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 2034, 2036, 2100, 2109, 2114, 2117, 2130, 2132, 2133, 2140, 2141, 2142, 2147, 2150, 2154, 2158, 2166, 2183, 2192, 2194, 2197, 2200], "activ": [2, 6, 8, 10, 19, 30, 34, 36, 37, 38, 54, 56, 60, 66, 805, 807, 809, 818, 822, 871, 872, 881, 891, 892, 965, 1042, 1049, 1067, 1082, 1101, 1201, 1203, 1213, 1214, 1215, 1387, 1488, 1518, 1519, 1520, 1524, 1534, 1552, 1579, 1581, 1599, 1610, 1624, 1626, 1628, 1679, 1717, 1741, 1770, 1791, 1793, 1822, 1827, 1877, 2045, 2078, 2106, 2114, 2117, 2130, 2133, 2134, 2136, 2142, 2154, 2157, 2159, 2161, 2162, 2163, 2166, 2171, 2181, 2182, 2189, 2194, 2199, 2204, 2205], "emit_nvtx": [2, 5, 1057], "vtune": [2, 5, 2202], "emit_itt": [2, 5], "use_cuda": [2, 2159], "use_devic": 2, "record_shap": [2, 2159], "with_flop": [2, 2159], "profile_memori": [2, 2159], "with_stack": [2, 2159], "with_modul": [2, 2159], "use_kineto": 2, "use_cpu": 2, "experimental_config": [2, 2159], "acc_ev": [2, 2159], "custom_trace_id_callback": [2, 2159], "hold": [2, 30, 32, 37, 49, 51, 54, 55, 56, 60, 64, 68, 69, 537, 1042, 1387, 1526, 1581, 1582, 1590, 1591, 1632, 1760, 1770, 1773, 1774, 1790, 1800, 1813, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1976, 1977, 1978, 1979, 1980, 1981, 2128, 2130, 2133, 2135, 2140, 2144, 2157, 2159, 2166, 2167, 2168, 2170, 2171, 2173, 2174, 2176, 2177, 2191, 2192, 2195], "summari": [2, 4, 52, 1057, 1102, 1940, 2109, 2136, 2176, 2182, 2192, 2198, 2205, 2207], "hood": [2, 37, 56, 68, 2114, 2127, 2130, 2132, 2144, 2158, 2168, 2193, 2194], "just": [2, 3, 8, 16, 26, 34, 39, 41, 49, 56, 58, 69, 589, 698, 708, 803, 842, 851, 919, 921, 935, 936, 958, 962, 1020, 1021, 1041, 1226, 1228, 1236, 1330, 1331, 1369, 1372, 1377, 1378, 1404, 1518, 1519, 1520, 1524, 1770, 1793, 1794, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1932, 2021, 2022, 2023, 2024, 2034, 2091, 2093, 2114, 2126, 2127, 2133, 2134, 2138, 2140, 2142, 2143, 2147, 2158, 2166, 2167, 2171, 2173, 2174, 2175, 2177, 2182, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2203, 2204], "record": [2, 6, 21, 22, 30, 34, 35, 37, 42, 43, 44, 45, 49, 52, 56, 58, 68, 69, 86, 88, 445, 446, 447, 448, 449, 486, 496, 693, 813, 837, 839, 840, 841, 846, 852, 895, 968, 971, 980, 1039, 1040, 1145, 1146, 1147, 1157, 1162, 1180, 1198, 1199, 1200, 1237, 1272, 1273, 1314, 1330, 1334, 1385, 1401, 1427, 1433, 1434, 1443, 1516, 1580, 1831, 1832, 1834, 1877, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2050, 2089, 2090, 2093, 2095, 2104, 2117, 2126, 2127, 2130, 2133, 2136, 2147, 2149, 2151, 2154, 2159, 2166, 2176, 2177, 2178, 2180, 2181, 2182, 2189, 2191, 2192, 2195, 2205, 2207, 2209], "event": [2, 33, 34, 39, 41, 50, 54, 68, 88, 486, 693, 962, 963, 964, 1040, 1101, 1104, 1330, 1331, 1392, 1433, 1434, 1738, 2109, 2114, 2130, 2159, 2176, 2180, 2202, 2207, 2209], "being": [2, 4, 6, 10, 13, 14, 21, 22, 25, 30, 32, 35, 36, 39, 41, 44, 45, 51, 52, 54, 56, 57, 60, 64, 65, 68, 69, 71, 80, 97, 150, 402, 415, 684, 771, 806, 814, 922, 935, 936, 938, 944, 1000, 1004, 1019, 1040, 1050, 1103, 1108, 1121, 1122, 1157, 1190, 1191, 1202, 1211, 1212, 1227, 1228, 1303, 1314, 1318, 1404, 1413, 1418, 1489, 1490, 1491, 1492, 1493, 1513, 1515, 1522, 1523, 1527, 1528, 1533, 1539, 1546, 1571, 1572, 1580, 1583, 1584, 1585, 1586, 1587, 1594, 1612, 1613, 1629, 1651, 1658, 1659, 1669, 1681, 1682, 1686, 1698, 1722, 1730, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1806, 1807, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1892, 1893, 1988, 1989, 1990, 2040, 2041, 2093, 2096, 2100, 2103, 2108, 2109, 2115, 2116, 2117, 2126, 2127, 2130, 2133, 2134, 2135, 2136, 2138, 2142, 2144, 2145, 2146, 2147, 2150, 2157, 2158, 2161, 2164, 2166, 2167, 2171, 2178, 2180, 2181, 2185, 2189, 2191, 2192, 2194, 2195, 2202, 2204, 2205, 2206, 2209], "those": [2, 3, 5, 6, 16, 25, 26, 30, 32, 34, 35, 36, 38, 39, 56, 58, 60, 65, 68, 69, 681, 843, 949, 1053, 1066, 1132, 1134, 1213, 1228, 1241, 1330, 1372, 1378, 1386, 1426, 1484, 1492, 1493, 1513, 1515, 1523, 1539, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1633, 1658, 1659, 1669, 1678, 1698, 1722, 1730, 1765, 1766, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1994, 2018, 2045, 2058, 2095, 2115, 2116, 2117, 2126, 2127, 2130, 2133, 2134, 2136, 2139, 2142, 2146, 2147, 2150, 2154, 2157, 2164, 2166, 2168, 2185, 2189, 2192, 2193, 2194, 2195, 2197, 2198, 2201, 2204, 2205], "report": [2, 4, 5, 20, 30, 44, 52, 68, 69, 1039, 1101, 1205, 1206, 1208, 1226, 2050, 2126, 2130, 2147, 2150, 2154, 2171, 2186, 2198, 2201, 2207], "runtim": [2, 4, 6, 16, 19, 21, 22, 30, 32, 36, 37, 38, 41, 56, 57, 58, 69, 71, 81, 82, 852, 908, 962, 1014, 1057, 1142, 1144, 1228, 1238, 1245, 1253, 1278, 1314, 1320, 1330, 1580, 1773, 1774, 1835, 1838, 1877, 1888, 2033, 2046, 2096, 2100, 2115, 2116, 2127, 2130, 2133, 2144, 2149, 2150, 2152, 2154, 2156, 2161, 2180, 2183, 2185, 2189, 2191, 2192, 2195, 2200, 2204, 2208], "note": [2, 3, 4, 6, 9, 13, 14, 16, 17, 20, 24, 25, 26, 30, 32, 35, 36, 37, 38, 39, 40, 41, 49, 51, 54, 56, 57, 58, 60, 64, 66, 68, 69, 71, 79, 80, 150, 233, 258, 377, 486, 488, 499, 500, 513, 515, 517, 746, 752, 753, 754, 804, 806, 807, 808, 814, 871, 891, 895, 914, 923, 930, 933, 935, 938, 939, 940, 941, 942, 943, 944, 945, 950, 956, 958, 965, 986, 992, 1002, 1009, 1019, 1036, 1044, 1127, 1132, 1144, 1150, 1165, 1195, 1198, 1213, 1224, 1226, 1255, 1268, 1301, 1311, 1312, 1314, 1315, 1321, 1384, 1387, 1409, 1433, 1434, 1444, 1489, 1490, 1491, 1492, 1493, 1499, 1510, 1511, 1512, 1513, 1515, 1522, 1523, 1527, 1531, 1533, 1539, 1545, 1546, 1550, 1571, 1572, 1580, 1581, 1583, 1584, 1585, 1586, 1587, 1590, 1591, 1594, 1596, 1603, 1612, 1613, 1620, 1624, 1629, 1633, 1641, 1658, 1659, 1669, 1677, 1678, 1686, 1697, 1698, 1722, 1725, 1730, 1731, 1745, 1760, 1770, 1772, 1779, 1780, 1827, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1863, 1865, 1872, 1874, 1877, 1892, 1899, 1975, 1976, 1977, 1978, 1980, 1981, 1986, 1990, 1994, 2018, 2033, 2034, 2036, 2045, 2091, 2093, 2094, 2097, 2100, 2103, 2108, 2114, 2117, 2118, 2127, 2128, 2129, 2132, 2133, 2134, 2137, 2138, 2139, 2140, 2141, 2142, 2144, 2145, 2146, 2147, 2150, 2154, 2157, 2158, 2159, 2162, 2164, 2165, 2167, 2168, 2171, 2173, 2175, 2176, 2179, 2185, 2186, 2191, 2192, 2193, 2196, 2202, 2203, 2204, 2205, 2208, 2210], "propag": [2, 6, 32, 33, 36, 37, 39, 41, 51, 69, 71, 80, 513, 697, 700, 701, 702, 706, 707, 708, 709, 777, 778, 779, 780, 790, 793, 794, 796, 797, 798, 866, 869, 970, 1190, 1191, 1226, 1237, 1251, 1471, 1779, 1780, 1975, 2114, 2115, 2117, 2126, 2130, 2133, 2138, 2140, 2166, 2177, 2181, 2182, 2191, 2194, 2195, 2203], "async": [2, 30, 31, 32, 68, 603, 1770, 2097, 2130, 2140, 2173, 2192, 2209], "task": [2, 4, 8, 26, 61, 66, 88, 1317, 1333, 1542, 1543, 1544, 2096, 2117, 2129, 2140, 2142, 2144, 2148, 2192, 2195, 2208], "cuda": [2, 4, 5, 6, 16, 18, 21, 24, 25, 26, 30, 32, 34, 35, 38, 60, 67, 86, 87, 88, 150, 289, 313, 321, 335, 340, 486, 515, 517, 524, 580, 684, 895, 907, 909, 923, 944, 965, 971, 973, 980, 1002, 1007, 1037, 1038, 1039, 1040, 1041, 1042, 1045, 1062, 1065, 1078, 1145, 1146, 1147, 1157, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1196, 1199, 1263, 1272, 1273, 1314, 1334, 1336, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1355, 1356, 1357, 1358, 1360, 1361, 1362, 1363, 1369, 1372, 1375, 1376, 1378, 1379, 1385, 1386, 1401, 1404, 1420, 1443, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1522, 1550, 1580, 1596, 1620, 1640, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1678, 1686, 1697, 1725, 1738, 1757, 1758, 1759, 1760, 1770, 1773, 1774, 1776, 1777, 1778, 1779, 1780, 1785, 1826, 1828, 1831, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1877, 1892, 1901, 1903, 1905, 1907, 1908, 1932, 1936, 1941, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1971, 1976, 1977, 1978, 1979, 1980, 1981, 1994, 2011, 2013, 2022, 2024, 2029, 2033, 2089, 2094, 2100, 2104, 2115, 2117, 2122, 2125, 2126, 2133, 2134, 2136, 2137, 2142, 2145, 2151, 2154, 2155, 2157, 2159, 2160, 2165, 2166, 2171, 2173, 2174, 2177, 2178, 2180, 2183, 2185, 2186, 2193, 2194, 2197, 2201, 2205, 2208, 2209], "cudaev": [2, 30], "approxim": [2, 4, 26, 35, 51, 69, 1209, 1268, 1378, 1387, 1484, 1529, 1594, 1610, 1617, 1684, 1730, 1741, 1788, 1836, 1860, 1882, 1936, 1995, 2018, 2094, 2096, 2130, 2132, 2133, 2138, 2154, 2199, 2210], "4u": 2, "xpu": [2, 684, 1263, 1314, 1580, 1877, 2050, 2052, 2055, 2057, 2100, 2126, 2137, 2159, 2160, 2174, 2180, 2197, 2202], "mtia": [2, 1263, 1314, 1443, 1445, 1449, 1580, 1877, 2159, 2160, 2180], "privateuseon": 2, "shape": [2, 6, 9, 13, 14, 21, 26, 30, 36, 37, 38, 39, 57, 60, 62, 64, 66, 69, 71, 72, 73, 76, 77, 79, 83, 97, 150, 171, 191, 208, 218, 400, 402, 445, 447, 449, 471, 497, 498, 513, 515, 517, 544, 566, 617, 681, 696, 698, 699, 708, 746, 756, 757, 767, 769, 771, 775, 777, 778, 779, 780, 783, 784, 785, 792, 809, 908, 914, 930, 932, 935, 939, 941, 942, 943, 962, 972, 973, 975, 978, 983, 985, 989, 990, 994, 995, 1002, 1019, 1022, 1054, 1134, 1135, 1136, 1138, 1139, 1144, 1145, 1147, 1149, 1164, 1165, 1166, 1167, 1175, 1176, 1177, 1183, 1189, 1190, 1191, 1192, 1199, 1206, 1207, 1211, 1212, 1213, 1228, 1229, 1245, 1251, 1255, 1257, 1271, 1276, 1277, 1281, 1289, 1291, 1305, 1311, 1328, 1330, 1331, 1334, 1339, 1340, 1344, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1403, 1404, 1408, 1416, 1421, 1422, 1465, 1466, 1477, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1641, 1642, 1643, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1653, 1654, 1655, 1657, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1677, 1678, 1682, 1686, 1688, 1697, 1698, 1703, 1711, 1712, 1713, 1723, 1724, 1727, 1728, 1729, 1731, 1738, 1757, 1760, 1769, 1770, 1773, 1774, 1787, 1790, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1828, 1831, 1833, 1835, 1880, 1889, 1893, 1897, 1898, 1901, 1903, 1904, 1905, 1912, 1914, 1915, 1919, 1928, 1931, 1955, 1970, 1971, 1973, 1974, 1977, 1979, 1985, 1990, 1991, 1994, 2007, 2014, 2018, 2028, 2029, 2030, 2031, 2045, 2048, 2089, 2093, 2094, 2096, 2100, 2115, 2116, 2122, 2124, 2127, 2128, 2130, 2133, 2134, 2135, 2150, 2155, 2159, 2163, 2166, 2171, 2172, 2173, 2176, 2177, 2178, 2180, 2183, 2193, 2195, 2199, 2202, 2203, 2205], "about": [2, 9, 10, 14, 19, 25, 30, 31, 32, 34, 35, 36, 37, 41, 44, 48, 50, 51, 52, 56, 61, 65, 69, 255, 486, 498, 618, 949, 950, 956, 1007, 1019, 1041, 1046, 1047, 1066, 1092, 1094, 1095, 1097, 1099, 1100, 1101, 1102, 1109, 1110, 1111, 1202, 1227, 1228, 1238, 1251, 1344, 1351, 1523, 1595, 1769, 1813, 1856, 1860, 1872, 1935, 2067, 2091, 2093, 2095, 2096, 2100, 2103, 2122, 2129, 2130, 2132, 2133, 2135, 2136, 2140, 2144, 2145, 2147, 2149, 2151, 2154, 2158, 2159, 2161, 2164, 2167, 2168, 2171, 2175, 2177, 2190, 2191, 2192, 2193, 2195, 2200, 2204, 2205], "dimens": [2, 13, 25, 30, 34, 37, 38, 39, 56, 60, 65, 66, 69, 71, 76, 80, 83, 218, 232, 233, 254, 260, 313, 315, 317, 321, 433, 434, 472, 473, 474, 493, 513, 515, 517, 537, 543, 545, 546, 560, 583, 584, 585, 587, 588, 607, 617, 697, 703, 704, 706, 707, 708, 710, 746, 769, 790, 792, 796, 904, 905, 906, 907, 916, 917, 918, 922, 935, 936, 944, 981, 989, 992, 993, 994, 995, 996, 1036, 1053, 1056, 1123, 1124, 1125, 1126, 1127, 1132, 1133, 1134, 1135, 1136, 1142, 1144, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1183, 1213, 1221, 1222, 1224, 1227, 1232, 1238, 1255, 1268, 1277, 1278, 1289, 1291, 1311, 1335, 1336, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1394, 1395, 1402, 1405, 1409, 1412, 1414, 1415, 1416, 1417, 1420, 1422, 1441, 1471, 1472, 1473, 1474, 1475, 1476, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1501, 1502, 1503, 1508, 1509, 1511, 1512, 1513, 1514, 1515, 1516, 1519, 1521, 1522, 1523, 1525, 1526, 1529, 1530, 1533, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1548, 1549, 1550, 1552, 1560, 1561, 1566, 1567, 1568, 1569, 1570, 1571, 1574, 1575, 1579, 1586, 1587, 1588, 1589, 1592, 1593, 1594, 1595, 1599, 1600, 1601, 1603, 1608, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1628, 1629, 1630, 1631, 1632, 1651, 1657, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1685, 1686, 1687, 1688, 1697, 1700, 1703, 1704, 1705, 1723, 1724, 1725, 1738, 1744, 1745, 1757, 1769, 1779, 1780, 1787, 1788, 1789, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1807, 1808, 1814, 1815, 1817, 1819, 1821, 1824, 1826, 1827, 1880, 1883, 1890, 1892, 1893, 1894, 1899, 1913, 1914, 1915, 1919, 1928, 1930, 1931, 1940, 1961, 1965, 1969, 1972, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1985, 1987, 1988, 1989, 1990, 1993, 1994, 2006, 2008, 2012, 2013, 2014, 2015, 2017, 2018, 2020, 2021, 2022, 2023, 2024, 2027, 2028, 2029, 2030, 2031, 2032, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2094, 2095, 2096, 2100, 2117, 2122, 2124, 2128, 2130, 2134, 2135, 2138, 2145, 2161, 2170, 2171, 2172, 2173, 2174, 2176, 2177, 2185, 2191, 2192, 2199], "collect": [2, 4, 8, 25, 31, 32, 34, 35, 37, 41, 51, 60, 68, 69, 814, 815, 843, 891, 892, 990, 1082, 1145, 1277, 1416, 1770, 1804, 1831, 1901, 1905, 2089, 2094, 2095, 2096, 2100, 2109, 2111, 2130, 2132, 2134, 2150, 2154, 2157, 2159, 2161, 2164, 2168, 2171, 2176, 2178, 2184, 2195, 2201, 2203, 2204, 2205, 2207, 2209], "further": [2, 5, 10, 14, 16, 21, 26, 30, 32, 56, 60, 68, 71, 81, 82, 88, 486, 1014, 1228, 1258, 1318, 1354, 1484, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1770, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1880, 2096, 2103, 2136, 2142, 2144, 2147, 2158, 2159, 2168, 2176, 2180, 2182, 2188, 2191, 2199, 2202, 2205], "group": [2, 4, 10, 25, 26, 31, 32, 34, 35, 36, 41, 48, 51, 52, 54, 55, 56, 60, 63, 69, 610, 681, 723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 749, 750, 751, 752, 753, 754, 783, 784, 785, 910, 962, 1055, 1500, 1507, 1508, 1509, 1510, 1511, 1512, 1534, 1556, 1557, 1558, 1559, 1560, 1561, 1620, 1661, 1662, 1663, 1664, 1665, 1666, 1687, 1738, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878, 2030, 2091, 2094, 2096, 2114, 2122, 2124, 2130, 2132, 2136, 2154, 2156, 2157, 2158, 2159, 2166, 2176, 2190, 2192, 2195, 2199, 2205], "prof": [2, 48, 965, 1057, 2159, 2202], "key_averag": [2, 965, 2159], "group_by_input_shap": [2, 962, 2159], "skew": [2, 4, 5, 25, 1366, 1787], "neglig": [2, 1327, 1936], "bottom": [2, 34, 60, 1490, 1686, 2103, 2202], "But": [2, 8, 60, 68, 486, 1330, 1360, 1770, 2122, 2127, 2133, 2135, 2138, 2146, 2158, 2171, 2175, 2194, 2195, 2198, 2204, 2206], "total": [2, 4, 5, 8, 22, 25, 26, 30, 36, 48, 50, 51, 52, 60, 907, 963, 965, 1056, 1095, 1101, 1115, 1198, 1276, 1277, 1425, 1499, 1526, 1539, 1546, 1571, 1586, 1632, 1724, 1770, 1776, 1778, 1785, 1826, 1828, 1830, 1865, 1872, 1914, 1940, 1990, 2075, 2078, 2091, 2095, 2109, 2111, 2117, 2130, 2136, 2139, 2144, 2157, 2171], "artifici": [2, 2171], "increas": [2, 4, 8, 26, 30, 39, 48, 60, 681, 884, 930, 932, 935, 986, 1066, 1101, 1144, 1276, 1277, 1484, 1493, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1592, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1728, 1729, 1738, 1858, 1864, 1865, 1870, 1872, 1874, 1877, 1928, 1936, 2018, 2039, 2058, 2078, 2094, 2102, 2110, 2122, 2129, 2130, 2139, 2144, 2145, 2162, 2171, 2189, 2195, 2198], "estim": [2, 4, 25, 39, 1023, 1027, 1268, 1311, 1494, 1495, 1496, 1529, 1533, 1534, 1542, 1543, 1544, 1552, 1620, 1684, 1788, 1838, 1857, 1956, 1995, 2157, 2159], "flop": [2, 2159], "hardwar": [2, 9, 889, 891, 892, 1350, 1351, 1378, 2033, 2122, 2130, 2144, 2146, 2162, 2171, 2186, 2195, 2197, 2205], "matrix": [2, 3, 26, 30, 39, 191, 208, 697, 700, 701, 702, 771, 970, 972, 981, 982, 990, 992, 993, 994, 995, 1002, 1023, 1027, 1127, 1131, 1132, 1134, 1144, 1213, 1258, 1264, 1279, 1335, 1344, 1345, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1380, 1382, 1384, 1387, 1395, 1404, 1406, 1409, 1419, 1466, 1468, 1522, 1523, 1531, 1550, 1632, 1641, 1642, 1643, 1677, 1678, 1738, 1787, 1793, 1821, 1827, 1880, 1881, 1882, 1892, 1936, 1963, 1966, 1970, 1971, 1973, 1974, 1976, 1977, 1978, 1979, 1980, 1981, 1986, 1994, 1995, 2013, 2016, 2018, 2020, 2021, 2022, 2023, 2024, 2039, 2045, 2096, 2115, 2116, 2124, 2129, 2130, 2133, 2138, 2142, 2145, 2159, 2171, 2176, 2177, 2195], "2d": [2, 32, 34, 37, 39, 60, 587, 588, 711, 714, 717, 746, 750, 753, 777, 779, 784, 790, 794, 796, 797, 798, 1023, 1027, 1132, 1144, 1370, 1371, 1482, 1486, 1490, 1493, 1494, 1495, 1508, 1511, 1515, 1519, 1523, 1527, 1542, 1543, 1548, 1574, 1583, 1585, 1586, 1587, 1633, 1634, 1635, 1646, 1649, 1651, 1654, 1659, 1662, 1665, 1673, 1678, 1681, 1708, 1712, 1722, 1725, 1788, 1821, 1898, 1973, 1979, 2020, 2106, 2117, 2124, 2133, 2159, 2161, 2171], "alloc": [2, 5, 13, 19, 20, 22, 26, 32, 34, 36, 39, 41, 51, 60, 88, 254, 331, 445, 446, 447, 448, 449, 486, 1038, 1040, 1041, 1042, 1046, 1047, 1049, 1065, 1066, 1067, 1092, 1094, 1096, 1097, 1099, 1100, 1101, 1102, 1110, 1111, 1115, 1145, 1147, 1196, 1222, 1228, 1231, 1234, 1237, 1238, 1260, 1423, 1425, 1426, 1438, 1457, 1458, 1901, 1905, 1907, 1932, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2057, 2058, 2073, 2074, 2076, 2077, 2078, 2080, 2081, 2111, 2114, 2117, 2127, 2132, 2136, 2139, 2144, 2150, 2151, 2159, 2174, 2188, 2189, 2191, 2194, 2202, 2205], "dealloc": [2, 69, 486, 1198, 1226, 2114, 2130, 2135, 2139, 2159], "line": [2, 5, 20, 21, 30, 41, 56, 57, 69, 681, 945, 962, 1144, 1202, 1314, 1325, 1580, 1651, 1686, 1877, 1940, 1968, 2093, 2096, 2097, 2104, 2117, 2128, 2133, 2138, 2139, 2146, 2148, 2154, 2159, 2171, 2186, 2188, 2192, 2193, 2195, 2197, 2198, 2201, 2204, 2205, 2207], "hierarchi": [2, 32, 36, 56, 69, 869, 1226, 1318, 2097, 2108, 2133, 2159, 2161, 2191], "callstack": [2, 30, 2159], "A": [2, 3, 4, 6, 8, 9, 10, 14, 16, 19, 20, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 48, 51, 52, 54, 56, 57, 58, 60, 61, 66, 68, 71, 72, 73, 76, 86, 87, 88, 560, 580, 583, 584, 585, 594, 625, 681, 689, 703, 708, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 756, 757, 767, 772, 773, 774, 775, 776, 803, 805, 813, 829, 888, 889, 891, 892, 964, 971, 980, 981, 983, 988, 993, 994, 995, 1001, 1002, 1004, 1007, 1008, 1012, 1014, 1015, 1019, 1023, 1027, 1039, 1040, 1052, 1054, 1055, 1056, 1129, 1144, 1149, 1157, 1158, 1159, 1171, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1212, 1213, 1224, 1228, 1230, 1257, 1268, 1271, 1272, 1273, 1277, 1304, 1305, 1306, 1307, 1310, 1312, 1314, 1317, 1322, 1325, 1327, 1330, 1331, 1335, 1339, 1344, 1345, 1346, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1384, 1387, 1395, 1403, 1404, 1405, 1406, 1410, 1443, 1477, 1493, 1497, 1499, 1515, 1518, 1519, 1520, 1522, 1523, 1524, 1532, 1533, 1541, 1551, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1570, 1579, 1580, 1586, 1609, 1614, 1616, 1624, 1629, 1630, 1640, 1644, 1651, 1657, 1669, 1688, 1698, 1705, 1717, 1738, 1744, 1745, 1760, 1771, 1772, 1773, 1774, 1781, 1783, 1787, 1790, 1793, 1814, 1815, 1818, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1854, 1856, 1857, 1858, 1859, 1860, 1864, 1865, 1868, 1871, 1872, 1874, 1877, 1882, 1892, 1894, 1895, 1896, 1897, 1898, 1909, 1915, 1921, 1924, 1956, 1965, 1968, 1969, 1972, 1985, 1989, 1990, 1994, 1995, 2015, 2020, 2021, 2022, 2023, 2024, 2028, 2029, 2030, 2032, 2033, 2041, 2045, 2048, 2050, 2091, 2093, 2094, 2095, 2096, 2100, 2103, 2106, 2115, 2116, 2117, 2122, 2124, 2126, 2129, 2130, 2133, 2134, 2135, 2136, 2137, 2144, 2145, 2147, 2154, 2156, 2157, 2158, 2159, 2161, 2166, 2167, 2168, 2171, 2172, 2173, 2174, 2176, 2177, 2180, 2182, 2189, 2190, 2193, 2194, 2195, 2197, 2199, 2202, 2203, 2204, 2205, 2206, 2207, 2210], "aten": [2, 4, 6, 14, 16, 20, 37, 56, 57, 58, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 1086, 1202, 1833, 1834, 1968, 2093, 2094, 2100, 2111, 2117, 2129, 2133, 2141, 2148, 2150, 2155, 2159, 2161, 2171, 2183, 2186, 2189, 2190, 2196, 2198, 2202, 2205], "torchscript": [2, 4, 9, 35, 56, 57, 69, 617, 1312, 1315, 1317, 1318, 1319, 1321, 1326, 1330, 1332, 1834, 2097, 2125, 2147, 2150, 2159, 2166, 2204, 2207], "eager": [2, 9, 34, 56, 58, 1002, 1015, 1044, 1222, 1227, 1312, 1315, 1326, 1444, 1939, 2096, 2100, 2130, 2136, 2137, 2159, 2162, 2164, 2177, 2189, 2195, 2196, 2197, 2201, 2204, 2205], "experiment": [2, 3, 26, 30, 32, 35, 36, 38, 56, 57, 60, 69, 71, 74, 79, 80, 83, 233, 938, 940, 944, 1002, 1012, 1119, 1202, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1345, 1356, 1358, 1359, 1363, 1376, 1738, 1770, 1860, 2093, 2095, 2100, 2104, 2115, 2116, 2130, 2132, 2137, 2146, 2148, 2150, 2158, 2159, 2160, 2180, 2184, 2186, 2191, 2205], "kineto": [2, 958, 2159], "_experimentalconfig": [2, 2159], "librari": [2, 3, 4, 5, 9, 10, 13, 16, 17, 19, 21, 22, 25, 30, 40, 49, 54, 56, 58, 61, 64, 65, 66, 69, 681, 958, 1025, 1040, 1068, 1072, 1086, 1195, 1327, 1358, 1404, 1960, 2059, 2063, 2092, 2106, 2109, 2129, 2130, 2132, 2133, 2134, 2135, 2140, 2141, 2142, 2144, 2145, 2148, 2154, 2158, 2159, 2160, 2161, 2166, 2179, 2185, 2189, 2192, 2195, 2204, 2206, 2208], "functionev": [2, 2159], "across": [2, 9, 16, 21, 22, 25, 26, 30, 32, 34, 35, 36, 37, 38, 41, 52, 60, 65, 69, 86, 617, 746, 904, 963, 1041, 1056, 1100, 1101, 1144, 1158, 1213, 1325, 1330, 1416, 1443, 1493, 1516, 1526, 1568, 1586, 1588, 1620, 1632, 1656, 1659, 1688, 1704, 1753, 1770, 1800, 1804, 1827, 1877, 1924, 2045, 2078, 2092, 2093, 2109, 2115, 2122, 2127, 2132, 2135, 2140, 2142, 2144, 2145, 2146, 2157, 2159, 2162, 2166, 2167, 2173, 2176, 2182, 2184, 2189, 2191, 2195, 2205], "cycl": [2, 486, 923, 1040, 1228, 1865, 1872, 2127, 2159], "100": [2, 21, 25, 30, 35, 39, 69, 71, 79, 80, 85, 300, 693, 749, 750, 753, 754, 958, 1057, 1275, 1314, 1326, 1332, 1370, 1385, 1392, 1401, 1416, 1465, 1484, 1492, 1493, 1494, 1495, 1496, 1508, 1509, 1511, 1512, 1514, 1515, 1542, 1543, 1544, 1580, 1587, 1589, 1620, 1629, 1668, 1669, 1722, 1843, 1861, 1862, 1868, 1869, 1870, 1871, 1873, 1875, 1876, 1877, 1894, 1949, 2031, 2094, 2096, 2114, 2129, 2130, 2157, 2162, 2168, 2170, 2171, 2176, 2190, 2193, 2198, 2204], "realli": [2, 8, 56, 69, 1226, 1228, 2096, 2117, 2127, 2158, 2194], "y": [2, 6, 13, 16, 25, 37, 39, 48, 56, 57, 58, 60, 65, 66, 69, 71, 74, 76, 77, 78, 79, 80, 81, 82, 83, 486, 617, 620, 792, 914, 916, 917, 918, 928, 929, 930, 933, 935, 936, 938, 939, 940, 941, 942, 943, 945, 946, 965, 984, 990, 1020, 1027, 1057, 1086, 1087, 1127, 1138, 1144, 1148, 1201, 1203, 1206, 1207, 1208, 1212, 1213, 1254, 1321, 1326, 1330, 1383, 1392, 1393, 1416, 1492, 1493, 1494, 1495, 1496, 1497, 1513, 1515, 1534, 1539, 1540, 1542, 1543, 1544, 1546, 1552, 1567, 1571, 1572, 1583, 1584, 1585, 1587, 1589, 1612, 1613, 1620, 1623, 1629, 1630, 1657, 1686, 1703, 1727, 1760, 1793, 1825, 1896, 1914, 1916, 1917, 1970, 1985, 2014, 2018, 2019, 2045, 2048, 2093, 2094, 2095, 2096, 2100, 2105, 2115, 2116, 2124, 2127, 2128, 2129, 2130, 2134, 2138, 2139, 2143, 2154, 2158, 2161, 2166, 2168, 2172, 2176, 2180, 2181, 2182, 2189, 2190, 2191, 2192, 2195, 2203, 2204, 2205], "column": [2, 4, 26, 30, 38, 191, 260, 584, 587, 965, 1000, 1023, 1027, 1127, 1157, 1185, 1186, 1280, 1350, 1351, 1354, 1370, 1373, 1378, 1382, 1387, 1466, 1589, 1632, 1677, 1678, 1787, 1838, 1882, 1892, 1973, 1976, 1977, 1978, 1980, 1981, 1994, 1995, 2018, 2022, 2024, 2039, 2124, 2138, 2171, 2176], "were": [2, 3, 4, 20, 21, 30, 41, 51, 55, 58, 60, 65, 68, 69, 150, 321, 335, 471, 486, 884, 919, 921, 923, 935, 936, 944, 965, 1089, 1202, 1213, 1216, 1322, 1386, 1651, 1770, 1776, 1785, 1800, 1816, 1928, 1932, 2007, 2014, 2045, 2095, 2103, 2126, 2130, 2133, 2147, 2154, 2158, 2185, 2189, 2192, 2194, 2195, 2200, 2203, 2204, 2205], "remov": [2, 4, 25, 26, 30, 32, 34, 39, 52, 55, 60, 69, 487, 488, 513, 546, 557, 708, 811, 830, 831, 832, 889, 954, 955, 958, 965, 969, 992, 993, 1089, 1202, 1259, 1311, 1314, 1318, 1404, 1405, 1409, 1501, 1502, 1503, 1580, 1581, 1590, 1688, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1788, 1794, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1806, 1807, 1808, 1809, 1811, 1812, 1822, 1824, 1827, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1892, 1908, 1930, 1985, 1994, 2020, 2027, 2029, 2091, 2106, 2117, 2118, 2127, 2133, 2142, 2147, 2150, 2154, 2155, 2158, 2168, 2173, 2178, 2192, 2195, 2197, 2200, 2203], "breviti": [2, 69, 965, 1027, 2117, 2154], "print": [2, 4, 6, 14, 20, 25, 27, 30, 36, 37, 41, 43, 48, 49, 52, 56, 57, 58, 60, 65, 68, 233, 731, 739, 740, 745, 756, 757, 767, 775, 952, 954, 955, 965, 1057, 1201, 1202, 1211, 1228, 1314, 1318, 1321, 1322, 1326, 1404, 1497, 1541, 1567, 1580, 1592, 1593, 1668, 1725, 1728, 1729, 1793, 1797, 1803, 1804, 1805, 1808, 1818, 1822, 1834, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876, 1877, 1940, 2037, 2091, 2093, 2094, 2100, 2104, 2108, 2117, 2122, 2127, 2129, 2130, 2133, 2137, 2142, 2143, 2151, 2152, 2154, 2155, 2158, 2159, 2166, 2176, 2177, 2181, 2182, 2185, 2186, 2189, 2190, 2192, 2193, 2195, 2197, 2205], "tabl": [2, 4, 30, 37, 56, 69, 965, 1004, 1522, 1677, 2094, 2096, 2130, 2133, 2141, 2157, 2158, 2159, 2161, 2166, 2171, 2178, 2194, 2196, 2198, 2201, 2205], "sort_bi": [2, 965, 2159], "self_cpu_time_tot": [2, 965, 2159], "avg": [2, 30, 37, 965, 1837], "mul": [2, 20, 56, 58, 69, 71, 74, 77, 79, 420, 758, 759, 768, 965, 1057, 1291, 1467, 2093, 2094, 2096, 2115, 2133, 2155, 2163, 2167, 2171, 2174, 2181, 2190, 2191, 2192, 2199, 2203], "32": [2, 3, 26, 30, 56, 87, 757, 1198, 1311, 1324, 1404, 1490, 1518, 1519, 1520, 1524, 1525, 1527, 1528, 1548, 1568, 1574, 1585, 1624, 1625, 1626, 1627, 1628, 1640, 1651, 1681, 1682, 1688, 1738, 2116, 2117, 2142, 2146, 2154, 2164, 2171, 2174, 2176, 2177, 2192, 2193, 2198], "048m": 2, "200": [2, 35, 1314, 1392, 1580, 1877, 1894, 2096, 2171, 2192, 2205], "27": [2, 617, 1382, 1864, 1889, 2039, 2154], "041m": 2, "powbackward0": [2, 965], "9": [2, 8, 25, 26, 30, 40, 69, 71, 76, 313, 315, 317, 321, 401, 402, 471, 513, 560, 581, 583, 708, 756, 757, 884, 986, 992, 996, 1000, 1027, 1126, 1127, 1142, 1145, 1166, 1167, 1176, 1177, 1187, 1190, 1191, 1194, 1195, 1268, 1278, 1344, 1346, 1367, 1369, 1371, 1382, 1384, 1475, 1476, 1482, 1483, 1486, 1487, 1500, 1502, 1522, 1523, 1576, 1577, 1592, 1593, 1603, 1606, 1677, 1678, 1725, 1728, 1729, 1827, 1828, 1837, 1840, 1841, 1842, 1843, 1844, 1856, 1859, 1860, 1861, 1865, 1872, 1874, 1875, 1877, 1878, 1881, 1885, 1921, 1928, 1937, 1940, 1950, 1955, 1965, 1973, 1982, 2011, 2012, 2016, 2018, 2027, 2039, 2046, 2093, 2097, 2103, 2111, 2135, 2137, 2142, 2147, 2148, 2154, 2155, 2157, 2158, 2166, 2171, 2172, 2174, 2178, 2192, 2204], "727m": 2, "55": [2, 1533, 2154], "483m": 2, "accumulategrad": [2, 965, 2127], "148m": 2, "graphroot": [2, 965], "691": 2, "816u": 2, "emit": [2, 16, 43, 48, 58, 69, 681, 1228, 1330, 1942, 2096, 2102, 2165, 2171, 2189, 2204], "nvtx": [2, 5], "program": [2, 4, 5, 9, 14, 20, 25, 29, 30, 37, 43, 52, 55, 56, 57, 60, 69, 617, 834, 958, 1020, 1021, 1092, 1094, 1202, 1241, 1936, 2073, 2074, 2093, 2095, 2097, 2110, 2127, 2135, 2140, 2143, 2144, 2146, 2147, 2148, 2150, 2154, 2161, 2176, 2183, 2184, 2185, 2186, 2189, 2191, 2192, 2193, 2194, 2195, 2197, 2200, 2202, 2205, 2207], "off": [2, 6, 8, 9, 16, 21, 29, 30, 34, 41, 60, 69, 946, 947, 971, 980, 1057, 1106, 1202, 1272, 1273, 1311, 1330, 1378, 1489, 1490, 1491, 1493, 1573, 1574, 1575, 1686, 1725, 2129, 2130, 2132, 2135, 2140, 2145, 2146, 2159, 2161, 2162, 2166, 2167, 2191, 2194, 2201], "o": [2, 26, 30, 31, 32, 39, 41, 52, 54, 55, 56, 69, 1057, 1219, 1223, 1225, 1314, 1386, 1433, 1434, 1435, 1551, 1580, 1586, 1770, 1877, 1924, 2091, 2097, 2114, 2127, 2130, 2132, 2135, 2137, 2148, 2150, 2154, 2158, 2166, 2185], "trace_nam": [2, 1057], "regular": [2, 4, 5, 30, 41, 52, 58, 60, 63, 69, 1004, 1086, 1087, 1201, 1228, 1242, 1362, 1363, 1499, 1517, 1518, 1519, 1520, 1524, 1565, 1579, 1580, 1581, 1582, 1590, 1591, 1679, 1717, 1760, 1773, 1774, 1822, 1838, 1841, 1856, 2096, 2100, 2116, 2117, 2130, 2133, 2134, 2140, 2142, 2158, 2161, 2164, 2166, 2171, 2172, 2173, 2180, 2182], "command": [2, 5, 30, 41, 49, 52, 69, 1057, 2111, 2130, 2137, 2139, 2144, 2148, 2159, 2167, 2185, 2186, 2198, 2201, 2204], "unfortun": [2, 10, 25, 56, 1770, 2127, 2133, 2193, 2194, 2204], "wai": [2, 4, 6, 8, 9, 10, 16, 25, 26, 30, 32, 35, 39, 44, 48, 56, 60, 62, 63, 68, 69, 150, 580, 681, 809, 837, 841, 846, 891, 892, 920, 923, 935, 936, 939, 941, 942, 943, 944, 949, 956, 1165, 1167, 1202, 1228, 1241, 1242, 1268, 1314, 1344, 1345, 1360, 1375, 1492, 1523, 1542, 1543, 1544, 1550, 1562, 1563, 1564, 1580, 1609, 1626, 1628, 1678, 1731, 1765, 1766, 1770, 1791, 1820, 1860, 1864, 1872, 2093, 2095, 2096, 2100, 2102, 2103, 2104, 2109, 2114, 2115, 2116, 2117, 2127, 2129, 2130, 2133, 2134, 2135, 2136, 2138, 2142, 2144, 2145, 2148, 2154, 2157, 2158, 2161, 2166, 2167, 2171, 2175, 2177, 2180, 2182, 2185, 2189, 2190, 2191, 2192, 2194, 2195, 2202, 2203, 2204, 2205, 2207], "disk": [2, 21, 25, 32, 1386, 1924, 2127, 2142, 2158, 2173, 2176], "annot": [2, 36, 37, 38, 44, 49, 69, 959, 1312, 1320, 1326, 2093, 2095, 2097, 2100, 2150, 2154, 2166, 2195, 2196, 2202, 2204], "wait": [2, 20, 30, 34, 37, 41, 49, 51, 68, 86, 88, 486, 693, 843, 1035, 1039, 1040, 1120, 1237, 1317, 1427, 1433, 1434, 1440, 1443, 1464, 1874, 2050, 2088, 2094, 2096, 2105, 2114, 2129, 2130, 2132, 2155, 2159, 2166, 2195, 2202, 2207, 2209], "either": [2, 9, 10, 16, 19, 20, 21, 25, 26, 30, 32, 35, 37, 38, 39, 41, 44, 49, 51, 52, 54, 56, 57, 58, 60, 65, 68, 69, 154, 221, 313, 321, 513, 515, 617, 681, 743, 749, 750, 751, 756, 757, 767, 775, 790, 796, 804, 888, 920, 922, 930, 931, 932, 933, 934, 935, 936, 945, 949, 950, 956, 969, 989, 1002, 1052, 1144, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1198, 1202, 1236, 1268, 1291, 1307, 1314, 1330, 1370, 1385, 1386, 1401, 1414, 1416, 1471, 1482, 1483, 1486, 1487, 1490, 1491, 1492, 1493, 1507, 1508, 1509, 1511, 1512, 1513, 1515, 1523, 1533, 1539, 1546, 1548, 1549, 1571, 1572, 1574, 1575, 1580, 1583, 1584, 1585, 1586, 1587, 1594, 1596, 1598, 1612, 1613, 1628, 1629, 1631, 1633, 1634, 1635, 1658, 1659, 1669, 1697, 1698, 1722, 1730, 1757, 1764, 1770, 1805, 1827, 1840, 1841, 1843, 1856, 1859, 1872, 1877, 1889, 1891, 1936, 1990, 1994, 2048, 2091, 2093, 2095, 2096, 2098, 2100, 2102, 2116, 2124, 2127, 2128, 2130, 2133, 2134, 2135, 2138, 2140, 2142, 2144, 2146, 2147, 2157, 2158, 2161, 2167, 2168, 2171, 2172, 2175, 2178, 2191, 2196, 2204, 2210], "nvidia": [2, 16, 30, 1050, 1064, 1066, 1097, 1103, 1108, 1121, 1122, 2033, 2130, 2135, 2139, 2146, 2148, 2161, 2171, 2180, 2183, 2186, 2189, 2201, 2202, 2205], "visual": [2, 37, 69, 1416, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1573, 1574, 1575, 1632, 2130, 2142, 2148, 2151, 2159, 2160, 2176, 2195, 2202, 2205], "nvvp": 2, "timelin": [2, 5, 1433, 1434, 2159], "load_nvprof": 2, "load": [2, 13, 16, 17, 26, 32, 35, 36, 56, 60, 67, 415, 865, 892, 961, 1002, 1038, 1314, 1318, 1325, 1330, 1523, 1580, 1760, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1847, 1848, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1924, 2093, 2100, 2104, 2105, 2106, 2107, 2116, 2122, 2127, 2130, 2140, 2142, 2146, 2148, 2154, 2166, 2176, 2185, 2186, 2197, 2198, 2202, 2205], "repl": [2, 2197], "append": [2, 4, 30, 32, 37, 68, 69, 229, 254, 607, 772, 774, 776, 1089, 1134, 1136, 1409, 1532, 1551, 1582, 1591, 1596, 1598, 1609, 1770, 2094, 2095, 2096, 2127, 2129, 2130, 2144, 2148, 2154, 2155, 2171, 2176, 2203], "size": [2, 3, 4, 8, 13, 20, 22, 25, 26, 30, 32, 34, 37, 38, 39, 41, 51, 56, 57, 58, 60, 63, 69, 71, 72, 77, 79, 80, 85, 138, 208, 242, 254, 255, 313, 315, 321, 339, 445, 446, 447, 449, 487, 493, 498, 499, 500, 513, 515, 517, 520, 523, 544, 545, 546, 566, 581, 583, 584, 585, 587, 588, 606, 607, 617, 618, 681, 701, 702, 704, 706, 707, 708, 710, 731, 739, 740, 746, 752, 753, 754, 756, 757, 767, 775, 777, 778, 779, 780, 790, 796, 797, 798, 809, 888, 895, 907, 908, 910, 922, 935, 936, 938, 939, 940, 941, 942, 943, 962, 970, 971, 973, 980, 982, 983, 984, 985, 986, 989, 993, 996, 1002, 1027, 1036, 1046, 1052, 1053, 1055, 1056, 1101, 1125, 1126, 1132, 1135, 1142, 1144, 1145, 1146, 1147, 1150, 1161, 1162, 1163, 1165, 1166, 1167, 1169, 1170, 1173, 1174, 1175, 1176, 1177, 1179, 1180, 1181, 1196, 1198, 1199, 1200, 1207, 1208, 1213, 1227, 1228, 1232, 1238, 1242, 1255, 1272, 1273, 1277, 1278, 1289, 1291, 1311, 1314, 1336, 1345, 1354, 1359, 1367, 1371, 1375, 1378, 1380, 1381, 1382, 1384, 1385, 1387, 1395, 1401, 1402, 1404, 1405, 1409, 1412, 1414, 1415, 1416, 1417, 1420, 1421, 1422, 1423, 1425, 1436, 1466, 1468, 1471, 1474, 1476, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1522, 1523, 1525, 1526, 1527, 1528, 1531, 1533, 1534, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1568, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1592, 1593, 1595, 1596, 1602, 1603, 1604, 1605, 1606, 1607, 1612, 1620, 1624, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1641, 1642, 1643, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1653, 1654, 1655, 1659, 1664, 1665, 1666, 1669, 1670, 1677, 1678, 1681, 1682, 1686, 1697, 1704, 1711, 1712, 1713, 1722, 1723, 1725, 1728, 1729, 1731, 1738, 1757, 1758, 1759, 1760, 1769, 1770, 1789, 1804, 1813, 1814, 1815, 1816, 1817, 1819, 1821, 1824, 1826, 1828, 1831, 1832, 1838, 1843, 1858, 1877, 1880, 1881, 1882, 1883, 1885, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1908, 1914, 1919, 1928, 1931, 1949, 1970, 1971, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1985, 1987, 1988, 1989, 1990, 1993, 1994, 1995, 2011, 2012, 2013, 2018, 2020, 2028, 2029, 2030, 2031, 2032, 2040, 2041, 2043, 2044, 2045, 2046, 2078, 2089, 2090, 2093, 2094, 2096, 2100, 2104, 2106, 2109, 2111, 2115, 2116, 2117, 2122, 2126, 2127, 2128, 2130, 2132, 2133, 2134, 2135, 2138, 2139, 2140, 2146, 2147, 2150, 2154, 2155, 2159, 2160, 2161, 2163, 2166, 2171, 2173, 2174, 2176, 2177, 2185, 2189, 2191, 2192, 2193, 2194, 2195, 2198, 2199, 2202, 2205, 2207], "format": [2, 4, 22, 23, 26, 30, 32, 44, 54, 57, 58, 69, 155, 170, 172, 175, 178, 179, 180, 195, 206, 209, 233, 240, 267, 297, 325, 331, 393, 499, 500, 525, 580, 583, 584, 585, 586, 587, 588, 623, 681, 746, 771, 805, 806, 895, 999, 1057, 1089, 1105, 1144, 1145, 1146, 1200, 1221, 1228, 1232, 1311, 1314, 1328, 1357, 1499, 1523, 1531, 1550, 1580, 1596, 1628, 1770, 1779, 1780, 1814, 1816, 1817, 1832, 1834, 1877, 1902, 1904, 1906, 1924, 1966, 1970, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 2090, 2091, 2093, 2096, 2097, 2102, 2117, 2118, 2122, 2130, 2133, 2139, 2142, 2149, 2150, 2154, 2155, 2159, 2161, 2166, 2167, 2171, 2174, 2176, 2178, 2202, 2204, 2205], "arg0": [2, 30], "arg1": [2, 30, 49, 50, 52, 57, 2150], "repres": [2, 9, 13, 25, 26, 30, 32, 34, 36, 37, 38, 39, 40, 41, 44, 45, 51, 54, 56, 57, 58, 60, 69, 150, 233, 771, 805, 806, 809, 919, 935, 936, 1004, 1012, 1023, 1027, 1037, 1041, 1075, 1079, 1144, 1165, 1167, 1172, 1174, 1175, 1176, 1177, 1202, 1216, 1224, 1239, 1268, 1275, 1303, 1304, 1307, 1310, 1313, 1330, 1331, 1362, 1404, 1484, 1499, 1580, 1586, 1628, 1630, 1632, 1640, 1641, 1642, 1643, 1770, 1786, 1790, 1795, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1813, 1823, 1834, 1865, 1872, 1880, 1882, 1893, 1936, 1974, 1976, 1977, 1978, 1980, 1981, 1990, 1994, 2029, 2030, 2036, 2043, 2044, 2065, 2093, 2095, 2096, 2100, 2103, 2104, 2109, 2117, 2122, 2127, 2133, 2134, 2138, 2140, 2142, 2145, 2149, 2150, 2154, 2161, 2162, 2164, 2166, 2171, 2174, 2180, 2191, 2192, 2194, 2204, 2207, 2210], "order": [2, 3, 4, 6, 19, 30, 31, 32, 34, 35, 36, 39, 52, 56, 60, 61, 66, 68, 69, 88, 150, 191, 208, 233, 313, 315, 317, 321, 331, 402, 487, 488, 681, 805, 806, 817, 884, 906, 923, 925, 944, 954, 955, 969, 981, 992, 1040, 1089, 1101, 1132, 1135, 1136, 1144, 1162, 1164, 1165, 1171, 1183, 1184, 1185, 1186, 1203, 1213, 1226, 1268, 1314, 1334, 1345, 1350, 1351, 1352, 1353, 1360, 1367, 1370, 1371, 1378, 1379, 1382, 1384, 1387, 1416, 1422, 1441, 1466, 1484, 1493, 1499, 1516, 1580, 1581, 1590, 1608, 1609, 1644, 1651, 1659, 1686, 1711, 1712, 1713, 1738, 1760, 1770, 1790, 1800, 1813, 1814, 1815, 1816, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1872, 1877, 1880, 1883, 1893, 1928, 1931, 1955, 1965, 1994, 2015, 2022, 2024, 2029, 2033, 2039, 2045, 2091, 2093, 2094, 2096, 2097, 2100, 2114, 2115, 2116, 2117, 2124, 2128, 2130, 2132, 2133, 2134, 2136, 2138, 2139, 2142, 2145, 2147, 2150, 2154, 2157, 2158, 2161, 2163, 2166, 2167, 2168, 2171, 2172, 2174, 2178, 2180, 2182, 2189, 2190, 2191, 2192, 2195, 2198, 2202, 2204, 2205], "backend": [2, 16, 50, 55, 57, 60, 752, 753, 754, 805, 806, 860, 885, 886, 889, 891, 892, 938, 944, 1002, 1004, 1012, 1014, 1067, 1101, 1144, 1202, 1227, 1232, 1328, 1351, 1358, 1360, 1378, 1433, 1434, 1435, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1639, 1644, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1686, 1725, 1738, 1770, 1834, 1835, 1936, 2034, 2036, 2094, 2095, 2105, 2106, 2110, 2112, 2113, 2125, 2129, 2130, 2133, 2145, 2146, 2150, 2154, 2156, 2160, 2162, 2164, 2171, 2180, 2193, 2195, 2196, 2197, 2198, 2199, 2201, 2204, 2212], "side": [2, 16, 30, 51, 54, 56, 57, 65, 69, 71, 74, 486, 779, 780, 783, 784, 785, 995, 1078, 1138, 1160, 1161, 1163, 1166, 1167, 1172, 1174, 1175, 1176, 1177, 1180, 1311, 1312, 1359, 1364, 1375, 1377, 1489, 1490, 1491, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1556, 1557, 1558, 1559, 1560, 1561, 1573, 1574, 1575, 1602, 1603, 1605, 1606, 1607, 1632, 1636, 1637, 1638, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1711, 1712, 1713, 1725, 1817, 1865, 1897, 1898, 1928, 1974, 1990, 2020, 2091, 2093, 2094, 2096, 2126, 2127, 2130, 2133, 2138, 2166, 2185, 2189, 2202], "creation": [2, 3, 25, 30, 32, 37, 69, 486, 756, 757, 767, 775, 843, 1039, 1202, 1770, 1772, 1795, 2050, 2093, 2097, 2109, 2114, 2122, 2127, 2130, 2166, 2168, 2171, 2177, 2191], "warmup": [2, 4, 1014, 1089, 2130, 2159, 2189, 2195, 2202], "correl": [2, 39, 52, 1023, 1507, 1508, 1509, 1510, 1511, 1512, 1518, 1519, 1520, 1524], "view": [2, 8, 9, 13, 20, 25, 26, 32, 35, 37, 41, 57, 60, 69, 71, 80, 222, 254, 435, 497, 498, 499, 607, 618, 703, 708, 771, 908, 916, 917, 918, 929, 945, 969, 984, 996, 1020, 1021, 1134, 1135, 1142, 1183, 1184, 1185, 1186, 1202, 1278, 1314, 1370, 1381, 1434, 1500, 1523, 1531, 1550, 1580, 1596, 1632, 1633, 1634, 1635, 1678, 1724, 1770, 1776, 1785, 1877, 1883, 1915, 1919, 1920, 1924, 1930, 1931, 1961, 1982, 1993, 2007, 2012, 2016, 2028, 2043, 2044, 2046, 2093, 2094, 2100, 2114, 2116, 2128, 2133, 2136, 2150, 2155, 2160, 2163, 2166, 2168, 2171, 2173, 2174, 2177, 2194, 2199, 2201, 2203, 2204, 2205], "difficult": [2, 8, 10, 36, 56, 65, 1004, 1213, 2045, 2194, 2195, 2200, 2202, 2204, 2205], "eas": [2, 69, 2129, 2133, 2139, 2191, 2203], "sequenc": [2, 25, 32, 35, 36, 37, 38, 39, 56, 58, 60, 69, 88, 150, 566, 746, 771, 829, 895, 910, 923, 944, 986, 988, 989, 992, 1000, 1015, 1051, 1052, 1056, 1129, 1143, 1145, 1213, 1226, 1276, 1277, 1280, 1330, 1370, 1416, 1484, 1494, 1499, 1507, 1516, 1523, 1531, 1550, 1586, 1596, 1609, 1624, 1625, 1626, 1627, 1628, 1641, 1678, 1738, 1790, 1793, 1800, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1828, 1831, 1835, 1857, 1861, 1899, 1901, 1905, 1928, 1987, 1990, 2031, 2045, 2047, 2089, 2093, 2094, 2095, 2100, 2117, 2122, 2130, 2135, 2136, 2150, 2154, 2158, 2166, 2170, 2177, 2178, 2189, 2191, 2192, 2193, 2195, 2203, 2205], "gener": [2, 3, 4, 8, 9, 16, 25, 26, 30, 32, 34, 36, 37, 39, 42, 44, 45, 49, 52, 56, 58, 60, 61, 62, 71, 76, 80, 153, 154, 173, 258, 286, 377, 421, 454, 481, 608, 681, 756, 757, 950, 972, 1002, 1074, 1078, 1086, 1087, 1090, 1091, 1112, 1113, 1115, 1116, 1117, 1144, 1166, 1167, 1202, 1213, 1217, 1218, 1222, 1228, 1238, 1267, 1272, 1290, 1318, 1324, 1335, 1346, 1351, 1360, 1377, 1378, 1382, 1387, 1407, 1415, 1428, 1429, 1433, 1434, 1435, 1437, 1439, 1453, 1461, 1466, 1515, 1526, 1540, 1624, 1632, 1633, 1642, 1643, 1651, 1677, 1695, 1760, 1788, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1821, 1824, 1828, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1849, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 1880, 1882, 1885, 1899, 1901, 1903, 1904, 1905, 1907, 1929, 1941, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1995, 2013, 2017, 2034, 2036, 2039, 2045, 2064, 2071, 2072, 2082, 2083, 2085, 2086, 2092, 2093, 2094, 2095, 2096, 2097, 2100, 2102, 2106, 2115, 2117, 2122, 2124, 2127, 2130, 2133, 2135, 2136, 2138, 2140, 2141, 2142, 2144, 2148, 2150, 2151, 2154, 2155, 2157, 2158, 2159, 2160, 2165, 2166, 2167, 2171, 2173, 2174, 2176, 2178, 2181, 2183, 2185, 2186, 2189, 2190, 2191, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2202, 2203, 2205, 2206], "seq": [2, 605, 771, 1001, 1416, 1531, 1550, 1586, 1596, 1624, 1626, 1628, 1816, 2027], "n": [2, 4, 21, 30, 32, 37, 38, 39, 41, 44, 49, 52, 57, 69, 229, 260, 406, 465, 466, 486, 697, 700, 701, 702, 746, 769, 771, 792, 907, 962, 968, 970, 971, 973, 980, 982, 986, 992, 993, 994, 995, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1125, 1126, 1136, 1157, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1184, 1205, 1208, 1213, 1226, 1232, 1238, 1251, 1268, 1272, 1273, 1277, 1311, 1314, 1326, 1330, 1331, 1334, 1335, 1344, 1345, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1387, 1395, 1404, 1409, 1411, 1416, 1419, 1468, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1527, 1528, 1530, 1531, 1532, 1533, 1534, 1539, 1540, 1542, 1543, 1544, 1546, 1547, 1548, 1549, 1550, 1552, 1562, 1563, 1564, 1568, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1583, 1584, 1585, 1586, 1587, 1589, 1595, 1596, 1598, 1602, 1603, 1604, 1605, 1606, 1607, 1612, 1614, 1615, 1616, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1651, 1657, 1669, 1670, 1678, 1682, 1686, 1722, 1725, 1727, 1738, 1769, 1770, 1787, 1799, 1807, 1826, 1877, 1880, 1881, 1882, 1887, 1892, 1893, 1899, 1905, 1907, 1920, 1928, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1970, 1971, 1974, 1988, 1989, 1990, 1994, 1995, 2005, 2012, 2013, 2018, 2022, 2024, 2039, 2040, 2041, 2042, 2045, 2094, 2096, 2100, 2115, 2116, 2122, 2124, 2127, 2130, 2133, 2135, 2138, 2144, 2158, 2159, 2161, 2162, 2171, 2172, 2176, 2177, 2178, 2192, 2195, 2199, 2204], "counter": [2, 30, 945, 956, 1082, 1101, 1516, 2109, 2114, 2127], "increment": [2, 30, 56, 956, 958, 1198, 1277, 1318, 1516, 2093, 2095, 2127, 2166, 2192], "object": [2, 4, 6, 7, 9, 16, 19, 25, 26, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 44, 51, 53, 54, 56, 57, 58, 60, 68, 69, 71, 73, 86, 87, 88, 206, 209, 415, 603, 623, 806, 807, 810, 813, 816, 884, 891, 910, 920, 921, 922, 930, 935, 936, 962, 964, 969, 1002, 1041, 1042, 1044, 1065, 1078, 1144, 1183, 1195, 1198, 1203, 1204, 1206, 1207, 1208, 1212, 1219, 1223, 1228, 1247, 1248, 1249, 1300, 1301, 1314, 1321, 1322, 1325, 1326, 1330, 1331, 1346, 1367, 1371, 1384, 1386, 1387, 1407, 1443, 1516, 1518, 1519, 1520, 1524, 1542, 1543, 1544, 1580, 1590, 1620, 1770, 1791, 1805, 1814, 1815, 1818, 1819, 1820, 1833, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1924, 1998, 2000, 2004, 2034, 2037, 2038, 2057, 2091, 2095, 2096, 2097, 2100, 2104, 2106, 2107, 2114, 2118, 2122, 2127, 2129, 2130, 2133, 2134, 2135, 2138, 2140, 2144, 2146, 2147, 2148, 2150, 2156, 2157, 2159, 2161, 2163, 2164, 2165, 2166, 2168, 2173, 2174, 2176, 2178, 2190, 2192, 2193, 2194, 2200, 2203, 2204, 2206, 2207, 2210], "stash": [2, 6, 1042, 2130, 2133], "associ": [2, 9, 10, 30, 32, 37, 45, 53, 56, 57, 58, 60, 927, 928, 1002, 1047, 1104, 1105, 1107, 1263, 1276, 1277, 1314, 1364, 1375, 1377, 1386, 1499, 1580, 1590, 1670, 1770, 1788, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1949, 1951, 2093, 2096, 2102, 2108, 2115, 2116, 2127, 2130, 2138, 2142, 2145, 2147, 2158, 2159, 2166, 2167, 2173, 2174, 2177, 2192, 2194, 2195, 2205, 2207, 2208], "tell": [2, 8, 69, 496, 1004, 1240, 1241, 1251, 1315, 1322, 1386, 1835, 2093, 2100, 2103, 2127, 2133, 2134, 2158, 2184, 2192, 2193, 2204, 2207], "top": [2, 4, 8, 9, 14, 25, 32, 37, 38, 39, 44, 57, 60, 64, 69, 758, 962, 1492, 1493, 1515, 1539, 1546, 1571, 1587, 1630, 1633, 1686, 1795, 1799, 1801, 1956, 2015, 2035, 2097, 2100, 2103, 2114, 2133, 2157, 2184, 2186, 2192, 2193, 2201, 2202, 2204], "m": [2, 5, 9, 21, 26, 30, 38, 39, 48, 52, 56, 58, 69, 86, 697, 700, 701, 702, 731, 739, 740, 749, 750, 751, 752, 753, 754, 756, 757, 767, 769, 775, 829, 834, 870, 890, 891, 892, 970, 982, 986, 990, 1157, 1211, 1277, 1312, 1314, 1319, 1321, 1325, 1326, 1332, 1335, 1346, 1354, 1360, 1361, 1362, 1363, 1367, 1368, 1369, 1371, 1372, 1373, 1378, 1379, 1380, 1381, 1387, 1404, 1405, 1409, 1419, 1443, 1466, 1468, 1481, 1482, 1483, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1494, 1495, 1496, 1497, 1498, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1512, 1517, 1518, 1519, 1520, 1521, 1522, 1524, 1525, 1527, 1528, 1529, 1530, 1534, 1535, 1536, 1537, 1538, 1541, 1542, 1543, 1544, 1547, 1548, 1549, 1566, 1567, 1569, 1570, 1573, 1574, 1575, 1579, 1580, 1588, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1610, 1611, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1631, 1633, 1634, 1635, 1636, 1637, 1638, 1725, 1727, 1770, 1787, 1789, 1793, 1797, 1803, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1820, 1821, 1824, 1877, 1880, 1881, 1882, 1892, 1899, 1928, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1970, 1971, 1990, 1994, 1995, 2013, 2020, 2093, 2094, 2095, 2096, 2104, 2122, 2130, 2133, 2135, 2137, 2138, 2142, 2144, 2147, 2161, 2171, 2182, 2183, 2188, 2195, 2209], "By": [2, 3, 4, 6, 16, 21, 25, 30, 34, 38, 43, 48, 56, 58, 60, 69, 88, 445, 446, 447, 448, 449, 910, 1002, 1027, 1092, 1094, 1127, 1139, 1162, 1164, 1165, 1166, 1167, 1175, 1176, 1177, 1203, 1204, 1206, 1207, 1213, 1268, 1276, 1277, 1318, 1367, 1378, 1386, 1415, 1420, 1470, 1492, 1493, 1494, 1495, 1496, 1513, 1515, 1533, 1539, 1542, 1543, 1544, 1545, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1620, 1629, 1658, 1659, 1669, 1698, 1722, 1730, 1789, 1824, 1882, 1893, 1914, 1968, 2018, 2045, 2073, 2074, 2091, 2095, 2100, 2103, 2111, 2122, 2127, 2130, 2133, 2135, 2136, 2142, 2144, 2145, 2147, 2150, 2151, 2154, 2157, 2165, 2166, 2171, 2178, 2192, 2193, 2195, 2198, 2200, 2204, 2205, 2209], "compar": [2, 4, 6, 16, 25, 34, 37, 56, 60, 69, 705, 895, 906, 944, 945, 946, 1004, 1101, 1148, 1149, 1172, 1173, 1174, 1178, 1179, 1180, 1181, 1190, 1191, 1228, 1257, 1271, 1303, 1339, 1403, 1413, 1418, 1477, 1586, 1770, 1825, 1995, 2029, 2078, 2096, 2109, 2130, 2133, 2138, 2145, 2148, 2150, 2151, 2161, 2162, 2166, 2171, 2176, 2178, 2181, 2182, 2189, 2196, 2201], "down": [2, 8, 16, 25, 39, 41, 49, 50, 52, 69, 790, 1101, 1139, 1186, 1192, 1324, 1360, 1697, 1893, 1921, 2078, 2133, 2140, 2144, 2154, 2166, 2168, 2171, 2176, 2198, 2205, 2209], "irrelev": [2, 4, 2097], "simpli": [2, 4, 16, 25, 30, 32, 38, 39, 44, 52, 56, 58, 68, 69, 893, 1202, 1301, 1312, 1488, 1517, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1936, 2093, 2095, 2117, 2127, 2134, 2138, 2142, 2143, 2159, 2171, 2191, 2192, 2193, 2195, 2200, 2204], "earlier": [2, 7, 34, 36, 60, 1779, 1780, 1994, 2127, 2130, 2135, 2136, 2140, 2147, 2154, 2159], "hand": [2, 5, 36, 58, 60, 65, 69, 995, 1138, 1144, 1312, 1359, 1364, 1375, 1377, 1488, 1590, 1609, 1974, 2020, 2033, 2093, 2095, 2096, 2127, 2138, 2142, 2144, 2147, 2158, 2171, 2192, 2194, 2195, 2204], "underwai": [2, 1084, 2130], "up": [2, 7, 8, 9, 10, 16, 21, 25, 26, 30, 34, 35, 36, 39, 41, 44, 48, 50, 51, 54, 55, 56, 58, 60, 63, 69, 790, 796, 920, 935, 936, 958, 1002, 1014, 1086, 1087, 1089, 1127, 1144, 1173, 1174, 1179, 1181, 1186, 1202, 1226, 1253, 1305, 1318, 1324, 1327, 1328, 1373, 1484, 1499, 1526, 1586, 1626, 1628, 1632, 1633, 1651, 1677, 1686, 1697, 1757, 1770, 1779, 1780, 1860, 1899, 1921, 2029, 2030, 2091, 2093, 2095, 2103, 2109, 2111, 2114, 2115, 2116, 2122, 2127, 2128, 2129, 2130, 2135, 2136, 2138, 2139, 2142, 2145, 2150, 2154, 2156, 2158, 2159, 2161, 2166, 2167, 2178, 2180, 2189, 2192, 2193, 2194, 2200, 2202, 2204, 2205, 2207, 2209], "nonzero": [2, 34, 58, 60, 1238, 1311, 1396, 1398, 1399, 1404, 2048, 2094, 2100, 2104, 2155, 2191, 2194, 2199], "themselv": [2, 10, 34, 39, 51, 60, 806, 871, 2015, 2130, 2158, 2173, 2206], "later": [2, 3, 4, 8, 24, 26, 30, 32, 34, 36, 37, 60, 68, 69, 87, 486, 756, 757, 767, 775, 961, 1078, 1237, 1386, 1550, 1573, 1574, 1575, 1596, 1610, 1711, 1712, 1713, 1741, 1770, 1994, 2093, 2127, 2129, 2132, 2142, 2147, 2159, 2167, 2168, 2180, 2185, 2192, 2200, 2204], "origin": [2, 6, 13, 14, 20, 21, 25, 26, 30, 32, 34, 36, 37, 44, 56, 57, 60, 63, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 206, 209, 221, 486, 545, 603, 607, 617, 623, 681, 771, 811, 866, 867, 868, 884, 887, 888, 987, 992, 1015, 1040, 1164, 1165, 1167, 1171, 1175, 1176, 1177, 1183, 1201, 1211, 1217, 1289, 1311, 1322, 1326, 1327, 1330, 1331, 1408, 1422, 1484, 1488, 1500, 1515, 1516, 1531, 1610, 1620, 1669, 1741, 1779, 1780, 1787, 1788, 1789, 1790, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1813, 1816, 1819, 1821, 1822, 1824, 1834, 1856, 1872, 1883, 1919, 1930, 1965, 1982, 2018, 2029, 2030, 2093, 2096, 2102, 2114, 2116, 2117, 2122, 2127, 2130, 2133, 2135, 2136, 2140, 2144, 2145, 2147, 2154, 2156, 2157, 2158, 2161, 2162, 2170, 2171, 2173, 2177, 2181, 2182, 2190, 2192, 2193, 2194, 2195, 2196, 2198, 2202, 2203, 2204, 2205, 2206], "did": [2, 8, 9, 30, 51, 1241, 1473, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 2095, 2096, 2138, 2147, 2158, 2192, 2197, 2204, 2207], "relationship": [2, 10, 36, 48, 56, 69, 999, 1268, 1630, 2127, 2130, 2147, 2158, 2173, 2194], "conceptu": [2, 4, 2117, 2127, 2134, 2168, 2193], "tag": [2, 4, 8, 30, 56, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 1012, 1386, 2091, 2092, 2100, 2140, 2147, 2158, 2161, 2176], "eventu": [2, 8, 51, 60, 1009, 2091, 2141, 2194, 2204], "itt": [2, 2159], "intel": [2, 5, 2125, 2148, 2179, 2183, 2185, 2197, 2201, 2202, 2212], "r": [2, 39, 66, 150, 919, 921, 923, 935, 936, 944, 949, 990, 1001, 1004, 1023, 1144, 1203, 1205, 1208, 1213, 1215, 1230, 1255, 1258, 1268, 1326, 1344, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1360, 1361, 1364, 1366, 1373, 1375, 1377, 1378, 1387, 1522, 1523, 1532, 1592, 1593, 1612, 1677, 1678, 1728, 1729, 1787, 1858, 1892, 2045, 2093, 2094, 2095, 2127, 2129, 2133, 2138, 2148, 2171, 2174, 2176, 2186, 2204, 2205], "instrument": [2, 4, 26, 1434, 2140, 2182], "technologi": [2, 56, 2100, 2152, 2183], "applic": [2, 3, 10, 21, 36, 39, 42, 51, 488, 814, 825, 826, 827, 828, 930, 933, 935, 1002, 1066, 1207, 1228, 1238, 1426, 1515, 1516, 1626, 1628, 1669, 1770, 1859, 2033, 2058, 2100, 2103, 2117, 2127, 2129, 2130, 2132, 2133, 2137, 2139, 2140, 2142, 2146, 2154, 2157, 2161, 2166, 2167, 2168, 2171, 2177, 2195, 2207], "tool": [2, 5, 9, 10, 20, 30, 36, 52, 57, 69, 891, 961, 1434, 1968, 2091, 2093, 2095, 2108, 2117, 2129, 2130, 2148, 2151, 2158, 2159, 2173, 2180, 2182, 2186, 2192, 2193, 2195, 2198, 2202, 2205, 2207], "With": [2, 20, 25, 30, 39, 60, 68, 750, 751, 752, 753, 754, 796, 1101, 1165, 1166, 1167, 1175, 1176, 1177, 1331, 1494, 1495, 1496, 1508, 1509, 1511, 1512, 1525, 1542, 1543, 1544, 1620, 1631, 1633, 1662, 1665, 1697, 1723, 1757, 1857, 1903, 2097, 2117, 2127, 2130, 2133, 2161, 2166, 2171, 2176, 2188, 2192, 2196, 2201, 2205], "abl": [2, 3, 8, 9, 20, 30, 32, 36, 51, 56, 65, 486, 1004, 1202, 1227, 1312, 1325, 1624, 2093, 2104, 2108, 2115, 2117, 2127, 2133, 2134, 2136, 2147, 2154, 2158, 2161, 2166, 2171, 2178, 2190, 2191, 2192, 2194, 2195, 2196, 2200, 2204, 2205, 2207], "labl": 2, "gui": 2, "detect_anomali": 2, "check_nan": 2, "engin": [2, 9, 10, 13, 17, 22, 56, 58, 335, 752, 753, 754, 930, 931, 935, 944, 956, 1213, 1899, 2045, 2127, 2130, 2132, 2133, 2149, 2150, 2166, 2167, 2183, 2195], "traceback": [2, 20, 44, 52, 56, 68, 69, 945, 1015, 1228, 1299, 1968, 2095, 2096, 2097, 2104, 2114, 2133, 2146, 2171, 2178, 2204, 2205, 2207], "fail": [2, 8, 21, 22, 30, 32, 41, 43, 44, 45, 49, 50, 51, 52, 55, 56, 68, 69, 71, 76, 80, 81, 82, 486, 949, 950, 1014, 1040, 1101, 1218, 1238, 1315, 1322, 1325, 1344, 1373, 1378, 1386, 1387, 1404, 1833, 2096, 2098, 2111, 2114, 2127, 2130, 2133, 2144, 2145, 2147, 2148, 2154, 2158, 2166, 2174, 2186, 2190, 2191, 2192, 2193, 2195, 2196, 2204, 2205, 2207], "test": [2, 4, 16, 20, 30, 49, 51, 52, 69, 71, 79, 80, 704, 710, 1002, 1161, 1163, 1164, 1169, 1170, 1175, 1176, 1177, 1179, 1181, 1228, 1236, 1242, 1247, 1248, 1249, 1254, 1300, 1301, 1305, 1306, 1308, 1309, 1834, 1877, 1957, 2092, 2093, 2097, 2109, 2114, 2127, 2136, 2138, 2146, 2156, 2157, 2159, 2160, 2176, 2182, 2186, 2194, 2204, 2205, 2206], "slow": [2, 41, 949, 1324, 1328, 1344, 1345, 1776, 1777, 1778, 1785, 1820, 2029, 2130, 2138, 2144, 2176, 2191, 2194, 2205], "import": [2, 3, 4, 6, 8, 10, 14, 16, 19, 20, 22, 25, 26, 30, 31, 32, 35, 36, 38, 39, 40, 43, 45, 48, 49, 54, 56, 57, 58, 60, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 681, 745, 752, 753, 754, 783, 784, 785, 805, 890, 891, 892, 945, 952, 954, 981, 988, 1015, 1027, 1057, 1195, 1198, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1209, 1211, 1311, 1312, 1315, 1317, 1319, 1320, 1321, 1322, 1324, 1325, 1326, 1330, 1331, 1332, 1366, 1367, 1370, 1371, 1384, 1416, 1580, 1640, 1644, 1770, 1791, 1793, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1815, 1816, 1817, 1818, 1819, 1820, 1827, 1859, 1860, 1886, 2031, 2093, 2095, 2096, 2097, 2100, 2104, 2105, 2109, 2114, 2117, 2124, 2126, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2137, 2140, 2142, 2144, 2145, 2146, 2147, 2149, 2150, 2151, 2152, 2154, 2161, 2164, 2166, 2167, 2168, 2171, 2174, 2176, 2177, 2178, 2180, 2182, 2183, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2195, 2197, 2202, 2203, 2204, 2205, 2206, 2212], "myfunc": [2, 2134], "inp": [2, 14, 25, 30, 56, 69, 925, 928, 929, 1632, 1770, 2100, 2189, 2199, 2202, 2204, 2206], "clone": [2, 17, 25, 60, 71, 87, 254, 448, 930, 931, 934, 935, 936, 945, 946, 947, 952, 954, 955, 984, 1318, 1522, 1756, 2011, 2020, 2094, 2100, 2114, 2147, 2155, 2157, 2171, 2173, 2174, 2178, 2189, 2199], "runtimeerror": [2, 16, 30, 35, 65, 69, 87, 233, 583, 708, 930, 931, 935, 945, 983, 1057, 1192, 1299, 1314, 1344, 1345, 1346, 1354, 1355, 1356, 1358, 1362, 1368, 1375, 1380, 1381, 1407, 1466, 1580, 1833, 1877, 1930, 1968, 2033, 2093, 2095, 2096, 2115, 2117, 2122, 2126, 2128, 2135, 2146, 2148, 2154, 2161, 2165, 2171, 2174, 2185, 2186, 2189], "run_fn": [2, 6, 887, 893], "recent": [2, 8, 9, 55, 68, 945, 1015, 1299, 1968, 2095, 2096, 2104, 2133, 2145, 2146, 2171, 2178, 2201, 2204, 2205], "last": [2, 6, 7, 13, 25, 26, 31, 34, 35, 37, 38, 39, 41, 51, 56, 57, 68, 69, 315, 617, 703, 771, 907, 945, 969, 971, 980, 986, 996, 1015, 1086, 1127, 1132, 1136, 1161, 1163, 1166, 1167, 1169, 1170, 1173, 1174, 1176, 1177, 1179, 1181, 1183, 1228, 1272, 1273, 1277, 1291, 1299, 1311, 1336, 1370, 1373, 1378, 1415, 1420, 1484, 1489, 1490, 1491, 1497, 1515, 1523, 1525, 1531, 1550, 1552, 1567, 1587, 1590, 1594, 1595, 1596, 1609, 1625, 1626, 1632, 1657, 1678, 1687, 1700, 1724, 1725, 1769, 1770, 1772, 1779, 1780, 1826, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878, 1919, 1928, 1936, 1965, 1968, 1976, 1977, 1978, 1980, 1981, 1982, 1990, 1994, 2013, 2015, 2018, 2043, 2044, 2095, 2096, 2104, 2109, 2115, 2127, 2130, 2133, 2138, 2146, 2158, 2159, 2171, 2177, 2178, 2190, 2192, 2198, 2204, 2205], "stdin": [2, 30, 945, 1968, 2104, 2133, 2146, 2171], "instal": [2, 3, 4, 16, 17, 30, 37, 69, 1144, 1228, 2091, 2142, 2143, 2150, 2151, 2152, 2154, 2158, 2166, 2176, 2185, 2190, 2191, 2192, 2193, 2200, 2204], "_tensor": [2, 37, 154], "py": [2, 5, 16, 20, 30, 35, 36, 39, 43, 45, 50, 52, 57, 58, 60, 69, 890, 1057, 1770, 2091, 2093, 2096, 2102, 2117, 2132, 2138, 2140, 2144, 2154, 2158, 2159, 2161, 2167, 2185, 2186, 2188, 2190, 2191, 2192, 2193, 2194, 2195, 2197, 2198, 2201, 2204, 2205, 2207], "93": [2, 617, 1126], "retain_graph": [2, 150, 923, 944, 954, 955, 1213, 2045, 2094, 2126, 2127, 2133, 2166], "90": [2, 1128, 1876, 1920, 2100, 2111], "allow_unreach": 2, "76": 2, "_forward_cl": 2, "tmp": [2, 4, 16, 30, 49, 51, 2091, 2130, 2159, 2186, 2189, 2198, 2204], "53": [2, 481], "44": [2, 321, 445, 1147, 1491, 1549, 1575, 1820, 2193], "set_detect_anomali": 2, "behaviour": [2, 56, 704, 705, 710, 1686, 1725, 1872, 1942, 2091, 2145, 2173], "interpos": [2, 2133], "grad_fn": [2, 150, 335, 488, 910, 923, 938, 939, 940, 941, 942, 943, 952, 954, 955, 1201, 1788, 1970, 2117, 2127, 2133, 2142, 2147], "node": [2, 30, 34, 35, 41, 44, 45, 50, 51, 56, 60, 69, 71, 81, 82, 681, 834, 837, 839, 840, 843, 846, 851, 867, 930, 965, 1089, 1211, 1226, 1228, 1246, 1251, 1329, 1499, 1516, 1770, 1834, 2106, 2130, 2150, 2154, 2158, 2166, 2167, 2168, 2180, 2182, 2184, 2186, 2191, 2192, 2194, 2195, 2201, 2203, 2205], "grad_mod": [2, 945, 946, 947, 2094], "least": [2, 6, 7, 9, 26, 32, 34, 39, 50, 51, 60, 260, 402, 708, 973, 1132, 1134, 1135, 1144, 1185, 1186, 1196, 1227, 1268, 1276, 1277, 1311, 1337, 1360, 1387, 1409, 1470, 1484, 1770, 1814, 2091, 2096, 2116, 2124, 2127, 2128, 2130, 2135, 2136, 2162, 2168, 2171, 2172, 2173, 2178, 2195, 2197, 2204], "intermediari": [2, 16, 39, 930, 933, 935, 2127, 2138, 2192, 2195], "access": [2, 10, 16, 19, 20, 25, 30, 32, 36, 56, 57, 68, 71, 73, 488, 557, 745, 930, 933, 935, 936, 968, 1048, 1057, 1314, 1317, 1330, 1377, 1484, 1580, 1760, 1773, 1774, 1788, 1793, 1814, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 2067, 2093, 2094, 2096, 2097, 2100, 2106, 2108, 2110, 2112, 2114, 2116, 2117, 2127, 2130, 2135, 2138, 2140, 2142, 2147, 2166, 2171, 2173, 2174, 2175, 2177, 2185, 2189, 2191, 2192, 2193, 2194, 2195, 2197, 2200, 2204, 2210], "isinst": [2, 25, 39, 69, 952, 954, 955, 1301, 1312, 2094, 2096, 2127, 2133, 2142, 2157, 2158, 2171, 2195, 2203, 2205], "dir": [2, 1086, 1834, 2091, 2096, 2158], "__call__": [2, 1314, 1580, 1877, 2192], "__class__": [2, 45, 71], "__delattr__": 2, "__dir__": 2, "__doc__": 2, "__eq__": 2, "__format__": [2, 2097], "__ge__": 2, "__getattribute__": 2, "__gt__": 2, "__hash__": [2, 2097], "__init_subclass__": 2, "__le__": 2, "__lt__": [2, 2096], "__ne__": 2, "__new__": [2, 2095, 2097], "__reduce__": [2, 2158], "__reduce_ex__": 2, "__repr__": [2, 4, 2133], "__setattr__": 2, "__sizeof__": 2, "__str__": [2, 69, 2094, 2096], "__subclasshook__": 2, "_raw_saved_result": 2, "_register_hook_dict": 2, "_saved_result": [2, 2127], "metadata": [2, 4, 6, 14, 32, 44, 45, 56, 58, 71, 79, 80, 956, 1019, 1386, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1924, 2100, 2104, 2117, 2127, 2133, 2134, 2147, 2158, 2159, 2166, 2167, 2171, 2173, 2176, 2194, 2203], "next_funct": 2, "register_prehook": [2, 2127], "allclos": [2, 65, 66, 69, 949, 950, 1086, 1166, 1167, 1173, 1174, 1202, 1203, 1205, 1206, 1207, 1208, 1212, 1213, 1362, 1364, 1375, 1377, 1380, 1381, 1406, 1793, 1819, 1892, 2045, 2094, 2100, 2134, 2155, 2171], "pack": [2, 35, 749, 750, 751, 752, 753, 754, 756, 757, 771, 792, 1330, 1331, 1406, 1516, 1531, 1550, 1596, 1813, 1814, 1815, 1816, 2094, 2106, 2117, 2127, 2130, 2135, 2148, 2161, 2192], "unpack": [2, 71, 76, 77, 771, 926, 929, 1330, 1362, 1406, 1516, 1816, 1818, 1825, 1835, 2096, 2097, 2127, 2133, 2135], "hook": [2, 30, 31, 34, 35, 37, 60, 487, 488, 759, 768, 930, 933, 935, 954, 955, 958, 1089, 1314, 1516, 1580, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1789, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1805, 1810, 1821, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 2118, 2132, 2133, 2140, 2149, 2150, 2157, 2158, 2160, 2161, 2193, 2194, 2195, 2196], "common": [2, 4, 9, 25, 36, 41, 65, 71, 696, 806, 895, 975, 978, 983, 1004, 1022, 1139, 1144, 1189, 1190, 1191, 1192, 1238, 1256, 1337, 1386, 1465, 1494, 1495, 1496, 1499, 1620, 1668, 1761, 1762, 1764, 1765, 1766, 1767, 1768, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1912, 1924, 1991, 2036, 2096, 2101, 2116, 2117, 2127, 2130, 2133, 2134, 2135, 2142, 2144, 2147, 2158, 2170, 2171, 2172, 2173, 2175, 2178, 2189, 2190, 2191, 2195, 2200, 2202, 2203, 2204, 2205, 2207], "trade": [2, 6, 9, 34, 60, 1378, 1493, 1936, 2129, 2135, 2162], "leav": [2, 9, 41, 52, 58, 150, 923, 1221, 1319, 1332, 1791, 1794, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1985, 2093, 2095, 2096, 2104, 2127, 2130, 2158, 2162, 2192, 2204], "especi": [2, 10, 13, 25, 30, 57, 69, 254, 895, 984, 1002, 1013, 1756, 2095, 2104, 2127, 2130, 2133, 2134, 2145, 2147, 2161, 2166, 2171, 2180, 2189, 2194, 2195, 2197, 2204], "notic": [2, 14, 30, 57, 70, 700, 834, 1164, 1178, 1222, 1409, 1419, 1492, 1633, 1703, 1862, 1863, 1869, 1870, 1876, 2029, 2092, 2093, 2121, 2127, 2171, 2186, 2192, 2195, 2198, 2200, 2202], "fit": [2, 10, 43, 64, 65, 499, 962, 1311, 1843, 1914, 2130, 2150, 2178, 2205], "evalu": [2, 5, 9, 10, 34, 35, 39, 56, 58, 63, 69, 704, 710, 812, 893, 949, 1014, 1101, 1208, 1209, 1218, 1226, 1228, 1253, 1314, 1484, 1488, 1494, 1495, 1496, 1517, 1534, 1542, 1543, 1544, 1552, 1580, 1594, 1599, 1620, 1730, 1738, 1753, 1791, 1843, 1865, 1877, 1899, 2096, 2097, 2133, 2142, 2149, 2150, 2171, 2180, 2183, 2191, 2193, 2194], "saved_tensors_hook": [2, 930, 933, 935, 2127], "pack_hook": [2, 2127], "unpack_hook": [2, 2127], "pair": [2, 30, 32, 38, 39, 54, 56, 617, 746, 895, 969, 990, 1027, 1178, 1224, 1228, 1328, 1378, 1416, 1572, 1581, 1586, 1590, 1727, 1858, 1908, 2095, 2096, 2102, 2115, 2122, 2127, 2130, 2166, 2167, 2168, 2176, 2178, 2182, 2195, 2202, 2204], "retriev": [2, 25, 26, 30, 35, 36, 51, 69, 87, 537, 919, 920, 935, 936, 1057, 1226, 1245, 1522, 1526, 1632, 1677, 1770, 1814, 1834, 1863, 1968, 2117, 2127, 2140, 2150, 2154, 2158, 2166, 2167, 2168, 2185, 2193, 2207], "everytim": 2, "store": [2, 4, 6, 16, 20, 26, 32, 36, 41, 45, 52, 56, 57, 58, 60, 69, 326, 332, 398, 697, 841, 846, 920, 935, 982, 1051, 1053, 1056, 1230, 1258, 1314, 1320, 1322, 1325, 1345, 1356, 1357, 1358, 1387, 1392, 1404, 1494, 1495, 1496, 1522, 1580, 1609, 1770, 1787, 1790, 1797, 1803, 1804, 1806, 1807, 1808, 1809, 1813, 1877, 1936, 1973, 2091, 2093, 2100, 2104, 2116, 2117, 2118, 2132, 2133, 2134, 2135, 2140, 2157, 2158, 2161, 2166, 2167, 2168, 2171, 2173, 2176, 2177, 2182, 2185, 2186, 2192, 2193, 2194, 2197, 2209], "content": [2, 4, 8, 21, 32, 37, 44, 56, 57, 69, 930, 933, 935, 954, 1322, 1325, 1345, 1356, 1358, 1363, 1376, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1985, 2017, 2038, 2091, 2096, 2107, 2114, 2127, 2130, 2144, 2157, 2166, 2175, 2176, 2177, 2189, 2200, 2204, 2205], "equal": [2, 14, 19, 26, 30, 39, 52, 54, 56, 69, 260, 499, 545, 617, 681, 705, 706, 707, 750, 751, 752, 753, 754, 771, 779, 780, 839, 840, 841, 846, 891, 906, 971, 978, 980, 991, 992, 1016, 1027, 1053, 1056, 1073, 1115, 1133, 1149, 1188, 1203, 1204, 1221, 1224, 1228, 1238, 1239, 1254, 1257, 1272, 1273, 1275, 1276, 1277, 1299, 1303, 1339, 1360, 1373, 1377, 1380, 1381, 1404, 1405, 1416, 1438, 1477, 1481, 1482, 1483, 1485, 1486, 1487, 1492, 1493, 1499, 1508, 1509, 1511, 1512, 1516, 1523, 1526, 1527, 1528, 1531, 1533, 1550, 1585, 1586, 1594, 1596, 1632, 1641, 1654, 1655, 1659, 1662, 1665, 1677, 1678, 1681, 1682, 1688, 1695, 1770, 1817, 1877, 1880, 1893, 1949, 1950, 1955, 1982, 1990, 2012, 2028, 2034, 2048, 2094, 2097, 2103, 2115, 2116, 2117, 2127, 2128, 2133, 2138, 2145, 2155, 2156, 2157, 2172, 2173, 2176, 2178, 2192, 2203], "term": [2, 9, 10, 39, 51, 57, 58, 69, 558, 745, 774, 805, 992, 1014, 1160, 1161, 1162, 1163, 1164, 1165, 1167, 1175, 1176, 1177, 1180, 1192, 1228, 1235, 1346, 1484, 1492, 1533, 1540, 1550, 1551, 1585, 1594, 1612, 1683, 1695, 1730, 1742, 1770, 1787, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1912, 1948, 1956, 2092, 2096, 2117, 2126, 2127, 2133, 2134, 2135, 2138, 2144, 2154, 2157, 2158, 2161, 2167, 2171, 2183, 2191, 2192, 2195, 2204], "mulbackward0": [2, 939, 942, 943, 2133], "inplac": [2, 32, 56, 63, 65, 69, 71, 79, 80, 766, 769, 787, 789, 791, 804, 811, 829, 834, 866, 868, 869, 887, 888, 893, 930, 931, 935, 956, 1002, 1202, 1314, 1488, 1498, 1517, 1518, 1519, 1520, 1521, 1524, 1536, 1537, 1538, 1566, 1579, 1580, 1599, 1600, 1601, 1608, 1610, 1623, 1652, 1660, 1671, 1672, 1673, 1674, 1675, 1679, 1690, 1691, 1692, 1701, 1717, 1732, 1733, 1736, 1739, 1741, 1751, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1848, 1849, 1856, 1857, 1858, 1859, 1860, 1877, 2033, 2094, 2103, 2127, 2133, 2154, 2182, 2199, 2203], "lead": [2, 6, 8, 24, 25, 30, 40, 56, 57, 60, 66, 69, 895, 930, 931, 935, 938, 940, 944, 950, 1004, 1195, 1213, 1218, 1228, 1345, 1550, 1596, 1612, 1877, 1979, 1985, 2045, 2096, 2100, 2116, 2117, 2127, 2129, 2132, 2133, 2134, 2136, 2144, 2145, 2148, 2157, 2158, 2161, 2166, 2171, 2176, 2177, 2189, 2196, 2204], "undefin": [2, 30, 37, 40, 44, 319, 471, 617, 908, 930, 934, 935, 936, 949, 950, 978, 986, 1004, 1147, 1197, 1198, 1414, 1492, 1833, 1886, 2100, 2122, 2127, 2130, 2133, 2134, 2146, 2166], "recurs": [2, 34, 39, 56, 58, 60, 69, 1004, 1008, 1136, 1226, 1235, 1254, 1314, 1326, 1328, 1580, 1779, 1780, 1863, 1875, 1877, 2095, 2133, 2141, 2142, 2158, 2166, 2192, 2193, 2195, 2196, 2204], "inner": [2, 4, 60, 61, 66, 830, 832, 938, 1127, 1203, 1207, 1212, 1225, 1233, 2018, 2094, 2133, 2155, 2166, 2182, 2204], "save_on_cpu": 2, "pin_memori": [2, 25, 34, 71, 73, 76, 80, 81, 82, 445, 446, 447, 448, 449, 1145, 1147, 1196, 1901, 1905, 1907, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2093, 2094, 2100, 2117, 2130, 2133, 2155, 2173, 2199], "within": [2, 6, 10, 14, 21, 25, 26, 30, 35, 36, 37, 38, 39, 51, 52, 54, 56, 57, 60, 68, 69, 87, 488, 908, 925, 949, 950, 956, 1002, 1019, 1045, 1127, 1217, 1218, 1226, 1232, 1314, 1318, 1407, 1445, 1489, 1490, 1491, 1499, 1518, 1519, 1520, 1524, 1526, 1573, 1574, 1575, 1580, 1586, 1620, 1632, 1686, 1696, 1711, 1712, 1713, 1770, 1791, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1806, 1807, 1808, 1809, 1810, 1877, 1897, 1898, 1928, 1949, 2032, 2036, 2052, 2093, 2095, 2096, 2108, 2109, 2114, 2122, 2124, 2129, 2130, 2133, 2139, 2140, 2141, 2142, 2145, 2147, 2154, 2157, 2158, 2161, 2164, 2165, 2166, 2167, 2173, 2176, 2180, 2185, 2191, 2192, 2195, 2197, 2203, 2204, 2205], "move": [2, 6, 8, 9, 10, 16, 30, 32, 56, 60, 67, 69, 86, 524, 589, 840, 1164, 1235, 1314, 1322, 1381, 1386, 1422, 1443, 1494, 1495, 1496, 1553, 1554, 1555, 1580, 1620, 1725, 1773, 1774, 1857, 1877, 2095, 2106, 2107, 2114, 2116, 2122, 2130, 2131, 2134, 2135, 2142, 2143, 2144, 2147, 2157, 2158, 2161, 2166, 2173, 2174, 2178, 2195, 2205], "copi": [2, 8, 13, 25, 26, 30, 32, 34, 41, 49, 56, 60, 64, 65, 69, 190, 196, 206, 209, 315, 402, 448, 458, 463, 471, 493, 499, 580, 581, 582, 583, 603, 617, 623, 805, 829, 866, 868, 909, 910, 928, 945, 946, 947, 969, 991, 999, 1002, 1051, 1052, 1183, 1184, 1185, 1186, 1188, 1202, 1228, 1314, 1326, 1386, 1387, 1476, 1516, 1526, 1580, 1590, 1632, 1770, 1813, 1823, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1848, 1856, 1857, 1858, 1859, 1860, 1877, 1909, 1915, 1921, 2011, 2020, 2026, 2093, 2094, 2104, 2114, 2117, 2127, 2128, 2130, 2133, 2136, 2144, 2155, 2157, 2158, 2159, 2161, 2166, 2171, 2173, 2174, 2175, 2177, 2182, 2186, 2189, 2194, 2195, 2197, 2199, 2203, 2204], "pin": [2, 32, 34, 209, 337, 445, 446, 447, 448, 449, 463, 580, 603, 623, 1145, 1147, 1196, 1314, 1580, 1813, 1877, 1901, 1905, 1907, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2117, 2147, 2173, 2180], "asynchron": [2, 4, 5, 32, 37, 68, 88, 196, 209, 580, 603, 623, 1067, 1314, 1317, 1333, 1580, 1877, 2097, 2129, 2132, 2166, 2173, 2176, 2180, 2202, 2209], "prod_1": 2, "prod_2": 2, "del": [2, 36, 56, 486, 2097, 2114, 2130, 2133, 2135], "illustr": [2, 2096, 2126, 2133, 2171, 2173, 2185, 2189, 2198], "aliv": [2, 6, 25, 41, 51, 1040, 2127, 2130, 2135, 2144, 2166, 2167, 2168], "live": [2, 35, 486, 1086, 1089, 1314, 1580, 1877, 2093, 2130, 2135, 2136, 2166, 2168, 2189, 2192, 2194, 2204, 2207], "releas": [2, 8, 24, 30, 51, 54, 64, 69, 513, 698, 992, 993, 1036, 1037, 1046, 1066, 1078, 1079, 1082, 1086, 1087, 1089, 1101, 1259, 1311, 1314, 1345, 1356, 1358, 1359, 1360, 1363, 1376, 1404, 1405, 1426, 1519, 1550, 1580, 1596, 1711, 1712, 1713, 1827, 1877, 1892, 1908, 1924, 1990, 1994, 2020, 2058, 2091, 2092, 2095, 2109, 2114, 2117, 2127, 2129, 2130, 2137, 2139, 2145, 2146, 2147, 2148, 2150, 2154, 2161, 2166, 2177, 2178, 2185, 2186, 2192, 2195, 2205], "delet": [2, 30, 36, 56, 69, 925, 927, 1037, 1042, 1047, 2091, 2106, 2114, 2127, 2130, 2155, 2165, 2166, 2168, 2173, 2203], "disable_saved_tensors_hook": 2, "error_messag": 2, "featur": [2, 6, 9, 10, 13, 14, 17, 20, 21, 30, 32, 35, 36, 52, 56, 58, 60, 61, 68, 71, 681, 700, 771, 779, 780, 938, 940, 944, 1019, 1119, 1222, 1326, 1409, 1419, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1494, 1512, 1517, 1518, 1519, 1520, 1524, 1527, 1528, 1531, 1532, 1542, 1550, 1551, 1586, 1596, 1598, 1615, 1624, 1626, 1628, 1629, 1630, 1631, 1654, 1655, 1672, 1673, 1674, 1679, 1681, 1682, 1703, 1738, 1770, 1882, 2033, 2092, 2093, 2095, 2096, 2097, 2102, 2116, 2117, 2122, 2125, 2127, 2130, 2133, 2135, 2137, 2138, 2146, 2147, 2149, 2150, 2154, 2159, 2161, 2166, 2171, 2176, 2180, 2183, 2185, 2192, 2196, 2197], "messag": [2, 3, 6, 20, 21, 30, 36, 37, 44, 45, 54, 56, 65, 69, 71, 72, 625, 681, 1104, 1105, 1107, 1221, 1228, 1344, 1345, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876, 2091, 2093, 2094, 2096, 2097, 2102, 2135, 2147, 2154, 2159, 2166, 2168, 2178, 2197, 2204, 2205], "get": [2, 9, 14, 16, 21, 25, 30, 31, 32, 34, 37, 41, 51, 52, 54, 55, 56, 58, 60, 65, 68, 69, 87, 150, 335, 697, 745, 800, 802, 891, 892, 923, 929, 945, 958, 969, 986, 1041, 1069, 1070, 1071, 1073, 1090, 1131, 1202, 1205, 1206, 1207, 1219, 1220, 1223, 1225, 1228, 1260, 1261, 1330, 1382, 1501, 1502, 1503, 1522, 1523, 1547, 1548, 1549, 1576, 1577, 1578, 1590, 1608, 1770, 1772, 1788, 1814, 1821, 1865, 1878, 1913, 1928, 2036, 2060, 2061, 2062, 2071, 2091, 2093, 2096, 2104, 2108, 2109, 2114, 2115, 2117, 2125, 2127, 2130, 2133, 2134, 2135, 2136, 2138, 2140, 2142, 2143, 2155, 2157, 2158, 2161, 2166, 2168, 2171, 2175, 2176, 2177, 2184, 2186, 2189, 2191, 2192, 2193, 2194, 2198, 2204, 2205, 2206, 2209], "register_multi_grad_hook": [2, 2127], "fn": [2, 6, 41, 43, 44, 48, 54, 60, 69, 937, 954, 955, 1004, 1005, 1008, 1203, 1209, 1213, 1314, 1315, 1327, 1332, 1580, 1877, 2045, 2093, 2095, 2096, 2100, 2114, 2127, 2140, 2147, 2166, 2190, 2192, 2196, 2197, 2202, 2203, 2204, 2205], "multi": [2, 5, 34, 36, 37, 41, 51, 771, 1040, 1090, 1112, 1144, 1164, 1237, 1277, 1314, 1493, 1516, 1531, 1550, 1580, 1583, 1584, 1585, 1586, 1596, 1624, 1626, 1633, 1659, 1770, 1877, 2071, 2082, 2093, 2096, 2127, 2129, 2130, 2142, 2146, 2157, 2166, 2171, 2173, 2174, 2176, 2177, 2180, 2189], "specifi": [2, 3, 4, 6, 9, 14, 16, 21, 22, 25, 26, 30, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 49, 50, 51, 52, 56, 57, 58, 60, 69, 87, 97, 150, 195, 259, 319, 331, 471, 481, 493, 497, 499, 500, 513, 515, 517, 537, 545, 546, 560, 580, 583, 584, 585, 587, 588, 603, 681, 746, 752, 753, 754, 779, 780, 806, 807, 808, 814, 829, 842, 851, 869, 884, 888, 889, 891, 908, 910, 922, 923, 935, 936, 939, 942, 944, 969, 973, 996, 1002, 1026, 1027, 1037, 1039, 1040, 1051, 1052, 1053, 1056, 1057, 1074, 1078, 1089, 1095, 1116, 1125, 1126, 1127, 1131, 1132, 1134, 1144, 1147, 1158, 1161, 1163, 1164, 1166, 1167, 1169, 1170, 1171, 1173, 1174, 1175, 1176, 1177, 1179, 1181, 1203, 1204, 1207, 1213, 1222, 1224, 1232, 1234, 1255, 1268, 1276, 1277, 1311, 1314, 1318, 1330, 1331, 1357, 1367, 1369, 1371, 1372, 1381, 1384, 1386, 1387, 1397, 1414, 1416, 1422, 1470, 1471, 1474, 1490, 1491, 1492, 1493, 1499, 1511, 1513, 1515, 1516, 1522, 1523, 1526, 1533, 1539, 1540, 1545, 1546, 1550, 1571, 1572, 1577, 1580, 1583, 1584, 1585, 1586, 1587, 1594, 1612, 1613, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1634, 1635, 1654, 1655, 1658, 1659, 1669, 1670, 1677, 1678, 1683, 1686, 1695, 1698, 1705, 1718, 1722, 1723, 1730, 1738, 1744, 1745, 1770, 1777, 1779, 1780, 1787, 1788, 1789, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1824, 1827, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 1865, 1871, 1872, 1877, 1878, 1882, 1890, 1899, 1915, 1920, 1921, 1924, 1940, 1967, 1969, 1971, 1972, 1973, 1976, 1977, 1978, 1979, 1980, 1981, 1985, 1988, 1989, 1990, 1993, 2012, 2014, 2018, 2028, 2029, 2030, 2031, 2032, 2036, 2039, 2040, 2041, 2045, 2050, 2064, 2085, 2091, 2093, 2095, 2096, 2100, 2102, 2103, 2104, 2107, 2109, 2115, 2116, 2117, 2122, 2127, 2130, 2133, 2139, 2142, 2144, 2148, 2150, 2154, 2156, 2157, 2158, 2159, 2161, 2165, 2166, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2185, 2190, 2191, 2203, 2208], "ignor": [2, 6, 8, 30, 35, 37, 43, 49, 58, 60, 69, 150, 499, 544, 697, 700, 701, 702, 746, 807, 808, 888, 891, 892, 923, 944, 949, 950, 970, 992, 994, 995, 1014, 1027, 1031, 1035, 1090, 1091, 1112, 1113, 1165, 1167, 1175, 1176, 1177, 1228, 1258, 1275, 1314, 1326, 1332, 1335, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1361, 1362, 1363, 1364, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1383, 1384, 1386, 1406, 1471, 1472, 1473, 1489, 1490, 1491, 1492, 1493, 1513, 1515, 1523, 1531, 1533, 1539, 1545, 1546, 1550, 1571, 1572, 1573, 1574, 1575, 1580, 1583, 1584, 1585, 1586, 1587, 1594, 1596, 1612, 1613, 1624, 1629, 1658, 1659, 1669, 1678, 1698, 1722, 1730, 1770, 1827, 1835, 1865, 1874, 1877, 1880, 1940, 1971, 1972, 1990, 1994, 2020, 2071, 2072, 2082, 2083, 2093, 2096, 2097, 2103, 2116, 2127, 2130, 2133, 2171, 2178, 2193, 2200, 2203, 2204], "rel": [2, 9, 10, 16, 26, 30, 39, 60, 69, 487, 488, 705, 906, 949, 950, 954, 955, 1027, 1235, 1303, 1369, 1372, 1629, 1630, 1651, 1686, 1835, 1838, 1840, 1841, 1859, 1874, 1995, 2103, 2109, 2129, 2130, 2136, 2140, 2158, 2178], "removablehandl": [2, 954, 955, 1314, 1580, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 2158], "allow_mutation_on_saved_tensor": 2, "mutat": [2, 6, 14, 56, 57, 69, 71, 78, 79, 80, 811, 866, 868, 887, 888, 1002, 1019, 1202, 1318, 2100, 2158, 2177, 2194, 2195, 2204], "_allowmutationonsavedcontext": 2, "purpos": [2, 21, 26, 30, 32, 69, 471, 499, 771, 949, 1324, 1409, 1499, 1531, 1586, 1763, 1764, 1765, 1766, 1940, 1974, 2109, 2117, 2127, 2130, 2133, 2158, 2167, 2173, 2190, 2192, 2195, 2198, 2204, 2205], "clear": [2, 3, 9, 10, 34, 54, 69, 969, 1013, 1226, 1230, 1314, 1580, 1581, 1590, 1834, 1877, 2091, 2117, 2127, 2130, 2142, 2147, 2155, 2157, 2192], "upon": [2, 3, 25, 31, 41, 44, 69, 1002, 1644, 1770, 1790, 1793, 2029, 2114, 2117, 2127, 2130, 2154, 2161, 2168, 2208, 2209], "sin_": [2, 2094, 2115], "8415": [2, 2133, 2171], "sinbackward0": 2, "gradientedg": [2, 923, 944], "output_nr": [2, 2094, 2155], "edg": [2, 30, 57, 790, 796, 1268, 1276, 1277, 1697, 1757, 2101, 2117, 2134, 2167, 2200], "get_gradient_edg": 2, "equival": [2, 4, 6, 13, 14, 25, 26, 27, 35, 39, 44, 51, 52, 56, 64, 65, 69, 86, 155, 170, 172, 175, 178, 179, 180, 240, 255, 267, 297, 319, 325, 393, 448, 458, 486, 498, 500, 513, 525, 604, 610, 617, 618, 620, 703, 755, 759, 766, 768, 770, 796, 797, 798, 906, 919, 920, 935, 936, 983, 985, 988, 990, 993, 1000, 1001, 1019, 1132, 1136, 1139, 1142, 1143, 1144, 1146, 1161, 1163, 1166, 1169, 1170, 1173, 1174, 1176, 1179, 1181, 1200, 1202, 1205, 1207, 1213, 1228, 1241, 1251, 1278, 1280, 1291, 1313, 1314, 1325, 1330, 1331, 1334, 1346, 1367, 1371, 1379, 1384, 1416, 1421, 1441, 1443, 1471, 1484, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1522, 1523, 1534, 1540, 1542, 1543, 1544, 1545, 1550, 1552, 1580, 1596, 1612, 1620, 1632, 1634, 1641, 1642, 1643, 1695, 1705, 1727, 1738, 1757, 1758, 1759, 1770, 1776, 1778, 1832, 1860, 1877, 1899, 1902, 1905, 1906, 1930, 1936, 1943, 1965, 1972, 1986, 1996, 1997, 2006, 2011, 2030, 2045, 2046, 2047, 2090, 2093, 2095, 2096, 2104, 2122, 2127, 2154, 2156, 2158, 2162, 2171, 2172, 2174, 2177, 2178, 2190, 2193, 2206, 2210], "variou": [3, 6, 16, 25, 30, 32, 56, 69, 681, 1057, 1224, 1387, 2034, 2036, 2100, 2103, 2114, 2117, 2133, 2142, 2144, 2157, 2161, 2163, 2171, 2183, 2194, 2204, 2206, 2208], "get_cpu_cap": 3, "capabl": [3, 9, 16, 17, 30, 58, 1069, 1452, 1779, 1780, 1899, 2060, 2130, 2139, 2140, 2143, 2180], "string": [3, 4, 6, 15, 16, 25, 30, 41, 48, 49, 56, 57, 69, 603, 816, 829, 884, 1012, 1067, 1086, 1087, 1144, 1202, 1228, 1314, 1322, 1325, 1386, 1507, 1508, 1509, 1580, 1581, 1590, 1624, 1626, 1628, 1661, 1662, 1663, 1804, 1877, 1892, 1924, 1932, 1934, 2035, 2036, 2091, 2094, 2095, 2096, 2097, 2100, 2116, 2122, 2127, 2133, 2140, 2141, 2142, 2147, 2158, 2159, 2166, 2173, 2174, 2176, 2182, 2190, 2192, 2195, 2205, 2206, 2207], "vsx": 3, "z": [3, 4, 12, 39, 58, 60, 65, 71, 74, 79, 80, 617, 839, 907, 930, 933, 935, 936, 965, 993, 1016, 1057, 1144, 1148, 1416, 1532, 1686, 1793, 1825, 1826, 1886, 1916, 1917, 2093, 2094, 2095, 2100, 2116, 2127, 2129, 2130, 2138, 2139, 2158, 2164, 2166, 2168, 2189, 2191, 2192, 2195, 2203, 2205], "vector": [3, 13, 26, 39, 60, 61, 65, 254, 313, 315, 321, 700, 701, 702, 914, 923, 928, 938, 939, 940, 941, 942, 943, 944, 983, 984, 990, 1001, 1023, 1027, 1036, 1125, 1126, 1131, 1133, 1208, 1212, 1213, 1258, 1347, 1354, 1362, 1370, 1371, 1375, 1378, 1382, 1383, 1384, 1404, 1409, 1416, 1466, 1468, 1494, 1495, 1496, 1499, 1516, 1522, 1523, 1526, 1534, 1542, 1543, 1544, 1589, 1620, 1629, 1632, 1677, 1678, 1686, 1688, 1723, 1727, 1756, 1776, 1785, 1786, 1788, 1793, 1823, 1827, 1838, 1881, 1882, 1973, 1994, 2039, 2042, 2045, 2118, 2127, 2138, 2161, 2171, 2174, 2176, 2185, 2197], "NO": [3, 1227], "avx": [3, 2188], "avx2": [3, 2161, 2188], "avx512": [3, 2188], "sve256": 3, "is_built": [3, 2143], "built": [3, 4, 8, 9, 16, 26, 30, 37, 38, 44, 63, 69, 1003, 1067, 1324, 1630, 1865, 2100, 2127, 2129, 2130, 2133, 2139, 2142, 2143, 2144, 2147, 2161, 2163, 2173, 2186, 2190, 2192, 2193, 2204, 2205, 2206], "necessarili": [3, 26, 30, 39, 41, 51, 56, 58, 471, 949, 1351, 1373, 1384, 1415, 1515, 1587, 1779, 1780, 2130, 2133], "machin": [3, 30, 41, 51, 60, 61, 66, 1318, 1324, 1360, 1617, 2139, 2140, 2142, 2143, 2144, 2146, 2149, 2158, 2165, 2166, 2167, 2183, 2185, 2188, 2192, 2197], "driver": [3, 22, 1258, 1360, 1378, 1379, 1425, 2094, 2130, 2137, 2145, 2166, 2186, 2189, 2202, 2205], "would": [3, 4, 6, 9, 10, 13, 16, 25, 30, 34, 36, 37, 38, 39, 44, 51, 52, 56, 57, 58, 60, 62, 65, 69, 445, 446, 447, 448, 449, 486, 709, 771, 807, 884, 923, 930, 931, 935, 944, 992, 1010, 1145, 1147, 1165, 1196, 1206, 1207, 1227, 1228, 1240, 1241, 1242, 1312, 1314, 1315, 1319, 1322, 1330, 1331, 1433, 1434, 1466, 1489, 1490, 1491, 1492, 1493, 1531, 1545, 1550, 1573, 1574, 1575, 1580, 1590, 1596, 1686, 1697, 1760, 1770, 1772, 1779, 1780, 1813, 1825, 1860, 1877, 1901, 1905, 1907, 1918, 1928, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2012, 2017, 2093, 2095, 2096, 2104, 2111, 2115, 2116, 2117, 2118, 2126, 2127, 2128, 2129, 2130, 2132, 2133, 2134, 2136, 2137, 2138, 2144, 2147, 2151, 2154, 2157, 2158, 2161, 2166, 2167, 2168, 2170, 2171, 2180, 2186, 2189, 2190, 2191, 2192, 2194, 2195, 2196, 2197, 2198, 2200, 2203, 2205, 2209], "allow_tf32": [3, 1936, 2094, 2130, 2145], "tensorfloat": 3, "core": [3, 4, 8, 9, 34, 56, 64, 1002, 1032, 1101, 1833, 2078, 2096, 2100, 2129, 2130, 2132, 2144, 2145, 2158, 2180, 2190, 2191, 2195, 2201], "amper": [3, 2171], "newer": [3, 16, 56, 1108, 1821, 2129, 2130, 2139, 2147, 2149, 2157, 2158, 2162, 2197], "tf32": [3, 22], "allow_fp16_reduced_precision_reduct": [3, 2130, 2145], "reduc": [3, 4, 16, 26, 30, 31, 32, 34, 35, 38, 60, 321, 513, 516, 517, 697, 704, 706, 707, 708, 710, 837, 839, 840, 841, 846, 852, 895, 904, 905, 1002, 1007, 1052, 1055, 1066, 1101, 1222, 1224, 1288, 1367, 1371, 1373, 1378, 1384, 1402, 1412, 1414, 1415, 1417, 1420, 1471, 1472, 1473, 1474, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1513, 1515, 1523, 1539, 1545, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1620, 1629, 1658, 1659, 1667, 1669, 1678, 1694, 1697, 1698, 1699, 1710, 1718, 1719, 1720, 1721, 1722, 1723, 1730, 1742, 1743, 1754, 1757, 1770, 1788, 1825, 1843, 1874, 1890, 1892, 1893, 1927, 1970, 1975, 1988, 1989, 1993, 1994, 2018, 2033, 2040, 2041, 2058, 2094, 2114, 2115, 2122, 2127, 2129, 2132, 2133, 2136, 2142, 2144, 2146, 2147, 2148, 2150, 2151, 2155, 2157, 2158, 2161, 2171, 2186, 2189, 2191, 2195, 2199, 2200, 2204, 2205, 2206], "precis": [3, 4, 9, 13, 16, 26, 34, 36, 39, 58, 60, 697, 700, 895, 949, 950, 970, 982, 1089, 1187, 1264, 1360, 1378, 1384, 1409, 1419, 1489, 1490, 1491, 1493, 1507, 1508, 1509, 1510, 1511, 1512, 1532, 1551, 1567, 1573, 1574, 1575, 1633, 1697, 1738, 1770, 1921, 1936, 1940, 2096, 2109, 2111, 2118, 2125, 2127, 2137, 2142, 2156, 2158, 2161, 2162, 2164, 2172, 2174, 2176, 2177, 2201, 2204, 2210], "gemm": [3, 19, 21, 2129, 2154, 2195], "allow_bf16_reduced_precision_reduct": [3, 2130, 2145], "cufft_plan_cach": [3, 2130], "cufft": 3, "queri": [3, 21, 30, 51, 69, 86, 88, 746, 1039, 1040, 1050, 1103, 1108, 1121, 1122, 1238, 1314, 1427, 1443, 1580, 1586, 1641, 1738, 1792, 1877, 2050, 2094, 2108, 2122, 2130, 2158, 2191, 2194], "specif": [3, 4, 8, 9, 10, 13, 21, 22, 30, 32, 34, 35, 36, 38, 39, 41, 49, 54, 56, 58, 60, 65, 69, 71, 87, 513, 884, 891, 909, 962, 1014, 1135, 1164, 1277, 1311, 1318, 1324, 1328, 1330, 1331, 1350, 1352, 1415, 1526, 1552, 1595, 1738, 1763, 1764, 1769, 1795, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1853, 1856, 1857, 1858, 1859, 1860, 1875, 1931, 1936, 1970, 1993, 2034, 2091, 2093, 2095, 2096, 2098, 2100, 2102, 2109, 2111, 2116, 2118, 2122, 2127, 2130, 2133, 2139, 2144, 2146, 2157, 2158, 2159, 2161, 2162, 2164, 2166, 2168, 2176, 2177, 2184, 2185, 2188, 2191, 2192, 2194, 2195, 2197, 2201, 2203, 2204, 2205, 2212], "via": [3, 8, 16, 17, 25, 30, 32, 34, 37, 38, 39, 42, 49, 56, 57, 60, 64, 67, 69, 86, 415, 486, 517, 617, 949, 950, 958, 989, 1010, 1037, 1080, 1101, 1148, 1205, 1226, 1230, 1231, 1233, 1235, 1386, 1387, 1443, 1494, 1495, 1496, 1516, 1534, 1542, 1543, 1544, 1552, 1620, 1787, 1821, 1824, 1872, 2093, 2095, 2096, 2100, 2108, 2109, 2114, 2117, 2122, 2124, 2127, 2130, 2133, 2134, 2135, 2139, 2141, 2142, 2144, 2145, 2147, 2150, 2154, 2158, 2161, 2166, 2167, 2171, 2173, 2174, 2175, 2190, 2191, 2192, 2194, 2196, 2200, 2206], "readonli": 3, "int": [3, 4, 14, 19, 20, 21, 25, 26, 30, 32, 34, 35, 36, 37, 38, 39, 41, 45, 48, 49, 51, 52, 55, 56, 57, 58, 60, 69, 71, 79, 80, 82, 85, 87, 88, 216, 218, 232, 233, 242, 254, 313, 315, 317, 321, 437, 444, 445, 447, 449, 457, 472, 476, 493, 497, 499, 513, 515, 517, 520, 537, 543, 545, 546, 558, 560, 566, 583, 584, 585, 587, 588, 607, 617, 681, 685, 686, 687, 688, 690, 691, 693, 704, 706, 707, 708, 710, 766, 767, 786, 788, 790, 791, 796, 797, 798, 810, 813, 837, 904, 905, 906, 908, 922, 930, 933, 935, 936, 953, 958, 965, 971, 973, 980, 987, 989, 996, 1001, 1002, 1004, 1026, 1027, 1031, 1032, 1035, 1036, 1040, 1041, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1059, 1060, 1061, 1062, 1063, 1064, 1069, 1070, 1071, 1073, 1074, 1077, 1081, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1097, 1098, 1099, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1114, 1115, 1116, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1131, 1132, 1133, 1134, 1135, 1136, 1142, 1145, 1147, 1157, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1183, 1196, 1198, 1199, 1203, 1204, 1205, 1206, 1207, 1213, 1220, 1223, 1226, 1228, 1245, 1249, 1255, 1262, 1265, 1266, 1268, 1272, 1273, 1275, 1276, 1277, 1278, 1286, 1287, 1288, 1289, 1290, 1311, 1312, 1314, 1315, 1317, 1320, 1321, 1326, 1334, 1336, 1346, 1347, 1367, 1368, 1371, 1380, 1381, 1382, 1383, 1384, 1385, 1387, 1394, 1401, 1402, 1407, 1412, 1414, 1415, 1417, 1420, 1422, 1423, 1424, 1425, 1428, 1429, 1436, 1439, 1446, 1447, 1448, 1449, 1450, 1452, 1453, 1457, 1458, 1460, 1461, 1466, 1471, 1472, 1473, 1474, 1475, 1476, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1489, 1490, 1491, 1494, 1495, 1496, 1497, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1514, 1515, 1516, 1522, 1523, 1525, 1526, 1527, 1528, 1530, 1532, 1534, 1542, 1543, 1544, 1547, 1548, 1549, 1551, 1552, 1556, 1557, 1558, 1559, 1560, 1561, 1565, 1567, 1568, 1570, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1582, 1585, 1587, 1588, 1591, 1592, 1593, 1595, 1598, 1602, 1603, 1604, 1605, 1606, 1607, 1614, 1616, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1668, 1669, 1670, 1677, 1678, 1685, 1688, 1697, 1705, 1722, 1723, 1724, 1728, 1729, 1744, 1745, 1753, 1757, 1758, 1759, 1769, 1770, 1788, 1789, 1798, 1799, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1813, 1814, 1816, 1821, 1824, 1827, 1828, 1830, 1831, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1882, 1883, 1890, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1901, 1903, 1904, 1905, 1907, 1913, 1914, 1915, 1918, 1919, 1920, 1921, 1924, 1929, 1930, 1931, 1935, 1938, 1939, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1961, 1965, 1969, 1972, 1973, 1975, 1982, 1985, 1987, 1988, 1989, 1990, 1993, 1995, 2000, 2002, 2008, 2012, 2013, 2015, 2017, 2018, 2021, 2022, 2023, 2024, 2027, 2028, 2029, 2030, 2031, 2032, 2035, 2036, 2039, 2040, 2041, 2045, 2046, 2053, 2054, 2055, 2056, 2060, 2061, 2062, 2064, 2068, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2084, 2085, 2088, 2089, 2093, 2094, 2095, 2096, 2097, 2100, 2109, 2114, 2115, 2117, 2122, 2124, 2130, 2134, 2141, 2144, 2147, 2150, 2154, 2155, 2156, 2159, 2161, 2165, 2166, 2170, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2185, 2191, 2195, 2199, 2203, 2204, 2207, 2210], "show": [3, 5, 8, 15, 20, 25, 26, 30, 32, 36, 40, 56, 58, 60, 69, 938, 944, 1002, 1195, 1314, 1416, 1580, 1760, 1834, 1877, 2091, 2096, 2115, 2117, 2129, 2130, 2132, 2133, 2138, 2139, 2142, 2149, 2150, 2154, 2157, 2158, 2159, 2166, 2168, 2173, 2189, 2192, 2197, 2198, 2201, 2202, 2205, 2207], "max_siz": [3, 50, 52, 2130], "capac": [3, 1115, 2130, 2144], "preferred_blas_librari": 3, "overrid": [3, 6, 16, 21, 22, 26, 30, 31, 32, 34, 37, 39, 44, 52, 58, 60, 65, 69, 805, 806, 884, 920, 922, 935, 936, 1086, 1492, 1493, 1513, 1515, 1539, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1597, 1612, 1613, 1629, 1658, 1659, 1669, 1698, 1722, 1730, 1795, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1924, 1940, 2096, 2100, 2104, 2147, 2150, 2157, 2158, 2160, 2161, 2166, 2171, 2176, 2182, 2203, 2205], "bla": [3, 21, 2129], "choos": [3, 10, 17, 21, 69, 922, 935, 936, 962, 1014, 1067, 1360, 1373, 1378, 1492, 1995, 2124, 2126, 2129, 2150, 2158, 2162, 2176, 2185], "cubla": [3, 13, 19, 21, 22, 1058, 2033, 2146, 2189], "cublaslt": [3, 19, 22], "ck": 3, "rocm": [3, 19, 697, 700, 970, 982, 1409, 1419, 1507, 1508, 1509, 1510, 1511, 1512, 1532, 1551, 1567, 2125], "subject": [3, 4, 13, 20, 30, 32, 35, 37, 38, 60, 68, 69, 70, 233, 895, 1639, 1640, 1641, 1644, 1738, 1770, 2096, 2115, 2116, 2121, 2127, 2133, 2147, 2159, 2161, 2162, 2166, 2171, 2174, 2180, 2181, 2182, 2185, 2191, 2201], "hipbla": [3, 19, 21], "hipblaslt": [3, 19, 21], "offer": [3, 30, 32, 34, 37, 60, 63, 1586, 1624, 1625, 1626, 1627, 1628, 1770, 2033, 2130, 2133, 2139, 2151, 2158, 2159, 2166, 2171, 2190, 2195, 2199, 2208], "wherev": [3, 10, 2115], "prefer": [3, 6, 10, 25, 30, 32, 41, 52, 60, 892, 908, 940, 1218, 1241, 1312, 1355, 1368, 1372, 1380, 1387, 1587, 1738, 1928, 1990, 2011, 2093, 2100, 2104, 2127, 2130, 2145, 2150, 2154, 2157, 2158, 2171, 2195, 2204], "environ": [3, 4, 8, 16, 17, 20, 21, 24, 26, 32, 36, 37, 39, 41, 44, 49, 55, 56, 58, 69, 681, 1057, 1226, 1228, 1251, 1324, 1330, 1550, 1596, 2033, 2091, 2093, 2102, 2127, 2129, 2130, 2132, 2139, 2145, 2146, 2148, 2160, 2166, 2184, 2185, 2186, 2188, 2190, 2195, 2204, 2205], "variabl": [3, 4, 6, 14, 16, 20, 21, 24, 26, 34, 36, 37, 39, 41, 44, 49, 51, 55, 57, 58, 60, 65, 69, 71, 74, 79, 80, 448, 681, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 739, 740, 741, 742, 743, 745, 749, 750, 751, 752, 753, 754, 756, 757, 767, 771, 775, 814, 930, 931, 935, 1004, 1019, 1023, 1027, 1114, 1145, 1213, 1228, 1328, 1330, 1387, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1522, 1523, 1531, 1532, 1550, 1551, 1552, 1565, 1567, 1580, 1583, 1588, 1596, 1598, 1770, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1831, 1835, 1837, 1861, 1862, 1863, 1864, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1878, 1901, 1903, 1905, 2033, 2045, 2089, 2091, 2102, 2103, 2116, 2117, 2127, 2129, 2130, 2132, 2135, 2138, 2139, 2145, 2146, 2148, 2150, 2154, 2157, 2160, 2161, 2166, 2173, 2176, 2184, 2185, 2186, 2191, 2192, 2193, 2195, 2197, 2204, 2205], "torch_blas_prefer_cublaslt": 3, "global": [3, 4, 6, 9, 13, 14, 22, 25, 30, 32, 35, 37, 39, 41, 52, 60, 65, 68, 69, 71, 74, 79, 80, 884, 891, 895, 903, 958, 971, 980, 1019, 1037, 1064, 1078, 1095, 1103, 1145, 1147, 1157, 1162, 1180, 1196, 1199, 1202, 1272, 1273, 1295, 1302, 1314, 1317, 1330, 1334, 1385, 1401, 1580, 1738, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1800, 1804, 1831, 1877, 1901, 1903, 1905, 1908, 1932, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2075, 2089, 2093, 2096, 2097, 2100, 2108, 2118, 2126, 2133, 2140, 2142, 2144, 2146, 2161, 2166, 2167, 2168, 2171, 2174, 2176, 2192, 2193, 2194, 2195, 2196, 2203, 2205], "overridden": [3, 6, 16, 69, 919, 920, 921, 935, 936, 1086, 1580, 1968, 2096, 2127, 2133, 2145, 2205, 2206], "achiev": [3, 21, 25, 26, 30, 32, 38, 39, 52, 60, 1144, 1209, 1314, 1493, 1499, 1580, 1586, 1587, 1659, 1688, 1770, 1877, 2110, 2130, 2140, 2144, 2158, 2166, 2168, 2173, 2205], "better": [3, 4, 8, 9, 10, 16, 25, 29, 30, 41, 56, 64, 945, 1002, 1114, 1201, 1205, 1206, 1222, 1301, 1330, 1515, 1614, 1738, 1744, 1770, 1779, 1780, 1872, 1877, 1899, 2096, 2117, 2126, 2127, 2129, 2130, 2136, 2138, 2146, 2148, 2150, 2154, 2157, 2159, 2161, 2162, 2171, 2176, 2182, 2185, 2190, 2192, 2193, 2201, 2204], "select": [3, 6, 17, 19, 21, 23, 25, 30, 32, 39, 41, 49, 57, 313, 315, 317, 321, 685, 686, 687, 771, 992, 1028, 1029, 1031, 1044, 1045, 1046, 1050, 1059, 1060, 1061, 1062, 1064, 1065, 1073, 1088, 1092, 1094, 1095, 1097, 1099, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1114, 1115, 1118, 1121, 1122, 1164, 1387, 1416, 1444, 1445, 1446, 1447, 1448, 1449, 1460, 1462, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1531, 1550, 1596, 1644, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1738, 1808, 1809, 1931, 2008, 2036, 2048, 2051, 2052, 2053, 2054, 2055, 2057, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2084, 2087, 2093, 2094, 2096, 2114, 2115, 2116, 2117, 2127, 2129, 2130, 2138, 2146, 2149, 2155, 2161, 2171, 2175, 2178, 2193, 2199, 2201, 2204, 2207], "incorrect": [3, 5, 6, 60, 69, 254, 513, 556, 930, 933, 935, 949, 958, 984, 1004, 1014, 1330, 1373, 1386, 1586, 1624, 1625, 1626, 1627, 1628, 1756, 1827, 1979, 1990, 2093, 2096, 2100, 2130, 2145, 2154, 2192, 2208], "_blasbackend": 3, "preferred_linalg_librari": [3, 1351], "heurist": [3, 16, 25, 34, 51, 52, 69, 1007, 1144, 2136, 2189, 2198], "cusolv": [3, 1378, 1379, 1994], "magma": [3, 1360, 1404, 1892, 1994, 2148, 2171], "algebra": [3, 10, 1144, 1351, 1372, 2101], "decid": [3, 5, 8, 30, 41, 51, 58, 64, 486, 1224, 1804, 2103, 2154, 2171, 2194, 2195, 2198], "pick": [3, 30, 50, 52, 56, 513, 1002, 2127, 2166, 2191, 2193, 2198], "torch_linalg_prefer_cusolv": 3, "linalg": [3, 13, 406, 992, 993, 994, 995, 1036, 1130, 1258, 1292, 1395, 1404, 1405, 1406, 1410, 1411, 1787, 1788, 1793, 1827, 1879, 1884, 1886, 1892, 1962, 1974, 1994, 1995, 2020, 2042, 2160], "inv": [3, 39, 1292, 1346, 1350, 1356, 1372, 1376, 1380], "inv_ex": [3, 1355], "cholesky_ex": [3, 1344], "lu_factor": [3, 1363, 1364, 1404, 1405, 1406], "lu": [3, 12, 1356, 1362, 1363, 1364, 1405, 1406, 2094], "eigh": [3, 1344, 1350, 1353, 1372, 1378, 2145], "eighval": 3, "svdval": [3, 1346, 1360, 1369, 1378, 1994, 2145], "_linalgbackend": 3, "sdpaparam": 3, "flash_sdp_en": 3, "flash": [3, 1639, 1644], "scale": [3, 8, 25, 36, 39, 41, 50, 52, 97, 173, 473, 475, 617, 696, 700, 701, 702, 749, 750, 751, 752, 753, 754, 755, 760, 761, 762, 763, 764, 765, 766, 767, 770, 781, 783, 784, 785, 786, 788, 791, 792, 808, 814, 817, 837, 839, 840, 841, 846, 970, 1158, 1159, 1162, 1180, 1212, 1213, 1401, 1488, 1517, 1522, 1523, 1524, 1540, 1552, 1608, 1633, 1634, 1635, 1639, 1644, 1677, 1678, 1679, 1695, 1697, 1738, 1739, 1744, 1778, 1837, 1838, 1865, 1894, 1895, 1896, 1897, 1898, 1971, 1972, 1991, 2045, 2094, 2116, 2117, 2122, 2124, 2125, 2130, 2135, 2137, 2142, 2161, 2162, 2164, 2172, 2195, 2199], "product": [3, 17, 30, 32, 37, 39, 51, 150, 697, 700, 701, 702, 771, 923, 928, 939, 941, 942, 943, 944, 970, 982, 988, 992, 1023, 1036, 1050, 1103, 1108, 1121, 1122, 1125, 1141, 1144, 1208, 1212, 1213, 1291, 1335, 1347, 1354, 1380, 1381, 1383, 1409, 1416, 1419, 1468, 1531, 1532, 1550, 1551, 1639, 1644, 1685, 1738, 1787, 1880, 1881, 1890, 1936, 2013, 2028, 2042, 2045, 2093, 2115, 2117, 2122, 2127, 2138, 2140, 2158, 2161, 2171, 2192, 2204, 2207], "attent": [3, 8, 37, 38, 746, 1493, 1586, 1624, 1626, 1628, 1639, 1641, 1659, 1738, 2148, 2160, 2175, 2192], "enable_mem_efficient_sdp": [3, 1738], "mem_efficient_sdp_en": 3, "enable_flash_sdp": [3, 1738], "math_sdp_en": 3, "math": [3, 25, 69, 1154, 1366, 1639, 1644, 1698, 1738, 1882, 1899, 1995, 2093, 2095, 2096, 2111, 2136, 2145, 2171, 2172, 2178, 2186, 2205], "enable_math_sdp": [3, 1738], "fp16_bf16_reduction_math_sdp_allow": 3, "allow_fp16_bf16_reduction_math_sdp": [3, 2145], "cudnn_sdp_en": 3, "enable_cudnn_sdp": 3, "is_flash_attention_avail": 3, "check": [3, 4, 5, 6, 13, 16, 21, 22, 25, 30, 31, 32, 37, 39, 51, 60, 71, 72, 77, 80, 86, 88, 221, 233, 340, 499, 684, 689, 705, 891, 930, 931, 933, 934, 935, 936, 949, 950, 956, 1004, 1015, 1039, 1040, 1048, 1082, 1101, 1224, 1228, 1236, 1237, 1247, 1248, 1249, 1301, 1311, 1314, 1330, 1331, 1344, 1345, 1350, 1351, 1353, 1356, 1358, 1363, 1369, 1372, 1376, 1378, 1379, 1404, 1443, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1580, 1760, 1770, 1790, 1793, 1805, 1815, 1834, 1835, 1877, 1968, 1976, 1977, 1978, 1979, 1980, 1981, 2034, 2050, 2078, 2091, 2095, 2096, 2097, 2100, 2106, 2115, 2116, 2126, 2130, 2133, 2134, 2135, 2136, 2140, 2142, 2143, 2146, 2147, 2154, 2157, 2158, 2159, 2161, 2166, 2171, 2173, 2176, 2178, 2180, 2185, 2188, 2189, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2203, 2204, 2205, 2206, 2209], "flashattent": [3, 1628, 1738], "depend": [3, 5, 6, 14, 16, 25, 30, 32, 34, 35, 36, 37, 39, 41, 51, 52, 54, 57, 60, 69, 86, 315, 796, 908, 954, 1050, 1103, 1108, 1121, 1122, 1165, 1167, 1175, 1176, 1177, 1203, 1207, 1212, 1228, 1238, 1240, 1241, 1242, 1245, 1326, 1330, 1350, 1351, 1378, 1404, 1409, 1443, 1492, 1493, 1513, 1515, 1523, 1526, 1539, 1545, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1632, 1633, 1651, 1658, 1659, 1669, 1678, 1686, 1698, 1722, 1730, 1738, 1757, 1760, 1770, 1793, 1794, 1800, 1865, 1880, 1882, 1899, 1915, 1976, 1977, 1978, 1980, 1981, 1994, 2020, 2048, 2091, 2093, 2095, 2096, 2100, 2103, 2104, 2114, 2122, 2127, 2129, 2130, 2133, 2134, 2136, 2138, 2142, 2144, 2149, 2152, 2154, 2159, 2161, 2166, 2171, 2177, 2178, 2183, 2185, 2189, 2190, 2191, 2192, 2194, 2195, 2197, 2200, 2202, 2203, 2207], "can_use_flash_attent": 3, "debug": [3, 5, 6, 9, 21, 22, 25, 36, 42, 48, 56, 61, 681, 813, 834, 852, 855, 859, 873, 949, 950, 1002, 1004, 1012, 1037, 1077, 1119, 1262, 1344, 1763, 1764, 1765, 1766, 1935, 1942, 2095, 2102, 2127, 2129, 2130, 2132, 2139, 2140, 2142, 2146, 2148, 2150, 2154, 2158, 2181, 2191, 2192, 2193, 2196, 2197, 2200, 2207, 2208, 2209], "util": [3, 8, 19, 32, 52, 56, 57, 58, 60, 61, 68, 69, 71, 499, 743, 746, 749, 750, 751, 756, 757, 767, 771, 775, 803, 812, 936, 1056, 1145, 1146, 1147, 1195, 1247, 1248, 1249, 1314, 1531, 1550, 1580, 1596, 1597, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1770, 1790, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1813, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1877, 1998, 2000, 2002, 2003, 2004, 2033, 2096, 2100, 2104, 2109, 2117, 2126, 2128, 2129, 2130, 2133, 2135, 2137, 2138, 2140, 2142, 2144, 2146, 2151, 2154, 2158, 2160, 2185, 2191, 2192, 2195, 2202, 2205, 2208], "_sdpaparam": 3, "kei": [3, 4, 25, 32, 36, 41, 49, 51, 52, 56, 57, 58, 60, 67, 69, 415, 603, 681, 746, 813, 884, 889, 957, 962, 969, 1111, 1201, 1211, 1229, 1314, 1330, 1331, 1386, 1580, 1581, 1586, 1590, 1624, 1625, 1626, 1627, 1628, 1641, 1738, 1806, 1822, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1877, 2034, 2036, 2080, 2081, 2094, 2095, 2096, 2100, 2108, 2122, 2130, 2133, 2140, 2142, 2147, 2150, 2154, 2155, 2157, 2159, 2161, 2164, 2166, 2167, 2173, 2176, 2178, 2181, 2183, 2196, 2201, 2202, 2203, 2208], "mask": [3, 49, 399, 400, 401, 402, 403, 544, 746, 949, 950, 1408, 1488, 1499, 1524, 1586, 1624, 1625, 1626, 1627, 1628, 1679, 1738, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1860, 2094, 2100, 2115, 2116, 2117, 2122, 2160, 2171, 2195, 2199], "dropout": [3, 6, 38, 69, 745, 746, 771, 1314, 1488, 1518, 1519, 1520, 1524, 1531, 1550, 1580, 1586, 1596, 1597, 1624, 1626, 1628, 1652, 1672, 1673, 1674, 1679, 1738, 1877, 2094, 2106, 2116, 2127, 2130, 2155, 2163], "causal": [3, 746, 1586, 1624, 1625, 1626, 1627, 1628, 1640, 1641, 1642, 1643, 1738, 2122], "warn": [3, 4, 16, 20, 21, 26, 27, 30, 35, 36, 37, 56, 681, 938, 944, 992, 1050, 1103, 1108, 1119, 1121, 1122, 1213, 1228, 1295, 1311, 1330, 1372, 1386, 1416, 1586, 1624, 1625, 1626, 1627, 1628, 1738, 1790, 1793, 1935, 1942, 1990, 2033, 2045, 2091, 2102, 2109, 2122, 2128, 2133, 2147, 2155, 2158, 2165, 2192, 2204, 2205], "why": [3, 4, 8, 25, 56, 65, 69, 1144, 1318, 1738, 1840, 1841, 1859, 2100, 2103, 2134, 2136, 2191, 2192, 2194, 2202, 2207], "could": [3, 5, 6, 8, 9, 19, 21, 25, 30, 36, 37, 38, 39, 41, 51, 58, 65, 68, 69, 583, 584, 585, 587, 588, 958, 1082, 1165, 1167, 1175, 1176, 1177, 1229, 1311, 1320, 1345, 1386, 1404, 1433, 1434, 1779, 1780, 1864, 1970, 1995, 2029, 2095, 2096, 2103, 2114, 2127, 2130, 2132, 2147, 2148, 2151, 2154, 2158, 2161, 2162, 2166, 2167, 2168, 2171, 2175, 2176, 2190, 2192, 2195, 2196, 2200, 2204, 2205, 2208, 2209], "can_use_efficient_attent": 3, "efficient_attent": [3, 1639, 1644], "can_use_cudnn_attent": 3, "cudnn_attent": [3, 1639], "sdp_kernel": 3, "enable_flash": 3, "enable_math": 3, "enable_mem_effici": 3, "enable_cudnn": 3, "temporarili": [3, 41, 1932, 2100, 2127, 2154, 2159, 2198], "previou": [3, 20, 30, 32, 34, 51, 56, 58, 60, 69, 513, 556, 771, 1002, 1004, 1042, 1078, 1189, 1268, 1325, 1385, 1401, 1531, 1550, 1596, 1644, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1834, 1874, 1899, 1990, 2106, 2127, 2130, 2133, 2142, 2148, 2150, 2151, 2157, 2161, 2168, 2195, 2204], "restor": [3, 6, 32, 35, 37, 69, 87, 1013, 1189, 1385, 1401, 1644, 1824, 1919, 1940, 2142, 2147, 2193], "is_avail": [3, 19, 30, 684, 693, 2036, 2130, 2137, 2139, 2143, 2147, 2159, 2180, 2185, 2212], "determinist": [3, 4, 6, 24, 30, 34, 39, 69, 87, 486, 499, 513, 903, 1145, 1146, 1147, 1262, 1295, 1317, 1330, 1331, 1412, 1415, 1417, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1550, 1596, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1738, 1929, 1935, 2033, 2094, 2127, 2136, 2146, 2157, 2160, 2165], "algorithm": [3, 4, 8, 13, 21, 23, 26, 31, 35, 39, 41, 60, 87, 681, 771, 790, 796, 992, 1311, 1355, 1362, 1368, 1372, 1378, 1387, 1404, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1529, 1531, 1550, 1596, 1632, 1633, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1686, 1697, 1738, 1757, 1770, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1860, 1882, 1921, 1936, 1994, 1995, 2033, 2127, 2130, 2145, 2160, 2166, 2171], "are_deterministic_algorithms_en": [3, 2189], "use_deterministic_algorithm": [3, 29, 499, 903, 1145, 1146, 1147, 1295, 1935, 2146], "benchmark": [3, 21, 681, 2094, 2130, 2139, 2159, 2160, 2189, 2195, 2201, 2204], "fastest": [3, 19, 21, 907, 1770, 1826, 1840, 1841, 1859, 2138, 2146, 2157], "benchmark_limit": 3, "maximum": [3, 29, 39, 51, 52, 56, 499, 706, 708, 782, 808, 839, 840, 841, 846, 851, 904, 1052, 1055, 1092, 1094, 1101, 1109, 1110, 1123, 1124, 1145, 1146, 1147, 1190, 1207, 1275, 1276, 1277, 1387, 1412, 1438, 1538, 1677, 1678, 1777, 1838, 1863, 1872, 1899, 1913, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2035, 2073, 2074, 2078, 2094, 2102, 2111, 2117, 2124, 2126, 2130, 2144, 2155, 2164, 2178, 2179, 2191, 2199, 2207, 2209], "try": [3, 4, 5, 8, 9, 30, 32, 43, 44, 48, 51, 56, 64, 65, 233, 1002, 1004, 1115, 1198, 1207, 1213, 1228, 1253, 1319, 1321, 1330, 1351, 1438, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1624, 1625, 1627, 1633, 1639, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1738, 1770, 1836, 1837, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 2045, 2091, 2093, 2096, 2097, 2100, 2127, 2130, 2133, 2135, 2138, 2144, 2154, 2157, 2158, 2161, 2162, 2166, 2171, 2190, 2191, 2194, 2195, 2197, 2204, 2205, 2207], "dispatch": [3, 16, 30, 56, 60, 69, 1214, 1215, 1229, 1319, 1433, 1434, 2034, 2036, 2096, 2100, 2130, 2133, 2141, 2154, 2195, 2196, 2206], "v8": [3, 22], "api": [3, 4, 6, 9, 10, 16, 19, 22, 26, 30, 31, 32, 34, 38, 41, 43, 44, 48, 49, 50, 51, 52, 60, 61, 64, 68, 70, 71, 76, 80, 81, 82, 233, 815, 843, 891, 925, 926, 927, 928, 929, 941, 946, 947, 991, 1004, 1007, 1014, 1037, 1057, 1078, 1079, 1080, 1086, 1087, 1089, 1118, 1148, 1188, 1202, 1205, 1206, 1208, 1213, 1226, 1238, 1325, 1326, 1328, 1438, 1462, 1770, 1822, 1824, 1825, 1833, 1921, 1932, 2026, 2036, 2045, 2067, 2087, 2091, 2092, 2102, 2103, 2104, 2110, 2111, 2114, 2115, 2117, 2121, 2127, 2132, 2137, 2141, 2147, 2149, 2162, 2166, 2167, 2171, 2174, 2176, 2180, 2183, 2186, 2193, 2197, 2204, 2206, 2209], "get_fastpath_en": 3, "fast": [3, 8, 9, 25, 30, 41, 69, 949, 1521, 1542, 1543, 1544, 1612, 1628, 1779, 1780, 1872, 1880, 1899, 1921, 1936, 2111, 2129, 2130, 2133, 2139, 2157, 2166, 2171, 2174, 2175, 2183, 2192, 2194, 2197, 2198, 2207], "path": [3, 4, 5, 9, 16, 22, 30, 32, 41, 49, 51, 54, 55, 56, 58, 60, 69, 745, 959, 960, 961, 1037, 1144, 1237, 1314, 1580, 1597, 1628, 1834, 1877, 2091, 2094, 2095, 2127, 2130, 2133, 2136, 2139, 2147, 2150, 2154, 2157, 2158, 2159, 2171, 2181, 2185, 2189, 2197, 2198], "transformerencod": 3, "multiheadattent": [3, 1624, 1626, 1628, 2161], "fastpath": [3, 1586, 2194], "condit": [3, 6, 14, 23, 25, 56, 57, 58, 65, 69, 71, 79, 80, 617, 620, 625, 705, 771, 939, 949, 950, 1014, 1019, 1311, 1330, 1344, 1346, 1351, 1354, 1360, 1361, 1362, 1373, 1378, 1531, 1550, 1596, 1628, 1815, 1820, 2020, 2048, 2093, 2094, 2095, 2097, 2105, 2127, 2133, 2145, 2176, 2191, 2192, 2193, 2194, 2199, 2204], "met": [3, 14, 617, 1019, 1354, 1361, 1362, 1373, 1387, 1628, 1979], "set_fastpath_en": 3, "verbos": [3, 16, 21, 30, 69, 681, 1228, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 2091, 2102, 2111, 2116, 2130, 2150, 2154, 2156, 2176, 2205], "On": [3, 16, 24, 25, 30, 31, 34, 39, 52, 58, 60, 65, 69, 697, 700, 970, 982, 1042, 1096, 1362, 1409, 1419, 1507, 1508, 1509, 1510, 1511, 1512, 1532, 1547, 1548, 1549, 1550, 1551, 1567, 1590, 1596, 1609, 1770, 1840, 1841, 1856, 1859, 2093, 2103, 2127, 2129, 2130, 2133, 2145, 2158, 2166, 2167, 2168, 2171, 2180, 2189, 2191, 2192, 2194, 2195, 2204], "demand": [3, 25, 1080, 2095, 2117, 2140, 2144, 2166], "onemkl": 3, "easier": [3, 8, 25, 37, 56, 69, 2093, 2095, 2122, 2127, 2128, 2133, 2134, 2136, 2171, 2195, 2204, 2205], "dump": [3, 69, 1037, 2132, 2148, 2150, 2154, 2195, 2205, 2209], "durat": [3, 21, 30, 48, 967, 1433, 1434, 2109, 2150, 2159, 2195], "kernel": [3, 4, 5, 13, 16, 20, 22, 30, 60, 68, 88, 486, 681, 693, 750, 751, 752, 753, 754, 783, 784, 785, 956, 1002, 1035, 1040, 1045, 1086, 1087, 1120, 1122, 1440, 1445, 1489, 1490, 1491, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1527, 1528, 1547, 1548, 1549, 1556, 1557, 1558, 1559, 1560, 1561, 1573, 1574, 1575, 1576, 1577, 1578, 1632, 1661, 1662, 1663, 1664, 1665, 1666, 1681, 1682, 1738, 1779, 1780, 1791, 2034, 2036, 2052, 2088, 2093, 2100, 2106, 2111, 2117, 2122, 2130, 2133, 2134, 2136, 2141, 2143, 2145, 2150, 2154, 2157, 2159, 2162, 2171, 2186, 2189, 2192, 2193, 2194, 2195, 2196, 2197, 2204, 2205, 2208], "mkl_verbos": 3, "methodologi": 3, "larg": [3, 4, 8, 9, 25, 30, 36, 38, 69, 681, 888, 1025, 1027, 1101, 1351, 1360, 1378, 1484, 1526, 1632, 1680, 1770, 1872, 1960, 1973, 1995, 2078, 2114, 2116, 2117, 2125, 2129, 2130, 2133, 2135, 2142, 2145, 2147, 2150, 2154, 2158, 2162, 2166, 2171, 2174, 2177, 2189, 2195, 2202, 2204, 2205, 2207], "moreov": [3, 32, 58, 513, 1770, 1859, 2208], "investig": [3, 8, 30, 65, 2202, 2204], "singl": [3, 4, 6, 14, 16, 21, 26, 30, 32, 35, 36, 37, 39, 41, 44, 49, 50, 51, 58, 60, 61, 63, 64, 65, 66, 68, 69, 71, 79, 80, 254, 681, 706, 707, 777, 778, 779, 780, 783, 784, 785, 829, 925, 938, 939, 940, 941, 942, 943, 944, 956, 971, 980, 984, 1002, 1004, 1019, 1023, 1027, 1055, 1086, 1089, 1201, 1203, 1204, 1207, 1209, 1213, 1272, 1273, 1277, 1299, 1313, 1314, 1330, 1331, 1334, 1392, 1416, 1433, 1434, 1482, 1483, 1486, 1487, 1490, 1491, 1493, 1507, 1508, 1509, 1511, 1512, 1515, 1516, 1527, 1528, 1534, 1547, 1548, 1549, 1552, 1574, 1575, 1580, 1588, 1592, 1593, 1595, 1609, 1620, 1645, 1646, 1647, 1648, 1649, 1650, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1681, 1682, 1683, 1711, 1712, 1713, 1756, 1762, 1764, 1767, 1768, 1769, 1770, 1776, 1777, 1778, 1781, 1783, 1785, 1786, 1822, 1823, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1854, 1856, 1857, 1858, 1859, 1860, 1865, 1877, 1889, 1915, 1936, 1982, 1988, 1989, 2029, 2030, 2033, 2040, 2041, 2045, 2093, 2095, 2096, 2103, 2106, 2114, 2116, 2117, 2118, 2122, 2127, 2129, 2130, 2133, 2134, 2136, 2138, 2142, 2144, 2145, 2146, 2147, 2154, 2157, 2158, 2159, 2161, 2167, 2168, 2171, 2173, 2174, 2177, 2178, 2182, 2185, 2188, 2189, 2191, 2193, 2194, 2195, 2197, 2203, 2204, 2205], "enough": [3, 9, 26, 37, 58, 69, 1228, 1235, 1326, 1630, 1976, 1977, 1978, 1979, 1980, 1981, 2033, 2095, 2114, 2117, 2130, 2133, 2138, 2157, 2158, 2174, 2192, 2195, 2204, 2206], "scope": [3, 8, 14, 54, 69, 834, 1019, 1105, 1198, 1620, 1804, 2093, 2095, 2096, 2130, 2135, 2154, 2158, 2168, 2194, 2203], "second": [3, 6, 16, 20, 30, 35, 36, 41, 44, 51, 54, 56, 66, 69, 697, 700, 702, 705, 771, 807, 904, 905, 906, 914, 922, 935, 936, 949, 950, 970, 974, 975, 977, 978, 979, 982, 1036, 1050, 1103, 1108, 1121, 1122, 1132, 1134, 1135, 1141, 1149, 1190, 1191, 1203, 1206, 1207, 1208, 1212, 1213, 1241, 1256, 1257, 1268, 1271, 1279, 1280, 1281, 1291, 1303, 1337, 1339, 1347, 1383, 1386, 1392, 1393, 1403, 1409, 1413, 1415, 1416, 1418, 1419, 1472, 1477, 1480, 1484, 1490, 1491, 1497, 1508, 1509, 1511, 1512, 1522, 1523, 1530, 1531, 1545, 1548, 1549, 1550, 1568, 1572, 1574, 1575, 1596, 1609, 1668, 1670, 1704, 1760, 1804, 1838, 1840, 1841, 1844, 1856, 1860, 1872, 1874, 1877, 1920, 1970, 1979, 2017, 2022, 2024, 2039, 2042, 2045, 2095, 2096, 2100, 2105, 2114, 2127, 2130, 2133, 2134, 2135, 2136, 2138, 2142, 2146, 2150, 2154, 2157, 2159, 2166, 2172, 2176, 2185, 2189, 2192, 2204], "verbose_on": 3, "level": [3, 4, 8, 9, 10, 14, 17, 20, 25, 27, 30, 32, 34, 36, 37, 41, 43, 44, 48, 56, 57, 58, 60, 64, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 499, 681, 758, 925, 926, 927, 928, 929, 941, 1202, 1222, 1238, 1241, 1258, 1493, 1516, 1770, 1874, 2038, 2093, 2096, 2097, 2102, 2109, 2111, 2114, 2124, 2127, 2129, 2133, 2136, 2138, 2158, 2159, 2161, 2162, 2166, 2171, 2173, 2176, 2181, 2182, 2183, 2184, 2186, 2191, 2192, 2193, 2195, 2196, 2199, 2202, 2203, 2204, 2205, 2206], "verbose_off": 3, "dnn": [3, 2129], "onednn": [3, 885, 886, 889, 1316, 1323, 2155, 2161], "former": [3, 58, 60, 1550, 1580, 2127], "dnnl_verbos": 3, "verbose_on_cr": 3, "set_flag": 3, "_enabl": 3, "opt": [3, 30, 35, 1144, 1326, 2093, 2138, 2180, 2204], "einsum": [3, 2094, 2155], "automat": [3, 16, 21, 26, 30, 32, 51, 52, 56, 69, 589, 919, 921, 935, 936, 956, 1002, 1080, 1089, 1144, 1277, 1324, 1330, 1416, 1627, 1738, 1771, 1772, 1911, 1940, 1993, 2034, 2091, 2095, 2096, 2105, 2106, 2107, 2115, 2116, 2125, 2127, 2128, 2130, 2133, 2137, 2142, 2144, 2150, 2154, 2158, 2161, 2162, 2166, 2174, 2176, 2177, 2184, 2191, 2194, 2195, 2197, 2202, 2204, 2205], "pip": [3, 1144, 2148, 2150, 2151, 2152, 2154, 2176, 2193, 2204], "itself": [3, 4, 6, 8, 9, 21, 30, 31, 34, 37, 56, 60, 66, 69, 488, 704, 710, 909, 1027, 1144, 1206, 1207, 1314, 1326, 1330, 1580, 1614, 1744, 1770, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1967, 2093, 2114, 2133, 2142, 2144, 2146, 2149, 2154, 2158, 2166, 2171, 2173, 2175, 2180, 2190, 2192, 2194, 2205], "accordingli": [3, 39, 69, 1324, 1550, 1793, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 2157, 2166, 2200], "properli": [3, 4, 8, 25, 26, 32, 35, 37, 41, 51, 68, 1004, 1165, 1166, 1167, 1175, 1176, 1177, 1416, 1581, 1582, 1590, 1591, 1770, 2034, 2091, 2103, 2117, 2133, 2138, 2142, 2144, 2147, 2166, 2167, 2174], "get_opt_einsum": 3, "els": [3, 6, 8, 14, 25, 30, 32, 36, 37, 39, 41, 43, 51, 56, 58, 69, 71, 603, 684, 771, 969, 973, 1019, 1326, 1332, 1545, 1620, 1724, 1738, 1770, 1838, 1840, 1841, 1844, 1856, 1857, 1858, 1859, 1877, 1878, 1916, 1917, 1949, 1955, 2036, 2093, 2095, 2097, 2098, 2100, 2103, 2114, 2117, 2130, 2133, 2134, 2136, 2142, 2143, 2152, 2157, 2158, 2173, 2185, 2189, 2190, 2191, 2192, 2203, 2204], "readthedoc": [3, 1144], "io": [3, 8, 16, 25, 32, 56, 1144, 1322, 1325, 1386, 1550, 1551, 1628, 1924, 2147, 2148, 2161, 2185], "en": [3, 16, 26, 88, 1144, 2139, 2176, 2210], "path_find": [3, 1144], "html": [3, 4, 5, 8, 13, 16, 17, 30, 52, 60, 681, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 1002, 1144, 1630, 2033, 2036, 2100, 2128, 2139, 2142, 2146, 2158, 2159, 2176, 2204], "calcul": [3, 21, 25, 30, 32, 41, 48, 771, 779, 780, 814, 817, 837, 839, 843, 946, 990, 1027, 1132, 1136, 1144, 1148, 1305, 1311, 1370, 1392, 1393, 1395, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1499, 1510, 1511, 1512, 1526, 1531, 1533, 1534, 1542, 1543, 1544, 1552, 1620, 1629, 1632, 1633, 1653, 1654, 1655, 1659, 1678, 1683, 1686, 1697, 1727, 1778, 1788, 1800, 1821, 1825, 1827, 1838, 1865, 1914, 1988, 1989, 2022, 2024, 2040, 2041, 2122, 2124, 2127, 2128, 2132, 2136, 2138, 2145, 2147, 2148, 2161, 2171, 2182], "contract": [3, 57, 1144, 2013, 2116, 2158, 2190], "fall": [3, 8, 16, 21, 22, 25, 56, 808, 949, 1002, 1241, 1277, 1328, 1386, 1540, 1612, 1695, 1742, 1776, 1777, 1778, 1785, 2091, 2161, 2195, 2202, 2204], "left": [3, 25, 69, 460, 499, 829, 839, 895, 971, 975, 978, 980, 981, 986, 991, 1144, 1164, 1171, 1185, 1188, 1189, 1193, 1268, 1272, 1273, 1277, 1311, 1312, 1319, 1334, 1355, 1364, 1368, 1372, 1375, 1376, 1377, 1378, 1380, 1392, 1393, 1466, 1484, 1489, 1490, 1491, 1492, 1493, 1507, 1508, 1509, 1526, 1533, 1546, 1547, 1548, 1549, 1568, 1569, 1570, 1571, 1573, 1574, 1575, 1583, 1584, 1585, 1589, 1590, 1629, 1632, 1633, 1634, 1635, 1641, 1643, 1686, 1706, 1725, 1738, 1777, 1838, 1863, 1864, 1880, 1908, 1921, 1928, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1974, 1990, 2013, 2018, 2039, 2093, 2094, 2096, 2127, 2133, 2136, 2142, 2164, 2172, 2192, 2202, 2207], "strategi": [3, 4, 8, 19, 25, 26, 30, 35, 37, 44, 60, 938, 940, 1144, 1205, 1328, 1484, 1770, 1779, 1780, 1872, 1878, 2095, 2134, 2138, 2162, 2192, 2195, 2204], "auto": [3, 30, 56, 61, 1144, 1492, 1493, 2096, 2154, 2174, 2176, 2194], "greedi": [3, 35, 36, 1144], "doc": [3, 4, 5, 10, 13, 17, 19, 30, 32, 37, 51, 52, 57, 681, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 869, 1002, 1213, 1333, 1625, 1626, 1627, 1628, 2033, 2045, 2097, 2100, 2114, 2128, 2132, 2133, 2142, 2146, 2158, 2161, 2166, 2171, 2176, 2192, 2195, 2196, 2200, 2204], "timer": [4, 33], "stmt": [4, 2129], "setup": [4, 16, 26, 32, 36, 51, 52, 60, 839, 840, 841, 846, 1014, 1213, 1770, 2045, 2129, 2130, 2143, 2157, 2159, 2166, 2167, 2190, 2204], "global_setup": 4, "perf_count": 4, "label": [4, 7, 8, 25, 30, 35, 37, 965, 1144, 1484, 1493, 1499, 1513, 1515, 1539, 1572, 1583, 1584, 1670, 1814, 1864, 2132, 2136, 2144, 2176], "sub_label": 4, "descript": [4, 8, 15, 16, 22, 25, 27, 44, 51, 69, 88, 745, 1286, 1287, 1288, 1360, 1387, 1651, 1892, 1936, 2095, 2096, 2105, 2111, 2130, 2133, 2138, 2140, 2142, 2179, 2183, 2196, 2202, 2204, 2209, 2210], "env": [4, 30, 39, 44, 49, 51, 52, 53, 55, 69, 1101, 1228, 1229, 2132, 2145, 2150, 2152, 2166, 2195, 2205], "num_thread": [4, 2144], "languag": [4, 16, 44, 56, 1326, 1484, 1624, 1685, 2100, 2111, 2135, 2149, 2192], "measur": [4, 39, 48, 86, 1039, 1092, 1094, 1346, 1427, 1443, 1492, 1493, 1513, 1539, 1546, 1571, 1572, 1629, 1630, 1658, 1718, 1874, 2050, 2073, 2074, 2108, 2130, 2140, 2142, 2157, 2171, 2205], "statement": [4, 14, 39, 57, 58, 65, 69, 71, 76, 79, 80, 1019, 1315, 1330, 2097, 2127, 2133, 2144, 2147, 2149, 2154, 2158, 2164, 2166, 2190, 2192, 2204], "full": [4, 8, 9, 16, 17, 25, 26, 30, 32, 34, 35, 36, 37, 39, 55, 56, 60, 61, 65, 69, 486, 513, 930, 934, 935, 936, 971, 980, 1002, 1172, 1173, 1174, 1178, 1179, 1181, 1200, 1212, 1213, 1272, 1273, 1318, 1352, 1353, 1360, 1361, 1362, 1373, 1378, 1379, 1387, 1404, 1493, 1499, 1533, 1594, 1624, 1661, 1662, 1663, 1670, 1683, 1730, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1940, 1994, 1995, 2045, 2091, 2093, 2094, 2095, 2096, 2098, 2111, 2116, 2117, 2122, 2126, 2132, 2133, 2136, 2138, 2142, 2145, 2146, 2155, 2158, 2161, 2164, 2167, 2175, 2178, 2193, 2195, 2198, 2199, 2204, 2205], "org": [4, 5, 8, 10, 12, 13, 14, 17, 26, 36, 39, 52, 56, 60, 681, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 1002, 1019, 1387, 1550, 1600, 1627, 1630, 1789, 1824, 1882, 1936, 1956, 2036, 2091, 2097, 2100, 2122, 2127, 2128, 2137, 2142, 2146, 2148, 2151, 2158, 2176, 2177, 2204, 2207, 2210], "timeit": [4, 2129], "sever": [4, 14, 17, 25, 30, 39, 60, 69, 749, 750, 751, 752, 753, 754, 777, 778, 783, 784, 785, 793, 794, 945, 946, 1089, 1148, 1314, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1507, 1508, 1509, 1510, 1511, 1512, 1527, 1528, 1547, 1548, 1549, 1568, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1634, 1635, 1645, 1646, 1647, 1648, 1649, 1650, 1653, 1661, 1662, 1663, 1664, 1665, 1666, 1681, 1682, 1704, 1707, 1708, 1709, 1711, 1712, 1713, 1770, 1790, 1791, 1793, 1794, 1825, 1833, 1877, 1897, 1898, 2028, 2033, 2093, 2126, 2127, 2129, 2130, 2140, 2142, 2144, 2154, 2157, 2161, 2166, 2192, 2193, 2195, 2208], "awar": [4, 8, 60, 486, 723, 724, 725, 726, 727, 728, 729, 730, 731, 741, 742, 743, 744, 866, 868, 885, 892, 893, 1628, 1770, 1998, 2000, 2002, 2003, 2004, 2116, 2124, 2127, 2130, 2158, 2164, 2167, 2171, 2201], "element": [4, 14, 25, 30, 37, 39, 57, 58, 65, 66, 69, 71, 77, 79, 80, 97, 119, 150, 154, 196, 216, 242, 254, 258, 286, 313, 315, 317, 319, 321, 352, 398, 400, 402, 435, 454, 471, 473, 474, 497, 499, 513, 515, 517, 520, 545, 546, 558, 560, 609, 610, 617, 682, 694, 695, 698, 699, 704, 705, 709, 710, 746, 769, 771, 781, 782, 783, 784, 785, 791, 795, 806, 904, 906, 907, 908, 911, 912, 913, 914, 915, 923, 938, 939, 941, 942, 943, 949, 950, 972, 981, 984, 991, 997, 1001, 1019, 1021, 1023, 1024, 1025, 1086, 1123, 1124, 1125, 1126, 1127, 1128, 1131, 1133, 1134, 1135, 1139, 1141, 1144, 1147, 1149, 1150, 1154, 1174, 1178, 1179, 1181, 1183, 1188, 1190, 1191, 1193, 1196, 1198, 1203, 1204, 1206, 1207, 1208, 1212, 1213, 1255, 1256, 1257, 1258, 1268, 1271, 1274, 1275, 1276, 1277, 1291, 1299, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1334, 1336, 1337, 1339, 1356, 1358, 1362, 1373, 1377, 1388, 1389, 1391, 1394, 1396, 1397, 1398, 1399, 1403, 1404, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1441, 1466, 1471, 1472, 1474, 1475, 1476, 1477, 1478, 1488, 1489, 1492, 1493, 1494, 1495, 1496, 1498, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1517, 1518, 1519, 1520, 1521, 1523, 1524, 1526, 1531, 1532, 1535, 1536, 1537, 1538, 1539, 1540, 1545, 1546, 1550, 1552, 1556, 1557, 1558, 1559, 1560, 1561, 1566, 1569, 1571, 1572, 1573, 1574, 1575, 1579, 1581, 1583, 1584, 1585, 1586, 1587, 1588, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1608, 1610, 1611, 1612, 1613, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1629, 1630, 1632, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1671, 1675, 1678, 1679, 1684, 1685, 1689, 1690, 1691, 1692, 1695, 1698, 1699, 1701, 1706, 1711, 1712, 1713, 1717, 1718, 1722, 1723, 1725, 1728, 1729, 1730, 1731, 1732, 1733, 1738, 1739, 1740, 1741, 1742, 1744, 1746, 1748, 1749, 1750, 1751, 1756, 1769, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1806, 1807, 1813, 1814, 1816, 1817, 1826, 1827, 1828, 1830, 1835, 1885, 1886, 1889, 1890, 1897, 1898, 1900, 1911, 1914, 1915, 1919, 1921, 1923, 1940, 1943, 1945, 1957, 1958, 1960, 1961, 1965, 1972, 1976, 1977, 1978, 1979, 1980, 1981, 1983, 1984, 1988, 1989, 1993, 2007, 2009, 2010, 2014, 2015, 2016, 2018, 2020, 2021, 2022, 2023, 2024, 2026, 2028, 2029, 2030, 2031, 2040, 2041, 2042, 2045, 2048, 2094, 2096, 2100, 2103, 2117, 2122, 2124, 2128, 2129, 2133, 2138, 2145, 2147, 2150, 2154, 2157, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2180, 2192, 2194, 2197, 2206], "lazili": [4, 19, 32, 1039, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1760, 2050, 2093, 2133, 2202, 2212], "threadpool": 4, "comparison": [4, 26, 30, 56, 69, 810, 1314, 1330, 1331, 1580, 1835, 1877, 2097, 2133, 2178, 2182, 2193], "appl": [4, 2110, 2111], "synchron": [4, 5, 19, 20, 22, 26, 32, 35, 41, 51, 60, 68, 86, 88, 486, 907, 1039, 1040, 1052, 1055, 1057, 1077, 1119, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1355, 1356, 1357, 1358, 1362, 1363, 1369, 1372, 1375, 1376, 1378, 1379, 1387, 1427, 1443, 1620, 1770, 1826, 1828, 1914, 2050, 2129, 2130, 2132, 2137, 2139, 2144, 2166, 2173, 2180, 2195, 2208], "focu": [4, 57, 1874], "replic": [4, 25, 32, 34, 37, 38, 60, 1268, 1325, 1507, 1508, 1509, 1516, 1526, 1556, 1557, 1558, 1605, 1606, 1607, 1632, 1725, 1753, 1838, 2204], "particularli": [4, 25, 26, 54, 1515, 1516, 1587, 2093, 2130, 2191, 2192, 2202, 2204], "variat": [4, 39, 1877, 2096, 2133, 2157, 2162, 2205], "confound": 4, "quantifi": [4, 1630], "nois": [4, 2094, 2146, 2205], "median": [4, 39, 173, 1472, 2033, 2094, 2115, 2155], "robust": [4, 1387, 2114, 2142], "deviat": [4, 39, 60, 377, 1488, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1620, 1828, 1838, 1950, 1955, 1988, 1989, 2124, 2195], "merg": [4, 7, 8, 10, 25, 30, 32, 36, 52, 1581, 1586, 1590], "repeat": [4, 39, 56, 65, 494, 895, 1027, 1144, 1238, 1378, 1404, 1576, 1577, 1578, 1658, 1659, 1882, 1914, 1973, 1994, 1995, 2014, 2094, 2096, 2130, 2155, 2159, 2163, 2171, 2199], "autorang": 4, "exact": [4, 16, 25, 41, 54, 57, 58, 88, 339, 752, 753, 754, 808, 904, 905, 906, 949, 950, 1002, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1415, 1511, 1550, 1628, 1697, 1770, 1875, 1966, 2117, 2124, 2130, 2132, 2144, 2171, 2180, 2186, 2194, 2195, 2201, 2204, 2205, 2206], "discuss": [4, 6, 9, 10, 12, 39, 56, 58, 69, 1540, 1586, 1624, 1625, 1626, 1627, 1628, 1697, 2103, 2127, 2133, 2136, 2142, 2146, 2147, 2166, 2168, 2171, 2192, 2193], "docstr": [4, 16, 69, 891, 892, 1314, 1580, 1877, 2091, 2130], "adapt": [4, 56, 777, 778, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1517, 1645, 1646, 1647, 1648, 1649, 1650, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1865, 2111, 2130, 2157, 2191], "field": [4, 8, 21, 30, 32, 35, 41, 44, 48, 49, 57, 60, 69, 488, 851, 923, 924, 967, 1312, 1314, 1484, 1492, 1493, 1513, 1515, 1539, 1545, 1546, 1571, 1572, 1580, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1651, 1658, 1659, 1669, 1686, 1698, 1722, 1730, 1813, 1860, 1877, 2109, 2127, 2132, 2144, 2154, 2166, 2167, 2176, 2192, 2203, 2205], "displai": [4, 20, 36, 37, 1088, 1102, 1228, 1697, 1757, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878, 2091, 2097, 2102, 2107, 2154, 2173, 2176, 2178, 2185, 2195, 2205, 2208], "instruct": [4, 5, 13, 16, 54, 58, 68, 681, 1936, 2093, 2096, 2130, 2145, 2161, 2178, 2188, 2192, 2194, 2204, 2205], "count": [4, 22, 25, 37, 39, 48, 56, 69, 924, 958, 967, 973, 1026, 1041, 1082, 1198, 1276, 1277, 1312, 1352, 1353, 1813, 1874, 2029, 2030, 2094, 2109, 2130, 2136, 2139, 2155, 2159, 2166, 2168, 2170, 2171, 2195, 2205], "wall": [4, 2198], "callgrind": 4, "analog": [4, 56, 69, 486, 705, 945, 1127, 1165, 1167, 1364, 1550, 1859, 1994, 2014, 2142, 2191], "constructor": [4, 16, 25, 26, 35, 37, 51, 60, 69, 71, 80, 843, 891, 892, 1484, 1585, 1590, 1591, 1609, 1634, 1635, 1770, 1820, 1968, 2093, 2096, 2097, 2117, 2130, 2132, 2142, 2166, 2171, 2173, 2174, 2177, 2210], "snippet": [4, 52, 2091, 2142, 2147, 2197], "loop": [4, 21, 26, 32, 36, 54, 56, 57, 58, 61, 65, 66, 69, 71, 76, 892, 893, 944, 1089, 1092, 1094, 1207, 1213, 1330, 1770, 1791, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2045, 2073, 2074, 2093, 2094, 2096, 2109, 2129, 2130, 2135, 2138, 2142, 2145, 2149, 2154, 2157, 2159, 2161, 2176, 2189, 2192, 2194, 2203, 2204], "callabl": [4, 6, 14, 25, 26, 30, 34, 35, 36, 37, 39, 41, 44, 49, 54, 56, 57, 60, 68, 69, 119, 398, 871, 1002, 1004, 1015, 1019, 1086, 1087, 1089, 1202, 1203, 1204, 1209, 1212, 1213, 1216, 1250, 1314, 1317, 1320, 1326, 1330, 1386, 1387, 1580, 1624, 1626, 1628, 1630, 1763, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1854, 1856, 1857, 1858, 1859, 1860, 1868, 1871, 1877, 2045, 2091, 2093, 2095, 2096, 2097, 2100, 2109, 2122, 2130, 2133, 2142, 2147, 2150, 2154, 2158, 2159, 2166, 2178, 2181, 2182, 2190, 2193, 2196, 2203, 2206], "present": [4, 10, 25, 30, 32, 34, 57, 58, 60, 924, 967, 969, 1263, 1312, 1314, 1404, 1484, 1550, 1580, 1590, 1813, 1833, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1877, 1990, 2091, 2107, 2114, 2115, 2116, 2117, 2122, 2126, 2127, 2130, 2133, 2138, 2142, 2147, 2154, 2157, 2158, 2167, 2170, 2171, 2173, 2174, 2192, 2196, 2200, 2204, 2207], "default_tim": 4, "dict": [4, 6, 14, 25, 26, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 49, 54, 56, 57, 58, 60, 62, 64, 67, 69, 415, 681, 805, 806, 807, 810, 813, 830, 831, 832, 864, 884, 951, 958, 969, 1002, 1019, 1086, 1087, 1101, 1111, 1201, 1211, 1213, 1221, 1226, 1228, 1237, 1252, 1312, 1313, 1314, 1315, 1321, 1326, 1330, 1331, 1386, 1387, 1457, 1458, 1516, 1526, 1580, 1581, 1590, 1632, 1760, 1770, 1804, 1822, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1849, 1850, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 2045, 2060, 2078, 2079, 2080, 2081, 2091, 2093, 2094, 2096, 2097, 2100, 2107, 2109, 2122, 2133, 2142, 2147, 2150, 2154, 2155, 2156, 2166, 2167, 2176, 2181, 2182, 2185, 2193, 2200, 2203, 2206], "summar": [4, 5, 52, 1940, 2096, 2136, 2157, 2171, 2192, 2193, 2205], "relu": [4, 26, 36, 56, 65, 66, 69, 711, 712, 716, 717, 718, 719, 720, 721, 722, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 738, 739, 740, 776, 805, 806, 829, 884, 890, 1086, 1203, 1213, 1320, 1326, 1580, 1596, 1598, 1609, 1617, 1624, 1626, 1628, 1734, 1736, 1760, 1834, 2045, 2093, 2094, 2106, 2116, 2124, 2127, 2142, 2147, 2149, 2154, 2155, 2161, 2163, 2164, 2185, 2186, 2190, 2197, 2199, 2202, 2203, 2205], "readabl": [4, 15, 25, 49, 56, 69, 1088, 1102, 2011, 2154, 2157, 2193, 2205, 2206], "supplement": 4, "disambigu": [4, 49, 69, 1392, 2205], "ident": [4, 16, 25, 30, 32, 39, 69, 800, 829, 949, 950, 1132, 1241, 1352, 1353, 1354, 1355, 1368, 1380, 1383, 1387, 1404, 1471, 1472, 1488, 1517, 1727, 1779, 1780, 1787, 1790, 2038, 2042, 2048, 2097, 2124, 2145, 2146, 2157, 2158, 2163, 2171, 2194, 2205], "easi": [4, 25, 30, 32, 36, 51, 56, 1224, 2093, 2127, 2135, 2140, 2142, 2144, 2158, 2161, 2166, 2167, 2171, 2190, 2193, 2195, 2197, 2204], "differenti": [4, 37, 39, 61, 66, 150, 352, 589, 817, 919, 921, 923, 928, 929, 930, 932, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 999, 1014, 1089, 1206, 1207, 1208, 1212, 1329, 1361, 1362, 1373, 1404, 1498, 1499, 1522, 1688, 1723, 1770, 1793, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2033, 2103, 2133, 2135, 2138, 2150, 2154, 2157, 2166, 2177, 2195, 2204], "distinguish": [4, 1227, 2117, 2161, 2171], "princip": [4, 1361, 1882], "signal": [4, 13, 32, 41, 51, 54, 749, 750, 751, 777, 778, 793, 794, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1311, 1377, 1481, 1482, 1483, 1485, 1486, 1487, 1489, 1490, 1491, 1507, 1508, 1509, 1527, 1528, 1547, 1548, 1549, 1568, 1573, 1574, 1575, 1634, 1635, 1645, 1646, 1647, 1648, 1649, 1650, 1653, 1661, 1664, 1681, 1682, 1704, 1707, 1708, 1709, 1711, 1712, 1713, 1990, 2114, 2144, 2159, 2160, 2166, 2209], "form": [4, 8, 10, 13, 25, 30, 36, 39, 50, 51, 52, 56, 57, 58, 60, 65, 69, 771, 790, 796, 993, 1132, 1172, 1174, 1221, 1224, 1314, 1354, 1357, 1362, 1373, 1378, 1482, 1483, 1486, 1487, 1499, 1527, 1528, 1531, 1550, 1580, 1596, 1632, 1633, 1670, 1681, 1682, 1685, 1697, 1725, 1738, 1757, 1793, 1859, 1861, 1867, 1874, 1875, 1877, 1880, 2013, 2091, 2093, 2097, 2117, 2127, 2133, 2142, 2147, 2154, 2158, 2161, 2171, 2176, 2192, 2193, 2197, 2203, 2204], "treat": [4, 39, 50, 56, 58, 63, 69, 71, 76, 77, 321, 471, 806, 949, 950, 1004, 1086, 1201, 1242, 1314, 1367, 1370, 1372, 1384, 1386, 1396, 1397, 1398, 1399, 1416, 1474, 1523, 1533, 1552, 1584, 1585, 1586, 1587, 1590, 1595, 1609, 1614, 1678, 1769, 1770, 1822, 1826, 1865, 1921, 1936, 1990, 2007, 2008, 2014, 2029, 2095, 2096, 2100, 2115, 2117, 2127, 2166, 2171, 2174, 2182, 2192, 2195, 2196, 2200, 2203, 2204], "distinct": [4, 13, 1201, 1350, 1351, 1395, 1493, 2096, 2130, 2133, 2147, 2157, 2166, 2167, 2191, 2204], "workload": [4, 9, 21, 25, 30, 60, 1089, 2130, 2136, 2137, 2140, 2145, 2159, 2166, 2184, 2188, 2202], "good": [4, 8, 9, 16, 69, 1002, 1205, 1235, 1588, 1874, 1956, 2091, 2100, 2114, 2130, 2133, 2136, 2140, 2142, 2144, 2154, 2158, 2161, 2191, 2192, 2193, 2194, 2201, 2204], "intrins": [4, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 805, 806, 2162, 2163], "contrast": [4, 39, 41, 56, 58, 771, 1224, 1531, 1838, 1859, 2124, 2127, 2134, 2136, 2171, 2199], "adaptive_autorang": 4, "threshold": [4, 26, 69, 1369, 1372, 1540, 1612, 1617, 1695, 1746, 1752, 1838, 1874, 1940, 2094, 2126, 2130, 2155, 2176], "min_run_tim": 4, "01": [4, 31, 35, 54, 488, 766, 791, 840, 841, 1145, 1187, 1566, 1701, 1702, 1760, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1865, 1872, 1894, 1947, 1949, 1950, 1955, 1956, 2094, 2124, 2140, 2157, 2199, 2204], "max_run_tim": 4, "callback": [4, 26, 30, 41, 54, 68, 69, 1770, 2109, 2133, 2140, 2159, 2166], "similar": [4, 8, 10, 13, 22, 25, 30, 34, 36, 37, 39, 48, 57, 60, 65, 68, 69, 493, 515, 723, 724, 725, 726, 727, 728, 731, 741, 742, 743, 744, 756, 757, 767, 775, 817, 907, 922, 935, 936, 983, 988, 1001, 1002, 1190, 1191, 1314, 1513, 1514, 1526, 1539, 1542, 1543, 1544, 1580, 1629, 1668, 1813, 1827, 1828, 1838, 1860, 1877, 1886, 1914, 1921, 1970, 1974, 2008, 2014, 2030, 2095, 2096, 2100, 2114, 2115, 2117, 2127, 2129, 2130, 2133, 2134, 2138, 2145, 2158, 2161, 2166, 2167, 2171, 2172, 2173, 2177, 2191, 2194, 2195, 2197, 2200, 2204, 2205, 2210], "blocked_autorang": 4, "variablil": 4, "until": [4, 6, 8, 25, 26, 30, 32, 35, 41, 51, 56, 60, 68, 69, 86, 88, 486, 1039, 1040, 1080, 1198, 1335, 1387, 1427, 1433, 1434, 1443, 1686, 1760, 1770, 1862, 1864, 1869, 2014, 2050, 2067, 2100, 2108, 2114, 2124, 2130, 2135, 2136, 2147, 2154, 2159, 2166, 2168, 2173, 2189, 2192, 2195], "iqr": 4, "smaller": [4, 21, 25, 34, 69, 499, 545, 1027, 1550, 1770, 1874, 1891, 1936, 1982, 2130, 2147, 2157, 2158, 2190, 2207, 2210], "reach": [4, 8, 9, 10, 25, 26, 30, 31, 41, 51, 56, 61, 1387, 1770, 1862, 1865, 1869, 1870, 2127, 2133, 2144, 2162, 2166, 2193], "At": [4, 6, 7, 8, 17, 19, 21, 25, 34, 36, 1178, 1494, 1495, 1496, 1507, 1508, 1509, 1510, 1511, 1512, 1547, 1548, 1549, 2034, 2038, 2106, 2129, 2138, 2161, 2166, 2172, 2192, 2193, 2195, 2205], "high": [4, 5, 8, 9, 10, 12, 17, 26, 30, 34, 39, 41, 48, 50, 52, 69, 119, 1499, 1627, 1903, 1904, 1936, 2038, 2094, 2104, 2109, 2111, 2114, 2133, 2138, 2139, 2142, 2143, 2144, 2157, 2161, 2162, 2166, 2171, 2176, 2177, 2178, 2182, 2186, 2188, 2189, 2192, 2199, 2204, 2205, 2208, 2209], "pseudo": [4, 87], "block_siz": [4, 2100, 2122], "enough_data": 4, "len": [4, 25, 32, 69, 71, 76, 218, 545, 704, 706, 707, 710, 1163, 1167, 1170, 1174, 1177, 1181, 1212, 1318, 1381, 1402, 1414, 1471, 1474, 1516, 1725, 1799, 1801, 1816, 1864, 1872, 1979, 1982, 1988, 1989, 1993, 2039, 2040, 2041, 2093, 2094, 2096, 2130, 2133, 2137, 2155, 2157, 2170, 2171, 2176, 2192, 2203, 2204], "small_iqr": 4, "break": [4, 8, 30, 39, 63, 69, 681, 923, 1002, 1004, 1228, 1314, 1360, 1580, 1877, 1921, 1940, 2092, 2097, 2102, 2104, 2117, 2132, 2157, 2171, 2180, 2185, 2189, 2191, 2193, 2196, 2198, 2200], "stop": [4, 6, 30, 39, 41, 51, 52, 54, 57, 895, 924, 967, 1082, 1228, 1312, 1387, 1499, 1813, 1874, 2093, 2096, 2159, 2166, 2170, 2192, 2196, 2204], "repetit": [4, 1914, 2014], "statist": [4, 26, 30, 39, 814, 815, 839, 840, 841, 843, 846, 1050, 1064, 1092, 1094, 1095, 1097, 1099, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1121, 1122, 1392, 1452, 1457, 1458, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1620, 1877, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2109, 2127, 2135, 2157, 2161, 2164, 2195], "minimum": [4, 16, 21, 26, 51, 52, 56, 707, 708, 782, 808, 839, 840, 841, 846, 851, 905, 973, 1124, 1191, 1275, 1276, 1277, 1417, 1499, 1538, 1630, 1863, 1864, 1872, 1956, 1976, 1977, 1978, 1979, 1980, 1981, 2094, 2117, 2124, 2127, 2138, 2155, 2164, 2174, 2199], "total_tim": 4, "choic": [4, 9, 10, 30, 34, 1330, 1378, 1581, 1590, 1899, 2129, 2154, 2164, 2171, 2191, 2192, 2205], "block": [4, 8, 9, 22, 25, 30, 32, 34, 35, 38, 51, 54, 60, 68, 69, 88, 486, 583, 584, 585, 965, 981, 1039, 1101, 1335, 1387, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1556, 1557, 1558, 1559, 1560, 1561, 1583, 1586, 1624, 1625, 1626, 1627, 1628, 1632, 1680, 1756, 1770, 1976, 1977, 1978, 2093, 2095, 2096, 2109, 2114, 2117, 2118, 2122, 2127, 2130, 2132, 2136, 2138, 2154, 2161, 2166, 2171, 2183, 2202, 2204, 2207, 2209], "qualiti": [4, 8, 26], "balanc": [4, 1002], "compet": [4, 2144], "amort": 4, "invoc": [4, 6, 69, 871, 1002, 1007, 1226, 1317, 1330, 2093, 2096, 2130, 2133, 2140, 2166, 2168, 2184, 2189, 2202, 2204], "less": [4, 7, 8, 16, 25, 26, 30, 37, 39, 54, 56, 60, 364, 681, 938, 940, 949, 950, 1027, 1097, 1115, 1144, 1188, 1192, 1201, 1339, 1351, 1387, 1403, 1404, 1484, 1540, 1594, 1603, 1612, 1618, 1816, 1912, 2022, 2024, 2076, 2091, 2094, 2096, 2117, 2130, 2133, 2136, 2144, 2145, 2155, 2161, 2192, 2195, 2202], "bias": [4, 26, 745, 771, 807, 1494, 1495, 1496, 1531, 1532, 1534, 1542, 1543, 1544, 1550, 1551, 1552, 1596, 1598, 1620, 1640, 1641, 2157], "trivial": [4, 34, 37, 41, 44, 58, 746, 992, 1221, 1228, 1787, 1979, 2154, 2168, 2192, 2194], "low": [4, 8, 20, 26, 34, 39, 60, 499, 941, 1238, 1258, 1499, 1882, 1899, 1903, 1904, 1921, 1995, 2094, 2109, 2111, 2114, 2130, 2144, 2145, 2159, 2173, 2178, 2192, 2198, 2199, 2206], "digit": [4, 986, 1940, 2091, 2107, 2140, 2145], "microsecond": [4, 2130], "bia": [4, 10, 30, 36, 56, 71, 723, 724, 725, 726, 727, 728, 729, 730, 731, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 749, 750, 751, 752, 753, 754, 760, 762, 763, 764, 765, 767, 771, 772, 775, 776, 783, 784, 785, 792, 805, 1211, 1314, 1324, 1484, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1531, 1532, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1580, 1586, 1596, 1597, 1598, 1624, 1626, 1628, 1641, 1656, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1687, 1696, 1700, 1703, 1738, 1760, 1770, 1782, 1784, 1787, 1788, 1789, 1797, 1803, 1806, 1821, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1896, 2094, 2100, 2104, 2106, 2108, 2117, 2123, 2133, 2142, 2147, 2150, 2157, 2161, 2163, 2171, 2176, 2199], "period": [4, 10, 35, 51, 971, 980, 1050, 1088, 1102, 1103, 1108, 1121, 1122, 1164, 1272, 1273, 1334, 1876, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2094, 2109, 2114, 2144, 2209], "overal": [4, 10, 25, 36, 41, 51, 949, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1627, 2127, 2129, 2130, 2144, 2161, 2162, 2198], "main": [4, 8, 25, 26, 30, 31, 32, 37, 39, 41, 42, 43, 44, 49, 51, 52, 54, 55, 56, 69, 260, 496, 1002, 1131, 1132, 1133, 1134, 1135, 1377, 1688, 1973, 2021, 2022, 2023, 2024, 2091, 2093, 2109, 2114, 2116, 2117, 2126, 2127, 2130, 2132, 2133, 2134, 2136, 2142, 2144, 2148, 2149, 2150, 2161, 2166, 2167, 2176, 2177, 2180, 2183, 2185, 2190, 2192, 2195, 2204], "collect_callgrind": 4, "collect_baselin": 4, "retain_out_fil": 4, "callgrindstat": 4, "tupl": [4, 6, 14, 16, 21, 25, 30, 32, 36, 37, 38, 41, 48, 49, 51, 56, 57, 58, 60, 69, 233, 319, 445, 447, 449, 493, 497, 520, 537, 560, 583, 584, 585, 704, 706, 707, 708, 710, 746, 777, 778, 779, 780, 783, 784, 785, 790, 796, 797, 798, 806, 810, 813, 832, 833, 884, 891, 892, 908, 909, 916, 917, 918, 919, 920, 922, 935, 936, 938, 939, 940, 941, 942, 943, 944, 949, 950, 953, 954, 955, 969, 985, 996, 1004, 1012, 1019, 1026, 1041, 1051, 1052, 1055, 1056, 1069, 1089, 1095, 1123, 1124, 1142, 1145, 1147, 1161, 1163, 1164, 1166, 1167, 1169, 1170, 1171, 1173, 1174, 1176, 1177, 1179, 1181, 1184, 1194, 1199, 1201, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1211, 1212, 1213, 1226, 1228, 1237, 1252, 1254, 1258, 1276, 1278, 1314, 1321, 1326, 1330, 1331, 1336, 1345, 1350, 1351, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1367, 1371, 1373, 1374, 1376, 1378, 1381, 1384, 1402, 1404, 1406, 1412, 1414, 1416, 1417, 1420, 1422, 1452, 1471, 1474, 1481, 1482, 1483, 1485, 1486, 1487, 1489, 1490, 1491, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1516, 1526, 1527, 1528, 1547, 1548, 1549, 1556, 1557, 1558, 1559, 1560, 1561, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1581, 1586, 1590, 1602, 1603, 1604, 1605, 1606, 1607, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1646, 1647, 1649, 1650, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1681, 1682, 1697, 1711, 1712, 1713, 1723, 1725, 1757, 1758, 1759, 1764, 1770, 1782, 1784, 1793, 1804, 1816, 1822, 1826, 1827, 1831, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1852, 1856, 1857, 1858, 1859, 1860, 1877, 1882, 1883, 1892, 1901, 1903, 1905, 1915, 1919, 1920, 1965, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1985, 1988, 1989, 1993, 1994, 1995, 2011, 2012, 2013, 2014, 2015, 2020, 2027, 2028, 2029, 2030, 2031, 2040, 2041, 2045, 2046, 2048, 2089, 2093, 2094, 2097, 2100, 2114, 2117, 2122, 2127, 2130, 2133, 2134, 2141, 2142, 2147, 2150, 2154, 2156, 2157, 2158, 2161, 2166, 2170, 2171, 2173, 2176, 2178, 2180, 2182, 2192, 2195, 2203, 2206], "modulo": [4, 39, 1192, 1241, 1912], "determin": [4, 6, 9, 13, 16, 19, 20, 24, 25, 26, 30, 39, 41, 49, 51, 60, 65, 69, 233, 842, 851, 938, 940, 949, 950, 971, 980, 987, 992, 1090, 1146, 1165, 1175, 1200, 1201, 1230, 1231, 1272, 1273, 1276, 1277, 1328, 1348, 1360, 1371, 1374, 1395, 1409, 1523, 1527, 1528, 1550, 1586, 1589, 1596, 1639, 1678, 1681, 1682, 1697, 1731, 1757, 1792, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1822, 1832, 1872, 1902, 1904, 1906, 1933, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 2071, 2090, 2096, 2097, 2116, 2117, 2130, 2132, 2133, 2136, 2142, 2150, 2154, 2158, 2161, 2166, 2168, 2171, 2173, 2174, 2176, 2178, 2191, 2194, 2195, 2203, 2204, 2205, 2212], "jitter": 4, "interpret": [4, 25, 30, 35, 39, 41, 51, 54, 56, 57, 58, 233, 790, 796, 910, 944, 1041, 1100, 1165, 1166, 1167, 1172, 1174, 1175, 1176, 1177, 1198, 1226, 1265, 1277, 1314, 1319, 1326, 1330, 1367, 1387, 1519, 1644, 1686, 1697, 1698, 1757, 1933, 1938, 2091, 2095, 2096, 2100, 2114, 2129, 2130, 2171, 2173, 2175, 2192, 2193, 2204], "ideal": [4, 50, 52, 1330, 1860, 2116, 2117, 2130, 2195, 2204], "analysi": [4, 26, 39, 56, 58, 69, 1334, 1882, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2097, 2104, 2142, 2149, 2150, 2182, 2190, 2192, 2193, 2194, 2198], "valgrind": 4, "degrad": [4, 16, 60, 2129, 2132, 2133, 2171], "due": [4, 5, 6, 8, 26, 30, 32, 34, 39, 50, 60, 65, 69, 71, 73, 486, 910, 938, 939, 944, 1023, 1218, 1327, 1350, 1351, 1378, 1404, 1519, 1533, 1624, 1633, 1697, 1738, 1820, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1995, 2093, 2130, 2138, 2139, 2145, 2146, 2147, 2154, 2161, 2162, 2166, 2168, 2189, 2195, 2200, 2204, 2205, 2207, 2209], "amelior": 4, "suffici": [4, 16, 26, 30, 39, 43, 51, 52, 57, 60, 486, 1014, 1840, 1841, 1859, 1995, 2091, 2100, 2171, 2174, 2195], "callgrind_control": 4, "callgrind_annot": 4, "boundari": [4, 34, 36, 69, 790, 796, 986, 1268, 1501, 1502, 1503, 1504, 1505, 1506, 1602, 1603, 1604, 1605, 1606, 1607, 1633, 1636, 1637, 1638, 1697, 1757, 1865, 1872, 2094, 2117, 2132, 2158, 2166, 2195], "caller": [4, 41, 51, 69, 884, 1314, 1580, 1628, 1877, 1979, 2100, 2127, 2130, 2166, 2168], "structur": [4, 6, 10, 14, 25, 26, 30, 34, 36, 40, 41, 44, 52, 56, 57, 58, 60, 69, 71, 72, 76, 80, 922, 935, 936, 968, 1002, 1019, 1195, 1208, 1213, 1226, 1233, 1234, 1330, 1580, 1640, 1800, 1804, 1835, 1882, 1995, 2045, 2095, 2097, 2100, 2103, 2109, 2122, 2130, 2132, 2133, 2134, 2136, 2144, 2147, 2148, 2154, 2157, 2158, 2166, 2173, 2176, 2177, 2178, 2180, 2182, 2185, 2191, 2192, 2193, 2195, 2196, 2200, 2207], "restrict": [4, 9, 14, 25, 39, 57, 60, 65, 66, 1004, 1019, 1386, 1409, 1515, 2095, 2096, 2097, 2116, 2117, 2127, 2130, 2138, 2147, 2161, 2191], "builtin": [4, 30, 69, 71, 80, 1327, 1386, 1908, 2002, 2093, 2095, 2097, 2166, 2168, 2192, 2195, 2204, 2205], "surpris": [4, 9, 60, 2091, 2138, 2145, 2194], "serial": [4, 17, 25, 30, 32, 35, 51, 1314, 1324, 1325, 1386, 1580, 1760, 1877, 1924, 2091, 2094, 2107, 2116, 2125, 2127, 2130, 2136, 2140, 2142, 2144, 2150, 2154, 2158, 2161, 2166, 2167, 2173], "subsequ": [4, 8, 16, 17, 19, 30, 56, 58, 60, 69, 1002, 1040, 1314, 1326, 1330, 1507, 1508, 1509, 1510, 1511, 1512, 1580, 1609, 1877, 2117, 2130, 2146, 2154, 2159, 2166, 2171, 2184, 2185, 2189, 2195], "deseri": [4, 32, 1228, 1386, 1760, 2091, 2107, 2147, 2166, 2173], "globalsbridg": 4, "care": [4, 8, 16, 30, 39, 60, 68, 69, 1165, 1167, 1227, 1228, 1580, 2114, 2129, 2130, 2132, 2133, 2135, 2142, 2144, 2147, 2154, 2166, 2171, 2189, 2194, 2195, 2196], "reli": [4, 10, 16, 25, 26, 36, 41, 44, 60, 69, 150, 923, 949, 1144, 1516, 1860, 2105, 2127, 2129, 2132, 2133, 2136, 2146, 2147, 2171, 2175, 2185, 2194, 2195, 2196, 2198], "pickl": [4, 25, 26, 30, 1314, 1386, 1580, 1877, 1924, 2091, 2107, 2114, 2147, 2151, 2158, 2166, 2207], "transfer": [4, 19, 25, 30, 60, 2106, 2114, 2130, 2139, 2142, 2157, 2158, 2166, 2174], "profil": [4, 5, 19, 21, 48, 69, 486, 957, 958, 965, 1002, 1057, 1328, 1763, 1764, 1765, 1766, 1940, 2111, 2136, 2150, 2154, 2155, 2160, 2166, 2183, 2184, 2195, 2204], "empti": [4, 14, 29, 30, 32, 37, 41, 49, 56, 57, 58, 60, 65, 69, 233, 321, 513, 515, 523, 537, 545, 832, 954, 969, 972, 973, 983, 989, 1019, 1144, 1146, 1312, 1314, 1315, 1340, 1360, 1361, 1366, 1373, 1396, 1397, 1398, 1399, 1406, 1414, 1451, 1493, 1515, 1523, 1580, 1587, 1659, 1678, 1725, 1820, 1832, 1833, 1877, 1979, 1994, 2011, 2090, 2093, 2094, 2095, 2096, 2098, 2106, 2108, 2115, 2116, 2124, 2128, 2130, 2133, 2146, 2147, 2155, 2158, 2171, 2172, 2177, 2180, 2191, 2192, 2194, 2199, 2202], "drive": [4, 10, 30, 2127], "facil": [4, 27, 1386, 2114], "analyz": [4, 5, 20, 56, 58, 69, 2132, 2133, 2136, 2145, 2147, 2205], "manipul": [4, 21, 60, 68, 1318, 2126, 2135, 2142, 2164, 2173, 2203], "1000000": [4, 1836], "mirror": [4, 139, 1770], "semant": [4, 10, 13, 19, 30, 37, 51, 52, 56, 57, 60, 67, 69, 88, 150, 807, 904, 905, 906, 923, 944, 984, 1101, 1202, 1213, 1226, 1241, 1242, 1318, 1325, 1384, 1493, 1659, 1731, 1779, 1780, 1860, 2030, 2045, 2095, 2096, 2100, 2103, 2117, 2125, 2134, 2142, 2154, 2166, 2171, 2184, 2195], "number_per_run": 4, "raw_tim": 4, "task_spec": 4, "serializ": [4, 26, 2093], "consum": [4, 25, 32, 36, 40, 54, 57, 68, 435, 1144, 2114, 2130, 2136, 2144, 2149, 2150, 2154, 2176], "extrapol": 4, "sinc": [4, 8, 16, 25, 26, 30, 32, 34, 38, 39, 44, 54, 56, 58, 60, 69, 315, 488, 534, 758, 796, 806, 823, 824, 834, 992, 1092, 1094, 1097, 1144, 1184, 1185, 1186, 1201, 1311, 1314, 1319, 1325, 1328, 1404, 1492, 1522, 1576, 1577, 1578, 1580, 1633, 1641, 1651, 1686, 1688, 1757, 1760, 1804, 1822, 1827, 1835, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1990, 2073, 2074, 2076, 2093, 2094, 2095, 2096, 2100, 2102, 2106, 2109, 2117, 2126, 2127, 2130, 2133, 2134, 2135, 2136, 2138, 2140, 2142, 2147, 2148, 2149, 2154, 2155, 2158, 2159, 2161, 2165, 2166, 2167, 2168, 2171, 2172, 2174, 2175, 2177, 2178, 2186, 2189, 2192, 2195, 2200, 2203, 2204, 2205], "properti": [4, 25, 30, 31, 32, 35, 36, 37, 39, 43, 48, 51, 56, 57, 60, 69, 805, 910, 936, 953, 963, 1041, 1071, 1160, 1161, 1163, 1165, 1166, 1167, 1175, 1176, 1177, 1314, 1488, 1580, 1614, 1639, 1744, 1760, 1771, 1772, 1773, 1774, 1813, 1877, 2062, 2096, 2100, 2109, 2122, 2127, 2130, 2133, 2138, 2150, 2157, 2159, 2166, 2171, 2173, 2174, 2177, 2180, 2185, 2191, 2192, 2193, 2194, 2206, 2210], "significant_figur": 4, "figur": [4, 8, 9, 32, 37, 69, 958, 2129, 2132, 2133, 2151, 2154, 2168, 2176, 2182, 2192, 2195, 2209], "intend": [4, 32, 51, 56, 58, 69, 920, 930, 933, 935, 1046, 1228, 1334, 1651, 1763, 1764, 1765, 1766, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 2096, 2124, 2127, 2130, 2142, 2150, 2154, 2158, 2204], "interquartil": 4, "mitig": [4, 71, 2136, 2145, 2173], "tail": [4, 25, 49], "645": 4, "conjunct": [4, 25, 30, 35, 60, 843, 1651, 1686, 1770, 2164, 2166], "trim_sigfig": 4, "human": [4, 15, 36, 49, 56, 1088, 1102, 2124, 2154, 2193, 2206], "raw": [4, 69, 1198, 1373, 2100, 2130, 2158, 2159], "built_with_debug_symbol": 4, "baseline_inclusive_stat": 4, "baseline_exclusive_stat": 4, "stmt_inclusive_stat": 4, "stmt_exclusive_stat": 4, "stmt_callgrind_out": 4, "done": [4, 17, 25, 30, 32, 34, 35, 36, 37, 39, 49, 57, 60, 68, 69, 486, 496, 681, 771, 949, 956, 1161, 1163, 1166, 1167, 1169, 1170, 1173, 1174, 1176, 1177, 1179, 1181, 1330, 1404, 1494, 1495, 1496, 1516, 1519, 1531, 1542, 1543, 1544, 1554, 1555, 1562, 1563, 1564, 1565, 1590, 1620, 1626, 1628, 1678, 1770, 1862, 1869, 1877, 1985, 2096, 2106, 2108, 2114, 2127, 2129, 2130, 2132, 2133, 2134, 2135, 2142, 2145, 2150, 2151, 2154, 2157, 2161, 2162, 2166, 2168, 2174, 2190, 2191, 2192, 2194, 2201, 2203], "functioncount": 4, "stat": [4, 63, 813, 851, 864, 865, 1101, 1109, 1110, 1111, 1620, 1770, 2080, 2081, 2109, 2130, 2181, 2195, 2205], "as_standard": 4, "strip": [4, 1688, 1770, 2093, 2155, 2171], "prefix": [4, 30, 32, 41, 60, 69, 759, 768, 1314, 1580, 1770, 1877, 2091, 2102, 2127, 2150, 2154, 2158, 2161, 2181, 2202], "stumbl": 4, "filepath": 4, "dif": 4, "compon": [4, 8, 10, 17, 20, 30, 37, 39, 69, 681, 924, 949, 1004, 1164, 1165, 1167, 1175, 1176, 1177, 1354, 1624, 1625, 1626, 1627, 1628, 1760, 1882, 1990, 2043, 2044, 2097, 2102, 2117, 2122, 2127, 2132, 2133, 2140, 2142, 2171, 2173, 2184, 2190, 2196, 2204, 2205], "locat": [4, 10, 16, 30, 32, 36, 39, 48, 56, 58, 154, 254, 486, 513, 681, 909, 984, 986, 1053, 1123, 1124, 1336, 1386, 1412, 1417, 1420, 1466, 1516, 1526, 1615, 1632, 1651, 1686, 1753, 1756, 1770, 1793, 1893, 1928, 1949, 1971, 1975, 2033, 2091, 2093, 2107, 2122, 2130, 2147, 2158, 2159, 2166, 2168, 2171, 2176, 2181, 2185, 2189, 2194, 2204], "someth": [4, 8, 56, 57, 62, 69, 938, 940, 1144, 1228, 1238, 1314, 1330, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 2005, 2098, 2109, 2114, 2115, 2117, 2127, 2139, 2148, 2154, 2166, 2190, 2191, 2192, 2195, 2197, 2203, 2204, 2205, 2206], "resembl": [4, 17, 2185], "23234231": 4, "first_build_dir": 4, "foo": [4, 16, 30, 48, 49, 56, 68, 69, 71, 79, 80, 843, 884, 889, 1002, 1014, 1201, 1202, 1211, 1312, 1317, 1322, 1325, 1326, 1329, 1330, 1822, 2034, 2036, 2091, 2093, 2095, 2096, 2100, 2104, 2133, 2142, 2154, 2158, 2178, 2189, 2192, 2195, 2204, 2205], "9823794": 4, "bar": [4, 8, 48, 56, 69, 71, 79, 80, 884, 889, 1014, 1027, 1201, 1317, 1325, 1988, 1989, 2040, 2041, 2091, 2093, 2095, 2100, 2107, 2142, 2154, 2158, 2178], "53453": 4, "src": [4, 30, 69, 196, 228, 313, 321, 471, 512, 513, 514, 515, 516, 517, 519, 538, 1135, 1624, 1627, 1628, 1833, 1925, 1926, 1927, 1931, 1961, 2007, 2033, 2094, 2111, 2117, 2158, 2199], "function_that_actually_chang": 4, "second_build_dir": 4, "cancel": [4, 1311], "site": [4, 8, 2185], "denois": 4, "explan": [4, 10, 22, 27, 44, 892, 1314, 1580, 1877, 2132, 2133, 2142, 2195, 2201, 2205], "delta": [4, 39, 771, 1027, 1531, 1540, 1550, 1612, 1695, 1837, 1988, 1989, 2018, 2040, 2041, 2094, 2124], "inclus": [4, 39, 56, 87, 513, 1232, 1238, 1275, 1277, 1385, 1401, 1407, 1642, 1643, 1903, 1904, 1987, 2165, 2178], "diff": [4, 8, 2093, 2094, 2117, 2155], "One": [4, 9, 16, 30, 32, 56, 57, 63, 65, 69, 583, 981, 1004, 1202, 1213, 1305, 1633, 1724, 1771, 1779, 1780, 1787, 1791, 1860, 1865, 1874, 1903, 1904, 2028, 2045, 2093, 2095, 2096, 2116, 2128, 2129, 2130, 2133, 2140, 2147, 2159, 2168, 2176, 2186, 2190, 2191, 2193, 2194, 2202, 2209], "reason": [4, 9, 10, 25, 30, 32, 34, 41, 56, 60, 65, 681, 871, 935, 936, 1165, 1167, 1314, 1330, 1331, 1350, 1351, 1378, 1415, 1492, 1519, 1580, 1688, 1738, 1793, 1877, 1924, 2093, 2095, 2096, 2100, 2102, 2117, 2127, 2132, 2134, 2136, 2145, 2147, 2154, 2166, 2174, 2190, 2191, 2192, 2194, 2195, 2198, 2204, 2205, 2206], "unit": [4, 13, 16, 39, 41, 52, 60, 69, 771, 772, 1162, 1180, 1488, 1498, 1521, 1524, 1529, 1530, 1531, 1532, 1599, 1600, 1610, 1651, 1675, 1679, 1684, 1685, 1732, 1741, 1797, 1798, 1802, 1806, 1809, 1905, 2020, 2075, 2110, 2127, 2129, 2136, 2138, 2158, 2188, 2189], "next": [4, 25, 30, 34, 36, 39, 51, 56, 57, 58, 60, 69, 560, 771, 1226, 1318, 1480, 1532, 1551, 1598, 1770, 1815, 2114, 2126, 2127, 2129, 2130, 2133, 2134, 2136, 2142, 2144, 2149, 2159, 2166, 2167, 2171, 2173, 2174, 2176, 2185, 2189, 2192, 2193, 2195], "logic": [4, 6, 14, 16, 25, 42, 55, 58, 60, 69, 974, 976, 977, 979, 1009, 1010, 1161, 1163, 1166, 1167, 1169, 1170, 1173, 1174, 1176, 1177, 1179, 1181, 1202, 1318, 1396, 1397, 1398, 1399, 1409, 1586, 1770, 1891, 1918, 2004, 2096, 2097, 2130, 2132, 2133, 2134, 2138, 2161, 2192], "question": [4, 12, 25, 69, 1236, 1824, 2125, 2127, 2136, 2183, 2191, 2194], "involv": [4, 6, 8, 10, 13, 25, 30, 56, 58, 60, 63, 65, 69, 1224, 1770, 1936, 2096, 2115, 2117, 2127, 2130, 2132, 2135, 2142, 2145, 2154, 2161, 2166, 2167, 2168, 2171, 2191, 2194, 2202, 2204], "look": [4, 5, 8, 9, 10, 14, 17, 30, 37, 39, 50, 56, 57, 58, 62, 65, 69, 71, 81, 82, 486, 892, 938, 940, 1019, 1226, 1237, 1314, 1409, 1484, 1580, 1677, 1805, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1976, 1977, 1978, 1980, 1981, 2093, 2095, 2100, 2115, 2122, 2126, 2127, 2130, 2134, 2140, 2142, 2144, 2148, 2154, 2158, 2161, 2166, 2167, 2182, 2186, 2189, 2190, 2191, 2192, 2195, 2196, 2197, 2198, 2201, 2202, 2203, 2204, 2205, 2207], "autom": [4, 9, 69, 2093, 2161, 2185, 2195], "easili": [4, 8, 9, 13, 26, 30, 32, 36, 56, 1202, 1587, 1686, 1725, 1860, 1921, 2034, 2108, 2117, 2133, 2134, 2138, 2142, 2147, 2157, 2165, 2166, 2168, 2176, 2195, 2203, 2204, 2205], "exclus": [4, 25, 30, 39, 41, 51, 60, 69, 746, 1277, 1770, 1903, 1904, 1907, 2127, 2178], "basi": [4, 10, 12, 39, 681, 1387, 1865, 2130, 2140, 2161, 2166, 2184, 2189, 2204], "thought": [4, 48, 69, 1162, 1164, 1180, 1232, 2192], "path_and_function_nam": 4, "children": [4, 36, 44, 60, 69, 804, 1314, 1580, 1877, 2114, 2136, 2142, 2158, 2168], "identifi": [4, 8, 10, 30, 32, 41, 45, 48, 51, 52, 54, 69, 86, 486, 832, 1277, 1386, 1443, 1620, 2097, 2100, 2114, 2128, 2140, 2142, 2147, 2158, 2166, 2167, 2168, 2173, 2176, 2184, 2191, 2202, 2204], "hot": [4, 39, 1688, 1724, 2138, 2189], "spot": [4, 1779, 1780], "_data": 4, "truncate_row": 4, "_linewidth": 4, "subtract": [4, 313, 564, 895, 1198, 1688, 1976, 1977, 1978, 1980, 1981, 1991, 2094, 2155, 2171], "index": [4, 17, 21, 25, 26, 30, 32, 36, 39, 49, 58, 69, 191, 208, 281, 312, 313, 314, 315, 316, 317, 319, 321, 322, 471, 472, 512, 513, 514, 515, 516, 517, 518, 519, 684, 685, 686, 690, 691, 692, 706, 707, 832, 884, 907, 922, 924, 935, 936, 967, 986, 1015, 1059, 1062, 1095, 1123, 1124, 1164, 1205, 1206, 1207, 1211, 1213, 1255, 1286, 1287, 1288, 1289, 1312, 1331, 1336, 1344, 1362, 1380, 1394, 1402, 1404, 1408, 1412, 1415, 1416, 1417, 1420, 1446, 1449, 1466, 1472, 1475, 1476, 1484, 1499, 1515, 1522, 1523, 1581, 1582, 1587, 1590, 1591, 1630, 1632, 1677, 1678, 1724, 1799, 1801, 1807, 1808, 1813, 1826, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1875, 1876, 1878, 1893, 1925, 1926, 1927, 1928, 1930, 1931, 1932, 1961, 1972, 1973, 1976, 1977, 1978, 1980, 1981, 1990, 2007, 2028, 2029, 2031, 2032, 2033, 2036, 2045, 2053, 2055, 2093, 2094, 2096, 2100, 2103, 2114, 2115, 2116, 2122, 2127, 2130, 2132, 2134, 2137, 2139, 2146, 2150, 2155, 2157, 2168, 2170, 2171, 2173, 2174, 2175, 2176, 2177, 2178, 2194, 2195, 2199, 2204, 2205], "cpython": [4, 56, 69, 2183, 2193], "known": [4, 8, 10, 24, 29, 30, 35, 45, 51, 57, 61, 64, 66, 71, 81, 82, 1208, 1209, 1228, 1330, 1331, 1386, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1550, 1596, 1610, 1612, 1632, 1697, 1741, 1760, 1948, 1949, 1995, 2011, 2094, 2098, 2100, 2109, 2114, 2117, 2124, 2127, 2129, 2146, 2150, 2154, 2157, 2166, 2168, 2172, 2183, 2191, 2196, 2205], "quit": [4, 8, 69, 1779, 1780, 2096, 2122, 2133, 2135, 2158, 2166, 2202], "noisi": 4, "higher": [4, 8, 9, 26, 30, 34, 60, 61, 66, 71, 76, 80, 88, 150, 923, 925, 944, 1089, 1101, 1136, 1203, 1209, 1213, 1222, 1238, 1241, 1275, 1291, 1473, 1515, 1572, 1587, 1738, 1837, 1893, 1995, 2045, 2100, 2130, 2133, 2134, 2138, 2140, 2147, 2161, 2162, 2166, 2174, 2191, 2204], "filter": [4, 22, 544, 783, 784, 785, 1311, 1334, 1507, 1508, 1509, 1510, 1511, 1512, 1661, 1662, 1663, 1664, 1665, 1666, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1990, 2096, 2158, 2205], "transform": [4, 14, 25, 32, 36, 37, 38, 56, 60, 65, 67, 415, 792, 811, 866, 868, 887, 888, 993, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1201, 1202, 1203, 1207, 1212, 1235, 1311, 1324, 1497, 1534, 1542, 1543, 1544, 1552, 1567, 1586, 1609, 1625, 1626, 1627, 1628, 1651, 1657, 1686, 1703, 1723, 1760, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1852, 1856, 1857, 1858, 1859, 1860, 1956, 1990, 2104, 2117, 2134, 2136, 2137, 2161, 2171, 2176, 2182, 2183, 2193, 2197, 2204], "rather": [4, 9, 10, 16, 30, 41, 44, 54, 56, 58, 60, 69, 71, 80, 790, 796, 962, 992, 1015, 1312, 1315, 1386, 1476, 1651, 1686, 1697, 1757, 1788, 1936, 1940, 2093, 2096, 2116, 2117, 2128, 2130, 2133, 2134, 2147, 2154, 2158, 2161, 2166, 2171, 2176, 2189, 2190, 2192, 2194, 2195, 2196, 2197, 2204], "unicod": [4, 2097], "dictionari": [4, 16, 25, 26, 32, 36, 37, 39, 56, 64, 69, 415, 681, 805, 806, 807, 811, 830, 831, 832, 866, 868, 869, 884, 888, 894, 969, 1002, 1101, 1201, 1211, 1221, 1228, 1314, 1315, 1322, 1326, 1330, 1331, 1386, 1387, 1457, 1458, 1522, 1523, 1580, 1581, 1590, 1677, 1804, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 2060, 2078, 2079, 2095, 2097, 2133, 2142, 2150, 2154, 2157, 2166, 2176, 2181, 2185, 2200, 2206, 2207], "lookup": [4, 32, 39, 51, 1522, 1677, 2093, 2097, 2129, 2167, 2198], "map": [4, 16, 30, 32, 37, 39, 41, 48, 49, 51, 52, 56, 57, 58, 60, 65, 66, 69, 71, 80, 233, 695, 746, 805, 806, 810, 811, 814, 829, 830, 832, 868, 869, 884, 885, 886, 887, 888, 894, 915, 983, 1196, 1202, 1213, 1224, 1226, 1228, 1233, 1268, 1277, 1322, 1325, 1386, 1387, 1510, 1511, 1512, 1518, 1519, 1520, 1524, 1526, 1576, 1577, 1578, 1581, 1590, 1672, 1673, 1674, 1679, 1787, 1804, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1893, 1895, 2029, 2030, 2045, 2097, 2100, 2108, 2116, 2118, 2127, 2130, 2132, 2133, 2134, 2143, 2148, 2150, 2154, 2157, 2158, 2161, 2164, 2166, 2167, 2168, 2171, 2173, 2178, 2193, 2194, 2203, 2206], "agnost": [4, 18, 51, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1686, 1779, 1780, 2100, 2116], "reliabl": 4, "warrant": 4, "except": [4, 6, 8, 10, 16, 30, 31, 32, 34, 37, 39, 41, 43, 44, 48, 52, 56, 57, 60, 68, 69, 233, 583, 587, 588, 617, 684, 695, 704, 706, 707, 710, 771, 834, 915, 948, 949, 950, 989, 996, 1000, 1043, 1053, 1056, 1088, 1102, 1136, 1142, 1144, 1190, 1191, 1211, 1213, 1230, 1278, 1314, 1322, 1330, 1332, 1336, 1370, 1386, 1402, 1412, 1414, 1415, 1417, 1420, 1442, 1471, 1474, 1476, 1531, 1550, 1580, 1596, 1633, 1724, 1763, 1770, 1788, 1813, 1820, 1821, 1825, 1827, 1877, 1890, 1914, 1930, 1933, 1966, 1974, 1979, 1986, 1988, 1989, 1993, 2018, 2040, 2041, 2045, 2046, 2092, 2093, 2095, 2096, 2097, 2098, 2100, 2103, 2114, 2130, 2133, 2136, 2142, 2145, 2148, 2158, 2166, 2168, 2171, 2173, 2174, 2178, 2190, 2192, 2194, 2202, 2203, 2207, 2209], "filter_fn": 4, "map_fn": 4, "coalesc": [4, 323, 328, 544, 614, 1052, 1055, 1975, 1979, 2028, 2094, 2132, 2155, 2171, 2195], "entri": [4, 21, 30, 31, 35, 39, 41, 42, 49, 51, 52, 315, 746, 888, 889, 962, 1086, 1087, 1134, 1185, 1186, 1289, 1314, 1335, 1522, 1523, 1580, 1586, 1677, 1678, 1799, 1800, 1807, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1972, 2093, 2096, 2097, 2103, 2117, 2127, 2132, 2133, 2138, 2142, 2147, 2164, 2171, 2176, 2181, 2190, 2191, 2192, 2193], "color": [4, 69, 1544, 2095, 2096, 2176, 2196, 2204], "rowwis": [4, 38], "columnwis": 4, "extend_result": 4, "highlight_warn": 4, "highlight": [4, 57, 741, 742, 2096], "trim_significant_figur": 4, "trim": [4, 971, 980, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1272, 1273, 1311], "h": [5, 12, 16, 36, 39, 487, 488, 752, 753, 754, 771, 994, 995, 1344, 1351, 1354, 1364, 1378, 1482, 1483, 1490, 1491, 1493, 1495, 1496, 1508, 1509, 1511, 1519, 1520, 1522, 1524, 1531, 1532, 1543, 1544, 1550, 1551, 1552, 1563, 1564, 1574, 1575, 1592, 1593, 1596, 1598, 1615, 1631, 1634, 1635, 1651, 1659, 1686, 1722, 1728, 1729, 1738, 1787, 1788, 1821, 1833, 1882, 1994, 1995, 2094, 2111, 2115, 2116, 2122, 2127, 2130, 2132, 2133, 2135, 2138, 2154, 2175, 2176, 2177, 2185, 2191, 2201], "finit": [5, 39, 949, 950, 1303, 1304, 1350, 1351, 1361, 1362, 1378, 1404, 1466, 1470, 1492, 1994, 2133, 2138, 2178], "natur": [5, 8, 9, 13, 32, 39, 60, 71, 73, 949, 950, 1343, 1348, 1374, 1388, 1390, 1395, 1484, 1628, 1738, 2136, 2138, 2149, 2150, 2171, 2172], "against": [5, 6, 16, 30, 41, 51, 58, 807, 895, 949, 950, 1172, 1173, 1174, 1178, 1179, 1181, 1255, 1305, 1314, 1330, 1331, 1580, 1586, 1834, 1877, 2091, 2096, 2156, 2158, 2182, 2192, 2201], "cprofil": 5, "mode": [5, 9, 25, 26, 30, 32, 34, 39, 51, 54, 56, 58, 65, 66, 69, 221, 222, 488, 757, 758, 783, 784, 785, 790, 796, 797, 798, 830, 832, 842, 851, 889, 890, 919, 921, 925, 928, 929, 930, 935, 936, 938, 939, 940, 941, 945, 946, 947, 949, 1002, 1007, 1015, 1037, 1044, 1077, 1119, 1148, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1202, 1205, 1206, 1207, 1208, 1211, 1212, 1214, 1215, 1222, 1227, 1262, 1297, 1298, 1312, 1314, 1315, 1318, 1330, 1332, 1373, 1386, 1416, 1433, 1434, 1444, 1494, 1495, 1496, 1507, 1508, 1509, 1523, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1597, 1620, 1633, 1634, 1661, 1662, 1663, 1678, 1686, 1697, 1725, 1738, 1757, 1758, 1759, 1772, 1781, 1783, 1788, 1793, 1825, 1865, 1874, 1877, 1892, 1935, 1937, 2033, 2094, 2100, 2106, 2115, 2124, 2130, 2132, 2134, 2135, 2136, 2137, 2142, 2149, 2150, 2155, 2159, 2162, 2163, 2164, 2166, 2177, 2180, 2185, 2189, 2193, 2194, 2195, 2196, 2197, 2199, 2204, 2205, 2206], "correct": [5, 6, 7, 8, 26, 30, 31, 32, 36, 37, 39, 51, 56, 58, 88, 205, 206, 209, 221, 555, 580, 603, 604, 615, 623, 930, 931, 935, 950, 1027, 1165, 1167, 1175, 1176, 1177, 1233, 1289, 1312, 1315, 1330, 1331, 1350, 1516, 1533, 1545, 1760, 1770, 1813, 1939, 1988, 1989, 2040, 2041, 2093, 2094, 2095, 2100, 2104, 2115, 2116, 2124, 2130, 2133, 2138, 2157, 2173, 2192, 2199, 2203, 2204], "launch": [5, 16, 25, 33, 36, 37, 41, 43, 44, 49, 50, 51, 55, 68, 1040, 1770, 2127, 2129, 2130, 2132, 2133, 2166, 2189, 2197], "spent": [5, 30, 963, 1872, 2129, 2142, 2195, 2202, 2205], "appear": [5, 26, 30, 39, 56, 57, 69, 884, 965, 1089, 1144, 1185, 1186, 1213, 1386, 1420, 1422, 1771, 1772, 1914, 1942, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2045, 2093, 2096, 2115, 2116, 2133, 2134, 2142, 2154, 2158, 2192, 2195, 2202], "extrem": [5, 30, 1770, 2127, 2154, 2194], "expens": [5, 25, 39, 60, 1787, 2122, 2130, 2138, 2140, 2159, 2166, 2177, 2191, 2195, 2198, 2201, 2205], "bound": [5, 17, 26, 30, 57, 60, 481, 808, 986, 997, 1158, 1159, 1228, 1232, 1237, 1314, 1489, 1490, 1491, 1573, 1574, 1575, 1580, 1599, 1686, 1874, 1877, 1907, 1928, 2096, 2097, 2124, 2127, 2136, 2158, 2161, 2172, 2191, 2192, 2194, 2204, 2205], "greater": [5, 19, 30, 71, 72, 292, 617, 681, 978, 991, 992, 997, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1257, 1271, 1369, 1438, 1492, 1629, 1686, 1697, 1724, 1738, 1754, 1757, 1788, 1821, 1874, 2033, 2094, 2117, 2127, 2130, 2146, 2155, 2171, 2172], "spend": [5, 8, 21, 36, 1387, 2104, 2198], "sens": [5, 39, 51, 69, 1804, 2029, 2030, 2096, 2127, 2136], "respons": [5, 8, 10, 16, 30, 32, 35, 36, 37, 39, 41, 48, 54, 60, 68, 1004, 1040, 1230, 1568, 1704, 1770, 1979, 2100, 2127, 2130, 2133, 2134, 2142, 2166, 2194, 2204], "Of": [5, 1826, 2091, 2132, 2133, 2183, 2192, 2195], "cours": [5, 21, 69, 1216, 2091, 2132, 2133, 2166, 2192, 2195], "realiti": [5, 2136, 2204], "complic": [5, 26, 38, 56, 69, 806, 1936, 2100, 2116, 2128, 2158, 2166, 2168, 2192, 2194, 2204], "account": [5, 36, 49, 69, 1493, 1770, 2122, 2124, 2129, 2136, 2171, 2189], "heavili": [5, 1843, 2129, 2133, 2158], "similarli": [5, 8, 30, 32, 36, 56, 68, 69, 771, 803, 807, 888, 993, 1164, 1314, 1370, 1580, 1628, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 1877, 2021, 2022, 2023, 2024, 2095, 2100, 2127, 2133, 2135, 2138, 2145, 2171, 2194, 2197, 2202], "platform": [5, 9, 10, 16, 30, 43, 44, 48, 1361, 1362, 1373, 1892, 1994, 2106, 2139, 2145, 2146, 2161, 2185], "startup": [5, 21], "slower": [5, 16, 30, 36, 906, 939, 1184, 1185, 1186, 1344, 1351, 1705, 1787, 1837, 1838, 2133, 2146, 2157, 2172, 2194, 2204], "rerun": [6, 30, 2130], "segment": [6, 1101, 1198, 1217, 1612, 2130, 2158, 2195, 2200, 2204, 2207], "persist": [6, 23, 32, 56, 60, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 771, 830, 831, 832, 1314, 1531, 1550, 1580, 1596, 1771, 1773, 1877, 2142, 2147, 2148, 2173, 2184, 2189, 2194, 2198], "rng": [6, 25, 1074, 1116, 1428, 1439, 1453, 1461, 1929, 2064, 2085, 2130, 2146, 2165], "advanc": [6, 17, 25, 26, 41, 1624, 1626, 1628, 1826, 1995, 2036, 2100, 2103, 2116, 2130, 2133, 2139, 2144, 2175, 2176, 2195, 2204], "juggl": 6, "moder": 6, "hit": [6, 9, 16, 58, 1230, 1770, 2091, 2117, 2130, 2189, 2192, 2195, 2198, 2204, 2205], "preserve_rng_st": 6, "checkpoint_sequenti": 6, "omit": [6, 16, 30, 52, 150, 1178, 1179, 1181, 1228, 1533, 1594, 2148, 2154, 2166, 2178, 2192, 2196], "exclud": [6, 10, 26, 34, 51, 69, 1012, 1277, 1523, 1678, 1727, 1834, 1936, 2021, 2022, 2023, 2024, 2127, 2139, 2147, 2158, 2167, 2193, 2195], "_infer_device_typ": 6, "remain": [6, 9, 21, 37, 39, 51, 69, 1422, 1522, 1523, 1677, 1678, 1760, 1770, 1779, 1780, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1874, 1893, 1915, 2108, 2109, 2114, 2126, 2130, 2135, 2142, 2157, 2173, 2185, 2193], "consequ": [6, 65, 1378, 1550, 1994, 2096, 2127, 2130, 2144, 2146, 2149], "random": [6, 37, 39, 41, 51, 52, 61, 69, 87, 154, 771, 922, 935, 936, 972, 1074, 1075, 1081, 1090, 1091, 1112, 1113, 1116, 1117, 1206, 1213, 1267, 1290, 1387, 1407, 1428, 1429, 1437, 1439, 1453, 1461, 1488, 1499, 1524, 1531, 1550, 1599, 1679, 1730, 1736, 1760, 1788, 1795, 1801, 1802, 1808, 1809, 1828, 1882, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1929, 1941, 1995, 2036, 2045, 2064, 2065, 2068, 2071, 2072, 2082, 2083, 2085, 2086, 2091, 2094, 2100, 2102, 2124, 2134, 2138, 2145, 2147, 2154, 2155, 2160, 2176, 2195, 2205], "gradient": [6, 13, 25, 26, 30, 34, 35, 36, 37, 39, 60, 61, 64, 150, 221, 222, 290, 335, 487, 488, 495, 513, 706, 707, 910, 919, 921, 923, 926, 927, 928, 929, 930, 931, 932, 933, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 946, 949, 950, 954, 955, 973, 999, 1148, 1201, 1202, 1203, 1204, 1208, 1213, 1255, 1314, 1350, 1351, 1354, 1361, 1362, 1378, 1387, 1404, 1406, 1412, 1415, 1417, 1492, 1499, 1510, 1511, 1512, 1515, 1516, 1522, 1523, 1533, 1547, 1548, 1549, 1580, 1587, 1612, 1669, 1670, 1677, 1678, 1688, 1697, 1705, 1707, 1708, 1709, 1722, 1757, 1758, 1759, 1770, 1772, 1775, 1776, 1777, 1778, 1787, 1793, 1825, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1863, 1864, 1877, 1880, 1975, 1994, 2045, 2093, 2094, 2100, 2103, 2116, 2117, 2118, 2124, 2130, 2132, 2133, 2135, 2136, 2138, 2142, 2145, 2155, 2157, 2166, 2167, 2171, 2173, 2177, 2202], "among": [6, 21, 25, 26, 30, 35, 39, 51, 1051, 1052, 1056, 1277, 1516, 1828, 2096, 2144, 2192, 2194], "detect": [6, 16, 19, 20, 21, 25, 27, 30, 31, 41, 44, 60, 69, 681, 689, 693, 938, 939, 940, 941, 942, 943, 1002, 1202, 1318, 1624, 1625, 1627, 1770, 2033, 2114, 2130, 2138, 2145, 2158, 2166, 2191, 2192, 2195, 2205, 2209], "priorit": [6, 36, 1205, 1206, 1208, 2117, 2171, 2173], "defaultdevicetyp": 6, "anticip": [6, 2204, 2207], "belong": [6, 30, 32, 35, 39, 48, 69, 986, 1226, 2091, 2130, 2157, 2203, 2206], "use_reentr": [6, 1770], "context_fn": 6, "noop_context_fn": 6, "determinism_check": 6, "techniqu": [6, 19, 21, 36, 69, 1517, 1795, 2018, 2118, 2142, 2149, 2150, 2157, 2161, 2188, 2204, 2205], "recomput": [6, 38, 930, 933, 935, 1633, 1697, 1824, 2157, 2191], "refer": [6, 8, 16, 25, 26, 30, 31, 32, 35, 37, 39, 43, 46, 47, 51, 52, 60, 61, 68, 254, 745, 746, 767, 775, 805, 806, 807, 810, 837, 839, 840, 843, 846, 851, 889, 903, 908, 923, 984, 1041, 1082, 1087, 1147, 1198, 1228, 1262, 1264, 1295, 1302, 1314, 1317, 1326, 1333, 1346, 1351, 1367, 1371, 1384, 1387, 1466, 1499, 1533, 1580, 1630, 1651, 1659, 1668, 1686, 1697, 1698, 1756, 1765, 1766, 1770, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1877, 1882, 1899, 1906, 1935, 1936, 1956, 1995, 2033, 2091, 2094, 2114, 2115, 2117, 2118, 2126, 2127, 2130, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2142, 2144, 2146, 2154, 2157, 2160, 2162, 2163, 2166, 2167, 2171, 2173, 2174, 2175, 2176, 2180, 2183, 2189, 2190, 2192, 2193, 2197, 2200, 2204, 2205], "potenti": [6, 9, 32, 51, 54, 191, 208, 486, 1229, 1324, 1360, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1738, 1770, 2033, 2095, 2103, 2114, 2127, 2130, 2133, 2136, 2158, 2171, 2174, 2175, 2191, 2195, 2204], "silent": [6, 21, 30, 1004, 1014, 1090, 1091, 1112, 1113, 1289, 1330, 1580, 1776, 1777, 1778, 1785, 1979, 2071, 2072, 2082, 2083, 2130, 2145, 2154], "consider": [6, 8, 914, 1311, 1523, 1770, 1779, 1780, 2096, 2129], "limit": [6, 9, 10, 14, 22, 25, 36, 57, 60, 61, 66, 1019, 1115, 1202, 1328, 1438, 1499, 1522, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1738, 1770, 1804, 1940, 2092, 2096, 2100, 2111, 2114, 2116, 2117, 2122, 2127, 2130, 2132, 2137, 2141, 2142, 2145, 2146, 2147, 2149, 2150, 2158, 2161, 2164, 2166, 2167, 2171, 2177, 2178, 2191, 2194, 2195, 2201, 2205], "reentrant": [6, 1770], "soon": [6, 51, 56, 58, 60, 806, 2127, 2161, 2166, 2168, 2195], "intermedi": [6, 14, 16, 36, 37, 40, 56, 57, 58, 65, 69, 983, 1019, 1195, 1202, 1209, 1404, 1523, 1624, 1626, 1628, 1678, 1738, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2093, 2096, 2100, 2117, 2130, 2133, 2134, 2135, 2145, 2182, 2191, 2192, 2194, 2204], "set_checkpoint_early_stop": 6, "entireti": 6, "graph": [6, 9, 14, 30, 32, 36, 39, 58, 60, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 87, 139, 150, 221, 222, 681, 758, 805, 806, 830, 831, 832, 834, 842, 851, 923, 930, 933, 935, 944, 1002, 1004, 1007, 1009, 1010, 1015, 1037, 1079, 1084, 1089, 1202, 1218, 1222, 1226, 1228, 1232, 1238, 1251, 1314, 1317, 1318, 1324, 1326, 1330, 1770, 1834, 1836, 1837, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 2096, 2100, 2102, 2106, 2111, 2117, 2118, 2126, 2132, 2133, 2136, 2138, 2142, 2143, 2149, 2150, 2154, 2158, 2159, 2162, 2163, 2164, 2166, 2167, 2168, 2171, 2176, 2182, 2183, 2185, 2186, 2190, 2191, 2193, 2194, 2196, 2197, 2198, 2200, 2201], "no_grad": [6, 58, 488, 891, 945, 1148, 1203, 1207, 1212, 1314, 1522, 1580, 1586, 1628, 1772, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1877, 2124, 2127, 2137, 2142, 2151, 2161, 2180, 2185, 2186, 2204], "unmet": 6, "particip": [6, 10, 25, 30, 31, 35, 51, 52, 1624, 1770, 2167, 2191], "wherea": [6, 13, 34, 36, 39, 56, 286, 1314, 1370, 1433, 1434, 1471, 1580, 1860, 1877, 1994, 2096, 2127, 2157, 2173, 2178, 2194], "avoid": [6, 9, 10, 19, 21, 22, 25, 30, 32, 34, 36, 37, 39, 49, 52, 58, 60, 69, 71, 79, 80, 191, 208, 448, 792, 895, 923, 983, 1002, 1101, 1218, 1314, 1360, 1386, 1514, 1545, 1546, 1571, 1580, 1589, 1594, 1632, 1668, 1698, 1723, 1730, 1770, 1788, 1838, 1860, 1877, 1914, 1942, 1990, 2002, 2011, 2029, 2067, 2100, 2109, 2116, 2117, 2127, 2129, 2130, 2135, 2138, 2139, 2142, 2151, 2157, 2166, 2167, 2173, 2175, 2176, 2177, 2189, 2191, 2192, 2194, 2195, 2196, 2204], "know": [6, 8, 9, 16, 19, 21, 30, 31, 34, 36, 40, 56, 58, 69, 486, 684, 930, 931, 935, 939, 956, 1004, 1144, 1195, 1202, 1217, 1228, 1238, 1242, 1325, 1770, 2093, 2096, 2103, 2104, 2108, 2122, 2126, 2127, 2130, 2133, 2136, 2138, 2154, 2158, 2166, 2167, 2168, 2171, 2184, 2189, 2191, 2192, 2193, 2194, 2195, 2204, 2208], "lstm": [6, 774, 1551, 1597, 2094, 2130, 2154, 2155, 2161, 2163, 2164, 2176], "hidden": [6, 771, 1211, 1531, 1532, 1550, 1551, 1596, 1598, 1772, 2130, 2176], "correctli": [6, 21, 25, 30, 36, 37, 51, 60, 486, 1202, 1314, 1330, 1580, 1705, 1877, 2093, 2095, 2096, 2100, 2109, 2116, 2126, 2127, 2130, 2132, 2133, 2134, 2144, 2146, 2157, 2161, 2166, 2202], "compil": [6, 14, 16, 17, 56, 57, 58, 60, 61, 69, 681, 1019, 1057, 1068, 1072, 1086, 1087, 1202, 1222, 1227, 1242, 1312, 1314, 1315, 1318, 1319, 1326, 1327, 1328, 1330, 1331, 1332, 1580, 1877, 2059, 2063, 2093, 2095, 2096, 2097, 2098, 2100, 2102, 2126, 2129, 2132, 2140, 2148, 2152, 2154, 2160, 2166, 2173, 2177, 2180, 2186, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2197, 2198, 2199, 2200, 2201], "turn": [6, 16, 25, 29, 36, 37, 65, 69, 681, 903, 1002, 1302, 1330, 1625, 1627, 1976, 1977, 1978, 1979, 1980, 1981, 2033, 2100, 2103, 2122, 2127, 2130, 2145, 2146, 2159, 2161, 2167, 2171, 2191, 2194, 2197, 2202], "open": [6, 9, 10, 13, 16, 25, 39, 51, 56, 61, 700, 959, 986, 1194, 1322, 1386, 1409, 1419, 1703, 2093, 2100, 2103, 2114, 2139, 2147, 2148, 2149, 2151, 2154, 2158, 2161, 2166, 2171, 2172, 2173, 2192, 2195, 2202, 2204, 2207, 2208], "ran": [6, 20, 60, 2195, 2200], "sequenti": [6, 25, 35, 36, 56, 57, 60, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 806, 1213, 1314, 1324, 1525, 1580, 1620, 1631, 1779, 1780, 1790, 1804, 1875, 1877, 2045, 2093, 2114, 2117, 2130, 2142, 2154, 2157, 2161, 2182, 2192, 2195, 2202, 2205], "divid": [6, 26, 30, 34, 35, 36, 238, 583, 584, 585, 1056, 1139, 1142, 1162, 1180, 1189, 1223, 1277, 1278, 1325, 1492, 1493, 1499, 1500, 1513, 1539, 1540, 1546, 1571, 1572, 1583, 1584, 1585, 1594, 1612, 1613, 1629, 1630, 1658, 1659, 1669, 1670, 1698, 1722, 1730, 1770, 1994, 2046, 2094, 2155], "func": [6, 30, 37, 63, 65, 69, 71, 73, 892, 922, 925, 930, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943, 945, 949, 950, 1215, 1317, 1330, 1331, 1822, 2036, 2045, 2096, 2100, 2125, 2126, 2160, 2166, 2168, 2189, 2204, 2206], "compris": [6, 52, 56, 2136, 2204], "chunk": [6, 25, 30, 34, 36, 37, 60, 989, 1056, 1207, 1516, 1770, 1982, 2093, 2094, 2115, 2117, 2136, 2155, 2157, 2166, 2171, 2175], "input_var": [6, 1516], "set_checkpoint_debug_en": 6, "defer": [6, 26, 60, 1228, 2130], "checkpointpolici": 6, "enum": [6, 30, 49, 71, 809, 1639, 1640, 1641, 2111, 2133, 2159, 2161, 2166], "polici": [6, 34, 36, 39, 41, 44, 60, 1222, 1865, 1872, 2192], "backpropag": [6, 39, 950, 1858, 1892, 2135, 2183], "_save": [6, 2127], "_recomput": 6, "must_": 6, "prefer_": 6, "subsystem": [6, 8, 13, 58, 61, 66, 2100, 2133], "prefer_recomput": 6, "vanilla": [6, 26, 57, 2103], "prefer_sav": 6, "selectivecheckpointcontext": 6, "is_recomput": 6, "relev": [6, 10, 31, 36, 41, 51, 68, 681, 1378, 1552, 2097, 2117, 2126, 2127, 2158, 2161, 2180, 2185, 2195, 2196, 2197, 2204, 2208], "policy_fn": 6, "functool": [6, 60, 63, 71, 871, 1250, 1967, 2133, 2178], "partial": [6, 30, 37, 39, 41, 51, 56, 60, 63, 69, 871, 1089, 1134, 1212, 1226, 1268, 1361, 1362, 1363, 1405, 1576, 1577, 1578, 1714, 1715, 1716, 1770, 1800, 1967, 1973, 2096, 2097, 2116, 2127, 2133, 2136, 2138, 2154, 2168, 2178, 2200], "create_selective_checkpoint_context": 6, "policy_fn_or_list": 6, "allow_cache_entry_mut": 6, "certain": [6, 19, 25, 26, 30, 36, 37, 48, 49, 56, 65, 68, 69, 697, 700, 746, 895, 945, 970, 982, 1066, 1132, 1226, 1311, 1314, 1322, 1386, 1409, 1419, 1507, 1508, 1509, 1510, 1511, 1512, 1532, 1551, 1567, 1580, 1586, 1632, 1687, 1698, 1700, 1826, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 2058, 2096, 2100, 2103, 2116, 2117, 2127, 2128, 2130, 2133, 2140, 2142, 2145, 2147, 2154, 2159, 2166, 2167, 2171, 2194, 2195, 2198, 2204, 2205], "accept": [6, 8, 10, 25, 30, 32, 37, 38, 56, 60, 61, 62, 64, 66, 513, 817, 919, 920, 921, 922, 923, 930, 932, 935, 936, 944, 956, 992, 1086, 1089, 1197, 1213, 1227, 1277, 1314, 1318, 1515, 1580, 1587, 1609, 1628, 1800, 1813, 1814, 1820, 1835, 1877, 1970, 1985, 2045, 2096, 2100, 2116, 2130, 2133, 2134, 2139, 2154, 2157, 2166, 2174, 2176, 2195, 2204, 2205], "opoverload": [6, 37, 69, 1226, 2100], "must_sav": 6, "ops_to_sav": 6, "person": [7, 8, 10], "land": [7, 10, 12, 1004, 2100, 2125, 2133, 2192, 2201], "six": [7, 1509], "commit": [7, 8, 10, 37, 61, 2091, 2092, 2111, 2145, 2146, 2201], "repositori": [7, 10, 64, 69, 2091, 2144, 2161], "submit": [7, 10, 37, 86, 88, 1039, 1040, 1427, 1443, 2050, 2108, 2130, 2146, 2193, 2195, 2201, 2204], "month": [7, 10], "qualifi": [7, 30, 32, 34, 36, 38, 48, 69, 681, 1226, 1314, 1580, 1877, 2100, 2102, 2108, 2158], "pr": [7, 8, 1882, 1995, 2182, 2195], "interest": [7, 8, 10, 2127, 2134, 2138, 2142, 2149, 2184, 2192, 2193, 2194, 2198, 2202, 2204], "merge_rul": 7, "vote": [7, 10], "decis": [7, 32, 41, 51, 54, 69, 681, 1228, 1330, 2103, 2126, 2191, 2192], "criteria": [7, 10, 1387, 1995], "approv": [7, 10], "Not": [7, 52, 1235, 1474, 1628, 1990, 2093, 2095, 2096, 2097, 2130, 2133, 2155, 2161, 2166], "busi": [7, 10, 2198], "dai": [7, 8, 2192, 2194, 2201], "contributor": [7, 8, 9, 10], "seen": [7, 14, 20, 39, 69, 221, 957, 989, 1002, 1027, 1416, 1510, 1511, 1512, 1612, 1711, 1712, 1713, 1874, 2093, 2103, 2127, 2130, 2154, 2171], "thumb": [7, 30], "wiki": [8, 10, 26, 2149, 2210], "acceler": [8, 26, 30, 86, 88, 968, 1263, 1443, 1494, 1495, 1496, 1620, 1836, 2130, 2139, 2147, 2160, 2174, 2183, 2189, 2195, 2202], "deep": [8, 10, 69, 1494, 1495, 1496, 1521, 1620, 1859, 2092, 2124, 2130, 2137, 2142, 2161, 2188, 2191, 2193, 2205], "neural": [8, 9, 17, 69, 1488, 1499, 1517, 1524, 1533, 1545, 1579, 1580, 1587, 1592, 1593, 1608, 1610, 1624, 1626, 1628, 1717, 1741, 1791, 1857, 1865, 1872, 2093, 2095, 2096, 2124, 2130, 2133, 2145, 2149, 2161, 2191], "tape": [8, 2189], "system": [8, 9, 16, 17, 19, 25, 34, 52, 56, 58, 65, 69, 995, 1013, 1014, 1221, 1268, 1322, 1346, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1375, 1376, 1377, 1381, 1386, 1405, 1438, 1624, 1626, 1628, 1770, 1791, 1793, 1937, 1974, 2020, 2097, 2102, 2108, 2109, 2111, 2127, 2129, 2140, 2142, 2144, 2148, 2158, 2166, 2185, 2191, 2192, 2202, 2204, 2212], "organ": [8, 2132, 2140, 2158, 2195], "govern": [8, 9, 11], "technic": [8, 10, 51, 56, 60, 69, 1314, 1580, 1877, 2127, 2135, 2136, 2144, 2158, 2191], "found": [8, 16, 17, 18, 20, 21, 30, 32, 51, 56, 69, 969, 986, 1036, 1123, 1124, 1237, 1314, 1318, 1336, 1412, 1415, 1417, 1420, 1472, 1488, 1498, 1524, 1580, 1608, 1856, 1877, 1928, 2091, 2093, 2096, 2100, 2117, 2126, 2133, 2136, 2138, 2142, 2144, 2150, 2154, 2158, 2159, 2161, 2166, 2176, 2190, 2194, 2198, 2201, 2203, 2204, 2206], "md": [8, 69, 2158], "healthi": [8, 41, 51], "team": [8, 30, 61, 2147], "commun": [8, 9, 10, 31, 32, 34, 35, 36, 41, 51, 54, 60, 486, 681, 1770, 2127, 2130, 2132, 2149, 2160, 2166, 2167, 2189, 2192, 2195, 2209], "project": [8, 32, 36, 1416, 1550, 1586, 1793, 1882, 2091, 2100, 2136, 2139, 2149, 2185, 2203], "ve": [8, 63, 64, 65, 69, 1222, 1318, 2036, 2103, 2114, 2127, 2134, 2167, 2176, 2194, 2195], "come": [8, 9, 10, 25, 36, 39, 40, 48, 51, 56, 61, 65, 486, 1002, 1144, 1195, 1202, 1314, 1386, 1518, 1519, 1520, 1524, 1545, 1833, 2106, 2132, 2134, 2140, 2158, 2166, 2168, 2171, 2173, 2193, 2200], "peopl": [8, 30, 2127, 2161, 2197], "scratch": [8, 2127, 2157, 2204, 2205], "own": [8, 10, 30, 31, 34, 35, 39, 43, 51, 54, 56, 58, 60, 69, 681, 1078, 1178, 1198, 1277, 1314, 1386, 1507, 1508, 1509, 1510, 1511, 1512, 1580, 1586, 1624, 1625, 1626, 1627, 1628, 1790, 1793, 1877, 2096, 2100, 2118, 2126, 2130, 2136, 2158, 2161, 2162, 2166, 2168, 2171, 2173, 2192, 2194, 2197, 2204], "itch": 8, "acquaint": 8, "tip": [8, 2130, 2192, 2195, 2204], "tracker": [8, 681, 1387, 2108], "confirm": [8, 2091, 2093, 2133, 2154, 2166, 2168, 2200], "tend": [8, 940, 2033], "bootcamp": 8, "1hr": 8, "although": [8, 9, 39, 58, 65, 69, 1510, 1511, 1512, 1580, 1588, 1770, 2092, 2096, 2104, 2126, 2133, 2145, 2161, 2173, 2189, 2202, 2203, 2204], "join": [8, 26, 30, 35, 51, 52, 68, 69, 1254, 1770, 2091, 2097, 2114, 2127, 2132, 2144, 2155, 2160, 2177, 2185], "u": [8, 9, 14, 32, 36, 61, 66, 69, 71, 771, 938, 968, 993, 1227, 1251, 1351, 1353, 1357, 1361, 1362, 1378, 1404, 1406, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1531, 1532, 1550, 1551, 1565, 1567, 1596, 1598, 1599, 1620, 1631, 1793, 1838, 1882, 1994, 1995, 2093, 2094, 2100, 2103, 2116, 2117, 2124, 2127, 2130, 2132, 2133, 2134, 2142, 2158, 2171, 2175, 2176, 2180, 2184, 2185, 2189, 2191, 2192, 2195, 2198, 2199, 2204, 2205, 2208], "dev": [8, 12, 43, 48, 56, 2193, 2205], "happi": 8, "research": [8, 9, 10, 1770, 2091, 2127, 2138, 2147], "partner": [8, 2183], "speed": [8, 9, 16, 35, 60, 1050, 1144, 1201, 1305, 1318, 1324, 1378, 1484, 1586, 1779, 1780, 1936, 1994, 2104, 2127, 2129, 2130, 2132, 2133, 2135, 2139, 2145, 2161, 2166, 2180, 2192, 2193], "design": [8, 10, 11, 25, 32, 34, 39, 48, 51, 57, 61, 64, 65, 66, 949, 950, 1314, 1334, 1493, 1580, 1639, 1877, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2008, 2091, 2109, 2117, 2123, 2126, 2130, 2133, 2136, 2139, 2142, 2150, 2154, 2157, 2158, 2185, 2191, 2192, 2193, 2195, 2197, 2199, 2204, 2205], "comment": [8, 36, 69, 1824, 1932, 2096, 2097, 2133, 2174, 2176, 2198], "crack": 8, "usual": [8, 16, 25, 26, 30, 32, 38, 51, 52, 56, 57, 60, 69, 481, 858, 859, 860, 861, 871, 923, 938, 940, 944, 954, 1015, 1213, 1518, 1519, 1520, 1524, 1539, 1542, 1543, 1544, 1545, 1760, 1770, 1835, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2045, 2093, 2096, 2117, 2126, 2127, 2129, 2130, 2133, 2135, 2140, 2147, 2157, 2162, 2164, 2166, 2173, 2176, 2180, 2188, 2189, 2192, 2194, 2198, 2206], "idea": [8, 61, 958, 1144, 1232, 1484, 1770, 2130, 2140, 2154, 2167, 2173, 2195, 2204], "rfc": [8, 30, 34, 2127, 2161, 2167], "big": [8, 21, 1840, 1841, 1844, 1856, 1857, 1976, 1977, 1978, 1979, 1980, 1981, 2122, 2130, 2147, 2157, 2161, 2191, 2194, 2198], "post": [8, 9, 31, 32, 34, 35, 37, 60, 486, 488, 681, 886, 887, 891, 1314, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1849, 1851, 1856, 1857, 1858, 1859, 1860, 1877, 2100, 2127, 2132, 2133, 2135, 2148, 2150, 2171, 2192, 2193, 2194, 2205], "standard": [8, 16, 20, 21, 26, 39, 44, 45, 49, 56, 57, 58, 65, 69, 352, 377, 589, 1164, 1228, 1488, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1545, 1552, 1620, 1626, 1628, 1641, 1828, 1882, 1905, 1950, 1955, 1988, 1989, 2095, 2097, 2117, 2124, 2129, 2130, 2141, 2144, 2145, 2149, 2154, 2158, 2172, 2173, 2192, 2204], "lot": [8, 16, 21, 25, 56, 1238, 2114, 2127, 2130, 2138, 2144, 2158, 2165, 2167, 2176, 2191, 2194, 2198, 2204, 2207], "boil": 8, "mostli": [8, 36, 39, 58, 1312, 1770, 2130, 2161, 2171, 2191, 2192, 2206], "evid": [8, 1877], "peer": [8, 30, 35, 36, 51, 60, 1048, 1770, 2130, 2166], "paper": [8, 10, 26, 36, 38, 39, 57, 771, 1484, 1488, 1494, 1495, 1496, 1498, 1510, 1511, 1512, 1517, 1518, 1519, 1520, 1521, 1524, 1527, 1528, 1531, 1534, 1537, 1542, 1543, 1544, 1552, 1586, 1592, 1593, 1595, 1599, 1608, 1612, 1620, 1624, 1626, 1628, 1629, 1630, 1681, 1682, 1691, 1769, 1838, 1840, 1841, 1856, 1858, 1865, 1872, 2138], "framework": [8, 9, 10, 39, 48, 61, 68, 771, 1046, 1425, 1531, 1770, 1787, 1838, 1859, 1940, 2104, 2143, 2160, 2161, 2167, 2168], "bit": [8, 69, 87, 330, 458, 772, 774, 776, 837, 839, 840, 841, 846, 852, 888, 975, 978, 1020, 1021, 1198, 1294, 1916, 1917, 1929, 1936, 1957, 2130, 2136, 2141, 2142, 2145, 2148, 2161, 2164, 2165, 2171, 2174, 2177, 2192, 2198, 2204, 2210], "overwhelm": [8, 2166, 2205], "newli": [8, 60, 69, 87, 1158, 1159, 1228, 1522, 1523, 1894, 1895, 2173], "publish": [8, 10, 43, 48, 1387], "ground": [8, 10, 38, 1515, 1669, 1695, 1718, 2176, 2192], "becom": [8, 9, 10, 14, 25, 30, 34, 38, 39, 58, 69, 290, 771, 906, 1268, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1531, 1550, 1565, 1585, 1596, 1609, 1669, 1686, 1760, 1838, 1863, 1965, 2018, 2103, 2106, 2117, 2127, 2132, 2133, 2150, 2154, 2158, 2159, 2166, 2204, 2205, 2207], "refactor": [8, 69, 2148, 2161], "coordin": [8, 30, 32, 39, 41, 583, 586, 914, 1268, 1277, 1416, 1886, 1979, 2022, 2024, 2031, 2127, 2171, 2176, 2195, 2205, 2209], "pace": 8, "branch": [8, 14, 56, 58, 69, 71, 74, 76, 79, 80, 1019, 2002, 2091, 2095, 2096, 2130, 2191, 2192, 2201], "definit": [8, 9, 25, 30, 31, 39, 47, 56, 57, 69, 993, 994, 995, 1027, 1086, 1192, 1238, 1241, 1335, 1344, 1345, 1387, 1414, 1466, 1545, 1624, 1698, 1745, 1827, 1912, 2018, 2091, 2093, 2095, 2097, 2126, 2127, 2133, 2138, 2158, 2161, 2176, 2178], "fundament": [8, 65, 2095, 2142, 2166, 2171, 2194, 2204], "cut": [8, 36, 2117, 2184, 2195], "guidanc": [8, 10, 17, 62, 486, 1240, 2191, 2204], "stage": [8, 20, 26, 32, 35, 37, 48, 60, 68, 2092, 2103, 2117, 2159, 2168, 2205], "piec": [8, 13, 37, 2102, 2167, 2173, 2192, 2195, 2207], "advic": [8, 2195], "readi": [8, 16, 30, 36, 37, 68, 891, 892, 971, 980, 1272, 1273, 1770, 2093, 2132, 2137, 2166, 2167, 2189], "draft": 8, "convert": [8, 13, 25, 30, 32, 37, 38, 39, 40, 57, 58, 60, 64, 67, 69, 580, 584, 585, 586, 587, 588, 746, 800, 802, 803, 805, 806, 807, 830, 831, 832, 866, 868, 884, 887, 888, 889, 909, 910, 968, 988, 1001, 1128, 1164, 1195, 1314, 1384, 1580, 1590, 1591, 1620, 1627, 1760, 1773, 1774, 1779, 1780, 1833, 1834, 1860, 1877, 1894, 1895, 1900, 1976, 1977, 1978, 1979, 1980, 1981, 2031, 2093, 2094, 2095, 2096, 2104, 2117, 2118, 2133, 2139, 2149, 2150, 2154, 2161, 2164, 2171, 2176, 2178, 2182, 2183, 2195, 2203, 2205], "press": [8, 69], "button": [8, 2201], "prepend": [8, 16, 25, 30, 35, 69, 229, 1136, 1314, 1409, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1877, 2014, 2094, 2128], "titl": [8, 2155, 2161], "wip": 8, "progress": [8, 35, 41, 52, 55, 486, 1039, 1427, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 2039, 2050, 2091, 2107], "ci": [8, 11, 2201], "folk": 8, "who": [8, 9, 10, 13, 51, 71, 1838, 2158], "regularli": [8, 2204], "queue": [8, 41, 54, 88, 2114, 2176], "everyth": [8, 25, 39, 57, 64, 71, 2093, 2114, 2158, 2191, 2195, 2198, 2205], "happen": [8, 10, 30, 32, 34, 35, 37, 38, 39, 41, 44, 51, 56, 60, 65, 69, 607, 804, 829, 935, 936, 1202, 1251, 1620, 1770, 1787, 1862, 1869, 1870, 1876, 1994, 2092, 2105, 2109, 2114, 2127, 2130, 2132, 2133, 2134, 2135, 2136, 2143, 2144, 2148, 2154, 2161, 2166, 2173, 2175, 2189, 2192, 2195, 2204, 2209], "patch": [8, 34, 37, 62, 1526, 1632, 2034, 2196], "feel": [8, 2154, 2171, 2195], "ll": [8, 21, 65, 69, 771, 839, 840, 891, 892, 993, 994, 995, 1089, 1228, 1236, 1344, 1531, 1532, 1550, 1551, 2100, 2103, 2127, 2130, 2133, 2134, 2144, 2154, 2161, 2167, 2190, 2194, 2198, 2202, 2204], "round": [8, 25, 30, 71, 73, 80, 508, 666, 667, 814, 817, 839, 895, 1023, 1025, 1101, 1139, 1165, 1166, 1167, 1171, 1175, 1176, 1177, 1192, 1360, 1373, 1633, 1697, 1892, 1893, 1912, 1960, 2078, 2094, 2096, 2115, 2130, 2155, 2161, 2164, 2171, 2172, 2199, 2207], "trip": [8, 69, 1165, 1166, 1167, 1171, 1175, 1176, 1177], "noth": [8, 16, 38, 41, 69, 681, 1034, 1080, 1793, 1875, 2067, 2093, 2095, 2130, 2146, 2168, 2184], "accompani": 8, "solut": [8, 9, 21, 37, 65, 995, 1221, 1359, 1360, 1364, 1372, 1375, 1377, 1381, 1492, 1770, 1974, 2020, 2093, 2094, 2124, 2126, 2135, 2144, 2161, 2204], "think": [8, 10, 13, 69, 71, 486, 1860, 2093, 2095, 2127, 2130, 2157, 2158, 2168, 2192, 2194, 2196], "confid": [8, 1779, 1780, 2136, 2141, 2176, 2196], "ahead": [8, 56, 2063, 2092, 2161, 2183, 2191, 2195], "search": [8, 13, 26, 837, 986, 1537, 1691, 1770, 1834, 1899, 1928, 2093, 2115, 2116, 2158, 2171, 2190, 2194, 2201, 2207], "repo": [8, 36, 71, 1865, 2091, 2133, 2148, 2180], "unabl": [8, 56, 65, 2154, 2157], "reproduc": [8, 25, 65, 313, 321, 515, 517, 973, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1576, 1577, 1578, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1678, 1686, 1697, 1725, 1738, 1757, 1758, 1759, 1760, 2033, 2091, 2125, 2157, 2158, 2186, 2195, 2205], "problemat": [8, 25, 56, 69, 956, 2093, 2145, 2162, 2192, 2195, 2204], "insight": [8, 20, 2185, 2204, 2207], "individu": [8, 10, 16, 25, 26, 30, 32, 35, 60, 69, 242, 681, 805, 866, 868, 993, 1111, 1162, 1180, 1222, 1314, 1499, 1580, 1620, 1770, 1776, 1785, 1877, 2080, 2081, 2096, 2115, 2117, 2122, 2126, 2127, 2130, 2133, 2136, 2140, 2145, 2146, 2154, 2157, 2164, 2166, 2178, 2189, 2197, 2201, 2204, 2207], "intent": [8, 32, 49, 51, 60, 65, 1838, 1933, 2103, 2158, 2161, 2200], "lock": [8, 25, 30, 35, 39, 2127, 2130, 2141, 2144, 2158, 2167, 2207], "strike": 8, "convers": [8, 32, 458, 580, 583, 806, 987, 1299, 1779, 1780, 1813, 2097, 2133, 2139, 2141, 2154, 2161, 2162, 2171, 2191, 2194, 2203], "medium": [8, 60, 1936], "prioriti": [8, 10, 12, 30, 88, 681, 884, 1644, 2095, 2147, 2209], "entranc": [8, 2130], "great": [8, 14, 56, 2127, 2138, 2189, 2191, 2192], "deal": [8, 9, 25, 41, 54, 56, 58, 2013, 2114, 2117, 2135, 2166, 2191, 2194, 2198, 2202], "welcom": [8, 2117, 2149, 2157, 2171], "aim": [8, 56, 58, 2100, 2134, 2171, 2183, 2204], "rare": [8, 954, 2126, 2154, 2191, 2196, 2206], "typo": [8, 2204], "send": [8, 25, 30, 36, 41, 54, 1082, 1760, 1770, 2114, 2132, 2144, 2148, 2155, 2159, 2166, 2167, 2168, 2180, 2182, 2194, 2197], "forum": [8, 10, 2135, 2144], "resolv": [8, 9, 10, 32, 39, 51, 69, 1228, 1314, 1510, 1511, 1512, 1526, 1577, 1580, 1877, 2095, 2096, 2097, 2148, 2150, 2158, 2173, 2191, 2206], "challeng": [8, 30, 32, 2167, 2189, 2195, 2204], "feedback": [8, 20, 26, 37, 60, 61, 1770, 2092, 2171], "direct": [8, 10, 13, 19, 30, 36, 57, 771, 805, 1014, 1185, 1186, 1238, 1314, 1531, 1550, 1580, 1596, 1789, 1824, 1858, 1877, 1882, 1899, 1920, 2100, 2127, 2130, 2133, 2136, 2142, 2166, 2192, 2203, 2204], "solv": [8, 13, 56, 1221, 1258, 1268, 1346, 1355, 1357, 1358, 1361, 1362, 1364, 1368, 1376, 1377, 1381, 1387, 1405, 1974, 2020, 2127, 2138, 2145, 2148, 2171, 2183, 2192, 2195], "yourself": [8, 63, 1037, 2034, 2117, 2133, 2142, 2144, 2195, 2204, 2206], "problem": [8, 25, 30, 51, 56, 65, 71, 1144, 1224, 1228, 1330, 1360, 1372, 1387, 1515, 1587, 1651, 1877, 1932, 2114, 2117, 2127, 2130, 2135, 2138, 2144, 2148, 2161, 2162, 2168, 2174, 2183, 2191, 2192, 2195, 2204, 2205], "area": [8, 10, 57, 1697, 2117, 2142, 2161, 2172], "appreci": 8, "strive": 8, "respond": [8, 30], "quickli": [8, 9, 26, 51, 2117, 2136, 2197], "ey": [8, 39, 191, 208, 994, 995, 1213, 1335, 1344, 1355, 1366, 1369, 1372, 1373, 1380, 1381, 1787, 1892, 1971, 2045, 2094, 2098, 2133, 2155, 2192], "everyon": [8, 41, 51], "touch": [8, 49, 69], "versu": [8, 1227, 1584], "write": [8, 9, 10, 14, 18, 20, 21, 25, 30, 32, 36, 37, 41, 44, 48, 49, 50, 56, 60, 65, 66, 254, 486, 513, 708, 984, 1004, 1197, 1202, 1213, 1230, 1291, 1325, 1345, 1356, 1357, 1358, 1362, 1363, 1376, 1756, 1924, 2020, 2033, 2045, 2095, 2100, 2109, 2116, 2130, 2133, 2134, 2135, 2138, 2147, 2157, 2158, 2161, 2171, 2176, 2183, 2186, 2189, 2191, 2192, 2195, 2197, 2198, 2204, 2205, 2209], "blog": [8, 9, 14, 1019, 2100, 2122, 2132, 2133, 2161, 2171], "around": [8, 10, 13, 19, 30, 34, 39, 53, 56, 64, 65, 68, 69, 150, 625, 923, 944, 1028, 1037, 1039, 1040, 1044, 1190, 1191, 1202, 1314, 1427, 1444, 1770, 1921, 2050, 2051, 2093, 2100, 2114, 2117, 2127, 2130, 2151, 2154, 2161, 2166, 2189, 2192, 2195], "internet": 8, "grow": [8, 9, 69, 2117, 2130, 2171], "market": [8, 10], "benefit": [8, 9, 30, 69, 877, 1779, 1780, 1874, 2114, 2117, 2130, 2136, 2161, 2171, 2189, 2204, 2205], "opinion": [8, 9, 1838, 2171], "isn": [8, 21, 25, 69, 458, 1311, 2127, 2130, 2133, 2166, 2173, 2178, 2194, 2204], "categor": [8, 44, 1688, 2097, 2162, 2166, 2176, 2203], "aspect": [8, 30, 36, 69, 1597, 2117, 2133, 2142, 2204], "seem": [8, 1228, 2154], "unusu": [8, 2173, 2194], "claim": [8, 1779, 1780, 1872, 2138], "wast": [8, 2130], "someon": [8, 10, 1312, 2116], "end": [8, 9, 10, 21, 25, 26, 30, 36, 39, 44, 48, 63, 69, 86, 361, 362, 538, 771, 795, 811, 839, 840, 895, 958, 966, 971, 1022, 1037, 1057, 1105, 1106, 1134, 1144, 1183, 1198, 1253, 1268, 1274, 1275, 1311, 1314, 1335, 1340, 1370, 1380, 1382, 1385, 1387, 1401, 1443, 1475, 1476, 1491, 1492, 1493, 1501, 1502, 1503, 1513, 1515, 1521, 1525, 1531, 1532, 1535, 1536, 1537, 1538, 1539, 1540, 1546, 1550, 1551, 1566, 1571, 1574, 1575, 1580, 1582, 1587, 1588, 1591, 1596, 1599, 1609, 1612, 1618, 1623, 1630, 1669, 1678, 1690, 1691, 1770, 1787, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1863, 1869, 1874, 1877, 1908, 1940, 1943, 1946, 1948, 1961, 2018, 2029, 2030, 2048, 2093, 2094, 2095, 2096, 2114, 2117, 2126, 2127, 2130, 2132, 2133, 2135, 2136, 2137, 2138, 2141, 2145, 2148, 2154, 2157, 2159, 2161, 2164, 2166, 2172, 2189, 2192, 2194, 2197, 2199, 2204, 2205, 2209], "too": [8, 10, 16, 26, 32, 51, 65, 69, 486, 1101, 1201, 1228, 1232, 1360, 1378, 1472, 1499, 1515, 1670, 1772, 1822, 1838, 2078, 2096, 2117, 2129, 2135, 2138, 2144, 2145, 2146, 2148, 2150, 2158, 2168, 2171, 2191, 2192, 2194, 2204, 2205, 2207], "advisori": 8, "fashion": [8, 25, 30, 36, 38, 54, 56, 515, 1392, 1804, 2093, 2204], "rough": [8, 10, 2117], "consensu": [8, 10], "corpor": [8, 2186, 2205], "wrote": [8, 9, 2186], "implicitli": [8, 30, 44, 69, 1127, 1227, 1258, 1268, 1330, 1331, 1386, 1489, 1490, 1491, 1573, 1574, 1575, 1933, 2018, 2093, 2095, 2096, 2127, 2133, 2139, 2141], "lifetim": [8, 486, 2100, 2166, 2194], "immedi": [8, 9, 10, 21, 30, 32, 34, 51, 52, 60, 68, 486, 1238, 1314, 1317, 1580, 1779, 1780, 1877, 2096, 2117, 2130, 2136, 2142, 2147, 2157, 2166, 2168, 2191, 2194, 2204], "sai": [8, 56, 57, 58, 69, 496, 958, 1205, 1206, 1207, 1217, 1227, 1234, 1314, 1580, 1877, 2093, 2126, 2127, 2135, 2157, 2158, 2167, 2168, 2171, 2189, 2191, 2192, 2198, 2203], "bugfix": 8, "Or": [8, 21, 41, 69, 910, 997, 2139, 2143, 2150, 2154, 2171, 2204], "motiv": [8, 9, 56, 69, 746, 2136, 2142, 2167, 2204, 2205], "ye": [8, 2105, 2154, 2157, 2171, 2195], "knuth": 8, "bewar": 8, "mere": [8, 36, 57], "proven": [8, 1517, 1770], "ok": [8, 44, 49, 64, 1232, 1241, 1319, 2168, 2174, 2192], "sometim": [8, 58, 69, 941, 1101, 1218, 1320, 1330, 1526, 1632, 1664, 1665, 1666, 1793, 2092, 2096, 2100, 2114, 2127, 2130, 2134, 2135, 2136, 2142, 2144, 2158, 2174, 2177, 2191, 2192, 2194, 2198, 2202, 2206], "obvious": [8, 2194], "broken": [8, 25, 1101, 2078, 2130, 2154, 2158, 2204], "contrari": [8, 36, 1838, 2129, 2180], "accident": 8, "put": [8, 10, 25, 30, 37, 41, 64, 68, 69, 319, 1164, 1386, 1534, 1865, 2091, 2094, 2114, 2130, 2136, 2144, 2155, 2158, 2167, 2168, 2192, 2194, 2196], "difficulti": [8, 30, 2124], "nonlinearli": 8, "sign": [8, 39, 341, 529, 914, 1022, 1132, 1180, 1192, 1198, 1348, 1373, 1374, 1395, 1572, 1858, 1912, 1943, 1957, 2094, 2115, 2155, 2164, 2171, 2174, 2177, 2178, 2192, 2199], "split": [8, 13, 25, 30, 69, 617, 783, 784, 785, 889, 891, 892, 989, 996, 1101, 1142, 1278, 1516, 1530, 1531, 1550, 1586, 1596, 1661, 1662, 1663, 1664, 1665, 1666, 1685, 2012, 2046, 2093, 2094, 2115, 2117, 2122, 2130, 2136, 2155, 2158, 2161, 2166, 2171, 2175, 2189, 2192, 2202, 2207], "shippabl": 8, "complet": [8, 16, 21, 25, 30, 32, 41, 43, 49, 51, 54, 65, 68, 86, 88, 486, 681, 693, 891, 1035, 1039, 1040, 1057, 1120, 1201, 1202, 1317, 1326, 1328, 1333, 1345, 1373, 1427, 1433, 1434, 1440, 1443, 1464, 1651, 1770, 1790, 1822, 1892, 1936, 2050, 2088, 2092, 2095, 2096, 2097, 2102, 2114, 2126, 2127, 2130, 2134, 2139, 2141, 2146, 2158, 2166, 2167, 2188, 2196, 2201, 2202], "subtl": [8, 1542, 1543, 1544, 2133, 2194, 2195, 2205], "nuanc": [8, 2149], "extra": [8, 16, 25, 26, 30, 34, 35, 37, 39, 42, 56, 60, 69, 1105, 1144, 1202, 1213, 1227, 1314, 1322, 1325, 1360, 1386, 1580, 1587, 1595, 1769, 1787, 1877, 1990, 2045, 2095, 2116, 2127, 2129, 2130, 2132, 2133, 2135, 2140, 2150, 2158, 2159, 2171, 2177, 2178, 2180, 2194, 2198, 2204, 2209], "understand": [8, 9, 10, 30, 32, 37, 41, 43, 56, 58, 60, 71, 1202, 1236, 1372, 2124, 2127, 2130, 2139, 2147, 2159, 2160, 2176, 2183, 2190, 2191, 2192, 2193, 2194, 2195, 2197, 2204, 2205], "hack": 8, "answer": [8, 12, 69, 843, 1238, 1493, 1805, 2194, 2195], "regress": [8, 1492, 2145, 2146, 2189, 2200, 2204], "scrutini": 8, "undertak": 8, "rest": [8, 25, 26, 52, 56, 58, 60, 69, 806, 829, 1009, 1010, 1198, 1380, 1381, 2012, 2116, 2142, 2146, 2158, 2161, 2166, 2171, 2173, 2192, 2195, 2196, 2198, 2202], "stai": [8, 35, 139, 1516, 1779, 1780, 2130, 2144, 2161, 2166, 2171], "chanc": [8, 32, 39, 2133, 2194, 2195, 2198], "unrel": [8, 34, 1013, 1211, 2126, 2133, 2158], "aid": [8, 69, 2127, 2205], "troubleshoot": [8, 30, 2183, 2195], "mayb": [8, 1209, 2036, 2194, 2204], "rebas": 8, "latest": [8, 16, 30, 35, 39, 56, 58, 927, 958, 1800, 2091, 2133, 2139, 2154, 2204], "statu": [8, 10, 41, 86, 1404, 1443, 2092, 2097, 2114, 2157, 2161, 2185], "hud": 8, "risk": [8, 9, 32, 56, 58, 60, 1014, 1790, 1793, 2173], "anyth": [8, 40, 44, 56, 60, 68, 842, 851, 1238, 1326, 1860, 2093, 2108, 2117, 2136, 2142, 2147, 2158, 2191, 2192, 2208, 2209], "configur": [8, 15, 19, 22, 25, 26, 30, 34, 36, 38, 41, 43, 48, 51, 52, 54, 60, 800, 802, 805, 806, 811, 829, 830, 831, 832, 842, 851, 866, 868, 869, 873, 875, 878, 888, 889, 890, 891, 892, 1002, 1041, 1101, 1770, 1813, 1937, 2033, 2102, 2109, 2130, 2132, 2133, 2146, 2148, 2158, 2164, 2166, 2176, 2178, 2184, 2186, 2191, 2195, 2201, 2202, 2204, 2205], "riski": 8, "had": [8, 69, 958, 1228, 1251, 1330, 1760, 2014, 2127, 2130, 2134, 2191, 2192, 2200, 2204], "beforehand": [8, 68, 2195], "hei": 8, "my": [8, 25, 1516, 2140, 2154, 2161], "member": [8, 10, 25, 30, 41, 51, 52, 69, 1314, 1533, 1580, 1683, 1877, 2093, 2095, 2096, 2109, 2135, 2159, 2166, 2178, 2180], "sphinx": 8, "folder": [8, 10, 16, 25, 32, 49, 69, 1834, 2091, 2176, 2192, 2197, 2205], "doxygen": 8, "special": [8, 13, 34, 36, 44, 54, 57, 58, 65, 69, 71, 76, 79, 80, 752, 753, 754, 842, 851, 949, 1002, 1137, 1151, 1152, 1153, 1155, 1156, 1165, 1167, 1221, 1227, 1282, 1283, 1284, 1328, 1386, 1400, 1469, 1516, 1628, 1771, 1772, 1773, 1774, 1826, 1860, 1887, 1944, 1955, 1959, 2005, 2049, 2097, 2102, 2116, 2117, 2130, 2133, 2136, 2138, 2140, 2158, 2160, 2161, 2175, 2176, 2185, 2191, 2193, 2194, 2200], "server": [8, 25, 30, 52, 1318, 2130, 2158, 2161, 2166, 2185, 2188], "cppdoc": [8, 17], "accomplish": [8, 32, 2117, 2142, 2195], "holist": 8, "concept": [8, 56, 57, 58, 65, 69, 2100, 2133, 2134, 2142, 2174, 2180, 2196], "galleri": 8, "restructur": [8, 2158], "text": [8, 25, 39, 57, 153, 154, 173, 608, 617, 682, 694, 695, 696, 697, 698, 699, 700, 701, 702, 705, 709, 756, 757, 767, 769, 771, 775, 779, 780, 781, 783, 784, 785, 791, 795, 839, 840, 895, 911, 912, 913, 914, 915, 970, 971, 972, 975, 978, 980, 982, 991, 994, 995, 997, 1021, 1022, 1024, 1025, 1027, 1139, 1158, 1159, 1188, 1189, 1193, 1194, 1257, 1271, 1272, 1273, 1274, 1281, 1303, 1311, 1335, 1338, 1339, 1340, 1343, 1344, 1351, 1354, 1360, 1364, 1369, 1372, 1378, 1385, 1394, 1401, 1402, 1403, 1404, 1465, 1466, 1477, 1478, 1481, 1482, 1483, 1485, 1486, 1487, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1518, 1519, 1520, 1521, 1522, 1524, 1525, 1526, 1527, 1528, 1529, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1565, 1566, 1567, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1583, 1584, 1585, 1586, 1587, 1588, 1592, 1593, 1594, 1595, 1596, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1610, 1611, 1612, 1613, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1653, 1654, 1655, 1657, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1669, 1672, 1673, 1674, 1679, 1682, 1684, 1685, 1686, 1690, 1691, 1701, 1706, 1711, 1712, 1713, 1717, 1722, 1725, 1730, 1731, 1733, 1738, 1739, 1740, 1741, 1744, 1745, 1746, 1748, 1749, 1750, 1769, 1777, 1787, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1865, 1882, 1885, 1886, 1889, 1892, 1905, 1908, 1911, 1923, 1943, 1945, 1946, 1958, 1960, 1971, 1972, 1983, 1990, 1991, 1994, 1995, 2009, 2010, 2048, 2117, 2122, 2124, 2138, 2158, 2164, 2172, 2176, 2178, 2192, 2197, 2204], "rst": 8, "trigger": [8, 10, 30, 37, 51, 52, 68, 221, 958, 1119, 1940, 2126, 2127, 2130, 2132, 2133, 2140, 2147, 2166, 2189, 2192, 2193, 2195, 2200, 2201, 2204, 2205, 2209], "rebuild": [8, 26], "entir": [8, 16, 25, 30, 32, 36, 38, 41, 52, 69, 513, 708, 949, 950, 1002, 1202, 1268, 1518, 1519, 1520, 1524, 1542, 1543, 1544, 1552, 1672, 1673, 1674, 1679, 1770, 1789, 1799, 1801, 1824, 2096, 2100, 2127, 2130, 2133, 2134, 2135, 2140, 2142, 2154, 2158, 2161, 2166, 2168, 2171, 2190, 2191, 2193, 2194, 2195, 2202, 2205, 2207], "circleci": 8, "shard": [8, 25, 32, 34, 35, 36, 37, 38, 60, 1770, 2136, 2195], "worker": [8, 16, 25, 26, 30, 31, 34, 35, 36, 41, 43, 44, 45, 51, 54, 55, 60, 1770, 2096, 2146, 2159, 2166, 2167, 2168], "40": [8, 1268, 1387, 1497, 1542, 1787, 1788, 1789, 1811, 1812, 1821, 1824, 2008, 2193], "minut": [8, 12, 30, 2176, 2204], "netlifi": 8, "noplot": 8, "render": [8, 30, 1232, 2176, 2207], "notebook": 8, "rebuilt": [8, 26, 35], "deploi": [8, 14, 41, 51, 2140, 2147, 2158, 2185, 2188, 2192], "action": [8, 30, 37, 39, 41, 45, 69, 1037, 1078, 2130, 2147, 2150, 2158, 2159, 2168, 2204, 2207], "document": [9, 10, 12, 19, 25, 30, 57, 58, 60, 61, 69, 681, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 903, 904, 905, 906, 987, 1039, 1040, 1101, 1144, 1258, 1262, 1264, 1295, 1302, 1314, 1433, 1434, 1473, 1484, 1522, 1523, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1580, 1765, 1766, 1790, 1799, 1807, 1827, 1877, 1891, 1918, 1935, 2033, 2091, 2093, 2095, 2096, 2105, 2106, 2110, 2114, 2115, 2116, 2117, 2118, 2126, 2130, 2133, 2135, 2142, 2146, 2147, 2150, 2154, 2157, 2158, 2161, 2162, 2163, 2166, 2171, 2175, 2180, 2183, 2190, 2196, 2200, 2203, 2204, 2205, 2208], "develop": [9, 10, 12, 16, 26, 30, 34, 36, 37, 69, 2095, 2096, 2103, 2110, 2111, 2117, 2127, 2133, 2140, 2142, 2146, 2154, 2158, 2161, 2162, 2166, 2171, 2192, 2197, 2199, 2204, 2205, 2208], "meant": [9, 31, 32, 37, 51, 54, 60, 1813, 1878, 2126, 2166], "rule": [9, 10, 16, 30, 39, 69, 71, 79, 80, 150, 890, 923, 986, 987, 1127, 1364, 1375, 1494, 1495, 1496, 1542, 1543, 1544, 1620, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1928, 2018, 2093, 2095, 2100, 2115, 2127, 2128, 2133, 2136, 2138, 2174, 2178, 2194, 2195], "concern": [9, 25, 60, 2114, 2122, 2130, 2154, 2202], "disagr": 9, "contribut": [9, 10, 11, 32, 962, 1276, 1277, 1515, 1522, 1523, 1587, 1669, 1677, 1678, 1722, 1770, 2133, 2134, 2154], "maintainership": [9, 10], "escal": [9, 10], "hacker": 9, "poster": 9, "amaz": 9, "ml": [9, 2159, 2204], "obsess": 9, "soumith": [9, 12], "goe": [9, 69, 1198, 1488, 2100, 2135, 2192, 2195, 2196], "depth": [9, 10, 22, 27, 36, 56, 88, 790, 796, 1106, 1107, 1328, 1491, 1509, 1512, 1549, 1575, 1586, 1624, 1625, 1626, 1627, 1628, 1633, 1697, 1757, 2103, 2132, 2142, 2159, 2193, 2204, 2207], "primari": [9, 10, 30, 69, 1324, 2097, 2103, 2104, 2171, 2194, 2205], "goal": [9, 48, 64, 69, 1416, 2103, 2127, 2132, 2138, 2168, 2197], "secondari": 9, "abil": [9, 14, 56, 1924, 2103, 2140, 2150, 2158, 2192, 2204], "flexibl": [9, 14, 26, 36, 37, 56, 60, 64, 1233, 1371, 2103, 2130, 2133, 2142, 2161, 2192], "abstract": [9, 18, 25, 26, 30, 31, 32, 37, 39, 41, 49, 51, 54, 951, 952, 953, 954, 955, 958, 1234, 1795, 2096, 2100, 2104, 2132, 2141, 2161, 2166, 2189], "critic": [9, 30, 34, 37, 51, 681, 1788, 1821, 2109, 2129, 2130, 2195, 2196], "futur": [9, 10, 14, 26, 30, 32, 37, 41, 51, 52, 56, 58, 65, 69, 86, 88, 290, 321, 486, 513, 517, 557, 681, 698, 806, 830, 831, 832, 851, 891, 930, 933, 935, 936, 992, 993, 1002, 1019, 1020, 1021, 1036, 1037, 1039, 1040, 1078, 1079, 1086, 1087, 1089, 1259, 1311, 1314, 1317, 1324, 1325, 1328, 1333, 1345, 1356, 1358, 1359, 1360, 1363, 1376, 1404, 1405, 1416, 1427, 1443, 1519, 1580, 1688, 1711, 1712, 1713, 1761, 1770, 1776, 1821, 1822, 1827, 1843, 1877, 1892, 1908, 1990, 1994, 2020, 2050, 2093, 2094, 2095, 2096, 2097, 2102, 2103, 2109, 2116, 2117, 2122, 2129, 2130, 2133, 2147, 2154, 2157, 2158, 2159, 2160, 2161, 2163, 2166, 2171, 2173, 2177, 2178, 2180, 2182, 2191, 2195, 2199, 2204, 2207], "concret": [9, 13, 32, 39, 55, 57, 58, 64, 69, 486, 796, 815, 843, 871, 1002, 1226, 1228, 1247, 1248, 1249, 1633, 1725, 1757, 2093, 2096, 2100, 2130, 2133, 2144, 2150, 2191, 2192, 2194], "manner": [9, 30, 36, 41, 87, 513, 938, 940, 2116, 2118, 2124, 2128, 2141, 2157, 2204], "jump": [9, 560, 2174, 2204], "regim": 9, "ei": 9, "tradeoff": [9, 26, 56, 486, 2161, 2167, 2195, 2200], "temptat": 9, "impos": [9, 54, 66, 1932, 2114, 2126, 2174], "strict": [9, 32, 57, 938, 939, 940, 941, 942, 943, 1201, 1208, 1232, 1314, 1330, 1331, 1580, 1822, 1877, 2100, 2158, 2176, 2178, 2185], "upfront": [9, 2191, 2204], "simplifi": [9, 26, 34, 68, 1221, 1228, 1253, 1322, 1570, 1788, 1860, 2103, 2127, 2133, 2138, 2142, 2157, 2161, 2167, 2191, 2204], "worth": [9, 10, 25, 26, 55, 57, 1202, 2091, 2173, 2175, 2198, 2204], "friction": 9, "compel": 9, "narrow": [9, 1238, 1384, 1476, 1860, 1950, 2094, 2096, 2115, 2117, 2155, 2163, 2175, 2205], "subproblem": 9, "fragment": [9, 1066, 1101, 2058, 2100, 2130, 2205], "ecosystem": [9, 2140, 2143, 2180, 2192], "incomprehens": 9, "seamlessli": [9, 2204], "softwar": [9, 21, 1350, 1351, 1378, 2033, 2130, 2139, 2183, 2192], "experi": [9, 10, 13, 26, 34, 56, 66, 1213, 1610, 1741, 1770, 2045, 2103, 2133, 2137, 2176, 2193], "rich": [9, 36, 2096], "denomin": [9, 698, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1595, 1620, 1769, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1896], "subset": [9, 25, 30, 35, 37, 52, 57, 1326, 1860, 2093, 2095, 2096, 2117, 2133, 2149, 2154, 2164, 2199], "borrow": 9, "zen": 9, "implicit": [9, 56, 57, 779, 780, 783, 784, 785, 1258, 1268, 1489, 1490, 1491, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1573, 1574, 1575, 1632, 1653, 1654, 1655, 1661, 1662, 1663, 1711, 1712, 1713, 1880, 2094, 2096, 2097, 2136, 2154, 2158, 2175, 2199], "concis": [9, 44, 2166], "interchang": [9, 39, 1857, 2017, 2095, 2139, 2183, 2196], "everydai": 9, "english": 9, "movement": [9, 2175, 2195], "worri": [9, 30, 37, 2166], "placement": [9, 34, 38, 41, 889, 1760, 2122, 2130, 2161, 2166, 2195], "favor": [9, 30, 796, 797, 798, 993, 1114, 1118, 1314, 1369, 1372, 1404, 1405, 1462, 1538, 1580, 1634, 1635, 1757, 1758, 1759, 1761, 1775, 1877, 1892, 1994, 2020, 2087], "practition": 9, "debugg": [9, 30, 1319, 2138, 2195, 2205], "plug": 9, "ir": [9, 56, 58, 69, 771, 1317, 1318, 1531, 1532, 1834, 2093, 2096, 2150, 2154, 2183, 2185, 2191, 2192, 2194, 2195, 2205], "classic": [9, 2127], "sort": [9, 35, 69, 590, 609, 906, 907, 930, 932, 935, 1144, 1238, 1275, 1441, 1484, 1814, 1815, 1826, 1893, 1928, 2015, 2029, 2094, 2096, 2133, 2135, 2155, 2171, 2191, 2195, 2199], "distribut": [9, 13, 21, 25, 26, 31, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 55, 60, 68, 173, 258, 286, 377, 454, 481, 608, 681, 706, 707, 837, 965, 972, 1119, 1466, 1484, 1488, 1493, 1515, 1516, 1517, 1518, 1519, 1520, 1524, 1529, 1533, 1545, 1594, 1599, 1620, 1669, 1671, 1672, 1673, 1674, 1679, 1683, 1684, 1688, 1698, 1730, 1770, 1828, 1885, 1899, 1901, 1902, 1903, 1904, 1905, 1906, 2092, 2096, 2116, 2124, 2125, 2126, 2130, 2159, 2160, 2162, 2168, 2172, 2176, 2180, 2184, 2189, 2204], "tldr": 9, "resourc": [9, 16, 25, 30, 41, 47, 51, 56, 69, 2096, 2114, 2130, 2144, 2150, 2171, 2195, 2201, 2202, 2205, 2208, 2209], "characterist": [9, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1995, 2134, 2142, 2204], "uniformli": [9, 39, 1903, 1904, 2178], "leak": [9, 923, 930, 933, 935, 2096, 2114, 2127], "smart": [9, 2133, 2158, 2166], "anywai": [9, 34, 2127, 2136], "obviou": [9, 1221, 2135, 2168, 2194, 2204], "extens": [9, 16, 20, 30, 32, 39, 56, 1015, 1386, 1387, 1924, 1943, 2103, 2105, 2126, 2133, 2141, 2147, 2158, 2171, 2194, 2195, 2204, 2205], "unavoid": 9, "latenc": [9, 32, 48, 2104, 2129, 2130, 2195, 2201], "caveat": [9, 1760, 1820, 2103, 2114, 2130, 2142, 2147, 2190, 2200, 2205], "valuabl": 9, "certainli": [9, 2103], "heterogen": [9, 2095, 2117], "cluster": [9, 30, 32, 36, 37, 50, 52, 60, 1484, 2176, 2209], "focus": [9, 2095, 2096, 2133, 2205], "beaten": 9, "space": [9, 10, 25, 39, 783, 784, 785, 1127, 1162, 1164, 1166, 1167, 1173, 1180, 1268, 1277, 1330, 1331, 1385, 1401, 1484, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1545, 1556, 1557, 1558, 1559, 1560, 1561, 1574, 1575, 1632, 1661, 1662, 1663, 1664, 1665, 1666, 1698, 2018, 2094, 2104, 2118, 2127, 2138, 2142, 2147, 2173, 2207], "innov": 9, "growth": 9, "ultim": [9, 10, 16, 44, 54, 56, 2183], "evidenc": 9, "began": 9, "bind": [9, 16, 30, 69, 1080, 1226, 1228, 1237, 1251, 1252, 2096, 2097, 2100, 2133, 2158, 2192], "monolith": 9, "deepli": 9, "integr": [9, 25, 37, 45, 57, 64, 154, 972, 974, 975, 976, 977, 978, 979, 1027, 1127, 1276, 1314, 1338, 1382, 1383, 1475, 1580, 1877, 1899, 1911, 2018, 2117, 2133, 2140, 2142, 2152, 2157, 2161, 2172, 2174, 2178, 2190], "numpi": [9, 25, 58, 65, 448, 493, 704, 705, 710, 907, 909, 910, 930, 931, 935, 986, 1139, 1141, 1142, 1144, 1162, 1183, 1184, 1185, 1186, 1190, 1191, 1196, 1197, 1213, 1278, 1345, 1346, 1356, 1367, 1369, 1370, 1371, 1372, 1373, 1378, 1379, 1382, 1384, 1414, 1416, 1421, 1886, 1911, 1914, 1921, 1933, 1940, 1976, 1977, 1978, 1979, 1980, 1981, 1994, 1996, 1997, 2008, 2011, 2012, 2014, 2042, 2045, 2046, 2100, 2103, 2128, 2133, 2134, 2145, 2146, 2147, 2148, 2158, 2174, 2175, 2176, 2177, 2178, 2192, 2210], "scipi": [9, 990, 1361, 1362, 1727, 1886, 1948, 2158, 2169, 2172, 2176], "scikit": [9, 1697], "favorit": 9, "cython": 9, "numba": 9, "reinvent": 9, "wheel": [9, 2137, 2148], "year": [9, 2171], "rewrot": 9, "frontend": [9, 17, 34, 36, 57, 64, 69, 1004, 2195], "familiar": [9, 17, 57, 69, 1037, 1041, 1078, 1100, 2093, 2127, 2134, 2158, 2161, 2167, 2168, 2192, 2193, 2195, 2203, 2204], "perhap": [9, 1228, 2130, 2134, 2192, 2204], "importantli": 9, "huge": [9, 1995, 2109, 2192, 2204], "scientif": [9, 1940], "pareto": 9, "close": [9, 17, 30, 51, 69, 71, 74, 79, 1082, 1224, 1303, 1350, 1351, 1377, 1378, 1404, 1493, 1612, 1630, 1659, 1856, 1994, 2020, 2109, 2127, 2133, 2145, 2157, 2158, 2161, 2166, 2176, 2178], "curv": [9, 2176], "torchdynamo": [9, 56, 58, 71, 82, 681, 1002, 1010, 2102, 2154, 2183, 2190, 2191, 2192, 2193, 2195, 2197], "frame": [9, 56, 69, 1002, 1311, 1990, 2035, 2135, 2149, 2150, 2176, 2183, 2191, 2193, 2195, 2196, 2204, 2205, 2207], "torch_funct": [9, 2133], "torch_dispatch": [9, 2100], "torch": [9, 10, 13, 17, 20, 21, 23, 26, 27, 31, 35, 41, 42, 43, 44, 45, 48, 49, 51, 53, 54, 55, 60, 63, 71, 72, 73, 74, 75, 76, 77, 78, 86, 87, 88, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 839, 840, 841, 842, 843, 846, 851, 852, 855, 856, 857, 858, 859, 860, 861, 862, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 924, 925, 930, 935, 936, 945, 946, 947, 957, 958, 965, 966, 967, 968, 969, 1029, 1037, 1038, 1039, 1040, 1041, 1042, 1045, 1062, 1065, 1078, 1148, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1312, 1313, 1314, 1329, 1427, 1443, 1445, 1449, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1641, 1760, 1769, 1770, 1771, 1772, 1773, 1774, 1790, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1813, 1825, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1899, 1968, 2050, 2052, 2055, 2057, 2093, 2094, 2095, 2104, 2105, 2115, 2116, 2125, 2126, 2127, 2128, 2129, 2132, 2135, 2136, 2138, 2140, 2141, 2142, 2143, 2144, 2146, 2148, 2150, 2151, 2152, 2160, 2161, 2162, 2163, 2166, 2167, 2168, 2175, 2186, 2189, 2190, 2191, 2192, 2193, 2194, 2197, 2200, 2203, 2205, 2207], "fx": [9, 14, 56, 57, 681, 758, 830, 831, 832, 833, 870, 890, 1004, 1202, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 2100, 2149, 2150, 2154, 2160, 2162, 2163, 2184, 2186, 2190, 2191, 2192, 2193, 2194, 2195, 2203, 2204, 2205], "tracer": [9, 36, 56, 1330, 2154, 2176, 2182, 2192], "functorch": [9, 57, 61, 66, 71, 74, 79, 80, 83, 2190], "anchor": [9, 69, 1629, 1630, 1754, 1755, 2094, 2203], "hackabl": 9, "todai": [9, 30, 57, 61, 66, 1002, 2108, 2117, 2161, 2180, 2191], "evolv": [9, 2132, 2152], "ai": [9, 2137, 2150, 2154, 2159, 2172], "adopt": [10, 30, 731, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 1779, 1780], "hierarch": [10, 2176], "pull": [10, 12, 17, 69, 2158, 2194, 2208], "request": [10, 12, 13, 30, 32, 54, 69, 700, 891, 909, 910, 958, 1101, 1387, 1409, 1419, 1703, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 2078, 2091, 2108, 2117, 2126, 2127, 2129, 2130, 2154, 2158, 2166, 2167, 2168, 2171, 2172, 2191, 2207, 2208], "overseen": 10, "catch": [10, 44, 2093, 2127, 2134, 2138, 2192, 2196], "maker": 10, "strong": 10, "toward": [10, 71, 1139, 1276, 1277, 1387, 1480, 1770, 1869, 1912, 1920, 1921, 2136], "philosophi": [10, 11, 64], "beyond": [10, 26, 58, 1438, 1515, 1840, 1841, 1856, 1919, 2111, 2135, 2142, 2191], "encourag": [10, 41, 2161, 2171, 2178], "propos": [10, 1836, 1863, 1864, 1877, 2103, 2138, 2157, 2167], "review": [10, 12, 26, 2106, 2158, 2197], "willing": [10, 2184], "invest": 10, "anyon": 10, "ownership": [10, 69], "codebas": [10, 2133, 2204], "strictli": [10, 25, 150, 191, 208, 486, 923, 986, 1277, 1314, 1318, 1580, 1877, 2127, 2172], "compani": 10, "bui": 10, "addition": [10, 16, 25, 26, 30, 32, 37, 39, 41, 56, 58, 60, 150, 513, 617, 923, 958, 1202, 1206, 1207, 1318, 1378, 1484, 1542, 1543, 1544, 1970, 2135, 2180, 2204, 2207], "membership": [10, 41, 50, 51, 2097], "That": [10, 14, 19, 21, 41, 49, 52, 62, 69, 1015, 1019, 1311, 1385, 1401, 2033, 2100, 2106, 2133, 2134, 2135, 2136, 2147, 2158, 2166, 2192, 2195], "seat": 10, "reserv": [10, 34, 48, 1101, 2078, 2097, 2130, 2142, 2207], "emploi": [10, 32, 1859, 2142, 2158, 2185], "directori": [10, 16, 30, 32, 36, 41, 49, 1834, 2091, 2107, 2140, 2150, 2154, 2158, 2159, 2176, 2185, 2186, 2195, 2205], "procedur": [10, 39, 889, 1330, 1331, 1387, 1968, 2166, 2205], "disput": 10, "made": [10, 19, 22, 30, 32, 35, 52, 56, 69, 930, 933, 935, 950, 1042, 1314, 1580, 1626, 1628, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1848, 1850, 1856, 1857, 1858, 1859, 1860, 1877, 1909, 2095, 2103, 2127, 2130, 2148, 2158, 2176, 2178, 2189, 2191, 2192, 2204, 2205, 2206], "public": [10, 12, 37, 1202, 2117, 2133, 2204, 2206], "resolut": [10, 1592, 1593, 1651, 1686, 1728, 1729, 2018, 2097, 2158, 2210], "conclus": 10, "publicli": [10, 2206], "vision": [10, 1324, 1515, 1669, 2091, 2197], "roadmap": [10, 12], "parti": [10, 51, 2091, 2093, 2100, 2130, 2134, 2142, 2158, 2192], "triag": [10, 12], "meet": [10, 12, 14, 32, 50, 1014, 1019, 1344, 2130, 2195], "Their": [10, 1136, 2133, 2194], "articul": 10, "cohes": 10, "negoti": [10, 2166], "contenti": 10, "broad": [10, 2142, 2208], "stakehold": 10, "power": [10, 14, 34, 50, 1108, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1187, 1338, 1368, 1382, 1547, 1548, 1549, 1707, 1708, 1709, 1788, 1821, 1836, 1873, 1889, 1913, 2039, 2097, 2130, 2171], "veto": 10, "admin": 10, "amongst": 10, "commonli": [10, 39, 60, 1416, 1838, 2096, 2098, 2117, 2126, 2127, 2136, 2157, 2161, 2174, 2183, 2188, 2191], "merit": 10, "demonstr": [10, 36, 52, 56, 69, 71, 79, 80, 1499, 2093, 2142, 2147, 2150, 2151, 2157, 2166, 2173, 2193, 2195, 2197, 2202], "expertis": 10, "align": [10, 26, 56, 771, 790, 796, 839, 851, 1002, 1144, 1268, 1370, 1491, 1499, 1515, 1531, 1545, 1550, 1574, 1575, 1596, 1633, 1641, 1642, 1643, 1669, 1670, 1697, 1698, 1738, 1757, 1787, 1827, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1863, 2018, 2115, 2122, 2127, 2130, 2138, 2147, 2154, 2164, 2172], "continu": [10, 25, 30, 32, 39, 55, 58, 60, 69, 402, 608, 837, 939, 1268, 1350, 1351, 1378, 1498, 1499, 1770, 1874, 2097, 2103, 2127, 2136, 2147, 2159, 2173, 2180, 2190, 2192, 2193, 2195, 2204], "light": [10, 2176, 2204], "mainten": [10, 51, 52], "emeritu": [10, 12], "inact": [10, 1101, 2130, 2207], "contact": [10, 30], "item": [10, 25, 32, 56, 71, 81, 82, 583, 584, 585, 589, 805, 806, 807, 829, 830, 831, 832, 969, 1015, 1515, 1581, 1590, 1793, 1940, 2091, 2093, 2094, 2095, 2096, 2104, 2115, 2117, 2130, 2137, 2147, 2154, 2155, 2157, 2158, 2166, 2176, 2177, 2189, 2191, 2192, 2194, 2199, 2204], "nomine": 10, "breadth": [10, 36], "testimoni": 10, "posit": [10, 25, 32, 36, 37, 39, 56, 69, 87, 402, 471, 545, 746, 887, 891, 893, 971, 973, 980, 993, 994, 995, 1160, 1161, 1162, 1163, 1164, 1172, 1174, 1178, 1180, 1198, 1208, 1209, 1212, 1226, 1228, 1272, 1273, 1306, 1309, 1314, 1317, 1344, 1345, 1356, 1358, 1369, 1372, 1373, 1387, 1407, 1422, 1470, 1475, 1476, 1493, 1507, 1508, 1509, 1514, 1515, 1516, 1523, 1533, 1540, 1580, 1586, 1617, 1624, 1629, 1630, 1651, 1659, 1678, 1683, 1686, 1754, 1755, 1763, 1764, 1877, 1919, 1921, 1948, 1971, 1973, 2021, 2022, 2023, 2024, 2032, 2091, 2094, 2108, 2115, 2116, 2117, 2122, 2133, 2134, 2138, 2150, 2154, 2155, 2165, 2171, 2172, 2178, 2180, 2195, 2204, 2206, 2210], "neg": [10, 13, 16, 22, 25, 30, 39, 54, 69, 87, 88, 441, 443, 458, 662, 663, 690, 691, 709, 766, 791, 973, 978, 1022, 1025, 1062, 1069, 1070, 1101, 1114, 1160, 1161, 1162, 1163, 1164, 1165, 1179, 1180, 1181, 1187, 1198, 1232, 1238, 1304, 1306, 1308, 1368, 1395, 1407, 1433, 1434, 1449, 1460, 1466, 1470, 1475, 1476, 1484, 1493, 1501, 1502, 1503, 1524, 1533, 1566, 1573, 1574, 1575, 1583, 1587, 1589, 1594, 1612, 1629, 1630, 1679, 1683, 1686, 1688, 1697, 1701, 1711, 1712, 1713, 1722, 1730, 1754, 1755, 1757, 1885, 1886, 1917, 1921, 1955, 1957, 1960, 1972, 2013, 2021, 2022, 2023, 2024, 2031, 2032, 2055, 2060, 2061, 2078, 2084, 2093, 2094, 2115, 2117, 2124, 2127, 2133, 2134, 2154, 2155, 2165, 2171, 2172, 2191, 2195, 2199], "interact": [10, 17, 25, 30, 37, 69, 892, 945, 1040, 1080, 2097, 2100, 2127, 2133, 2158, 2161, 2176, 2189, 2192, 2195, 2198, 2207], "final": [10, 21, 30, 32, 35, 39, 41, 51, 56, 57, 58, 60, 64, 65, 697, 700, 701, 771, 970, 988, 1001, 1144, 1183, 1202, 1241, 1268, 1386, 1404, 1409, 1500, 1531, 1533, 1550, 1596, 1609, 1760, 1838, 1971, 2018, 2093, 2095, 2096, 2097, 2115, 2133, 2136, 2138, 2142, 2145, 2147, 2149, 2150, 2154, 2157, 2158, 2167, 2168, 2189, 2191, 2193, 2204, 2205], "declin": 10, "conflict": [10, 26, 32, 52, 2158], "lack": [10, 13, 36, 969, 1350, 1351, 1378], "unfit": 10, "conduct": [10, 1770, 1882, 1995, 2166, 2185, 2189], "filial": 10, "romant": 10, "strength": 10, "candid": [10, 962, 2158], "letter": [10, 1144], "befit": 10, "candidaci": 10, "behind": [10, 30, 56, 2092, 2147, 2167, 2194], "75": [10, 1276, 1568, 1686, 1704, 1836, 1893, 2094, 2172], "unforeseen": 10, "circumst": [10, 51, 1002, 1238, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1738, 2130], "perman": [10, 69, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 2127, 2168], "unavail": [10, 1057, 2095], "rank": [10, 25, 26, 30, 31, 32, 35, 36, 37, 39, 41, 45, 49, 51, 52, 55, 57, 60, 71, 80, 1360, 1361, 1362, 1369, 1404, 1572, 1620, 1770, 1793, 1882, 1995, 2094, 2130, 2132, 2136, 2144, 2154, 2166, 2167, 2184, 2191, 2204, 2205, 2209], "elect": 10, "invit": [10, 2091], "convinc": 10, "approach": [10, 26, 30, 34, 69, 990, 1213, 1493, 1877, 1936, 1968, 2045, 2093, 2114, 2130, 2133, 2138, 2149, 2150, 2151, 2157, 2161, 2166, 2195, 2204], "interview": 10, "talk": [10, 54, 2100, 2140], "gather": [10, 30, 32, 34, 36, 37, 51, 60, 513, 2008, 2033, 2094, 2130, 2133, 2135, 2136, 2140, 2155, 2158, 2199], "read": [10, 14, 20, 21, 25, 30, 32, 37, 40, 41, 44, 51, 52, 57, 60, 64, 69, 448, 956, 1019, 1103, 1127, 1195, 1197, 1198, 1230, 1322, 1386, 1874, 2100, 2115, 2116, 2122, 2127, 2128, 2130, 2132, 2134, 2140, 2145, 2147, 2149, 2158, 2161, 2166, 2189, 2192, 2193, 2195, 2197, 2204], "attend": [10, 746, 1586, 1624], "confer": [10, 1533], "pipelin": [10, 32, 69, 2160, 2166, 2195], "world": [10, 30, 34, 35, 41, 49, 51, 52, 56, 60, 1620, 1770, 2127, 2158, 2161, 2191, 2192, 2193, 2204], "cover": [10, 57, 58, 61, 69, 71, 1119, 1144, 1573, 1711, 1712, 1713, 2096, 2098, 2116, 2127, 2133, 2136, 2138, 2140, 2142, 2166, 2193, 2198, 2202, 2208], "push": [10, 43, 1105, 1107, 1213, 1380, 2045, 2147, 2159, 2192, 2204], "codeown": 10, "notifi": [10, 31, 52, 2168], "expert": [10, 34, 2157], "strongli": [10, 30, 41, 52, 58, 1518, 1519, 1520, 1524, 1990, 2091], "failur": [10, 30, 39, 41, 43, 44, 48, 49, 50, 51, 55, 56, 681, 949, 950, 1002, 1004, 1202, 1228, 1330, 1331, 1438, 2096, 2102, 2111, 2114, 2136, 2166, 2168, 2178, 2192, 2195, 2204], "revert": [10, 39, 60, 1617, 1746, 2168], "substanti": [10, 26, 2130, 2184, 2189, 2204], "syntact": [10, 44, 69], "incompat": [10, 16, 65, 983, 1311, 1779, 1780, 2128, 2158, 2189, 2204], "establish": [10, 21, 30, 51, 1874, 2117, 2127], "seri": [10, 36, 69, 1499, 1542, 2137, 2146, 2154, 2189, 2200, 2206], "lf": 10, "llc": 10, "guidelin": [10, 1804, 2144, 2149, 2158, 2161, 2162], "trademark": 10, "www": [10, 1499, 2176], "lfproject": 10, "acknowledg": [10, 30, 2168, 2171], "copyright": [10, 2186, 2205], "holder": 10, "independ": [10, 25, 30, 51, 56, 60, 68, 153, 154, 790, 796, 938, 939, 940, 941, 942, 943, 954, 1268, 1277, 1373, 1517, 1518, 1519, 1520, 1524, 1672, 1673, 1674, 1679, 1696, 1697, 1757, 1789, 1824, 1892, 2093, 2126, 2127, 2130, 2147, 2158, 2173, 2202, 2204], "authorship": 10, "claus": [10, 2135], "bsd": 10, "licens": 10, "opensourc": 10, "outbound": 10, "inbound": 10, "q": [10, 26, 39, 431, 479, 769, 814, 1258, 1335, 1351, 1354, 1373, 1415, 1473, 1545, 1586, 1640, 1787, 1880, 1882, 1892, 1893, 1995, 2093, 2094, 2122, 2138, 2154, 2171, 2172, 2194], "partli": [10, 2096], "domain": [10, 39, 44, 695, 851, 915, 1158, 1159, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1172, 1174, 1175, 1176, 1177, 1268, 2117, 2150, 2154, 2161], "absolut": [10, 13, 16, 69, 92, 682, 705, 949, 950, 1192, 1303, 1343, 1348, 1369, 1372, 1374, 1395, 1540, 1546, 1612, 1695, 1699, 1742, 1798, 1799, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1827, 1835, 1886, 1912, 1943, 2094, 2104, 2142, 2155, 2172, 2177, 2178, 2185], "health": 10, "success": [10, 32, 39, 41, 48, 69, 286, 1345, 1356, 1358, 1404, 1800, 1976, 1977, 1978, 1980, 1981, 2130, 2142, 2154, 2171, 2205], "am": 10, "grant": 10, "purchas": 10, "board": 10, "driven": [10, 2154], "clearli": [10, 1228, 2103, 2158], "sponsorship": 10, "foundat": 10, "ptf": 10, "minor": [10, 1069, 1345, 1361, 1452, 2171, 2192], "committ": 10, "prior": [10, 21, 26, 30, 32, 41, 930, 934, 935, 936, 1007, 1387, 1626, 1628, 1738, 1804, 2122, 2128, 2130, 2133, 2157, 2161, 2189, 2195], "walkthrough": [10, 2126], "facebook": 10, "infrastructur": [10, 36, 43, 2158, 2191], "employe": 10, "expand": [10, 39, 255, 493, 908, 930, 934, 935, 936, 949, 950, 985, 1367, 1368, 1416, 1586, 1631, 1731, 2028, 2091, 2094, 2102, 2115, 2116, 2128, 2130, 2133, 2134, 2154, 2155, 2158, 2175, 2199], "deliv": [10, 2159], "offici": [10, 30, 1484, 2137, 2161], "showcas": [10, 14, 38, 1576, 2130, 2144], "whenev": [10, 37, 56, 58, 910, 1787, 1788, 2109, 2114, 2117, 2133, 2164, 2167, 2168, 2194, 2204, 2205, 2206], "fix": [12, 20, 25, 30, 39, 41, 51, 56, 58, 62, 65, 69, 262, 808, 816, 958, 1202, 1328, 1360, 1522, 1523, 1599, 1677, 1678, 1697, 1770, 1878, 2093, 2094, 2109, 2124, 2126, 2130, 2135, 2136, 2144, 2148, 2154, 2155, 2157, 2189, 2192, 2195, 2202, 2204, 2205], "plu": [12, 16, 32, 938, 1198, 1361, 2136, 2171], "quarterli": 12, "chintala": 12, "edward": 12, "yang": [12, 1387], "ezyang": [12, 2100, 2175, 2204], "greg": 12, "chanan": 12, "gchanan": 12, "dmytro": 12, "dzhulgakov": 12, "nikita": 12, "shulga": 12, "malfet": 12, "alban": 12, "desmaison": 12, "alband": 12, "piotr": 12, "bialecki": 12, "ptrblck": 12, "mikayla": 12, "gawarecki": 12, "mikaylagawarecki": 12, "joel": [12, 1882, 1995], "schlosser": 12, "jbschlosser": 12, "sam": 12, "gross": 12, "colesburi": 12, "adam": [12, 31, 32, 35, 39, 60, 958, 1841, 1842, 1844, 1856, 1860, 2157, 2204], "paszk": 12, "apaszk": 12, "jane": 12, "xu": [12, 60], "janeyx99": 12, "ilqar": 12, "ramazanli": 12, "iramazanli": 12, "vincent": 12, "quennevil": 12, "belair": 12, "vincentqb": 12, "jeffrei": 12, "wan": 12, "soulitz": 12, "animesh": 12, "jain": 12, "anijain2305": 12, "jason": [12, 2193], "ansel": [12, 2193], "jansel": 12, "elia": 12, "ellison": 12, "eellison": 12, "horac": 12, "he": [12, 2124], "chille": 12, "shunt": 12, "zhang": 12, "shunting314": [12, 2198], "jiong": 12, "gong": 12, "jgong5": 12, "brian": 12, "hirsh": 12, "bdhirsh": [12, 2036], "richard": [12, 39], "zou": 12, "zou3519": 12, "avik": 12, "chaudhuri": 12, "avikchaudhuri": 12, "yanan": 12, "cao": 12, "gmagogsfm": 12, "bin": [12, 41, 49, 51, 300, 301, 837, 973, 1275, 1276, 1277, 2094, 2096, 2155, 2176, 2201], "bao": [12, 2201], "desertfir": 12, "angela": 12, "yi": 12, "angelayi": [12, 58], "chen": 12, "chenyang78": 12, "michael": [12, 2205], "suo": 12, "jame": 12, "reed": 12, "jamesr66a": 12, "zach": 12, "devito": 12, "zdevito": 12, "fritz": 12, "obermey": 12, "fritzo": 12, "neeraj": 12, "pradhan": 12, "neerajprad": 12, "alican": 12, "bozkurt": 12, "alicanb": 12, "vishwak": 12, "srinivasan": 12, "vishwakftw": 12, "Will": [12, 30, 36, 60, 69, 1004, 1226, 1979, 2095, 2116, 2154, 2189, 2200], "constabl": [12, 2200], "wconstab": 12, "howard": 12, "huang": 12, "wanchao": 12, "liang": 12, "wanchaol": 12, "ke": 12, "wen": 12, "kwen2501": 12, "chien": 12, "chin": 12, "fegin": 12, "tristan": 12, "rice": 12, "d4l3k": 12, "shen": 12, "li": [12, 14, 1473, 1893, 2130, 2192, 2195], "mrshenli": 12, "pritam": 12, "damania": 12, "pritamdamania87": 12, "yanli": 12, "zhao": 12, "zhaojuanmao": 12, "rohan": 12, "varma": 12, "junji": 12, "wang": [12, 39], "fduwjj": 12, "alisson": 12, "azzolini": 12, "aazzolini": 12, "kiuk": 12, "chung": 12, "kiukchung": 12, "pieter": 12, "noordhui": 12, "pietern": 12, "mingzh": 12, "mingzhe09088": 12, "omkar": 12, "salpekar": 12, "osalpekar": 12, "simon": 12, "ssnl": 12, "vitali": 12, "fedyunin": 12, "vitalyfedyunin": 12, "mario": 12, "lezcano": 12, "mike": 12, "ruberri": 12, "mruberri": 12, "ivan": 12, "yashchuk": 12, "ivanyashchuk": 12, "vedeneev": 12, "nikitav": 12, "pearu": 12, "peterson": 12, "christian": 12, "puhrsch": 12, "cpuhrsch": 12, "andrew": [12, 1387, 1877], "amjam": 12, "driss": 12, "guessou": 12, "drisspg": 12, "natalia": 12, "gimelshein": 12, "ngimel": 12, "georg": 12, "qi": 12, "peter": 12, "bell": 12, "peterbell10": 12, "xiaob": 12, "xiaobingsup": 12, "mingfei": 12, "ma": 12, "mingfeima": 12, "xiaoqiang": 12, "zheng": 12, "xq": 12, "ilia": 12, "cherniavskii": 12, "cher": 12, "bai": 12, "bddppq": 12, "yinghai": 12, "jianhui": 12, "sarofeen": 12, "csarofeen": 12, "tulloch": 12, "ajtulloch": 12, "jeff": 12, "daili": 12, "jeffdaili": 12, "jithun": 12, "nair": 12, "jithunnair": 12, "eli": 12, "uriega": 12, "seemether": 12, "andrei": 12, "talman": 12, "atalman": 12, "zain": 12, "rizvi": 12, "zainrizvi": 12, "mikei": 12, "dagits": 12, "nirav": 12, "mehta": 12, "mehtanirav": 12, "zhuoji": 12, "zhou": 12, "zhouzhuoji": 12, "karl": 12, "ostmo": 12, "kostmo": 12, "taylor": [12, 1268], "robi": 12, "robieta": 12, "xuzhao9": 12, "victor": 12, "bittorf": 12, "bitfort": 12, "gisl": 12, "dankel": 12, "gdankel": 12, "feng": 12, "yf225": 12, "sebastian": 12, "messmer": 12, "smessmer": 12, "shubham": 12, "bhokar": 12, "shubhambhokare1": 12, "justin": 12, "chu": [12, 39], "justinchubi": 12, "xavier": [12, 2124], "dupr\u00e9": 12, "xadupr": 12, "titai": 12, "titaiwangm": 12, "bowen": 12, "bowenbao": 12, "thiago": 12, "crepaldi": 12, "thiagocrepaldi": 12, "aaron": 12, "bockov": 12, "abock": 12, "gari": 12, "miguel": 12, "garymm": 12, "lara": 12, "haidar": 12, "hdr": 12, "fang": 12, "houseroad": 12, "negin": 12, "raoof": 12, "neginraoof": 12, "spandan": 12, "tiwari": 12, "spandantiwari": 12, "david": [12, 1484], "reiss": 12, "dreiss": 12, "raziel": 12, "guevara": 12, "linbin": 12, "yu": 12, "linbinyu": 12, "kobzarev": 12, "ivankobzarev": 12, "tao": 12, "xta0": 12, "mark": [12, 32, 36, 51, 68, 69, 71, 76, 80, 486, 851, 930, 931, 932, 935, 958, 1005, 1007, 1222, 1433, 1434, 1770, 1834, 2093, 2095, 2127, 2130, 2132, 2133, 2142, 2147, 2158, 2159, 2167, 2177, 2183, 2189, 2192, 2195, 2196], "saroufim": [12, 2195], "msaroufim": 12, "vasilii": 12, "kuznetsov": 12, "vkuzo": 12, "jerri": 12, "jerryzh168": [12, 806], "zafar": 12, "takhirov": 12, "raghuraman": 12, "krishnamoorthi": 12, "raghuramank100": 12, "guoliang": 12, "hua": 12, "nbcsm": 12, "teng": 12, "gao": 12, "gaoteng": 12, "git": [12, 2186, 2195, 2205], "johnson": 12, "peterjc123": [12, 2148], "kulin": 12, "seth": 12, "kulinseth": 12, "ramin": 12, "azarmehr": 12, "razarmehr": 12, "alfredo": 12, "mendoza": 12, "avmgithub": 12, "sunita": 12, "nadamp": 12, "snadamp": 12, "svetlana": 12, "karslioglu": 12, "svekar": 12, "jack": 12, "jackcaog": 12, "daniel": [12, 39], "sohn": 12, "jysohn23": 12, "cain": 12, "zcain117": 12, "gregori": 12, "ail": 12, "ailzhang": 12, "libenzi": 12, "dlibenzi": 12, "alex": 12, "suhan": 12, "asuhan": 12, "ning": 12, "lxning": 12, "ankith": 12, "gunap": 12, "agunap": 12, "hamid": 12, "shojanazeri": 12, "hamidshojanazeri": 12, "manoj": 12, "rao": 12, "mycpuorg": 12, "vamshi": 12, "dantu": 12, "vdantu": 12, "dhanasekar": 12, "karuppasami": 12, "dhanainm": 12, "nicola": 12, "hug": 12, "nicolashug": 12, "philip": 12, "meier": 12, "pmeier": 12, "fomin": 12, "vfdev": 12, "francisco": 12, "massa": 12, "fmassa": 12, "vasili": 12, "vrynioti": 12, "datumbox": 12, "yosua": 12, "maranatha": 12, "yosuamichael": 12, "joao": 12, "gome": 12, "jdsgome": 12, "nayef": 12, "ahm": 12, "nayef211": 12, "parmeet": 12, "singh": 12, "bhatia": 12, "guanheng": 12, "zhangguanheng66": 12, "moto": 12, "hira": 12, "mthrok": 12, "hwang": 12, "hwangjeff": 12, "carolin": 12, "carolineechen": 12, "xiaohui": 12, "zhaoheng": 12, "ni": 12, "nateanl": 12, "qb": 12, "colin": 12, "colin2328": 12, "paul": 12, "paulzhang12": 12, "ivchenko": 12, "divchenko": 12, "ho": [12, 1550, 1551], "andrewkho": 12, "divyansh": 12, "khanna": 12, "divyanshk": 12, "wenlei": 12, "xie": 12, "wenleix": 12, "mergen": 12, "nachin": 12, "mergennachin": 12, "kimish": 12, "patel": 12, "kimishpatel": 12, "dave": 12, "bort": 12, "dbort": 12, "martin": 12, "yuan": 12, "iseeyuan": 12, "kartikai": 12, "khandelw": 12, "kartikayk": 12, "evan": 12, "smother": 12, "ebsmoth": 12, "joe": [12, 39], "cum": 12, "joecum": 12, "khuu": 12, "jess": 12, "white": [12, 2196], "byjlw": 12, "gschwind": 12, "mikekgfb": 12, "ahmad": 12, "sharif": 12, "ahmadsharif1": 12, "scott": 12, "schneider": 12, "express": [13, 14, 32, 57, 58, 61, 65, 66, 69, 71, 79, 80, 81, 82, 319, 1019, 1221, 1224, 1228, 1235, 1239, 1240, 1241, 1242, 1253, 1312, 1315, 1824, 1990, 2097, 2106, 2117, 2127, 2133, 2161, 2191, 2192, 2195, 2205, 2206], "bj": 13, "j": [13, 30, 39, 313, 315, 321, 513, 515, 517, 703, 928, 938, 940, 1016, 1144, 1160, 1161, 1168, 1174, 1178, 1179, 1255, 1311, 1314, 1350, 1351, 1362, 1378, 1387, 1394, 1402, 1404, 1409, 1518, 1519, 1520, 1524, 1580, 1583, 1672, 1673, 1674, 1679, 1877, 1886, 1893, 1972, 1990, 1994, 2042, 2095, 2124, 2127, 2133, 2138, 2147, 2176], "imaginari": [13, 311, 949, 1016, 1023, 1165, 1167, 1175, 1176, 1177, 1285, 1304, 1306, 1307, 1310, 1905, 1990, 2043, 2044, 2097, 2127, 2138, 2178], "satisfi": [13, 23, 26, 39, 57, 58, 69, 617, 705, 771, 807, 939, 949, 950, 986, 1160, 1161, 1163, 1165, 1167, 1175, 1176, 1177, 1192, 1227, 1328, 1354, 1380, 1381, 1484, 1499, 1526, 1531, 1550, 1596, 1804, 1820, 1912, 1928, 1968, 1990, 2096, 2100, 2127, 2130, 2136, 2138, 2157, 2159, 2171, 2174, 2189, 2193], "equat": [13, 995, 1144, 1221, 1232, 1258, 1272, 1358, 1359, 1360, 1361, 1362, 1364, 1375, 1377, 1492, 1953, 1974, 2020, 2094, 2127, 2138, 2157, 2172], "frequent": [13, 32, 1484, 2111, 2125, 2130, 2144, 2145, 2147, 2171, 2183, 2185, 2189, 2197, 2204], "occur": [13, 25, 30, 44, 45, 51, 60, 65, 196, 315, 925, 958, 1002, 1104, 1144, 1228, 1311, 1317, 1328, 1358, 1499, 1620, 1639, 1670, 1827, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1860, 2095, 2109, 2111, 2116, 2117, 2126, 2127, 2130, 2135, 2145, 2150, 2154, 2159, 2166, 2168, 2175, 2178, 2191, 2192, 2195, 2197, 2200, 2202, 2204, 2205, 2206, 2207], "mathemat": [13, 69, 938, 939, 940, 941, 942, 943, 1192, 1268, 1492, 1494, 1495, 1496, 1542, 1543, 1544, 1545, 1620, 1705, 1745, 1770, 1827, 1912, 1970, 1971, 2096, 2100, 2127, 2145, 2172, 2180], "topic": [13, 56, 2140, 2142, 2193], "tradition": [13, 2117], "torchaudio": [13, 2137], "mimick": 13, "assembli": 13, "lapack": [13, 1258, 1345, 1356, 1357, 1358, 1360, 1363, 1376, 1892, 1994], "spectral": [13, 1334, 1350, 1378, 1788, 1811, 1821, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2145], "fft": [13, 2130, 2160], "4621": 13, "0303j": 13, "2438": [13, 1360, 1677], "5874j": 13, "7706": 13, "1421j": 13, "2110": 13, "1918j": 13, "complex128": [13, 175, 1016, 1187, 1197, 1293, 1314, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1507, 1508, 1509, 1580, 1661, 1662, 1663, 1833, 1877, 1886, 1933, 2173, 2174, 2177, 2178, 2195], "complex64": [13, 178, 994, 995, 1016, 1161, 1163, 1164, 1169, 1170, 1197, 1293, 1346, 1369, 1372, 1507, 1508, 1509, 1661, 1662, 1663, 1833, 1886, 1933, 2173, 2174, 2177, 2178, 2195], "apart": [13, 2096, 2127], "linspac": [13, 973, 997, 1165, 1175, 1416, 2094, 2098, 2155], "logspac": [13, 2094, 2098, 2155], "arang": [13, 25, 30, 40, 513, 607, 702, 703, 704, 708, 710, 916, 917, 918, 984, 996, 1000, 1127, 1142, 1160, 1164, 1172, 1178, 1180, 1184, 1185, 1186, 1187, 1194, 1195, 1278, 1335, 1336, 1340, 1343, 1367, 1370, 1371, 1384, 1476, 1500, 1501, 1502, 1602, 1603, 1604, 1605, 1606, 1633, 1634, 1635, 1724, 1827, 1828, 1881, 1889, 1893, 1908, 1915, 1920, 1940, 1973, 1982, 1993, 2012, 2013, 2015, 2016, 2018, 2046, 2094, 2100, 2103, 2117, 2130, 2147, 2155, 2172, 2176, 2177, 2186, 2189, 2192, 2197, 2199], "switch": [13, 21, 25, 32, 34, 63, 68, 69, 1357, 1358, 1359, 1519, 1686, 1725, 1776, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1878, 1924, 2033, 2100, 2114, 2127, 2130, 2142, 2144, 2157, 2196, 2202], "view_as_r": [13, 1990, 2094, 2117, 2155, 2175], "6125": 13, "1681": 13, "3773": 13, "3487": 13, "0861": 13, "7981": 13, "1681j": 13, "3487j": 13, "7981j": 13, "mul_": [13, 71, 84, 2094, 2115, 2117, 2171], "2250": [13, 1371, 1827], "7546": 13, "1722": 13, "x1": [13, 56, 990, 1362, 1514, 1572, 1629, 1630, 1668, 1726, 2094, 2199], "3j": [13, 30, 709, 1020, 1021, 1916, 1917, 1933], "4j": [13, 30, 1943], "0000": [13, 39, 513, 895, 938, 940, 973, 993, 997, 1023, 1125, 1131, 1132, 1133, 1158, 1159, 1162, 1164, 1165, 1171, 1172, 1175, 1180, 1192, 1193, 1194, 1268, 1274, 1277, 1281, 1340, 1343, 1344, 1345, 1357, 1358, 1361, 1366, 1367, 1371, 1373, 1385, 1401, 1471, 1522, 1523, 1633, 1634, 1636, 1637, 1677, 1678, 1827, 1886, 1892, 1897, 1898, 1899, 1908, 1912, 1913, 1937, 1943, 1945, 1946, 1948, 1951, 1952, 1953, 1954, 1971, 2020, 2021, 2023, 2048, 2103, 2117, 2130, 2171, 2172, 2177], "6569": [13, 1281], "5708": [13, 1128], "7854": 13, "complex_tensor": 13, "pt": [13, 26, 32, 60, 1196, 1319, 1322, 1325, 1332, 1386, 1924, 2093, 2104, 2142, 2147, 2158, 2197], "conjug": [13, 330, 458, 703, 949, 994, 995, 1020, 1021, 1294, 1344, 1345, 1351, 1354, 1357, 1364, 1378, 1383, 1387, 1787, 1880, 1916, 1990, 1994, 2042, 2138, 2157, 2177, 2180], "wirting": [13, 949, 2138], "deriv": [13, 30, 36, 56, 60, 150, 749, 750, 751, 752, 753, 754, 792, 815, 843, 923, 944, 949, 950, 1208, 1212, 1224, 1268, 1311, 1372, 1404, 1628, 1760, 2095, 2133, 2134, 2138, 2166, 2171, 2172], "steepest": [13, 2127], "descent": [13, 39, 1836, 1859, 1863, 1864, 2127, 2142], "box": [13, 30, 52, 69, 1004, 1213, 1226, 2045, 2116, 2117, 2127, 2132, 2190, 2191, 2196, 2197], "real_param": 13, "p": [13, 26, 32, 39, 58, 60, 69, 154, 234, 286, 425, 426, 453, 488, 491, 492, 697, 700, 970, 972, 982, 990, 1138, 1335, 1346, 1352, 1353, 1361, 1362, 1404, 1406, 1409, 1419, 1469, 1488, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1545, 1547, 1548, 1549, 1585, 1589, 1591, 1629, 1630, 1652, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1707, 1708, 1709, 1719, 1723, 1726, 1727, 1738, 1754, 1776, 1785, 1791, 1793, 1799, 1807, 1827, 1859, 1913, 1970, 2094, 2095, 2126, 2127, 2130, 2135, 2138, 2144, 2157, 2159, 2171, 2172, 2198, 2199], "complex_optim": 13, "adamw": [13, 1840, 1844, 1856, 2157], "real_optim": 13, "slight": [13, 1932, 2171, 2174], "discrep": [13, 1770, 1899, 2138], "foreach": [13, 1775, 1776, 1777, 1778, 1785, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2157], "v": [13, 32, 36, 48, 56, 64, 69, 487, 488, 544, 928, 939, 941, 942, 943, 969, 986, 1144, 1201, 1211, 1213, 1228, 1311, 1328, 1350, 1378, 1382, 1387, 1586, 1629, 1630, 1640, 1677, 1723, 1789, 1819, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1882, 1915, 1975, 1979, 1994, 1995, 2045, 2093, 2094, 2095, 2096, 2109, 2127, 2133, 2138, 2141, 2148, 2157, 2158, 2171, 2176, 2188], "forloop": 13, "numerical_accuraci": 13, "impact": [13, 26, 30, 58, 1014, 1101, 1936, 2106, 2109, 2117, 2127, 2161, 2175, 2195, 2200, 2204, 2205], "pointwis": [13, 39, 1002, 1206, 1207, 1392, 1393, 1545, 2115, 2117, 2128, 2194, 2197, 2198], "lbfg": [13, 2157], "yet": [13, 30, 31, 36, 37, 41, 56, 57, 60, 65, 68, 69, 78, 486, 1039, 1119, 1239, 1317, 1319, 1332, 1420, 1770, 1795, 1799, 1801, 1840, 1841, 2092, 2095, 2096, 2102, 2108, 2116, 2117, 2130, 2147, 2154, 2155, 2161, 2166, 2168, 2171, 2172, 2174, 2189, 2192, 2194, 2195, 2200, 2202, 2204, 2205], "fulli": [13, 16, 25, 30, 32, 34, 35, 36, 38, 56, 64, 69, 681, 1108, 1226, 1314, 1576, 1577, 1578, 1580, 1877, 2096, 2102, 2108, 2133, 2158, 2161, 2191, 2192, 2199, 2204], "quantiz": [13, 29, 56, 69, 219, 326, 338, 472, 473, 474, 475, 476, 478, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 839, 840, 841, 842, 843, 846, 851, 852, 855, 856, 857, 858, 859, 860, 861, 862, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 888, 889, 890, 891, 892, 893, 894, 962, 1129, 1158, 1159, 1894, 1895, 1896, 1897, 1898, 2033, 2155, 2160, 2174, 2177, 2178, 2181, 2182], "pred": [14, 58, 71, 74, 79, 80, 1019, 1545, 1770, 2143, 2157, 2166, 2199, 2204], "union": [14, 16, 25, 32, 34, 36, 37, 38, 41, 45, 49, 52, 56, 57, 60, 69, 1002, 1019, 1220, 1224, 1226, 1228, 1254, 1286, 1300, 1326, 1386, 1481, 1482, 1483, 1485, 1486, 1487, 1489, 1490, 1491, 1527, 1528, 1547, 1548, 1549, 1573, 1574, 1575, 1580, 1624, 1626, 1628, 1631, 1644, 1683, 1793, 1813, 1892, 1924, 1985, 2036, 2094, 2095, 2096, 2100, 2117, 2122, 2147, 2154, 2158, 2173, 2176, 2178, 2182, 2185], "true_fn": [14, 57, 58, 71, 74, 79, 80, 1019], "false_fn": [14, 57, 58, 71, 74, 79, 80, 1019], "operand": [14, 58, 71, 79, 80, 978, 1019, 1144, 2096, 2097, 2133, 2171, 2174], "Its": [14, 30, 57, 69, 1027, 1053, 1314, 1362, 1380, 1381, 1406, 1580, 1827, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 1974, 2042, 2096, 2132, 2173], "uniqu": [14, 30, 41, 48, 51, 52, 54, 233, 513, 517, 1305, 1350, 1351, 1355, 1361, 1362, 1364, 1373, 1375, 1377, 1378, 1415, 1422, 1970, 1974, 1994, 2030, 2091, 2093, 2102, 2107, 2133, 2158, 2159, 2166, 2167, 2168, 2171, 2173, 2176, 2184, 2189, 2207], "predic": [14, 71, 76, 79, 80, 1228], "unlock": [14, 2103], "architectur": [14, 38, 69, 1068, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1515, 1624, 1669, 1937, 2059, 2130, 2145, 2150, 2154, 2157, 2161, 2171, 2188, 2204], "prototyp": [14, 20, 30, 34, 37, 56, 681, 938, 940, 944, 949, 950, 1019, 1324, 1628, 1640, 1641, 1840, 1841, 2092, 2103, 2109, 2116, 2117, 2122, 2137, 2142, 2147, 2164, 2166, 2171, 2174, 2180, 2181, 2182, 2185], "classif": [14, 1019, 1493, 1499, 1515, 1583, 1585, 1587, 1613, 1670, 2092, 2122, 2124, 2162], "co": [14, 56, 57, 58, 66, 71, 75, 76, 79, 80, 81, 82, 84, 201, 636, 637, 694, 980, 1002, 1019, 1086, 1203, 1206, 1207, 1212, 1272, 1273, 1366, 1513, 1514, 1517, 1863, 1864, 1872, 1878, 1886, 1947, 1951, 1952, 1953, 1954, 1956, 1976, 1977, 1978, 1980, 1981, 2094, 2100, 2115, 2155, 2157, 2171, 2176, 2178, 2190, 2197, 2199], "sin": [14, 16, 56, 57, 58, 65, 66, 71, 75, 76, 79, 80, 81, 82, 532, 670, 671, 911, 1002, 1019, 1086, 1203, 1205, 1206, 1207, 1209, 1212, 1273, 1366, 1416, 1886, 1948, 1954, 2094, 2100, 2115, 2117, 2127, 2155, 2171, 2172, 2176, 2190, 2195, 2197, 2199, 2202, 2204], "dynamicshapecondpred": 14, "dyn_shape_mod": 14, "eagerli": [14, 36, 1014, 1074, 1081, 2064, 2068, 2130, 2191, 2195, 2204], "vari": [14, 56, 1320, 1493, 1612, 1813, 1949, 2109, 2117, 2122, 2130, 2144, 2145, 2157, 2161, 2162, 2171, 2185, 2189, 2191, 2192, 2194, 2195, 2204, 2205, 2207], "inp2": 14, "assert": [14, 25, 26, 32, 36, 39, 62, 64, 65, 66, 69, 71, 77, 80, 81, 82, 625, 689, 693, 952, 954, 955, 1203, 1205, 1206, 1207, 1208, 1211, 1212, 1213, 1227, 1228, 1312, 1317, 1318, 1324, 1738, 1833, 2045, 2095, 2097, 2100, 2130, 2133, 2134, 2142, 2147, 2157, 2158, 2161, 2173, 2178, 2191, 2195, 2203, 2205], "export": [14, 17, 20, 30, 36, 40, 55, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 681, 834, 870, 961, 1004, 1009, 1019, 1039, 1222, 1232, 1317, 1319, 1320, 1326, 1332, 1814, 1815, 1834, 1835, 2093, 2095, 2096, 2100, 2133, 2155, 2156, 2159, 2160, 2166, 2183, 2186, 2191, 2196, 2202, 2203], "deploy": [14, 41, 51, 56, 2106, 2125, 2185, 2196], "dim_batch": 14, "dim": [14, 30, 34, 37, 38, 39, 56, 58, 65, 66, 69, 71, 73, 79, 80, 112, 114, 115, 116, 118, 134, 135, 136, 184, 204, 207, 210, 211, 212, 213, 214, 215, 229, 233, 260, 264, 281, 312, 313, 314, 315, 316, 317, 321, 322, 354, 380, 392, 407, 409, 410, 411, 414, 429, 430, 431, 432, 436, 437, 453, 462, 470, 479, 491, 492, 494, 505, 506, 512, 513, 514, 515, 516, 517, 518, 519, 537, 538, 541, 542, 544, 547, 552, 553, 555, 560, 565, 573, 578, 579, 583, 584, 585, 587, 588, 590, 605, 606, 609, 610, 611, 612, 615, 617, 704, 706, 707, 708, 710, 904, 905, 906, 940, 941, 943, 989, 996, 1017, 1019, 1026, 1036, 1053, 1056, 1123, 1124, 1125, 1126, 1127, 1136, 1142, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1183, 1184, 1203, 1213, 1222, 1255, 1268, 1278, 1286, 1287, 1288, 1289, 1291, 1336, 1346, 1347, 1367, 1371, 1381, 1383, 1384, 1394, 1402, 1412, 1414, 1415, 1417, 1420, 1422, 1441, 1471, 1472, 1473, 1474, 1475, 1476, 1484, 1514, 1515, 1516, 1519, 1523, 1525, 1530, 1545, 1551, 1570, 1586, 1587, 1588, 1614, 1616, 1628, 1630, 1631, 1668, 1669, 1685, 1688, 1697, 1705, 1711, 1712, 1713, 1722, 1723, 1725, 1727, 1731, 1738, 1744, 1745, 1753, 1770, 1788, 1789, 1795, 1799, 1801, 1807, 1808, 1821, 1824, 1827, 1838, 1883, 1890, 1893, 1913, 1914, 1919, 1920, 1925, 1926, 1927, 1930, 1931, 1961, 1964, 1965, 1969, 1972, 1975, 1982, 1985, 1987, 1988, 1989, 1990, 1993, 2008, 2012, 2013, 2014, 2015, 2018, 2019, 2027, 2028, 2029, 2030, 2032, 2040, 2041, 2045, 2046, 2093, 2094, 2100, 2116, 2117, 2134, 2135, 2147, 2150, 2154, 2155, 2171, 2172, 2174, 2181, 2185, 2191, 2199], "batch": [14, 26, 30, 36, 37, 39, 52, 55, 56, 60, 61, 62, 65, 66, 69, 71, 79, 80, 583, 584, 585, 587, 588, 697, 713, 714, 715, 716, 717, 718, 746, 771, 790, 796, 944, 949, 950, 970, 982, 983, 990, 993, 994, 995, 1002, 1036, 1132, 1134, 1144, 1206, 1207, 1213, 1311, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1382, 1383, 1384, 1387, 1395, 1404, 1405, 1409, 1492, 1493, 1494, 1495, 1496, 1499, 1507, 1508, 1513, 1515, 1516, 1518, 1519, 1520, 1522, 1523, 1524, 1526, 1531, 1532, 1533, 1534, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1550, 1551, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1571, 1572, 1583, 1584, 1585, 1586, 1587, 1589, 1592, 1593, 1594, 1595, 1596, 1598, 1612, 1613, 1620, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1632, 1651, 1656, 1658, 1659, 1669, 1670, 1672, 1673, 1674, 1677, 1678, 1679, 1680, 1683, 1696, 1697, 1698, 1722, 1730, 1738, 1756, 1757, 1760, 1769, 1770, 1787, 1813, 1814, 1816, 1817, 1819, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1864, 1865, 1872, 1877, 1880, 1882, 1892, 1896, 1976, 1977, 1978, 1980, 1981, 1985, 1990, 1994, 1995, 2017, 2020, 2021, 2023, 2042, 2045, 2100, 2115, 2116, 2117, 2122, 2126, 2130, 2134, 2135, 2142, 2144, 2151, 2161, 2166, 2171, 2176, 2177, 2185, 2189, 2191, 2192, 2194, 2195, 2198, 2202, 2205], "min": [14, 25, 30, 37, 44, 51, 56, 69, 116, 185, 186, 187, 188, 300, 706, 707, 708, 767, 769, 781, 782, 791, 817, 837, 839, 840, 841, 846, 905, 997, 998, 1086, 1124, 1158, 1159, 1238, 1275, 1346, 1360, 1361, 1367, 1371, 1373, 1378, 1384, 1404, 1466, 1498, 1538, 1566, 1568, 1588, 1601, 1608, 1660, 1697, 1701, 1731, 1733, 1739, 1757, 1838, 1858, 1863, 1864, 1874, 1880, 1882, 1892, 1994, 1995, 2003, 2021, 2022, 2023, 2024, 2094, 2109, 2115, 2154, 2155, 2161, 2164, 2166, 2185, 2191, 2195, 2199, 2210], "ep": [14, 56, 58, 723, 724, 725, 726, 727, 728, 734, 735, 747, 748, 760, 762, 763, 764, 765, 808, 834, 837, 839, 840, 841, 846, 851, 949, 950, 1324, 1400, 1480, 1494, 1495, 1496, 1514, 1533, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1589, 1594, 1595, 1620, 1624, 1626, 1628, 1629, 1656, 1668, 1683, 1687, 1688, 1696, 1700, 1723, 1726, 1730, 1735, 1754, 1769, 1788, 1821, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1874, 1896, 2094, 2133, 2138, 2172, 2186, 2199, 2210], "dynamic_shap": [14, 56, 71, 73, 79, 80, 1221, 1222, 2150, 2154, 2185, 2201], "graphmodul": [14, 36, 56, 57, 58, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 867, 889, 890, 891, 892, 1216, 2161, 2182, 2190, 2193, 2194, 2203, 2204, 2205], "arg0_1": [14, 56, 58], "f32": [14, 56, 58, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 2204], "s0": [14, 56, 57, 71, 79, 80, 486, 1218, 1228, 2173, 2191, 2192, 2204, 2205], "sym_siz": [14, 57, 71, 79, 80, 2155, 2199], "sym": [14, 71, 79, 80, 81, 82, 1228, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956], "gt": [14, 71, 79, 80, 296, 1269, 2094, 2115, 2138, 2155, 2199], "true_graph_0": [14, 57, 71, 74, 79, 80], "false_graph_0": [14, 57, 71, 74, 79, 80], "symbol": [14, 16, 24, 56, 57, 71, 80, 625, 832, 870, 1004, 1221, 1222, 1224, 1226, 1228, 1230, 1231, 1233, 1234, 1237, 1238, 1242, 1252, 1329, 1383, 1550, 1596, 2020, 2042, 2096, 2100, 2117, 2150, 2189, 2191, 2194, 2195, 2204, 2205], "sub": [14, 30, 38, 44, 60, 68, 71, 74, 79, 80, 562, 829, 891, 892, 1326, 1330, 1331, 1412, 1415, 1417, 1592, 1593, 1624, 1625, 1627, 1913, 1992, 2012, 2029, 2091, 2093, 2094, 2115, 2117, 2127, 2144, 2154, 2155, 2171, 2174, 2192, 2199, 2203, 2204], "datadependentcondpred": 14, "sum_1": [14, 69, 2190, 2192, 2193], "b8": [14, 71, 74, 79], "flatten": [14, 26, 34, 37, 56, 57, 60, 69, 71, 77, 904, 905, 1133, 1277, 1371, 1384, 1632, 1786, 1827, 1835, 1893, 1909, 1914, 1919, 2008, 2028, 2029, 2030, 2031, 2094, 2115, 2116, 2118, 2122, 2124, 2154, 2155, 2163, 2175, 2191], "closur": [14, 35, 71, 79, 80, 1004, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1854, 1856, 1857, 1858, 1859, 1860, 2193, 2196], "flat": [14, 34, 56, 1914, 1956, 2031, 2094, 2136, 2154, 2171], "_higher_order_op": 14, "condition": [14, 51, 946, 1019, 2204], "constraint": [14, 30, 34, 56, 60, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 807, 808, 939, 1019, 1078, 1089, 1207, 1221, 1222, 1224, 1227, 1228, 1238, 1738, 1770, 1788, 1813, 1860, 2096, 2134, 2136, 2138, 2142, 2171, 2189, 2191, 2192], "true_branch": [14, 1019], "false_branch": [14, 1019], "consist": [14, 21, 25, 30, 32, 36, 39, 51, 52, 57, 69, 949, 993, 994, 995, 1019, 1236, 1314, 1344, 1350, 1351, 1353, 1355, 1356, 1357, 1358, 1382, 1384, 1414, 1580, 1628, 1790, 1793, 1835, 1877, 1892, 1994, 2093, 2096, 2100, 2103, 2116, 2117, 2130, 2133, 2134, 2136, 2137, 2142, 2144, 2146, 2154, 2157, 2159, 2171, 2184, 2190, 2193, 2198, 2205], "possibli": [14, 25, 56, 58, 60, 1019, 1240, 1241, 1314, 1330, 1357, 1362, 1580, 1770, 1877, 2093, 2100, 2117, 2146, 2158, 2194, 2207], "aka": [14, 30, 56, 57, 71, 79, 80, 962, 1019, 1540, 1695, 2117, 2127, 2174, 2191], "add_": [14, 30, 56, 63, 65, 71, 74, 488, 1019, 1202, 2094, 2115, 2128, 2147, 2171, 2189], "tempor": [14, 1019, 1494, 1496, 1499, 1620, 1633, 1670, 1697, 1757], "pytre": [14, 56, 58, 69, 71, 1019, 2134], "parallel_info": [15, 2129], "cppextens": 16, "setuptool": 16, "bare": 16, "pypa": 16, "userguid": 16, "ext_modul": 16, "libtorch_python": 16, "py_limited_api": 16, "libtorch": [16, 17, 2125, 2185], "buildextens": 16, "cpp": [16, 30, 2132, 2185, 2191, 2209], "extra_compile_arg": [16, 2148], "extra_link_arg": 16, "wl": 16, "lm": [16, 36], "cmdclass": 16, "build_ext": 16, "cudaextens": 16, "cuda_extens": 16, "extension_kernel": 16, "cu": 16, "cxx": 16, "nvcc": [16, 1072, 2186, 2205], "o2": 16, "lcuda": 16, "arch": [16, 2204], "card": [16, 2130, 2148], "visibl": [16, 30, 32, 48, 57, 1066, 1115, 1581, 1582, 1590, 1591, 2100, 2191, 2192, 2196], "ptx": 16, "road": 16, "recompil": [16, 69, 681, 1002, 1014, 1328, 2102, 2117, 2139, 2191, 2192, 2193, 2200], "cc": [16, 30, 2130], "newest": [16, 64, 2149], "torch_cuda_arch_list": 16, "6": [16, 19, 20, 21, 25, 26, 30, 36, 39, 49, 56, 69, 71, 72, 76, 77, 79, 80, 81, 82, 313, 315, 317, 321, 401, 402, 471, 487, 499, 513, 517, 560, 607, 696, 697, 702, 708, 752, 753, 754, 756, 757, 769, 772, 774, 776, 938, 939, 941, 942, 943, 965, 973, 981, 986, 992, 996, 1000, 1027, 1050, 1103, 1108, 1121, 1122, 1123, 1127, 1128, 1139, 1142, 1143, 1160, 1168, 1173, 1174, 1178, 1179, 1181, 1183, 1184, 1187, 1194, 1268, 1278, 1280, 1281, 1303, 1325, 1336, 1340, 1351, 1367, 1371, 1372, 1373, 1380, 1381, 1385, 1387, 1416, 1474, 1475, 1476, 1489, 1500, 1501, 1502, 1503, 1506, 1511, 1514, 1522, 1523, 1532, 1533, 1534, 1536, 1537, 1576, 1577, 1581, 1589, 1598, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1624, 1625, 1627, 1629, 1632, 1638, 1653, 1683, 1690, 1691, 1724, 1726, 1733, 1760, 1778, 1815, 1816, 1818, 1820, 1826, 1827, 1828, 1837, 1858, 1881, 1882, 1885, 1892, 1893, 1899, 1900, 1903, 1909, 1919, 1920, 1924, 1928, 1940, 1961, 1965, 1970, 1973, 1976, 1977, 1982, 1993, 1995, 1996, 1997, 2007, 2012, 2013, 2014, 2015, 2016, 2018, 2021, 2023, 2027, 2031, 2033, 2046, 2047, 2093, 2096, 2097, 2103, 2111, 2117, 2124, 2127, 2133, 2134, 2136, 2137, 2142, 2147, 2154, 2166, 2167, 2171, 2172, 2174, 2177, 2178, 2186, 2192, 2193, 2195, 2199, 2201, 2204, 2205, 2206], "build_my_extens": 16, "7": [16, 25, 26, 30, 39, 56, 58, 69, 71, 76, 260, 313, 315, 317, 321, 401, 402, 471, 513, 560, 607, 617, 696, 708, 756, 757, 941, 943, 978, 981, 986, 992, 994, 996, 1000, 1126, 1127, 1139, 1141, 1142, 1145, 1160, 1183, 1184, 1187, 1190, 1194, 1268, 1278, 1291, 1336, 1340, 1350, 1355, 1357, 1358, 1361, 1362, 1366, 1367, 1371, 1378, 1474, 1475, 1476, 1482, 1483, 1486, 1487, 1489, 1500, 1501, 1502, 1522, 1568, 1576, 1577, 1602, 1603, 1604, 1605, 1606, 1629, 1632, 1653, 1725, 1779, 1780, 1805, 1810, 1820, 1827, 1843, 1899, 1903, 1909, 1919, 1920, 1921, 1928, 1936, 1940, 1943, 1945, 1956, 1957, 1965, 1973, 1976, 1977, 1982, 1994, 1996, 1997, 2007, 2012, 2013, 2016, 2018, 2027, 2031, 2042, 2046, 2093, 2097, 2103, 2111, 2116, 2117, 2128, 2130, 2133, 2145, 2147, 2150, 2154, 2155, 2161, 2171, 2174, 2175, 2176, 2177, 2178, 2192, 2197, 2201, 2204], "older": [16, 2130, 2147, 2158], "modestli": [16, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860], "imag": [16, 25, 752, 753, 754, 891, 892, 1016, 1482, 1486, 1487, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1526, 1527, 1528, 1543, 1552, 1587, 1592, 1593, 1615, 1632, 1634, 1635, 1651, 1662, 1663, 1665, 1666, 1680, 1681, 1686, 1697, 1756, 1757, 1917, 2094, 2117, 2138, 2155, 2161, 2175, 2176, 2191, 2195, 2196, 2199, 2204], "11": [16, 30, 321, 513, 681, 992, 996, 1089, 1142, 1278, 1335, 1371, 1385, 1401, 1484, 1500, 1528, 1577, 1682, 1827, 1828, 1834, 1965, 2012, 2046, 2093, 2097, 2103, 2116, 2130, 2133, 2147, 2148, 2154, 2155, 2171, 2172, 2205], "pars": [16, 30, 52, 55, 959, 2096, 2100, 2158, 2166, 2192], "window": [16, 25, 30, 69, 351, 556, 971, 980, 1272, 1273, 1311, 1334, 1489, 1490, 1491, 1527, 1528, 1547, 1548, 1549, 1573, 1574, 1575, 1576, 1577, 1578, 1653, 1681, 1682, 1711, 1712, 1713, 1897, 1898, 1990, 2094, 2109, 2125, 2130, 2137, 2147, 2159, 2191], "workaround": [16, 25, 36, 56, 69, 1318, 2091, 2117, 2146, 2154, 2161, 2195], "pure": [16, 17, 56, 65, 1015, 1317, 2093, 2122, 2133], "sigmoidalphablendforwardcuda": 16, "69460": 16, "facebookresearch": 16, "pytorch3d": 16, "relocat": 16, "link": [16, 17, 39, 69, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1573, 1574, 1575, 1632, 1688, 2116, 2130, 2140, 2142, 2171, 2192, 2202], "rdc": 16, "dc": 16, "anymor": [16, 30, 60], "dlto": 16, "dlink": 16, "protent": 16, "perf": [16, 681, 2161, 2198, 2204], "lib": [16, 2100, 2148], "nvshmem": 16, "ninja": [16, 2148], "dlink_librari": 16, "dlink_lib": 16, "std": [16, 30, 41, 49, 87, 377, 454, 1158, 1159, 1190, 1191, 1192, 1828, 1886, 1912, 1950, 1955, 1989, 2030, 2094, 2115, 2124, 2130, 2140, 2141, 2148, 2155, 2185, 2199], "17": [16, 30, 696, 1311, 1367, 1500, 1577, 1965, 2093, 2154, 2155, 2171, 2185, 2193], "mix": [16, 26, 30, 34, 36, 39, 60, 1089, 1770, 2125, 2127, 2129, 2137, 2161, 2171, 2191, 2193, 2195, 2204], "use_ninja": 16, "greatli": [16, 69, 2130, 2191, 2204], "fallback": [16, 22, 30, 51, 56, 63, 1245, 1328, 1378, 2100, 2117, 2126, 2130, 2147, 2150, 2154, 2189, 2195, 2205], "distutil": 16, "max_job": 16, "extra_cflag": 16, "extra_cuda_cflag": 16, "extra_ldflag": [16, 2130], "extra_include_path": 16, "build_directori": [16, 2130], "with_cuda": [16, 2130, 2148], "is_python_modul": [16, 2130], "is_standalon": 16, "keep_intermedi": 16, "torch_extens": 16, "temporari": [16, 69, 842, 851, 1772, 2127, 2135, 2185, 2197], "torch_extensions_dir": 16, "subfold": [16, 2205], "o3": 16, "cuh": 16, "Such": [16, 25, 26, 36, 56, 68, 2039, 2117, 2130, 2171, 2192], "lib64": 16, "cudart": [16, 2148], "fine": [16, 30, 32, 35, 40, 56, 486, 888, 891, 1195, 1330, 1738, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 2091, 2114, 2127, 2130, 2133, 2150, 2154, 2158, 2161, 2171, 2183, 2192, 2197, 2204, 2205], "cuda_hom": 16, "safest": 16, "pybind11": [16, 17, 2095], "linker": 16, "workspac": [16, 22, 1002], "header": [16, 37, 49, 2147, 2148, 2176, 2178], "construct": [16, 17, 25, 30, 32, 34, 35, 36, 37, 39, 51, 56, 57, 60, 62, 64, 65, 69, 71, 76, 77, 81, 82, 150, 448, 805, 806, 843, 908, 909, 923, 944, 956, 1016, 1131, 1147, 1213, 1277, 1314, 1326, 1330, 1331, 1338, 1345, 1385, 1386, 1401, 1416, 1522, 1523, 1580, 1641, 1642, 1643, 1677, 1760, 1770, 1773, 1774, 1813, 1820, 1877, 1882, 1886, 1933, 1968, 1976, 1977, 1978, 1979, 1980, 1981, 1995, 2011, 2014, 2045, 2093, 2100, 2104, 2109, 2122, 2130, 2132, 2136, 2142, 2144, 2147, 2158, 2161, 2166, 2168, 2174, 2176, 2177, 2178, 2185, 2192, 2195], "plain": [16, 1493, 1581, 1590, 1787, 1978, 2133, 2147, 2171, 2192, 2194], "standalon": [16, 50, 51, 52, 832, 1326, 1330, 2093, 2198, 2204], "torch_lib_path": 16, "load_inlin": [16, 2130], "cpp_sourc": [16, 2130], "cuda_sourc": 16, "with_pytorch_error_handl": 16, "use_pch": 16, "behav": [16, 17, 30, 56, 58, 68, 69, 313, 321, 493, 515, 517, 871, 1212, 1230, 1241, 1330, 1576, 1577, 1578, 1765, 1766, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 2095, 2096, 2100, 2103, 2127, 2133, 2134, 2142, 2146, 2158, 2166, 2171], "exactli": [16, 26, 30, 36, 39, 54, 56, 57, 58, 233, 895, 949, 950, 996, 1051, 1056, 1144, 1190, 1191, 1234, 1311, 1314, 1356, 1523, 1526, 1527, 1528, 1580, 1609, 1612, 1678, 1688, 1770, 1827, 1835, 1877, 1936, 2103, 2104, 2115, 2127, 2130, 2132, 2133, 2136, 2138, 2139, 2150, 2154, 2158, 2189, 2192], "filenam": [16, 21, 25, 32, 56, 69, 1196, 1313, 1322, 1325, 2091, 2094, 2107, 2127, 2149, 2158, 2173, 2176, 2197, 2207], "typic": [16, 25, 26, 30, 34, 36, 39, 40, 41, 44, 51, 52, 54, 57, 58, 60, 69, 87, 486, 1004, 1027, 1037, 1187, 1195, 1236, 1242, 1314, 1335, 1338, 1386, 1513, 1539, 1580, 1760, 1770, 1840, 1841, 1859, 1877, 1936, 1948, 1976, 1977, 1978, 1980, 1981, 2091, 2092, 2093, 2096, 2102, 2104, 2127, 2129, 2130, 2137, 2145, 2146, 2147, 2150, 2154, 2157, 2161, 2166, 2173, 2175, 2177, 2188, 2190, 2191, 2194, 2202, 2204, 2205, 2207, 2210], "inlin": [16, 30, 56, 58, 68, 71, 77, 1015, 1086, 1314, 1318, 1330, 2129, 2150, 2195, 2204], "concaten": [16, 25, 30, 34, 37, 940, 989, 1000, 1053, 1143, 1228, 1280, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1523, 1550, 1670, 1678, 1776, 1785, 1793, 1987, 2047, 2094, 2097, 2154, 2155, 2171], "furthermor": [16, 49, 64, 1350, 1351, 1378, 1404, 1517, 2115, 2116, 2127, 2146, 2164, 2166], "cuda_runtim": 16, "se": 16, "macro": [16, 41, 2139], "pybind": 16, "_safe_foo": 16, "redirect": [16, 41, 49, 53, 2131, 2180], "obscur": 16, "sin_add": 16, "inline_extens": 16, "toolchain": 16, "toolkit": [16, 36, 69], "include_path": 16, "sycl": [16, 2137], "get_compiler_abi_compatibility_and_vers": 16, "abi": [16, 17, 2125], "alongsid": [16, 1314, 1580, 1877, 2117, 2133, 2180], "shell": 16, "torchvers": 16, "verify_ninja_avail": 16, "is_ninja_avail": 16, "embed": [17, 34, 36, 37, 38, 57, 69, 746, 757, 928, 1135, 1484, 1513, 1523, 1539, 1552, 1586, 1630, 1678, 1738, 1860, 1931, 2094, 2122, 2129, 2130, 2136, 2155, 2159, 2161, 2163, 2166, 2171, 2176, 2199], "simpl": [17, 20, 26, 30, 36, 37, 44, 51, 56, 64, 66, 69, 488, 1027, 1101, 1203, 1211, 1212, 1213, 1314, 1318, 1326, 1494, 1495, 1496, 1522, 1553, 1554, 1555, 1580, 1620, 1677, 1877, 1948, 2045, 2091, 2093, 2097, 2117, 2129, 2130, 2132, 2133, 2135, 2138, 2140, 2149, 2154, 2158, 2166, 2171, 2192, 2193, 2194, 2197], "modif": [17, 36, 60, 69, 221, 791, 930, 931, 935, 1197, 1198, 1314, 1580, 1770, 1877, 2122, 2127, 2133, 2142, 2158, 2161, 2192, 2195, 2204], "submodul": [17, 32, 34, 36, 38, 56, 57, 60, 69, 804, 811, 829, 866, 868, 869, 888, 891, 892, 1211, 1314, 1318, 1320, 1325, 1326, 1516, 1580, 1581, 1582, 1609, 1767, 1877, 2093, 2095, 2096, 2106, 2142, 2147, 2158, 2161, 2166, 2182, 2190, 2203], "preprocess": [17, 56, 496, 1314, 2204], "augment": [17, 2097, 2178], "walk": [17, 69, 2100, 2133, 2158, 2167, 2168, 2175, 2205], "interfac": [17, 21, 26, 32, 40, 41, 43, 48, 51, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 756, 757, 767, 772, 773, 774, 775, 776, 807, 1198, 1760, 1935, 1990, 2033, 2096, 2100, 2109, 2110, 2112, 2113, 2117, 2130, 2133, 2140, 2157, 2159, 2164, 2171, 2176, 2199], "opencv": [17, 1686, 1697], "struct": [17, 1212, 1213, 2045, 2106, 2140], "explain": [17, 30, 56, 58, 1860, 1936, 2091, 2096, 2126, 2130, 2134, 2136, 2144, 2171, 2192, 2195, 2204, 2205], "reshap": [17, 30, 39, 498, 499, 513, 544, 617, 703, 1000, 1127, 1142, 1143, 1183, 1278, 1335, 1367, 1371, 1380, 1381, 1384, 1476, 1501, 1502, 1526, 1602, 1603, 1604, 1605, 1606, 1632, 1788, 1821, 1827, 1973, 1975, 1982, 2012, 2013, 2018, 2046, 2047, 2094, 2103, 2116, 2154, 2155, 2163, 2175, 2176, 2199], "classat_1_1_tensor": 17, "tensor_index": 17, "crucial": [17, 87, 2185, 2197, 2198, 2204], "cpp_autograd": 17, "workflow": [17, 2091, 2133, 2137, 2161, 2162, 2180, 2183, 2191, 2194, 2198, 2200, 2201, 2204], "undesir": [17, 36, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1738, 1990, 2133], "overview": [17, 30, 48, 1640, 1770, 2103, 2114, 2127, 2138, 2142, 2152, 2161, 2166, 2183, 2187, 2204], "cpp_frontend": 17, "library_root": 17, "linux": [17, 30, 2091, 2137], "gcc": 17, "pre": [17, 30, 34, 35, 37, 56, 60, 69, 944, 955, 1214, 1226, 1251, 1314, 1580, 1764, 1766, 1778, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1803, 1805, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1848, 1850, 1852, 1856, 1857, 1858, 1859, 1860, 1862, 1869, 1877, 2091, 2093, 2096, 2106, 2117, 2127, 2129, 2130, 2137, 2142, 2177, 2194, 2195, 2200, 2205], "cxx11": 17, "facilit": [18, 31, 39, 65, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1040, 1132, 1779, 1780, 1933, 2091, 2093, 2096, 2146], "use_mem_pool": [19, 2130], "pool": [19, 68, 777, 778, 779, 780, 793, 794, 1037, 1041, 1042, 1078, 1079, 1089, 1101, 1423, 1425, 1481, 1482, 1483, 1485, 1486, 1487, 1489, 1490, 1491, 1527, 1528, 1547, 1548, 1549, 1573, 1574, 1575, 1576, 1577, 1578, 1581, 1645, 1646, 1647, 1648, 1649, 1650, 1653, 1654, 1655, 1681, 1682, 1707, 1708, 1709, 1711, 1712, 1713, 1897, 1898, 2078, 2129, 2130, 2133, 2142, 2144, 2163, 2166, 2189], "rout": [19, 21, 1041, 1042, 2192], "mempool": [19, 1042, 2130], "current_devic": [19, 30, 32, 60, 684, 1050, 1060, 1061, 1064, 1069, 1070, 1071, 1088, 1092, 1094, 1095, 1097, 1099, 1101, 1102, 1103, 1108, 1109, 1110, 1111, 1120, 1121, 1122, 1447, 1448, 1452, 1457, 1458, 2036, 2054, 2060, 2061, 2073, 2074, 2075, 2076, 2077, 2078, 2080, 2081, 2088, 2174, 2193, 2204], "tunabl": 19, "gd": 19, "thin": [19, 1787, 1892], "wrapper": [19, 26, 30, 39, 53, 60, 68, 69, 71, 625, 768, 803, 843, 1028, 1037, 1039, 1040, 1118, 1190, 1191, 1211, 1217, 1314, 1427, 1462, 1516, 2050, 2087, 2093, 2095, 2096, 2100, 2109, 2114, 2130, 2132, 2154, 2189, 2204], "cufil": 19, "bounc": 19, "12": [19, 25, 26, 30, 37, 60, 321, 517, 617, 697, 752, 753, 754, 756, 757, 965, 992, 996, 1142, 1160, 1278, 1318, 1334, 1351, 1373, 1484, 1500, 1511, 1526, 1527, 1528, 1577, 1592, 1593, 1615, 1624, 1632, 1640, 1681, 1682, 1723, 1728, 1729, 1788, 1821, 1881, 1892, 1940, 1955, 1965, 2012, 2028, 2031, 2046, 2091, 2093, 2094, 2097, 2103, 2117, 2130, 2133, 2136, 2143, 2147, 2154, 2155, 2171, 2173, 2178, 2186, 2189, 2192, 2193, 2201, 2202], "gdsfile": 19, "earli": [20, 26, 30, 41, 68, 486, 1518, 1519, 1520, 1524, 2092, 2147, 2161, 2162, 2181, 2182, 2194, 2204], "race": [20, 30, 486, 2127], "enable_cuda_sanit": 20, "torch_cuda_sanit": 20, "concurr": [20, 30, 35, 36, 2129, 2130, 2136, 2144, 2166, 2167], "uniniti": [20, 29, 37, 445, 499, 1145, 1146, 1760, 1773, 1774, 1820, 2033, 2104, 2155], "overwrit": [20, 21, 25, 30, 32, 37, 69, 1057, 1581, 1590, 2096, 2127, 2189], "commandlin": 20, "example_error": 20, "csan": 20, "pointer": [20, 139, 956, 1058, 1597, 2100, 2130, 2132, 2140, 2141, 2166, 2168, 2194], "139719969079296": 20, "94646435460352": 20, "_sanit": 20, "364": 20, "_handle_kernel_launch": 20, "stack_trac": [20, 57, 69], "stacksummari": 20, "extract": [20, 37, 69, 813, 864, 994, 995, 1251, 1522, 1526, 1632, 1677, 1756, 2166, 2182, 2188, 2190, 2192, 2193, 2195, 2196, 2204], "10000": [20, 22, 26, 705, 1872, 1921, 2135, 2142, 2171, 2176, 2197], "420": 20, "_handle_memory_alloc": 20, "incorrectli": [20, 60, 1040, 1189, 2196, 2204], "id": [20, 22, 25, 30, 32, 35, 36, 41, 45, 49, 50, 51, 52, 60, 69, 785, 813, 843, 965, 1037, 1041, 1079, 1620, 1713, 1753, 1770, 1834, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 2096, 2140, 2155, 2158, 2159, 2165, 2166, 2167, 2173, 2201, 2204, 2205], "faulti": [20, 30], "schema": [20, 30, 32, 57, 2093, 2094, 2096, 2100, 2117, 2133, 2141, 2150, 2154, 2199, 2203], "current_stream": [20, 1039, 2050, 2130], "wait_stream": [20, 30, 88, 486, 1040, 2130], "default_stream": [20, 30, 2130], "begin": [20, 25, 26, 30, 31, 32, 36, 43, 51, 60, 69, 496, 681, 771, 795, 839, 840, 895, 971, 1007, 1022, 1037, 1092, 1094, 1105, 1164, 1268, 1274, 1335, 1370, 1382, 1491, 1492, 1493, 1501, 1502, 1503, 1513, 1515, 1521, 1531, 1532, 1535, 1536, 1537, 1538, 1539, 1540, 1546, 1550, 1551, 1566, 1571, 1574, 1575, 1587, 1588, 1596, 1599, 1612, 1618, 1623, 1630, 1669, 1690, 1691, 1770, 1787, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1863, 1865, 1872, 1940, 1943, 1946, 1990, 2018, 2029, 2048, 2073, 2074, 2096, 2117, 2126, 2127, 2130, 2133, 2136, 2138, 2140, 2146, 2154, 2157, 2164, 2172, 2173, 2189, 2195, 2204, 2205], "suspect": [20, 1860, 2130, 2204, 2205], "blaslt": 21, "rocbla": [21, 2145], "databas": [21, 25], "prepar": [21, 32, 36, 38, 60, 69, 811, 868, 871, 887, 889, 891, 892, 893, 1211, 1324, 2097, 2154, 2181, 2182], "tunableop_result": 21, "csv": [21, 1057], "ordin": [21, 289, 1976, 1977, 1978, 1980, 1981, 2174], "insert": [21, 25, 30, 39, 60, 68, 69, 758, 805, 806, 891, 892, 969, 1581, 1582, 1590, 1770, 1928, 1931, 1940, 1961, 1987, 2032, 2093, 2106, 2130, 2155, 2161, 2202, 2203, 2204], "discov": [21, 30, 1002, 2166, 2184], "termin": [21, 30, 37, 41, 51, 54, 57, 69, 1843, 2114, 2166, 2197], "pt_version": 21, "rocm_vers": [21, 2139], "12969": 21, "1544e39": 21, "hipblaslt_vers": 21, "a9c5cc7": 21, "rocblas_vers": 21, "72e57364": 21, "dirti": [21, 2127, 2192], "gemmtunableop_float_nt": 21, "nt_25088_4096_64": 21, "1219": [21, 1374, 1911], "262": 21, "nt_4096_4096_64": 21, "1216": [21, 1465], "033": 21, "reject": 21, "comma": [21, 22, 30, 1144, 2096, 2102], "averag": [21, 30, 35, 746, 777, 778, 779, 780, 840, 841, 962, 964, 1027, 1108, 1121, 1314, 1481, 1482, 1483, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1513, 1515, 1523, 1533, 1539, 1545, 1546, 1547, 1548, 1549, 1553, 1554, 1555, 1571, 1572, 1580, 1583, 1584, 1585, 1586, 1587, 1594, 1612, 1613, 1620, 1629, 1645, 1646, 1647, 1653, 1654, 1655, 1658, 1659, 1669, 1683, 1698, 1707, 1708, 1709, 1722, 1730, 1770, 1836, 1837, 1838, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1877, 1878, 2018, 2132, 2159], "edit": [21, 69, 2158, 2175], "caution": [21, 49, 1014, 2196], "untun": 21, "gemmtunableop": 21, "transpos": [21, 460, 593, 594, 617, 703, 752, 753, 754, 994, 995, 1144, 1212, 1344, 1345, 1351, 1354, 1357, 1364, 1375, 1378, 1510, 1511, 1512, 1596, 1632, 1664, 1665, 1666, 1738, 1781, 1782, 1787, 1880, 1994, 1996, 1997, 2006, 2020, 2094, 2115, 2117, 2124, 2127, 2145, 2154, 2155, 2163, 2171, 2175, 2177, 2199], "k": [21, 25, 30, 32, 39, 52, 58, 69, 286, 354, 506, 513, 515, 517, 590, 617, 771, 969, 995, 1131, 1144, 1201, 1221, 1228, 1255, 1277, 1336, 1344, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1360, 1361, 1364, 1366, 1373, 1375, 1377, 1378, 1387, 1394, 1405, 1409, 1489, 1491, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1527, 1528, 1531, 1532, 1550, 1551, 1565, 1567, 1568, 1573, 1575, 1586, 1587, 1596, 1598, 1640, 1669, 1681, 1682, 1704, 1722, 1787, 1880, 1882, 1892, 1920, 1970, 1971, 1972, 1973, 1976, 1977, 1978, 1980, 1981, 1990, 1995, 2015, 2020, 2094, 2095, 2111, 2124, 2130, 2133, 2148, 2157, 2171, 2172, 2174, 2195, 2198, 2199, 2205], "diagnost": [21, 44, 681, 2093, 2150], "besid": [21, 26, 30, 37, 958, 2130, 2132, 2176, 2190], "pytorch_tunableop_verobs": 21, "30m": 21, "whichev": [21, 1027, 1213, 1686, 1893, 2045, 2130], "successfulli": [21, 30, 41, 48, 56, 1321, 1937, 2114, 2142, 2147, 2166, 2186, 2204, 2205], "bgemm": 21, "transa": 21, "transb": [21, 2154], "gettuningcontext": 21, "tuningcontext": 21, "preced": [21, 35, 41, 60, 67, 681, 1764, 1872, 2017, 2097, 2129, 2157, 2161, 2179], "val": [21, 57, 71, 74, 79, 1086, 1228, 1243, 1244, 1320, 1321, 2094, 2096, 2100, 2124, 2194], "is_en": [21, 1968, 1976, 1977, 1978, 1979, 1980, 1981], "tuning_en": 21, "tuning_is_en": 21, "record_untuned_en": 21, "perat": 21, "offlin": [21, 32, 1325], "record_untuned_is_en": 21, "set_max_tuning_dur": 21, "millisecond": [21, 45, 48, 86, 1039, 1427, 1443, 2050, 2109], "honor": [21, 2096], "get_max_tuning_dur": 21, "set_max_tuning_iter": 21, "get_max_tuning_iter": 21, "set_filenam": 21, "insert_device_ordin": 21, "cenario": 21, "get_filenam": 21, "get_result": 21, "get_valid": 21, "write_file_on_exit": 21, "destruct": [21, 30, 2109, 2166, 2168], "write_fil": 21, "read_fil": 21, "tune_gemm_in_fil": 21, "mgpu_tune_gemm_in_fil": 21, "filename_pattern": 21, "num_gpu": [21, 2136], "pytorch_no_cuda_memory_cach": [22, 2130, 2139], "pytorch_cuda_alloc_conf": [22, 1067], "pytorch_nvml_based_cuda_check": [22, 2130, 2180], "nvml": [22, 2130], "fork": [22, 25, 49, 1057, 1333, 1770, 2096, 2129, 2130, 2135, 2140, 2144, 2148, 2165, 2166, 2168, 2180], "torch_cudnn_v8_api_lru_cache_limit": 22, "cudnn": [22, 23, 24, 771, 1324, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1531, 1550, 1596, 1597, 1639, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1738, 1779, 1780, 1936, 2094, 2130, 2145, 2146, 2198, 2208], "roughli": [22, 25, 1545, 2132, 2202, 2203], "2gib": 22, "200kib": 22, "executionplan": 22, "torch_cudnn_v8_api_dis": 22, "And": [22, 41, 56, 64, 684, 811, 843, 1123, 1124, 1201, 1235, 1314, 1336, 1412, 1417, 1499, 1580, 1877, 2034, 2036, 2127, 2133, 2134, 2136, 2148, 2154, 2161, 2182, 2190, 2192, 2196, 2197], "v7": 22, "torch_allow_tf32_cublas_overrid": 22, "set_float32_matmul_precis": [22, 1264], "torch_nccl_use_comm_nonblock": 22, "nccl": [22, 26, 31, 32, 34, 52, 60, 1770, 2136, 2139, 2209], "torch_nccl_avoid_record_stream": 22, "stream": [22, 25, 30, 34, 41, 49, 60, 68, 86, 150, 486, 687, 692, 693, 923, 944, 1029, 1031, 1035, 1037, 1039, 1040, 1045, 1046, 1047, 1056, 1057, 1060, 1061, 1078, 1084, 1118, 1120, 1427, 1433, 1434, 1440, 1443, 1445, 1447, 1448, 1462, 1464, 1914, 2050, 2052, 2054, 2087, 2088, 2094, 2096, 2136, 2139, 2141, 2166, 2180, 2195, 2207, 2209], "torch_cudnn_v8_api_debug": 22, "saniti": [22, 32, 37, 2134], "cuda_visible_devic": [22, 30, 1114, 1770, 2130], "cuda_launch_block": [22, 24, 1550, 1596, 2130], "cublas_workspace_config": [22, 24, 1550, 1596, 2033, 2130, 2139, 2146], "4096": [22, 24, 56, 1550, 1596, 2033, 2130, 2139, 2154], "16": [22, 24, 30, 37, 38, 56, 58, 321, 617, 749, 750, 751, 752, 753, 754, 783, 1142, 1160, 1187, 1268, 1278, 1314, 1326, 1338, 1344, 1350, 1351, 1355, 1371, 1476, 1488, 1490, 1491, 1499, 1500, 1503, 1506, 1507, 1508, 1509, 1511, 1512, 1517, 1518, 1519, 1520, 1524, 1527, 1528, 1547, 1548, 1549, 1550, 1568, 1573, 1574, 1575, 1577, 1578, 1580, 1587, 1596, 1607, 1624, 1638, 1661, 1663, 1664, 1666, 1670, 1681, 1682, 1830, 1877, 1889, 1936, 1965, 2033, 2042, 2046, 2093, 2097, 2100, 2124, 2130, 2139, 2142, 2145, 2147, 2154, 2155, 2166, 2171, 2172, 2174, 2176, 2177, 2185, 2186, 2192, 2193], "kib": [22, 2130, 2139], "cudnn_conv_wscap_dbg": 22, "cublaslt_workspace_s": 22, "cudnn_errata_json_fil": 22, "errata": 22, "config": [22, 26, 30, 60, 69, 805, 806, 807, 808, 889, 891, 1002, 2117, 2132, 2148, 2164, 2183, 2185, 2186, 2189, 2195, 2197, 2198, 2200, 2202, 2204, 2205], "primarili": [22, 39, 57, 68, 830, 831, 832, 842, 1228, 1237, 1476, 2109, 2122, 2161, 2177, 2204], "hardcod": [22, 2194], "autotun": [22, 1002, 2198, 2204], "nvidia_tf32_overrid": 22, "float16": [23, 26, 32, 60, 297, 697, 700, 771, 842, 851, 861, 880, 881, 888, 970, 982, 1197, 1296, 1314, 1409, 1419, 1507, 1508, 1509, 1510, 1511, 1512, 1531, 1532, 1550, 1551, 1567, 1580, 1596, 1640, 1697, 1738, 1779, 1780, 1839, 1840, 1841, 1859, 1877, 1921, 1933, 2122, 2126, 2137, 2142, 2161, 2163, 2171, 2173, 2174, 2177, 2178, 2210], "v100": [23, 771, 1531, 1550, 1596, 2130], "packedsequ": [23, 771, 1531, 1550, 1596, 1814, 1815, 1816, 1818], "rnn": [24, 745, 771, 772, 773, 774, 776, 888, 1531, 1532, 1550, 1551, 1597, 1598, 1772, 1791, 1813, 2098, 2135, 2142, 2156, 2163, 2176], "enforc": [24, 25, 26, 68, 808, 920, 935, 1314, 1550, 1580, 1596, 1838, 1877, 2096, 2142, 2175], "colon": [24, 1550, 1596, 2166], "heart": 25, "dataload": [25, 496, 1770, 1864, 1865, 1872, 2130, 2135, 2137, 2144, 2148, 2157, 2176, 2180], "batch_siz": [25, 36, 39, 64, 66, 922, 935, 936, 1203, 1211, 1213, 1586, 1596, 1813, 1815, 1816, 1818, 2045, 2094, 2100, 2117, 2134, 2135, 2137, 2146, 2154, 2176], "shuffl": [25, 1500, 2176], "batch_sampl": 25, "num_work": [25, 41, 2146, 2148], "drop_last": 25, "timeout": [25, 30, 41, 51, 2105, 2114, 2166, 2209], "worker_init_fn": [25, 2135, 2146], "prefetch_factor": 25, "persistent_work": 25, "__getitem__": [25, 2033], "__len__": [25, 69, 2094], "protocol": [25, 32, 40, 54, 910, 1195, 1198, 1924, 2133, 2148, 2154, 2166, 2206], "sampl": [25, 32, 39, 56, 61, 66, 69, 87, 153, 154, 258, 286, 377, 454, 481, 608, 790, 972, 1027, 1050, 1089, 1103, 1108, 1121, 1122, 1162, 1180, 1203, 1213, 1268, 1311, 1331, 1404, 1466, 1488, 1492, 1493, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1515, 1517, 1518, 1519, 1520, 1522, 1523, 1524, 1533, 1539, 1542, 1543, 1544, 1545, 1546, 1565, 1567, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1599, 1612, 1613, 1620, 1629, 1651, 1658, 1659, 1669, 1671, 1672, 1673, 1674, 1677, 1678, 1679, 1683, 1686, 1688, 1695, 1696, 1697, 1698, 1718, 1722, 1730, 1738, 1770, 1788, 1828, 1864, 1882, 1885, 1899, 1901, 1903, 1905, 1906, 1907, 1948, 1971, 1988, 1989, 1990, 2040, 2041, 2045, 2100, 2109, 2124, 2126, 2130, 2140, 2142, 2158, 2159, 2161, 2162, 2176, 2186, 2205], "idx": [25, 69, 930, 932, 935, 1314, 1320, 1484, 1522, 1580, 1788, 1877, 2029, 2094, 2116], "th": [25, 39, 154, 286, 313, 315, 321, 771, 938, 940, 972, 992, 1131, 1136, 1289, 1311, 1336, 1354, 1362, 1368, 1404, 1518, 1519, 1520, 1524, 1531, 1539, 1550, 1596, 1672, 1673, 1674, 1679, 1893, 1990, 2031, 2117, 2133, 2148, 2172, 2174, 2207], "iterabledataset": [25, 2140], "__iter__": [25, 2097], "suitabl": [25, 39, 486, 986, 1334, 1860, 1928, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2145, 2162, 2176, 2196], "improb": 25, "fetch": [25, 68, 69, 1226, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1833, 2166], "remot": [25, 30, 35, 41, 1770, 2166, 2167], "real": [25, 36, 39, 58, 69, 697, 698, 699, 700, 701, 703, 709, 949, 970, 994, 995, 1016, 1023, 1089, 1160, 1161, 1163, 1165, 1166, 1167, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1216, 1228, 1245, 1304, 1306, 1307, 1310, 1311, 1335, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1357, 1358, 1359, 1364, 1367, 1369, 1371, 1372, 1373, 1374, 1378, 1379, 1383, 1384, 1385, 1395, 1401, 1546, 1589, 1592, 1593, 1630, 1787, 1843, 1905, 1990, 1994, 2042, 2043, 2044, 2091, 2094, 2096, 2100, 2104, 2127, 2130, 2155, 2158, 2161, 2166, 2168, 2175, 2177, 2178, 2190, 2191, 2192, 2194, 2197, 2199, 2204, 2206], "replica": [25, 26, 30, 35, 37, 49, 1516, 1770, 2132], "duplic": [25, 49, 315, 319, 471, 544, 681, 971, 980, 1001, 1228, 1272, 1273, 1314, 1580, 1877, 2029, 2030, 2157, 2171], "yield": [25, 26, 56, 60, 69, 1132, 1134, 1314, 1361, 1362, 1580, 1877, 2048, 2096, 2097, 2103, 2161, 2172, 2195], "stochast": [25, 39, 1527, 1528, 1681, 1682, 1836, 1839, 1840, 1842, 1859, 1863, 1864, 1877, 1878, 2142, 2157], "decent": 25, "randomli": [25, 756, 757, 767, 775, 950, 1488, 1517, 1518, 1519, 1520, 1524, 1599, 1671, 1672, 1673, 1674, 1679, 1801, 2140, 2142], "permut": [25, 71, 80, 1144, 1361, 1362, 1381, 1404, 1406, 1779, 1780, 1907, 2094, 2116, 2155, 2163, 2175, 2177, 2199], "mini": [25, 790, 796, 1494, 1495, 1496, 1522, 1523, 1534, 1539, 1542, 1543, 1544, 1552, 1572, 1583, 1585, 1595, 1620, 1629, 1677, 1678, 1697, 1757, 1769], "neither": [25, 30, 808, 929, 930, 933, 935, 1127, 1187, 1586, 1628, 1827, 2018, 2133, 2145, 2166], "nor": [25, 30, 41, 60, 808, 930, 933, 935, 1228, 1350, 1351, 1378, 1586, 1628, 1770, 1827, 1891, 1994, 2133, 2189, 2194], "notion": [25, 949, 1494, 1495, 1496, 1542, 1543, 1544, 1620, 2192, 2195], "collat": 25, "minibatch": [25, 779, 780, 783, 784, 785, 1404, 1484, 1492, 1493, 1513, 1515, 1539, 1545, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1633, 1653, 1654, 1655, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1669, 1698, 1711, 1712, 1713, 1722, 1730], "loader": [25, 1877, 1878, 2157, 2185], "essenti": [25, 30, 41, 69, 1404, 2116, 2122, 2130, 2137, 2148, 2171, 2185, 2189, 2204], "dummi": [25, 35, 2100, 2127, 2133, 2205, 2206], "infinit": [25, 1306, 1387, 1492, 1499, 1670, 1886, 2133, 2145, 2166, 2194], "drop": [25, 64, 66, 69, 1089, 1319, 1373, 1378, 1488, 1822, 1936, 1990, 2093, 2116, 2144, 2151, 2207], "dataset_it": 25, "pad": [25, 26, 56, 723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 746, 749, 750, 751, 752, 753, 754, 779, 780, 783, 784, 785, 790, 793, 794, 796, 1002, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1311, 1489, 1490, 1491, 1499, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1522, 1523, 1526, 1556, 1557, 1558, 1559, 1560, 1561, 1573, 1574, 1575, 1576, 1577, 1578, 1583, 1586, 1602, 1603, 1604, 1605, 1606, 1607, 1627, 1628, 1632, 1636, 1637, 1638, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1677, 1678, 1680, 1686, 1697, 1711, 1712, 1713, 1714, 1715, 1716, 1756, 1757, 1814, 1816, 1817, 1819, 1897, 1898, 1990, 2094, 2135, 2147, 2154, 2155, 2161, 2176, 2189, 2191, 2199], "length": [25, 26, 30, 32, 34, 38, 39, 58, 260, 313, 315, 321, 351, 433, 434, 583, 584, 585, 746, 771, 829, 923, 944, 966, 1001, 1056, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1198, 1213, 1289, 1311, 1330, 1334, 1475, 1476, 1494, 1499, 1507, 1516, 1523, 1526, 1531, 1547, 1550, 1586, 1596, 1624, 1632, 1641, 1661, 1662, 1663, 1670, 1678, 1697, 1738, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1899, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1973, 1976, 1977, 1978, 1980, 1981, 1990, 2018, 2045, 2094, 2096, 2103, 2116, 2117, 2122, 2128, 2135, 2170, 2171, 2173, 2178, 2191, 2192, 2195, 2199, 2205], "cheaper": [25, 68], "bulk": [25, 2194], "arrai": [25, 30, 37, 448, 771, 839, 840, 909, 910, 973, 991, 1023, 1027, 1144, 1188, 1197, 1198, 1206, 1207, 1386, 1416, 1526, 1531, 1532, 1550, 1551, 1680, 1914, 1921, 1940, 1976, 1977, 1978, 1980, 1981, 2008, 2011, 2018, 2026, 2039, 2093, 2097, 2117, 2130, 2142, 2147, 2171, 2173, 2177, 2178, 2195], "untouch": 25, "slightli": [25, 30, 39, 56, 60, 1827, 1882, 1995, 2091, 2130, 2133, 2136, 2138, 2145, 2158, 2195], "default_col": 25, "channel": [25, 63, 472, 473, 474, 790, 796, 823, 841, 846, 860, 875, 883, 1158, 1494, 1495, 1496, 1500, 1507, 1508, 1509, 1510, 1511, 1512, 1517, 1518, 1519, 1520, 1524, 1526, 1534, 1542, 1543, 1544, 1552, 1556, 1557, 1558, 1559, 1560, 1561, 1568, 1588, 1615, 1620, 1632, 1633, 1634, 1635, 1656, 1672, 1673, 1674, 1679, 1696, 1697, 1704, 1731, 1757, 1779, 1780, 1789, 1799, 1800, 1801, 1807, 1808, 1824, 1894, 2116, 2118, 2124, 2127, 2161, 2162, 2164, 2176], "class_index": 25, "namedtupl": [25, 32, 56, 57, 58, 69, 924, 929, 1123, 1124, 1258, 1314, 1326, 1336, 1356, 1406, 1412, 1415, 1417, 1420, 1472, 1484, 1580, 1877, 1882, 1892, 1965, 1994, 2015, 2020, 2093, 2095, 2096, 2161], "situat": [25, 39, 54, 69, 486, 1002, 1023, 1793, 2104, 2114, 2117, 2133, 2134, 2144, 2145, 2158, 2161, 2168, 2184, 2191, 2194, 2195, 2206], "gil": [25, 30, 35, 2127, 2130, 2166], "integ": [25, 29, 30, 37, 39, 51, 56, 57, 58, 87, 289, 445, 447, 449, 499, 545, 560, 566, 696, 697, 698, 699, 700, 701, 777, 778, 796, 798, 895, 922, 935, 936, 970, 971, 980, 991, 1022, 1040, 1062, 1069, 1070, 1101, 1139, 1142, 1144, 1145, 1146, 1147, 1187, 1188, 1189, 1190, 1191, 1192, 1198, 1199, 1203, 1204, 1205, 1206, 1207, 1228, 1238, 1247, 1248, 1249, 1256, 1272, 1273, 1276, 1277, 1278, 1325, 1328, 1337, 1338, 1345, 1356, 1358, 1368, 1387, 1449, 1465, 1484, 1499, 1507, 1508, 1509, 1552, 1595, 1645, 1646, 1647, 1648, 1649, 1650, 1759, 1769, 1813, 1828, 1831, 1868, 1871, 1875, 1882, 1894, 1895, 1901, 1903, 1904, 1905, 1907, 1912, 1921, 1933, 1982, 1991, 1995, 2005, 2012, 2013, 2026, 2031, 2046, 2055, 2060, 2061, 2078, 2089, 2095, 2096, 2097, 2100, 2115, 2134, 2138, 2161, 2162, 2164, 2171, 2172, 2173, 2174, 2177, 2178, 2180, 2191, 2192, 2210], "descriptor": [25, 30, 1629, 1630, 2097], "parent": [25, 44, 49, 54, 60, 681, 800, 802, 832, 1580, 2108, 2114, 2148, 2158, 2168, 2176, 2192], "simplest": [25, 30, 32, 41, 69, 888, 1489, 1490, 1491, 1507, 1508, 1509, 1573, 1574, 1575, 1791, 2132, 2133, 2142, 2150, 2161, 2168, 2171, 2195], "refcount": [25, 2114, 2144], "panda": 25, "pyarrow": 25, "13246": 25, "enumer": [25, 36, 39, 56, 69, 1015, 1314, 1580, 1582, 1591, 1864, 1877, 2094, 2095, 2126, 2130, 2137, 2148, 2176, 2203], "get_worker_info": [25, 2166], "seed": [25, 87, 1081, 1090, 1091, 1113, 1290, 1407, 1429, 1882, 1899, 1995, 2036, 2068, 2071, 2072, 2083, 2094, 2135, 2144, 2146, 2155, 2165], "naiv": [25, 2145, 2191, 2195], "shut": [25, 2166], "garbag": [25, 2111, 2168], "subtleti": [25, 71, 1516, 2133, 2135], "multiprocess": [25, 26, 30, 31, 33, 41, 44, 52, 53, 54, 1516, 1770, 2116, 2125, 2132, 2167, 2173, 2204], "unix": [25, 42, 49, 2114], "child": [25, 30, 36, 41, 44, 60, 804, 1314, 1580, 1800, 1877, 2114, 2142, 2148, 2168], "address": [25, 30, 51, 55, 65, 216, 949, 950, 1047, 2103, 2114, 2117, 2130, 2133, 2151, 2157, 2166, 2167, 2173, 2189, 2192, 2204, 2207], "maco": [25, 30, 2114, 2143], "spawn": [25, 26, 31, 41, 43, 49, 54, 1317, 1770, 2126, 2132, 2144, 2148, 2167], "__name__": [25, 26, 30, 42, 43, 44, 45, 52, 2132, 2133, 2144, 2147, 2148, 2158, 2167, 2186], "__main__": [25, 26, 30, 42, 43, 44, 52, 2128, 2132, 2144, 2147, 2148, 2167, 2186], "bytecod": [25, 56, 58, 681, 2102, 2149, 2150, 2158, 2190, 2192, 2193, 2195, 2205], "base_se": 25, "worker_id": [25, 54, 2146], "therebi": [25, 39, 2157, 2161], "mandatorili": 25, "faq": [25, 1516, 1816, 2125, 2204], "initial_se": [25, 87, 2094, 2146, 2155, 2165], "host": [25, 30, 34, 36, 37, 41, 44, 50, 51, 52, 54, 88, 196, 209, 580, 603, 623, 907, 1314, 1580, 1770, 1793, 1826, 1877, 2130, 2166, 2167, 2173, 2180, 2189, 2194, 2207], "recogn": [25, 2096, 2117, 2166, 2171, 2194], "simplecustombatch": 25, "transposed_data": 25, "zip": [25, 32, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 2091, 2094, 2095, 2107, 2130, 2140, 2147, 2157, 2171], "tgt": [25, 1624, 1625, 1626], "collate_wrapp": 25, "float32": [25, 26, 30, 56, 60, 267, 580, 617, 837, 839, 840, 841, 846, 851, 910, 1016, 1158, 1159, 1197, 1261, 1264, 1296, 1480, 1493, 1500, 1633, 1634, 1635, 1653, 1839, 1840, 1841, 1859, 1886, 1891, 1903, 1918, 1933, 1934, 1936, 1979, 2043, 2117, 2126, 2130, 2145, 2147, 2149, 2150, 2151, 2154, 2163, 2171, 2172, 2173, 2174, 2177, 2178, 2192, 2193, 2195, 2204, 2205, 2210], "tensordataset": 25, "batch_ndx": 25, "is_pin": [25, 1813, 2094, 2115, 2155, 2173], "multiprocessing_context": 25, "pin_memory_devic": 25, "in_ord": 25, "reshuffl": 25, "draw": [25, 39, 154, 286, 972, 1108, 1466, 1899, 2176, 2202], "mutual": [25, 30, 41, 60, 746, 2178], "subprocess": [25, 30, 33, 49, 51, 54, 1057, 2135, 2144, 2180], "incomplet": [25, 938, 2098, 2117, 2172], "divis": [25, 34, 37, 56, 583, 617, 698, 783, 784, 785, 996, 1139, 1189, 1192, 1325, 1358, 1507, 1508, 1509, 1510, 1511, 1512, 1514, 1534, 1546, 1571, 1589, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1723, 1912, 1982, 2012, 2096, 2126, 2130], "basecontext": 25, "randomsampl": 25, "prefetch": [25, 34, 60], "unpickl": [25, 30, 1386, 2147, 2158], "practic": [25, 30, 36, 38, 39, 57, 60, 486, 2093, 2103, 2114, 2116, 2125, 2127, 2133, 2136, 2138, 2142, 2147, 2158, 2166, 2173, 2180, 2183, 2192, 2194, 2195, 2204], "proper": [25, 37, 41, 68, 69, 1135, 1931, 2095, 2127, 2130, 2133, 2144, 2148, 2173], "guess": [25, 1228], "trust": [25, 30, 1386, 2091, 2147, 2158], "inaccur": [25, 26, 1697], "harm": 25, "fed": [25, 2176], "trainer": [25, 26, 30, 32, 41, 44, 49, 51, 52, 54, 1770, 2166], "imbalanc": [25, 1484], "__getitems__": 25, "speedup": [25, 26, 1586, 1628, 2122, 2183, 2189, 2201, 2204], "myiterabledataset": 25, "worker_info": 25, "iter_start": 25, "iter_end": 25, "per_work": 25, "ceil": [25, 177, 634, 635, 779, 780, 1489, 1490, 1491, 1547, 1548, 1549, 1573, 1574, 1575, 1653, 1654, 1655, 1711, 1712, 1713, 1897, 1898, 1921, 2094, 2115, 2130, 2155, 2171, 2199], "mult": 25, "overall_start": 25, "overall_end": 25, "stackdataset": 25, "assembl": [25, 2193], "imagedataset": 25, "textdataset": 25, "tuple_stack": 25, "dict_stack": 25, "concatdataset": 25, "chaindataset": 25, "chain": [25, 26, 39, 68, 69, 150, 923, 992, 1218, 1370, 1523, 1609, 1861, 1875, 2096, 2127, 2130, 2133, 2138, 2142, 2157, 2192, 2203], "fly": [25, 1086, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 2127], "whole": [25, 30, 32, 36, 1213, 1314, 1580, 1609, 1620, 1770, 1877, 2045, 2127, 2132, 2144, 2145, 2158, 2192, 2194, 2196, 2200, 2201], "_util": [25, 1009, 2202], "collate_fn_map": 25, "registri": [25, 2147, 2150, 2154], "default_collate_fn_map": 25, "collate_tensor_fn": 25, "custom_col": 25, "collate_map": 25, "outer": [25, 30, 702, 938, 1144, 1203, 1207, 1212, 1233, 1259, 2094, 2096, 2155], "unchang": [25, 499, 513, 515, 746, 829, 1183, 1314, 1580, 1624, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1877, 1913, 1985, 2126, 2145, 2157, 2161], "byte": [25, 30, 32, 39, 51, 242, 435, 558, 910, 1046, 1064, 1092, 1094, 1097, 1099, 1196, 1198, 1313, 1386, 1423, 1425, 1436, 1833, 1843, 1924, 2073, 2074, 2075, 2076, 2077, 2095, 2096, 2097, 2115, 2136, 2147, 2150, 2158, 2171, 2173, 2207], "v_i": 25, "v_1": 25, "v_2": 25, "v1_i": 25, "v2_i": 25, "v1_1": 25, "v1_2": 25, "v2_1": 25, "v2_2": 25, "elem": [25, 2094], "customtyp": 25, "collate_customtype_fn": 25, "default_convert": 25, "np": [25, 58, 990, 1139, 1144, 1184, 1185, 1186, 1727, 1886, 2100, 2134, 2146, 2147, 2154, 2176, 2177, 2178, 2195], "fraction": [25, 39, 1073, 1115, 1187, 1193, 1438, 1510, 1511, 1512, 1527, 1528, 1586, 1628, 1681, 1682, 1798, 1799, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1893, 2124, 2195], "workerinfo": [25, 2166], "random_split": 25, "floor": [25, 271, 648, 649, 779, 780, 1139, 1189, 1325, 1489, 1490, 1491, 1547, 1548, 1549, 1573, 1574, 1575, 1653, 1654, 1655, 1711, 1712, 1713, 1897, 1898, 1912, 1921, 1990, 2094, 2096, 2115, 2144, 2147, 2155, 2171, 2199], "frac": [25, 39, 279, 377, 650, 651, 698, 771, 783, 784, 785, 895, 971, 980, 1023, 1027, 1139, 1189, 1268, 1272, 1273, 1334, 1346, 1350, 1351, 1354, 1366, 1378, 1385, 1401, 1484, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1500, 1507, 1508, 1509, 1510, 1511, 1512, 1515, 1517, 1526, 1531, 1532, 1533, 1534, 1542, 1543, 1544, 1545, 1547, 1548, 1549, 1550, 1551, 1552, 1565, 1567, 1568, 1569, 1570, 1573, 1574, 1575, 1583, 1584, 1585, 1587, 1595, 1596, 1598, 1599, 1611, 1613, 1614, 1616, 1617, 1619, 1620, 1621, 1632, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1706, 1723, 1725, 1727, 1738, 1740, 1744, 1746, 1748, 1749, 1769, 1778, 1837, 1838, 1839, 1842, 1844, 1856, 1863, 1864, 1896, 1905, 1908, 1911, 1923, 1943, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1972, 1988, 1989, 1990, 1994, 2018, 2040, 2041, 2094, 2115, 2122, 2124, 2127, 2138, 2155, 2171, 2172], "remaind": [25, 490, 1192, 1268, 2094, 2155, 2193, 2199], "robin": [25, 30], "generator1": 25, "manual_se": [25, 65, 87, 1941, 2094, 2115, 2142, 2144, 2146, 2155, 2165], "42": [25, 843, 980, 1465, 1947, 2130, 2142, 2150, 2193], "generator2": 25, "30": [25, 30, 39, 51, 445, 617, 731, 739, 740, 767, 775, 1268, 1337, 1497, 1499, 1506, 1567, 1632, 1638, 1661, 1670, 1760, 1868, 1870, 1876, 1895, 2008, 2104, 2133, 2136, 2151, 2154, 2157, 2159, 2166, 2170, 2192, 2193, 2204], "_t": [25, 771, 1235, 1250, 1531, 1550, 1838, 1857, 1859, 2133, 2157], "data_sourc": 25, "accedingsequencelengthsampl": 25, "argsort": [25, 2008, 2094, 2134, 2155], "tolist": [25, 352, 2096, 2155, 2173], "accedingsequencelengthbatchsampl": 25, "sequentialsampl": 25, "num_sampl": [25, 421, 1466, 2094], "drawn": [25, 173, 258, 286, 1466, 1828, 1899, 1903, 1904, 2124, 2178, 2180], "subsetrandomsampl": 25, "weightedrandomsampl": 25, "probabl": [25, 38, 60, 154, 258, 771, 972, 1004, 1234, 1276, 1392, 1466, 1484, 1488, 1492, 1499, 1515, 1517, 1518, 1519, 1520, 1524, 1531, 1533, 1550, 1586, 1587, 1596, 1658, 1669, 1670, 1671, 1672, 1673, 1674, 1679, 1688, 1698, 1722, 1738, 1892, 2114, 2133, 2148, 2172, 2176, 2191, 2194, 2195, 2196, 2200], "row": [25, 26, 30, 37, 38, 39, 208, 313, 315, 321, 585, 588, 704, 710, 907, 938, 940, 990, 1023, 1027, 1127, 1157, 1185, 1186, 1207, 1213, 1277, 1336, 1362, 1370, 1373, 1378, 1402, 1404, 1412, 1414, 1415, 1417, 1420, 1466, 1472, 1473, 1474, 1677, 1678, 1727, 1787, 1826, 1838, 1890, 1893, 1913, 1973, 1975, 1976, 1977, 1978, 1980, 1981, 1993, 2015, 2018, 2022, 2024, 2039, 2045, 2047, 2094, 2117, 2122, 2138, 2141, 2171, 2176], "05": [25, 35, 56, 69, 113, 344, 705, 723, 724, 725, 726, 727, 728, 734, 735, 747, 748, 760, 762, 763, 764, 765, 949, 950, 1158, 1303, 1330, 1331, 1401, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1620, 1624, 1626, 1628, 1656, 1687, 1696, 1700, 1770, 1862, 1869, 1870, 1876, 1877, 1878, 1949, 1950, 1955, 2093, 2094, 2157, 2167, 2178], "batchsampl": 25, "distributedsampl": [25, 1770], "num_replica": 25, "world_siz": [25, 26, 30, 31, 35, 41, 51, 52, 55, 60, 1770, 2130, 2132, 2166, 2167], "evenli": [25, 37, 38, 583, 584, 585, 706, 707, 1142, 1278, 1385, 1401, 2046], "set_epoch": 25, "is_distribut": [25, 2094, 2155], "start_epoch": 25, "n_epoch": 25, "allreduc": [26, 30, 37, 1770, 2130, 2132, 2155], "register_comm_hook": [26, 30, 35, 60, 1770], "mainli": [26, 37, 39, 852, 1499, 1670, 2181, 2205], "bucket": [26, 30, 35, 1241, 1484, 1770, 2094, 2132, 2155, 2195, 2205], "gradbucket": [26, 30, 1770], "decompos": [26, 56, 69, 1194, 1202, 1359, 2127, 2133, 2154, 2199], "get_per_parameter_tensor": 26, "wise": [26, 30, 37, 38, 39, 698, 699, 709, 769, 781, 782, 791, 795, 914, 1021, 1144, 1149, 1190, 1191, 1256, 1257, 1271, 1280, 1337, 1339, 1396, 1397, 1398, 1399, 1403, 1413, 1416, 1418, 1477, 1498, 1512, 1519, 1521, 1535, 1536, 1537, 1538, 1540, 1566, 1569, 1579, 1588, 1599, 1600, 1601, 1608, 1610, 1611, 1612, 1617, 1618, 1619, 1621, 1622, 1660, 1675, 1684, 1685, 1689, 1690, 1691, 1692, 1695, 1699, 1701, 1706, 1717, 1718, 1731, 1732, 1733, 1739, 1740, 1741, 1742, 1746, 1748, 1749, 1750, 1973, 2047, 2129, 2133, 2171, 2172, 2175, 2201], "_distributed_c10d": [26, 30], "1d": [26, 34, 37, 39, 60, 713, 716, 749, 752, 783, 793, 1001, 1023, 1027, 1127, 1141, 1276, 1277, 1291, 1311, 1370, 1371, 1416, 1473, 1481, 1485, 1489, 1499, 1507, 1510, 1515, 1518, 1519, 1523, 1547, 1572, 1573, 1585, 1587, 1633, 1645, 1648, 1651, 1653, 1661, 1664, 1672, 1678, 1707, 1711, 1893, 1894, 1897, 1990, 2008, 2018, 2042, 2117, 2136], "is_last": 26, "set_buff": 26, "stateless": [26, 65, 2118, 2142], "ddp_comm_hook": [26, 35], "default_hook": 26, "allreduce_hook": 26, "process_group": [26, 30, 31, 32, 35, 60, 1620, 1770], "aggreg": [26, 30, 32, 44, 60, 1523, 1678, 1770, 1804, 2109, 2195, 2205], "henc": [26, 32, 34, 35, 37, 39, 41, 50, 51, 55, 60, 68, 286, 972, 1014, 1198, 1576, 1577, 1578, 1633, 1779, 1780, 1814, 1979, 2127, 2130, 2132, 2136, 2147, 2166, 2168, 2189], "unaffect": [26, 499, 500, 1533], "ddp_model": [26, 30, 32, 1770, 2132], "fp16_compress_hook": 26, "compress": [26, 60, 208, 587, 588, 1166, 1167, 1176, 1177, 1770, 1976, 1977, 1978, 1980, 1981, 2017, 2201], "decompress": [26, 2091, 2107], "bf16_compress_hook": 26, "brain": [26, 2174, 2177], "fp16_compress_wrapp": 26, "powersgdst": 26, "matrix_approximation_rank": 26, "start_powersgd_it": 26, "powersgd_hook": 26, "bf16_compress_wrapp": 26, "wikipedia": [26, 1724, 2127, 2138, 2210], "bfloat16_float": 26, "point_format": 26, "vogel": 26, "et": [26, 39, 60, 1499, 1592, 1593, 1629, 1630, 1859, 1956, 1995, 2124], "al": [26, 39, 60, 1499, 1592, 1593, 1629, 1630, 1859, 1956, 1995, 2124], "neurip": [26, 39], "2019": [26, 39, 1101], "bandwidth": [26, 30, 36, 50, 52, 2130, 2161, 2166, 2197, 2198], "hyperparamet": [26, 60, 69, 1838, 2176], "1000": [26, 1159, 1164, 1190, 1191, 1484, 1522, 1630, 1894, 1921, 1940, 2011, 2127, 2137, 2147, 2154, 2176, 2209], "min_compression_r": 26, "use_error_feedback": 26, "warm_start": 26, "orthogonalization_epsilon": 26, "random_se": 26, "compression_stats_logging_frequ": 26, "batch_tensors_with_same_shap": 26, "tune": [26, 30, 35, 1101, 1351, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 2127, 2130, 2143, 2161, 2205], "stronger": [26, 56, 57, 71], "exponenti": [26, 258, 1154, 1366, 1392, 1393, 1394, 1402, 1498, 1521, 1675, 1877, 2096, 2155, 2157, 2172, 2180], "grid": [26, 1164, 1416, 1651, 1686, 2094, 2100, 2130, 2176, 2199], "satisfactori": 26, "nlp": [26, 1542, 1543, 1544, 1552, 2195], "appendix": 26, "hybrid": [26, 60, 218, 543, 583, 584, 585, 587, 588, 1279], "scheme": [26, 49, 58, 478, 817, 837, 839, 840, 841, 846, 852, 2142, 2180], "sensit": [26, 1540, 1612, 2130, 2154, 2158, 2167, 2184, 2194, 2204], "suboptim": [26, 2197], "trajectori": 26, "irrecover": 26, "warm": [26, 35, 1014, 1089, 1863, 1864, 2130, 2159, 2189, 2195, 2202], "num_row": 26, "num_col": 26, "1e": [26, 32, 39, 56, 69, 113, 344, 705, 723, 724, 725, 726, 727, 728, 734, 735, 747, 748, 760, 762, 763, 764, 765, 766, 949, 950, 993, 994, 995, 1303, 1330, 1331, 1381, 1494, 1495, 1496, 1514, 1533, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1566, 1589, 1594, 1620, 1624, 1626, 1628, 1629, 1656, 1668, 1683, 1687, 1688, 1696, 1700, 1723, 1726, 1730, 1754, 1778, 1788, 1821, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 1872, 1874, 1884, 1937, 2093, 2094, 2133, 2142, 2157, 2172, 2178], "orthogon": [26, 1351, 1354, 1373, 1378, 1387, 1880, 1892, 2124, 2127, 2142, 2171, 2204], "div": [26, 236, 1140, 1189, 1192, 1484, 1592, 1593, 1912, 2025, 2094, 2100, 2115, 2155, 2171, 2174, 2199, 2203], "epsilon": [26, 69, 837, 839, 840, 841, 846, 895, 1369, 1372, 1494, 1495, 1496, 1514, 1534, 1542, 1543, 1544, 1552, 1589, 1595, 1620, 1668, 1723, 1769, 1782, 1784, 1788, 1821, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1896, 2094, 2172], "bucket_cap_mb": [26, 1770, 2132], "footprint": [26, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 2150, 2171, 2201], "bottleneck": [26, 2142, 2160, 2197], "memor": 26, "compens": 26, "apex": 26, "uncompress": [26, 2122, 2147, 2171], "pq": 26, "mq": [26, 2161, 2182], "tp": [26, 30, 36, 38, 60], "awai": [26, 69, 1005, 1686, 2116, 2127, 2134, 2191], "comm": [26, 30, 51, 681, 2132], "handler": [26, 30, 42, 44, 45, 53, 1015, 1800, 2109, 2133, 2140, 2158, 2204, 2206], "batched_powersgd_hook": 26, "destroi": [26, 30, 51, 1228, 1516, 2127, 2159, 2166], "squar": [26, 39, 551, 750, 751, 752, 753, 790, 796, 807, 1027, 1131, 1133, 1311, 1346, 1348, 1350, 1351, 1352, 1355, 1356, 1360, 1362, 1364, 1366, 1368, 1372, 1374, 1375, 1377, 1378, 1382, 1395, 1404, 1482, 1486, 1490, 1491, 1508, 1509, 1511, 1512, 1527, 1528, 1540, 1548, 1549, 1571, 1574, 1575, 1578, 1595, 1612, 1624, 1641, 1653, 1662, 1665, 1681, 1682, 1686, 1695, 1697, 1718, 1735, 1738, 1742, 1757, 1769, 1787, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1923, 1974, 1983, 2020, 2039, 2094, 2155, 2171], "truncat": [26, 1189, 1936, 2026, 2117, 2124, 2135, 2145], "impli": [26, 51, 58, 60, 258, 1232, 2114, 2127, 2136, 2150, 2154, 2164, 2166, 2173, 2194], "debugging_hook": 26, "noop_hook": 26, "headroom": 26, "desynchron": [26, 30], "restart": [26, 41, 50, 52, 55, 1863, 1864, 2114, 2176, 2184, 2193], "__setstate__": 26, "__getstate__": 26, "reload": [26, 35, 60, 2091], "sy": [26, 43, 52, 55, 2091, 2130, 2147, 2158], "tempfil": [26, 2147], "mp": [26, 30, 31, 54, 1427, 1770, 1840, 1841, 2100, 2125, 2132, 2133, 2144, 2157, 2160, 2161, 2167, 2173, 2174, 2180, 2182, 2208], "simplemodel": 26, "24": [26, 30, 39, 975, 1373, 1568, 1651, 1820, 1892, 1936, 2013, 2093, 2124, 2129, 2172, 2192, 2193], "fc2": [26, 1760, 2150, 2157, 2185], "master_addr": [26, 30, 41, 51, 52, 55, 2132, 2166, 2167], "localhost": [26, 30, 51, 52, 2132, 2166, 2167], "master_port": [26, 30, 41, 51, 52, 55, 2132, 2166, 2167], "12355": 26, "init_process_group": [26, 30, 31, 35, 41, 52, 55, 1770, 2130, 2132, 2166], "cleanup": [26, 1228, 2173], "destroy_process_group": [26, 30], "run_demo": 26, "demo_fn": 26, "nproc": [26, 30, 49, 50, 52, 2114, 2132, 2167], "demo_seri": 26, "gettempdir": 26, "device_id": [26, 30, 31, 35, 52, 60, 1386, 1516, 1620, 1753, 1770, 2132], "powersgd_st": 26, "lr": [26, 31, 32, 35, 60, 488, 1760, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878, 2130, 2132, 2137, 2142, 2144, 2157, 2167, 2176, 2204], "001": [26, 949, 950, 1324, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1873, 2132, 2137], "state_dict": [26, 32, 35, 37, 56, 57, 60, 67, 864, 865, 1314, 1580, 1760, 1771, 1806, 1824, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 2091, 2107, 2108, 2132, 2137, 2142, 2144, 2147, 2150, 2157, 2161, 2181], "comm_hook": 26, "comm_hook_st": 26, "barrier": [26, 41, 51, 2155], "map_loc": [26, 1318, 1322, 1386, 1770, 2091, 2104, 2107, 2158], "new_ddp_model": 26, "load_state_dict": [26, 32, 35, 60, 67, 415, 1314, 1386, 1580, 1760, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 2091, 2142, 2147, 2157, 2161], "n_gpu": 26, "device_count": [26, 34, 2036], "got": [26, 30, 921, 935, 936, 958, 2130, 2133, 2147, 2178], "thank": [26, 39, 2133], "author": [26, 52, 60, 1213, 1856, 1899, 2045, 2126, 2193, 2195, 2197, 2200, 2201, 2202, 2205], "thij": 26, "par": 26, "torch_show_cpp_stacktrac": [27, 30], "torch_cpp_log_level": [27, 30], "c10": [27, 2140, 2141, 2185, 2191], "glog": 27, "logger": [27, 30, 41, 813, 867, 2181, 2182], "info": [27, 30, 36, 37, 45, 49, 51, 60, 681, 922, 935, 936, 1039, 1040, 1228, 1345, 1356, 1358, 1359, 1363, 1376, 1404, 1433, 1434, 1833, 2094, 2100, 2102, 2132, 2133, 2134, 2158, 2160, 2186, 2191, 2193, 2194, 2204, 2205, 2209], "fatal": [27, 56, 2114, 2144], "torch_log": [27, 36, 37, 71, 73, 80, 681, 1002, 2102, 2132, 2191, 2192, 2193, 2195, 2205], "_log": [27, 36, 37, 2096, 2160, 2185, 2204, 2205, 2208], "home": [28, 2130], "fill_uninitialized_memori": [29, 499, 1145, 1146, 1147, 2033, 2146], "fill": [29, 30, 36, 37, 154, 173, 258, 259, 260, 286, 317, 321, 377, 400, 445, 446, 447, 449, 454, 481, 513, 608, 624, 973, 1132, 1145, 1146, 1147, 1199, 1200, 1345, 1356, 1358, 1523, 1624, 1678, 1725, 1831, 1832, 1901, 1902, 1903, 1904, 1905, 1906, 1994, 2033, 2089, 2090, 2094, 2104, 2116, 2117, 2124, 2130, 2133, 2147, 2155, 2171, 2173, 2178, 2194, 2199], "detriment": [29, 2146], "resize_": [29, 500, 1202, 1336, 2033, 2093, 2094, 2095, 2115, 2146, 2163, 2173, 2199], "empty_strid": [29, 2094, 2098, 2155, 2191, 2199], "empty_permut": [29, 2094, 2155, 2199], "empty_lik": [29, 32, 58, 2094, 2098, 2100, 2104, 2115, 2155, 2171], "brief": [30, 36, 1770, 2114, 2166], "introduct": [30, 39, 1078, 1770, 2093, 2097, 2115, 2128, 2142, 2154, 2166, 2171, 2176], "mpi": [30, 1770], "gloo": [30, 52, 1770, 2132, 2139, 2166], "recv": [30, 36, 1770, 2155, 2167], "broadcast": [30, 32, 35, 37, 38, 39, 60, 65, 97, 196, 398, 400, 401, 402, 513, 515, 517, 566, 696, 697, 698, 699, 700, 701, 702, 708, 746, 914, 970, 975, 978, 982, 983, 984, 985, 1022, 1052, 1086, 1138, 1139, 1144, 1149, 1189, 1190, 1191, 1192, 1255, 1257, 1271, 1281, 1339, 1340, 1347, 1360, 1364, 1369, 1370, 1372, 1375, 1383, 1403, 1408, 1409, 1419, 1465, 1468, 1477, 1480, 1493, 1514, 1533, 1586, 1659, 1668, 1731, 1738, 1770, 1835, 1881, 1889, 1912, 1914, 1991, 1995, 2013, 2018, 2048, 2096, 2115, 2116, 2122, 2125, 2132, 2154, 2155, 2172, 2195, 2199], "all_reduc": [30, 37, 54, 1770, 2130, 2155, 2189], "all_gath": [30, 37], "scatter": [30, 34, 35, 37, 60, 513, 515, 517, 1516, 2033, 2094, 2135, 2136, 2155, 2166, 2199], "reduce_scatt": [30, 37, 2155], "all_to_al": [30, 37], "v1": [30, 60, 1383, 1881, 2091, 2132, 2166], "init_method": [30, 1770, 2166], "adher": [30, 1004, 2096, 2117, 2171], "some_fil": 30, "machine_nam": 30, "share_folder_nam": 30, "tcpstore": [30, 51], "past": [30, 56, 69, 86, 1050, 1103, 1108, 1121, 1122, 1443, 1770, 2135, 2197, 2198, 2201, 2204], "ask": [30, 64, 65, 2091, 2125, 2134, 2138, 2183, 2192, 2207], "infiniband": [30, 1770, 2166], "interconnect": [30, 36], "gpudirect": 30, "ethernet": 30, "ip": [30, 51], "ib": 30, "upcom": [30, 2126], "nccl_socket_ifnam": 30, "eth0": 30, "gloo_socket_ifnam": 30, "eth1": 30, "eth2": 30, "eth3": 30, "imper": 30, "nccl_debug": 30, "nccl_debug_subsi": 30, "coll": 30, "hang": [30, 31, 35, 39, 1770, 2105, 2132, 2209], "topologi": [30, 32, 37, 38, 41, 2184], "effort": [30, 56, 2117, 2166, 2192, 2198], "socket": [30, 42, 2114, 2166], "nccl_socket_nthread": 30, "nccl_nsocks_perthread": 30, "cloud": [30, 2171, 2176], "aw": [30, 43, 1027], "gcp": [30, 2201], "primit": [30, 35, 36, 37, 51, 58, 1386, 2093, 2095, 2097, 2129, 2143, 2147, 2154, 2166, 2199], "kind": [30, 45, 56, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 681, 1224, 1334, 1771, 1772, 1834, 1891, 1955, 2091, 2100, 2133, 2144, 2146, 2158, 2161, 2172, 2173, 2174], "connect": [30, 36, 41, 51, 1507, 1508, 1509, 1510, 1511, 1512, 1556, 1557, 1558, 1559, 1560, 1561, 1609, 2114, 2122, 2166, 2202], "advantag": [30, 51, 52, 1493, 1540, 2132, 2135, 2149, 2150, 2166, 2171, 2189, 2204], "redund": [30, 60, 1160, 1161, 1163, 1165, 1179, 1181, 1990, 2150], "elimin": [30, 56, 69, 610, 1221, 2029, 2030, 2146, 2150, 2197, 2203], "thrash": 30, "recurr": [30, 771, 772, 1330, 1499, 1516, 1531, 1532, 1550, 1596, 1791, 1816, 1857, 2130], "device_mesh": [30, 37, 38, 60, 1770], "init_device_mesh": [30, 38], "inconsist": [30, 60, 895, 1908, 2133], "uuid": [30, 2127], "use_distribut": 30, "group_nam": [30, 48], "pg_option": 30, "url": [30, 961, 2091, 2107, 2137, 2166], "encod": [30, 41, 48, 51, 58, 69, 1362, 1386, 1433, 1434, 1492, 1493, 1624, 1625, 1626, 1627, 1628, 1770, 1936, 1976, 1977, 1978, 1980, 1981, 2093, 2096, 2097, 2133, 2147, 2158, 2167, 2171], "ucc": 30, "plugin": [30, 2159, 2176, 2190], "c10d": [30, 41, 50, 52, 55, 681, 1770, 2132, 2155], "registr": [30, 35, 68, 1086, 1762, 1767, 1768, 1770, 1790, 1793, 2100, 2158, 2190], "lowercas": 30, "deadlock": [30, 1770], "invalid": [30, 44, 49, 1005, 1314, 1580, 1877, 2126, 2127, 2146, 2156, 2158, 2186, 2194], "job": [30, 41, 44, 45, 47, 48, 50, 51, 52, 54, 1464, 1770, 1865, 1872, 2130, 2140, 2159, 2176, 2184, 2192, 2204, 2207, 2209], "exchang": [30, 51, 1040, 1132, 2130, 2149], "timedelta": [30, 51, 2109], "abort": [30, 2130, 2209], "crash": [30, 44, 51, 1351, 2114, 2127, 2166, 2168, 2176, 2191, 2204], "corrupt": [30, 51, 1516, 2130, 2144, 2147], "torch_nccl_blocking_wait": [30, 2209], "processgroupopt": 30, "processgroupnccl": [30, 2130, 2132, 2208], "is_high_priority_stream": 30, "availbl": 30, "deeplearn": 30, "ncclconfig": 30, "ncclcomminit": 30, "lazi": [30, 1020, 1218, 1327, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1760, 2067, 2191], "ncclcommsplit": 30, "unnecessari": [30, 35, 58, 1779, 1780, 1820, 2096, 2117, 2127, 2130, 2133, 2147, 2158, 2175], "backend_nam": [30, 2036], "custom_backend": 30, "mesh_shap": 30, "mesh_dim_nam": 30, "dimension": [30, 37, 39, 57, 513, 515, 910, 916, 917, 918, 981, 988, 1000, 1132, 1134, 1135, 1144, 1160, 1161, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1178, 1179, 1181, 1183, 1185, 1186, 1198, 1268, 1277, 1278, 1279, 1347, 1352, 1353, 1354, 1355, 1380, 1385, 1401, 1409, 1416, 1484, 1501, 1502, 1503, 1504, 1505, 1506, 1515, 1516, 1522, 1523, 1552, 1570, 1587, 1595, 1602, 1603, 1604, 1605, 1606, 1607, 1614, 1616, 1620, 1636, 1637, 1638, 1669, 1722, 1725, 1758, 1759, 1769, 1787, 1826, 1899, 1976, 1977, 1978, 1979, 1980, 1981, 1990, 2008, 2011, 2012, 2018, 2096, 2117, 2124, 2128, 2138, 2145, 2171, 2173, 2174, 2177, 2180, 2191], "layout": [30, 37, 38, 57, 69, 150, 191, 208, 233, 342, 343, 435, 445, 446, 447, 448, 449, 458, 544, 581, 582, 583, 584, 585, 587, 588, 617, 700, 895, 923, 928, 971, 980, 1054, 1145, 1146, 1147, 1157, 1162, 1180, 1196, 1199, 1200, 1226, 1272, 1273, 1334, 1385, 1401, 1409, 1419, 1476, 1703, 1831, 1832, 1860, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1970, 1971, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 2017, 2022, 2024, 2089, 2090, 2091, 2093, 2094, 2095, 2098, 2122, 2130, 2141, 2155, 2158, 2171, 2176, 2177, 2178, 2199], "spmd": [30, 32, 37, 2184], "nd": [30, 1370, 2136, 2145], "scene": [30, 2147, 2176], "mesh": [30, 34, 37, 38, 2176], "mesh_1d": 30, "mesh_2d": 30, "dp": 30, "is_initi": 30, "is_mpi_avail": 30, "is_nccl_avail": 30, "is_gloo_avail": 30, "distributed_c10d": [30, 2130], "is_xccl_avail": 30, "xccl": 30, "is_torchelastic_launch": 30, "elast": [30, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 2160], "torchelast": [30, 33, 41, 43, 44, 45, 48, 50, 52, 54, 55], "torchelastic_run_id": [30, 52], "proxi": [30, 32, 58, 1004, 1214, 1215, 1218, 2161, 2166, 2192], "rendezv": [30, 33, 41, 45, 48, 50, 55, 2132, 2166], "null": [30, 43, 45, 48, 71, 75], "discoveri": [30, 51, 2130, 2158], "reachabl": 30, "multicast": 30, "20": [30, 35, 39, 321, 696, 731, 739, 740, 745, 749, 750, 751, 752, 753, 754, 757, 767, 771, 772, 773, 774, 775, 776, 783, 1126, 1268, 1312, 1315, 1326, 1337, 1371, 1465, 1488, 1490, 1491, 1493, 1494, 1495, 1496, 1497, 1499, 1506, 1507, 1508, 1509, 1511, 1512, 1517, 1518, 1519, 1520, 1524, 1527, 1528, 1531, 1532, 1534, 1541, 1542, 1543, 1544, 1547, 1548, 1549, 1550, 1551, 1552, 1567, 1573, 1574, 1575, 1577, 1578, 1580, 1596, 1598, 1609, 1617, 1620, 1623, 1624, 1625, 1626, 1638, 1661, 1663, 1664, 1666, 1670, 1681, 1682, 1688, 1746, 1787, 1788, 1789, 1812, 1821, 1824, 1843, 1864, 1878, 1895, 2008, 2093, 2094, 2104, 2117, 2122, 2132, 2133, 2145, 2155, 2157, 2159, 2166, 2170, 2171, 2192, 2193, 2194], "23456": 30, "clean": [30, 36, 41, 56, 69, 1013, 1082, 2091, 2114, 2158], "fcntl": 30, "nf": 30, "init": [30, 38, 41, 44, 45, 56, 60, 1314, 1580, 1588, 1608, 1820, 1877, 2098, 2127, 2133, 2140, 2142, 2157, 2160, 2191], "brand": [30, 32, 2133], "succe": [30, 56, 65, 2130, 2133, 2141, 2147, 2148, 2204, 2205, 2207], "unexpect": [30, 32, 40, 69, 895, 1036, 1195, 1198, 1201, 1314, 1580, 1822, 1835, 1877, 1985, 2093, 2127, 2133, 2145, 2192, 2194, 2195], "unsuccess": 30, "mnt": 30, "sharedfil": 30, "port": [30, 41, 50, 51, 52, 2104, 2139], "backend_str": 30, "uppercas": 30, "classmethod": [30, 32, 51, 71, 73, 743, 749, 750, 751, 756, 757, 767, 775, 805, 806, 807, 830, 831, 832, 843, 884, 958, 1039, 1522, 1523, 1620, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1833, 2096, 2097, 2122, 2133, 2161, 2166, 2173, 2206], "register_backend": [30, 2166, 2190], "extended_api": 30, "instanti": [30, 35, 50, 51, 52, 60, 69, 871, 1523, 1678, 1790, 1813, 1820, 2091, 2093, 2095, 2096, 2100, 2117, 2130, 2133, 2142, 2147, 2150, 2173], "3rd": [30, 39, 51, 617, 2128], "processgroup": [30, 32, 35, 36, 37, 60, 1770], "four": [30, 1360, 1508, 2122, 2133, 2138, 2166, 2168], "distributedbackendopt": 30, "get_backend": [30, 51], "get_rank": [30, 60, 1620], "consecut": [30, 60, 610, 1815, 1861, 2018, 2029, 2030, 2116, 2154], "get_world_s": 30, "pattern": [30, 32, 36, 805, 806, 807, 809, 884, 891, 1086, 1516, 1640, 1816, 1971, 2093, 2096, 2117, 2122, 2127, 2130, 2133, 2135, 2139, 2147, 2162, 2163, 2171, 2189, 2191, 2192, 2194, 2203, 2207], "launcher": [30, 36, 52], "pg": [30, 1770], "destructor": [30, 2114, 2130, 2168], "ncclcommabort": 30, "gc": [30, 486, 2168], "fault": [30, 33, 41, 50, 51, 1198, 2130, 2204], "toler": [30, 33, 41, 50, 51, 69, 705, 949, 950, 1303, 1330, 1331, 1369, 1372, 1387, 1835, 1843, 2093, 2178], "_after_": [30, 2132], "unsupport": [30, 41, 56, 58, 65, 71, 73, 78, 80, 85, 1015, 2093, 2097, 2116, 2117, 2147, 2157, 2166, 2171, 2195, 2200, 2204], "untest": [30, 2116], "grain": [30, 56, 888, 891, 1738, 2127, 2150, 2154, 2171, 2183, 2197, 2204, 2205], "plai": [30, 2193, 2195], "new_group": [30, 60, 1620], "opaqu": [30, 40, 1004, 1037, 1078, 1079, 1195, 2100, 2200], "use_local_synchron": 30, "group_desc": 30, "enqueu": [30, 68, 1040, 1045, 1445, 2052, 2130, 2167], "groupmemb": 30, "non_group_memb": 30, "significantli": [30, 56, 60, 939, 1770, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1936, 2150, 2151, 2171, 2190, 2204], "taken": [30, 36, 39, 56, 58, 68, 69, 71, 76, 895, 1165, 1167, 1190, 1191, 1499, 1515, 1523, 1587, 1595, 1670, 1678, 1695, 1718, 1769, 1940, 1973, 2117, 2124, 2127, 2129, 2130, 2133, 2135, 2136, 2140, 2147, 2154, 2158, 2159, 2205, 2207], "get_group_rank": 30, "global_rank": [30, 41], "translat": [30, 1268, 2127, 2149, 2150, 2168], "get_global_rank": 30, "group_rank": [30, 41, 52], "get_process_group_rank": 30, "inter": [30, 41, 44, 60, 1265, 1938, 2129, 2132, 2166], "intra": [30, 34, 35, 60, 2129, 2132, 2180], "_init_backend": 30, "ndarrai": [30, 40, 458, 909, 1195, 1197, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2154, 2176, 2178, 2195], "from_group": 30, "get_all_group": 30, "get_coordin": 30, "get_group": 30, "mesh_dim": 30, "get_local_rank": 30, "denot": [30, 39, 56, 69, 173, 1027, 1238, 1335, 1354, 1360, 1373, 1383, 1507, 1508, 1545, 1790, 1793, 1859, 1976, 1977, 1978, 1980, 1981, 2042, 2104, 2138, 2164, 2167, 2171], "dst": [30, 2091, 2158], "group_dst": 30, "destin": [30, 32, 45, 48, 49, 60, 209, 416, 417, 603, 623, 1053, 1054, 1055, 1255, 1314, 1421, 1422, 1580, 1877, 2094, 2130, 2150, 2166, 2167, 2173], "group_src": 30, "unspecifi": [30, 481, 839, 840, 841, 846, 949, 950, 1228, 1614, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1972, 1979, 2103, 2171, 2176, 2185], "sender": [30, 2168], "isend": 30, "irecv": 30, "is_complet": 30, "finish": [30, 32, 34, 37, 41, 48, 49, 51, 54, 68, 486, 1202, 2130, 2132, 2137, 2148, 2159, 2166, 2168, 2207], "send_object_list": 30, "object_list": 30, "picklabl": [30, 1314, 1580, 1877, 2158], "sent": [30, 32, 1082, 2096, 2114, 2130, 2144, 2166, 2167, 2168], "set_devic": [30, 32, 60, 1770, 1932, 2130, 2166, 2174], "insecur": [30, 1386], "malici": [30, 1386, 2158], "ineffici": [30, 60, 2117, 2130, 2161], "recv_object_list": 30, "batch_isend_irecv": 30, "p2p_op_list": 30, "p2pop": 30, "op_list": 30, "send_tensor": 30, "recv_tensor": 30, "send_op": 30, "recv_op": 30, "req": 30, "p2p": 30, "group_peer": 30, "async_op": [30, 34, 37], "onto": [30, 37, 60, 69, 71, 73, 1107, 1322, 1325, 1386, 1793, 2034, 2091, 2100, 2104, 2114, 2130, 2134, 2135, 2142, 2147, 2159, 2203, 2207], "get_futur": [30, 1770], "regard": [30, 1510, 1511, 1512, 1522, 1523, 1677, 1678, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 2093, 2168, 2171, 2198], "101": [30, 958, 1484, 2186], "overwrot": 30, "broadcast_object_list": 30, "redoptyp": 30, "bitwis": [30, 974, 976, 977, 979, 2097, 2145, 2162, 2180], "reduceop": [30, 2189], "int64": [30, 58, 191, 208, 313, 321, 393, 895, 973, 986, 1145, 1158, 1159, 1197, 1669, 1813, 1903, 1907, 1908, 1928, 1976, 1977, 1978, 1980, 1981, 1993, 2100, 2117, 2130, 2171, 2173, 2174, 2177, 2210], "1j": [30, 709, 1020, 1021, 1310, 1916, 1917, 2042, 2127, 2138, 2147], "2j": [30, 709, 1020, 1021, 1916, 1917, 1943, 2042, 2127], "tensor_list": [30, 2117], "uneven": [30, 31, 35, 37, 38, 1770], "all_gather_into_tensor": [30, 2155], "output_tensor": 30, "input_tensor": [30, 2149, 2197], "accommod": [30, 1576, 1577, 1578], "ii": [30, 1023, 1144, 1550, 1551], "tensor_in": 30, "tensor_out": 30, "tensor_out2": 30, "all_gather_object": 30, "obj": [30, 69, 910, 1065, 1300, 1301, 1320, 1321, 1326, 1924, 2037, 2057, 2147, 2148, 2158, 2204], "pickabl": 30, "popul": [30, 39, 49, 60, 68, 69, 335, 495, 503, 504, 1226, 1237, 1415, 1472, 2130, 2133, 2147, 2194, 2203], "unmodifi": [30, 36, 2193], "responsibl": 30, "gather_object": 30, "gather_list": 30, "tensor_s": 30, "zeros_lik": [30, 69, 930, 932, 934, 935, 936, 2094, 2098, 2117, 2130, 2155, 2171, 2173], "object_gather_list": 30, "scatter_list": 30, "t_one": 30, "t_five": 30, "scatter_object_list": 30, "scatter_object_output_list": 30, "scatter_object_input_list": 30, "whose": [30, 39, 58, 60, 69, 544, 889, 928, 992, 1022, 1132, 1144, 1149, 1198, 1257, 1268, 1271, 1277, 1314, 1320, 1331, 1339, 1385, 1401, 1403, 1477, 1580, 1770, 1828, 1877, 1886, 1943, 2014, 2096, 2100, 2127, 2133, 2136, 2138, 2157, 2158, 2171, 2176, 2177, 2178, 2191, 2205], "output_list": 30, "input_list": 30, "reduce_scatter_tensor": [30, 2155], "all_to_all_singl": [30, 2155], "output_split_s": 30, "input_split_s": 30, "13": [30, 905, 965, 996, 1126, 1142, 1145, 1189, 1268, 1278, 1318, 1404, 1500, 1527, 1528, 1577, 1615, 1681, 1682, 1965, 2012, 2046, 2093, 2097, 2155, 2171, 2198, 2205], "14": [30, 71, 79, 80, 321, 517, 995, 1086, 1087, 1127, 1142, 1278, 1367, 1373, 1470, 1500, 1577, 1892, 1899, 1936, 1965, 2012, 2013, 2018, 2046, 2093, 2097, 2100, 2136, 2155, 2171, 2175, 2176, 2192, 2193], "15": [30, 58, 69, 617, 1126, 1142, 1256, 1268, 1278, 1337, 1351, 1500, 1577, 1578, 1817, 1819, 1884, 1956, 1965, 2016, 2046, 2093, 2094, 2097, 2122, 2150, 2154, 2171, 2193], "18": [30, 321, 445, 696, 1145, 1268, 1311, 1387, 1577, 2093, 2100, 2154, 2155, 2171, 2185, 2192, 2193], "21": [30, 39, 696, 965, 992, 1127, 1373, 1892, 2018, 2093, 2171, 2186], "22": [30, 39, 321, 617, 1387, 1760, 1817, 1819, 2093, 2171, 2192, 2193], "23": [30, 513, 1126, 1387, 1936, 1951, 2093, 2117, 2171, 2205], "31": [30, 978, 1491, 1549, 1575, 1760, 1951, 2154], "33": [30, 749, 750, 751, 752, 753, 754, 783, 1126, 1314, 1507, 1508, 1509, 1511, 1512, 1578, 1580, 1661, 1663, 1664, 1666, 1877, 2093, 2154], "34": [30, 2031, 2193, 2205], "35": [30, 1373, 1495, 1496, 1543, 1544, 1620, 1892], "36": [30, 321, 1187, 1268, 2193], "input_split": 30, "output_split": 30, "5j": 30, "6j": 30, "7j": 30, "8j": 30, "9j": 30, "10j": 30, "11j": 30, "12j": 30, "13j": 30, "14j": 30, "15j": 30, "16j": 30, "output_tensor_list": 30, "input_tensor_list": 30, "till": 30, "monitored_barri": [30, 2155], "wait_all_rank": 30, "datetim": [30, 2109, 2195], "throw": [30, 31, 68, 69, 190, 323, 328, 545, 614, 1299, 1314, 1355, 1404, 1580, 1770, 1773, 1774, 1816, 1827, 1877, 1888, 2033, 2117, 2127, 2146, 2166, 2177, 2192, 2195, 2205, 2209], "pend": [30, 34, 37, 1007, 2130, 2166, 2176, 2189], "exception_ptr": 30, "fut": [30, 68, 1317, 1770, 2129, 2166], "ddp": [30, 31, 32, 35, 36, 60, 681, 1620, 1770, 2130, 2132, 2160, 2166, 2195, 2204], "group_to_us": 30, "div_": [30, 2094, 2115, 2171], "cudafutur": 30, "worknccl": 30, "dedic": [30, 37, 68, 2130], "arriv": [30, 51, 52, 2166, 2168], "synch": 30, "get_future_result": 30, "workresult": 30, "call_back_func": 30, "is_success": 30, "source_rank": 30, "unbox": 30, "thrown": [30, 68, 617, 908, 910, 1101, 1142, 1278, 1314, 1345, 1354, 1356, 1358, 1361, 1362, 1373, 1580, 1738, 1776, 1785, 1877, 2046, 2158, 2209], "band": 30, "bor": 30, "bxor": 30, "premul_sum": 30, "suppos": [30, 69, 1251, 1311, 2103, 2136, 2171, 2186, 2194, 2195, 2196], "_make_nccl_premul_sum": 30, "__members__": 30, "reduce_op": [30, 37], "filestor": [30, 51], "hashstor": 30, "quantiti": [30, 61, 66, 1236, 1238, 1241, 1350, 1351, 1378, 1545, 1798, 1799, 1801, 1802, 1804, 1806, 1807, 1808, 1809, 1874, 2100, 2108, 2134, 2138], "127": [30, 807, 2116, 2161, 2176], "first_kei": 30, "po": [30, 32, 2154], "tato": 30, "potato": 30, "suffer": 30, "lisr": 30, "compare_set": 30, "arg2": [30, 57], "expected_valu": 30, "desired_valu": 30, "first_valu": 30, "second_valu": 30, "delete_kei": 30, "bad_kei": 30, "has_extended_api": 30, "multi_get": 30, "second_kei": 30, "multi_set": 30, "num_kei": 30, "written": [30, 32, 37, 41, 44, 49, 65, 961, 1103, 1196, 1516, 1838, 1859, 2093, 2095, 2103, 2106, 2127, 2132, 2133, 2134, 2142, 2147, 2154, 2158, 2159, 2173, 2176, 2183, 2186, 2191, 2192, 2193, 2197, 2198, 2203, 2205], "underli": [30, 32, 35, 39, 41, 56, 60, 65, 69, 97, 311, 326, 377, 400, 402, 473, 474, 475, 476, 483, 499, 520, 524, 557, 558, 559, 613, 759, 768, 908, 1039, 1196, 1228, 1245, 1247, 1248, 1249, 1285, 1289, 1314, 1386, 1475, 1730, 1814, 1910, 2017, 2032, 2050, 2093, 2096, 2117, 2130, 2135, 2139, 2166, 2173, 2175, 2183, 2194], "old": [30, 40, 56, 69, 486, 884, 1195, 1236, 1251, 1519, 1824, 1832, 1874, 1924, 2090, 2093, 2127, 2130, 2133, 2147, 2148, 2161, 2176, 2194, 2204], "set_timeout": 30, "overload": [30, 56, 69, 617, 2095, 2096, 2100], "client": [30, 35, 51, 1101, 1227, 1232, 2078, 2137, 2158, 2195], "host_nam": 30, "hostnam": [30, 41, 45, 51, 2159], "listen": 30, "is_mast": 30, "300": [30, 41, 1392, 1493, 1817, 1819, 1877, 1878, 2157], "wait_for_work": 30, "multi_ten": 30, "tcpserver": 30, "master_listen_fd": 30, "use_libuv": 30, "libuv": 30, "server_stor": 30, "1234": [30, 1291, 2031], "client_stor": 30, "libuvbackend": 30, "hashmap": 30, "file_nam": [30, 37, 2091, 2107, 2158], "store1": 30, "store2": 30, "prefixstor": 30, "underlying_stor": 30, "mention": [30, 58, 2091, 2095, 2096, 2116, 2127, 2130, 2142, 2147, 2150, 2154, 2171, 2173, 2175, 2183, 2198, 2205], "stand": [30, 36, 1208, 1212, 2095, 2158, 2168], "exemplifi": 30, "cpp_extens": [30, 2130, 2160], "cpp_c10d_extens": 30, "torchrun": [30, 33, 36, 37, 43, 50, 55], "benefici": [30, 87, 1779, 1780, 2142], "nproc_per_nod": [30, 36, 43], "num_gpus_you_hav": 30, "your_training_script": [30, 50, 52], "arg3": [30, 57], "192": [30, 617, 2154], "168": 30, "nnode": [30, 50, 52], "master": [30, 45, 55, 2091, 2166], "local_process_rank": 30, "local_rank": [30, 41, 44, 49, 52, 55, 1620, 2130], "argpars": [30, 52, 2130], "parser": [30, 52, 2130], "argumentpars": [30, 52, 2130], "add_argu": [30, 52, 2130], "parse_arg": [30, 43, 52, 55, 2130, 2154], "onward": [30, 52, 1874, 2172], "dash": [30, 52, 2166, 2168], "previous": [30, 51, 52, 56, 61, 64, 65, 66, 69, 709, 805, 806, 958, 1213, 1241, 1251, 1322, 1988, 1989, 2040, 2041, 2045, 2093, 2128, 2130, 2142, 2158, 2165, 2166, 2172, 2173, 2192, 2200, 2204, 2207], "underscor": [30, 52, 2091, 2116, 2166, 2177], "unrecogn": [30, 52, 2096], "output_devic": [30, 35, 52, 1516, 1620, 1753, 1770], "adjust": [30, 32, 35, 38, 39, 60, 1493, 1867, 1874, 1948, 2129, 2162, 2207, 2208], "filesystem": [30, 32, 2091, 2158], "12042": 30, "wrong": [30, 69, 930, 931, 935, 1007, 1312, 1315, 2132, 2144, 2148, 2154, 2157, 2189, 2192, 2193, 2204], "imagenet": [30, 2124], "suit": [30, 2093, 2095, 2096, 2154, 2162, 2166, 2201], "pdb": [30, 1319, 1326, 1332, 2093, 2095, 2204], "streamlin": [30, 57], "attach": [30, 36, 57, 63, 68, 69, 139, 723, 724, 725, 726, 727, 728, 729, 730, 731, 741, 742, 743, 744, 806, 834, 866, 869, 894, 1760, 2091, 2093, 2095, 2115, 2127, 2133, 2150, 2161, 2167, 2181, 2191, 2204], "rerout": 30, "sync": [30, 34, 35, 60, 68, 69, 486, 1770, 2117, 2130, 2132, 2189, 2194], "group_gloo": 30, "29501": 30, "monitoredbarri": 30, "transport": [30, 2166], "598": 30, "2401": [30, 36], "db00": 30, "eef0": 30, "1100": 30, "3560": 30, "1c05": 30, "25d": 30, "8594": 30, "twolinlayernet": 30, "i0607": 30, "739390": 30, "515217": 30, "173": 30, "broadcast_buff": [30, 1770], "bucket_cap_byt": 30, "26214400": 30, "find_unused_paramet": [30, 1770, 2132], "gradient_as_bucket_view": [30, 1770], "is_multi_device_modul": 30, "num_parameter_tensor": 30, "total_parameter_size_byt": 30, "440": 30, "bucket_s": 30, "module_nam": [30, 69, 832, 884, 2158], "nccl_async_error_handl": [30, 2130], "nccl_blocking_wait": 30, "nccl_ib_timeout": 30, "nccl_nthread": 30, "58": [30, 2198], "085681": 30, "544067": 30, "344": 30, "unused_parameter_s": 30, "40838608": 30, "5983335": 30, "4326421": 30, "comp": [30, 39], "4207652": 30, "085693": 30, "544066": 30, "42850427": 30, "3885553": 30, "2357981": 30, "2234674": 30, "enhanc": [30, 60, 2191, 2204], "unus": [30, 35, 51, 69, 944, 1082, 1097, 1319, 1326, 1541, 1770, 1835, 2076, 2093, 2095, 2096, 2130, 2132, 2139, 2158], "went": [30, 69, 2192], "wasn": [30, 51, 1386, 2093], "va": 30, "lue": 30, "indirectli": 30, "outstand": [30, 2166], "stuck": [30, 41, 54, 2209], "uninform": 30, "root": [30, 32, 34, 36, 44, 51, 52, 56, 60, 69, 806, 1210, 1224, 1352, 1353, 1595, 1735, 1769, 1857, 1923, 1983, 2106, 2127, 2136, 2137, 2158, 2166, 2167, 2171, 2195, 2204], "nontrivi": [30, 1228, 1239, 2130, 2191], "reveal": [30, 2132, 2189, 2204], "default_pg": [30, 2130], "longtensor": [30, 36, 134, 135, 136, 315, 317, 319, 452, 471, 513, 515, 517, 904, 905, 1255, 1289, 1336, 1466, 1522, 1523, 1583, 1677, 1678, 1724, 1826, 1928, 1965, 1979, 2007, 2015, 2048, 2174, 2177], "set_debug_level": 30, "set_debug_level_from_env": 30, "get_debug_level": 30, "disterror": 30, "distbackenderror": 30, "distnetworkerror": 30, "ex": [30, 43, 1228, 1770, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2109, 2203], "diststoreerror": 30, "skip": [30, 36, 37, 51, 57, 889, 1004, 1015, 1144, 1198, 1236, 1344, 1345, 1489, 1490, 1491, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1961, 2035, 2093, 2122, 2126, 2127, 2130, 2132, 2133, 2137, 2142, 2147, 2157, 2159, 2166, 2191, 2195, 2196, 2202, 2204], "outlin": [31, 58, 2137, 2167, 2195], "joinabl": [31, 35, 1770], "joinhook": 31, "throw_on_early_termin": [31, 1770], "shadow": [31, 35, 1770, 2181, 2182], "notify_join_context": 31, "zeroredundancyoptim": [31, 35, 1770], "vacuou": 31, "inherit": [31, 1805, 2093, 2095, 2133, 2142, 2144], "join_hook": [31, 35, 1770], "join_devic": [31, 35], "join_process_group": [31, 35], "repeatedli": [31, 2130, 2139, 2171], "main_hook": 31, "post_hook": 31, "is_last_join": 31, "dcp": 32, "reshard": [32, 34, 37, 60], "storag": [32, 37, 60, 221, 311, 339, 342, 343, 435, 458, 483, 499, 520, 524, 558, 559, 584, 585, 587, 588, 908, 928, 930, 931, 935, 1065, 1135, 1196, 1285, 1289, 1300, 1314, 1322, 1386, 1408, 1475, 1476, 1516, 1580, 1597, 1877, 1910, 1924, 1931, 1961, 1966, 1970, 1985, 2011, 2017, 2034, 2057, 2091, 2094, 2100, 2107, 2114, 2117, 2127, 2130, 2141, 2144, 2147, 2158, 2160, 2166, 2171, 2174, 2175, 2177, 2194], "entrypoint": [32, 38, 41, 44, 49, 52, 53, 56, 2100, 2114], "torchtitan": [32, 36], "state_dict_sav": 32, "checkpoint_id": 32, "storage_writ": 32, "planner": 32, "style": [32, 38, 40, 69, 907, 1139, 1195, 1826, 1856, 2093, 2095, 2096, 2150, 2154, 2158, 2176, 2196], "shardedtensor": [32, 60], "dtensor": [32, 34, 38, 60, 681], "save_state_dict": 32, "fsdp": [32, 36, 60, 486, 681, 2125, 2160, 2180, 2195, 2204], "shardingstrategi": [32, 60], "hybrid_shard": [32, 60], "shard_group": 32, "pathlik": [32, 56, 69, 1386, 1924, 2147, 2150, 2154, 2158], "storagewrit": 32, "writer": [32, 2109, 2142, 2176], "saveplann": 32, "my_model": [32, 1770, 2093, 2149, 2189], "mymodul": [32, 56, 57, 60, 69, 1318, 1319, 1321, 1325, 1326, 1332, 1581, 1582, 1590, 1591, 2093, 2095, 2096, 2135, 2147, 2166], "fs_storage_writ": 32, "filesystemwrit": 32, "async_sav": 32, "de": [32, 2095, 2130, 2158, 2161], "checkpoint_futur": 32, "coordinator_rank": 32, "no_dist": 32, "state_dict_load": 32, "storage_read": 32, "fullfil": 32, "deserail": 32, "storageread": 32, "reader": [32, 2192], "loadplann": 32, "adagrad": [32, 1522, 2103, 2157, 2166], "model_state_dict": [32, 2137], "fs_storage_read": 32, "filesystemread": 32, "asyncstag": 32, "stage_data": 32, "opportun": [32, 1345, 2093, 2167, 2194, 2195, 2204], "reflect": [32, 64, 458, 520, 556, 1197, 1198, 1201, 1311, 1507, 1508, 1509, 1556, 1557, 1558, 1602, 1603, 1604, 1686, 1725, 1822, 1875, 1990, 2093, 2094, 2130, 2135, 2175, 2189], "ram": [32, 1386, 2130], "should_synchronize_after_execut": 32, "assumpt": [32, 38, 48, 52, 56, 949, 1005, 1014, 1499, 1533, 2100, 2127, 2132, 2138, 2166, 2167, 2171, 2191, 2192, 2195, 2200, 2204, 2205], "responds": 32, "synchronize_stag": 32, "innocul": 32, "statefult": 32, "blockingasyncstag": 32, "cache_staged_state_dict": 32, "type_check": 32, "automodul": 32, "act": [32, 39, 41, 49, 65, 888, 1493, 1581, 1582, 1591, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1806, 1807, 1808, 1809, 1810, 2033, 2117, 2130, 2142, 2146, 2157, 2192], "told": [32, 2095], "role": [32, 41, 43, 51, 52], "read_metadata": 32, "set_up_storage_read": 32, "prepare_local_plan": 32, "prepare_global_plan": 32, "read_data": 32, "central": [32, 71, 1268, 2138, 2140], "loadplan": 32, "storage_data": 32, "load_byt": 32, "bytesio": [32, 56, 1322, 1325, 1386, 1924, 2161, 2185], "resolve_tensor": 32, "storagelay": 32, "schedul": [32, 34, 41, 44, 50, 68, 681, 1857, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 2102, 2132, 2136, 2140, 2159, 2195, 2204], "checkpiont_id": 32, "is_coordin": 32, "validate_checkpoint_id": 32, "stroag": 32, "set_up_storage_writ": 32, "write_data": 32, "recover": 32, "writeresult": 32, "saveplan": 32, "storage_meta": 32, "storagemeta": 32, "todo": [32, 36, 851, 889, 891, 892, 1238, 2182, 2194, 2200], "resolve_data": 32, "writeitem": 32, "tensor_data": 32, "set_up_plann": 32, "create_local_plan": 32, "create_global_plan": 32, "commit_tensor": 32, "defaultloadplann": 32, "rewrit": [32, 56, 58, 65, 71, 79, 80, 2106, 2127, 2138, 2149, 2150, 2154, 2192, 2193], "requit": 32, "intrincaci": 32, "renameplann": 32, "state_dict_typ": [32, 60], "original_state_dict": 32, "foo_": [32, 1202], "flatten_sharded_tensor": 32, "_flatten_sharded_tensor": 32, "flatten_state_dict": 32, "read_item": 32, "dest_index": 32, "fqn": [32, 36, 38, 56, 2108, 2182], "weights_onli": [32, 1386, 2091, 2105, 2107], "metamodelmateri": 32, "defaultsaveplann": 32, "global_plan": 32, "finish_plan": 32, "central_plan": 32, "resolve_byt": 32, "alia": [32, 39, 45, 56, 91, 92, 111, 187, 188, 353, 406, 436, 437, 444, 523, 541, 683, 799, 801, 896, 897, 898, 899, 900, 901, 902, 924, 967, 998, 1017, 1018, 1130, 1137, 1140, 1151, 1152, 1153, 1155, 1156, 1182, 1259, 1269, 1270, 1282, 1283, 1284, 1292, 1312, 1314, 1341, 1342, 1349, 1365, 1369, 1372, 1384, 1400, 1410, 1411, 1421, 1467, 1469, 1479, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1580, 1697, 1774, 1813, 1829, 1877, 1879, 1884, 1887, 1922, 1944, 1959, 1962, 1964, 1992, 1996, 1997, 2019, 2025, 2049, 2096, 2100, 2133, 2155, 2172, 2173, 2177, 2180, 2194, 2199], "readitem": 32, "planner_data": 32, "loaditemtyp": 32, "metadataindex": 32, "dest_offset": 32, "storage_index": 32, "storage_offset": [32, 138, 520, 617, 908, 2094, 2100, 2155, 2173, 2199], "tandem": 32, "fp16planner": 32, "write_item": 32, "writeitemtyp": 32, "byte_io": 32, "itertool": [32, 39, 988, 1001], "zip_longest": 32, "dataclass": [32, 56, 57, 58, 2203], "ddploadbalancingplann": 32, "all_plan": 32, "items_per_rank": 32, "saveextradataplann": 32, "merged_data": 32, "new_plan": 32, "idempot": [32, 2166, 2168], "safeti": [32, 41, 56, 58, 69, 486, 1004, 1005, 1238, 2093, 2096, 2116, 2146, 2196], "hi": [32, 1550, 1551, 2093, 2095, 2138, 2192], "peak": [32, 34, 35, 60, 1092, 1094, 1101, 1109, 1110, 1111, 1770, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1865, 1872, 2073, 2074, 2078, 2081, 2136, 2151, 2201], "late": [32, 51, 486, 1878], "tensor_storage_s": 32, "single_file_per_rank": 32, "sync_fil": 32, "thread_count": 32, "per_thread_copy_ahead": 32, "10000000": 32, "simplif": [32, 2191], "atom": [32, 69, 2097], "distributedtensor": [32, 38], "dedup_replicated_tensor": 32, "dedup_save_to_lowest_rank": 32, "lookup_object": 32, "transform_object": 32, "allow_partial_load": 32, "lookup_tensor": 32, "transform_tensor": 32, "legaci": [32, 40, 52, 1688, 2156, 2159, 2174, 2177], "layer1": [32, 2157], "unparallel": 32, "tackl": [32, 2195], "get_model_state_dict": 32, "get_optimizer_state_dict": 32, "uniform": [32, 37, 481, 608, 972, 1515, 1599, 1669, 1901, 1902, 1949, 2124, 2155, 2180, 2199], "set_model_state_dict": 32, "set_optimizer_state_dict": 32, "getter": 32, "get_state_dict": 32, "fully_shard": [32, 2160], "tensor_parallel": 32, "parallelize_modul": [32, 38], "hide": [32, 36, 66, 1213, 2045, 2134], "canon": [32, 41, 44, 1224, 1235, 2093, 2194], "named_paramet": [32, 56, 60, 62, 64, 1201, 1314, 1318, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1877, 2142, 2147, 2157], "named_buff": [32, 56, 60, 1314, 1580, 1877, 2142, 2147], "fullyshardeddataparallel": [32, 34, 681, 2136], "fsdp_model": [32, 60], "deepcopi": [32, 64, 2157, 2161, 2182, 2204], "fsdp_optim": 32, "ddp_optim": 32, "ddp_state_dict": 32, "ddp_optim_state_dict": 32, "fsdp_state_dict": 32, "fsdp_optim_state_dict": 32, "ddp_optim_st": 32, "statedictopt": 32, "valuetyp": 32, "optimizerstatetyp": 32, "set_state_dict": 32, "optim_state_dict": [32, 60], "counterpart": [32, 887, 894, 1384, 1770, 2096, 2106, 2118, 2173, 2180, 2181, 2191, 2195], "missing_kei": [32, 1314, 1580, 1877], "miss": [32, 49, 700, 1201, 1230, 1314, 1409, 1419, 1513, 1542, 1543, 1544, 1580, 1703, 1822, 1877, 2104, 2133, 2148, 2154, 2157, 2171, 2191, 2196, 2204, 2208], "unexpected_kei": [32, 1314, 1580, 1877], "full_state_dict": [32, 60], "cpu_offload": [32, 60], "ignore_frozen_param": 32, "keep_submodule_prefix": 32, "broadcast_from_rank0": 32, "flatten_optimizer_state_dict": 32, "offload": [32, 34, 60], "oom": [32, 36, 60, 2111, 2135, 2207], "rank0": [32, 41, 51, 60], "frozen": [32, 34, 35, 60, 1228, 1318, 1324, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 2097, 2148], "betwe": 32, "format_util": 32, "dcp_to_torch_sav": 32, "dcp_checkpoint_dir": 32, "torch_save_path": 32, "torch_save_to_dcp": 32, "onlin": [32, 69, 1839], "broadcastingtorchsaveread": 32, "dynamicmetaloadplann": 32, "sd": [32, 780, 785], "path_to_model": 32, "incurr": 32, "hopefulli": [32, 2136, 2194], "extnd": 32, "quickstart": 33, "agent": [33, 43, 44, 45, 48, 50, 52, 54, 2166], "expir": 33, "metric": [33, 1092, 1094, 1101, 1874, 2073, 2074, 2078, 2109, 2142, 2159, 2176, 2195, 2201], "plane": [33, 41, 51, 749, 750, 751, 752, 753, 754, 777, 778, 779, 780, 783, 784, 785, 793, 794, 1132, 1481, 1482, 1483, 1485, 1486, 1487, 1489, 1490, 1491, 1507, 1508, 1509, 1510, 1511, 1512, 1527, 1528, 1547, 1548, 1549, 1552, 1568, 1573, 1574, 1575, 1645, 1646, 1647, 1648, 1649, 1650, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1681, 1682, 1704, 1707, 1708, 1709, 1711, 1712, 1713, 1789, 1824, 1897, 1898, 1920], "kubernet": 33, "usabl": [34, 56, 68, 2096, 2152, 2192, 2193], "fsdp1": 34, "simpler": [34, 56, 66, 1213, 2045, 2093, 2100, 2127, 2133, 2138, 2142, 2192], "throughput": [34, 60, 2093, 2129, 2130, 2136], "intuit": [34, 58, 2103, 2197], "relax": [34, 36, 39, 1037, 1078, 1330, 1331, 1793, 2117, 2161, 2195], "record_stream": [34, 2094, 2130, 2155], "limit_all_gath": [34, 60, 2136], "fsdpmodul": 34, "surfac": [34, 2183], "full_tensor": [34, 37], "checkpoint": [34, 35, 36, 52, 55, 60, 961, 1386, 1770, 2091, 2107, 2130, 2135, 2136, 2137, 2147, 2160, 2168, 2186, 2189, 2204], "onboard": [34, 2103], "appeal": [34, 36], "reshard_after_forward": 34, "shard_placement_fn": 34, "mp_polici": 34, "mixedprecisionpolici": 34, "param_dtyp": [34, 60], "reduce_dtyp": [34, 60], "output_dtyp": [34, 805, 807, 891, 2163, 2199], "cast_forward_input": [34, 60], "offload_polici": 34, "offloadpolici": 34, "unshard": [34, 60, 2136], "partit": [34, 35, 36, 37, 38, 1484, 1738, 2018, 2155, 2167, 2168, 2195, 2203, 2204], "topmost": 34, "devicemesh": [34, 38, 60], "1st": [34, 39, 2128, 2136], "0th": [34, 69, 1213, 2045], "hsdp": 34, "divisor": [34, 276, 277, 489, 490, 779, 780, 1139, 1189, 1192, 1223, 1256, 1490, 1491, 1526, 1632, 1654, 1655, 1912, 2025], "paramt": 34, "fsdplinear": 34, "set_is_last_backward": 34, "is_last_backward": 34, "microbatch": 34, "set_modules_to_backward_prefetch": 34, "pretch": 34, "singleton": [34, 39, 254, 1552, 1595, 1769, 2032, 2128], "set_modules_to_forward_prefetch": 34, "set_post_optim_ev": 34, "discard": [34, 60, 1228, 1311, 1372, 1791, 2091, 2095, 2109], "set_reduce_scatter_divide_factor": 34, "premulsum": 34, "set_requires_all_reduc": 34, "requires_all_reduc": 34, "set_requires_gradient_sync": 34, "requires_gradient_sync": 34, "set_reshard_after_backward": 34, "reshard_after_backward": 34, "set_unshard_in_backward": 34, "unshard_in_backward": 34, "unshardhandl": 34, "register_fsdp_forward_method": 34, "method_nam": [34, 69], "autocast": [34, 1089, 1586, 2100, 2130, 2133, 2137, 2205], "cpuoffloadpolici": 34, "freed": [34, 60, 150, 923, 944, 1047, 1101, 2078, 2080, 2114, 2130, 2136, 2139, 2166, 2173, 2189, 2207], "h2d": 34, "d2h": 34, "insuffici": [34, 1090, 1218, 2071, 2191, 2205], "distributedoptim": [35, 1770, 2166, 2167], "rref": [35, 1770, 2096, 2167], "optimizer_class": 35, "params_rref": 35, "get_gradi": [35, 2155, 2166, 2167], "multithread": [35, 947, 2130], "dist_autograd": [35, 1770, 2166, 2167], "rpc": [35, 68, 1770, 2096, 2160, 2167, 2168], "context_id": [35, 1770, 2166, 2167], "rref1": [35, 2166, 2167], "worker1": [35, 68, 1770, 2166, 2167], "rref2": [35, 2166, 2167], "to_her": [35, 1770, 2155, 2166, 2167, 2168], "dist_optim": [35, 1770, 2167], "postlocalsgdoptim": 35, "afer": 35, "modelaverag": 35, "localsgd": 35, "model_averag": 35, "post_localsgd_hook": 35, "postlocalsgdst": 35, "subgroup": 35, "start_localsgd_it": 35, "warmup_step": 35, "local_optim": 35, "periodicmodelaverag": 35, "parameters_as_bucket_view": 35, "overlap_with_ddp": 35, "consumpt": [35, 64, 1825, 2171, 2176, 2183], "offset": [35, 225, 226, 227, 228, 339, 520, 558, 757, 908, 1132, 1133, 1134, 1135, 1198, 1349, 1523, 1642, 1643, 1678, 1770, 1894, 1895, 1973, 2022, 2024, 2094, 2096, 2100, 2117, 2147, 2173, 2193, 2199], "intact": [35, 2166], "ddp_zero_hook": 35, "disjointli": 35, "trail": [35, 1815, 1817, 2117, 2124, 2128, 2133], "wari": 35, "static_graph": [35, 1770], "third": [35, 39, 1143, 1144, 1404, 1484, 1491, 1509, 1512, 1549, 1575, 1872, 1874, 2093, 2100, 2130, 2134, 2142, 2157, 2158, 2159, 2192], "add_param_group": [35, 1793, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860], "param_group": [35, 60, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 1868, 1871, 2157, 2204], "trainabl": [35, 1089, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1856, 1857, 1858, 1859, 1860, 2133], "consolidate_state_dict": 35, "consolid": [35, 60], "pertain": 35, "alpha": [36, 37, 39, 97, 98, 99, 100, 105, 106, 107, 108, 109, 110, 151, 152, 312, 313, 488, 554, 561, 562, 563, 564, 696, 697, 700, 701, 702, 755, 781, 786, 970, 1086, 1087, 1272, 1286, 1488, 1498, 1521, 1568, 1608, 1652, 1660, 1675, 1676, 1686, 1704, 1739, 1836, 1857, 1952, 1953, 1966, 1971, 1986, 1991, 1992, 2094, 2127, 2133, 2154, 2157, 2195, 2199], "migrat": [36, 52, 61, 1416, 1824, 2137, 2164], "pippi": 36, "micro": 36, "convent": [36, 51, 56, 60, 69, 335, 991, 1144, 1162, 1164, 1188, 1211, 1226, 1228, 1494, 1495, 1496, 1542, 1543, 1544, 1620, 1921, 1924, 2026, 2091, 2100, 2107, 2127, 2138, 2142, 2147], "promis": 36, "intrus": [36, 2133], "said": [36, 938, 939, 940, 941, 942, 943, 1004, 2103, 2145, 2192], "gpipe": 36, "1f1b": 36, "interleav": [36, 58, 1864], "bf": [36, 1629, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "pp": [36, 1311, 1533, 1956], "compos": [36, 38, 39, 64, 69, 749, 750, 751, 752, 753, 754, 777, 778, 783, 784, 785, 793, 794, 993, 1203, 1205, 1206, 1207, 1213, 1314, 1481, 1482, 1483, 1485, 1486, 1487, 1489, 1490, 1491, 1507, 1508, 1509, 1510, 1511, 1512, 1527, 1528, 1547, 1548, 1549, 1568, 1573, 1574, 1575, 1580, 1629, 1634, 1635, 1645, 1646, 1647, 1648, 1649, 1650, 1653, 1661, 1662, 1663, 1664, 1665, 1666, 1681, 1682, 1704, 1707, 1708, 1709, 1711, 1712, 1713, 1877, 1897, 1898, 2045, 2093, 2096, 2115, 2133, 2134, 2137, 2142, 2154, 2158, 2176, 2199, 2200], "3d": [36, 712, 715, 718, 746, 751, 754, 778, 780, 785, 790, 1416, 1483, 1487, 1491, 1494, 1496, 1509, 1512, 1519, 1520, 1526, 1528, 1542, 1544, 1549, 1575, 1586, 1633, 1647, 1650, 1651, 1655, 1663, 1666, 1674, 1680, 1682, 1697, 1709, 1713, 1725, 1757, 2117, 2145, 2161, 2171, 2176], "llama": [36, 2136], "pipeliningshapeerror": 36, "paral": [36, 37], "portion": [36, 60, 1193, 1516, 1612, 1727, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 2162, 2196, 2204, 2205], "traceabl": [36, 56, 69, 625, 832, 1233, 2093, 2100, 2161, 2191], "schedulegpip": 36, "n_microbatch": 36, "in_dim": [36, 65, 66, 922, 935, 936, 1203, 1213, 2045, 2100, 2134], "servic": [36, 43, 2132, 2191], "condens": 36, "partition": 36, "model_arg": [36, 2150], "modelarg": 36, "tok_embed": 36, "moduledict": [36, 1787, 1788, 1789, 2095, 2142], "layer_id": 36, "n_layer": 36, "transformerblock": [36, 38, 2136], "token": [36, 51, 1037, 1078, 1079, 1089, 2091, 2097, 2197, 2199], "freqs_ci": 36, "meta": [36, 37, 53, 57, 58, 60, 64, 69, 336, 1236, 2100, 2150, 2160, 2166, 2173, 2174, 2176, 2178, 2191, 2194, 2196, 2203], "num_stag": 36, "stage_index": 36, "elif": [36, 69, 684, 1321, 1545, 2095, 2096, 2139, 2192, 2203], "output_arg": 36, "emb": [36, 1135, 1931, 1961], "modulelist": [36, 1609, 2142], "lmhead": 36, "lin": 36, "in_featur": [36, 64, 731, 739, 740, 743, 744, 767, 775, 1211, 1314, 1484, 1565, 1567, 1580, 1760, 1787, 1788, 1789, 1820, 1821, 1824, 1877, 2104, 2142], "out_featur": [36, 64, 731, 739, 740, 743, 744, 767, 775, 1211, 1314, 1497, 1565, 1567, 1580, 1760, 1787, 1788, 1789, 1820, 1821, 1824, 1877, 2104, 2142], "proj": [36, 1550], "splitpoint": 36, "pipe": [36, 41, 54, 2166, 2209], "mod": [36, 37, 56, 57, 69, 732, 733, 743, 749, 750, 751, 756, 757, 767, 775, 825, 826, 827, 828, 864, 865, 894, 1201, 1317, 1318, 1324, 1331, 1822, 2037, 2095, 2096, 2108, 2158, 2181, 2190, 2204, 2205], "mb_arg": 36, "split_spec": 36, "submod_0": 36, "interpretermodul": [36, 56], "submod_1": 36, "reconstruct": [36, 1039, 1404, 1492, 1493, 2122, 2138, 2147, 2158, 2192], "replai": [36, 1037, 1078, 2130, 2159, 2189, 2192, 2205], "stage_mod": 36, "get_stage_modul": 36, "stage_idx": 36, "build_stag": 36, "dp_mod": 36, "kept": [36, 56, 60, 64, 69, 708, 790, 796, 1494, 1495, 1496, 1542, 1543, 1544, 1620, 1697, 1738, 1757, 2096, 2114, 2136, 2150, 2164, 2171, 2186], "huggingfac": [36, 2197, 2201], "gpt2": 36, "acycl": [36, 57, 805, 2127, 2192], "dag": [36, 57, 2130, 2192], "pipelininig": 36, "truli": [36, 58, 69, 2100, 2149, 2154, 2184], "almost": [36, 1361, 1362, 2148, 2192, 2194, 2202], "pipelineschedulesingl": 36, "pipelineschedulemulti": 36, "schedule1f1b": 36, "scheduleinterleaved1f1b": 36, "scheduleloopedbf": 36, "scheduleinterleavedzerobubbl": 36, "schedulezbvzerobubbl": 36, "mb_kwarg": 36, "split_polici": 36, "marker": [36, 1039, 1427, 2050], "split_gm": 36, "has_loss_and_backward": 36, "loss_spec": 36, "pipe_split": 36, "mm_param": 36, "tensorchunkspec": 36, "split_dim": [36, 2155, 2199], "split_args_kwargs_into_chunk": 36, "args_chunk_spec": 36, "kwargs_chunk_spec": 36, "spec": [36, 37, 41, 43, 54, 56, 57, 71, 806, 807, 837, 839, 840, 843, 846, 851, 2150, 2163, 2177], "kwargs_split": 36, "args_split": 36, "merge_chunk": 36, "chunk_spec": 36, "input_arg": [36, 56, 1834, 2156], "dw_builder": 36, "feed": [36, 69, 2093, 2135, 2142, 2181, 2185, 2194], "stage0": 36, "stage1": 36, "forth": [36, 1865, 2039, 2091, 2159, 2189], "bypass": [36, 1004, 1144, 2100, 2130, 2133, 2157, 2196, 2202], "stage_modul": 36, "pipe_info": 36, "pipeinfo": 36, "_pipelinestag": 36, "output_merge_spec": 36, "drain": 36, "steadi": 36, "arxiv": [36, 39, 1550, 1600, 1627, 1789, 1824, 1882, 1936, 1995, 2127, 2177], "pdf": [36, 258, 1499, 1956, 2111, 2127], "2104": [36, 1144], "04473": 36, "num_microbatch": 36, "pp_size": 36, "flex_pp": 36, "num_round": 36, "pp_group_siz": 36, "ab": [36, 39, 90, 91, 626, 627, 683, 990, 1144, 1346, 1367, 1368, 1370, 1371, 1384, 1387, 1550, 1600, 1627, 1630, 1632, 1727, 1789, 1824, 1827, 1874, 1882, 1886, 1936, 2094, 2096, 2115, 2116, 2130, 2142, 2155, 2171, 2177, 2189, 2190, 2192, 2193, 2195, 2199, 2205], "2211": 36, "05953": 36, "simliar": 36, "bubbl": 36, "10241": 36, "zb1p": 36, "stage_index_to_group_rank": 36, "zbv": 36, "zb": 36, "unequ": [36, 750, 751, 752, 753, 754, 1508, 1509, 1511, 1512], "unbalanc": [36, 1515, 1587], "_step_microbatch": 36, "use_full_backward": 36, "transpar": [37, 58, 60, 2132, 2166, 2168], "fsdp2": 37, "empow": 37, "converg": [37, 1387, 1612, 1787, 1840, 1841, 1872, 2126, 2142, 2145, 2157], "redistribut": [37, 38, 2148], "local_tensor": 37, "create_dtensor": 37, "from_loc": 37, "run_check": 37, "ndim": [37, 1380, 1381, 2115, 2117, 2171, 2177, 2193], "grad_plac": 37, "syntat": 37, "sugar": [37, 44, 2095], "to_loc": 37, "hint": [37, 71, 81, 82, 681, 1037, 1078, 1089, 1228, 1238, 1245, 1315, 1586, 1624, 1625, 1626, 1627, 1628, 2093, 2095, 2096, 2100, 2130, 2133, 2150, 2166, 2191, 2204], "src_dim": 37, "dst_dim": 37, "formula": [37, 39, 87, 779, 780, 919, 921, 935, 936, 971, 980, 1272, 1273, 1340, 1406, 1407, 1594, 1654, 1655, 1745, 1859, 1895, 1948, 2100, 2133, 2138, 2159, 2165, 2171, 2191], "asynccollectivetensor": 37, "placement_typ": 37, "distribute_tensor": [37, 38], "stub": [37, 800, 802, 2158], "is_parti": 37, "is_repl": 37, "is_shard": 37, "leaf": [37, 48, 57, 150, 222, 335, 448, 488, 503, 504, 804, 866, 869, 909, 923, 1211, 1834, 2011, 2117, 2126, 2127, 2136, 2182, 2194], "materi": [37, 56, 60, 930, 934, 935, 936, 1020, 1641, 1642, 1643, 1773, 1774, 1860, 1916, 1917, 2117, 2133, 2147, 2195], "compli": [37, 2096, 2158], "truth": [37, 38, 1515, 1669, 1695, 1718, 2103, 2141, 2176], "middl": [37, 2117, 2150, 2154, 2192, 2204], "xlashardedtensor": 37, "xla": [37, 2100, 2147, 2174, 2191], "distribute_modul": 37, "partition_fn": 37, "input_fn": 37, "output_fn": 37, "forward_pre_hook": [37, 1805, 2142], "forward_hook": [37, 2142, 2200], "set_default_dtyp": [37, 895, 971, 980, 1145, 1147, 1157, 1162, 1180, 1196, 1199, 1261, 1272, 1273, 1334, 1831, 1901, 1905, 1908, 1934, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2089], "fill_valu": [37, 260, 446, 1199, 1200, 1499, 2094, 2130, 2199], "interv": [37, 39, 54, 258, 895, 968, 1023, 1194, 1433, 1434, 1875, 1901, 1902, 1949, 2109, 2117, 2130, 2136, 2159, 2209], "varianc": [37, 39, 1027, 1494, 1495, 1496, 1524, 1533, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1620, 1679, 1683, 1782, 1784, 1838, 1856, 1857, 1896, 1905, 1906, 2040, 2041, 2124, 2142], "commdebugmod": 37, "torchdispatchmod": [37, 2100, 2133, 2204], "comm_mod": 37, "get_comm_count": 37, "generate_comm_debug_tracing_t": 37, "noise_level": 37, "generate_json_dump": 37, "comm_mode_log": 37, "json": [37, 44, 49, 54, 2140, 2159, 2198, 2202], "browser": [37, 2198, 2202, 2204], "get_parameter_info": 37, "get_sharding_info": 37, "get_total_count": 37, "log_comm_debug_tracing_table_to_fil": 37, "txt": [37, 56, 1322, 1325, 2158, 2185, 2204, 2205], "consol": [37, 41, 45, 48, 49, 52, 2176], "visualize_shard": 37, "tabul": [37, 69], "context_parallel": 37, "buffer_seq_dim": 37, "no_restore_buff": 37, "cp": 37, "sdpa": [37, 2117], "local_map": 37, "out_plac": 37, "in_plac": 37, "redistribute_input": 37, "placementtyp": 37, "examin": [37, 69, 2117, 2142, 2154, 2159, 2207], "assertionerror": [37, 60, 69, 71, 78, 745, 1057, 1834, 2122, 2156, 2178, 2205], "valueerror": [37, 68, 71, 924, 967, 1015, 1312, 1314, 1580, 1793, 1794, 1813, 1816, 1877, 2133, 2156, 2170, 2178, 2203], "mm_allreduce_forward": 37, "w": [37, 39, 66, 150, 771, 919, 921, 923, 930, 933, 935, 936, 944, 971, 980, 1004, 1027, 1203, 1230, 1255, 1272, 1273, 1311, 1482, 1483, 1490, 1491, 1493, 1495, 1496, 1508, 1509, 1515, 1519, 1520, 1522, 1523, 1524, 1531, 1543, 1544, 1552, 1563, 1564, 1574, 1575, 1585, 1586, 1587, 1592, 1593, 1615, 1631, 1632, 1634, 1635, 1651, 1659, 1677, 1678, 1686, 1722, 1728, 1729, 1788, 1789, 1821, 1824, 2094, 2100, 2115, 2116, 2124, 2127, 2133, 2138, 2157, 2158, 2176, 2202], "partial_sum_tensor": 37, "reduced_tensor": 37, "funcol": 37, "row_wis": 37, "col_wis": 37, "col": [37, 1838, 2022, 2024, 2094, 2122], "local_mm_allreduce_forward": 37, "w_dt": 37, "x_dt": 37, "y_dt": 37, "register_shard": 37, "intput": 37, "_softmax": [37, 2155, 2172, 2199], "custom_softmax_shard": 37, "half_to_float": [37, 2199], "softmax_dim": 37, "acceptable_shard": 37, "all_repl": 37, "sharding_dim": 37, "all_shard": 37, "colwis": 38, "parallelize_plan": 38, "sub_modul": 38, "parallelstyl": 38, "slice": [38, 56, 69, 71, 80, 82, 607, 706, 707, 1226, 1494, 1495, 1496, 1614, 1616, 1620, 1744, 1745, 1823, 1913, 1930, 1931, 1961, 1972, 2027, 2093, 2097, 2117, 2130, 2154, 2155, 2171, 2172, 2173, 2175, 2177, 2195, 2199], "colwiseparallel": 38, "tp_mesh": 38, "w1": [38, 69], "w2": [38, 69], "rowwiseparallel": 38, "mlp": [38, 1760, 2150, 2161], "input_layout": 38, "output_layout": 38, "use_local_output": 38, "sharded_mod": 38, "mind": [38, 1360, 1378, 1522, 2100, 2127, 2134, 2138, 2161, 2173, 2180, 2185, 2195, 2202], "sequenceparallel": 38, "sequence_dim": 38, "layernorm": [38, 1534, 1542, 1543, 1544, 1624, 1626, 1628, 1700, 2163, 2205], "rmsnorm": [38, 1735], "preparemoduleinput": 38, "desired_input_layout": 38, "input_kwarg_layout": 38, "desired_input_kwarg_layout": 38, "placehold": [38, 56, 69, 814, 834, 843, 861, 1226, 1228, 1541, 2130, 2190, 2193, 2203], "attn": [38, 1626, 1628], "preparemoduleoutput": 38, "desired_output_layout": 38, "loss_parallel": 38, "crossentropyloss": [38, 1587, 1669, 2137, 2204], "logit": [38, 39, 391, 1493, 1515, 1659, 1669, 1688, 2094, 2155, 2172], "label_smooth": [38, 1515, 1669, 2094], "dist_input": 38, "randint": [38, 544, 973, 1027, 1126, 1187, 1499, 1630, 1669, 1670, 1779, 1780, 1975, 2094, 2098, 2116, 2155, 2176, 2180], "parameteriz": 39, "tensorflow": [39, 1857, 2127, 2176], "surrog": 39, "likelihood": [39, 1484, 1533, 1587, 1594, 1683, 1722, 1730, 2130], "ratio": [39, 41, 617, 1527, 1528, 1681, 1682, 2094, 2111, 2130, 2171, 2180, 2201], "reinforc": [39, 1610, 1741], "reparameter": [39, 1201, 1789, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810, 1811, 1812, 1824], "trick": [39, 941, 1493, 1688, 2117, 2127, 2138, 2140, 2195], "autoencod": 39, "whilst": [39, 2130], "densiti": [39, 258, 301, 1276, 1277, 1956, 2094, 2172], "log_prob": [39, 1484, 1499, 1670, 2094], "theta": [39, 1651, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2094], "pi": [39, 173, 377, 709, 980, 1272, 1273, 1366, 1529, 1594, 1684, 1730, 1863, 1864, 1886, 1947, 1948, 1951, 1952, 1953, 1954, 1956, 1990, 2095, 2096, 2158, 2172], "reward": 39, "ascent": 39, "prob": [39, 2094], "policy_network": 39, "next_stat": 39, "rsampl": 39, "parameter": [39, 377, 454, 1321, 2118, 2171], "has_rsampl": 39, "batch_shap": 39, "event_shap": 39, "validate_arg": 39, "arg_constraint": 39, "cdf": 39, "cumul": [39, 41, 1123, 1124, 1125, 1126, 1127, 1394, 1494, 1495, 1496, 1529, 1553, 1554, 1555, 1620, 1684], "mass": 39, "enumerate_support": 39, "discret": [39, 59, 481, 486, 1160, 1161, 1162, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1173, 1174, 1179, 1181, 1688, 1956, 2111, 2176, 2180], "cardin": [39, 1416], "univari": 39, "cartesian": [39, 988, 1416, 1886], "_instanc": 39, "icdf": 39, "perplex": 39, "sample_shap": 39, "sample_n": 39, "set_default_validate_arg": 39, "mimic": [39, 1872], "stddev": 39, "exp_famili": 39, "famili": 39, "p_": [39, 992, 1406, 1859], "langl": 39, "rangl": 39, "carrier": 39, "analyt": [39, 949, 950, 1677, 2171], "bregman": 39, "courtesi": 39, "frank": 39, "nielsen": 39, "nock": 39, "70": [39, 965, 1373, 1892], "odd": [39, 1165, 1166, 1167, 1175, 1176, 1177, 1661, 1662, 1663], "lower_bound": 39, "upper_bound": 39, "has_enumerate_support": 39, "param_shap": 39, "concentration1": 39, "concentration0": 39, "concentr": 39, "1046": 39, "2nd": [39, 617, 1588, 1615, 1725, 2128], "greaterthan": 39, "total_count": 39, "71": 39, "trial": [39, 286], "integergreaterthan": 39, "ldot": [39, 286, 1346, 1354, 1385, 1401, 1416, 1552, 1573, 1574, 1575, 1595, 1769, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "unnorm": [39, 1515, 1659, 1669, 1688], "likewis": [39, 2017], "25": [39, 496, 586, 587, 588, 965, 990, 1276, 1382, 1387, 1525, 1583, 1585, 1588, 1760, 1770, 1817, 1819, 1843, 1872, 1893, 2039, 2093, 2147, 2171, 2172], "independentconstraint": 39, "simplex": 39, "loc": [39, 1386], "lorentz": 39, "3214": 39, "width": [39, 790, 796, 888, 1275, 1276, 1277, 1490, 1491, 1508, 1509, 1511, 1512, 1548, 1549, 1574, 1575, 1587, 1615, 1633, 1697, 1757, 2116, 2171], "df": 39, "chi": 39, "continuous_bernoulli": 39, "lim": [39, 1311], "499": 39, "501": 39, "2538": [39, 1346], "pervas": 39, "loaiza": 39, "ganem": 39, "cunningham": 39, "jp": 39, "1907": 39, "06845": 39, "8954": 39, "greaterthaneq": 39, "df1": 39, "df2": 39, "fisher": 39, "snedecor": 39, "2453": 39, "degre": [39, 1027, 1121, 1128, 1314, 1352, 1353, 1580, 1589, 1629, 1770, 1877, 1900, 1920, 1988, 1989, 2040, 2041, 2094, 2138, 2155, 2171], "freedom": [39, 1027, 1988, 1989, 2040, 2041, 2138], "geometric_": [39, 2094, 2180], "0124": 39, "half_cauchi": 39, "half_norm": 39, "base_distribut": 39, "reinterpreted_batch_ndim": 39, "reinterpret": [39, 499, 2194], "diagon": [39, 65, 224, 260, 595, 596, 597, 598, 981, 1023, 1027, 1131, 1132, 1133, 1135, 1144, 1157, 1206, 1207, 1258, 1344, 1356, 1358, 1361, 1373, 1377, 1641, 1642, 1643, 1727, 1738, 1973, 2016, 2020, 2021, 2022, 2023, 2024, 2094, 2133, 2155, 2175, 2199], "multivari": [39, 1466, 2172], "multivariate_norm": 39, "mvn": 39, "scale_tril": 39, "diag": [39, 66, 1205, 1206, 1207, 1350, 1351, 1378, 1882, 1973, 1994, 1995, 2094, 2155], "diagn": 39, "inverse_gamma": 39, "2953": 39, "1729": [39, 2142], "lkj_choleski": 39, "lkj": 39, "matric": [39, 260, 697, 700, 970, 982, 983, 992, 993, 994, 995, 1132, 1258, 1335, 1344, 1345, 1346, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1364, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1377, 1378, 1379, 1387, 1395, 1404, 1406, 1419, 1530, 1589, 1651, 1685, 1787, 1793, 1880, 1882, 1892, 1940, 1966, 1970, 1971, 1994, 1995, 2020, 2021, 2023, 2094, 2115, 2138, 2145, 2171, 2177], "eta": [39, 1836, 1839, 1858], "proport": [39, 1547, 1548, 1549, 1586, 1628], "det": [39, 1352, 1353, 1374, 1395, 2094, 2155], "l": [39, 746, 771, 971, 980, 986, 993, 994, 995, 1144, 1272, 1273, 1314, 1334, 1344, 1345, 1350, 1351, 1352, 1353, 1357, 1361, 1362, 1404, 1406, 1489, 1492, 1493, 1494, 1507, 1515, 1518, 1519, 1526, 1531, 1539, 1540, 1542, 1545, 1546, 1550, 1562, 1571, 1573, 1580, 1582, 1586, 1587, 1596, 1612, 1629, 1630, 1632, 1738, 1799, 1807, 1815, 1817, 1843, 1877, 1928, 1990, 2094, 2096, 2122, 2127, 2176, 2192, 2193, 2204, 2205], "lkjcorr": 39, "onion": 39, "3x3": [39, 1127, 2018], "3516": 39, "9361": 39, "1899": [39, 1417], "4748": 39, "8593": 39, "vine": 39, "2009": [39, 1882, 1995], "lewandowski": 39, "dorota": 39, "kurowicka": 39, "harri": [39, 1956], "journal": [39, 1899], "1016": 39, "jmva": 39, "04": [39, 1187, 1392, 1949, 1956], "008": 39, "corrcholeski": 39, "log_norm": [39, 2155], "lowrank_multivariate_norm": 39, "cov_factor": 39, "cov_diag": 39, "covari": [39, 983, 1023, 1027, 1494, 1495, 1496, 1620, 1882], "covariance_matrix": 39, "2102": 39, "5429": [39, 2020], "woodburi": 39, "lemma": 39, "capacit": 39, "precision_matrix": 39, "mixture_same_famili": 39, "mixture_distribut": 39, "component_distribut": 39, "rightmost": [39, 983, 1276, 1277, 2096], "gaussian": [39, 1529, 1533, 1610, 1683, 1684, 1741, 1955, 2172], "gmm": 39, "bivari": 39, "categori": [39, 44, 2096, 2098, 2150, 2154, 2157, 2159, 2162, 2174, 2198, 2200], "innermost": [39, 69, 233, 1268, 1277, 1928], "1338": 39, "mathbf": [39, 1335, 1788, 1789, 1821, 1824, 1858], "sigma": [39, 173, 377, 771, 1493, 1530, 1531, 1532, 1550, 1551, 1610, 1611, 1685, 1741, 1788, 1821, 1950, 1988, 1989, 2040, 2041, 2094], "triangular": [39, 993, 994, 995, 1344, 1345, 1351, 1353, 1361, 1362, 1369, 1372, 1373, 1375, 1377, 1640, 1641, 1642, 1643, 1727, 1738, 1865, 1892, 2020, 2021, 2022, 2023, 2024], "decomposit": [39, 56, 57, 69, 993, 994, 995, 1258, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1356, 1361, 1362, 1363, 1364, 1369, 1373, 1374, 1378, 1379, 1404, 1406, 1787, 1880, 1882, 1886, 1892, 1994, 1995, 2145, 2150, 2154, 2191, 2194, 2203, 2204], "positivedefinit": 39, "lowercholeski": 39, "negative_binomi": 39, "halfopeninterv": 39, "mu": [39, 377, 1857, 1859], "one_hot_categor": 39, "onehot": 39, "5623": 39, "nonneg": [39, 1630, 1882, 1995, 2172], "pmf": 39, "mathrm": [39, 972, 1352, 1353, 1354, 1355, 1366, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1589, 1594, 1595, 1620, 1769, 1787, 1840, 1841, 1842, 1858, 1896, 2127, 2172], "relaxed_bernoulli": 39, "temperatur": [39, 1688], "parametr": [39, 1201, 1790, 1821, 1822, 1824, 2118, 2133], "reparametriz": 39, "99": [39, 1326, 1857, 2093], "2951": [39, 1414], "3442": 39, "8918": 39, "9021": 39, "maddison": 39, "2017": [39, 1624, 1626, 1628, 1975, 2148], "reparametr": [39, 1688, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1824], "jang": 39, "relaxed_categor": 39, "1294": [39, 993], "2324": [39, 1314, 1580, 1877], "3859": 39, "2523": 39, "student": 39, "transformed_distribut": 39, "composit": [39, 65, 1205, 1362, 1787, 2093, 2096, 2100, 2134, 2142, 2154], "basedistribut": 39, "dx": [39, 56, 1127, 1492, 2018, 2094, 2100, 2133, 2134, 2172], "dy": [39, 56], "logist": [39, 1610, 1613, 1741, 2172], "sigmoidtransform": 39, "affinetransform": 39, "invert": [39, 69, 1305, 1346, 1355, 1356, 1362, 1368, 1375, 1377, 1380, 1381, 1395, 1576, 1577, 1578, 2020, 2094, 2145, 2166], "3418": 39, "upper": [39, 57, 181, 182, 183, 594, 808, 981, 986, 993, 994, 995, 997, 1158, 1159, 1232, 1275, 1276, 1344, 1345, 1351, 1353, 1361, 1362, 1373, 1377, 1599, 1641, 1643, 1727, 1736, 1737, 1738, 1865, 1872, 1892, 1907, 1928, 2020, 2023, 2024, 2094, 2124, 2155, 2172, 2178, 2204], "von_mis": 39, "circular": [39, 1501, 1502, 1503, 1507, 1508, 1509, 1556, 1557, 1558, 1725], "von": 39, "mise": 39, "unconstrain": [39, 1793], "angl": [39, 766, 914, 1128, 1395, 1566, 1886, 1900, 1943, 2094, 2155, 2171], "9777": 39, "radian": [39, 709, 914, 1128, 1900, 2094, 2155], "simul": [39, 488, 814, 816, 2159, 2161, 2164, 2191], "1979": 39, "152": [39, 617], "157": 39, "_rejection_sampl": 39, "88443": 39, "4784": [39, 1419], "symmetr": [39, 817, 839, 971, 980, 993, 994, 995, 1165, 1166, 1167, 1172, 1174, 1178, 1179, 1181, 1272, 1273, 1334, 1344, 1345, 1350, 1351, 1353, 1357, 1358, 1359, 1366, 1369, 1372, 1378, 1387, 1787, 1793, 1872, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2161, 2164], "x_ij": 39, "wu": [39, 1387], "2018": [39, 1387, 1877, 1890], "sawyer": 39, "2007": 39, "anderson": 39, "2003": 39, "ed": [39, 65, 1518, 1519, 2127, 2158, 2183, 2202, 2206], "odel": 39, "feiveson": 39, "1966": 39, "samplecovari": 39, "jasa": 39, "61": 39, "313": [39, 2204], "199": 39, "203": [39, 617], "ku": 39, "bloomfield": 39, "2010": [39, 2124], "ox": 39, "max_try_correct": 39, "bartlett": [39, 971], "singular": [39, 1346, 1360, 1361, 1367, 1369, 1371, 1372, 1378, 1379, 1387, 1395, 1404, 1788, 1793, 1882, 1994, 1995, 2145], "inf": [39, 60, 258, 695, 697, 700, 701, 702, 915, 970, 986, 1303, 1304, 1306, 1308, 1309, 1346, 1361, 1367, 1371, 1374, 1384, 1395, 1470, 1570, 1614, 1624, 1738, 1776, 1785, 1799, 1807, 1827, 1921, 1928, 2126, 2127, 2134, 2145, 2172, 2178, 2180, 2186, 2205], "kl_diverg": 39, "kullback": [39, 1545, 1698], "leibler": [39, 1545, 1698], "notimplementederror": [39, 2100, 2104, 2117, 2158], "register_kl": 39, "type_p": 39, "type_q": 39, "pairwis": [39, 1539, 1589, 1629], "kl_normal_norm": 39, "ambigu": [39, 69, 233, 1299, 1510, 1511, 1512, 1526, 1576, 1577, 1578, 1633, 2096], "runtimewarn": 39, "basep": 39, "derivedq": 39, "kl_version1": 39, "derivedp": 39, "baseq": 39, "kl_version2": 39, "tie": 39, "abstransform": 39, "cache_s": 39, "event_dim": 39, "affin": [39, 60, 472, 473, 474, 475, 476, 760, 762, 763, 764, 817, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1553, 1554, 1555, 1562, 1563, 1564, 1567, 1595, 1620, 1651, 1769, 2130, 2142], "cattransform": 39, "tseq": 39, "functor": [39, 1086, 1087], "submatrix": 39, "x0": [39, 2186, 2197], "t0": [39, 1268, 1836, 2095], "exptransform": 39, "identity_transform": 39, "composetransform": 39, "corrcholeskytransform": 39, "uncontrain": 39, "euclidean": [39, 990, 1723], "x_i": [39, 65, 997, 1123, 1124, 1125, 1126, 1383, 1390, 1570, 1589, 1595, 1614, 1616, 1629, 1706, 1744, 1769, 1889, 1972, 1988, 1989, 2018, 2040, 2041, 2042, 2172], "stickbreakingtransform": 39, "r_i": 39, "tanh": [39, 577, 771, 776, 808, 915, 1529, 1531, 1532, 1550, 1551, 1579, 1596, 1598, 1622, 1684, 1717, 1750, 2094, 2115, 2116, 2124, 2155, 2163, 2171, 2199], "unsign": [39, 2164, 2174, 2177, 2178, 2195], "z_i": 39, "s_i": 39, "y_i": [39, 997, 1123, 1124, 1125, 1126, 1383, 1390, 1595, 1629, 1769, 2018, 2042, 2138], "sqrt": [39, 69, 377, 549, 674, 675, 771, 1023, 1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1281, 1334, 1416, 1494, 1495, 1496, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1529, 1531, 1532, 1534, 1542, 1543, 1544, 1547, 1548, 1549, 1550, 1551, 1552, 1565, 1567, 1595, 1596, 1598, 1620, 1684, 1738, 1769, 1793, 1837, 1838, 1839, 1840, 1841, 1844, 1856, 1857, 1896, 1923, 1955, 1988, 1989, 2094, 2115, 2122, 2124, 2126, 2127, 2155, 2171, 2172, 2178, 2199], "cumulativedistributiontransform": 39, "copula": 39, "base_dist": 39, "independenttransform": 39, "base_transform": 39, "log_abs_det_jacobian": 39, "lowercholeskytransform": 39, "positivedefinitetransform": 39, "powertransform": 39, "expon": [39, 268, 269, 280, 468, 469, 1187, 1194, 1338, 1368, 1484, 1568, 1723, 1889, 1899, 1936, 2094, 2174, 2177, 2199], "reshapetransform": 39, "in_shap": 39, "out_shap": 39, "softplustransform": 39, "tanhtransform": 39, "softmaxtransform": 39, "biject": 39, "hmc": 39, "stacktransform": 39, "stick": [39, 2157], "aris": [39, 69, 2127, 2191], "memoiz": [39, 2194], "_call": [39, 2204], "_invers": 39, "codomain": [39, 2127], "iff": [39, 1586], "weaker": [39, 2130], "pseudoinvers": [39, 1355, 1372, 1380], "monoton": [39, 1579, 1717, 1928], "forward_shap": 39, "inverse_shap": 39, "corr_choleski": 39, "greater_than": 39, "greater_than_eq": 39, "integer_interv": 39, "less_than": 39, "lower_choleski": 39, "lower_triangular": 39, "nonnegative_integ": 39, "one_hot": [39, 2094, 2155], "positive_integ": 39, "positive_semidefinit": 39, "positive_definit": 39, "real_vector": 39, "unit_interv": 39, "is_discret": 39, "constrain": [39, 1232, 1239, 1617, 2096, 2142], "_cat": 39, "dependent_properti": 39, "_dependentproperti": 39, "_greaterthan": 39, "_greaterthaneq": 39, "_independentconstraint": 39, "_integerinterv": 39, "_interv": 39, "half_open_interv": 39, "_halfopeninterv": 39, "is_depend": 39, "_depend": 39, "refin": [39, 56, 1321, 2116], "constraint1": 39, "constraint2": 39, "_lessthan": 39, "_multinomi": 39, "_stack": [39, 2155], "constraintregistri": 39, "biject_to": 39, "transform_to": 39, "overparameter": 39, "rotat": [39, 1920, 1994], "hamiltonian": 39, "mont": 39, "carlo": 39, "invari": [39, 56, 1813, 1968, 1976, 1977, 1978, 1979, 1980, 1981, 2168, 2171, 2189, 2203], "potential_energi": 39, "cheap": [39, 1228, 1484, 2195], "svi": 39, "fewer": [39, 56, 65, 704, 706, 707, 710, 996, 1335, 1336, 1402, 1412, 1414, 1415, 1417, 1420, 1471, 1474, 1533, 1668, 1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 1890, 1975, 1988, 1989, 1993, 2014, 2040, 2041, 2102, 2128, 2147, 2178, 2204, 2207], "my_constraint": 39, "my_transform": 39, "myconstraintclass": 39, "my_factori": 39, "mytransform": 39, "param1": [39, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 2142], "param2": [39, 2142], "constraint_registri": 39, "my_registri": 39, "construct_transform": 39, "myconstraint": 39, "from_dlpack": [40, 910], "ext_tensor": [40, 1195], "extern": [40, 1040, 1195, 1330, 2036, 2109, 2129, 2130, 2145, 2150, 2154, 2156, 2183, 2204], "immut": [40, 1195, 2096], "__dlpack__": [40, 1195], "capsul": [40, 910, 1195], "pycapsul": [40, 1195], "to_dlpack": [40, 1195], "t2": [40, 698, 699, 910, 1141, 1195, 1268, 1770, 2038, 2166, 2167], "dltensor": [40, 1195], "t3": [40, 1195, 2167], "idiomat": 40, "inde": [40, 2093, 2103, 2158, 2168, 2200], "monitor": [41, 52, 54, 1039, 1427, 1874, 2050, 2130, 2139, 2160, 2209], "unhealthi": 41, "tear": [41, 2209], "react": [41, 2200], "decentr": 41, "diagram": [41, 51, 1314, 1580, 1877, 2161, 2168, 2193, 2195, 2205], "elasticag": 41, "quad": [41, 1492, 1493, 1515, 1546, 1571, 1587, 1595, 1630, 1769, 1905], "group_result": 41, "is_fail": [41, 43], "exit_cod": 41, "return_valu": [41, 43, 49, 2192, 2193, 2204], "get_worker_group": 41, "workergroup": [41, 52], "mutabl": [41, 1330, 2093, 2100, 2158, 2176], "implementor": 41, "defens": 41, "retri": [41, 44, 54, 1101, 2166, 2168], "max_restart": [41, 43, 52], "runresult": 41, "workerspec": [41, 43, 52, 54], "local_world_s": [41, 43, 52], "rdzv_handler": [41, 43, 51], "monitor_interv": [41, 43], "local_addr": [41, 51], "blueprint": 41, "homogen": [41, 52], "rendezvoushandl": [41, 43, 51, 52], "rdzv": [41, 50, 52], "chose": [41, 2126, 2191], "tee": [41, 49], "get_entrypoint_nam": 41, "__qualname__": 41, "workerst": 41, "unknown": [41, 57, 1773, 1774, 2100, 2168], "unrecover": 41, "interrupt": [41, 2114, 2202], "succeed": [41, 45, 51, 1404, 2192, 2195], "uncaught": [41, 44], "unhandl": 41, "recov": [41, 928, 1165, 1374, 1406, 1770, 1813, 1814, 1990, 2126, 2130, 2135, 2138, 2162], "is_run": 41, "role_rank": [41, 52], "role_world_s": [41, 52], "pid": [41, 44, 45, 52, 54, 1620, 2100, 2135, 2159], "local_elastic_ag": 41, "localelasticag": [41, 43, 54], "logs_spec": [41, 49], "start_method": [41, 43, 49, 54, 2114], "exit_barrier_timeout": 41, "log_line_prefix_templ": 41, "advis": [41, 544, 617, 895, 2144, 2204], "torchelastic_enable_file_tim": 41, "torchelastic_timer_fil": 41, "role_nam": 41, "trainer0": [41, 2166], "foobar": [41, 44, 48, 49], "templat": [41, 1002, 1086, 1087, 2157], "substitut": [41, 51, 69, 1327, 2127, 2174], "shared_queu": 41, "get_context": [41, 54, 2144], "nproc_per_process": 41, "other_param": [41, 54], "usr": [41, 49, 51, 2130], "simpleelasticag": 41, "scaffold": [41, 2192], "_assign_worker_rank": 41, "group_world_s": 41, "global_world_s": 41, "tcp": [41, 51, 52, 2166], "torch_elastic_worker_ident": 41, "role_info": 41, "front": [41, 254, 1002, 1387, 1583, 2116, 2134], "base_global_rank": 41, "_exit_barri": 41, "guard": [41, 71, 76, 80, 681, 1002, 1014, 1227, 1228, 1232, 1238, 1240, 1241, 1242, 1253, 1254, 2102, 2144, 2155, 2158, 2180, 2195, 2200, 2205, 2206], "_initialize_work": 41, "worker_group": 41, "fresh": [41, 69, 1135, 1231, 1234, 1931, 1961, 2091], "start_work": 41, "_stop_work": 41, "optimist": 41, "deleg": [41, 2106, 2192], "_monitor_work": 41, "_rendezv": 41, "_restart_work": 41, "_shutdown": 41, "death_sig": 41, "sigterm": 41, "is_restart": 41, "_start_work": [41, 49], "gracefulli": [41, 51, 52, 65, 1345, 2114, 2134, 2195, 2204], "meaning": [41, 44, 45, 1101, 2130, 2198], "meaningless": 41, "intention": [41, 1141, 2042, 2139, 2166], "torchelastic_health_check_port": 41, "health_check_serv": 41, "healthcheckserv": 41, "alive_callback": 41, "dead": [41, 69, 2203], "create_healthcheck_serv": 41, "control_plan": 42, "worker_main": 42, "_workerserv": 42, "torch_worker_server_socket": 42, "ship": [43, 1202, 2129, 2166], "programmat": [43, 69, 2142, 2204], "my_launch": 43, "argv": [43, 55], "trainer_entrypoint_fn": 43, "fn_arg": 43, "run_result": 43, "tricki": [43, 61, 66, 2127, 2142, 2168, 2189, 2192, 2204], "myrendezvoushandl": 43, "elastic_ag": 43, "metrichandl": [43, 48], "mymetrichandl": 43, "metric_data": [43, 48], "metricdata": 43, "sink": [43, 48, 2109], "eventhandl": 43, "cloudwatch": 43, "nulleventhandl": 43, "myeventhandl": 43, "infra": [44, 2203], "start_process": [44, 49, 2114], "torchelastic_error_fil": 44, "smallest": [44, 57, 991, 1336, 1346, 1367, 1371, 1387, 1891, 2015, 2178, 2205, 2210], "timestamp": [44, 45, 48, 52, 2109, 2159, 2176, 2205], "error_handl": 44, "get_error_handl": 44, "childfailederror": 44, "get_first_failur": 44, "dump_error_fil": 44, "error_fil": [44, 49], "exitcod": [44, 52], "nanni": 44, "accur": [44, 956, 1039, 1268, 1390, 1427, 1493, 1521, 1899, 2018, 2100, 2108, 2130, 2167, 2183, 2194, 2209], "tree": [44, 64, 1002, 1580, 1834, 2105, 2112, 2113, 2158, 2159, 2168, 2183], "torchelastic_ag": 44, "trainer_0": 44, "trainer_1": 44, "trainer_n": 44, "errorhandl": 44, "record_except": 44, "processfailur": 44, "test_ev": 45, "eventsourc": 45, "get_logging_handl": 45, "construct_and_record_rdzv_ev": 45, "run_id": [45, 51, 52, 54], "node_st": 45, "master_endpoint": 45, "local_id": 45, "nodest": 45, "endpoint": [45, 50, 51, 52], "dynamic_rendezv": [45, 51], "dynamicrendezvoushandl": [45, 51], "_record": 45, "get_method_nam": 45, "_set": 45, "_this_nod": 45, "eventmetadatavalu": 45, "readm": [46, 47, 69, 2117], "telemetri": 48, "timeseri": 48, "metric_group": 48, "metric_nam": 48, "sensibl": 48, "my_modul": [48, 57, 60, 69, 2093, 2158], "nullmetricshandl": 48, "consolemetricshandl": 48, "my_method": 48, "put_metr": 48, "calculate_lat": 48, "succinctli": 48, "baz": [48, 69, 884, 2158, 2178], "leaf_modul": 48, "classnam": [48, 2096], "threw": [48, 2207], "my_app": 48, "consolemetrichandl": 48, "toi": [48, 2205], "stdout": [48, 49, 53, 1862, 1863, 1864, 1865, 1866, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1876], "stdoutmetrichandl": 48, "1574213883": 48, "4182858": 48, "my_metr": 48, "1574213940": 48, "5237644": 48, "nullmetrichandl": 48, "class_nam": [48, 69], "def_nam": 48, "metric_valu": 48, "metric_group_nam": 48, "popen": [49, 53], "log_dir": [49, 2109, 2176], "stderr": [49, 53, 2091, 2107], "err": [49, 2130], "echo": 49, "hello": [49, 65, 2095, 2158, 2192], "pcontext": 49, "multiprocesscontext": 49, "subprocesscontext": 49, "log_line_prefix": 49, "keyset": [49, 2100], "bitmask": [49, 2111], "bar0": 49, "bar1": 49, "file1": 49, "file2": 49, "short": [49, 69, 745, 774, 1144, 1241, 1311, 1499, 1550, 1551, 1670, 1833, 1940, 1990, 2095, 2100, 2115, 2127, 2128, 2142, 2166, 2173, 2174, 2177, 2192, 2193], "ing": 49, "cmd": [49, 52], "forkserv": [49, 1770, 2114, 2144], "local_ranks_filt": 49, "processcontext": [49, 2114], "superset": [49, 52, 2100], "tee_stdout": 49, "tee_stderr": 49, "runprocsresult": 49, "defaultlogsspec": 49, "logsspec": 49, "reifi": 49, "rdzv_run_id": 49, "attempt_": 49, "logsdest": 49, "num_nod": [50, 52], "trainers_per_nod": 50, "num_allowed_failur": 50, "job_id": [50, 52, 2184], "host_node_addr": [50, 52], "min_siz": [50, 52], "num_allowed_failures_or_membership_chang": 50, "node1": [50, 52], "29400": [50, 52], "sidecar": [50, 51], "agre": [51, 1373, 2168], "resum": [51, 1865, 1872, 1874, 2157, 2166, 2168, 2176, 2193, 2195, 2204], "retryabl": 51, "announc": 51, "lose": [51, 55, 58, 60, 191, 208, 2116, 2130, 2204], "train_loop": [51, 892], "rendezvousbackend": 51, "c10drendezvousbackend": 51, "etcdrendezvousbackend": 51, "supersed": [51, 1230], "etcdrendezvoushandl": 51, "my_run_id": 51, "from_backend": 51, "min_nod": 51, "max_nod": 51, "rendezvousparamet": 51, "admit": [51, 52, 2130], "get_as_bool": 51, "get_as_int": 51, "rendezvoushandlerregistri": 51, "get_run_id": 51, "is_clos": 51, "set_clos": 51, "next_rendezv": 51, "rendezvousinfo": 51, "rendezvousclosederror": 51, "rendezvousconnectionerror": 51, "rendezvousstateerror": 51, "rendezvoustimeouterror": 51, "num_nodes_wait": 51, "shutdown": [51, 2105, 2114, 2166, 2167], "use_agent_stor": 51, "lifecyl": 51, "rendez": 51, "impl": [51, 56, 1086, 1320, 2100], "rendezvousstoreinfo": 51, "bootstrap_store_info": 51, "bootstrap": [51, 2148], "server_port": 51, "rendezvouserror": 51, "rendezvousgracefulexiterror": 51, "create_handl": 51, "join_timeout": 51, "600": 51, "last_call_timeout": 51, "close_timeout": 51, "rendezvoustimeout": 51, "get_stat": [51, 87, 2130], "fenc": 51, "set_stat": [51, 87, 2130], "last_cal": 51, "heartbeat": [51, 2209], "keep_al": 51, "c10d_rendezvous_backend": 51, "create_backend": 51, "store_typ": 51, "read_timeout": 51, "60": [51, 54, 965, 1533, 1876, 2008, 2013, 2109, 2166, 2193], "is_host": 51, "cname": 51, "fqdn": [51, 52], "etcdstor": 51, "etcdserv": 51, "cumbersom": [51, 2096], "highli": [51, 1484, 1770, 2091, 2143, 2150, 2154, 2171, 2173, 2178, 2208], "etcd_serv": 51, "data_dir": 51, "v3": [51, 52], "torchelastic_etcd_binary_path": 51, "2379": [51, 1412], "get_client": 51, "etcd_binary_path": 51, "entry_point": [52, 2190], "train_script": 52, "aforment": 52, "suffic": [52, 69], "compliant": [52, 55], "num_train": 52, "wors": [52, 1874, 2033, 2195], "port_k": 52, "etcd": 52, "v2": [52, 1383, 1881, 2091], "revis": 52, "physic": [52, 233, 1162, 1180, 2097, 2129, 2144, 2171, 2195], "localworkergroup": 52, "rdzv_id": 52, "rdzv_backend": [52, 55], "rdzv_endpoint": [52, 55], "max_nnod": 52, "torchelastic_restart_count": 52, "far": [52, 1324, 1686, 2191, 2204], "torchelastic_max_restart": 52, "python_exec": 52, "gang": 52, "departur": 52, "surviv": 52, "kill": [52, 54, 2114, 2135], "frequenc": [52, 973, 1027, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1172, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1311, 1484, 1522, 1523, 1677, 1678, 1865, 1990, 2203], "ness": [52, 2194], "load_checkpoint": [52, 55], "checkpoint_path": [52, 55], "dataset": [52, 55, 71, 812, 1484, 1493, 1545, 2135, 2137, 2140, 2144, 2148, 2157, 2161, 2162, 2176, 2204], "train_step": 52, "should_checkpoint": 52, "save_checkpoint": [52, 55], "subprocess_handl": 53, "get_subprocess_handl": 53, "local_rank_id": 53, "fd": [53, 2176], "acquir": [54, 69, 2130, 2142, 2168, 2171], "deadlin": 54, "message_queu": 54, "localtimerserv": 54, "max_interv": 54, "trainer_func": 54, "localtimercli": 54, "expiri": 54, "timer_cli": 54, "countdown": 54, "timefram": [54, 2166], "elig": [54, 2168], "reap": 54, "timerserv": 54, "mp_queue": 54, "daemon": [54, 2114], "filetimerserv": 54, "file_path": 54, "log_ev": [54, 2109], "filetimercli": 54, "fifo": [54, 88], "watchdog": [54, 2209], "filetimerrequest": 54, "sigkil": 54, "named_pip": 54, "mkfifo": 54, "timercli": 54, "timerrequest": 54, "scope_id": 54, "expiration_tim": 54, "acquisit": 54, "whatev": [54, 69, 448, 1227, 1770, 1932, 2020, 2096, 2134, 2194, 2195], "request_queu": 54, "entiti": [54, 69], "clear_tim": 54, "get_expired_tim": 54, "register_tim": 54, "timer_request": 54, "debug_info_log": 54, "log_debug_info_for_expired_tim": 54, "expired_tim": 54, "use_env": 55, "expositori": 55, "worst": [55, 2133], "total_num_epoch": 55, "visit": [55, 60, 2137, 2154, 2198], "WILL": 56, "BE": 56, "aot": [56, 681, 2063, 2102, 2183, 2185, 2186, 2195, 2196, 2204, 2205], "example_arg": [56, 57, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "exported_program": [56, 2150, 2185, 2186], "exportedprogram": [56, 58, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 834, 2150, 2154, 2185], "exportgraphsignatur": [56, 57, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "input_spec": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "inputspec": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "inputkind": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "user_input": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "tensorargu": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "output_spec": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "outputspec": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "outputkind": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "user_output": [56, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84], "sound": [56, 58, 69, 1005, 1222, 1609, 2176, 2185, 2196, 2205], "alias": [56, 60, 928, 1202, 1213, 1697, 2045, 2095, 2096, 2100, 2133, 2194], "stacktrac": [56, 57], "leverag": [56, 1002, 2149, 2150, 2151, 2166, 2183, 2188, 2192, 2197, 2208], "_dynamo": [56, 71, 82, 1002, 1009, 1015, 2117, 2132, 2183, 2184, 2186, 2189, 2190, 2191, 2192, 2193, 2200, 2202, 2204, 2205], "massiv": [56, 2192], "pt2": [56, 1218, 2185, 2186, 2191, 2194], "artifact": [56, 681, 1014, 1990, 2102, 2140, 2150, 2154, 2158, 2185, 2192, 2202, 2205], "untrac": [56, 69], "disjoint": [56, 2093], "symbolic_trac": [56, 57, 69, 2161], "comprehens": [56, 1956, 2096, 2097, 2116, 2117, 2130, 2139, 2161, 2205], "straight": [56, 1492, 1688], "conv": [56, 69, 713, 714, 715, 716, 717, 718, 719, 720, 721, 805, 806, 809, 829, 884, 890, 1314, 1324, 1330, 1331, 1507, 1508, 1509, 1510, 1511, 1512, 1580, 1581, 1587, 1781, 1782, 1877, 2106, 2124, 2130, 2145, 2154, 2161, 2162, 2163, 2164, 2198, 2200], "in_channel": [56, 723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 749, 750, 751, 752, 753, 754, 1324, 1507, 1508, 1509, 1510, 1511, 1512, 1556, 1557, 1558, 1559, 1560, 1561, 2151], "out_channel": [56, 723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 749, 750, 751, 752, 753, 754, 1324, 1507, 1508, 1509, 1510, 1511, 1512, 1556, 1557, 1558, 1559, 1560, 1561, 2151], "kernel_s": [56, 723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 749, 750, 751, 752, 753, 754, 779, 780, 793, 794, 1314, 1324, 1489, 1490, 1491, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1527, 1528, 1547, 1548, 1549, 1556, 1557, 1558, 1559, 1560, 1561, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1632, 1653, 1654, 1655, 1664, 1665, 1666, 1680, 1681, 1682, 1707, 1708, 1709, 1711, 1712, 1713, 1714, 1715, 1716, 1756, 1877, 1897, 1898, 2094, 2176, 2199], "maxpool": [56, 809, 1527, 1528, 1681, 1682, 2154], "maxpool2d": [56, 794, 1577, 1581, 1712, 1715, 2154, 2163], "256": [56, 1499, 1889, 2130, 2154], "example_kwarg": [56, 71, 77], "p_conv_weight": 56, "p_conv_bia": 56, "max_pool2d": [56, 1898, 2094, 2155, 2163], "85": [56, 69, 1583, 1872, 2198, 2202], "lift": [56, 57, 58, 66, 1213, 2045, 2116, 2155, 2194], "get_attr": [56, 69, 1226], "harden": 56, "oncal": 56, "proxytensor": 56, "contextlib": [56, 71, 75], "contextmanag": 56, "__enter__": [56, 2096], "__exit__": [56, 69, 2096, 2097, 2158], "exc_typ": [56, 2097], "exc_valu": [56, 2097], "exc": [56, 1015, 2117, 2204], "export_for_train": [56, 834, 2161], "2206": 56, "run_decomposit": 56, "convbatchnorm": 56, "bn": [56, 713, 714, 715, 716, 717, 718, 829, 890, 1144, 1324, 1781, 1783, 1877, 2147, 2157, 2161, 2162], "batchnorm2d": [56, 63, 724, 727, 729, 734, 829, 1324, 1516, 1554, 1656, 2106, 2127, 2142, 2161, 2163], "ep_for_train": 56, "p_bn_weight": 56, "p_bn_bia": 56, "b_bn_running_mean": 56, "b_bn_running_var": 56, "b_bn_num_batches_track": 56, "i64": [56, 71, 76, 77, 81, 82], "batch_norm": [56, 711, 712, 1324, 2094, 2155], "pretti": [56, 1314, 1834, 1940, 2093, 2190, 2194], "decomp_t": 56, "default_decomposit": 56, "ep_for_infer": 56, "_native_batch_norm_legit_funct": [56, 2155], "getitem": [56, 71, 74, 79, 80, 83, 2192, 2203], "getitem_3": 56, "getitem_4": 56, "decomp": [56, 2191, 2194], "my_awesome_custom_conv2d_funct": 56, "dilat": [56, 723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 749, 750, 751, 752, 753, 754, 783, 784, 785, 793, 794, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1556, 1557, 1558, 1559, 1560, 1561, 1573, 1574, 1575, 1632, 1661, 1662, 1663, 1664, 1665, 1666, 1680, 1711, 1712, 1713, 1756, 1897, 1898, 2094, 2154, 2199], "my_awesome_conv2d_funct": 56, "branch1": 56, "64": [56, 63, 64, 66, 965, 1126, 1206, 1207, 1211, 1481, 1482, 1483, 1485, 1486, 1487, 1493, 1609, 1738, 1929, 2035, 2100, 2122, 2141, 2147, 2148, 2154, 2161, 2165, 2171, 2174, 2176, 2177, 2189, 2195, 2197], "branch2": 56, "128": [56, 617, 731, 739, 740, 767, 775, 807, 839, 1497, 1514, 1541, 1567, 1589, 1629, 1630, 1668, 1738, 2116, 2117, 2122, 2137, 2139, 2149, 2161, 2163, 2164, 2166, 2171, 2173, 2174, 2177, 2186, 2202], "x2": [56, 71, 77, 990, 1362, 1572, 1629, 1630, 1668, 1726, 2094, 2186, 2199], "out1": [56, 1202, 2094, 2195], "out2": [56, 1202, 2094, 2195], "p_branch1_0_weight": 56, "p_branch1_0_bia": 56, "p_branch2_0_weight": 56, "p_branch2_0_bia": 56, "c_buffer": 56, "linear_1": [56, 69], "relu_1": [56, 69], "vr": [56, 71, 79, 80, 81, 82, 1232], "int_oo": [56, 71, 79, 80, 2204], "range_constraint": [56, 57], "dimx": 56, "dimi": 56, "slice_1": [56, 71, 80, 82], "9223372036854775807": [56, 71, 80, 924, 967, 1312, 1813, 2109, 2170, 2207], "saved_exported_program": 56, "fold": [56, 58, 1015, 1632, 2094, 2106, 2150, 2154, 2164, 2171], "example_input": [56, 832, 833, 834, 891, 892, 1326, 1330, 2161, 2182, 2185, 2186, 2190, 2193, 2194], "rewritten": [56, 58, 2138, 2192, 2204], "primtivi": 56, "symint": [56, 58, 69, 1215, 1220, 1226, 1228, 1234, 1236, 1237, 1238, 1239, 1240, 1241, 1248, 1249, 1251, 1998, 2000, 2002, 2003, 2004, 2100, 2141, 2180, 2192, 2194, 2199], "symfloat": [56, 58, 69, 1215, 1226, 1228, 1998, 2000, 2141, 2180, 2191, 2192], "symbool": [56, 58, 69, 1215, 1226, 1228, 1247, 1253, 1254, 2004, 2141, 2180, 2191, 2192], "const": [56, 1533, 2140, 2141], "add_1": [56, 69, 71, 74, 76, 79, 80, 1202], "add_2": [56, 69, 71, 76, 79, 80], "shot": 56, "nearli": [56, 150, 923, 944, 1882, 2144, 2166, 2205], "imposs": [56, 1213, 1238, 2045, 2126], "exportdb": [56, 2180], "combinatori": 56, "explod": [56, 1612], "cond": [56, 57, 58, 65, 71, 74, 80, 2145, 2204], "faketensor": [56, 1229, 2100, 2147, 2150, 2173, 2194, 2204], "register_fak": [56, 58, 2100], "dynamo": [56, 69, 681, 1004, 1228, 2102, 2132, 2149, 2150, 2151, 2154, 2183, 2190, 2191, 2194, 2195, 2196, 2198, 2200, 2201, 2202, 2205], "preserve_module_call_signatur": 56, "dim0_x": [56, 71, 73, 79, 80], "verbatim": 56, "bake": [56, 69, 71, 80, 1318, 1324, 1840, 1841, 1859, 2157], "diverg": [56, 1242, 1330, 1331, 1545, 1698, 2096], "register_dataclass": [56, 57, 58], "ordereddict": [56, 1314, 1580, 1581, 1590, 1609, 1760, 1804, 1877, 2094, 2142, 2147, 2178], "extra_fil": [56, 1322, 1325], "opset_vers": [56, 2150, 2154, 2155, 2156], "opset": [56, 2150, 2154, 2155, 2190, 2199], "decod": [56, 1386, 1624, 1625, 1626, 1770, 2158], "utf": [56, 1386, 2158], "expected_opset_vers": 56, "rb": [56, 1322, 1386], "seek": [56, 1322, 1386, 2157, 2158, 2161], "cl": [56, 71, 73, 139, 2100, 2133, 2161, 2166, 2206], "serialized_type_nam": 56, "treespec": 56, "inputdataclass": 56, "outputdataclass": 56, "customdecompt": 56, "shapescollect": 56, "builder": [56, 2192, 2204], "tensor_x": [56, 2150], "tensor_i": 56, "tensor_z": 56, "refine_dynamic_shapes_from_suggested_fix": 56, "msg": [56, 1104, 1105, 1107, 1228, 2159, 2178, 2204], "constraintviol": 56, "straightforward": [56, 69, 2103, 2117, 2142, 2157, 2171, 2190, 2204], "ti": [56, 1201, 1822, 1921, 2100, 2136, 2194], "_dx": 56, "1024": [56, 2129, 2130, 2185, 2195], "_constraint": 56, "_derivedconstraint": 56, "_relaxedconstraint": 56, "graph_signatur": [56, 57], "module_call_graph": 56, "joint": [56, 681, 2102, 2204], "operatorbas": 56, "your_op": 56, "your_custom_decomp": 56, "exportbackwardsignatur": 56, "gradients_to_paramet": 56, "gradients_to_user_input": 56, "loss_output": 56, "gurante": 56, "getattr": [56, 69, 834, 2094, 2133, 2147, 2166], "parameters_buffers_constant_tensor": 56, "flattened_user_input": 56, "mutated_input": 56, "flattened_user_output": 56, "custommodul": [56, 866, 2161], "my_paramet": [56, 2095], "register_buff": [56, 1314, 1580, 1762, 1771, 1877, 2093, 2095, 2133, 2142], "my_buffer1": 56, "my_buffer2": 56, "arg1_1": [56, 58], "arg2_1": 56, "arg3_1": 56, "arg4_1": 56, "add_tensor": [56, 57], "call_funct": [56, 69, 71, 85, 1226, 2190, 2192, 2193, 2203, 2204, 2205], "mul_tensor": 56, "mul_tensor_1": 56, "add_tensor_1": 56, "add_tensor_2": 56, "buffer_mut": 56, "modulecallsignatur": 56, "symintargu": [56, 71, 80], "symfloatargu": 56, "symboolargu": 56, "constantargu": [56, 71, 73], "customobjargu": 56, "tokenargu": 56, "in_spec": 56, "_pytre": [56, 71], "out_spec": 56, "forward_arg_nam": 56, "modulecallentri": 56, "decomp_util": 56, "ever": [56, 2093, 2173, 2207], "pop": [56, 65, 969, 1105, 1106, 1581, 1590, 2155, 2159, 2192], "other_dict": 56, "replace_all_us": 56, "get_replace_hook": 56, "replace_input": 56, "class_fqn": 56, "fake_v": 56, "_librari": [56, 2100], "fake_class_registri": 56, "fakescriptobject": 56, "unflatten": [56, 60, 2094, 2115, 2116, 2117, 2118, 2155, 2175], "flatargsadapt": 56, "target_spec": 56, "input_args_with_path": 56, "codegen": [56, 57, 69, 2133, 2195, 2198, 2205], "interpretermoduledispatch": 56, "attr": [56, 69, 71, 73, 1233, 1386, 1416, 1921], "call_modul": [56, 69, 1226, 2203], "carri": [56, 58, 64, 336, 811, 866, 868, 887, 888, 2100, 2128, 2161], "flat_args_adapt": 56, "hierachi": 56, "swap": [56, 67, 69, 415, 617, 800, 802, 803, 806, 811, 894, 1320, 1404, 1629, 1630, 1754, 1755, 2017, 2038, 2094, 2097, 2130, 2161, 2171, 2173, 2181], "submod": [56, 69], "new_mod": 56, "unflattenedmodul": 56, "move_to_device_pass": 56, "bear": 57, "mlir": 57, "soundli": 57, "audienc": 57, "realiz": [57, 1936], "implic": [57, 58, 1312, 1330, 2111, 2133, 2147, 2166, 2171], "bundl": [57, 2140], "notabl": [57, 1002, 2096, 2122, 2177, 2184, 2185], "graph_modul": [57, 58, 889, 2193, 2203], "sympi": [57, 1228, 1235, 2191], "rangeconstraint": 57, "i0": [57, 306, 1334, 1955, 2094, 2155, 2172], "collorari": 57, "num_us": [57, 69], "textual": 57, "machineri": [57, 69, 2133, 2192, 2195, 2202], "op_nam": [57, 2100], "arg4": 57, "arg5": 57, "compact": [57, 1160, 1161, 1163, 1357, 1359, 1362, 2133, 2161], "args1": 57, "add1": 57, "predefin": [57, 2150, 2154], "referenc": [57, 69, 1040, 1226, 1314, 1580, 1877, 2020, 2095, 2117, 2127, 2150, 2154, 2166, 2193], "19": [57, 696, 757, 995, 1577, 2093, 2154, 2171, 2193, 2198], "dummy_help": 57, "helper_util": 57, "89": [57, 617, 1900, 2186, 2198], "nn_module_stack": 57, "came": [57, 2189, 2192], "self_linear": 57, "self_sequenti": 57, "source_fn_stack": 57, "source_fn": 57, "encapsul": [57, 68, 69, 1229, 2166, 2189], "control_flow": [57, 71, 74, 79, 80, 83], "x_1": [57, 1123, 1124, 1125, 1126, 1382, 1497, 1513, 1514, 1657, 1668, 2018, 2100, 2204], "y_1": [57, 2018, 2100], "higher_ord": [57, 71, 74, 79, 80, 83], "liter": [57, 1833, 2094, 2097, 2116, 2141, 2158, 2203, 2207], "dim_ord": 57, "tensormeta": 57, "promot": [57, 60, 696, 975, 978, 987, 1086, 1139, 1187, 1189, 1190, 1191, 1192, 1465, 1518, 1519, 1520, 1524, 1668, 1891, 1911, 1912, 1918, 1933, 1991, 1993, 2002, 2096, 2174, 2178, 2194, 2195, 2199], "max_pool2d_with_index": 57, "add_on": 57, "ph_0": 57, "jax": [57, 61, 64, 65, 66, 2127, 2134, 2192, 2195], "int64_t": [57, 1833, 2141], "scalartyp": [57, 2141, 2199], "memoryformat": [57, 2141, 2199], "memory_format": [57, 69, 155, 170, 172, 175, 178, 179, 180, 189, 195, 206, 209, 233, 240, 267, 297, 325, 331, 393, 499, 500, 525, 580, 623, 999, 1145, 1146, 1200, 1226, 1314, 1580, 1770, 1779, 1780, 1832, 1877, 1902, 1904, 1906, 2090, 2094, 2133, 2178, 2199], "_register_pytree_nod": 57, "mymod": [58, 2100], "burn": [58, 71, 82, 2189], "recal": [58, 1493, 2133, 2176, 2204], "moo": [58, 71], "unrol": [58, 71, 76, 2095, 2096, 2154, 2195], "permit": [58, 60, 1227, 1238, 2130, 2171], "m_old": 58, "m_new": 58, "_check": [58, 71, 81, 82], "nz": 58, "proce": [58, 2126, 2130, 2166, 2205], "arithmet": [58, 65, 975, 978, 992, 1370, 1918, 2097, 2109, 2115, 2116, 2145, 2161, 2174], "briefli": [58, 1936, 2136], "index_select": [58, 2033, 2094, 2155, 2171, 2199], "meta_index_select": 58, "result_s": 58, "numel": [58, 60, 435, 444, 1000, 1027, 1175, 1299, 2094, 2100, 2115, 2122, 2127, 2155, 2170, 2171], "new_empti": [58, 65, 2094, 2100, 2155], "latter": [58, 60, 698, 804, 1314, 1550, 1580, 1587, 1877, 2134, 2142, 2144, 2146, 2157, 2192], "understood": [58, 806, 989, 2100], "custom_op": [58, 2100, 2154, 2194], "mylib": [58, 2100], "mutates_arg": [58, 2100], "x_np": [58, 2100], "y_np": [58, 2100], "from_numpi": [58, 448, 909, 910, 1932, 2011, 2100, 2195], "custom_nonzero": [58, 2100], "nnz": [58, 191, 544, 583, 584, 585, 587, 588, 1238, 1476, 1968, 1970, 1971, 1973, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 2100, 2171], "get_ctx": [58, 2100], "new_dynamic_s": [58, 2100], "freeli": [58, 2158], "sharding_strategi": 60, "auto_wrap_polici": 60, "backward_prefetch": 60, "backwardprefetch": 60, "backward_pr": [60, 1314, 1580, 1877], "mixed_precis": [60, 1770], "ignored_modul": 60, "param_init_fn": 60, "sync_module_st": 60, "forward_prefetch": [60, 2136], "use_orig_param": 60, "ignored_st": 60, "inspir": [60, 1843, 2133, 2197], "deepspe": 60, "shorten": 60, "sharded_modul": 60, "0001": [60, 69, 1125, 1359, 1568, 1704, 1836, 1874, 2094, 2157], "dev_id": 60, "shard_grad_op": 60, "full_shard": 60, "summon_full_param": 60, "with_grad": 60, "gap": [60, 895, 1908, 2092, 2117, 2161, 2202], "delai": [60, 486, 1770, 2168, 2180, 2195], "reacquir": 60, "nccl_cross_nic": 60, "no_sync": [60, 1770], "cpuoffload": 60, "modulewrappolici": 60, "custompolici": 60, "proceed": [60, 86, 1039, 1427, 1443, 1533, 2050, 2151, 2167, 2168], "nonwrapped_numel": 60, "travers": [60, 864, 1237, 1770, 2132, 2133, 2167, 2181, 2182], "subtre": 60, "size_based_auto_wrap_polici": 60, "exce": [60, 1392, 2130, 2144, 2150, 2154], "100m": 60, "custom_auto_wrap_polici": 60, "min_num_param": 60, "1e8": 60, "my_auto_wrap_polici": 60, "1e5": 60, "mixedprecis": 60, "granular": [60, 1328, 2126, 2202], "is_meta": [60, 2155], "reset_paramet": [60, 1595, 1769], "torchdistx": 60, "deferred_init": 60, "materialize_modul": 60, "my_init_fn": 60, "fullstatedictconfig": 60, "flatparamet": 60, "unifi": [60, 2111, 2116, 2130, 2192], "alten": 60, "distributed_device_mesh": 60, "check_is_root": 60, "clip_grad_norm_": [60, 1775, 1778, 2126], "max_norm": [60, 756, 757, 1522, 1523, 1677, 1678, 1775, 1776, 1778, 2094, 2126], "norm_typ": [60, 756, 757, 1522, 1523, 1547, 1548, 1549, 1677, 1678, 1707, 1708, 1709, 1775, 1776, 1785, 2094, 2151], "clip": [60, 1023, 1775, 1776, 1777, 1778, 1838, 2094, 2117, 2118, 2134, 2154, 2155], "infin": [60, 1025, 1304, 1306, 1308, 1309, 1470, 1492, 1573, 1574, 1575, 1711, 1712, 1713, 1776, 1785, 1842, 1960, 1972, 2171, 2172, 2180], "no_shard": 60, "largest": [60, 590, 973, 1188, 1346, 1367, 1369, 1371, 1372, 1387, 1724, 1788, 2015, 2094, 2095, 2096, 2199, 2203, 2210], "fp32": [60, 792, 807, 832, 1129, 1770, 2130, 2136, 2145, 2161, 2162, 2164, 2197], "flatten_sharded_optim_state_dict": 60, "sharded_optim_state_dict": 60, "shard_full_optim_state_dict": 60, "fsdp_modul": 60, "root_onli": 60, "full_optim_state_dict": 60, "optim_input": 60, "rank0_onli": 60, "get_state_dict_typ": 60, "statedictset": 60, "differen": 60, "intercept": [60, 69, 2133, 2196], "occurr": [60, 402, 924, 967, 1312, 1415, 1813, 2029, 2030, 2170, 2191], "statedicttyp": 60, "fulloptimstatedictconfig": 60, "set_state_dict_typ": 60, "save_a_checkpoint": 60, "load_a_checkpoint": 60, "optim_state_dict_to_load": 60, "is_named_optim": 60, "load_directli": 60, "original_osd": 60, "namedoptim": 60, "keyedoptim": 60, "torchrec": 60, "gossipgrad": [60, 1770], "rekey_optim_state_dict": 60, "optim_state_key_typ": 60, "loadabl": [60, 2091], "wrapped_model": 60, "wrapped_optim": 60, "full_osd": 60, "nonwrapped_model": 60, "nonwrapped_optim": 60, "rekeyed_osd": 60, "optimstatekeytyp": 60, "param_id": [60, 2157], "osd": 60, "param_nam": [60, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1853, 1856, 1857, 1858, 1859, 1860, 2157], "sharded_osd": 60, "scatter_full_optim_state_dict": 60, "new_model": 60, "new_optim": 60, "resid": [60, 68, 196, 289, 337, 1386, 1770, 2130, 2166, 2189], "remap": [60, 87, 415, 1318, 1322, 1386, 1407, 2091, 2107, 2165], "state_dict_config": 60, "optim_state_dict_config": 60, "descend": [60, 69, 136, 542, 906, 1226, 1314, 1378, 1379, 1580, 1877, 1965, 1994, 2094, 2199], "sharded_state_dict": 60, "shardedstatedictconfig": 60, "offload_to_cpu": 60, "optimstatedictconfig": 60, "param_state_dict": 60, "statedictconfig": 60, "writeback": 60, "summon": 60, "redundantli": [60, 2126], "backward_post": 60, "altogeth": [60, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 2192], "contend": 60, "volum": [60, 1277], "_hybrid_shard_zero2": 60, "buffer_dtyp": 60, "keep_low_precision_grad": 60, "cast_root_forward_input": 60, "_module_classes_to_ignor": 60, "batchnorm": [60, 711, 712, 1210, 1314, 1324, 1580, 1620, 1770, 1771, 1781, 1782, 1783, 1784, 1877, 2106, 2118, 2127, 2142, 2157, 2161, 2163, 2164], "_batchnorm": [60, 1781, 1783], "thereaft": 60, "local_state_dict": 60, "upcast": [60, 2145], "recast": 60, "offload_param": 60, "cfg": 60, "finetun": [60, 1314, 1580, 1877], "model_fn": 60, "my_checkpoint": 60, "_use_dtensor": 60, "privat": [60, 1228, 2130, 2133, 2158, 2189, 2195], "localstatedictconfig": 60, "shardedoptimstatedictconfig": 60, "localoptimstatedictconfig": 60, "love": 61, "hear": 61, "vmap": [61, 63, 64, 69, 935, 936, 938, 940, 944, 949, 950, 1203, 1206, 1207, 1209, 1211, 2100], "arbitrarili": [61, 66, 513, 1317, 1651, 2096, 2127, 2133, 2134], "stock": [61, 66], "ensembl": [61, 64, 66, 1211], "maml": [61, 66], "vjp": [61, 64, 65, 919, 920, 930, 935, 936, 1207, 1213, 2045, 2133, 2134], "whirlwind": 61, "tour": 61, "ux": [61, 66, 1222, 2161], "jacrev": [62, 64, 65, 940, 1205, 1206, 2134], "functional_cal": [62, 64, 1211, 2195], "running_mean": [63, 1210, 1314, 1494, 1495, 1496, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1620, 1656, 1696, 1771, 1877, 2094, 2142, 2147, 2157, 2199], "running_var": [63, 1210, 1314, 1494, 1495, 1496, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1620, 1656, 1696, 1877, 2094, 2147, 2157, 2199], "groupnorm": [63, 1687], "anywher": [63, 2126], "track_running_stat": [63, 762, 763, 764, 1210, 1494, 1495, 1496, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1620, 2147], "resnet": [63, 2091, 2093, 2095, 2142, 2158, 2176, 2181], "regnet": 63, "norm_lay": 63, "resnet18": [63, 69, 2091, 2093, 2095, 2107, 2158, 2202], "num_group": [63, 760, 1534, 1687, 2094], "fragil": 63, "replace_all_batch_norm_modules_": 63, "upstream": [64, 2148], "coupl": [64, 2093, 2117, 2140, 2149, 2167, 2189, 2203], "jvp": [64, 65, 920, 925, 928, 929, 930, 934, 935, 936, 1209, 2133], "jacfwd": [64, 65, 940, 1205, 2134], "carefulli": [64, 68, 486, 2100, 2134, 2158, 2194, 2196], "make_functional_with_buff": 64, "hurri": 64, "gist": [64, 806, 2138, 2198], "emul": [64, 814, 2097, 2133, 2159], "fmodel": 64, "compute_loss": [64, 66, 1201, 1203], "predict": [64, 486, 1484, 1493, 1533, 1669, 1695, 1718, 2130, 2157, 2176, 2185], "argnum": [64, 1203, 1204, 1205, 1206, 1207], "stack_module_st": 64, "num_model": [64, 1211], "base_model": 64, "clearer": [64, 1371, 1860, 2133], "call_single_model": 64, "aotautograd": [64, 681, 1004, 2102, 2132, 2194, 2195, 2196, 2205], "stori": [64, 2138, 2192], "grad_x": [65, 2100, 2134, 2195], "has_aux": [65, 1203, 1204, 1206, 1207, 1208, 1212], "mental": [65, 1202], "absenc": 65, "unbind": [65, 1213, 2045, 2094, 2115, 2117, 2155, 2175], "presenc": [65, 69, 1324, 1471, 2144, 2158, 2171, 2200], "lst": 65, "batchedtensor": 65, "batched_tensor_input": 65, "new_": [65, 2130, 2177], "new_zero": [65, 2094, 2155, 2173], "diag_emb": [65, 1134, 1350, 1351, 1378, 1994, 2094, 2155], "vec": [65, 107, 108, 424, 701, 1468, 1823, 2094, 2171, 2199], "copy_": [65, 67, 415, 1202, 1633, 2093, 2094, 2115, 2130, 2173], "extra_arg": 65, "theoret": [65, 1840, 1841, 1859], "custom_dot": 65, "lax": 65, "while_loop": 65, "is_nonzero": [65, 2094, 2155, 2171], "rag": 65, "unclear": [65, 617], "add_nois": 65, "prng": 65, "cos_x": [66, 1203], "neg_sin_x": [66, 1203], "feature_s": [66, 1203, 1213, 2045], "feature_vec": [66, 1203, 1213, 2045], "mseloss": [66, 1203, 1540, 1612, 2130, 2132], "grad_weight_per_exampl": [66, 1203], "cotang": [66, 1212], "vjp_fn": [66, 1212], "out_tang": 66, "hessian0": 66, "hessian1": 66, "hess": [66, 1205], "set_overwrite_module_params_on_convers": 67, "to_empti": [67, 1314, 1580, 1877, 2104], "get_overwrite_module_params_on_convers": 67, "set_swap_module_params_on_convers": 67, "swap_tensor": [67, 415], "module_load": 67, "get_swap_module_params_on_convers": [67, 415, 1314, 1580, 1877], "rpc_async": [68, 2096, 2155, 2166, 2168], "add_done_callback": 68, "set_result": [68, 1770, 2166], "haven": [68, 2117, 2142, 2202], "set_except": 68, "baseexcept": 68, "twice": [68, 617, 939, 1209, 2126, 2127, 2135, 2138, 2184, 2194], "slow_set_futur": 68, "sleep": 68, "cb1": 68, "cb2": 68, "didn": [68, 2133, 2136, 2148, 2157], "cb_fut": 68, "chain_cb_fut": 68, "cb": [68, 2166], "held": [68, 1037, 1066, 1097, 1426, 2058, 2076, 2126, 2130, 2197], "collect_al": 68, "fut0": 68, "fut1": [68, 2166], "fut_list": 68, "wait_al": 68, "clamp": [69, 186, 187, 814, 817, 998, 1321, 1492, 1533, 1686, 1697, 1757, 2094, 2106, 2115, 2154, 2155, 2161, 2163, 2164, 2172, 2178, 2199], "call_method": [69, 1226, 2190, 2193, 2204], "fake": [69, 723, 724, 725, 726, 727, 728, 729, 730, 731, 741, 742, 743, 767, 806, 811, 814, 815, 825, 827, 866, 891, 892, 1158, 1159, 1226, 1228, 1237, 1251, 2100, 2150, 2158, 2161, 2164, 2173, 2183], "theses": 69, "callsit": [69, 2105, 2147], "constitut": [69, 2192], "isol": [69, 1760, 2114, 2157, 2205], "tracer_class": 69, "gm": [69, 2100, 2190, 2193, 2194, 2203, 2205], "treatment": 69, "topk": [69, 2094, 2115, 2155, 2199], "print_tabular": [69, 2190, 2193], "opcod": [69, 2158, 2190, 2193, 2204], "linear_weight": 69, "topk_1": 69, "pose": [69, 2167, 2192], "explor": [69, 2091, 2127, 2142, 2158, 2207], "lint": 69, "inserting_aft": [69, 2203], "new_nod": 69, "replace_all_uses_with": [69, 2203], "tediou": 69, "unwieldi": 69, "fusion": [69, 681, 805, 829, 890, 891, 1002, 1316, 1323, 1328, 1329, 1330, 1331, 1779, 1780, 1840, 1841, 1859, 2106, 2142, 2161, 2192, 2195, 2197, 2203, 2204, 2205], "imagin": [69, 2166, 2192, 2196], "requisit": 69, "relu_decomposit": 69, "decomposition_rul": 69, "constitu": [69, 2133, 2136], "new_graph": 69, "graphappendingtrac": 69, "proxy_arg": 69, "output_proxi": 69, "node_copi": 69, "ari": [69, 2005], "unari": [69, 1206, 1207, 1624, 1626, 1628, 2097, 2115], "organiz": 69, "shapeprop": 69, "named_modul": [69, 1314, 1580, 1877, 2142], "args_it": 69, "load_arg": 69, "map_arg": 69, "fetch_attr": [69, 1226], "target_atom": 69, "attr_itr": 69, "hasattr": [69, 2034, 2094, 2133, 2161, 2193, 2204], "nonexist": [69, 2095, 2096], "self_obj": 69, "encompass": 69, "prove": [69, 2114], "disprov": 69, "led": [69, 2207], "auxiliari": [69, 1203, 1204, 1206, 1207, 1208, 1212, 2091, 2140], "nondeterminist": [69, 313, 315, 321, 499, 515, 517, 973, 1145, 1146, 1147, 1336, 1499, 1507, 1508, 1509, 1510, 1511, 1512, 1576, 1577, 1578, 1661, 1662, 1663, 1664, 1665, 1666, 1670, 1678, 1686, 1697, 1725, 1738, 1757, 1758, 1759, 1935, 2033, 2190], "unord": [69, 1581, 1590], "nondetermin": [69, 950, 2146], "dedupl": 69, "torchvis": [69, 2091, 2093, 2095, 2137, 2154, 2158, 2161, 2176, 2181, 2202], "transformed_resnet18": 69, "input_imag": 69, "224": [69, 891, 892, 2093, 2095, 2137, 2154, 2202], "margin": [69, 1513, 1539, 1572, 1583, 1585, 1629, 1630, 1667, 1694, 1710, 1719, 1754, 1755, 2094, 2176], "commut": 69, "toolbox": 69, "tradit": [69, 1628, 2149, 2150], "luckili": 69, "my_pass": 69, "my_module_transform": 69, "input_valu": 69, "prompt": [69, 2091, 2148], "set_trac": [69, 1319, 1326, 1332, 2093], "undergon": 69, "subclassm": 69, "pre_trac": 69, "post_trac": 69, "sake": 69, "tabular": [69, 681, 2102], "transform_graph": 69, "session": [69, 2150], "luck": [69, 2192], "input_nod": 69, "stepwis": 69, "breakpoint": [69, 2096, 2192, 2203], "excel": [69, 2196], "realpython": 69, "pycharm": 69, "vscode": 69, "graphic": [69, 2110, 2137, 2148, 2202], "parlanc": 69, "func_to_trac": 69, "dyn": 69, "155": 69, "__bool__": [69, 2094, 2096], "to_bool": 69, "traceerror": [69, 2161], "hyper": [69, 1612, 2095, 2176], "do_activ": 69, "512": [69, 1624, 1625, 1626, 1627, 1628, 2117, 2130, 2188], "without_activ": 69, "with_activ": 69, "traced_without_activ": 69, "traced_with_activ": 69, "concrete_arg": 69, "__torch_function__": [69, 2206], "161": 69, "len_1": 69, "sqrt_1": 69, "truediv": [69, 2190, 2192, 2193], "mycustomtrac": 69, "traced_graph": 69, "runnabl": [69, 2126, 2176, 2186, 2205], "myspecialsubmodul": 69, "neg_1": 69, "is_leaf_modul": [69, 2182], "sparse_coo_tensor": [69, 544, 581, 1975, 2094, 2098, 2155, 2171], "ones_lik": [69, 1206, 1207, 1212, 2094, 2100, 2117, 2130, 2133, 2134, 2142, 2155], "viabl": [69, 2127, 2130], "torch_randn": 69, "gotcha": 69, "dropoutrepro": 69, "assert_clos": [69, 1161, 1163, 1164, 1169, 1170, 1175, 1176, 1177, 1179, 1181, 2093, 2178], "greatest": [69, 1256, 1470, 2178], "6207983493804932": 69, "dropoutrepro2": 69, "overspeci": [69, 1002, 2191], "ph": 69, "shouldn": [69, 1037, 2158, 2171, 2175], "fn_or_nam": 69, "callfunct": 69, "my_custom_funct": [69, 1004], "fn_to_be_trac": 69, "reassign": [69, 2130], "regener": 69, "unset": [69, 965, 2145], "add_submodul": 69, "subpath": 69, "get_submodul": [69, 1314, 1580, 1877], "delete_all_unused_submodul": 69, "delete_submodul": 69, "print_read": [69, 2100, 2193], "print_output": 69, "include_strid": 69, "include_devic": 69, "date": [69, 2158], "pythoncod": 69, "fxmodul": 69, "owning_modul": 69, "tracer_cl": 69, "tracer_extra": 69, "the_funct": 69, "type_expr": 69, "create_nod": 69, "inserting_befor": 69, "influenc": [69, 1838, 2147, 2150, 2171, 2208], "eliminate_dead_cod": 69, "is_impure_nod": 69, "topolog": [69, 2154], "impur": 69, "is_impur": 69, "attr_1": 69, "bad": [69, 71, 2114, 2154, 2158, 2161, 2194, 2202], "erase_nod": 69, "to_eras": 69, "eras": [69, 71, 76, 77, 2191], "find_nod": 69, "iterat": 69, "qualified_nam": 69, "graph_copi": 69, "val_map": 69, "return_output_nod": 69, "companion": 69, "arg_transform": 69, "value_remap": 69, "_node_list": 69, "doubli": 69, "on_generate_cod": 69, "make_transform": 69, "transformcodefunc": 69, "insert_pdb": 69, "bodi": [69, 71, 80, 83, 1326, 2093, 2095, 2096, 2097, 2193, 2205], "current_tran": 69, "stuff": [69, 2194], "output_nod": 69, "default_valu": 69, "_not_": 69, "process_input": [69, 1226], "process_output": [69, 1226], "python_cod": 69, "root_modul": [69, 806, 2163], "set_codegen": 69, "return_typ": [69, 708, 1123, 1124, 1277, 1336, 1374, 1412, 1415, 1417, 1420, 1472, 1965, 2015, 2020], "printout": [69, 1088, 1102, 2193], "all_input_nod": 69, "format_nod": 69, "placeholder_nam": 69, "maybe_return_typenam": 69, "autogener": [69, 2122, 2134], "insert_arg": 69, "normalized_argu": 69, "arg_typ": 69, "kwarg_typ": 69, "normalize_to_only_use_kwarg": 69, "vararg": 69, "argskwargspair": 69, "bx": 69, "ax": [69, 995, 1346, 1360, 1364, 1375, 1376, 1377, 1405, 1416, 1588, 1599, 2020, 2150, 2154, 2195], "prev": [69, 1858], "replace_with": 69, "delete_user_cb": 69, "propagate_meta": 69, "replace_input_with": 69, "old_input": 69, "new_input": 69, "create_proxi": [69, 2192], "record_stack_trac": 69, "outputgraph": [69, 2192], "update_arg": 69, "update_kwarg": 69, "autowrap_modul": 69, "autowrap_funct": 69, "create_arg": 69, "create_args_for_root": 69, "root_fn": 69, "is_modul": 69, "introspect": [69, 1004, 2195], "disallow": [69, 2158, 2166, 2174, 2195, 2196], "proxy_factory_fn": 69, "get_fresh_qualnam": 69, "clash": 69, "attr_val": 69, "parameter_proxy_cach": 69, "module_qualified_nam": [69, 2182], "path_of_modul": 69, "some_hyperparamet": 69, "indexed_item": 69, "proxied_valu": 69, "garbage_collect_valu": [69, 1226], "run_nod": [69, 1226], "vice": [69, 458, 603, 1197, 1198, 1572, 2127, 2164, 2173, 2191], "versa": [69, 458, 603, 1197, 1198, 1572, 2127, 2164, 2173, 2191], "negsigmswapinterpret": 69, "call_self": 69, "args_tail": 69, "boxed_run": [69, 1226], "args_list": [69, 1226], "promptli": [69, 1226, 1237, 1387], "fetch_args_kwargs_from_env": [69, 1226], "map_nodes_to_valu": [69, 1226], "initial_env": [69, 1226], "enable_io_process": [69, 1226], "negsigmswapxform": 69, "nodes_map": [69, 2203], "subgraph_rewrit": [69, 2203], "m1": [69, 2043, 2044, 2108, 2185], "m2": [69, 1820, 2043, 2044, 2108, 2161, 2185], "traced_modul": [69, 2147, 2203], "despit": [69, 1330, 1331, 2130, 2138, 2157], "stack_1": 69, "stack_2": 69, "sum_2": 69, "max_1": 69, "max_2": 69, "exhaust": [71, 1770, 2189, 2204, 2208], "escap": [71, 81, 1004, 2117], "hatch": [71, 81, 1004, 2117], "mypi": [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 1301, 2095, 2096], "untyp": [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "listunpack": [71, 76, 77], "args_0": [71, 76, 77], "args_1": [71, 76, 77], "args_2": [71, 76, 77], "anim": 71, "cow": [71, 72, 77, 80], "specializedattribut": 71, "staticforloop": [71, 76], "ret": [71, 76, 2133, 2166], "add_3": [71, 76], "add_4": [71, 76], "add_5": [71, 76], "add_6": [71, 76], "add_7": [71, 76], "add_8": [71, 76], "add_9": [71, 76], "condclosedovervari": [71, 74, 79], "fnwithkwarg": [71, 77], "pos0": [71, 77], "tuple0": [71, 77], "myarg": [71, 77], "mykw0": [71, 77], "mykwarg": [71, 77], "input0": [71, 77], "input1": [71, 77, 771, 1497, 1513, 1514, 1572, 1589, 1657, 1667, 1668, 1710, 2094, 2126, 2154], "tuple0_0": [71, 77], "tuple0_1": [71, 77], "myargs_0": [71, 77], "myargs_1": [71, 77], "mul_1": [71, 77, 2190, 2192], "mul_2": [71, 77], "mul_3": [71, 77], "mul_4": [71, 77], "mul_5": [71, 77], "mul_6": [71, 77], "constrainasvalueexampl": [71, 81, 82], "_check_is_s": [71, 81, 82], "u0": [71, 81, 82], "ge_1": [71, 81, 82], "_assert_scalar_default": [71, 81, 82], "_assert_scalar": [71, 81, 82, 2155, 2189], "le_1": [71, 81, 82], "_assert_scalar_default_1": [71, 81, 82], "u1": [71, 81, 82], "dynamicshapesl": [71, 80], "slice_2": [71, 80], "condbranchnonlocalvari": [71, 79, 80], "my_tensor_var": [71, 79, 80], "my_primitive_var": [71, 79, 80], "nonloc": [71, 74, 79, 80, 2097], "c_lifted_tensor_0": [71, 79, 80], "lift_fresh_copi": [71, 79, 80, 2155], "detach_": [71, 79, 80, 1770, 2094, 2115, 2163, 2171], "constant_tensor": [71, 79, 80], "lifted_tensor_0": [71, 79, 80], "myautogradfunct": 71, "autogradfunct": 71, "allow_in_graph": [71, 2195], "typereflectionmethod": [71, 73], "overli": [71, 73, 2133, 2192], "condoperand": [71, 79, 80], "extra_input": [71, 79, 80], "sym_size_int_1": [71, 79, 80], "test_decor": 71, "dynamicshapeview": [71, 80], "new_x_shap": [71, 80], "dynamicshapemap": [71, 80, 83], "body_graph_0": [71, 80, 83], "map_impl": [71, 80, 83], "nestedfunct": [71, 74], "dynamicshapeconstructor": [71, 80], "dynamicshapeifguard": [71, 76, 80], "assumeconstantresult": [71, 82], "tracabl": [71, 82], "get_item": [71, 82], "mysubmodul": [71, 79, 80], "condbranchclassmethod": [71, 79, 80], "subm": [71, 79, 80], "p_linear_weight": 71, "p_linear_bia": 71, "pytreeflatten": 71, "tree_flatten": 71, "x_0_1": 71, "x_0_2": 71, "dim1_x": [71, 80], "scalaroutput": [71, 80], "condpred": [71, 79, 80], "dynamicshapeassert": [71, 72], "tensorsetattr": [71, 73], "setattr": [71, 73, 2096], "constrainassizeexampl": [71, 81, 82], "sym_constrain_range_for_size_default": [71, 81, 82], "sym_constrain_range_for_s": [71, 81, 82, 2094, 2155], "ge_2": [71, 81, 82], "staticif": [71, 76], "listcontain": [71, 72, 77, 80], "monkei": [71, 72, 77, 80, 2034], "pig": [71, 72, 77, 80], "userinputmut": [71, 84], "nullcontextmanag": [71, 75], "nullcontext": [71, 75], "condbranchnestedfunct": [71, 79, 80], "inner_true_fn": [71, 79, 80], "inner_false_fn": [71, 79, 80], "not_supported_yet": [71, 73, 78, 80, 85], "_export": [71, 73, 78, 80, 85], "db": [71, 73, 78, 80, 85], "supportlevel": [71, 73, 78, 80, 85], "torchsymmin": [71, 85], "sym_min": [71, 85], "support_level": [71, 73, 78, 80, 85], "0x104e3fdc0": [71, 85], "optionalinput": [71, 78], "dynamicshaperound": [71, 73, 80], "violat": [71, 73, 80, 1221, 1228, 2130, 2134], "modelattrmut": [71, 78], "attr_list": [71, 78], "recreate_list": [71, 78], "enable_tim": [86, 693, 1039, 1427, 1443, 2050, 2130], "e_cuda": [86, 88, 1443], "elapsed_tim": [86, 693, 1039, 1427, 1443, 2050, 2130], "end_ev": [86, 693, 1039, 1427, 1443, 2050, 2130], "elaps": [86, 1039, 1427, 1443, 2050, 2109], "record_ev": [86, 88, 1040, 1443], "s_cuda": [86, 88, 1443], "e1_cuda": [86, 1443], "e2_cuda": [86, 1443], "s1_cuda": [86, 88, 1443], "s2_cuda": [86, 88, 1443], "s2": [86, 1443, 2171], "g_cpu": 87, "g_cuda": 87, "clone_st": 87, "cloned_st": 87, "bytetensor": [87, 1074, 1075, 1116, 1117, 1267, 1428, 1439, 1453, 1461, 1941, 2036, 2064, 2065, 2085, 2086, 2165, 2174, 2177], "graphsafe_get_st": [87, 2130], "current_st": 87, "graphsafe_set_st": [87, 2130], "g_cuda_oth": 87, "2147483647": 87, "0x8000_0000_0000_0000": [87, 1407, 2165], "0xffff_ffff_ffff_ffff": [87, 1407, 2165], "random_devic": 87, "1516516984916": 87, "new_stat": [87, 1116, 1117, 1439, 1461, 1941, 2036, 2085, 2086, 2165], "void": [87, 1087, 2130, 2140, 2195], "g_cpu_oth": 87, "queu": [88, 486, 1045, 1445, 2052, 2130], "wait_ev": [88, 1040], "abs_": [92, 2094, 2115, 2177], "acosh": [96, 122, 897, 2094, 2115, 2155, 2199], "batch1": [99, 100, 151, 152, 697, 970, 2094], "batch2": [99, 100, 151, 152, 169, 697, 970, 2094], "tensor1": [101, 102, 103, 104, 698, 699, 1409, 1918, 2094], "tensor2": [101, 102, 103, 104, 314, 404, 698, 699, 1409, 1918, 2094], "mat1": [105, 106, 554, 700, 1279, 1335, 1419, 1966, 1970, 1971, 1986, 2094, 2199], "mat2": [105, 106, 413, 554, 700, 982, 1279, 1335, 1419, 1966, 1970, 1971, 1986, 2094, 2199], "mat": [107, 108, 540, 701, 1468, 1899, 1963, 1966, 1986, 2094, 2176], "vec1": [109, 110, 702, 2094], "vec2": [109, 110, 288, 461, 702, 1259, 1881, 2094], "keepdim": [112, 114, 115, 116, 118, 134, 135, 354, 392, 407, 409, 410, 411, 414, 429, 430, 431, 432, 453, 470, 479, 555, 565, 615, 704, 706, 707, 708, 710, 904, 905, 1336, 1367, 1371, 1384, 1402, 1412, 1414, 1415, 1417, 1420, 1471, 1472, 1473, 1474, 1589, 1726, 1827, 1890, 1893, 1988, 1989, 1993, 2040, 2041, 2094, 2115, 2172, 2199], "rtol": [113, 344, 705, 949, 950, 1303, 1369, 1372, 1835, 2093, 2094, 2178], "atol": [113, 344, 705, 949, 950, 1303, 1369, 1372, 1381, 1835, 2093, 2094, 2133, 2178], "08": [113, 344, 705, 980, 1303, 1361, 1514, 1594, 1730, 1840, 1841, 1842, 1844, 1856, 1857, 1860, 1874, 1947, 2094, 2186], "equal_nan": [113, 344, 705, 1303, 2094, 2178], "arcco": [121, 2094, 2155, 2178], "acosh_": [123, 2094, 2115], "arccosh": [123, 2094, 2155], "arcsin": [125, 911, 2094, 2155, 2171], "arcsinh": [127, 2094, 2155], "atan2_": [130, 2094, 2115], "arctan2": [130, 2094, 2155], "arctan": [131, 2094, 2155], "arctanh": [133, 2094, 2155], "asinh": [143, 899, 2094, 2115, 2155, 2171, 2199], "atan": [147, 632, 633, 900, 2094, 2115, 2155, 2171, 2199], "atanh": [149, 902, 2094, 2115, 2155, 2171, 2199], "wrt": [150, 949, 950], "60521": [150, 923], "texttt": [153, 154, 705, 1303, 1484, 2178], "bernoulli": [154, 771, 1488, 1517, 1518, 1519, 1520, 1524, 1531, 1550, 1671, 1672, 1673, 1674, 1679, 2094, 2115, 2155, 2180], "preserve_format": [155, 170, 172, 175, 178, 179, 180, 189, 206, 209, 240, 267, 297, 325, 393, 525, 580, 623, 999, 1146, 1200, 1832, 1902, 1904, 1906, 2090, 2133, 2174], "minlength": [156, 973, 2094], "bitwise_and": [158, 2094, 2155, 2199], "bitwise_left_shift": [160, 2094, 2155], "bitwise_not": [162, 2094, 2115, 2155, 2199], "bitwise_or": [164, 2094, 2155, 2199], "bitwise_right_shift": [166, 2094, 2155], "bitwise_xor": [168, 2094, 2155, 2199], "uint8": [172, 242, 617, 704, 710, 1197, 1891, 1894, 1895, 1918, 2161, 2173, 2174, 2176, 2177, 2210], "cauchi": [173, 2127, 2138, 2155, 2180], "dfrac": [173, 377, 608, 1514, 1668, 1788, 1789, 1821, 1824], "complex32": [179, 1507, 1508, 1509, 1661, 1662, 1663, 1833, 1933, 2177, 2178], "int8": [180, 448, 740, 974, 975, 976, 977, 978, 979, 1197, 1396, 1397, 1398, 1399, 2161, 2164, 2171, 2173, 2174, 2177, 2210], "input2": [183, 459, 460, 517, 771, 1497, 1513, 1514, 1572, 1589, 1657, 1667, 1668, 1710, 2094, 2126, 2154], "clamp_": [188, 2094, 2115], "uncoalesc": [190, 328, 1979], "coo": [190, 323, 328, 342, 614, 1279, 1966, 1970, 1976, 1977, 1978, 1979, 1980, 1981, 2103, 2174, 2178], "inttensor": [191, 208, 1289, 1404, 1405, 1522, 2174, 2177], "csr": [191, 208, 343, 583, 588, 1523, 1966, 1970, 1971, 1974, 1978, 1981, 2103, 2178], "sparse_csr": [191, 208, 583, 588, 1970, 1971, 1973, 1974, 1978, 1981, 2171], "int32": [191, 208, 313, 321, 325, 447, 617, 986, 1146, 1158, 1159, 1194, 1197, 1198, 1345, 1356, 1357, 1358, 1376, 1404, 1499, 1891, 1928, 1993, 2161, 2171, 2173, 2174, 2177, 2197, 2210], "mkl": [191, 208, 2129, 2148, 2171, 2179, 2208], "routin": [191, 208, 906, 1387, 1965, 1994, 2171], "downcast": [191, 208, 2145], "to_sparse_csr": [191, 208, 584, 585, 1967, 1970, 1971, 2094, 2155, 2171], "conj_phys": [194, 1020, 2094, 2155, 2171, 2199], "contiguous_format": [195, 233, 331, 499, 500, 1145, 1770, 1779, 1780, 2174], "non_block": [196, 209, 580, 603, 623, 1314, 1580, 1813, 1877, 2094, 2130, 2173, 2199], "copysign": [198, 2094, 2155], "fweight": [205, 1027, 2094], "aweight": [205, 1027, 2094], "sparse_dim": [218, 545, 546, 1966, 1970, 1975, 1979, 2094, 2155, 2171], "dim1": [225, 227, 228, 569, 592, 593, 1132, 1134, 1135, 1349, 1997, 2017, 2094, 2199], "dim2": [225, 227, 228, 1132, 1134, 1135, 1349, 2094, 2199], "digamma": [231, 2094, 2115, 2155, 2172, 2199], "ambiguity_check": 233, "laid": 233, "outermost": [233, 1268], "legal": [233, 2096, 2180], "typeerror": [233, 1804, 2133, 2150, 2178, 2204, 2206], "channels_last": [233, 1314, 1580, 1770, 1779, 1780, 1877, 2174], "rounding_mod": [235, 236, 237, 238, 1139, 1140, 1189, 1192, 1912, 2025, 2094, 2199], "split_size_or_sect": [241, 302, 619, 1982], "eq": [244, 2094, 2115, 2155, 2199], "erf": [247, 640, 641, 2094, 2115, 2155, 2171, 2172, 2199], "erfc": [249, 642, 643, 2094, 2115, 2155, 2172, 2199], "lambd": [258, 298, 1535, 1618, 1689, 1747, 1836, 2094], "theori": [258, 2127, 2136], "tall": [260, 1373, 1378, 2133], "start_dim": [263, 1183, 1525, 2094], "end_dim": [263, 1183, 1525, 2094], "float_pow": [269, 2094, 2155], "floor_divid": [273, 1139, 2094, 2155, 2171], "fmod": [277, 1912, 2094, 2155, 2199], "mantissa": [280, 481, 1194, 1338, 1936, 2094, 2130, 2145, 2199], "gcd": [283, 2094, 2155, 2199], "ge": [285, 1270, 1408, 1531, 1536, 1537, 1550, 1588, 1690, 1691, 2094, 2115, 2155, 2199], "geometr": [286, 790, 796, 1686, 1697, 1757, 2039, 2155, 2180, 2201], "greater_equ": [294, 2094, 2155], "hypot": [304, 2094, 2155, 2199], "igamma": [308, 2094, 2155, 2199], "igammac": [310, 2094, 2155, 2199], "3100": [311, 483, 1285, 1910], "3553j": [311, 483, 1285, 1910], "5445": [311, 483, 1285, 1910], "7896j": [311, 483, 1285, 1910], "6492": [311, 483, 1285, 1910], "0633j": [311, 483, 1285, 1910], "0638": [311, 483, 1285, 1910], "8119j": [311, 483, 1285, 1910], "3553": [311, 1285], "7896": [311, 1285], "0633": [311, 1285, 1361], "8119": [311, 1285], "index_add_": [312, 930, 932, 935, 1286, 1287, 2094, 2146], "index_copy_": [314, 2094], "index_fill_": [316, 2094, 2115], "index_put_": [318, 2094], "include_self": [321, 516, 517, 1288, 1927, 2094, 2199], "identit": 321, "floattensor": [321, 487, 697, 698, 699, 700, 701, 746, 949, 950, 970, 1522, 1523, 1583, 1624, 1934, 2174, 2177], "amax": [321, 517, 707, 708, 1970, 2094, 2155, 2199], "amin": [321, 517, 706, 708, 1970, 2094, 2155, 2199], "fill_": [321, 1314, 1340, 1580, 1877, 1913, 2094, 2115, 2142, 2173], "72": [321, 617, 1268, 2161], "uint8_t": [326, 1833], "retain_grad": [335, 2094, 2127, 2155], "requires_grad_": [335, 448, 1314, 1499, 1580, 1670, 1877, 1967, 1970, 2011, 2094, 2115, 2127, 2177, 2205], "n_fft": [351, 556, 1311, 1990, 2094], "hop_length": [351, 556, 1311, 1990, 2094], "win_length": [351, 556, 1311, 1990, 2094], "center": [351, 556, 790, 796, 1164, 1311, 1651, 1686, 1697, 1757, 1857, 1882, 1949, 1990, 2094, 2127, 2137, 2155, 2176], "onesid": [351, 556, 1311, 1990, 2094, 2199], "return_complex": [351, 556, 1311, 1990, 2094], "element_s": [353, 435, 2094, 2115, 2155, 2173], "lcm": [356, 2094, 2155], "ldexp": [358, 1194, 2094, 2155], "le": [360, 1235, 1342, 1536, 1537, 1690, 1691, 2094, 2115, 2155, 2178, 2199], "lerp": [362, 2094, 2155], "lt": [363, 395, 1235, 1341, 2093, 2094, 2115, 2155, 2190, 2193, 2199], "less_equ": [366, 2094, 2155], "lgamma": [368, 652, 653, 2094, 2155, 2199], "ln": [377, 1343, 2172], "logical_and": [383, 2094, 2155, 2199], "logical_not": [385, 1738, 2094, 2115, 2155, 2199], "logical_or": [387, 2094, 2155, 2199], "logical_xor": [389, 2094, 2155, 2199], "pivot": [396, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1404, 1405, 1406, 1892, 2094], "get_info": [396, 1404], "lu_data": [397, 1405, 1406, 2094], "lu_pivot": [397, 1405, 1406, 2094], "masked_fill_": [399, 1738, 2094, 2115, 2116], "booltensor": [400, 402, 746, 1408, 1624, 2048, 2174, 2177], "masked_scatter_": [401, 2094], "mvlgamma": [426, 2094, 2155], "posinf": [427, 428, 1470, 2094], "neginf": [427, 428, 1470, 2094], "nan_to_num": [428, 2094, 2155], "interpol": [431, 479, 796, 797, 798, 1340, 1473, 1633, 1634, 1635, 1651, 1686, 1757, 1758, 1759, 1893, 2033, 2094, 2163], "ne": [439, 1788, 1821, 1829, 2094, 2115, 2155, 2199, 2205], "8182e": 445, "5765e": 445, "41": [445, 1147, 1373, 1760, 1820, 1892], "0545e": 445, "0949e": 445, "4842e": [445, 1147], "0000e": [445, 1147, 1187, 1392, 1401, 1470, 1820, 1947, 1949, 1950, 1955, 1956], "00": [445, 1147, 1187, 1392, 1401, 1470, 1820, 1834, 1947, 1949, 1950, 1955, 1956, 2093], "141592": [446, 1199], "1416": [446, 1128, 1199, 2011], "array_lik": [448, 909, 1976, 1977, 1978, 1979, 1980, 1981, 2011, 2117, 2177], "nextaft": [451, 2094, 2155, 2199], "fro": [453, 1346, 1367, 1371, 1384, 1799, 1807, 1827, 2094], "not_equ": [456, 2094, 2155], "resolve_conj": [458, 1020, 2094, 2155], "resolve_neg": [458, 2094, 2155], "shorthand": [458, 1334], "input3": [460, 2094], "polygamma": [466, 2094, 2155, 2172], "q_per_channel_axi": [473, 474, 2094, 2155], "zero_point": [474, 476, 749, 750, 751, 752, 753, 754, 755, 760, 761, 762, 763, 764, 765, 766, 767, 769, 770, 781, 783, 784, 785, 786, 788, 791, 792, 814, 817, 837, 839, 840, 841, 846, 882, 1158, 1159, 1894, 1895, 1896, 1897, 1898, 2094, 2161, 2162], "qtensor": [478, 2094], "life": [486, 1040], "unexpectedli": [486, 2173, 2177], "poll": 486, "realloc": [486, 1002, 1289, 2130], "counterintuit": [486, 2127], "s1": [486, 1228, 2173, 2192], "some_comm_op": 486, "wouldn": [486, 1241, 2168, 2194], "chrome": [486, 961, 2159, 2198, 2202], "export_chrome_trac": [486, 2159, 2202], "cudacachingalloc": [486, 1041, 2130, 2136], "enable_grad": [488, 2098, 2180], "0100": [488, 905, 1368, 1894], "0200": 488, "0300": [488, 2147], "maxnorm": [491, 492, 1913, 2094], "tile": [493, 2094, 2122, 2130, 2155, 2171, 2195], "repeat_interleav": [493, 1738, 2033, 2094, 2155, 2163], "output_s": [494, 752, 753, 754, 777, 778, 1481, 1482, 1483, 1485, 1486, 1487, 1511, 1526, 1527, 1528, 1576, 1577, 1578, 1632, 1645, 1646, 1647, 1648, 1649, 1650, 1680, 1681, 1682, 1714, 1715, 1716, 1914, 2094, 2117, 2199], "is_leaf": [495, 2094, 2115, 2117, 2155], "saved_weight": 496, "loaded_weight": 496, "5503": 496, "4926": [496, 2142], "1158": 496, "8303": 496, "1007": 496, "9853": 496, "2316": 496, "6606": 496, "resiz": [499, 500, 524, 545, 546, 1197, 1198, 1202, 1633, 1686, 1697, 2094, 2115, 2137, 2155, 2173, 2199], "set_": [499, 2094, 2173], "shift": [505, 975, 978, 1164, 1171, 1488, 1494, 1495, 1496, 1524, 1620, 1679, 1919, 1948, 2094, 2097, 2145], "decim": [507, 508, 1921, 2094, 2145, 2210], "scatter_": [512, 515, 1925, 2094], "scatter_add_": [513, 514, 1926, 2033, 2094], "scatter_reduce_": [513, 516, 1927, 2094], "axi": [513, 515, 517, 841, 846, 1018, 1143, 1158, 1184, 1255, 1280, 1894, 1914, 1919, 1920, 2047, 2094, 2100, 2134, 2150, 2154, 2161, 2195, 2203], "4600": 513, "2300": 513, "scatter_reduc": [517, 2033, 2094, 2155, 2199], "sgn": [522, 1193, 1945, 2094, 2115, 2155, 2171], "untypedstorag": [524, 557, 613, 1300, 2147, 2173], "int16": [525, 1197, 1397, 2171, 2173, 2174, 2177, 2210], "dense_dim": [543, 545, 546, 583, 584, 585, 587, 588, 1979, 2094, 2155, 2171], "nse": [544, 2171], "6550": 544, "2397": 544, "1611": 544, "0779": [544, 1351, 1889, 2048], "2326": 544, "0558": 544, "4711": 544, "9678": 544, "5138": 544, "0411": 544, "9417": 544, "5158": 544, "0793": 544, "0036": [544, 1412], "2569": 544, "1055": 544, "sparse_coo": [544, 583, 1476, 1970, 1973, 1975, 1979, 2171, 2174], "split_siz": [547, 1982, 2094, 2199], "squeez": [553, 704, 706, 707, 708, 710, 834, 1336, 1402, 1412, 1414, 1415, 1417, 1420, 1471, 1474, 1668, 1890, 1975, 1988, 1989, 1993, 2040, 2041, 2094, 2115, 2154, 2155, 2163, 2175, 2199], "pad_mod": [556, 1990, 2094], "typedstorag": [557, 1300, 2147, 2173], "untyped_storag": [557, 2173], "compute_uv": [567, 1378, 1379, 1994, 2094], "axis0": [568, 1996, 2094], "axis1": [568, 1996, 2094], "dim0": [569, 592, 593, 1997, 2017, 2094], "indices_or_sect": [578, 1142, 1278, 2012, 2046], "5044": 580, "0005": [580, 1870, 1876], "3310": 580, "0584": [580, 1994], "cuda0": [580, 2130, 2139, 2177], "masked_grad": [581, 2094], "sparse_mask": [581, 2094, 2155], "mkldnn": [582, 1324], "sparsedim": 583, "blocksiz": [583, 584, 585, 1976, 1977, 1978, 2094, 2171], "sparse_csc": [583, 587, 1973, 1978, 1980, 2171], "sparse_bsr": [583, 585, 1977, 1978, 2171], "sparse_bsc": [583, 584, 1976, 1978, 2171], "bsr": [583, 585, 1977, 1978, 2178], "bsc": [583, 584, 1976, 1978, 2178], "csc": [583, 587, 1978, 1980, 2178], "minu": [583, 584, 585, 587, 588, 2172], "crow_indic": [583, 585, 588, 1968, 1970, 1971, 1973, 1977, 1978, 1981, 2094, 2155, 2171, 2178], "col_indic": [583, 585, 588, 1970, 1971, 1973, 1977, 1978, 1981, 2094, 2122, 2155, 2171, 2178], "sparsecsr": [583, 2017, 2171], "row_indic": [584, 587, 1976, 1980, 2094, 2155, 2171, 2178], "ccol_indic": [584, 587, 1976, 1980, 2094, 2155, 2171, 2178], "_nnz": [586, 587, 588, 2155], "012766935862600803": 589, "5415473580360413": 589, "08909505605697632": 589, "7729271650314331": 589, "unitriangular": [594, 1377, 2020, 2094], "tril": [596, 1641, 1642, 1643, 1738, 2094, 2155, 2195], "triu": [598, 1793, 2020, 2094, 2155, 2195], "trunc": [602, 678, 679, 698, 1139, 1182, 1189, 1192, 1921, 2094, 2115, 2155, 2171, 2199], "sizedim": 607, "return_invers": [609, 610, 2029, 2030, 2094], "return_count": [609, 610, 2029, 2030, 2094], "unsqueez": [612, 1164, 1335, 1375, 1522, 1600, 1793, 2014, 2094, 2100, 2117, 2133, 2155, 2163, 2171, 2175, 2176, 2199], "subspac": [617, 1378, 1586, 1882, 1994, 1995], "span": [617, 1106, 1107, 1515, 1994, 2159, 2166], "foral": 617, "proportion": [617, 796, 1633, 1757], "9482": [617, 1291], "0310": 617, "4999": 617, "5316": 617, "1520": 617, "7472": 617, "5617": 617, "8649": 617, "4724": [617, 2142], "0334": 617, "2976": 617, "8499": 617, "2109": 617, "9913": 617, "9607": 617, "6123": 617, "1064483442": 617, "1124191867": 617, "1069546515": 617, "1089989247": 617, "1105482831": 617, "1061112040": 617, "1057999968": 617, "1084397505": 617, "1071760287": 617, "1123489973": 617, "1097310419": 617, "1084649136": 617, "1101533110": 617, "1073668768": 617, "1082790149": 617, "1088634448": 617, "1000000000": 617, "0047": 617, "0310j": 617, "5316j": 617, "7472j": 617, "8649j": 617, "0334j": 617, "8499j": 617, "9913j": 617, "6123j": 617, "202": 617, "154": [617, 2148], "59": [617, 2022, 2024], "182": 617, "243": [617, 1311, 1994], "253": 617, "188": 617, "185": [617, 2205], "252": [617, 2148], "191": 617, "63": [617, 2148, 2161, 2173], "240": 617, "227": 617, "165": 617, "190": 617, "146": 617, "106": 617, "205": 617, "112": [617, 2205], "206": 617, "189": [617, 2204], "95": [617, 1868, 1871, 1872, 2111], "147": 617, "43": 617, "246": [617, 2205], "87": 617, "235": 617, "226": 617, "254": [617, 2148], "111": [617, 1834], "117": 617, "177": 617, "28": [617, 757, 1127, 2018, 2154, 2192, 2193, 2198], "xlogi": [622, 2094, 2155, 2172], "inductor": [681, 1002, 1004, 2102, 2155, 2161, 2183, 2185, 2186, 2189, 2190, 2191, 2192, 2193, 2195, 2197, 2198, 2201, 2202, 2204, 2205, 2207], "onnx": [681, 1814, 1815, 1833, 1834, 1835, 2116, 2160, 2161, 2183], "aot_graph": [681, 2102, 2204], "aot_joint_graph": [681, 2102, 2204], "ddp_graph": [681, 2102, 2132], "graph_cod": [681, 2102, 2192, 2204], "graph_break": [681, 2102, 2189, 2192, 2195, 2196, 2202, 2204], "graph_siz": [681, 2192, 2204], "recompiles_verbos": [681, 2204], "trace_sourc": [681, 2204], "trace_cal": 681, "trace_bytecod": [681, 2204], "output_cod": [681, 2102, 2195, 2197, 2204, 2205], "kernel_cod": [681, 2204], "perf_hint": [681, 1002, 2204], "post_grad_graph": 681, "onnx_diagnost": 681, "cudagraph": [681, 1002, 1078, 2130, 2183, 2195, 2197, 2198, 2201], "sym_nod": 681, "compiled_autograd": [681, 2102], "compiled_autograd_verbos": 681, "cudagraph_static_input": 681, "graph_region_expans": 681, "toggl": [681, 2130, 2159], "suppress": [681, 2096, 2165], "silenc": 681, "highest": [681, 1484, 1903, 1904, 1936, 2162, 2178, 2204], "lowest": [681, 992, 1470, 1798, 1799, 1806, 1807, 1903, 1904, 2133, 2178], "notset": 681, "torchinductor": [681, 2102, 2183, 2185, 2191, 2193, 2195, 2197, 2204], "ddpoptim": [681, 2102], "symnod": [681, 1218, 2191], "opter": 681, "unregist": [681, 2102, 2109, 2154], "expans": 681, "current_device_index": [684, 687, 693], "is_half_support": 684, "has_half": 684, "get_device_properti": 684, "has_fp16": 684, "start_ev": [693, 2130], "current_acceler": [693, 2180], "elapsed_time_m": [693, 2130], "cosin": [694, 695, 1024, 1025, 1513, 1514, 1668, 1863, 1864, 1872, 1878, 1951, 2157, 2195], "3348": 694, "5889": 694, "2005": [694, 2041, 2186, 2205], "1584": 694, "2294": [694, 1414], "2004": 694, "3690": 694, "7298": [694, 1911], "hyperbol": [695, 912, 915, 1025, 1621, 1960, 2010], "uniform_": [695, 915, 972, 2094, 2115, 2124, 2133, 2172, 2180], "3192": 695, "9915": 695, "9674": 695, "7151": 695, "7791": 695, "3120": [695, 1022], "2979": 695, "1341": 695, "_i": [696, 697, 698, 699, 700, 705, 970, 972, 975, 978, 982, 997, 1139, 1189, 1303, 1338, 1340, 1465, 1586, 1629, 1885, 1889, 1905, 1908, 1943, 1991, 2048, 2172], "0202": 696, "0985": 696, "3506": [696, 1404], "6056": 696, "3944": 696, "9732": 696, "3497": 696, "6245": [696, 1346], "4022": [696, 1994], "3743": 696, "7724": 696, "5811": 696, "8017": 696, "7695": 696, "3930": 696, "3672": [696, 1036, 1347], "1450": [696, 1975], "6971": 696, "0736": [696, 2142], "0994": 696, "3216": 696, "7845": 696, "1610": 696, "1868": 696, "4090": 696, "9902": [696, 1036, 1347], "3667": [696, 1022], "3925": 696, "6147": 696, "sum_": [697, 1311, 1366, 1383, 1489, 1490, 1491, 1507, 1508, 1509, 1515, 1547, 1548, 1549, 1568, 1583, 1587, 1589, 1595, 1769, 1988, 1989, 1990, 2013, 2018, 2040, 2041, 2042, 2172], "mathbin": [697, 700, 701, 970, 982, 1971], "doubletensor": [697, 698, 699, 700, 701, 970, 1934, 2174, 2177], "tensorfloat32": [697, 700, 970, 982, 1409, 1419, 1507, 1508, 1509, 1510, 1511, 1512, 1567, 1661, 1662, 1663, 1664, 1665, 1666, 1703, 1936, 2130, 2145], "6311": 697, "0503": 697, "9768": [697, 2142], "0362": 697, "1653": 697, "8185": 697, "4255": [697, 1465], "6760": 697, "9453": 697, "5743": 697, "8202": 697, "3691": 697, "0943": 697, "1109": [697, 1533, 1956], "4730": [697, 2013], "histor": [698, 1101, 1519, 2078, 2080, 2129, 2142, 2147, 2173], "t1": [698, 699, 910, 1141, 1268, 1770, 2038, 2095, 2166, 2167], "2312": [698, 1975], "6496": 698, "1312": 698, "0428": 698, "4292": 698, "1030": 698, "5369": 698, "9829": 698, "0430": 698, "8635": 699, "6391": 699, "6174": 699, "7617": 699, "5879": 699, "7388": 699, "8353": 699, "6249": 699, "6511": 699, "8716": 700, "4671": 700, "3746": 700, "7573": 700, "9555": 700, "8681": 700, "3768": 701, "5565": 701, "otim": [702, 1335, 1530, 1685], "conj": [703, 1021, 1160, 1161, 1163, 1165, 1172, 1174, 1178, 1179, 1181, 1344, 1345, 1351, 1353, 1372, 1916, 1917, 2094, 2133, 2138, 2155, 2177, 2199], "mh": [703, 993, 994, 995, 1351, 1994, 2094, 2155, 2175, 2177], "lvert": [705, 1303, 1629, 1723, 2178], "rvert": [705, 1303, 2178], "leq": [705, 971, 972, 1022, 1162, 1164, 1303, 1335, 1339, 1354, 1360, 1499, 1521, 1583, 1585, 1587, 1670, 1722, 1725, 1946, 1990, 2124, 2172], "elementwis": [705, 1022, 1054, 1055, 1086, 1087, 1187, 1189, 1480, 1542, 1543, 1544, 1747, 2039, 2096, 2138, 2172], "07": [705, 837, 839, 840, 841, 846, 993, 1147, 1352, 1355, 1360, 1372, 1373, 1379, 1402, 1405, 1787, 1835, 1843, 1950, 1955, 1994], "09": [705, 1843, 1861, 2100, 2178], "8177": 706, "4878": 706, "2491": 706, "9130": 706, "7158": 706, "1775": 706, "0992": 706, "4817": 706, "0053": 706, "0164": 706, "3738": 706, "0507": [706, 2154], "9700": 706, "1106": 706, "0318": 706, "0816": [706, 1404], "6451": 707, "4866": [707, 2185], "2987": 707, "3312": 707, "5744": 707, "2980": 707, "8397": 707, "2713": 707, "9128": 707, "9214": 707, "7268": 707, "2995": 707, "9023": [707, 1345], "4853": 707, "9075": 707, "6165": 707, "180": [709, 1128, 1900], "14159": [709, 2011], "135": 709, "45": [709, 1495, 1496, 1543, 1544, 1620, 1820, 2154, 2186], "ao": [711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 837, 839, 840, 841, 842, 843, 846, 851, 852, 855, 856, 857, 858, 859, 860, 861, 862, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 2161, 2162, 2163], "fuse": [711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 734, 735, 736, 737, 738, 739, 740, 805, 806, 817, 819, 820, 821, 829, 877, 889, 890, 1002, 1328, 1329, 1738, 1779, 1780, 1781, 1782, 1783, 1784, 1839, 1840, 1841, 1859, 1936, 2106, 2115, 2117, 2118, 2150, 2154, 2157, 2161, 2162, 2163, 2164, 2195, 2197, 2203], "qat": [723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 741, 742, 743, 744, 805, 806, 876, 2161, 2162, 2163], "padding_mod": [723, 724, 725, 726, 727, 728, 729, 730, 736, 737, 738, 741, 742, 749, 750, 751, 752, 753, 754, 783, 784, 785, 1507, 1508, 1509, 1510, 1511, 1512, 1556, 1557, 1558, 1559, 1560, 1561, 1686, 2094, 2199], "momentum": [723, 724, 725, 726, 727, 728, 734, 735, 747, 748, 762, 763, 764, 1494, 1495, 1496, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1620, 1656, 1696, 1844, 1857, 1859, 1865, 1872, 1874, 2094, 2137, 2142, 2144, 2157, 2199], "freeze_bn": [723, 724, 725, 726, 727, 728], "qconfig": [723, 724, 725, 726, 727, 728, 729, 730, 731, 741, 742, 743, 744, 800, 802, 804, 807, 808, 809, 811, 866, 868, 869, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 888, 889, 891, 892, 2182], "batchnorm1d": [723, 726, 1553, 1620, 1656, 2147, 2163], "fakequant": [723, 724, 725, 726, 727, 728, 729, 730, 731, 741, 742, 743, 744, 817, 892], "weight_fake_qu": [723, 724, 725, 726, 727, 728, 729, 730, 741, 742], "quant": [723, 724, 725, 726, 727, 728, 729, 730, 731, 741, 742, 743, 767, 803, 805, 806, 811, 866, 891, 892, 1158, 1159, 2161, 2162], "batchnorm3d": [725, 728, 730, 735, 1555, 1620, 1656, 2163], "num_featur": [734, 735, 747, 748, 762, 763, 764, 1314, 1494, 1495, 1496, 1542, 1543, 1544, 1553, 1554, 1555, 1562, 1563, 1564, 1580, 1620, 1688, 1877, 2142], "qint8": [739, 740, 767, 772, 775, 776, 783, 784, 785, 792, 805, 807, 814, 839, 871, 888, 889, 891, 892, 1833, 1894, 1895, 2161, 2163, 2164, 2173, 2177, 2178], "from_float": [743, 749, 750, 751, 756, 757, 767, 775, 811, 832, 842, 851, 866, 2161], "use_precomputed_fake_qu": [743, 749, 750, 751, 756, 757, 767, 775, 811, 894], "qparams_dict": [743, 749, 750, 751, 775], "hidden_s": [745, 771, 772, 776, 1531, 1532, 1550, 1551, 1596, 1597, 1598, 2094], "num_lay": [745, 771, 1531, 1550, 1596, 1597, 1625, 1627, 2094, 2142], "batch_first": [745, 746, 771, 1531, 1550, 1586, 1596, 1597, 1624, 1626, 1628, 1814, 1816, 1817, 1819, 2094, 2135], "bidirect": [745, 771, 1531, 1550, 1596, 1597, 2094], "split_gat": 745, "_lstmlayer": 745, "nnqa": 745, "h0": [745, 771, 773, 1531, 1550, 1596], "c0": [745, 773, 1550, 2205], "hn": [745, 771, 773, 1531, 1532, 1550, 1596], "cn": [745, 773, 1314, 1550, 1905], "weight_ih": [745, 1532, 1551, 1596, 1598], "weight_hh": [745, 1532, 1551, 1596, 1598], "embed_dim": [746, 1586], "num_head": [746, 1586, 1640, 2094, 2122], "add_bias_kv": [746, 1586], "add_zero_attn": [746, 1586, 2094], "kdim": [746, 1586], "vdim": [746, 1586], "dequant": [746, 800, 803, 805, 806, 814, 816, 891, 2094, 2155, 2162, 2164, 2178, 2181], "mha": [746, 1586], "conver": 746, "key_padding_mask": [746, 1586, 2094], "need_weight": [746, 1586, 2094], "attn_mask": [746, 1586, 1624, 1738, 2094], "average_attn_weight": [746, 1586, 2094], "is_caus": [746, 1586, 1627, 1628, 1643, 1738, 2094], "attn_output_weight": [746, 1586], "unmask": [746, 1624], "attn_weight": [746, 1586, 1738], "head": [746, 1484, 1586, 1624, 1626, 1628, 1738, 2122], "attn_output": [746, 1586], "quint8": [749, 750, 751, 752, 753, 754, 756, 757, 767, 783, 784, 785, 792, 805, 807, 814, 837, 839, 840, 841, 846, 852, 889, 891, 1833, 1894, 1895, 1896, 1897, 1898, 2161, 2163, 2164, 2173, 2177, 2178], "learnabl": [749, 750, 751, 752, 753, 754, 756, 757, 767, 771, 775, 1494, 1495, 1496, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1522, 1523, 1531, 1532, 1534, 1542, 1543, 1544, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1567, 1588, 1595, 1596, 1598, 1620, 1678, 1731, 1769, 2142, 2157], "q_input": [749, 750, 751, 752, 753, 754, 783, 784, 785], "quantize_per_tensor": [749, 750, 751, 752, 753, 754, 767, 768, 769, 783, 784, 785, 1896, 1897, 1898, 2094, 2155, 2161], "50": [750, 752, 753, 754, 783, 843, 1370, 1490, 1491, 1499, 1507, 1508, 1509, 1511, 1512, 1527, 1528, 1547, 1548, 1549, 1573, 1574, 1575, 1631, 1663, 1664, 1666, 1670, 1681, 1682, 1858, 2008, 2117, 2130, 2176, 2195], "56": [751, 2031, 2171, 2198], "output_pad": [752, 753, 754, 1510, 1511, 1512, 1559, 1560, 1561, 1664, 1665, 1666, 2094, 2199], "qnnpack": [752, 753, 767, 775, 885, 886, 889, 891, 892, 2161, 2163], "convtranspose2d": [752, 1560, 1665, 1779, 2033, 2163], "nnq": [752, 753, 754, 800, 802, 803, 894, 2161], "downsampl": [752, 753, 754, 1511, 1633, 1651, 1686, 1697], "upsampl": [752, 753, 754, 790, 797, 798, 1511, 1634, 1635, 1651, 1686, 1697, 1758, 1759], "fbgemm": [753, 754, 767, 775, 860, 885, 886, 889, 891, 892, 2100, 2161, 2162, 2189, 2195, 2196], "cubic": [754, 1528, 1682, 1686], "num_embed": [756, 757, 1522, 1523, 1678], "embedding_dim": [756, 757, 1522, 1523, 1552, 1677, 1678], "padding_idx": [756, 1522, 1523, 1677, 1678, 2094, 2199], "scale_grad_by_freq": [756, 757, 1522, 1523, 1677, 1678, 2094, 2199], "_weight": [756, 757, 1522, 1523, 1844, 1856, 2203], "overwritten": [756, 757, 767, 775, 811, 871, 891, 909, 2127, 2133, 2150, 2178, 2189], "num": [756, 757, 771, 1466, 1531, 1534, 1550, 1586, 1596, 1624, 2144], "_embed": [756, 757], "_dim": [756, 757, 1522], "include_last_offset": [757, 1523, 1678, 2094, 2199], "embedding_bag": [757, 2094, 2155], "floatfunct": [758, 2161], "activation_post_process": [758, 814, 2161], "add_relu": [758, 759, 768, 2106, 2155, 2181], "add_scalar": [758, 759, 768, 2155, 2176, 2181], "mul_scalar": [758, 759, 768, 2155, 2181], "collector": 759, "f_add": 759, "num_channel": [760, 1534, 2116], "normalized_shap": [765, 1552, 1595, 1700, 1735, 1769, 2094, 2199], "elementwise_affin": [765, 1552, 1595, 1769], "negative_slop": [766, 791, 1566, 1701, 1702, 2094, 2124, 2199], "slope": [766, 791, 1566, 1612, 2124], "bias_": [767, 775], "_featur": [767, 775, 792, 1484, 1497, 1565, 1567, 1657, 1703], "precomput": [767, 811, 2191], "from_refer": [767, 775], "ref_qlinear": [767, 775], "output_scal": [767, 770, 1896, 2094], "output_zero_point": [767, 770, 1896, 2094], "q_add": 768, "qint32": [768, 769, 1833, 1894, 1895, 2161, 2164, 2173, 2177, 2178], "x_0": [769, 2018], "gate": [771, 772, 1530, 1531, 1532, 1550, 1610, 1685, 1741], "r_t": [771, 1531, 1838, 1856], "w_": [771, 1482, 1483, 1486, 1487, 1490, 1491, 1493, 1501, 1502, 1503, 1504, 1505, 1506, 1508, 1509, 1511, 1512, 1515, 1527, 1528, 1531, 1532, 1548, 1549, 1550, 1551, 1574, 1575, 1577, 1578, 1587, 1592, 1593, 1596, 1598, 1602, 1603, 1604, 1605, 1606, 1607, 1633, 1634, 1635, 1636, 1637, 1638, 1682, 1686], "x_t": [771, 925, 929, 930, 935, 936, 1494, 1495, 1496, 1531, 1542, 1543, 1544, 1550, 1596, 1620, 1837], "b_": [771, 1531, 1532, 1550, 1551, 1568, 1596, 1598, 2013, 2171], "hr": [771, 1531, 1532, 1550, 2138], "h_": [771, 1482, 1483, 1486, 1487, 1490, 1491, 1497, 1502, 1503, 1505, 1506, 1508, 1509, 1511, 1512, 1527, 1528, 1531, 1532, 1548, 1549, 1550, 1567, 1574, 1575, 1576, 1577, 1578, 1592, 1593, 1596, 1598, 1603, 1604, 1606, 1607, 1633, 1634, 1635, 1637, 1638, 1657, 1682, 1686], "z_t": [771, 1531], "iz": [771, 1531, 1532], "hz": [771, 1050, 1531, 1532, 2176], "n_t": [771, 1531], "odot": [771, 1531, 1532, 1550, 1551, 1838], "h_t": [771, 1531, 1550, 1596], "hadamard": [771, 1531, 1532, 1550, 1551], "multilay": [771, 1531, 1550, 2150], "b_ih": [771, 1531, 1532, 1550, 1551, 1596, 1598, 2094], "b_hh": [771, 1531, 1532, 1550, 1551, 1596, 1598, 2094], "h_0": [771, 1531, 1550, 1551], "seq_len": [771, 1531, 1550, 1586, 1596, 2117, 2122], "pack_padded_sequ": [771, 1531, 1550, 1596, 1813, 1815, 1816, 2135], "num_direct": [771, 1531, 1550, 1596], "h_n": [771, 1531, 1550, 1596], "_size": [771, 1481, 1482, 1483, 1485, 1486, 1487, 1489, 1490, 1491, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1527, 1528, 1531, 1532, 1547, 1548, 1549, 1550, 1551, 1573, 1574, 1575, 1576, 1577, 1578, 1596, 1598, 1632, 1682], "_layer": [771, 1531, 1550, 1596], "_direct": 771, "output1": [771, 1484, 2117, 2126, 2154], "output2": [771, 1484, 2117], "weight_ih_l": [771, 1531, 1550, 1596], "w_ir": [771, 1531], "w_iz": [771, 1531], "w_in": [771, 1531], "weight_hh_l": [771, 1531, 1550, 1596], "w_hr": [771, 1531], "w_hz": [771, 1531], "w_hn": [771, 1531], "bias_ih_l": [771, 1531, 1550, 1596], "b_ir": [771, 1531], "b_iz": [771, 1531], "b_in": [771, 1531], "bias_hh_l": [771, 1531, 1550, 1596], "b_hr": [771, 1531], "b_hz": [771, 1531], "b_hn": [771, 1531], "mathcal": [771, 1497, 1507, 1508, 1509, 1510, 1511, 1512, 1522, 1523, 1531, 1532, 1550, 1551, 1565, 1567, 1596, 1598, 1599, 1620, 1905, 2124, 2138], "subtli": [771, 1531, 1838, 1859], "gru": [772, 1532, 1597, 2094, 2130, 2155, 2161, 2163], "cell": [772, 774, 776, 1531, 1532, 1550, 1551, 1596, 1598], "hx": [772, 774, 776, 1532, 1551, 1596, 1598, 2094], "cx": [774, 1551, 2094], "nonlinear": [776, 1492, 1513, 1539, 1596, 1598, 1608, 2124, 2171], "elman": [776, 1596, 1598], "adaptiveavgpool2d": [777, 1646, 2033, 2163], "adaptiveavgpool3d": [778, 1647, 2033, 2163], "ceil_mod": [779, 780, 793, 794, 1489, 1490, 1491, 1547, 1548, 1549, 1573, 1574, 1575, 1653, 1654, 1655, 1707, 1708, 1709, 1711, 1712, 1713, 1897, 1898, 2094, 2199], "count_include_pad": [779, 780, 1489, 1490, 1491, 1653, 1654, 1655, 2094, 2199], "divisor_overrid": [779, 780, 1490, 1491, 1654, 1655, 2094, 2199], "kh": [779, 780, 784, 785, 1490, 1491, 1527, 1528, 1574, 1575, 1654, 1655, 1662, 1663, 1665, 1666, 1681, 1682, 1712, 1713], "kw": [779, 780, 784, 785, 1490, 1491, 1527, 1528, 1574, 1575, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1681, 1682, 1711, 1712, 1713], "sh": [779, 780, 784, 785, 1654, 1655, 1662, 1663, 1665, 1666, 1712, 1713, 2205], "sw": [779, 780, 783, 784, 785, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1711, 1712, 1713], "avgpool2d": [779, 1654, 2163], "_channel": [779, 780, 783, 784, 785, 1507, 1508, 1509, 1510, 1511, 1512, 1534, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1711, 1712, 1713, 2166], "ih": [779, 780, 784, 785, 1596, 1598, 1654, 1655, 1662, 1663, 1665, 1666, 1712, 1713], "iw": [779, 780, 783, 784, 785, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666, 1711, 1712, 1713], "padh": [779, 780, 784, 785, 1654, 1655, 1662, 1663, 1665, 1666], "padw": [779, 780, 783, 784, 785, 1653, 1654, 1655, 1661, 1662, 1663, 1664, 1665, 1666], "kd": [780, 785, 1491, 1575], "padd": [780, 785], "formul": [781, 1498, 1521, 1535, 1570, 1617, 1618, 1705, 1723, 1738, 2138, 2171], "min_": [782, 1350, 1351, 1360, 1378, 1994], "max_": [782, 1573, 1574, 1575, 1788, 1821], "convolv": [783, 784, 785, 1507, 1508, 1509, 1510, 1511, 1512, 1556, 1557, 1558, 1559, 1560, 1561, 1661, 1662, 1663, 1664, 1665, 1666], "dw": [783, 784, 785, 1661, 1662, 1663, 1664, 1665, 1666], "qf": [783, 784, 785], "dtype_input": [783, 784, 785], "dtype_filt": [783, 784, 785], "q_filter": [783, 784, 785], "dh": [784, 785, 1662, 1663, 1665, 1666], "dd": 785, "min_val": [789, 1538, 1692, 1693, 2094, 2199], "max_val": [789, 1538, 1692, 1693, 2094, 2199], "scale_factor": [790, 796, 797, 798, 1633, 1634, 1635, 1697, 1738, 1757, 1758, 1759, 2094, 2199], "nearest": [790, 796, 798, 1473, 1633, 1635, 1686, 1697, 1757, 1759, 1893, 1921, 2130], "align_corn": [790, 796, 797, 1633, 1634, 1651, 1686, 1697, 1757, 1758, 2094, 2199], "height": [790, 796, 1490, 1491, 1508, 1509, 1511, 1512, 1548, 1549, 1574, 1575, 1587, 1615, 1633, 1697, 1757, 2116], "spatial": [790, 796, 797, 798, 990, 1164, 1495, 1526, 1552, 1592, 1593, 1615, 1632, 1633, 1634, 1635, 1651, 1659, 1686, 1697, 1727, 1728, 1729, 1757, 1758, 1759], "pixel": [790, 796, 798, 1508, 1515, 1518, 1519, 1520, 1524, 1587, 1592, 1593, 1633, 1651, 1686, 1697, 1757, 1759], "corner": [790, 796, 981, 1633, 1641, 1642, 1643, 1651, 1686, 1697, 1757], "leakyrelu": [791, 1581, 1701, 2142, 2163], "_slope": [791, 1566, 1701, 2124], "xa": [792, 1364, 1375, 1376, 1377, 1567, 1703], "return_indic": [793, 794, 1485, 1486, 1487, 1527, 1528, 1573, 1574, 1575, 1576, 1577, 1578, 1648, 1649, 1650, 1681, 1682, 1711, 1712, 1713, 2094], "maxpool1d": [793, 1576, 1711, 1714, 2163], "linearli": [796, 1209, 1373, 1633, 1757, 1869, 1892, 2135, 2157, 2164], "neighbour": [798, 1568, 1697, 1759], "calibr": [800, 802, 811, 866, 868, 887, 889, 891, 2126, 2161, 2162, 2164, 2182], "numeric_debug_handl": [801, 867], "quantstub": [803, 2161], "dequantstub": [803, 2161], "quantwrapp": 804, "backend_config": [805, 806, 807, 808, 809, 832, 833, 889, 890, 891, 892, 2182], "backendpatternconfig": [805, 891], "dtypeconfig": [805, 806, 808, 891], "observationtyp": [805, 806, 891, 2163], "weighted_int8_dtype_config": [805, 891], "input_dtyp": [805, 807, 891, 2163], "weight_dtyp": [805, 807, 891, 2163], "bias_dtyp": [805, 807, 2163], "fuse_conv2d_relu": 805, "is_qat": [805, 806], "convrelu2d": [805, 2163], "linear_config": 805, "set_observation_typ": [805, 806, 891], "output_use_different_observer_as_input": [805, 806, 809, 891, 2163], "add_dtype_config": [805, 806, 891], "set_root_modul": [805, 806], "set_qat_modul": [805, 806], "set_reference_quantized_modul": [805, 806], "conv_relu_config": 805, "set_fused_modul": [805, 806], "set_fuser_method": [805, 806], "fused_conv_relu_config": 805, "my_backend": [805, 2190], "set_backend_pattern_config": [805, 891], "from_dict": [805, 806, 807, 830, 831, 832, 884], "backend_config_dict": [805, 2161], "set_nam": 805, "to_dict": [805, 806, 807, 830, 831, 832, 884], "backendconfig": [806, 833, 889, 891, 2164], "dtype_config": [806, 2163], "backend_pattern_config_dict": 806, "observation_typ": [806, 2163], "qat_modul": [806, 2163], "reference_quantized_modul": 806, "fused_modul": [806, 2163], "fuser_method": [806, 829, 2163], "pattern_complex_format": 806, "set_dtype_config": 806, "fuser": [806, 1328, 2093], "fuse_linear_relu": 806, "linearrelu": [806, 2163], "8bea7180a8ba3c279f2c9b050f2a69a6": 806, "output_share_observer_with_input": [806, 809, 2163], "renam": [806, 2034, 2036, 2094, 2100, 2115, 2116, 2149, 2155, 2198], "quantdequantstub": 806, "set_pattern": 806, "is_dynam": [807, 814, 837, 839, 840, 841, 843, 846, 851, 2163], "quant1": 807, "dequant1": 807, "fp32_linear": 807, "quant2": 807, "dequant2": 807, "bracket": [807, 2167], "dtype_config1": 807, "dtype_config2": 807, "dtypewithconstraint": [807, 2163], "quant_min_lower_bound": [807, 808, 2163], "quant_max_upper_bound": [807, 808, 2163], "255": [807, 817, 1158, 1159, 1198, 1686, 1697, 1757, 2161, 2163, 2176], "input_dtype_with_constraint": 807, "scale_min_lower_bound": [807, 808, 2163], "scale_max_upper_bound": [807, 808, 2163], "dtype_config_dict": 807, "bias_typ": [807, 891], "scale_exact_match": [808, 2163], "zero_point_exact_match": [808, 2163], "quant_min": [808, 814, 817, 837, 839, 840, 841, 846, 851, 1158, 1159, 2094, 2161], "quant_max": [808, 814, 817, 837, 839, 840, 841, 846, 851, 1158, 1159, 2094, 2161], "fixedqparamsobserv": 808, "fixedqparamsfakequant": 808, "input_output_not_observ": [809, 2163], "ref_result": 810, "actual_result": 810, "debug_handle_id": 810, "nodeaccuracysummari": 810, "sqnr": [810, 2182], "mse": [810, 2192], "remove_qconfig": 811, "is_refer": 811, "convert_custom_config_dict": [811, 830, 2161], "from_observ": [811, 830, 2161], "observed_to_quantized_custom_module_class": [811, 830, 2161], "observedcustommodul": [811, 830, 832, 866, 2161], "quantizedcustommodul": [811, 830], "calib_data": 812, "debug_handl": 813, "fake_quant": [814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 892, 1158, 1159, 2182], "movingaverageminmaxobserv": [814, 817, 841], "observer_kwarg": [814, 817], "x_out": [814, 817], "quanti": 814, "choose_qparam": 814, "dq": 814, "fake_quant_en": 814, "observer_en": 814, "calculate_qparam": [815, 837, 839, 843], "extra_repr": [816, 1314, 1580, 1595, 1769, 1877, 2133], "qscheme": [817, 837, 839, 840, 841, 846, 851, 852, 2094, 2141, 2155, 2161, 2164, 2178], "fake_qu": [818, 822, 823, 824, 2161], "default_fake_qu": 819, "default_per_channel_weight_fake_qu": 820, "default_weight_fake_qu": 821, "histogram": [822, 837, 858, 1275, 1277, 2094, 2155, 2176], "memoryless": [823, 824], "averaging_const": [823, 824, 840, 841, 2094], "modules_to_fus": 829, "fuser_func": 829, "fuse_known_modul": 829, "fuse_custom_config_dict": [829, 831], "convmodul": 829, "bnmodul": 829, "convbnmodul": 829, "additional_fuser_method_map": 829, "fuse_conv_bn": [829, 2163], "conv1": [829, 1326, 1580, 1609, 2093, 2149, 2161, 2176], "bn1": 829, "relu1": [829, 1609, 1760], "fused_m": 829, "custom_config": [830, 831, 832, 833], "convert_fx": [830, 2161, 2182], "convert_custom_config": [830, 889, 2161], "set_observed_to_quantized_map": 830, "set_preserved_attribut": [830, 831, 832], "attr1": [830, 831, 832, 2154], "attr2": [830, 831, 832, 2154], "floatcustommodul": [830, 832], "weight_onli": [830, 889, 2161], "preserved_attribut": [830, 831, 832], "observed_class": [830, 832], "quantized_class": 830, "quant_typ": [830, 832], "quanttyp": [830, 832], "fuse_fx": [831, 2161], "fuse_custom_config": [831, 890], "convertcustomconfig": [831, 889], "prepare_fx": [832, 869, 889, 892, 2161, 2182], "prepare_qat_fx": [832, 889, 2161], "prepare_custom_config": [832, 833, 891, 892, 2161], "set_standalone_module_nam": 832, "module1": [832, 884, 2130], "qconfig_map": [832, 833, 884, 885, 886, 889, 891, 892, 2161], "child_prepare_custom_config": 832, "set_standalone_module_class": 832, "mystandalonemodul": 832, "set_float_to_observed_map": 832, "set_non_traceable_module_nam": 832, "module2": [832, 884, 2130], "module3": [832, 2130], "set_non_traceable_module_class": 832, "nontraceablemodule1": 832, "nontraceablemodule2": 832, "set_input_quantized_index": 832, "set_output_quantized_index": 832, "prepare_custom_config_dict": [832, 866, 869, 2161], "standalone_module_nam": 832, "standalone_module_class": 832, "module_class": 832, "float_to_observed_custom_module_class": [832, 866, 2161], "non_traceable_module_nam": 832, "non_traceable_module_class": 832, "input_quantized_idx": 832, "output_quantized_idx": 832, "float_class": 832, "qconfigmap": [833, 885, 886, 889, 891, 2161, 2164], "preparecustomconfig": [833, 891], "numeric_debug_handle_id": [834, 867], "eager_model": 834, "xnnpackquant": [834, 2161], "prepare_pt2": [834, 2161], "convert_pt2": [834, 2161], "2048": [837, 1624, 1626, 1628, 2130], "per_tensor_affin": [837, 839, 840, 1895, 1896, 1897, 1898, 2161, 2164], "reduce_rang": [837, 839, 840, 841, 846, 852, 2094, 2161, 2162], "factory_kwarg": [837, 839, 846], "1920928955078125e": [837, 839, 840, 841, 846], "finfo": [837, 839, 840, 841, 846, 1369, 1372, 1480, 1595, 1769, 2178], "minmaxobserv": [837, 840, 846, 871, 891, 892, 2164], "x_": [839, 840, 1027, 1154, 1388, 1389, 1391, 1394, 1402, 1493, 1515, 1570, 1587, 1614, 1616, 1744, 1970, 1972, 2018, 2127, 2164, 2172], "q_": [839, 2164], "x_orig": 839, "reset_min_max_v": [839, 846], "ch_axi": [841, 846, 2094], "per_channel_affin": [841, 846, 1894, 2161, 2164], "custom_op_nam": [842, 851], "with_arg": [843, 871, 891, 892], "_callable_arg": 843, "_with_arg": 843, "foo_build": 843, "foo_instance1": 843, "foo_instance2": 843, "with_callable_arg": 843, "_with_callable_arg": 843, "cur_tim": 843, "get_time_func": 843, "dan": 843, "creation_tim": 843, "compute_dtyp": 851, "ptq": [858, 2161, 2162, 2164], "obs_dict": 865, "get_observer_state_dict": 865, "allow_list": [866, 2181], "observer_non_leaf_module_list": 866, "preemptiv": [866, 868, 1770], "propagate_qconfig_": 869, "qconfig_dict": [869, 884], "pt2e": 870, "export_util": 870, "my_qconfig": 871, "default_observ": 871, "default_qat_config": 877, "set_glob": [884, 889, 891, 2161], "set_object_typ": [884, 889, 891], "set_module_name_regex": 884, "regex": 884, "set_module_nam": [884, 889, 891], "set_module_name_object_type_ord": 884, "global_qconfig": 884, "qconfig1": 884, "qconfig2": 884, "qconfig3": 884, "object_typ": 884, "module_name_regex": 884, "module_name_object_type_ord": 884, "conv0": 884, "x86": [885, 886, 1937, 2161, 2163], "run_arg": [887, 893], "qconfig_spec": 888, "quantize_fx": [889, 890, 891, 892, 2161, 2182], "_remove_qconfig": 889, "qconfig_from_prepar": 889, "prepared_model": [889, 891, 892], "xnnpack": [889, 2106, 2161], "get_default_backend_config": [889, 891, 892], "quantized_model": 889, "fusion_pattern": 890, "fusecustomconfig": 890, "_equalization_config": 891, "get_default_qconfig_map": [891, 2161], "float_model": [891, 892, 2161, 2181], "data_load": [891, 892, 1865, 1872, 2144, 2161], "get_default_qconfig": [891, 892, 2161], "linear_pattern_config": 891, "suer": 891, "sample_inference_data": [891, 2161], "get_default_qat_qconfig_map": [892, 2161], "load_weight": 892, "train_data": 892, "get_default_qat_qconfig": [892, 2161], "custom_module_class_map": 894, "lceil": [895, 991], "rceil": [895, 991], "adjac": [895, 981, 1518, 1519, 1520, 1524, 1908, 2171, 2202], "get_default_dtyp": [895, 1385, 1401, 1833, 1908, 2173, 2174, 2210], "set_default_devic": [895, 971, 980, 1145, 1147, 1157, 1162, 1180, 1196, 1199, 1272, 1273, 1334, 1385, 1401, 1831, 1901, 1903, 1905, 1907, 1908, 1934, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1976, 1977, 1978, 1979, 1980, 1981, 2022, 2024, 2089, 2174], "5000": [895, 910, 916, 917, 918, 973, 997, 1162, 1164, 1165, 1172, 1175, 1180, 1190, 1192, 1193, 1194, 1268, 1274, 1277, 1340, 1366, 1385, 1471, 1473, 1504, 1505, 1523, 1633, 1893, 1897, 1898, 1899, 1908, 1912, 2172, 2177], "maxim": [904, 1412, 1513, 1576, 1577, 1578, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 2171, 2195, 2204, 2205], "3398": 904, "2663": [904, 2130], "2686": 904, "2450": 904, "7401": 904, "8805": 904, "3402": 904, "1936": 904, "4907": [904, 1402], "3948": [904, 1022], "0691": 904, "3132": 904, "6092": 904, "5419": 904, "2993": [904, 1993], "3195": 904, "1139": 905, "2254": 905, "1381": [905, 1993], "3687": 905, "1975": [905, 2117], "0102": 905, "4732": 905, "9240": 905, "1207": [905, 1465], "7506": 905, "0213": 905, "7809": 905, "2960": 905, "9384": 905, "1438": 905, "ascend": [906, 1164, 1351, 1353, 1382, 1441, 1928, 1965, 2029], "0785": 906, "5267": 906, "8521": 906, "4065": 906, "1598": 906, "0788": 906, "0745": 906, "2700": 906, "2208": 906, "0722": 906, "7064": 906, "2564": 906, "0669": 906, "2318": 906, "8229": 906, "9280": 906, "lexicograph": [907, 1826, 2096, 2171], "9039": 908, "6291": 908, "0795": [908, 1893, 2142], "1586": 908, "1939": [908, 2133], "4900": 908, "1909": 908, "7503": 908, "9355": 908, "deviceliketyp": [909, 910], "histori": [909, 910, 1211, 1843, 2011, 2103, 2117, 2133, 2135, 2167], "cupi": 909, "dlpack": [910, 1195, 2160], "frombuff": [910, 1932], "data_ptr": [910, 956, 2100, 2115, 2130, 2173, 2175, 2204], "addbackward0": [910, 2142, 2147], "__array_interface__": [910, 2195], "5962": 911, "4985": 911, "4396": 911, "4525": [911, 2117], "6387": 911, "4552": 911, "sine": [912, 1948, 1958, 1960], "1606": 912, "4267": 912, "0899": 912, "0250": 912, "1599": 912, "1534": 912, "9435": 912, "8990": [912, 1139], "arctang": [913, 914], "2341": 913, "2539": 913, "6256": 913, "6448": 913, "2299": 913, "2487": 913, "5591": [913, 942], "5727": 913, "quadrant": 914, "9041": [914, 990], "0196": [914, 990], "3108": [914, 990], "4423": [914, 990], "9833": 914, "0811": 914, "9743": 914, "4151": 914, "tangent": [915, 924, 928, 929, 1208, 1209, 1621, 2009, 2010], "9385": 915, "2968": 915, "8591": 915, "1871": 915, "7253": 915, "3060": 915, "2899": 915, "1893": 915, "needs_input_grad": [919, 935, 936, 2133], "setup_context": [920, 930, 931, 932, 933, 934, 935, 936, 2100, 2134], "save_for_forward": [920, 930, 935, 936, 2134], "grad_input": [921, 930, 932, 934, 935, 936, 954, 1314, 1580, 1877, 2133, 2142], "underneath": [922, 935, 936, 2117], "generate_vmap_rul": [922, 935, 936, 2134], "out_dim": [922, 935, 936, 1213, 2045, 2094, 2100, 2116, 2134], "grad_tensor": [923, 944, 2094, 2130], "grad_vari": 923, "forward_ad": [924, 925], "primal": [924, 929, 1204, 1208, 1209, 1212], "unpack_du": [924, 925, 928], "dual": [924, 925, 926, 928, 929, 1825, 2134], "make_du": [925, 929, 930, 935, 936], "your_fn": 925, "grad_aft": 925, "dual_level": [928, 929, 930, 935, 936], "apply_jvp": 930, "mark_dirti": [930, 935, 936, 956, 2133], "x_npy": [930, 931, 935], "once_differenti": [930, 931, 932, 933, 934, 935, 936, 2133], "mark_non_differenti": [930, 935, 936, 2133, 2134], "g1": [930, 932, 934, 935, 936, 2130, 2168], "g2": [930, 932, 934, 935, 936, 2130, 2168], "oppos": [930, 933, 935, 936, 1004, 2134], "weren": [930, 933, 935], "grad_out": [930, 933, 935, 936, 2094, 2138, 2199], "gx": [930, 933, 935], "gy": [930, 933, 935], "gz": [930, 933, 935, 2159], "y_t": [930, 935, 936], "fwad": [930, 935, 936], "a_dual": [930, 935, 936], "set_materialize_grad": [930, 935, 936, 2133], "simplefunc": [930, 934, 935, 936], "induc": [930, 934, 935, 936, 1686, 1725, 2124, 2191], "backward_extend": 936, "forward_extend": 936, "outer_jacobian_strategi": 938, "disconnect": [938, 939, 940, 941, 942, 943], "cliff": [938, 940, 944], "_debug_only_display_vmap_fallback_warn": [938, 944], "pow_reduc": [938, 939, 942], "2265": 938, "8221": 938, "9456": [938, 972], "2550": 938, "viewbackward": [938, 940, 2136], "pow_adder_reduc": [938, 939, 942], "func_output": [939, 941, 942, 943], "1448": 939, "0239": 939, "6456": 939, "4988": 939, "4310": 939, "sumbackward0": [939, 942, 2133], "3030": 939, "vhp": 939, "batched_grad": 940, "exp_reduc": [940, 941, 943], "4917": 940, "4352": 940, "4369": 940, "3799": 940, "exp_add": 940, "8052": 940, "3963": 940, "3090": 941, "6742": 941, "9114": 941, "2106": 941, "sumbackward1": [941, 943], "squeezebackward1": 941, "adder": [941, 943], "2399": 941, "5005": 941, "0689": 942, "2431": 942, "0989": 942, "4456": 942, "8053": [942, 1923], "7817": 943, "2458": 943, "7830": 943, "7782": 943, "4458": 943, "3962": 943, "3042": [943, 1372], "6354": 943, "1288": [943, 1951, 1987], "0652": 943, "5483": 943, "5035": 943, "2046": [943, 1022, 2133], "1292": 943, "1432": 943, "3059": 943, "3225": 943, "6652": 943, "7753": 943, "0152": 943, "4225": 943, "3340": 943, "only_input": 944, "allow_unus": [944, 2094], "is_grads_batch": 944, "materialize_grad": 944, "require_grad": [944, 2096, 2127], "inferencemod": [945, 2127, 2185], "bump": [945, 956], "_version": [945, 2155], "doubler": [945, 1148, 1825], "is_train": [946, 2180], "gradgradcheck": [948, 949, 2133], "06": [949, 950, 1355, 1360, 1361, 1372, 1373, 1378, 1533, 1589, 1629, 1632, 1683, 1754, 1837, 1858, 1994, 2094, 2178], "raise_except": [949, 950, 2100], "nondet_tol": [949, 950], "check_undefined_grad": [949, 950], "check_grad_dtyp": [949, 950], "check_batched_grad": [949, 950], "check_batched_forward_grad": 949, "check_forward_ad": 949, "check_backward_ad": 949, "fast_mod": [949, 950, 2138], "differenc": [949, 2133], "perturb": [949, 950, 2138], "gen_non_contig_grad_output": 950, "check_fwd_over_rev": 950, "check_rev_over_rev": 950, "noncontigu": [950, 1086, 2178], "inaccuraci": 950, "clonebackward0": 952, "begun": 954, "gi": [954, 955, 2142], "inference_mod": [956, 1586, 1628], "88446": 958, "profilerstep": 958, "optimizer1step": 958, "optimizer2step": 958, "optimizer1": [958, 2126], "current_step": 958, "erase_step_count": 958, "increment_step": 958, "_kineto_step": 958, "init_step_count": 958, "eventlist": [961, 962], "group_by_stack_n": [962, 2159], "roof": 962, "functioneventavg": [962, 964], "node_id": 965, "77": 965, "47": 965, "470u": 965, "73": 965, "465u": 965, "03": [965, 993, 1392, 1949, 1950, 1955], "121": 965, "891u": 965, "324u": 965, "421u": 965, "503u": 965, "234": [965, 2100], "344u": 965, "000u": 965, "profiler_util": [966, 967, 968, 969], "elapsed_u": 966, "mem_record": 968, "in_interv": 968, "start_u": 968, "end_u": 968, "shallow": [969, 1314, 1516, 1580, 1629, 1630, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1848, 1856, 1857, 1858, 1859, 1860, 1877], "default_factori": [969, 2203], "__missing__": 969, "fromkei": [969, 1590], "keyerror": 969, "popitem": [969, 1590, 2155], "lifo": 969, "setdefault": [969, 1590, 2155], "window_length": [971, 980, 1272, 1273, 1334, 2094], "2n": [971, 1946, 2171], "_length": [971, 980, 1272, 1273, 1311, 1499, 1990], "sim": [972, 1594, 1730, 1885, 1905], "pseudorandom": [972, 1466, 1828, 1882, 1885, 1901, 1903, 1905, 1907, 1995], "1737": 972, "0950": [972, 1971], "3609": 972, "7148": 972, "0289": [972, 2021], "2676": 972, "8937": 972, "7202": 972, "2500": [973, 1162, 1164, 1165, 1175, 1180, 1385, 1633, 1899], "7500": [973, 1165, 1175, 1194, 1268, 1370, 1385, 1633, 1899, 1954], "AND": [974, 1232, 1396, 2096, 2127], "OR": [977, 1398, 2096, 2117], "xor": [979, 1399, 2096], "blackman": [980, 1956], "arrang": [981, 2204], "broadcast_tensor": [983, 2094, 2155], "out_int32": [986, 1928, 2094], "opposit": [986, 1165, 1167, 1624, 1994, 2017], "formal": [986, 1928, 2103, 2116, 2136, 2170], "eg": [986, 1921, 1928, 2130, 2203], "from_": [987, 2094], "tensor_a": [988, 1001], "tensor_b": 988, "6580": 989, "0969": [989, 2117], "4614": 989, "1034": [989, 1144], "5790": 989, "1497": 989, "compute_mod": [990, 2199], "use_mm_for_euclid_dist_if_necessari": 990, "distanc": [990, 1311, 1350, 1351, 1378, 1539, 1589, 1629, 1630, 1727, 1755, 1865, 1990, 1994], "infti": [990, 1311, 1366, 1492, 1547, 1548, 1549, 1612, 1727, 1856, 2172], "use_mm_for_euclid_dist": 990, "donot_use_mm_for_euclid_dist": 990, "minkowski": [990, 1727], "ham": [990, 1272, 1727, 1952], "closest": [990, 1727], "xn": [990, 1727], "4821": [990, 993], "059": 990, "0590": 990, "1763": [990, 1911], "4713": [990, 1911], "6986": [990, 1911], "3702": [990, 1911], "1193": [990, 1404], "0959": 990, "7138": 990, "8322": 990, "2830": [990, 2023], "3791": 990, "6341": 991, "4208": 991, "0900": 991, "5826": 991, "clr": [992, 1865], "3375": 992, "9790": 992, "1119": 992, "6577": 992, "5609": [992, 1677], "5095": 992, "2614": 992, "4038": 992, "3378": [992, 2023], "4982": 992, "2457": [992, 1417], "2561": 992, "4684": 992, "7163": 992, "9647": 992, "8917": [992, 1395], "3213": [992, 1391], "2284": [992, 1124], "8615": 992, "2816": 992, "tu": 993, "mt": [993, 1344, 1351, 1353, 1357, 1358, 1359, 1364, 1373, 1892, 1994, 2094, 2103, 2155, 2175, 2177], "4112": 993, "7486": 993, "4551": 993, "3544": 993, "6724": 993, "5528": 993, "0592": [993, 2142], "9371": 993, "5487": 993, "7023": 993, "3842e": [993, 1360], "hermitian": [994, 995, 1023, 1160, 1161, 1163, 1165, 1166, 1167, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1344, 1345, 1350, 1351, 1353, 1357, 1358, 1359, 1369, 1372, 1378, 2094], "9314": 994, "2251": [994, 1036, 1347, 1389], "0889": 994, "4439": 994, "2122": 994, "1412": 994, "6358e": 994, "lh": [995, 1360], "1625": 995, "6097": 995, "8398": 995, "2387": [995, 1023], "3771": [995, 1361], "4173": 995, "1626": [995, 1036, 1347], "6881e": 995, "tensor_split": [996, 1142, 1278, 2046, 2094, 2155, 2175], "min_valu": [997, 1538], "max_valu": [997, 1538, 2094], "_valu": [997, 1484, 1777, 1979, 2133, 2155, 2171], "7120": 997, "1734": [997, 1289], "0478": [997, 2048], "0922": 997, "3333": [997, 1268, 1277, 1633, 1634, 2011], "horizont": [1000, 1278, 1280, 1840, 1841, 1859, 2157, 2195], "hstack": [1000, 2094, 2155, 2171], "with_replac": [1001, 2094], "combinations_with_replac": 1001, "_inputt": 1002, "_rett": 1002, "fullgraph": [1002, 1015, 2117, 2195, 2205], "cache_size_limit": 1002, "list_backend": [1002, 2183, 2190, 2197], "compiler_custom_backend": 1002, "triton": [1002, 2100, 2122, 2134, 2183, 2186, 2189, 2193, 2195, 2197, 2202, 2204, 2205], "_inductor": [1002, 2184, 2185, 2186, 2189, 2195, 2204, 2205], "list_mode_opt": 1002, "epilogue_fus": 1002, "max_autotun": 1002, "fallback_random": [1002, 2195, 2205], "shape_pad": 1002, "graph_diagram": 1002, "pictur": 1002, "list_opt": 1002, "_glibcxx_use_cxx11_abi": 1003, "black": [1004, 2196], "throughout": [1004, 1813, 2117, 2138, 2142, 2161, 2192], "footgun": [1004, 2189, 2194], "bullet": [1004, 2096], "rand_foo": 1007, "compiler_cudagraph_tre": 1007, "external_util": 1009, "stricter": [1010, 1466, 2196], "is_compil": [1010, 2196], "exclude_tag": 1012, "stanc": 1014, "skip_guard_eval_unsaf": 1014, "force_backend": 1014, "force_eag": 1014, "eager_on_recompil": 1014, "fail_on_recompil": 1014, "unsaf": [1014, 1037, 1078, 1386, 1790, 1793, 2094, 2130, 2158], "varieti": [1014, 1222, 2130, 2150, 2167], "original_fn": 1015, "can_constant_fold_through": 1015, "skip_signature_check": 1015, "polyfil": 1015, "_f": [1015, 1360], "indexof": 1015, "xdoctest": [1015, 2150, 2152], "flip": [1020, 1185, 1186, 1382, 2094, 2155, 2157, 2195, 2199], "writeabl": [1020, 1021], "is_conj": [1020, 1916, 2094, 2155], "geq": [1022, 1257, 1346, 1354, 1489, 1490, 1491, 1515, 1566, 1587, 1599, 1669, 1722, 1787, 2124, 2172], "signbit": [1022, 2094, 2155, 2171, 2199], "2557": 1022, "0026": 1022, "5387": 1022, "4740": 1022, "9244": 1022, "7079": 1022, "2778": 1022, "0249": [1022, 1390], "5719": 1022, "0059": 1022, "2600": 1022, "4475": 1022, "9567": [1022, 1350, 1993], "5757": 1022, "1751": 1022, "0742": 1022, "2998": 1022, "1054": 1022, "2373": 1022, "3190": [1022, 2130], "1128": [1022, 1372, 1550], "pearson": 1023, "coeffici": [1023, 1272, 1837, 1838, 1840, 1841, 1842, 1844, 1856, 1860, 1951, 1952, 1953, 1974, 2020], "r_": [1023, 1838, 2013], "ij": [1023, 1144, 1394, 1402, 1416, 1583, 1970], "c_": [1023, 1507, 1508, 1509, 1510, 1511, 1512, 1550, 1592, 1593, 1838], "jj": 1023, "cov": [1023, 2094, 2155], "2678": [1023, 1522], "0908": 1023, "3766": 1023, "2780": 1023, "5812": 1023, "1535": [1023, 1522], "2350": 1023, "3582": 1023, "4309": 1024, "2706": 1024, "8562": 1024, "9796": [1024, 1360], "1395": 1024, "2957": 1024, "6553": 1024, "5574": 1024, "1632": 1025, "1835": 1025, "6979": 1025, "7325": [1025, 1134], "0133": 1025, "7860": 1025, "2536": 1025, "2805": 1025, "sleef": [1025, 1960], "y_": [1027, 1154, 1388, 1389, 1391, 1493, 1515, 1545, 1970, 2018, 2127, 2172], "_w": [1027, 1527], "w_i": 1027, "mu_x": 1027, "mu_i": [1027, 1844], "w_ia_i": 1027, "w_ix_": 1027, "mathbb": [1027, 1268, 1344, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1360, 1361, 1364, 1366, 1373, 1375, 1377, 1378, 1515, 1587, 1787], "bessel": [1027, 1334, 1955, 1988, 1989, 2040, 2041, 2172], "unbias": [1027, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1620, 1988, 1989, 2040, 2041, 2094, 2199], "corrcoef": [1027, 2094, 2155], "6667": [1027, 1277, 1633, 1634, 1913, 1946, 2147], "fw": 1027, "4282": 1027, "0255": [1027, 1131], "4144": [1027, 2130], "4169": 1027, "streamcontext": [1028, 1044, 1444, 2051], "abstractcontextmanag": 1028, "3956": [1036, 1347], "1455": [1036, 1347, 2148], "6895": [1036, 1347], "5849": [1036, 1347], "3599": [1036, 1347], "7180": [1036, 1347], "0521": [1036, 1347], "1339": [1036, 1347], "0225": [1036, 1347, 1360], "0257": [1036, 1347], "4725": [1036, 1347], "1479": [1036, 1347], "7005": [1036, 1347], "9757": [1036, 1347], "3904": [1036, 1347], "3726": [1036, 1347], "1836": [1036, 1347], "9688": [1036, 1347], "7153": [1036, 1347, 2172], "2159": [1036, 1347], "0844": [1036, 1347], "5281": [1036, 1347], "6120": [1036, 1347], "4490": [1036, 1347], "5687": [1036, 1347], "9792": [1036, 1125, 1347], "8304": [1036, 1347], "3037": [1036, 1347, 2142], "5650": [1036, 1347], "2329": [1036, 1347], "9883": [1036, 1347], "0551": [1036, 1347], "capture_begin": [1037, 2130], "capture_error_mod": [1037, 1078], "make_graphed_cal": [1037, 2130], "graph_pool_handl": [1037, 1078, 1089], "other_graph_inst": [1037, 1078, 1089], "cudastreamcapturemod": [1037, 1078], "thread_loc": [1037, 1078], "cudamalloc": [1037, 1078, 1101, 2130, 2207], "capture_end": [1037, 2130], "debug_dump": 1037, "debug_path": 1037, "enable_debug_mod": 1037, "path_to_so_fil": 1038, "alloc_fn_nam": 1038, "free_fn_nam": 1038, "interprocess": 1039, "from_ipc_handl": 1039, "ipc": [1039, 1082], "ipc_handl": 1039, "cudaeventsynchron": 1039, "cudastreamwaitev": [1039, 1040], "stream_ptr": 1040, "cudastream_t": [1040, 2130], "cudastreamsynchron": 1040, "_cuda_cudaalloc": 1041, "snapshot": [1041, 1100, 2096, 2130, 2139, 2151, 2160], "use_count": [1041, 2130], "active_pool": 1042, "_mempool": 1042, "interoper": 1046, "caching_allocator_delet": 1046, "mem_ptr": 1047, "caching_allocator_alloc": 1047, "peer_devic": 1048, "_cudaalloc": 1049, "clock": 1050, "sm": [1050, 2130], "hertz": 1050, "smi": [1050, 1064, 1066, 1097, 1103, 1108, 1121, 1122, 2076, 2130, 2135, 2139], "buffer_s": [1052, 1055], "10485760": [1052, 1055], "chunk_siz": [1056, 1207, 1213, 2045], "_cudart": 1057, "libcudart": 1057, "check_error": [1057, 1345, 1356, 1358, 1363, 1376, 2094], "cuda_profil": 1057, "perform_cuda_operations_with_stream": 1057, "nsy": 1057, "cudaprofilerstart": 1057, "cudaprofilerstop": 1057, "cudart_test": 1057, "cublashandle_t": 1058, "amd": [1064, 2139, 2183, 2202], "unoccupi": [1066, 1426, 2058], "cudamallocasync": [1067, 1101, 2130], "_cudadeviceproperti": 1071, "gencod": 1072, "total_memori": [1073, 1115, 1438], "cuda_graph": 1078, "ordinari": [1080, 1770, 2036, 2126], "code_str": [1086, 1087], "temp": [1086, 2185], "typenam": [1086, 1087], "my_kernel": [1086, 1087], "jitted_fn": [1086, 1087], "create_jit_fn": [1086, 1087], "util_fn": 1086, "gelu": [1086, 1610, 1624, 1626, 1628, 1741, 2094, 2155, 2199], "my_gelu": 1086, "my_lib": [1086, 2100, 2148], "num_output": 1087, "sample_arg": 1089, "num_warmup_it": 1089, "allow_unused_input": 1089, "datadistributedparallel": 1089, "amp": [1089, 2036, 2126, 2160, 2198, 2201, 2205], "manual_seed_al": [1090, 2036, 2071], "occupi": [1092, 1097, 1109, 1423, 1568, 1704, 2073, 2076, 2130, 2139, 2210], "reset_peak_memory_stat": [1092, 1094, 1109, 1110, 2073, 2074], "max_memory_reserv": [1093, 2130, 2139], "cudamemgetinfo": 1095, "memory_reserv": [1098, 2130, 2139], "large_pool": [1101, 2078], "small_pool": [1101, 2078], "allocated_byt": [1101, 2078], "reserved_byt": [1101, 2078], "active_byt": [1101, 2078], "inactive_split": 1101, "inactive_split_byt": 1101, "octob": 1101, "1mb": [1101, 2078, 2207], "num_alloc_retri": 1101, "num_oom": 1101, "num_sync_all_stream": 1101, "synchronize_and_free_ev": 1101, "num_device_alloc": 1101, "cumemmap": 1101, "num_device_fre": 1101, "cumemunmap": 1101, "cudafre": [1101, 2130, 2207], "assist": [1101, 2132, 2177, 2204], "max_split_s": 1101, "oversize_alloc": 1101, "oversize_seg": 1101, "requested_byt": [1101, 2078], "abbrevi": 1102, "percent": [1103, 1122, 2198], "instantan": [1104, 2159], "ascii": [1104, 1107, 1386, 2096, 2159], "sensor": [1108, 1121], "mw": 1108, "milliwatt": 1108, "fermi": 1108, "max_memory_alloc": [1109, 2130, 2139], "max_memory_cach": 1110, "memory_stat": [1111, 2079, 2080, 2081, 2130, 2139], "seed_al": [1112, 2082], "environment": [1114, 2198], "debug_mod": [1119, 1935], "centigrad": 1121, "x_2": [1123, 1124, 1125, 1126, 1382, 1497, 1513, 1514, 1657, 1668], "x_3": [1123, 1124, 1125, 1126, 1382], "3449": 1123, "5447": 1123, "0685": 1123, "5104": [1123, 2130], "1706": 1123, "2259": 1123, "4696": 1123, "3284": 1123, "9946": 1123, "8209": 1123, "6628": 1124, "0975": 1124, "2680": [1124, 2129], "3298": [1124, 1131], "4220": 1124, "3885": 1124, "1762": 1124, "9165": 1124, "6684": [1124, 1291], "6001": 1125, "2069": 1125, "1919": 1125, "6727": [1125, 1138], "0062": 1125, "4126": 1125, "2129": 1125, "4206": 1125, "1968": [1125, 2172], "1241": 1125, "0238": 1125, "0233": [1125, 1900], "0157": 1125, "0158": [1125, 1994], "0065": 1125, "0014": [1125, 2172], "0006": 1125, "46": [1126, 1272, 1951], "49": [1126, 1187, 1370, 2129], "74": 1126, "83": 1126, "trapezoid": [1127, 2019, 2094, 2155], "360": 1128, "2832": 1128, "diagflat": [1131, 2094, 2155], "5950": 1131, "0872": 1131, "4264": 1131, "1064": [1131, 2142], "8795": 1131, "2429": 1131, "1374": 1131, "1029": 1131, "6482": 1131, "6300": 1131, "5410": 1132, "2934": 1132, "1788": [1132, 2172], "5684": 1132, "0845": [1132, 1960, 2142], "3986": 1132, "2956": [1133, 1347], "9068": 1133, "1695": 1133, "2094": [1133, 2130], "3018": 1133, "1516": 1133, "9342": 1133, "0854": 1134, "1431": 1134, "1752": 1134, "8536": 1134, "0905": 1134, "0360": [1134, 1465], "6927": 1134, "3735": 1134, "4945": 1134, "2631": [1134, 1441, 2130], "3755": 1134, "5977": [1134, 2133], "8172": 1134, "1065": [1134, 2142], "0401": 1134, "2235": [1134, 1993], "7938": 1134, "3081": 1134, "6166": 1134, "2335": 1134, "0500": [1134, 2147], "7336": 1134, "3836": 1134, "1015": 1134, "5393": 1138, "8675": 1138, "5916": 1138, "6321": 1138, "0967": 1138, "0511": 1138, "6295": 1138, "8360": 1138, "6973": 1138, "6537": 1138, "dividend": [1139, 1189, 1192, 1912, 2025], "true_divid": [1139, 2094, 2155], "3810": [1139, 1276], "2774": 1139, "2972": 1139, "3719": 1139, "4637": [1139, 2133], "7620": 1139, "5548": 1139, "5944": 1139, "7438": 1139, "9274": 1139, "3711": 1139, "9353": 1139, "4605": 1139, "2917": 1139, "1815": [1139, 1395], "0111": [1139, 1949], "9805": 1139, "5923": 1139, "1062": 1139, "4581": [1139, 1354], "7759": 1139, "2344": 1139, "1830": 1139, "0313": 1139, "1908": 1139, "4757": 1139, "8032": 1139, "2930": 1139, "8113": 1139, "2308": 1139, "4620": [1139, 2048], "6051": 1139, "5676": 1139, "2639": 1139, "2260": 1139, "4509": [1139, 1368], "2086": 1139, "1322": 1139, "9764": 1139, "9564": 1139, "3484": [1139, 2117], "2278": 1139, "1068": [1139, 1289], "4678": 1139, "3938": [1139, 2006], "depthwis": [1142, 1143, 1507, 1508, 1509], "atleast_3d": [1143, 2094, 2155], "notat": [1144, 1545, 1940, 2097, 2142, 2177], "einstein": 1144, "summat": [1144, 1311, 1394, 1402, 2171], "subscript": [1144, 2097, 2144], "jk": [1144, 2198], "ik": [1144, 1387, 1394, 1970], "za": 1144, "alphabet": [1144, 1670, 2166], "arrow": [1144, 2168], "ki": 1144, "ellipsi": [1144, 2096, 2097, 2116], "fourth": 1144, "whitespac": [1144, 2097], "enrol": 1144, "opt_einsum": 1144, "disclaim": 1144, "sublist": [1144, 2205], "52": 1144, "op1": [1144, 2096], "sublist1": 1144, "op2": [1144, 2096], "sublist2": 1144, "subslist_out": 1144, "7952": 1144, "2433": 1144, "4545": 1144, "1156": 1144, "2897": [1144, 2142], "3918": 1144, "4963": 1144, "3744": 1144, "9381": 1144, "2685": 1144, "6070": 1144, "7208": 1144, "8058": 1144, "4419": 1144, "0936": 1144, "1713": 1144, "4291": 1144, "5802": 1144, "7350": [1144, 2172], "5704": 1144, "4290": 1144, "9323": 1144, "4480": 1144, "bij": 1144, "bjk": 1144, "bik": 1144, "0564": 1144, "5904": 1144, "2023": [1144, 2186], "1271": 1144, "6706": [1144, 1893], "8097": 1144, "8025": 1144, "1183": 1144, "2239": [1144, 1374], "3107": 1144, "5756": 1144, "2354": 1144, "4558": 1144, "3460": 1144, "5087": 1144, "8530": [1144, 1504, 1636], "8153": 1144, "8787": 1144, "3839": [1144, 2044], "2112": [1144, 2021], "3728": 1144, "1131": [1144, 1890], "0921": 1144, "8305": 1144, "ji": 1144, "anm": 1144, "bm": 1144, "ba": 1144, "3430": [1144, 1395], "2405": 1144, "4494": 1144, "3311": 1144, "5201": 1144, "0356": 1144, "4064e": 1145, "8000e": 1145, "3493e": 1145, "5751e": 1145, "1428e": 1145, "5955e": 1145, "9683e": 1147, "1239e": 1147, "0705e": 1147, "orig_func": [1148, 1825], "set_grad_en": [1148, 2094, 2155, 2180], "tripler": [1148, 1825], "elsewher": [1149, 1157, 1257, 1271, 1304, 1306, 1307, 1310, 1339, 1403, 1477, 1971, 2091], "_max": [1158, 1159, 2161], "_min": [1158, 1159, 2161], "nearbi": [1158, 1159], "_int": [1158, 1159], "_point": [1158, 1159], "2525": 1158, "0466": 1158, "3491": [1158, 1368], "2168": [1158, 2013], "5906": [1158, 2172], "6258": 1158, "6444": 1158, "0542": 1158, "0475": [1158, 2172], "0486": 1158, "3405": 1158, "6134": [1158, 1417], "6323": 1158, "0552": 1159, "9730": 1159, "3973": 1159, "0780": 1159, "4000": [1159, 1162, 1171, 1180, 1633, 1896, 1946], "fourier": [1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1311, 1956, 1990], "rfft": [1160, 1165, 1175, 1179, 1180, 1181], "chalf": [1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1175, 1176, 1177, 2094, 2155, 2177], "sm53": [1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181], "ortho": [1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1387], "orthonorm": [1160, 1161, 1163, 1165, 1166, 1167, 1168, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1181, 1378, 1787, 1994], "ifft": [1160, 1164, 1165, 1169, 1170, 1172, 1173, 1174, 1175, 1176, 1177], "fftn": [1161, 1164, 1170, 1173, 1181], "rfft2": [1161, 1176], "ifft2": [1161, 1173], "two_fft": [1161, 1163, 1173, 1179, 1181], "check_strid": [1161, 1163, 1164, 1169, 1170, 1175, 1176, 1177, 1179, 1181, 2178], "nyquist": [1162, 1164, 1172, 1174, 1178, 1179, 1180, 1181], "i_1": [1163, 1181, 1335], "i_n": [1163, 1181, 1213, 1335, 2013, 2045], "rfftn": [1163, 1167, 1173, 1177, 1179], "ifftn": [1163, 1169, 1174], "reorder": [1164, 1370, 2136, 2204], "rearrang": [1164, 1171, 1500, 1592, 1593, 1728, 1729, 2116], "fftfreq": [1164, 1171, 1180], "9000": [1164, 2011], "8000": [1164, 1471, 1633, 1893, 1946], "uncent": 1164, "ifftshift": 1164, "x_center": 1164, "x_uncent": 1164, "fft_uncent": 1164, "fft_center": 1164, "x_centered_2": 1164, "ihfft": [1165, 1173, 1174], "irfft": [1165, 1177, 1178], "symmetri": [1165, 1167, 1990], "transformed_dim_s": [1165, 1175], "0000j": [1165, 1172, 1175, 1344, 1345, 1350, 1351, 1353, 1886, 1943], "1250": [1165, 1441], "1720j": 1165, "0406j": 1165, "2809": 1165, "6250": [1165, 1175, 1194, 1633], "9691": 1165, "hfftn": [1166, 1174], "last_dim_s": [1166, 1167, 1176, 1177, 2199], "ihfft2": 1166, "roundtrip": [1166, 1167, 1175, 1176, 1177], "ihfftn": [1167, 1173], "irfftn": [1167, 1176, 1181], "fft2": [1169, 1179], "two_ifft": [1169, 1170, 1174], "fftshift": 1171, "hfft": 1172, "6882j": 1172, "1625j": 1172, "hfft2": 1173, "8602j": 1175, "2031j": 1175, "1562": 1175, "3511": 1175, "7812": 1175, "2114": 1175, "irfft2": 1179, "wider": [1187, 1877, 2093, 2096, 2157, 2171], "2500e": 1187, "1000e": 1187, "7656e": 1187, "lfloor": [1188, 1193, 1484, 1489, 1490, 1491, 1507, 1508, 1509, 1526, 1547, 1548, 1549, 1573, 1574, 1575, 1632, 1633, 1634, 1635, 1655, 1725, 1908, 1990], "rfloor": [1188, 1193, 1484, 1489, 1490, 1491, 1507, 1508, 1509, 1526, 1547, 1548, 1549, 1573, 1574, 1575, 1632, 1633, 1634, 1635, 1655, 1725, 1908, 1990], "8166": 1188, "5308": 1188, "2530": 1188, "2091": 1188, "7000": [1190, 1523, 1945], "3000": [1191, 1522, 1945, 2130], "entrywis": [1192, 1912], "modulu": [1192, 1374, 1912], "operatornam": [1193, 1350, 1351, 1352, 1353, 1370, 1378, 1492, 1493, 1499, 1539, 1540, 1546, 1571, 1612, 1630, 1882, 1905, 1945, 1995], "8750": [1194, 1633], "sizeof": [1196, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2173], "map_shar": [1196, 2147, 2173], "map_priv": [1196, 2147, 2173], "mmap": [1196, 1386, 2114, 2147, 2173], "tofil": 1196, "t_map": 1196, "char": [1198, 1833, 2115, 2141, 2173, 2195], "parameter_and_buffer_dict": 1201, "tie_weight": [1201, 1822], "submodule_nam": [1201, 1822], "parameter_nam": [1201, 1822], "ty": [1201, 1822, 2209], "foo_ti": [1201, 1822], "new_a": [1201, 1822], "grad_weight": [1201, 2133], "detached_param": 1201, "parameters_and_buffer_dict": 1201, "intermediate_upd": 1202, "mutations_and_view": 1202, "proxy_tensor": [1202, 2100, 2205], "make_fx": [1202, 1218, 2100, 2191, 2205], "inpt": 1202, "f_trace": 1202, "f_no_mutations_trac": 1202, "f_no_mutations_and_views_trac": 1202, "a_1": [1202, 1335], "view_1": 1202, "view_copi": [1202, 2094, 2155, 2180], "view_copy_1": 1202, "as_strid": [1202, 2094, 2155, 2175, 2199], "aux": [1203, 1204, 1206, 1207, 1208, 1212], "my_loss_func": 1203, "y_pred": [1203, 2130], "loss_per_sampl": 1203, "y_true": 1203, "autodiff": [1206, 1207, 1208, 1373], "jacobian_f": [1206, 1207], "f_x": [1206, 1207], "jacboian": [1206, 1207], "expectedx": [1206, 1207], "expectedi": [1206, 1207], "_preallocate_and_copi": 1207, "jvp_out": 1208, "wish": [1208, 1877, 1985, 2100, 2126, 2130, 2133, 2134], "jvp_fn": 1209, "optimiz": [1211, 2093], "l1": [1211, 1539, 1540, 1612, 1695, 1742, 1798, 1806, 2142, 2147], "l2": [1211, 1540, 1571, 1612, 1695, 1836, 1837, 1839, 1840, 1842, 1844, 1856, 1857, 1859, 2126], "vjpfunc": 1212, "unsuccessfulli": [1213, 2045], "rummag": [1213, 2045], "batched_dot": [1213, 2045], "jacobian_row": [1213, 2045], "get_vjp": [1213, 2045], "n1": [1213, 1914, 2045], "n0": [1213, 2045], "batched_pow": [1213, 2045], "autobatch": [1213, 2045], "proxytorchdispatchmod": 1214, "decomposition_t": 1216, "tracing_mod": [1216, 2100], "_allow_non_fake_input": 1216, "pre_dispatch": 1216, "record_module_stack": 1216, "_allow_fake_const": 1216, "_error_on_data_dependent_op": 1216, "thunkif": 1217, "maybe_enable_thunkifi": 1217, "thunkifi": 1218, "thunk": 1218, "buggi": [1218, 1697], "symbolic_shap": [1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 2191], "symbol_to_sourc": 1221, "var_to_v": 1221, "marked_dynam": 1221, "source_name_to_debug_nam": 1221, "solver": [1221, 2145], "expr": [1221, 1228, 1235, 1242, 1999], "tautologi": 1221, "add_equ": 1221, "forced_speci": 1221, "prettify_result": 1221, "original_signatur": 1221, "constraint_violation_error": 1221, "erro": 1221, "rewrite_with_congru": 1221, "congruenc": 1221, "ration": 1221, "inequ": [1221, 1235], "_sympyt": [1221, 1228], "duck": [1222, 1228, 2133, 2158], "nb": [1222, 1232, 1235, 1237, 1239, 1328, 2100, 2117], "simplic": [1222, 1793, 2122, 2166, 2167], "assume_static_by_default": [1222, 1229], "mark_dynamic_dim": 1222, "warn_onli": [1224, 1227, 1232, 2033], "source_pair": 1224, "derived_equ": 1224, "phantom_symbol": 1224, "relaxed_sourc": 1224, "forest": 1224, "transit": [1224, 1314, 1416, 1580, 1877, 1990, 2093, 2183], "phantom": 1224, "inner_nam": 1225, "unback": [1226, 1228, 1237, 1238, 1240, 1241, 1251, 2189, 2194], "unspeci": 1227, "unspec": 1227, "brittl": 1227, "strictminmaxconstraint": 1227, "unbound": [1227, 1232, 1238], "valuerang": [1227, 1228], "should_record_ev": 1228, "tracked_fak": 1228, "add_var_to_v": 1228, "bind_symbol": 1228, "littl": [1228, 2133, 2147, 2168, 2204], "evaluate_guard": 1228, "cleanest": 1228, "shenanigan": 1228, "bound_sympi": 1228, "size_oblivi": 1228, "check_equ": 1228, "create_symbol": [1228, 2204], "dynamic_dim": 1228, "dimdynam": [1228, 1231], "constraint_dim": 1228, "do_not_specialize_zero_on": 1228, "symbolic_context": [1228, 1230, 1231], "create_symbolic_sizes_strides_storage_offset": [1228, 1230, 1231, 1234], "create_symboolnod": 1228, "create_symfloatnod": 1228, "create_symintnod": 1228, "create_unbacked_symbool": 1228, "create_unbacked_symfloat": 1228, "create_unbacked_symint": 1228, "create_unspecified_symbol": 1228, "specialz": 1228, "create_unspecified_symint_and_symbol": 1228, "defer_runtime_assert": 1228, "orig_expr": 1228, "fx_node": 1228, "deserialize_symexpr": 1228, "compile_fx": [1228, 2205], "symexpr": 1228, "evaluate_guards_express": 1228, "produce_guards_express": 1228, "evaluate_guards_for_arg": 1228, "ignore_stat": 1228, "evaluate_symexpr": 1228, "format_guard": 1228, "freeze_runtime_assert": 1228, "discharg": [1228, 1238], "get_axiom": 1228, "compute_hint": 1228, "get_impl": 1228, "booleanatom": 1228, "get_nontrivial_guard": 1228, "get_pruned_guard": 1228, "prune": [1228, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 2118, 2171], "shapeguard": 1228, "ignore_fresh_unbacked_symbol": 1228, "is_unbacked_symint": 1228, "produce_guard": [1228, 2204], "produce_guards_verbos": 1228, "source_ref": 1228, "input_context": 1228, "equalities_input": 1228, "_simplifi": 1228, "localsourc": [1228, 2192], "boilerpl": [1228, 2142, 2158], "nice": [1228, 1507, 1508, 1509, 1510, 1511, 1512, 1526, 1573, 1574, 1575, 1632, 2116, 2127, 2130, 2158, 2192], "set_unbacked_var_to_v": 1228, "propagate_real_tensor": [1228, 1237], "resort": [1228, 2130, 2138, 2158], "size_hint": [1228, 2197], "allow_non": 1228, "suppress_guard": 1228, "_generatorcontextmanag": 1228, "allow_scalar_output": 1229, "allow_dynamic_output_shape_op": 1229, "specialize_zero_on": 1229, "duck_shap": 1229, "prefer_deferred_runtime_asserts_over_guard": 1229, "allow_complex_guards_as_runtime_assert": 1229, "dynamic_s": [1230, 1231, 1233], "dynamic_strid": [1230, 1231, 1233], "constraint_s": [1230, 1231, 1233], "constraint_strid": [1230, 1231, 1233], "view_base_context": [1230, 1231, 1233], "tensor_sourc": [1230, 1233], "shape_env_to_source_to_symbol_cach": [1230, 1233], "statelesssymboliccontext": 1230, "owner": [1230, 2091, 2133, 2155, 2166, 2167], "lifecycl": [1230, 2194], "shape_env": [1230, 1237, 1251, 1252], "dimconstraint": 1231, "relaxedunspecconstraint": 1232, "unsoundli": [1232, 1238], "inner_context": 1233, "canonic": 1235, "rh": [1235, 1360, 1405], "Ors": 1235, "cnf": 1235, "subexpr": 1235, "25924": 1235, "retrac": [1236, 1251, 1322, 2192], "example_valu": 1237, "old_example_valu": 1237, "peek": [1237, 2100], "freshli": 1237, "unbacked_var_to_v": 1237, "keyentri": [1237, 1252], "lie": [1238, 1614, 1616, 1744, 1972, 2172, 2176, 2194], "intersect": [1238, 2122], "fairli": [1238, 2144, 2191, 2195, 2197], "perfectli": [1238, 1936, 2130, 2204], "definitely_tru": 1240, "circuit": 1241, "oblivi": 1242, "118579": 1242, "free_symbol": 1243, "free_unbacked_symbol": 1244, "maxsiz": 1250, "_lru_cache_wrapp": 1250, "sym_and": 1254, "sparse_grad": [1255, 2094, 2199], "tau": [1258, 1354, 1688, 1838, 1839, 1859, 1879, 1880, 1949, 2094], "elementari": [1258, 2127, 2138], "reflector": [1258, 1787, 1880], "household": [1258, 1354, 1787, 1880], "householder_product": [1258, 1787, 1879], "lstsq": [1258, 1346, 1372], "gel": [1258, 1360], "set_deterministic_debug_mod": [1262, 2033], "fork_rng": [1267, 2165], "edge_ord": [1268, 2094], "rightarrow": 1268, "closer": [1268, 1630, 1893, 2133, 2142, 2161, 2189, 2197, 2198], "interior": 1268, "theorem": 1268, "h_l": 1268, "h_r": 1268, "neighbor": [1268, 1311, 1633, 1635, 1990], "xi_1": 1268, "xi_2": 1268, "approx": [1268, 1882, 1995, 2138], "80": [1268, 1370, 1870, 1940, 2130, 2157], "halv": 1268, "coord": 1268, "54": [1272, 1541, 1952], "hann_window": [1272, 1990, 2094, 2098, 2155], "hann": [1273, 1952], "hist": [1276, 1277, 2094], "bin_edg": [1276, 1277, 2094], "9524": 1276, "leftmost": [1277, 2117], "leg": 1281, "triangl": [1281, 2176], "hypotenus": 1281, "4031": 1281, "gammainc": [1283, 2172], "gammaincc": [1284, 2172], "_complex": 1286, "index_reduce_": [1288, 2094], "1427": 1289, "0231": 1289, "5414": 1289, "0009": 1289, "4664": [1289, 2013], "2647": 1289, "1228": 1289, "6571": 1289, "7230": 1289, "6004": 1289, "multidimension": [1291, 1384, 1542], "8173": 1291, "0874": 1291, "1784": 1291, "3279": 1291, "7894": 1291, "4682": 1291, "7159": 1291, "1506": 1291, "4034": 1291, "3657": [1291, 2147], "0387": 1291, "9892": 1291, "1774": 1291, "3261": 1291, "3917": 1291, "4537": [1291, 1760], "7493": 1291, "1724": 1291, "2291": 1291, "5749": 1291, "2267": 1291, "7920": 1291, "3607": 1291, "3701": 1291, "3666": 1291, "5850": [1291, 1345], "7242": 1291, "9837": 1291, "1560": 1291, "2907": 1291, "6785": 1291, "5671": [1291, 1346], "5452": 1291, "6912": 1291, "5509": 1291, "1782": 1291, "9843": 1291, "7366": 1291, "5672": [1291, 1828], "5115": 1291, "4864": 1291, "2476": 1291, "4337": 1291, "6347": 1291, "1748": 1291, "3567": [1291, 1345], "6558": 1291, "2469": [1291, 2142], "5787": [1291, 1395], "typing_extens": [1300, 1301, 2095], "typei": [1300, 1301], "typecheck": [1301, 2155], "warn_alwai": 1302, "set_warn_alwai": 1302, "nonfinit": 1303, "test_el": [1305, 2094], "assume_uniqu": [1305, 2094], "0j": [1310, 2042], "nola": 1311, "envelop": 1311, "hop": [1311, 1990], "shorter": [1311, 2154, 2166], "griffin": 1311, "ieee": [1311, 1533, 1956, 2145], "tran": 1311, "assp": 1311, "vol": [1311, 1533, 1956], "236": 1311, "apr": 1311, "1984": 1311, "slide": [1311, 1489, 1490, 1491, 1526, 1573, 1574, 1575, 1632, 1680, 1711, 1712, 1713, 1756, 1897, 1898, 1990], "fft_size": 1311, "scriptmodul": [1312, 1313, 1318, 1322, 1324, 1325, 1326, 1330, 1331, 1835, 2093, 2095, 2106, 2150, 2154, 2156], "attributemodul": 1312, "names_ag": 1312, "get_debug_st": 1313, "graphexecutorst": 1313, "_extra_fil": [1313, 1314, 1322, 1325, 2140], "save_to_buff": 1313, "add_modul": [1314, 1580, 1877], "init_weight": [1314, 1580, 1877, 2142], "buf": [1314, 1580, 1877], "20l": [1314, 1580, 1877], "1l": [1314, 1580, 1877], "5l": [1314, 1580, 1877], "syntax": [1314, 2093, 2096, 2158, 2186, 2196], "code_with_const": 1314, "constmap": 1314, "get_buff": [1314, 1580, 1877], "attributeerror": [1314, 1580, 1877, 2133, 2161], "get_extra_st": [1314, 1580, 1877], "set_extra_st": [1314, 1580, 1877], "get_paramet": [1314, 1580, 1877], "net_b": [1314, 1580, 1877], "net_c": [1314, 1580, 1877], "inlined_graph": 1314, "ipu": [1314, 1580, 1877, 2100, 2147], "remove_dupl": [1314, 1580, 1877], "named_children": [1314, 1580, 1877, 2142], "conv4": [1314, 1580, 1877], "conv5": [1314, 1580, 1877], "memo": [1314, 1580, 1877, 2194], "register_backward_hook": [1314, 1580, 1877], "register_full_backward_hook": [1314, 1580, 1765, 1877, 2142], "register_forward_hook": [1314, 1580, 1763, 1877, 2142], "with_kwarg": [1314, 1580, 1763, 1877], "always_cal": [1314, 1580, 1763, 1877], "fire": [1314, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860, 1877, 2132, 2140, 2200], "register_module_forward_hook": [1314, 1580, 1877, 2142], "register_forward_pre_hook": [1314, 1516, 1580, 1764, 1877, 2142], "forward_pr": [1314, 1580, 1877], "register_module_forward_pre_hook": [1314, 1580, 1877, 2142], "register_module_full_backward_hook": [1314, 1580, 1761, 1877, 2127, 2142], "register_full_backward_pre_hook": [1314, 1580, 1766, 1877, 2142], "register_module_full_backward_pre_hook": [1314, 1580, 1877, 2142], "register_load_state_dict_post_hook": [1314, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 1877], "incompatible_kei": [1314, 1580, 1877], "register_load_state_dict_pre_hook": [1314, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1846, 1856, 1857, 1858, 1859, 1860, 1877, 2157], "local_metadata": [1314, 1580, 1877], "error_msg": [1314, 1580, 1877, 2204], "noqa": [1314, 1580, 1877], "b950": [1314, 1580, 1877], "register_modul": [1314, 1580, 1767, 1877], "register_paramet": [1314, 1580, 1768, 1877, 2133, 2142], "register_state_dict_post_hook": [1314, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 1877], "register_state_dict_pre_hook": [1314, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860, 1877], "keep_var": [1314, 1580, 1877], "gan": [1314, 1580, 1788, 1821, 1877], "set_submodul": [1314, 1580, 1877], "overid": [1314, 1580, 1877], "share_memori": [1314, 1580, 1877, 2144], "share_memory_": [1314, 1580, 1877, 2114, 2173], "4d": [1314, 1495, 1526, 1543, 1580, 1633, 1680, 1697, 1725, 1757, 1779, 1780, 1877, 1896], "1913": [1314, 1580, 1877], "3420": [1314, 1580, 1877], "5113": [1314, 1580, 1877, 2013], "2325": [1314, 1347, 1580, 1877], "gpu1": [1314, 1580, 1877], "1914": [1314, 1580, 1877], "5112": [1314, 1580, 1877, 2130], "3741": [1314, 1580, 1877], "2382": [1314, 1465, 1580, 1877], "5593": [1314, 1580, 1877], "4443": [1314, 1580, 1877], "6122": [1314, 1580, 1877], "1150": [1314, 1580, 1877], "dst_type": [1314, 1580, 1877], "set_to_non": [1314, 1580, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1855, 1856, 1857, 1858, 1859, 1860, 1877, 2130], "the_typ": 1315, "the_valu": 1315, "script_bar": 1317, "addmod": 1317, "preserved_attr": 1318, "optimize_numer": 1318, "optimize_for_infer": [1318, 2190], "run_frozen_optim": 1318, "scripted_modul": [1318, 1326, 2147], "frozen_modul": 1318, "modified_tensor": 1318, "mymodule2": 1318, "dump_alias_db": 1318, "training_method": 1319, "testcod": [1320, 1321, 1322, 1325, 2095], "interfacetyp": 1320, "impl1": 1320, "impl2": 1320, "user_fn": 1320, "user_fn_jit": 1320, "target_typ": 1321, "key1": 1321, "val1": 1321, "key2": 1321, "val2": 1321, "_restore_shap": 1322, "scriptfunct": [1322, 1326, 1327, 1330, 2150, 2154], "readlin": [1322, 1386, 2158], "other_method": 1324, "lesser": [1324, 2127, 2129], "extent": [1324, 2129, 2171], "frozen_mod": 1324, "_frames_up": 1326, "_rcb": 1326, "scriptdict": 1326, "scriptlist": 1326, "test_sum": 1326, "scripted_fn": [1326, 2093], "conv2": [1326, 1580, 1609, 2093, 2161], "some_entry_point": 1326, "python_only_fn": 1326, "testnnmodul": 1326, "pdt_model": 1326, "scripted_model": [1326, 2158], "un": [1328, 1499, 2161], "unfus": 1328, "check_trac": [1330, 1331], "check_input": [1330, 1331, 2093], "check_toler": [1330, 1331], "_force_outplac": [1330, 1331], "_module_class": [1330, 1331], "_compilation_unit": [1330, 1331], "compilationunit": [1330, 1331], "example_kwarg_input": 1330, "_store_input": [1330, 1331], "trace_modul": [1330, 2093, 2096], "untrack": 1330, "checker": [1330, 1331, 2096, 2154], "traced_foo": [1330, 2093], "example_weight": [1330, 1331], "example_forward_input": [1330, 1331], "example_inputs_is_kwarg": 1331, "method2": 1331, "example_method2_input": 1331, "weighted_kernel_sum": 1331, "use_memory_effici": 1332, "memory_effici": 1332, "scriptabl": 1332, "kaiser": [1334, 1624, 1626, 1628], "i_0": [1334, 1335, 1955, 2013, 2172], "zeroth": [1334, 1955, 2172], "out_i": 1334, "kroneck": 1335, "a_0": 1335, "a_n": 1335, "b_0": 1335, "b_1": 1335, "b_n": 1335, "k_0": [1335, 2013], "k_1": 1335, "k_n": 1335, "j_0": 1335, "j_1": 1335, "j_n": 1335, "k_t": 1335, "i_t": [1335, 1550, 1858], "b_t": 1335, "j_t": 1335, "bmatrix": 1335, "a_": [1335, 1406, 1568, 2013], "cdot": [1335, 1360, 1372, 1492, 1493, 1514, 1515, 1537, 1545, 1583, 1584, 1585, 1586, 1587, 1624, 1668, 1691, 1838, 1886, 1990, 2172, 2178], "vdot": [1335, 1382, 1383, 2094, 2155], "ddot": [1335, 1382], "kth": 1336, "full_lik": [1340, 2094, 2098, 2100, 2155, 2199], "logarithm": [1343, 1348, 1374, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1401, 1499, 1670, 1705, 1969, 2172], "gamma": [1343, 1494, 1495, 1496, 1534, 1542, 1543, 1544, 1552, 1620, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1859, 1861, 1865, 1866, 1870, 1875, 1876, 1896, 2094, 2154, 2155, 2157, 2172], "5724": [1343, 2172], "1208": [1343, 2172], "mathrlap": [1344, 1350, 1351, 1352, 1353, 1361, 1364, 1373, 1375, 1377, 1378, 1787], "qquad": [1344, 1346, 1350, 1351, 1352, 1353, 1354, 1361, 1364, 1373, 1375, 1377, 1378, 1787], "eigenvalu": [1344, 1350, 1351, 1352, 1353, 1366, 1369, 1372, 1377, 1378, 1387, 1882, 2094], "resp": [1344, 1351, 1353, 1377, 1378, 1395], "5266": 1344, "9586": 1344, "0626j": 1344, "4160": 1344, "5895": 1344, "2322": 1344, "2976j": 1344, "4928": [1344, 2013], "4692e": 1344, "8747e": 1344, "performantli": 1345, "3792": 1345, "9831j": 1345, "8757": 1345, "5425": 1345, "6374j": 1345, "kappa": 1346, "_p": [1346, 1589], "frobeniu": [1346, 1360, 1367, 1371, 1827], "nuc": [1346, 1367, 1371, 1384, 1799, 1807, 1827], "nuclear": [1346, 1367, 1371, 1827], "sigma_1": [1346, 1360, 1369, 1372], "sigma_n": 1346, "kappa_2": 1346, "kappa_": 1346, "4142": [1346, 1371, 1827, 1886], "1623": [1346, 1367], "2426": [1346, 1371, 1827], "7071": [1346, 1948], "5917": 1346, "9941": 1347, "5132": 1347, "5681": 1347, "4653": 1347, "4507": 1347, "4119": 1347, "6163": 1347, "1073": 1347, "3957": 1347, "9666": [1347, 1677], "0840": 1347, "3357": 1347, "2139": 1347, "slogdet": [1348, 1395, 2094, 2155], "0934": 1348, "1990": [1348, 1395], "4099": [1348, 1395], "7386": [1348, 1395], "diagonaliz": [1350, 1352], "eigenvector": [1350, 1351, 1387, 2094], "neq": [1350, 1351, 1354, 1378, 1477, 1583, 1585, 1837, 1839, 1840, 1842, 1844, 1856, 1857, 1859, 1863, 1994], "phi": [1350, 1351, 1378, 1529, 1684, 1994], "shall": [1350, 1351, 1378, 1790, 1794], "lambda_i": [1350, 1351, 1366], "lambda_j": [1350, 1351], "eigval": [1350, 2094], "9828": [1350, 2021, 2142], "3889j": 1350, "4617": 1350, "3010j": 1350, "1662": 1350, "7435j": 1350, "6139": 1350, "0562j": 1350, "1226": [1350, 1352], "5738j": [1350, 1352], "7537": [1350, 1352], "1286j": [1350, 1352], "9218": 1350, "1882": 1350, "2220j": 1350, "0270": 1350, "3867j": 1350, "7119e": 1350, "2841e": 1350, "uplo": [1351, 1353, 2094], "unitari": [1351, 1354, 1373, 1378, 1787, 1880], "ill": [1351, 1651, 2145], "eigvalsh": [1351, 1369], "eig": [1351, 1352, 1378, 2145], "9228": [1351, 1353], "2029": [1351, 1353], "0862j": [1351, 1353], "3464": [1351, 1353], "3277": [1351, 1353], "9415": [1351, 1353], "0846": 1351, "9964": 1351, "9170": 1351, "3898j": 1351, "0331j": 1351, "1062e": 1351, "5423e": 1351, "polynomi": [1352, 1353, 1873, 2195], "_n": [1352, 1353, 1355, 1787, 2133], "4576e": [1352, 1379], "5797": 1353, "4629": 1353, "1605": 1353, "3780": 1353, "1113": [1353, 2142], "7381": 1353, "a_i": [1354, 1629, 1630, 1951], "b_i": 1354, "h_1h_2": 1354, "h_k": 1354, "h_i": [1354, 1615], "_m": [1354, 1787], "tau_i": 1354, "8034": 1354, "4184j": 1354, "2588": 1354, "0174j": 1354, "6853": 1354, "7953j": 1354, "0790": 1354, "5620j": 1354, "6989j": 1354, "5360": 1354, "1193j": 1354, "3877": 1354, "6691j": 1354, "3512": 1354, "3024j": 1354, "4766": 1354, "5783j": 1354, "0361": [1354, 2142], "6587j": 1354, "6396": [1354, 2142], "1612j": 1354, "3693": 1354, "4481j": 1354, "aa": 1355, "pinv": [1355, 1360, 1884], "moor": [1355, 1372], "penros": [1355, 1372], "ainv": [1355, 1356, 1376, 1380], "1921e": 1355, "9073e": [1355, 1632], "5107e": 1355, "ldl": [1357, 1359], "indefinit": [1357, 2105], "ld": [1357, 1358, 1359, 2094], "sytrf": [1357, 1358], "ldl_solv": 1357, "ldl_factor_ex": [1357, 1359], "2079": [1357, 1358, 2172], "2414": [1357, 1358, 2204], "9428": [1357, 1358], "4554": [1357, 1358], "3264": [1357, 1358], "3823": [1357, 1358], "5884": [1357, 1358], "9595": [1357, 1358, 1948], "2695": [1357, 1358], "8513": [1357, 1358], "1633": [1357, 1358], "ldl_factor": 1358, "rcond": [1360, 1372, 1884, 2094], "gelsi": 1360, "gelsd": 1360, "gelss": 1360, "tridiagon": 1360, "sigma_i": [1360, 1378, 1994], "residu": [1360, 1387, 2094, 2142], "singular_valu": [1360, 2094], "0838": [1360, 2142], "2275": [1360, 1441], "3844": 1360, "5499": 1360, "1175": 1360, "9102": 1360, "0870": 1360, "6772": 1360, "7758": 1360, "5109": 1360, "4382": 1360, "3769": 1360, "1818": 1360, "3450": 1360, "0806": [1360, 2142], "3967": 1360, "3994": 1360, "1521": 1360, "1473": 1360, "9194": 1360, "0458": 1360, "6705": [1360, 1419], "1802": 1360, "4086": 1360, "5152e": 1360, "zero_": [1360, 1677, 2094, 2115, 2116, 2142, 2171], "5007": 1361, "9755": 1361, "0489": 1361, "9644": [1361, 1414], "9605e": 1361, "0376e": 1361, "lu_factor_ex": [1362, 1404], "lu_unpack": [1362, 1404, 2094, 2155], "b1": 1362, "b2": [1362, 2130, 2139], "getrf": [1363, 1376], "adjoint": [1364, 2094, 2155, 2175, 2177], "_exp": 1366, "7183": [1366, 2142], "3891": 1366, "8660": 1366, "ord": [1367, 1371, 1384, 1827, 2094, 2096, 2155], "la": [1367, 1371, 1384, 2142], "2829": 1367, "2627": 1367, "0756": 1368, "4980": 1368, "6617": 1368, "4994": 1368, "9980": 1368, "2731": 1368, "8001": 1368, "2640": 1368, "4571": 1368, "5511": 1368, "0163": [1368, 1414], "5292": 1368, "4899": 1368, "0822": 1368, "2773": [1368, 2117], "varepsilon": [1369, 1372, 1629], "tol": [1369, 1387, 2094], "fewest": 1370, "bc": [1370, 2104, 2157], "75000": 1370, "26": [1370, 1864, 2192, 2193, 2205], "148": 1370, "vector_norm": [1371, 1827], "matrix_norm": [1371, 1384, 1788, 1827], "7460": [1371, 1827], "3485": 1371, "8570e": 1371, "8480": 1371, "2361": [1371, 1827, 1828], "7417": [1371, 1827], "computation": [1372, 2138], "5495": [1372, 1441], "0979": 1372, "4092": 1372, "4132": [1372, 1954], "1143": 1372, "3662": 1372, "6374": 1372, "9294": 1372, "3269": [1372, 2142], "5745": [1372, 1988, 1989, 2040, 2041], "0382": [1372, 1465], "5922": 1372, "6759": 1372, "0600": 1372, "1933": 1372, "2090": 1372, "0903": 1372, "0817": 1372, "4752": [1372, 1993], "7124": 1372, "1631": 1372, "2272": 1372, "1356": 1372, "3933": 1372, "5023": 1372, "0308": 1372, "1725": 1372, "5216": 1372, "apinv": 1372, "5633e": 1372, "0830e": 1372, "wide": [1373, 1378, 1787, 1950, 2111, 2117, 2129, 2133, 2142, 2157, 2195], "51": [1373, 1578, 1892], "167": [1373, 1892], "68": [1373, 1892, 2093, 2095], "8571": [1373, 1892], "3943": [1373, 1892], "3314": [1373, 1892], "4286": [1373, 1892], "9029": [1373, 1892], "0343": [1373, 1892], "2857": [1373, 1892], "1714": [1373, 1892, 2142], "9429": [1373, 1892], "175": [1373, 1892], "q2": 1373, "r2": [1373, 1620], "6099e": 1373, "2158e": 1373, "logabsdet": [1374, 2094], "0032": 1374, "6690": 1374, "1161": 1374, "4053": 1374, "6218": [1374, 2010], "9273": 1374, "0082": 1374, "7576": 1374, "logdet": [1374, 2094, 2155], "linalg_slogdet": [1374, 2094, 2155], "2776": 1374, "sparse_csr_tensor": [1375, 1968, 2094, 2155, 2171], "solve_ex": 1375, "solve_triangular": [1375, 2020], "expand_a": [1375, 2094, 2133, 2155, 2175], "rectangular": [1377, 1378, 1406, 1990, 2124], "triu_": [1377, 2094], "tril_": [1377, 2094], "full_matric": [1378, 1379, 1793, 1994, 2094, 2199], "vh": [1378, 1793, 1994, 2094, 2199], "gesvdj": [1378, 1379, 1994], "jacobi": 1378, "gesvda": [1378, 1379], "gesvd": [1378, 1379, 1994], "u_k": 1378, "v_k": 1378, "sigma_j": [1378, 1994], "eigendecomposit": 1378, "0486e": 1378, "0957e": 1378, "5139": 1379, "1087": 1379, "1066": 1379, "ind": [1380, 1381, 2094, 2134], "tensorsolv": 1380, "atensorinv": 1380, "movedim": [1381, 1421, 2094, 2100, 2134, 2155, 2175], "tensorinv": 1381, "vandermond": [1382, 2039], "pmatrix": 1382, "x_n": [1382, 1492, 1493, 1539, 1540, 1546, 1571, 1612, 2018, 2127], "125": [1382, 1599, 2039, 2094], "overlin": [1383, 2042], "3223": 1383, "2815": 1383, "1944": [1383, 2142], "4345": 1384, "pickle_modul": [1386, 1924, 2147], "pickle_load_arg": 1386, "register_packag": [1386, 2147], "binaryio": [1386, 1924, 2147, 2158], "add_safe_glob": [1386, 2147], "mmape": 1386, "untrust": [1386, 2091, 2107, 2158], "tamper": [1386, 2158], "surg": 1386, "unicodedecodeerror": 1386, "codec": 1386, "0x": 1386, "latin1": 1386, "byte_arrai": 1386, "niter": [1387, 1882, 1995], "ortho_iparam": 1387, "ortho_fparam": 1387, "ortho_bparam": 1387, "knyazev": 1387, "knyazev2001": 1387, "stathopoulosetal2002": 1387, "precondition": 1387, "eigenpair": 1387, "criterion": [1387, 1492, 1493, 1513, 1515, 1540, 1546, 1571, 1572, 1583, 1584, 1585, 1612, 1613, 1629, 1630, 1864, 1899, 2135, 2137], "fep": 1387, "eigenproblem": 1387, "iparam": 1387, "fparam": 1387, "bparam": 1387, "ivar": 1387, "fvar": 1387, "bvar": 1387, "tvar": 1387, "istep": 1387, "converged_count": 1387, "rerr": 1387, "force_stop": 1387, "2001": 1387, "precondit": 1387, "eigensolv": 1387, "siam": 1387, "sci": 1387, "517": 1387, "541": 1387, "epub": 1387, "doi": [1387, 1533, 1956], "1137": 1387, "s1064827500366124": 1387, "andrea": 1387, "stathopoulo": 1387, "kesheng": 1387, "2002": [1387, 1956], "2165": 1387, "2182": 1387, "s1064827500370883": 1387, "duerschetal2018": 1387, "jed": 1387, "duersch": 1387, "meiyu": 1387, "shao": 1387, "chao": 1387, "ming": 1387, "gu": 1387, "c655": 1387, "c676": 1387, "17m1129830": 1387, "log_": [1388, 1389, 1390, 1391, 2094, 2115], "7767": 1388, "3234": 1388, "2156": 1388, "2411": 1388, "5739": 1388, "5637": 1388, "4640": 1388, "1952": 1388, "4226": 1388, "5204": [1388, 1901], "5224": 1389, "9354": 1389, "7257": 1389, "1301": 1389, "2820": 1389, "0290": 1389, "1392": 1389, "8857": 1389, "6476": 1389, "0090": [1390, 1478, 1888, 2172], "9923": 1390, "5372": 1390, "2492": 1390, "8653": 1390, "7055": 1390, "7705": 1390, "2225": 1390, "8419": 1391, "8003": [1391, 2146], "9971": 1391, "5287": 1391, "0490": 1391, "2483": 1391, "0042": 1391, "9196": 1391, "3504": [1391, 2013], "logsumexp": [1392, 2094, 2115, 2122, 2155, 2172], "3069": 1392, "6867": 1392, "8731": 1392, "30000": 1392, "1269e": 1392, "log_2": 1393, "logaddexp": [1393, 2094, 2155], "limits_": 1394, "42296738": 1394, "04462666": 1394, "86278635": 1394, "94622083": 1394, "05277811": 1394, "39202815": 1394, "83525007": 1394, "84492621": 1394, "06084887": 1394, "06844475": 1394, "2611": [1395, 2010], "9254": 1395, "6213": [1395, 2142], "6843": 1395, "3242": 1395, "9665": 1395, "4539": 1395, "0887": [1395, 2172], "1336": 1395, "4025": 1395, "7089": [1395, 1522], "9032": 1395, "3031": 1395, "2589": 1401, "1135": 1401, "5481": [1401, 1414, 2142], "9566": 1401, "sum_j": [1402, 1570, 1614, 1616, 1744, 1972, 2172], "0593": [1402, 2142], "5696": 1402, "6859e": 1402, "compute_pivot": 1404, "transposit": [1404, 2017, 2171], "perm": 1404, "a_lu": 1404, "5558": 1404, "1684": 1404, "1551": 1404, "1940": 1404, "6189": 1404, "5497": 1404, "4526": 1404, "2526": 1404, "3285": 1404, "7988": 1404, "7175": 1404, "9701": 1404, "2634": 1404, "9255": 1404, "3459": 1404, "00000e": 1405, "8312": 1405, "unpack_data": [1406, 2094], "unpack_pivot": [1406, 2094], "l_": [1406, 1481, 1485, 1489, 1493, 1507, 1508, 1509, 1510, 1547, 1573], "u_": [1406, 1837, 1842], "3552": [1408, 1678], "3825": 1408, "8297": 1408, "3477": 1408, "2035": [1408, 1988, 1989, 2040, 2041], "2252": [1408, 2172], "5002": 1408, "6248": [1408, 1417], "1307": 1408, "0608": [1408, 1965], "1244": 1408, "0139": 1408, "6763": 1412, "7445": 1412, "2369": 1412, "argmax": [1412, 1484, 1573, 1711, 1712, 1713, 2008, 2094, 2155, 2199], "max_indic": 1412, "2360": 1412, "2942": 1412, "1222": [1412, 2142], "8475": 1412, "1949": 1412, "1127": 1412, "6702": 1412, "5717": 1412, "9207": 1412, "1297": 1412, "8768": 1412, "6172": 1412, "6060": 1412, "2432": 1412, "3288": 1414, "3367": [1414, 1987], "nanmean": [1414, 2094, 2155], "3841": 1414, "6320": 1414, "4254": 1414, "7384": 1414, "0131": 1414, "6549": [1414, 1948], "4279": 1414, "3350": 1414, "7694": 1414, "5600": [1414, 1633], "0842": 1414, "9580": 1414, "3623": [1414, 2117], "2343": 1414, "5085": 1414, "4599": 1414, "1807": 1414, "5219": 1415, "5212": 1415, "2202": 1415, "2505": 1415, "3982": 1415, "9948": 1415, "3518": 1415, "3131": 1415, "3180": [1415, 2171], "6993": 1415, "0436": 1415, "0438": 1415, "2270": 1415, "2751": 1415, "7303": 1415, "2192": 1415, "3321": 1415, "2488": 1415, "0778": 1415, "9510": 1415, "7048": 1415, "4742": [1415, 2026, 2172], "7125": [1415, 1975], "plot": [1416, 2129, 2159, 2176, 2207], "t_0": [1416, 1864], "t_": [1416, 1528, 1682, 1863, 1864, 2094, 2171, 2194], "s_0": 1416, "s_": [1416, 1482, 1483, 1525, 1631], "g_0": 1416, "g_": [1416, 1842, 1858, 1859], "g_i": 1416, "t_i": 1416, "0d": [1416, 1572], "xy": 1416, "50276": 1416, "cartesian_prod": [1416, 2094, 2155], "grid_x": 1416, "grid_i": 1416, "dstack": [1416, 2094, 2155, 2171], "matplotlib": [1416, 2176], "pyplot": 1416, "plt": 1416, "plot_surfac": 1416, "6750": 1417, "0857": [1417, 2023], "7197": [1417, 2048], "argmin": [1417, 2094, 2155, 2199], "min_indic": [1417, 2094], "1334": 1417, "2803": 1417, "4644": [1417, 1988, 1989, 2040, 2041], "2635": [1417, 2142], "3651": 1417, "0384": 1417, "0128": 1417, "7015": 1417, "1153": 1417, "9849": 1417, "1458": [1417, 2172], "5788": 1417, "deduc": [1419, 2171], "4851": 1419, "5037": 1419, "3633": 1419, "0760": 1419, "3362": [1421, 1422], "8437": [1421, 1422], "9627": [1421, 1422], "1727": [1421, 1422], "5173": [1421, 1422], "1398": [1421, 1422], "mpsalloc": [1423, 1425], "metal": [1425, 1436, 1438, 2106, 2110, 2111, 2143, 2155], "mpsgraph": 1425, "wait_until_complet": [1433, 1434], "signpost": [1433, 1434, 1435, 2111], "xcode": 1434, "recommendedmaxworkingsets": [1436, 1438, 2111], "unlimit": [1438, 2130], "1321": 1441, "4370": [1441, 2171], "1289": 1441, "0527": 1441, "3077": [1441, 1984], "0881": 1441, "1259": 1441, "0284": 1441, "2015": [1465, 2124, 2142], "6087": 1465, "1494": 1465, "5491": 1465, "260": 1465, "8663": [1465, 2117], "3137": 1465, "0700": [1465, 2117], "8378": 1465, "5146": 1465, "5244": 1465, "5767": 1465, "1363": 1465, "5877": 1465, "5083": 1465, "1614": 1465, "1645": 1465, "7021": 1465, "0085": 1465, "0367": 1465, "1567": 1465, "4312": 1465, "1019": 1465, "4394": 1465, "8753": 1465, "_sampl": 1466, "n_sampl": 1466, "prob_dist": 1466, "0404": 1468, "6361": 1468, "multigammaln": [1469, 2172], "4028e": 1470, "38": [1470, 2193], "1400e": 1470, "isnan": [1471, 2094, 2155, 2171, 2199], "midpoint": [1473, 1893], "weakli": [1475, 1476, 2172], "to_spars": [1476, 1970, 2094, 2146, 2155, 2171], "2262": [1478, 1888], "0682": [1478, 1888], "2866": [1478, 1888], "3940": [1478, 1888], "5x7": [1482, 1486], "7x7": [1482, 1486], "10x7": [1482, 1486], "cube": [1483, 1487, 1899], "d_": [1483, 1487, 1491, 1503, 1506, 1509, 1512, 1549, 1575, 1578, 1604, 1607, 1633, 1638, 1686, 2021, 2022, 2023, 2024], "5x7x9": [1483, 1487], "7x7x7": [1483, 1487], "7x9x8": [1483, 1487], "n_class": 1484, "cutoff": [1484, 2124], "div_valu": 1484, "head_bia": 1484, "edouard": 1484, "grave": [1484, 1499], "armand": 1484, "joulin": 1484, "moustapha": 1484, "ciss\u00e9": 1484, "grangier": 1484, "herv\u00e9": 1484, "j\u00e9gou": 1484, "zipf": 1484, "law": 1484, "102": [1484, 2198], "1001": 1484, "1002": 1484, "_class": 1484, "maxunpool1d": [1485, 1573, 1714, 2033], "maxunpool2d": [1486, 1527, 1574, 1715, 2033], "maxunpool3d": [1487, 1528, 1575, 1716, 2033], "selu": [1488, 1524, 1679, 2094, 2124, 2154, 2155], "n_i": [1489, 1490, 1491, 1507, 1508, 1509, 1573, 1574, 1575, 1629, 1630], "c_j": [1489, 1490, 1491, 1573, 1574, 1575], "size_averag": [1492, 1493, 1513, 1515, 1539, 1545, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1658, 1659, 1667, 1669, 1694, 1698, 1699, 1710, 1718, 1719, 1720, 1721, 1722, 1730, 1742, 1743, 1754, 2094], "unreduc": [1492, 1493, 1515, 1540, 1546, 1571, 1587, 1612, 1630], "ell": [1492, 1493, 1515, 1539, 1540, 1546, 1571, 1587, 1612, 1630], "l_1": [1492, 1493, 1515, 1539, 1540, 1546, 1571, 1587, 1612, 1630], "l_n": [1492, 1493, 1515, 1539, 1540, 1546, 1571, 1587, 1612, 1630], "w_n": [1492, 1493, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956], "y_n": [1492, 1493, 1515, 1539, 1540, 1546, 1571, 1587, 1612, 2018, 2127], "lim_": [1492, 2127], "secondli": 1492, "rescal": [1492, 1493, 1515, 1584, 1585, 1587, 1614, 1616, 1658, 1659, 1669, 1722, 1793, 1821], "nbatch": [1492, 1493], "meantim": [1492, 1493, 1513, 1515, 1539, 1546, 1571, 1572, 1583, 1584, 1585, 1587, 1594, 1612, 1613, 1629, 1658, 1659, 1669, 1698, 1722, 1730, 2205], "pos_weight": [1493, 1659, 2094], "ell_c": 1493, "l_c": 1493, "p_c": 1493, "imbal": 1493, "pai": [1493, 1659, 2148, 2175], "spacial": 1493, "random_": [1493, 1515, 1587, 1659, 2094, 2115, 2180], "hat": [1494, 1495, 1496, 1542, 1543, 1544, 1620], "terminologi": [1494, 1495, 1496, 1620], "5d": [1496, 1544, 1633, 1686, 1697, 1725, 1757], "volumetr": [1496, 1620, 1633, 1686, 1697, 1757, 1758, 1759], "spatio": [1496, 1620], "in1_featur": 1497, "in2_featur": 1497, "in1": [1497, 1657], "in2": [1497, 1657], "blank": [1499, 1670, 2094, 2097], "zero_infin": [1499, 1670, 2094], "connectionist": [1499, 1670], "unseg": 1499, "longest": [1499, 1814, 1816, 1817, 2135], "input_length": [1499, 1670, 2094, 2135], "target_length": [1499, 1670, 2094], "s_n": 1499, "target_n": 1499, "unbatch": [1499, 1515, 1526, 1531, 1542, 1550, 1586, 1596, 1624, 1680], "s_min": 1499, "toronto": 1499, "edu": [1499, 1899, 2204], "icml_2006": 1499, "background": [1499, 1510, 1686, 1725, 2130, 2144, 2166], "channel_shuffl": [1500, 2094, 2155], "_left": [1501, 1502, 1503, 1504, 1505, 1506, 1602, 1603, 1604, 1605, 1606, 1607, 1636, 1637, 1638, 1725], "_right": [1501, 1502, 1503, 1504, 1505, 1506, 1602, 1603, 1604, 1605, 1606, 1607, 1636, 1637, 1638, 1725], "_top": [1502, 1503, 1505, 1506, 1603, 1604, 1606, 1607, 1637, 1638, 1725], "_bottom": [1502, 1503, 1505, 1506, 1603, 1604, 1606, 1607, 1637, 1638, 1725], "_front": [1503, 1506, 1604, 1607, 1638, 1725], "_back": [1503, 1506, 1604, 1607, 1638, 1725], "320": [1503, 1607], "480": [1503, 1607], "0491": [1504, 1636], "7152": [1504, 1636], "0749": [1504, 1636], "3287": [1504, 1636], "8966": [1504, 1636], "1466": [1504, 1636], "2771": [1504, 1636], "6616": [1504, 1636], "4523": [1504, 1636], "1255": [1504, 1636], "6372": [1504, 1636, 1994], "1182": [1504, 1636], "8652": [1504, 1636], "6585": 1505, "4320": [1505, 2006], "8701": 1505, "4649": 1505, "_j": [1507, 1508], "star": [1507, 1508, 1509, 2096], "\u00e0": [1507, 1508, 1509, 1510, 1511, 1512, 1526, 1632], "trou": [1507, 1508, 1509, 1510, 1511, 1512, 1526, 1632], "harder": [1507, 1508, 1509, 1510, 1511, 1512, 1526, 1574, 1575, 1632, 2204], "prod_": [1508, 1509, 1511, 1512, 1525, 1631, 1844], "out_j": 1509, "deconvolut": [1510, 1511, 1512, 1664, 1665, 1666], "_pad": [1510, 1511, 1512], "semi": [1513, 1539, 2124], "supervis": [1513, 1539], "vert": [1514, 1589, 1668], "_2": [1514, 1668, 1788, 1821], "ast_1": [1514, 1530], "ast_2": [1514, 1530], "ignore_index": [1515, 1587, 1669, 1722, 2094], "d_1": [1515, 1587, 1669, 1722, 2117], "d_2": [1515, 1587, 1669, 1722], "d_k": [1515, 1587, 1669, 1722], "_index": [1515, 1587], "logsoftmax": [1515, 1587, 1614, 1705], "nllloss": [1515, 1614, 1722, 1744, 2033], "blend": 1515, "smooth": [1515, 1540, 1612, 1617, 1669, 1695, 1742, 1857, 2157], "w_c": 1515, "rethink": [1515, 1669], "incept": [1515, 1669], "spectral_norm": [1516, 1811], "neuron": 1517, "detector": 1517, "dropout1d": [1519, 2094], "_freez": 1522, "sparseadam": [1522, 2157], "0251": 1522, "6902": [1522, 1890], "7172": 1522, "6431": 1522, "0748": 1522, "6969": 1522, "4970": 1522, "3448": 1522, "9685": 1522, "3677": 1522, "7265": 1522, "1685": 1522, "4362": 1522, "4004": [1522, 1975], "9400": 1522, "9124": 1522, "3616": 1522, "1151": 1522, "0309": 1522, "9315": 1522, "1655": [1522, 2130], "9897": [1522, 2133], "0635": 1522, "7895": 1522, "0364": 1522, "6778": 1522, "5803": 1522, "from_pretrain": [1522, 1523, 2197], "bag": [1523, 1678], "per_sample_weight": [1523, 1678, 2094, 2199], "embedding_sum": 1523, "8861": 1523, "4350": 1523, "0523": 1523, "1306": 1523, "5798": 1523, "0044": 1523, "7082": [1523, 1678], "2145": [1523, 1678], "6251": [1523, 1678], "6500": 1523, "satur": [1524, 1679, 2130], "alphadropout": [1524, 1652], "160": [1525, 1877, 1878, 2157], "unfold": [1526, 2094, 2155, 2175], "prod_d": [1526, 1632], "neighborhood": [1526, 1632], "col2im": [1526, 2094, 2155, 2199], "fold_param": [1526, 1632], "input_on": [1526, 1632], "output_ratio": [1527, 1528, 1681, 1682, 2094], "_random_sampl": [1527, 1528, 1681, 1682, 2094], "ben": [1527, 1528, 1681, 1682], "graham": [1527, 1528, 1681, 1682], "oh": [1527, 1528, 1681, 1682], "ow": [1527, 1528, 1681, 1682], "_ratio": [1527, 1528, 1682], "_h": [1527, 1586], "13x12": [1527, 1681], "kt": [1528, 1655, 1663, 1666, 1682, 1713], "ot": [1528, 1682], "13x12x11": [1528, 1682], "044715": [1529, 1684], "pack_sequ": [1531, 1550, 1596, 1816, 1818], "bias_ih": [1532, 1551, 1596, 1598], "bias_hh": [1532, 1551, 1596, 1598], "homoscedast": [1533, 1683], "heteroscedast": [1533, 1683], "nix": 1533, "weigend": 1533, "1994": 1533, "icnn": 1533, "94": 1533, "orlando": 1533, "fl": 1533, "usa": [1533, 2176], "374138": 1533, "instancenorm": [1534, 2163], "shrinkag": [1535, 1618, 1689, 1747], "mobilenetv3": [1537, 1691], "_val": 1538, "dissimilar": 1539, "l1loss": [1540, 1612, 1699], "outlier": [1540, 1612, 2161, 2162], "huber": [1540, 1612, 1695], "smoothl1loss": [1540, 1695, 1742], "insensit": 1541, "unused_argument1": 1541, "unused_argument2": 1541, "ingredi": [1542, 1543, 1544], "styliz": [1542, 1543, 1544], "rgb": [1543, 1544, 2176], "log_target": [1545, 1698, 2094], "kl": [1545, 1698], "summaris": 1545, "loss_pointwis": 1545, "batchmean": [1545, 1698], "kl_loss": 1545, "mae": 1546, "proj_siz": [1550, 1597], "f_t": [1550, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "hf": [1550, 1551], "g_t": [1550, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "ig": [1550, 1551], "hg": [1550, 1551], "o_t": 1550, "c_t": [1550, 1838], "forget": [1550, 2095, 2096], "1402": 1550, "c_0": [1550, 1551, 1838], "c_n": 1550, "w_ii": 1550, "w_if": 1550, "w_ig": 1550, "w_io": 1550, "w_hi": 1550, "w_hf": 1550, "w_hg": 1550, "w_ho": 1550, "b_ii": 1550, "b_if": 1550, "b_ig": 1550, "b_io": 1550, "b_hi": 1550, "b_hf": 1550, "b_hg": 1550, "b_ho": 1550, "weight_hr_l": 1550, "_revers": 1550, "h_1": 1551, "c_1": 1551, "time_step": 1551, "_shape": [1552, 1595, 1769], "sentence_length": 1552, "lazymodulemixin": [1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565], "cls_to_becom": [1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1774], "convtranspose1d": [1559, 1664, 2033, 2163], "convtranspose3d": [1561, 1666, 1780, 2033, 2163], "instancenorm1d": [1562, 1696, 2163], "instancenorm2d": [1563, 1696, 2163], "instancenorm3d": [1564, 1696, 2163], "uninitializedparamet": [1565, 1760], "lrn": 1568, "signal_2d": 1568, "signal_4d": 1568, "output_2d": 1568, "output_4d": 1568, "x_j": [1570, 1614, 1616, 1744, 1972, 2138, 2172], "80827": [1576, 1577, 1578], "unpool": [1576, 1577, 1578], "maxpool3d": [1578, 1713, 1716, 2033, 2163], "unpooled_output": 1578, "t_destin": 1580, "lrelu": [1581, 2142], "hing": [1583, 1585], "sum_i": [1584, 1585, 1613], "nelement": [1584, 1613], "jointli": 1586, "multihead": [1586, 1626], "concat": [1586, 2094, 2136, 2155], "_1": [1586, 2134, 2158], "qw_i": 1586, "kw_i": 1586, "vw_i": 1586, "nestedtensor": [1586, 1628, 2117], "multihead_attn": 1586, "e_q": 1586, "e_k": 1586, "e_v": 1586, "_head": [1586, 1624], "merge_mask": 1586, "mask_typ": 1586, "merged_mask": 1586, "nll": 1587, "num_paramet": 1588, "nchannel": 1588, "decai": [1588, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 1866, 1869, 1870, 1873, 1874, 1876, 1949, 2157], "legitim": [1588, 1686, 2134], "vert_p": 1589, "upscale_factor": [1592, 1728, 2094], "upscal": 1592, "video": [1592, 1593, 2116, 2117, 2176, 2193], "shi": [1592, 1593], "2016": [1592, 1593, 1630], "_factor": [1592, 1593, 1633, 1634, 1635], "pixel_shuffl": [1592, 2094, 2155, 2163], "downscale_factor": [1593, 1729, 2094], "pixelshuffl": [1593, 1728, 1729, 2163], "downscal": 1593, "pixel_unshuffl": [1593, 2094, 2155, 2163], "log_input": [1594, 1730, 2094], "poisson": [1594, 1730, 1949, 2094, 2155], "stirl": [1594, 1730], "rm": [1595, 1629, 1630, 1769, 1838], "gamma_i": [1595, 1769], "rms_norm": [1595, 1769, 2094, 2155], "hh": [1596, 1598], "h_t_minus_1": 1596, "flatten_paramet": 1597, "3333333333333333": [1599, 1862, 1869, 2094], "leaki": [1599, 1736, 2124], "rectifi": [1599, 1600, 1732, 2124], "empir": [1599, 1877], "crelu": 1600, "1603": 1600, "05201": 1600, "6732632423543772848170429916717": [1608, 1739], "0507009873554804934193349852946": [1608, 1739], "kaiming_norm": 1608, "kaiming_normal_": [1608, 2098, 2124], "initialis": [1608, 1875], "calculate_gain": [1608, 2098, 2124], "cascad": 1609, "relu2": [1609, 1760], "swish": [1610, 1741], "coin": [1610, 1741], "cnn": [1612, 2161], "ross": 1612, "girshick": 1612, "quadrat": [1612, 2135], "huberloss": 1612, "w_j": 1615, "soft": [1618, 1688, 1747, 2111], "softshrinkag": 1618, "convert_sync_batchnorm": 1620, "r1": 1620, "sync_bn_network": 1620, "ddp_sync_bn_network": 1620, "sync_bn_modul": 1620, "d_model": [1624, 1625, 1626, 1627, 1628], "nhead": [1624, 1625, 1626, 1627, 1628], "num_encoder_lay": 1624, "num_decoder_lay": 1624, "dim_feedforward": [1624, 1626, 1628], "custom_encod": 1624, "custom_decod": 1624, "layer_norm_ep": [1624, 1626, 1628], "norm_first": [1624, 1626, 1628], "ashish": [1624, 1626, 1628], "vaswani": [1624, 1626, 1628], "noam": [1624, 1626, 1628, 1838], "shazeer": [1624, 1626, 1628, 1838], "niki": [1624, 1626, 1628], "parmar": [1624, 1626, 1628], "jakob": [1624, 1626, 1628], "uszkoreit": [1624, 1626, 1628], "llion": [1624, 1626, 1628], "jone": [1624, 1626, 1628], "aidan": [1624, 1626, 1628], "gomez": [1624, 1626, 1628], "lukasz": [1624, 1626, 1628], "illia": [1624, 1626, 1628], "polosukhin": [1624, 1626, 1628], "6000": [1624, 1626, 1628, 1633, 1896, 1943, 1946], "6010": [1624, 1626, 1628], "feedforward": [1624, 1626, 1628, 2124], "transformer_model": 1624, "src_mask": [1624, 1628], "tgt_mask": [1624, 1625, 1626], "memory_mask": [1624, 1625, 1626], "src_key_padding_mask": [1624, 1627, 1628], "tgt_key_padding_mask": [1624, 1625, 1626], "memory_key_padding_mask": [1624, 1625, 1626], "src_is_caus": 1624, "tgt_is_caus": [1624, 1625, 1626], "memory_is_caus": [1624, 1625, 1626], "_mask": [1624, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1810], "_key_padding_mask": 1624, "generate_square_subsequent_mask": 1624, "sz": 1624, "decoder_lay": [1625, 1626], "transformerdecoderlay": 1625, "transformer_decod": 1625, "encoder_lay": [1627, 1628], "enable_nested_tensor": 1627, "mask_check": 1627, "bert": [1627, 2197], "1810": 1627, "04805": 1627, "transformerencoderlay": 1627, "transformer_encod": 1627, "triplet": [1629, 1630, 1754, 1755], "x3": 1629, "balnta": [1629, 1630], "riba": [1629, 1630], "p_i": [1629, 1630], "rvert_p": [1629, 1723], "tripletmarginwithdistanceloss": [1629, 1755], "triplet_loss": [1629, 1630], "distance_funct": [1630, 1755], "l_i": 1630, "tripletmarginloss": [1630, 1754], "l_p": [1630, 1723], "pairwisedist": [1630, 1726], "penal": [1630, 2142, 2157], "distant": 1630, "anchor_id": 1630, "positive_id": 1630, "negative_id": 1630, "l_infin": 1630, "bmva": 1630, "archiv": [1630, 2140, 2147], "uk": 1630, "bmvc": 1630, "paper119": 1630, "unflattened_s": 1631, "namedtensor": 1631, "namedshap": 1631, "u_1": 1631, "u_n": 1631, "u_i": 1631, "im2col": [1632, 2094, 2155], "2x3": 1632, "3x4": 1632, "inp_unf": 1632, "out_unf": 1632, "recompute_scale_factor": [1633, 1697], "bicub": [1633, 1686, 1697, 1757, 2033], "trilinear": [1633, 1686, 1697, 1757, 2033], "input_3x3": 1633, "4375": 1633, "8125": 1633, "9375": 1633, "2400": [1633, 2013], "1200": [1633, 1921, 2130], "8800": 1633, "4400": [1633, 2013], "7200": 1633, "0400": 1633, "2800": [1633, 1943], "3600": 1633, "5200": 1633, "6400": 1633, "1678": 1637, "4418": 1637, "9466": [1637, 2172], "9604": 1637, "4219": 1637, "5241": 1637, "9162": 1637, "5436": [1637, 2013], "6446": 1637, "sdpa_kernel": [1639, 1738], "flash_attent": [1639, 1644, 1738], "seq_len_q": 1640, "seq_len_kv": 1640, "causalvari": 1640, "constru": 1640, "causal_upper_left": 1640, "causal_lower_right": 1640, "bsz": 1640, "seqlen_q": 1640, "seqlen_kv": 1640, "head_dim": 1640, "attn_bia": [1640, 1738], "upper_left": [1641, 1643], "lower_right": [1641, 1642], "diagonal_offset": [1641, 1642], "causalbia": [1642, 1643, 1738], "set_prior": 1644, "sdpbackend": [1644, 1738], "set_priority_ord": 1644, "adaptiveavgpool1d": [1645, 2163], "tripl": [1647, 1650], "adaptivemaxpool1d": 1648, "adaptivemaxpool2d": [1649, 2033], "adaptivemaxpool3d": 1650, "avgpool1d": [1653, 2163], "st": [1655, 1663, 1666, 1713, 2205], "avgpool3d": [1655, 2033, 2163], "iT": [1655, 1663, 1666], "padt": [1655, 1663, 1666], "score": [1659, 1738, 1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807, 2122], "dt": [1663, 1666, 2172, 2205], "out_padw": [1664, 1665, 1666], "out_padh": [1665, 1666], "out_padt": 1666, "cosineembeddingloss": 1667, "ctcloss": [1670, 2033], "charact": [1670, 1940, 2093, 2096, 2116, 2166], "elu": [1676, 2094, 2154, 2155, 2163, 2199], "embedding_matrix": [1677, 1678], "8490": 1677, "9625": 1677, "6753": 1677, "7761": 1677, "6108": 1677, "6246": 1677, "9751": 1677, "3618": 1677, "4161": [1677, 2171], "2419": 1677, "7383": 1677, "0237": 1677, "7794": 1677, "0528": 1677, "3385": 1677, "8612": 1677, "1867": 1677, "5384": 1677, "8720": 1677, "6262": 1677, "7471": 1677, "embeddingbag": [1678, 2033, 2161, 2163, 2177], "3397": 1678, "5545": 1678, "5893": 1678, "4386": 1678, "5882": 1678, "featurealphadropout": 1679, "gaussiannllloss": 1683, "border": 1686, "affine_grid": [1686, 2094], "extrema": 1686, "pil": [1686, 1697], "overshoot": [1686, 1697, 1757], "gumbel": 1688, "y_hard": 1688, "y_soft": 1688, "hardtanh": [1693, 2094, 2106, 2155, 2163, 2199], "hingeembeddingloss": 1694, "use_input_stat": [1696, 2094], "antialia": 1697, "anti": 1697, "pillow": [1697, 2176], "inter_nearest": 1697, "104157": 1697, "kldivloss": 1698, "batchsiz": [1698, 1976, 1977, 1978, 1980, 1981, 2171], "leaky_relu": [1702, 2094, 2124, 2155, 2163, 2199], "localresponsenorm": 1704, "_stacklevel": [1705, 1744, 1745, 2094, 2100], "lppool1d": 1707, "lppool2d": 1708, "lppool3d": 1709, "marginrankingloss": 1710, "max_unpool1d": [1711, 2094], "multimarginloss": 1719, "multilabelmarginloss": 1720, "multilabelsoftmarginloss": 1721, "n_0": 1723, "n_": 1723, "n_k": 1723, "everywher": [1724, 1990, 2157], "circularpad2d": 1725, "constantpad2d": 1725, "reflectionpad2d": [1725, 2033], "replicationpad2d": [1725, 2033], "t4d": 1725, "p1d": 1725, "p2d": 1725, "p3d": 1725, "pixelunshuffl": [1729, 2163], "poissonnllloss": 1730, "rrelu": [1737, 2094, 2155], "dropout_p": [1738, 2094], "enable_gqa": [1738, 2094, 2122], "temp_mask": 1738, "mymodel": [1738, 2096, 2126, 2144, 2149, 2150], "gqa": [1738, 2122], "number_of_heads_queri": 1738, "number_of_heads_key_valu": 1738, "number_of_heads_kei": 1738, "number_of_heads_valu": 1738, "hq": [1738, 2122], "ev": [1738, 2122], "legend": [1738, 2122], "llama3": 1738, "softmarginloss": 1743, "module_kwarg": 1753, "upsample_trilinear": 1758, "fo": 1758, "spatia": 1759, "mixin": 1760, "dry": 1760, "lazymlp": 1760, "lazylinear": 1760, "lazy_mlp": 1760, "8832e": 1760, "5636e": 1760, "1598e": 1760, "5637e": 1760, "8788e": 1760, "0042e": 1760, "0019": 1760, "lazymodul": 1760, "full_mlp": 1760, "3837": [1760, 1890], "0907": 1760, "6708": 1760, "5223": 1760, "9028": 1760, "2851": 1760, "6813": 1760, "5766": 1760, "8678": 1760, "1320": 1760, "2938": 1760, "0679": [1760, 2023], "2793": [1760, 1828], "1088": 1760, "1795": 1760, "2301": 1760, "2807": 1760, "2479": 1760, "1091": 1760, "has_uninitialized_param": 1760, "initialize_paramet": 1760, "check_reduct": 1770, "delay_all_reduce_named_param": 1770, "param_to_hook_all_reduc": 1770, "optimizer_param": 1770, "loss_func": [1770, 2166], "consume_prefix_in_state_dict_if_pres": 1770, "nccl2": 1770, "dictat": [1770, 2096], "mebibyt": 1770, "mib": [1770, 2139], "ddp_logging_data": 1770, "can_set_static_graph": 1770, "model_ddp": [1770, 2204], "_get_ddp_logging_data": 1770, "divide_by_initial_world_s": 1770, "caught": [1770, 2114], "syncbatchnorm": 1770, "deplet": 1770, "pariti": 1770, "another_input": 1770, "predivid": 1770, "noop": [1770, 2122], "encode_and_decod": 1770, "encoded_tensor": 1770, "decoded_tensor": 1770, "error_if_nonfinit": [1775, 1776, 1785], "get_total_norm": 1776, "clip_grads_with_norm_": 1776, "total_norm": [1776, 1778], "clip_valu": 1777, "_norm": 1778, "nhwc": [1779, 1780, 2174, 2176], "outweigh": [1779, 1780, 1860, 2117, 2204, 2205], "channels_last_3d": [1780, 2174], "ndhwc": [1780, 2174], "_convnd": 1781, "conv_w": 1782, "conv_b": 1782, "bn_rm": [1782, 1784], "bn_rv": [1782, 1784], "bn_ep": [1782, 1784], "bn_w": [1782, 1784], "bn_b": [1782, 1784], "linear_w": 1784, "linear_b": 1784, "orthogonal_map": 1787, "use_trivi": 1787, "qq": 1787, "matrix_exp": [1787, 2094, 2155], "caylei": 1787, "manifold": 1787, "register_parametr": [1787, 1788, 1790, 1791, 1821, 2118], "orth_linear": 1787, "parametrizedlinear": [1787, 1788, 1789], "parametrizationlist": [1787, 1788, 1789, 1793], "_orthogon": 1787, "9332e": 1787, "n_power_iter": [1788, 1821], "sn": [1788, 1821], "discrimin": [1788, 1821], "adversari": [1788, 1821], "lipschitz": 1788, "reimplement": [1788, 1821, 2192], "_spectralnorm": 1788, "convtranspos": [1788, 1821], "snm": 1788, "0081": 1788, "amaxbackward0": 1788, "decoupl": [1789, 1824, 1838, 1841, 1844, 1856], "1602": [1789, 1824], "07868": [1789, 1824], "_weightnorm": 1789, "original0": [1789, 1790, 1793, 1824], "original1": [1789, 1790, 1793, 1824], "tensor_nam": [1790, 1792, 1793, 1794], "right_invers": [1790, 1793], "out_rnn": 1791, "rnn_cell": 1791, "inbuilt": 1793, "unparametr": 1793, "rankon": 1793, "surject": 1793, "s0_sqrt": 1793, "linear_rank_on": 1793, "matrix_rank": 1793, "leave_parametr": 1794, "unparametris": 1794, "skeleton": 1795, "compute_mask": [1795, 1796, 1798, 1799, 1800, 1801, 1802], "importance_scor": [1795, 1796, 1798, 1799, 1800, 1801, 1802, 1804, 1806, 1807], "apply_mask": [1795, 1796, 1798, 1799, 1800, 1801, 1802], "pruned_tensor": [1795, 1796, 1798, 1799, 1800, 1801, 1802], "default_mask": [1795, 1796, 1798, 1799, 1800, 1801, 1802], "_orig": [1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1806, 1807, 1808, 1809, 1810], "undon": [1795, 1796, 1798, 1799, 1800, 1801, 1802, 1810], "unprun": [1797, 1798, 1799, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809], "bias_mask": [1797, 1803], "indexerror": [1799, 1801], "basepruningmethod": [1800, 1805], "add_pruning_method": 1800, "pruning_typ": [1800, 1804], "unstructur": [1800, 1804], "ravel": [1800, 2094, 2155], "nonmask": 1800, "pruning_method": 1804, "parameters_to_prun": 1804, "l1unstructur": 1804, "parameters_to_vector": 1804, "random_unstructur": [1805, 1810], "odict_kei": 1806, "weight_orig": 1806, "weight_mask": [1806, 1809], "columns_prun": 1808, "t_modul": [1811, 1812, 1821, 1824], "weight_norm": 1812, "sorted_indic": [1813, 1815, 1816, 1818], "unsorted_indic": [1813, 1815, 1816, 1818], "abc": [1813, 2096], "axbc": 1813, "conform": [1813, 2142], "is_cuda": [1813, 2115, 2155, 2173], "enforce_sort": [1814, 1815, 1816], "unsort": [1814, 1815, 1928], "shortest": 1814, "pad_packed_sequ": [1814, 2135], "uncondition": [1814, 2091, 2133, 2206], "pad_sequ": [1815, 1819, 2094, 2155], "padding_valu": [1816, 1817, 2094], "total_length": [1816, 2135], "seq_unpack": 1816, "lens_unpack": 1816, "padding_sid": [1817, 2094], "packed_sequ": 1818, "unpacked_sequ": 1818, "padded_sequ": 1819, "unpad": 1819, "unstack": 1819, "as_tensor": [1819, 2011, 2094, 2133, 2155, 2176, 2177, 2178], "unpadded_sequ": 1819, "module_cl": [1820, 2166], "5846e": 1820, "29": [1820, 1956, 2154, 2186], "8307e": 1820, "5250e": 1820, "1210e": 1820, "4677e": 1820, "5915e": 1820, "4013e": 1820, "weight_u": 1821, "parameters_and_buff": 1822, "reparamater": 1822, "weight_g": [1824, 2094], "weight_v": 1824, "modern": [1824, 2145, 2188, 2195], "bother": 1824, "102999": 1824, "remove_parametr": 1824, "as_tupl": [1826, 2048, 2122], "complexfloat": [1827, 1833], "0425": 1828, "7969": 1828, "2925": 1828, "7229": 1828, "2134": 1828, "0505": 1828, "1408": 1828, "0563": 1828, "0566": 1828, "0732": [1828, 2013], "0687": 1828, "1177": 1828, "2303": [1828, 1987], "1552": 1828, "6148": 1828, "6535": 1828, "8318": 1828, "3987": 1828, "9544": [1828, 1900], "6048": 1828, "7909": 1828, "120": [1830, 2176], "from_valu": 1833, "onnx_typ": 1833, "tensorprotodatatyp": 1833, "torch_c_value_with_type_float": 1833, "from_dtyp": 1833, "jit_type_bas": 1833, "safer": [1833, 2103, 2173], "onnxexportererror": [1833, 2150], "from_onnx_typ": 1833, "_c_onnx": [1833, 2150, 2154], "_onnx": 1833, "symbolicvalueerror": 1833, "onnx_compat": 1833, "scalar_nam": 1833, "complexhalf": 1833, "complexdoubl": 1833, "float8e5m2": 1833, "float8e4m3fn": 1833, "float8e5m2fnuz": 1833, "float8e4m3fnuz": 1833, "torch_nam": 1833, "int8_t": 1833, "int16_t": 1833, "float8_e5m2": [1833, 2173, 2177], "float8_e4m3fn": [1833, 2173, 2177], "float8_e5m2fnuz": [1833, 2173], "float8_e4m3fnuz": [1833, 2173], "verif": [1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860], "params_dict": 1834, "export_opt": [1834, 2150], "_excluded_node_kind": 1834, "frozenset": [1834, 2096], "scalarimplicit": [1834, 2155], "prim": [1834, 2093, 2154, 2155], "listconstruct": [1834, 2093], "all_mismatch_leaf_graph_info": 1834, "essential_node_count": 1834, "subgraph": [1834, 2127, 2132, 2150, 2154, 2158, 2182, 2193, 2194, 2204, 2205], "essential_node_kind": 1834, "export_repro": 1834, "repro_dir": 1834, "repro": [1834, 2186, 2195, 2204, 2205], "test_": 1834, "test_data_set_0": 1834, "input_0": [1834, 2154], "pb": [1834, 2150, 2154], "input_1": [1834, 2154], "output_0": 1834, "output_1": 1834, "find_mismatch": [1834, 2156], "exhibit": [1834, 2191, 2205], "verificationopt": [1834, 2156], "find_partit": 1834, "has_mismatch": 1834, "pretty_print_mismatch": 1834, "pretty_print_tre": 1834, "graph_info": 1834, "__2": 1834, "__1": 1834, "__3": 1834, "110": 1834, "verify_export": 1834, "onnx_graph": 1834, "onnx_out": 1834, "pt_out": 1834, "ignore_non": 1835, "check_shap": 1835, "check_dtyp": [1835, 2178], "onnxbackend": [1835, 2156], "onnx_runtime_cpu": 1835, "remained_onnx_input_idx": 1835, "acceptable_error_percentag": 1835, "percentag": [1835, 1872, 1949, 2122, 2161], "weight_decai": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860, 2142, 2157], "1e6": 1836, "tensorlist": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "prohibit": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859, 2130, 2147, 2204], "impair": [1836, 1837, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "ungraph": [1836, 1837, 1840, 1841, 1842, 1844, 1856, 1857, 1858], "removeablehandl": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1856, 1857, 1858, 1859, 1860], "register_step_post_hook": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860], "register_step_pre_hook": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1856, 1857, 1858, 1859, 1860], "new_arg": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1852, 1856, 1857, 1858, 1859, 1860], "new_kwarg": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1852, 1856, 1857, 1858, 1859, 1860], "momentum_buff": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860], "param0": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1853, 1856, 1857, 1858, 1859, 1860], "reevalu": [1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1854, 1856, 1857, 1858, 1859, 1860, 2157], "rho": 1837, "110mm": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "4pt": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "textbf": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "theta_0": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "v_0": [1837, 1840, 1841, 1844, 1856, 1857], "leftarrow": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "u_0": [1837, 1842], "hspace": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "5mm": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1857, 1858, 1859], "nabla_": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "theta_": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "10mm": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1857, 1858, 1859], "v_t": [1837, 1840, 1841, 1844, 1856, 1857], "v_": [1837, 1840, 1841, 1844, 1856, 1857, 1859], "2_t": [1837, 1838, 1839, 1840, 1841, 1844, 1856, 1857], "21mm": 1837, "u_t": [1837, 1838, 1842], "theta_t": [1837, 1838, 1839, 1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "oscil": 1837, "beta2_decai": 1838, "beta_2": [1838, 1840, 1841, 1842, 1844, 1856], "15mm": [1838, 1844, 1858, 1859], "epsilon_1": 1838, "epsilon_2": 1838, "textit": [1838, 1840, 1841, 1844, 1856, 1859], "r_0": 1838, "23mm": 1838, "widehat": [1838, 1840, 1841, 1844, 1856], "_0": [1838, 1857, 2134, 2158, 2207], "rho_t": [1838, 1856], "alpha_t": 1838, "1_m": 1838, "top_n": 1838, "sublinear": 1838, "mitchel": 1838, "stern": 1838, "beta2": 1838, "standardli": 1838, "epsilon1": 1838, "epsilon2": 1838, "presum": 1838, "1_n": 1838, "top_m": 1838, "alon": [1838, 2033, 2095, 2158], "lr_decai": 1839, "initial_accumulator_valu": 1839, "12mm": [1839, 1856], "_sum_0": 1839, "tild": [1839, 1857], "_sum_t": 1839, "_sum_": 1839, "subgradi": 1839, "999": [1840, 1841, 1842, 1844, 1856, 1860, 2147, 2157], "amsgrad": [1840, 1841], "beta_1": [1840, 1841, 1842, 1844, 1856], "13mm": [1840, 1841, 1842, 1844, 1856, 1857, 1858, 1859], "m_0": [1840, 1841, 1842, 1844, 1856], "m_t": [1840, 1841, 1842, 1844, 1856], "m_": [1840, 1841, 1842, 1844, 1856, 2171], "vertic": [1840, 1841, 1859, 2046, 2047, 2157, 2176, 2195], "002": [1842, 1844], "t_1": 1842, "2e": [1842, 1844], "max_it": 1843, "max_ev": 1843, "tolerance_grad": 1843, "tolerance_chang": 1843, "history_s": 1843, "line_search_fn": 1843, "bfg": 1843, "minfunc": 1843, "intens": [1843, 2130, 2145], "param_byt": 1843, "strong_wolf": 1843, "momentum_decai": 1844, "004": 1844, "decoupled_weight_decai": [1844, 1856], "gamma_t": 1844, "psi": [1844, 2172], "_decai": [1844, 1856], "mu_t": 1844, "96": 1844, "mu_": 1844, "11mm": 1844, "incorpor": [1844, 1948, 2161], "nesterov": [1844, 1859], "4e": 1844, "nadamw": 1844, "weightdecai": 1856, "18mm": 1856, "rho_": 1856, "6mm": 1856, "t_2": 1856, "l_t": 1856, "radamw": 1856, "av": 1857, "8mm": 1857, "3mm": 1857, "lectur": 1857, "hinton": 1857, "step_siz": [1858, 1876], "resili": [1858, 2145], "eta_": [1858, 1863, 1864], "etaplu": 1858, "etaminu": 1858, "gamma_": [1858, 2172], "0_": 1858, "eta_0": 1858, "i_": [1858, 2013], "eta_t": [1858, 1863, 1864], "dampen": 1859, "sutskev": 1859, "veloc": 1859, "conflat": 1860, "is_spars": [1860, 2115, 2155, 2171, 2173], "maskedtensor": [1860, 2171], "gain": [1860, 2117, 2124, 2183, 2185, 2197, 2198, 2204], "rig": 1860, "insist": 1860, "lr_schedul": [1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 2157, 2204], "chainabl": [1861, 1867, 1872, 1874, 1875], "081": 1861, "729": [1861, 1875], "6561": [1861, 2043], "59049": 1861, "scheduler1": [1861, 1875, 2157], "constantlr": [1861, 1875], "total_it": [1861, 1862, 1869, 1873, 1875], "scheduler2": [1861, 1875, 2157], "exponentiallr": [1861, 1875, 2157, 2204], "get_last_lr": [1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878], "get_lr": [1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878], "print_lr": [1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878], "is_verbos": [1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1878], "__dict__": [1861, 1862, 1863, 1864, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1878], "last_epoch": [1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1878], "mileston": [1862, 1869, 1870, 1875, 2157], "simultan": [1862, 1863, 1869, 1870, 1876, 2127, 2166], "025": [1862, 1869], "t_max": [1863, 1877, 2157], "eta_min": [1863, 1864], "anneal": [1863, 1864, 1872, 1878, 2157], "cur": [1863, 1864], "sgdr": [1863, 1864], "2k": 1863, "sole": [1863, 2173], "t_mult": 1864, "base_lr": [1865, 1872], "max_lr": [1865, 1872], "step_size_up": 1865, "step_size_down": 1865, "scale_fn": 1865, "scale_mod": 1865, "cycle_momentum": [1865, 1872], "base_momentum": [1865, 1872], "max_momentum": [1865, 1872], "cyclic": 1865, "amplitud": [1865, 1872], "triangular2": 1865, "exp_rang": 1865, "bckenstler": 1865, "train_batch": [1865, 1872], "lr_lambda": [1868, 1871, 1878], "lambda1": 1868, "lambda2": 1868, "start_factor": 1869, "end_factor": 1869, "03125": 1869, "0375": 1869, "04375": 1869, "005": [1870, 1876], "lmbda": 1871, "total_step": 1872, "steps_per_epoch": 1872, "pct_start": 1872, "anneal_strategi": [1872, 1878, 2157], "div_factor": 1872, "final_div_factor": 1872, "three_phas": 1872, "1cycl": 1872, "fastai": 1872, "unpublish": 1872, "initial_lr": 1872, "min_lr": [1872, 1874], "1e4": 1872, "annihil": 1872, "00075": 1873, "00050": 1873, "00025": 1873, "patienc": 1874, "threshold_mod": 1874, "cooldown": 1874, "stagnat": 1874, "new_lr": 1874, "baselin": 1874, "intoler": 1874, "optimum": 1874, "dynamic_threshold": 1874, "val_loss": 1874, "81": 1875, "recursive_undo": 1875, "sched": [1875, 2204], "undo": 1875, "swa_util": [1877, 1878, 2157], "avg_fn": [1877, 2157], "multi_avg_fn": [1877, 2157], "use_buff": 1877, "swa": [1877, 1878], "ema": 1877, "optima": [1877, 2157], "pavel": 1877, "izmailov": 1877, "dmitrii": 1877, "podoprikhin": 1877, "timur": 1877, "garipov": 1877, "dmitri": 1877, "vetrov": 1877, "gordon": 1877, "wilson": 1877, "uai": 1877, "polyak": [1877, 2157], "swa_model": [1877, 2157], "cosineannealinglr": [1877, 2157], "swa_start": [1877, 1878, 2157], "swa_schedul": [1877, 1878, 2157], "swalr": [1877, 2157], "swa_lr": [1877, 1878, 2157], "update_paramet": [1877, 2157], "update_bn": [1877, 2157], "ema_model": [1877, 2157], "get_ema_multi_avg_fn": [1877, 2157], "n_averag": 1877, "anneal_epoch": [1878, 2157], "averagedmodel": [1878, 2157], "annealing_epoch": 1878, "annealing_strategi": 1878, "multiplicativelr": 1878, "mn": 1880, "pca": [1882, 2171], "overestim": [1882, 1995], "nathan": [1882, 1995], "halko": [1882, 1995], "gunnar": [1882, 1995], "martinsson": [1882, 1995], "tropp": [1882, 1995], "probabilist": [1882, 1995], "0909": [1882, 1995], "4061": [1882, 1995], "na": [1882, 1995], "cmath": [1886, 2094], "4142j": 1886, "4331": 1889, "2475": [1889, 1993], "6834": 1889, "2791": 1889, "1875": 1889, "5561": 1889, "4670": 1889, "_dtype": 1890, "8020": 1890, "5428": 1890, "5854": 1890, "5261": [1890, 1994], "1857": 1890, "2498": 1890, "1646": [1890, 2130], "0705": [1890, 2133], "0629": 1890, "2962": 1890, "0821": [1890, 1949], "1831": 1890, "type1": [1891, 2094], "type2": [1891, 2094], "2117": 1893, "9765": 1893, "1707": 1893, "4884": 1893, "5661": 1893, "5795": 1893, "5280": 1893, "9206": 1893, "quantization_schem": [1894, 1895, 1896, 1897, 1898], "int_repr": [1894, 1895, 2094, 2155], "nchw": [1896, 2176], "qx": [1896, 1897, 1898], "00001": 1896, "max_pool1d": [1897, 2094, 2155, 2163], "quasirandom": 1899, "scrambl": 1899, "sobol": 1899, "quasi": 1899, "21201": 1899, "web": [1899, 2204], "unsw": 1899, "au": [1899, 2158], "fkuo": 1899, "art": 1899, "owen": 1899, "niederreit": 1899, "xing": 1899, "466": 1899, "489": 1899, "decemb": 1899, "1998": 1899, "zh": 1899, "vychisl": 1899, "phy": 1899, "784": 1899, "802": 1899, "1967": 1899, "soboleng": 1899, "draw_base2": 1899, "base2": 1899, "fast_forward": 1899, "142": 1900, "283": 1900, "570": 1900, "359": 1900, "9894": 1900, "2503": 1901, "3525": 1901, "5673": 1901, "8237": 1901, "5781": 1901, "6879": 1901, "3816": 1901, "7249": 1901, "0998": 1901, "im": [1905, 2127], "1436": 1905, "9966": 1905, "3426": 1905, "6366": 1905, "5954": 1905, "8929": 1905, "0923": 1905, "1719": 1905, "4709": 1905, "1996": 1905, "4595": 1911, "4314": 1911, "n2": 1914, "n3": 1914, "negat": [1917, 2004, 2096], "is_neg": [1917, 2094, 2155], "equidist": 1921, "inexact": 1921, "1234567": 1921, "1230": 1921, "vstack": [1922, 2094, 2155, 2171], "0370": 1923, "2970": 1923, "5420": 1923, "9105": 1923, "8351": 1923, "pickle_protocol": [1924, 2158], "_use_new_zipfile_seri": [1924, 2147], "zipfil": [1924, 2158], "sorted_sequ": [1928, 2094], "sorter": [1928, 2094], "sorted_sequence_1d": 1928, "select_copi": [1930, 2094, 2155], "92701": [1932, 2174], "get_default_devic": 1932, "henry2019": 1936, "nine": 1936, "fma": 1936, "10x": [1936, 1995], "1904": 1936, "06376": 1936, "denorm": [1937, 2145], "sse3": 1937, "aarch64": 1937, "323": 1937, "88131e": 1937, "324": 1937, "interop": 1938, "intraop": 1939, "edgeitem": 1940, "linewidth": 1940, "sci_mod": 1940, "shamelessli": 1940, "repr": [1940, 2096], "sane": 1940, "_tensor_str": 1940, "_formatt": 1940, "12345": 1940, "1235": 1940, "excess": [1942, 2195, 2204], "24j": 1943, "8000j": 1943, "9600j": 1943, "4472": [1943, 2142], "8944j": 1943, "expit": [1944, 2172], "2222": [1946, 2011], "4444": 1946, "8889": 1946, "4901e": 1947, "4000e": 1947, "0077e": 1947, "4923e": 1947, "waveform": [1948, 1949, 1950], "1564": 1948, "4540": 1948, "8910": 1948, "9877": 1948, "1423": [1948, 1971], "4154": 1948, "8413": [1948, 2172], "0302": 1949, "2231": 1949, "6065": 1949, "5400e": 1949, "3546e": 1949, "4788e": 1949, "8316e": 1949, "02": [1949, 1950, 1955], "3534e": 1949, "0065e": [1950, 1955], "1875e": [1950, 1955], "3937e": [1950, 1955], "2465e": [1950, 1955], "8250e": [1950, 1955], "9858e": [1950, 1955], "1365e": [1950, 1955], "8659e": [1950, 1955], "4658e": [1950, 1955], "3941e": [1950, 1955], "5400": 1951, "3376": 1951, "4200": 1951, "9136": 1951, "wit": [1951, 2093], "0955": [1951, 1952, 1954], "3455": [1951, 1952, 1954], "6545": [1951, 1952, 1954], "9045": [1951, 1952, 1954], "0800": [1952, 1953], "1876": [1952, 1953], "4601": [1952, 1953], "7700": [1952, 1953], "9723": [1952, 1953], "1679": 1953, "3979": 1953, "6821": 1953, "9121": 1953, "1170": 1954, "9698": 1954, "36358": 1956, "z_n": [1956, 2127], "48917": 1956, "2z_n": 1956, "13659": 1956, "3z_n": 1956, "01064": 1956, "4z_n": 1956, "sidelob": 1956, "transact": 1956, "acoust": 1956, "speech": 1956, "84": 1956, "91": 1956, "feb": 1956, "1981": 1956, "tassp": 1956, "1163506": 1956, "heinzel": 1956, "spectrum": [1956, 2145, 2208], "dft": 1956, "februari": 1956, "holomet": 1956, "fnal": 1956, "gov": 1956, "gh_fft": 1956, "nutal": 1956, "general_ham": 1956, "6280e": 1956, "2698e": 1956, "1052e": 1956, "9826e": 1956, "5461": [1958, 2142], "1347": 1958, "7266": 1958, "2746": 1958, "5194": 1958, "1343": 1958, "4032": 1958, "2711": 1958, "5380": 1960, "8632": 1960, "1265": 1960, "9399": 1960, "5644": 1960, "9744": 1960, "1268": 1960, "2162": 1965, "6719": 1965, "3332": 1965, "5793": [1965, 2142], "0061": 1965, "6058": 1965, "9497": 1965, "5071": 1965, "3343": 1965, "9553": 1965, "0960": 1965, "derivati": [1966, 1970], "to_sparse_coo": 1967, "sparsr": 1968, "run_my_model": 1968, "prev_checks_en": 1968, "check_invari": [1968, 1976, 1977, 1978, 1979, 1980, 1981, 2171], "z_": [1970, 2127, 2172], "bigoplus_": 1970, "kj": 1970, "bigoplu": 1970, "sparseaddmmbackward0": 1970, "y1": [1970, 2189], "sparsemmreduceimplbackward0": 1970, "y2": [1970, 2189], "sparsiti": [1971, 2103, 2122, 2124], "spy": 1971, "2847": 1971, "7805": 1971, "1900": [1971, 2146], "to_dens": [1971, 1973, 2094, 2122, 2155, 2171], "3903": 1971, "x_k": 1972, "6438": 1975, "6467": 1975, "3411": 1975, "0918": 1975, "5348": 1975, "0634": 1975, "0494": 1975, "0646": 1975, "1844": 1975, "1276": 1975, "1874": 1975, "6334": 1975, "9682": 1975, "5340": 1975, "7483": 1975, "4512": 1975, "4073": 1975, "8901": 1975, "3183": 1975, "7539": 1975, "6596": 1975, "ncolblock": [1976, 2171], "array_list": [1976, 1977, 1978, 1980, 1981], "nrow": [1976, 1977, 1978, 1980, 1981, 2171], "ncol": [1976, 1977, 1978, 1980, 1981, 2171], "denses": [1976, 1977, 1978, 1980, 1981, 2171], "check_sparse_tensor_invari": [1976, 1977, 1978, 1979, 1980, 1981, 2171], "nrowblock": [1977, 2171], "compressed_indic": [1978, 2094, 2171], "plain_indic": [1978, 2094, 2171], "compressed_dim_s": [1978, 2171], "is_coalesc": [1979, 2094, 2155, 2171], "rdinat": 1979, "prerequisit": [1979, 2132], "coalescion": 1979, "sparsetensor": 1979, "_indic": [1979, 2155, 2171, 2195], "0755": [1983, 1984], "0226": [1983, 1984], "0831": [1983, 1984], "4806": [1983, 1984], "0112": 1983, "2883": 1983, "6933": 1983, "0457": 1984, "0069": 1984, "2310": 1984, "2345": [1987, 2021], "1229": 1987, "1863": 1987, "2959": [1988, 1989, 2040, 2041], "8101": [1988, 1989, 2040, 2041], "5027": [1988, 1989, 2040, 2041], "3270": [1988, 1989, 2040, 2041], "5905": [1988, 1989, 2040, 2041], "6538": [1988, 1989, 2040, 2041, 2142], "3330": [1988, 1989, 2040, 2041], "5596": [1988, 1989, 2040, 2041], "6548": [1988, 1989, 2040, 2041], "1264": [1988, 1989, 2040, 2041], "5080": [1988, 1989, 1994, 2040, 2041, 2142], "6420": [1988, 1989, 2040, 2041], "1992": [1988, 1989, 2040, 2041], "0311": [1988, 2172], "7477": 1988, "2204": 1988, "9087": 1988, "2620": 1989, "0028": [1989, 2017], "0957": 1989, "6038": 1989, "0645": [1989, 2041], "4485": [1989, 2041], "8707": [1989, 2041], "0665": [1989, 2041], "taper": 1990, "librosa": 1990, "omega": 1990, "win": [1990, 2127], "_fft": [1990, 2094], "1133": 1993, "2958": 1993, "5475": 1993, "0569": 1993, "0737": 1993, "3429": 1993, "9138": 1993, "9337": 1993, "6864": [1993, 2021], "1132": 1993, "7892": 1993, "1003": 1993, "5688": 1993, "3637": 1993, "9906": 1993, "5197": 1993, "4598": 1993, "3708": 1993, "6217": 1993, "435": 1993, "1335": 1993, "3135": 1993, "gesdd": 1994, "conquer": 1994, "gesvdjbatch": 1994, "fortran": 1994, "2364": 1994, "7752": 1994, "7201": 1994, "7394": 1994, "0504": 1994, "3371": 1994, "5296": 1994, "3550": 1994, "5569": 1994, "2445": 1994, "1414": 1994, "4027": 1994, "0287": 1994, "5434": 1994, "1946": 1994, "8833": 1994, "3679": 1994, "4296": 1994, "2890": 1994, "6604": 1994, "2717": 1994, "2618": 1994, "4234": 1994, "2481": 1994, "4733": 1994, "3289": [1994, 2147], "0315": 1994, "7806": 1994, "0199": 1994, "8766": 1994, "4809": 1994, "4054": 1994, "7600": 1994, "8611": 1994, "2594": 1994, "4373": 1994, "6531e": 1994, "a_big": 1994, "6503e": 1994, "adequ": 1995, "choosen": 1995, "swapax": [1997, 2094, 2155, 2175], "faithfulli": [2002, 2104, 2191], "1995": 2006, "4608": 2006, "7702": 2006, "4875": 2006, "9158": 2006, "5872": 2006, "6929": 2006, "6932": 2006, "take_along_axi": [2008, 2134], "max_idx": 2008, "sorted_idx": 2008, "2027": 2009, "7687": 2009, "4412": 2009, "3856": 2009, "5930": 2009, "9859": 2009, "4722": 2009, "3366": 2009, "8986": 2010, "7279": 2010, "1745": [2010, 2133], "7156": 2010, "8257": 2010, "2553": 2010, "11111": 2011, "222222": 2011, "3333333": 2011, "1111": 2011, "array_split": 2012, "i_d": 2013, "k_": 2013, "4532": 2013, "4874": 2013, "5018": 2013, "4796": [2013, 2146], "5162": 2013, "5306": 2013, "2922": 2013, "7556": 2013, "2741": 2013, "3161": 2013, "0704": 2013, "0187": 2013, "4079": 2013, "3126": 2013, "8744": 2013, "8223": 2013, "9445": 2013, "4117": 2013, "7780": 2013, "7193": 2013, "4867": 2013, "3204": 2013, "5513": 2013, "4737": [2013, 2044], "2850": 2013, "2573": 2013, "5997": 2013, "sparsebsr": 2017, "sparsecsc": 2017, "sparsebsc": 2017, "9893": 2017, "5809": 2017, "1669": 2017, "7299": 2017, "4942": [2017, 2142], "y_0": 2018, "x_diff": 2018, "y_diff": 2018, "riemann": [2018, 2127, 2138, 2172], "badli": 2020, "cloned_coeffici": 2020, "1527": 2020, "0753": 2020, "7986": 2020, "0210": 2020, "3513": 2020, "5492": 2020, "7403": 2020, "0243": 2020, "7841": 2020, "9046": 2020, "5405": 2020, "9320": 2020, "9270": 2020, "2826": 2020, "lbrace": [2021, 2022, 2023, 2024], "rbrace": [2021, 2022, 2023, 2024], "0813": 2021, "8619": 2021, "7105": 2021, "0935": 2021, "1380": 2021, "3409": [2021, 2146], "2219": 2021, "5653": 2021, "2521": 2021, "2544": 2021, "3461": 2021, "4785": 2021, "4477": 2021, "6049": 2021, "6368": 2021, "8775": 2021, "7145": 2021, "1502": 2021, "2716": 2021, "1243": 2021, "5413": 2021, "3615": 2021, "0614": 2021, "7344": 2021, "3164": 2021, "7648": 2021, "4024": 2021, "0978": 2021, "2309": 2023, "5207": 2023, "0049": 2023, "2072": 2023, "0680": 2023, "6602": 2023, "3480": 2023, "5211": 2023, "4573": 2023, "5876": 2023, "0794": [2023, 2172], "8373": 2023, "6654": 2023, "2604": 2023, "5235": 2023, "2447": 2023, "9556": 2023, "2919": 2023, "1768": 2023, "4333": 2023, "3146": [2023, 2142], "6576": 2023, "0432": 2023, "9348": [2023, 2172], "4410": 2023, "9888": 2023, "3337": 2023, "6556": 2023, "4798": 2023, "5466": 2026, "8008": 2026, "9079": 2026, "unique_consecut": [2029, 2094, 2155], "inverse_indic": [2029, 2030], "a_unique_dim0": 2029, "5678": [2031, 2166], "78": 2031, "put_": [2033, 2094], "index_add": [2033, 2094, 2155], "fractionalmaxpool2d": 2033, "fractionalmaxpool3d": 2033, "reflectionpad1d": 2033, "reflectionpad3d": 2033, "replicationpad1d": 2033, "replicationpad3d": 2033, "histc": [2033, 2094, 2155], "bincount": [2033, 2094, 2155], "kthvalu": [2033, 2094, 2115, 2155], "avg_pool3d_backward_cuda": 2033, "for_tensor": 2034, "for_modul": 2034, "for_packed_sequ": 2034, "for_storag": 2034, "unsupported_dtyp": 2034, "privateuse1": [2034, 2036, 2159, 2165, 2180], "rename_privateuse1_backend": 2034, "is_foo": 2034, "frames_to_skip": 2035, "maximum_number_of_fram": 2035, "_register_device_modul": 2036, "backendmodul": 2036, "get_amp_supported_dtyp": 2036, "_is_in_bad_fork": 2036, "bad_fork": 2036, "get_rng_stat": [2036, 2165], "set_rng_stat": [2036, 2165], "extend_dispatch": 2036, "pytorch_open_registration_exampl": 2036, "nicer": 2037, "slot": [2038, 2188, 2206], "alexandr": 2039, "theophil": 2039, "0631": 2040, "5590": 2040, "4893": 2040, "8258": 2040, "5926": 2041, "0056": 2041, "3646": 2041, "vecdot": 2042, "mi": [2043, 2044], "6116": 2043, "5772": [2043, 2172], "4606": 2043, "9120": 2043, "0786": 2043, "7497": 2043, "6623": 2043, "5772j": 2043, "9120j": 2043, "7497j": 2043, "6623j": 2043, "3839j": 2044, "2098": 2044, "6699j": 2044, "3470": 2044, "9451j": 2044, "5174": 2044, "3136j": 2044, "6699": 2044, "9451": 2044, "3136": 2044, "atleast_2d": [2047, 2094, 2155], "3139": 2048, "3898": 2048, "1657": 2048, "0383": 2048, "8785": 2048, "1089": 2048, "_xpudeviceproperti": 2062, "hubconf": 2091, "entrypoint_nam": 2091, "_resnet18": 2091, "smoother": [2091, 2103], "load_state_dict_from_url": [2091, 2107], "2gb": [2091, 2150, 2154], "relative_path_to_checkpoint": 2091, "pth": [2091, 2107, 2137, 2147], "dirnam": 2091, "__file__": [2091, 2148, 2158, 2197], "5c106cde": [2091, 2107], "force_reload": 2091, "skip_valid": 2091, "trust_repo": 2091, "repo_own": 2091, "repo_nam": 2091, "ref": [2091, 2092, 2171, 2191, 2205], "torchhub": 2091, "github_token": 2091, "mute": 2091, "repo_or_dir": 2091, "resnet50": [2091, 2137, 2176, 2197], "resnet50_weight": [2091, 2137], "imagenet1k_v1": 2091, "download_url_to_fil": 2091, "hash_prefix": 2091, "temporary_fil": 2091, "sha256": [2091, 2107], "s3": [2091, 2107, 2148], "amazonaw": [2091, 2107, 2148], "model_dir": [2091, 2107], "check_hash": [2091, 2107], "hub_dir": [2091, 2107], "get_dir": [2091, 2107], "ext": [2091, 2107], "eight": [2091, 2107], "hash": [2091, 2094, 2096, 2107, 2155], "succinct": 2091, "set_dir": 2091, "path_to_hub_dir": 2091, "torch_hom": 2091, "xdg_cache_hom": [2091, 2130], "reiniti": [2091, 2104], "path_importer_cach": 2091, "subpackag": [2091, 2158], "offend": [2091, 2196], "classifi": [2092, 2096, 2154, 2157, 2161, 2176], "pypi": [2092, 2151], "conda": [2092, 2148], "genindex": 2092, "modindex": 2092, "disadvantag": 2093, "gentl": 2093, "beam": 2093, "traced_bar": 2093, "myscriptmodul": 2093, "103": [2093, 2095], "939": [2093, 2095], "116": [2093, 2095], "779": [2093, 2095], "123": [2093, 2095], "my_script_modul": [2093, 2095], "ins": 2093, "pytorch_jit": 2093, "traced_fn": 2093, "disable_jit_exampl": 2093, "printer": 2093, "rv": 2093, "rv0": 2093, "rv1": 2093, "ssa": 2093, "block0": 2093, "block1": 2093, "loop_in_traced_fn": 2093, "input_tupl": 2093, "fill_row_zero": 2093, "tracerwarn": 2093, "nr": 2093, "09115803241729736": 2093, "6782537698745728": 2093, "cpu_model": 2093, "gpu_model": 2093, "sample_input_cpu": 2093, "sample_input_gpu": 2093, "traced_cpu": 2093, "traced_gpu": 2093, "use_gpu": 2093, "__constants__": [2093, 2095], "my_module_inst": 2093, "redeclar": 2093, "nn_module_inst": 2093, "my_scripted_model": 2093, "pep": [2093, 2095, 2150, 2154, 2193], "526": [2093, 2095, 2150, 2154], "script_method": 2093, "implicitly_compiled_method": 2093, "another_forward": 2093, "unused_method": 2093, "some_fn": 2093, "some_fn2": 2093, "some_fn3": 2093, "some_fn4": 2093, "my_dict": [2093, 2095], "my_int": [2093, 2095], "my_const": 2093, "make_dict": 2093, "nnc": 2093, "nvfuser": 2093, "__and__": 2094, "__iand__": 2094, "__ilshift__": 2094, "__ior__": 2094, "__irshift__": 2094, "__ixor__": 2094, "__lshift__": 2094, "__or__": 2094, "__rshift__": 2094, "__xor__": 2094, "absolute_": 2094, "acos_": [2094, 2115], "addbmm_": 2094, "addcdiv_": 2094, "addcmul_": 2094, "addmv_": [2094, 2115], "addr_": 2094, "align_a": [2094, 2115, 2116, 2155], "align_to": [2094, 2115, 2116, 2155], "ellipsis_idx": 2094, "aminmax": [2094, 2155], "arccos_": 2094, "arccosh_": 2094, "arcsin_": [2094, 2171], "arcsinh_": 2094, "arctan2_": 2094, "arctan_": 2094, "arctanh_": 2094, "argwher": [2094, 2155], "as_strided_": 2094, "as_strided_scatt": [2094, 2155, 2199], "asin_": [2094, 2115, 2171], "asinh_": [2094, 2115], "atan_": [2094, 2115], "atanh_": [2094, 2115], "baddbmm_": 2094, "bernoulli_": [2094, 2115, 2180], "bitwise_and_": 2094, "bitwise_left_shift_": 2094, "bitwise_not_": [2094, 2115], "bitwise_or_": 2094, "bitwise_right_shift_": 2094, "bitwise_xor_": 2094, "broadcast_to": [2094, 2155], "cauchy_": [2094, 2115, 2180], "ceil_": [2094, 2115], "clamp_max": [2094, 2155], "clamp_max_": 2094, "clamp_min": [2094, 2155], "clamp_min_": 2094, "clip_": 2094, "conj_physical_": 2094, "copysign_": 2094, "cos_": [2094, 2115, 2127], "cosh_": [2094, 2115], "count_nonzero": [2094, 2155], "cummax": [2094, 2155], "cummin": [2094, 2155], "cumprod_": 2094, "cumsum_": 2094, "deg2rad": [2094, 2115, 2155, 2171], "deg2rad_": [2094, 2115, 2171], "outdim": 2094, "diagonal_scatt": [2094, 2155], "digamma_": [2094, 2115], "divide_": 2094, "dsplit": [2094, 2155], "eq_": 2094, "erf_": [2094, 2115], "erfc_": [2094, 2115], "erfinv_": [2094, 2115], "exp2": [2094, 2155, 2172, 2176, 2199], "exp2_": 2094, "exp_": [2094, 2115], "expm1_": [2094, 2115], "exponential_": [2094, 2115, 2180], "fill_diagonal_": 2094, "fix_": 2094, "fliplr": [2094, 2155], "flipud": [2094, 2155], "float_power_": 2094, "floor_": [2094, 2115], "floor_divide_": [2094, 2171], "fmax": [2094, 2155, 2199], "fmin": [2094, 2155, 2199], "fmod_": 2094, "frac_": [2094, 2115], "frexp": [2094, 2155, 2199], "gcd_": 2094, "ge_": 2094, "ger": [2094, 2155], "get_devic": [2094, 2115, 2155, 2171, 2173, 2174], "greater_": 2094, "greater_equal_": 2094, "gt_": 2094, "hardshrink": [2094, 2155], "heavisid": [2094, 2155], "heaviside_": 2094, "hsplit": [2094, 2155, 2175], "hypot_": 2094, "i0_": 2094, "igamma_": 2094, "igammac_": 2094, "index_fil": [2094, 2115, 2155], "index_reduc": [2094, 2155], "is_complex": [2094, 2155, 2171, 2174], "is_contigu": [2094, 2115, 2117, 2155, 2175], "is_floating_point": [2094, 2115, 2155, 2171, 2174], "is_infer": [2094, 2155], "is_same_s": [2094, 2155, 2171], "is_set_to": [2094, 2155], "is_sign": [2094, 2115, 2155, 2171], "isclos": [2094, 2155], "isfinit": [2094, 2145, 2155, 2199], "isinf": [2094, 2155, 2171, 2199], "isneginf": [2094, 2155, 2171], "isposinf": [2094, 2155, 2171], "isreal": [2094, 2155], "istft": [2094, 2155], "kron": [2094, 2155], "lcm_": 2094, "ldexp_": 2094, "le_": 2094, "lerp_": 2094, "less_": 2094, "less_equal_": 2094, "lgamma_": 2094, "log10_": [2094, 2115], "log1p_": [2094, 2115, 2171], "log2_": [2094, 2115], "log_normal_": [2094, 2115, 2180], "logaddexp2": [2094, 2155], "logcumsumexp": [2094, 2155], "logical_and_": 2094, "logical_not_": [2094, 2115], "logical_or_": 2094, "logical_xor_": 2094, "logit_": 2094, "lt_": 2094, "masked_fil": [2094, 2115, 2155, 2171], "masked_scatt": [2094, 2155, 2199], "masked_select": [2094, 2115, 2117, 2155], "matrix_pow": [2094, 2155], "moveaxi": [2094, 2155], "msort": [2094, 2155], "multinomi": [2094, 2155, 2189], "multiply_": 2094, "mvlgamma_": 2094, "nan_to_num_": 2094, "nanmedian": [2094, 2115, 2155], "nansum": [2094, 2155], "narrow_copi": [2094, 2155, 2171], "ne_": 2094, "neg_": [2094, 2115, 2171], "negative_": [2094, 2171], "new_empty_strid": [2094, 2155], "new_ful": [2094, 2130, 2155], "new_on": [2094, 2155], "nextafter_": 2094, "nonzero_stat": [2094, 2155], "normal_": [2094, 2115, 2124, 2130, 2180], "not_equal_": 2094, "polygamma_": 2094, "pow_": [2094, 2115], "q_per_channel_scal": [2094, 2155], "q_per_channel_zero_point": [2094, 2155], "q_scale": [2094, 2155], "q_zero_point": [2094, 2155], "rad2deg": [2094, 2115, 2155, 2171], "rad2deg_": [2094, 2115, 2171], "reciprocal_": [2094, 2115], "refine_nam": [2094, 2115, 2116, 2155], "relu_": [2094, 2163], "remainder_": 2094, "rename_": [2094, 2115, 2116], "renorm_": 2094, "reshape_a": [2094, 2155, 2175], "resize_a": [2094, 2155], "the_templ": 2094, "resize_as_": [2094, 2115, 2171], "resize_as_sparse_": 2094, "retains_grad": [2094, 2155], "roll": [2094, 2155], "rot90": [2094, 2155], "round_": [2094, 2115], "rsqrt_": [2094, 2115], "select_scatt": [2094, 2155, 2199], "sgn_": [2094, 2115], "sigmoid_": [2094, 2115, 2163], "sign_": [2094, 2115], "sinc_": 2094, "sinh_": [2094, 2115], "slice_invers": [2094, 2155], "slice_scatt": [2094, 2155, 2199], "smm": [2094, 2155, 2171], "sparse_resize_": 2094, "sparse_resize_and_clear_": 2094, "split_with_s": [2094, 2155, 2175, 2199], "sqrt_": [2094, 2115], "square_": 2094, "squeeze_": [2094, 2163], "sspaddmm": [2094, 2155, 2171], "sub_": [2094, 2115, 2171], "subtract_": 2094, "sum_to_s": [2094, 2155], "swapaxes_": 2094, "swapdim": [2094, 2155, 2175], "swapdims_": 2094, "take_along_dim": [2094, 2155], "tan_": [2094, 2115], "tanh_": [2094, 2115, 2163], "tensor_indices_or_sect": 2094, "to_mkldnn": [2094, 2155], "to_padded_tensor": [2094, 2117, 2155], "to_sparse_bsc": [2094, 2155], "to_sparse_bsr": [2094, 2155, 2171], "to_sparse_csc": [2094, 2155, 2171], "transpose_": [2094, 2171], "true_divide_": 2094, "trunc_": [2094, 2115], "type_a": [2094, 2115, 2155], "out0": [2094, 2147], "unsafe_chunk": [2094, 2155], "unsafe_split": [2094, 2155], "unsafe_split_with_s": [2094, 2155], "unsqueeze_": [2094, 2163], "view_a": [2094, 2155, 2175], "vsplit": [2094, 2155, 2175], "xlogy_": 2094, "adaptive_avg_pool2d": [2094, 2133, 2155, 2163], "adaptive_max_pool1d_with_indic": [2094, 2133], "adaptive_max_pool2d_with_indic": 2094, "adaptive_max_pool3d_with_indic": 2094, "alpha_dropout": [2094, 2155], "assert_int_or_pair": 2094, "arg_nam": 2094, "nonetyp": [2094, 2096], "binary_cross_entropi": [2094, 2155], "binary_cross_entropy_with_logit": [2094, 2155], "celu": [2094, 2155], "dropout2d": 2094, "dropout3d": 2094, "feature_alpha_dropout": [2094, 2155], "fractional_max_pool2d_with_indic": 2094, "fractional_max_pool3d_with_indic": 2094, "gaussian_nll_loss": 2094, "glu": [2094, 2155], "gumbel_softmax": 2094, "hardsigmoid": [2094, 2155, 2163], "hardswish": [2094, 2155, 2163], "instance_norm": [2094, 2155, 2163], "local_response_norm": 2094, "lp_pool1d": 2094, "lp_pool2d": 2094, "lp_pool3d": 2094, "max_pool1d_with_indic": [2094, 2155], "max_pool2d_with_indic": [2094, 2155, 2199], "max_pool3d_with_indic": [2094, 2155, 2199], "mish": [2094, 2155], "multi_head_attention_forward": 2094, "embed_dim_to_check": 2094, "in_proj_weight": 2094, "in_proj_bia": 2094, "bias_k": 2094, "bias_v": 2094, "out_proj_weight": 2094, "out_proj_bia": 2094, "use_separate_proj_weight": 2094, "q_proj_weight": 2094, "k_proj_weight": 2094, "v_proj_weight": 2094, "static_k": 2094, "static_v": 2094, "multilabel_soft_margin_loss": 2094, "relu6": [2094, 2155, 2163], "silu": [2094, 2155, 2189], "softsign": 2094, "tanhshrink": 2094, "adaptive_avg_pool1d": [2094, 2133, 2155, 2163, 2199], "adaptive_max_pool1d": [2094, 2133, 2155], "affine_grid_gener": [2094, 2155], "alias_copi": [2094, 2155], "align_tensor": [2094, 2155], "alpha_dropout_": 2094, "as_strided_copi": [2094, 2155], "atleast_1d": [2094, 2155], "avg_pool1d": [2094, 2155, 2163, 2199], "bartlett_window": [2094, 2098, 2155], "cudnn_en": 2094, "batch_norm_backward_elemt": 2094, "invstd": 2094, "sum_di": 2094, "sum_dy_xmu": 2094, "batch_norm_backward_reduc": 2094, "input_g": 2094, "bias_g": 2094, "out3": 2094, "batch_norm_elemt": [2094, 2155], "batch_norm_gather_stat": [2094, 2155], "batch_norm_gather_stats_with_count": [2094, 2155], "batch_norm_stat": [2094, 2155], "batch_norm_update_stat": [2094, 2155], "binomi": [2094, 2155], "blackman_window": [2094, 2098, 2155], "block_diag": [2094, 2155], "can_cast": [2094, 2155], "ccol_indices_copi": [2094, 2155], "celu_": 2094, "choose_qparams_optim": [2094, 2155], "n_bin": 2094, "bit_width": 2094, "col_indices_copi": [2094, 2155], "column_stack": [2094, 2155], "constant_pad_nd": [2094, 2155, 2199], "crow_indices_copi": [2094, 2155], "cudnn_affine_grid_gener": [2094, 2155], "cudnn_batch_norm": [2094, 2155], "exponential_average_factor": 2094, "cudnn_convolut": [2094, 2155], "cudnn_convolution_add_relu": [2094, 2155], "cudnn_convolution_relu": [2094, 2155], "cudnn_convolution_transpos": [2094, 2155], "cudnn_grid_sampl": [2094, 2155], "cudnn_is_accept": [2094, 2155], "cumulative_trapezoid": [2094, 2155], "detach_copi": [2094, 2155, 2203], "diagonal_copi": [2094, 2155], "dropout_": [2094, 2106], "embedding_renorm_": 2094, "physical_layout": [2094, 2199], "empty_quant": [2094, 2155], "anyenumtyp": 2094, "expand_copi": [2094, 2155], "fake_quantize_per_channel_affin": [2094, 2155], "fbgemm_linear_fp16_weight": [2094, 2155], "packed_weight": 2094, "fbgemm_linear_fp16_weight_fp32_activ": [2094, 2155], "fbgemm_linear_int8_weight": [2094, 2155], "col_offset": 2094, "weight_scal": 2094, "weight_zero_point": 2094, "fbgemm_linear_int8_weight_fp32_activ": [2094, 2155], "fbgemm_linear_quantize_weight": [2094, 2155], "fbgemm_pack_gemm_matrix_fp16": [2094, 2155], "fbgemm_pack_quantized_matrix": [2094, 2155], "feature_alpha_dropout_": 2094, "feature_dropout": [2094, 2155], "feature_dropout_": 2094, "frobenius_norm": [2094, 2155], "from_fil": [2094, 2155, 2173], "fused_moving_avg_obs_fake_qu": [2094, 2155], "observer_on": 2094, "fake_quant_on": 2094, "running_min": 2094, "running_max": 2094, "per_row_fake_qu": 2094, "symmetric_qu": 2094, "interpolation_mod": [2094, 2199], "has_bias": 2094, "gru_cel": [2094, 2155], "w_ih": 2094, "w_hh": 2094, "hamming_window": [2094, 2098, 2155], "histogramdd": [2094, 2155], "hspmm": [2094, 2155, 2171], "indices_copi": [2094, 2155], "is_autocast_cpu_en": [2094, 2155], "is_autocast_en": [2094, 2155], "is_grad_en": [2094, 2155], "is_vulkan_avail": [2094, 2155], "isin": [2094, 2155], "kaiser_window": [2094, 2155], "lstm_cell": [2094, 2155], "meshgrid": [2094, 2155], "miopen_batch_norm": [2094, 2155], "miopen_convolut": [2094, 2155], "miopen_convolution_add_relu": [2094, 2155], "miopen_convolution_relu": [2094, 2155], "miopen_convolution_transpos": [2094, 2155], "miopen_depthwise_convolut": [2094, 2155], "miopen_rnn": [2094, 2155], "weight_stride0": 2094, "dropout_st": 2094, "out4": 2094, "mkldnn_adaptive_avg_pool2d": [2094, 2155], "mkldnn_convolut": [2094, 2155], "mkldnn_linear_backward_weight": 2094, "bias_defin": 2094, "mkldnn_max_pool2d": [2094, 2155], "mkldnn_max_pool3d": [2094, 2155], "weight0": 2094, "weight1": 2094, "weight2": 2094, "weight3": 2094, "hx_": 2094, "cx_": 2094, "native_batch_norm": [2094, 2155], "save_mean": 2094, "save_invstd": 2094, "native_channel_shuffl": [2094, 2155], "native_dropout": [2094, 2155, 2199], "native_group_norm": [2094, 2155, 2199], "hxw": [2094, 2199], "native_layer_norm": [2094, 2155, 2199], "native_norm": [2094, 2155, 2171], "norm_except_dim": [2094, 2155], "nuclear_norm": [2094, 2155], "pairwise_dist": [2094, 2155], "permute_copi": [2094, 2155], "promote_typ": [2094, 2155, 2178], "quantize_per_channel": [2094, 2155, 2161], "quantize_per_tensor_dynam": [2094, 2155, 2161], "quantized_batch_norm": [2094, 2155], "quantized_gru_cel": [2094, 2155], "packed_ih": 2094, "packed_hh": 2094, "col_offsets_ih": 2094, "col_offsets_hh": 2094, "scale_ih": 2094, "scale_hh": 2094, "zero_point_ih": 2094, "zero_point_hh": 2094, "quantized_lstm_cel": [2094, 2155], "quantized_max_pool1d": [2094, 2155], "quantized_max_pool2d": [2094, 2155], "quantized_max_pool3d": [2094, 2155], "quantized_rnn_relu_cel": [2094, 2155], "quantized_rnn_tanh_cel": [2094, 2155], "rand_lik": [2094, 2098, 2130, 2155, 2180, 2189], "randint_lik": [2094, 2098, 2155, 2180], "randn_lik": [2094, 2098, 2155, 2180], "randperm": [2094, 2098, 2155, 2180, 2199], "result_typ": [2094, 2155], "scalar1": 2094, "scalar2": 2094, "rnn_relu": [2094, 2155], "rnn_relu_cel": [2094, 2155], "rnn_tanh": [2094, 2155], "rnn_tanh_cel": [2094, 2155], "row_indices_copi": [2094, 2155], "row_stack": [2094, 2155], "rrelu_": 2094, "rsub": [2094, 2155], "scalar_tensor": [2094, 2155, 2199], "searchsort": [2094, 2155], "segment_reduc": [2094, 2155], "selu_": 2094, "slice_copi": [2094, 2155], "sparse_bsc_tensor": [2094, 2155, 2171], "sparse_bsr_tensor": [2094, 2155, 2171], "sparse_compressed_tensor": [2094, 2155, 2171], "sparse_csc_tensor": [2094, 2155, 2171], "split_copi": [2094, 2155], "split_with_sizes_copi": [2094, 2155], "squeeze_copi": [2094, 2155], "std_mean": [2094, 2115, 2155], "sym_constrain_rang": [2094, 2155], "t_copi": [2094, 2155], "threshold_": 2094, "transpose_copi": [2094, 2155], "trapz": [2094, 2155], "tril_indic": [2094, 2098, 2155], "triu_indic": [2094, 2098, 2155], "unbind_copi": [2094, 2155], "unfold_copi": [2094, 2155], "unsqueeze_copi": [2094, 2155], "values_copi": [2094, 2155], "vander": [2094, 2098, 2155], "var_mean": [2094, 2115, 2155], "view_as_complex_copi": [2094, 2155], "view_as_real_copi": [2094, 2155], "_nn": 2094, "adaptive_max_pool2d": [2094, 2155], "avg_pool2d": [2094, 2155, 2163, 2199], "conv_depthwise3d": [2094, 2155], "input_scal": [2094, 2199], "elu_": 2094, "flatten_dense_tensor": [2094, 2155], "random_sampl": 2094, "gelu_": 2094, "hardsigmoid_": [2094, 2163], "hardswish_": 2094, "hardtanh_": [2094, 2163], "leaky_relu_": 2094, "log_sigmoid": [2094, 2155], "mish_": 2094, "mkldnn_linear": [2094, 2155], "mkldnn_reorder_conv2d_weight": [2094, 2155], "mkldnn_reorder_conv3d_weight": [2094, 2155], "nll_loss_nd": [2094, 2155], "reflection_pad3d": [2094, 2155, 2199], "relu6_": 2094, "rrelu_with_nois": [2094, 2155], "rrelu_with_noise_": 2094, "silu_": 2094, "slow_conv3d": [2094, 2155], "slow_conv_dilated2d": [2094, 2155], "slow_conv_dilated3d": [2094, 2155], "slow_conv_transpose2d": [2094, 2155], "slow_conv_transpose3d": [2094, 2155], "softshrink": [2094, 2155], "thnn_conv2d": [2094, 2155], "unflatten_dense_tensor": [2094, 2155], "upsample_bicubic2d": [2094, 2155], "scales_h": 2094, "scales_w": 2094, "upsample_bilinear2d": [2094, 2155, 2199], "upsample_linear1d": [2094, 2155], "upsample_nearest1d": [2094, 2155], "upsample_nearest2d": [2094, 2155, 2199], "upsample_nearest3d": [2094, 2155], "scales_d": 2094, "upsample_trilinear3d": [2094, 2155], "fft_fftfreq": [2094, 2155], "fft_fftshift": [2094, 2155], "fft_hfft2": [2094, 2155], "fft_hfftn": [2094, 2155], "fft_ifftshift": [2094, 2155], "fft_ihfft2": [2094, 2155], "fft_ihfftn": [2094, 2155], "fft_rfftfreq": [2094, 2155], "_linalg": 2094, "linalg_cross": [2094, 2155], "linalg_det": [2094, 2155], "linalg_diagon": [2094, 2155], "eigvec": 2094, "linalg_ldl_factor": [2094, 2155], "linalg_ldl_factor_ex": [2094, 2155], "linalg_ldl_solv": [2094, 2155], "linalg_lu": [2094, 2155], "linalg_lu_factor": [2094, 2155], "linalg_lu_factor_ex": [2094, 2155], "linalg_lu_solv": [2094, 2155], "linalg_matmul": [2094, 2155], "linalg_matrix_exp": [2094, 2155], "linalg_matrix_norm": [2094, 2155], "linalg_matrix_pow": [2094, 2155], "linalg_multi_dot": [2094, 2155], "linalg_norm": [2094, 2155], "linalg_pinv": [2094, 2155], "linalg_solve_ex": [2094, 2155], "linalg_solve_triangular": [2094, 2155], "linalg_vand": [2094, 2155], "linalg_vector_norm": [2094, 2155], "_nest": 2094, "nested_to_padded_tensor": [2094, 2155], "_spars": 2094, "sparse_sampled_addmm": [2094, 2155], "_special": 2094, "special_airy_ai": [2094, 2155], "special_bessel_j0": [2094, 2155], "special_bessel_j1": [2094, 2155], "special_bessel_y0": [2094, 2155], "special_bessel_y1": [2094, 2155], "special_chebyshev_polynomial_t": [2094, 2155], "special_chebyshev_polynomial_u": [2094, 2155], "special_chebyshev_polynomial_v": [2094, 2155], "special_chebyshev_polynomial_w": [2094, 2155], "special_digamma": [2094, 2155], "special_entr": [2094, 2155], "special_erf": [2094, 2155], "special_erfc": [2094, 2155], "special_erfcx": [2094, 2155], "special_erfinv": [2094, 2155], "special_exp2": [2094, 2155], "special_expit": [2094, 2155], "special_expm1": [2094, 2155], "special_gammainc": [2094, 2155], "special_gammaincc": [2094, 2155], "special_gammaln": [2094, 2155], "special_hermite_polynomial_h": [2094, 2155], "special_i0": [2094, 2155], "special_i1": [2094, 2155], "special_laguerre_polynomial_l": [2094, 2155], "special_legendre_polynomial_p": [2094, 2155], "special_log1p": [2094, 2155], "special_log_ndtr": [2094, 2155], "special_log_softmax": [2094, 2155], "special_logit": [2094, 2155], "special_logsumexp": [2094, 2155], "special_modified_bessel_i0": [2094, 2155], "special_modified_bessel_i1": [2094, 2155], "special_modified_bessel_k0": [2094, 2155], "special_modified_bessel_k1": [2094, 2155], "special_multigammaln": [2094, 2155], "special_ndtr": [2094, 2155], "special_ndtri": [2094, 2155], "special_polygamma": [2094, 2155], "special_psi": [2094, 2155], "special_round": [2094, 2155], "special_scaled_modified_bessel_k0": [2094, 2155], "special_scaled_modified_bessel_k1": [2094, 2155], "special_shifted_chebyshev_polynomial_t": [2094, 2155], "special_shifted_chebyshev_polynomial_u": [2094, 2155], "special_shifted_chebyshev_polynomial_v": [2094, 2155], "special_shifted_chebyshev_polynomial_w": [2094, 2155], "special_sinc": [2094, 2155], "special_softmax": [2094, 2155], "special_spherical_bessel_j0": [2094, 2155], "special_xlog1pi": [2094, 2155], "special_xlogi": [2094, 2155], "special_zeta": [2094, 2155], "tval": 2094, "is_accept": 2094, "rect": 2094, "magic": [2094, 2097, 2180, 2194], "__complex__": 2094, "__float__": 2094, "__int__": 2094, "hex": [2094, 2096, 2130, 2155, 2180], "__hex__": 2094, "oct": [2094, 2155], "__oct__": 2094, "divmod": [2094, 2096, 2155], "chr": [2094, 2096, 2155], "int_float": 2094, "float_int": 2094, "fab": [2094, 2155], "int_int": 2094, "float_float": 2094, "complex_complex": 2094, "int_complex": 2094, "complex_int": 2094, "float_complex": 2094, "complex_float": [2094, 2173], "scalar_scalar": 2094, "int_to_int": 2094, "modf": [2094, 2155], "mathremaind": [2094, 2155], "programm": [2095, 2096, 2161], "tn": 2095, "subtyp": 2095, "an_error": 2095, "noreturn": [2095, 2096], "classvar": [2095, 2096], "anystr": [2095, 2096], "nomin": 2095, "newtyp": [2095, 2096], "tup": [2095, 2096], "emptydatastructur": 2095, "my_list": 2095, "aug_add_x": 2095, "inc": [2095, 2096], "assign_x": [2095, 2096], "polymorph": 2095, "sum_pair": 2095, "red": [2095, 2096], "green": [2095, 2096, 2196, 2204], "enum_fn": [2095, 2096], "my_variable_nam": 2095, "top_level_method": 2095, "other_help": 2095, "ten": [2095, 2176], "my_submodul": 2095, "tuple_or_list": 2095, "a_tupl": 2095, "is_script": [2095, 2096, 2155], "unsupported_linear_op": 2095, "is_trac": [2095, 2096], "univers": 2095, "a_dict": 2095, "some_dict": 2095, "delimit": [2096, 2097], "tstype": 2096, "tsmoduletyp": 2096, "tsalltyp": 2096, "tsmetatyp": 2096, "tsprimitivetyp": 2096, "tsstructuraltyp": 2096, "tsnominaltyp": 2096, "myclass": [2096, 2158], "printabl": [2096, 2158], "sortabl": 2096, "nevertheless": [2096, 2168], "inc_first_el": 2096, "cpufloattyp": 2096, "tstupl": 2096, "tsnamedtupl": 2096, "tslist": 2096, "tsdict": 2096, "tsoption": 2096, "tsunion": 2096, "tsfutur": 2096, "tsrref": 2096, "tsawait": 2096, "await": [2096, 2097, 2166], "keytyp": 2096, "tensortyp": [2096, 2203], "_await": 2096, "mytupl": 2096, "scripted_inc": 2096, "_annotatednamedtupl": 2096, "_namedtupleannot": 2096, "_unannotatednamedtupl": 2096, "mistak": [2096, 2135, 2194], "nameerror": 2096, "remedi": 2096, "tsbuiltinclass": 2096, "tscustomclass": 2096, "tsenum": 2096, "tstensor": 2096, "subtensor": [2096, 2133, 2206], "subwithtorchfunct": 2096, "script_g": 2096, "tsclassdef": 2096, "methoddefinit": 2096, "__torch__": [2096, 2154], "class2": 2096, "tsenumdef": 2096, "tsenumtyp": 2096, "memberidentifi": 2096, "intenum": 2096, "intflag": 2096, "basecolor": 2096, "classbodydefinit": 2096, "moduleobj": 2096, "testmodul": 2096, "dosometh": 2096, "strateg": 2096, "congruent": 2096, "python3": 2096, "unannot": 2096, "python3annot": 2096, "paramannot": 2096, "returnannot": 2096, "funcormethodbodi": 2096, "mypyannot": 2096, "localvarannot": 2096, "setval": 2096, "moduletyp": [2096, 2158], "classidentifi": 2096, "instanceattridentifi": 2096, "offset_": 2096, "grammar": 2096, "chapter": [2096, 2138], "floattyp": 2096, "inttyp": 2096, "stringtyp": 2096, "devicetyp": 2096, "tupletyp": 2096, "listtyp": 2096, "enclosur": 2096, "parenth_form": 2096, "list_displai": 2096, "dict_displai": 2096, "stringliter": 2096, "floatnumb": 2096, "expression_list": 2096, "list_comprehens": 2096, "comp_for": 2096, "target_list": 2096, "or_expr": 2096, "key_datum_list": 2096, "dict_comprehens": 2096, "key_datum": 2096, "ongo": [2096, 2154, 2164, 2166], "enclos": 2096, "datum": [2096, 2182], "attributeref": 2096, "slice_list": 2096, "slice_item": 2096, "proper_slic": 2096, "argument_list": 2096, "desugar": [2096, 2194], "u_expr": 2096, "tightli": [2096, 2142], "m_expr": 2096, "a_expr": 2096, "shift_expr": 2096, "and_expr": 2096, "xor_expr": 2096, "comp_oper": 2096, "__contains__": 2096, "or_test": 2096, "and_test": 2096, "not_test": 2096, "conditional_express": 2096, "starred_item": 2096, "expression_stmt": 2096, "starred_express": 2096, "assignment_express": 2096, "assignment_stmt": 2096, "augmented_assignment_stmt": 2096, "augtarget": 2096, "augop": 2096, "annotated_assignment_stmt": 2096, "raise_stmt": 2096, "assert_stmt": 2096, "return_stmt": 2096, "del_stmt": 2096, "pass_stmt": 2096, "print_stmt": 2096, "break_stmt": 2096, "continue_stmt": 2096, "if_stmt": 2096, "while_stmt": 2096, "for_stmt": 2096, "with_stmt": 2096, "with_item": 2096, "tuple_stmt": 2096, "getattr_stmt": 2096, "hasattr_stmt": 2096, "zip_stmt": 2096, "iterable1": 2096, "iterable2": 2096, "enumerate_stmt": 2096, "five": [2096, 2147], "add_stat_valu": 2096, "sugaredvalu": 2096, "__abs__": 2096, "bytearrai": 2096, "delattr": 2096, "exec": 2096, "__index__": 2096, "isint": 2096, "issubclass": [2096, 2133], "ndigit": 2096, "__import__": [2096, 2158], "notimpl": [2096, 2097, 2133, 2194], "rpc_sync": [2096, 2155, 2166, 2167, 2168], "synonym": 2096, "_fork": [2096, 2129], "_wait": [2096, 2129], "lexic": 2097, "indent": 2097, "coroutin": [2097, 2192], "__del__": [2097, 2127], "__bytes__": 2097, "__slots__": 2097, "metaclass": 2097, "mro": 2097, "__r": 2097, "__": [2097, 2203], "bytesliter": 2097, "imagnumb": 2097, "parenthes": 2097, "ifs": 2097, "customiz": [2097, 2181, 2193, 2208], "compound": 2097, "eye_": [2098, 2124, 2157], "dirac_": [2098, 2124], "orthogonal_": [2098, 2124, 2142], "adaptivelogsoftmaxwithloss": 2098, "opcheck": 2100, "torch_librari": [2100, 2133, 2141, 2185], "test_util": 2100, "test_schema": 2100, "test_autograd_registr": 2100, "test_faketensor": [2100, 2151], "test_aot_dispatch_dynam": 2100, "register_autograd": 2100, "dispatchkei": [2100, 2133], "e2": [2100, 2161], "opoverloadpacket": 2100, "customopdef": 2100, "numpy_mul": 2100, "z_np": 2100, "sample_input": [2100, 2142], "718": 2100, "my_linear": [2100, 2108], "collis": 2100, "pessimist": 2100, "prone": [2100, 2114, 2117, 2144, 2194], "numpy_sin": 2100, "numpy_sin_cpu": 2100, "numpy_sin_inplac": 2100, "triton_op": 2100, "wrap_triton": 2100, "tl": [2100, 2186, 2197], "add_kernel": 2100, "in_ptr0": [2100, 2186, 2197], "in_ptr1": 2100, "out_ptr": 2100, "n_element": 2100, "constexpr": [2100, 2186, 2197], "program_id": [2100, 2186, 2197], "block_start": 2100, "cdiv": 2100, "triton_kernel": 2100, "__torch_dispatch__": [2100, 2171, 2194], "grid_fn": 2100, "triton_kernel_wrapper_mutation_proxi": 2100, "triton_kernel_wrapper_mut": 2100, "kernel_idx": 2100, "constant_args_idx": 2100, "register_kernel": 2100, "x_cpu": [2100, 2130], "x_cuda": 2100, "backward_fn": 2100, "functionctx": 2100, "keyword_only_input": 2100, "setup_context_fn": 2100, "custom_ops_landing_pag": [2100, 2204], "custom_linear": 2100, "_subclass": [2100, 2104, 2150, 2191, 2194], "fake_tensor": [2100, 2150, 2191, 2194], "faketensormod": [2100, 2150, 2151, 2191, 2194], "register_vmap": 2100, "vmap_func": 2100, "to_numpi": [2100, 2134], "numpy_cub": 2100, "numpy_cube_vmap": 2100, "numpy_mul_vmap": 2100, "x_bdim": [2100, 2134], "y_bdim": 2100, "impl_abstract": [2100, 2194], "qualnam": 2100, "abstractimplctx": 2100, "fakeimplctx": 2100, "register_torch_dispatch": 2100, "torch_dispatch_class": 2100, "_python_dispatch": [2100, 2133], "infer_schema": 2100, "prototype_funct": 2100, "foo_impl": 2100, "set_kernel_en": 2100, "2020": 2100, "googl": 2100, "colab": [2100, 2158, 2194], "dispatch_kei": [2100, 2193], "keynam": 2100, "alias_analysi": 2100, "conserv": [2100, 2103, 2130, 2194], "with_keyset": 2100, "fallthrough_kernel": 2100, "fallthrough": 2100, "redispatch": [2100, 2117, 2133, 2194], "fallback_kernel": 2100, "div_cpu": 2100, "impl_": 2100, "operator_nam": 2100, "mysin": 2100, "set_log": [2102, 2204, 2205], "off_by_default": 2102, "_registr": 2102, "spammi": [2102, 2193, 2205], "born": 2103, "citizen": 2103, "afterthought": 2103, "alik": 2103, "grai": 2103, "systemat": 2103, "maskedarrai": 2103, "masked_tensor": 2103, "principl": [2104, 2130, 2195], "meta_util": 2104, "undocu": 2104, "fidel": 2104, "torch_force_weights_only_load": [2105, 2147], "torch_force_no_weights_only_load": [2105, 2147], "torch_autograd_shutdown_wait_limit": 2105, "torch_device_backend_autoload": 2105, "mobil": [2106, 2161, 2195], "executorch": 2106, "vulkan": 2106, "optimize_for_mobil": 2106, "blocklist": [2106, 2158], "mobileoptimizertyp": 2106, "conv_bn_fus": 2106, "correspondingli": 2106, "prepack": [2106, 2155], "insert_fold_prepack_op": 2106, "arm": [2106, 2161], "remove_dropout": 2106, "hoist": 2106, "hoist_conv_packed_param": 2106, "fuse_add_relu": 2106, "vulkan_automatic_gpu_transf": 2106, "freeze_modul": 2106, "script_modul": 2106, "optimization_blocklist": 2106, "preserved_method": 2106, "_mobileoptimizertyp": 2106, "recursivescriptmodul": [2106, 2147], "hub": [2107, 2160, 2197], "load_url": 2107, "download": [2107, 2137, 2148, 2176, 2197, 2204], "friendli": 2108, "flopcountermod": 2108, "moduletrack": 2108, "is_bw": 2108, "infrequ": 2109, "window_s": 2109, "max_sampl": 2109, "cap": 2109, "hasn": [2109, 2158], "_monitor": 2109, "data_value_t": 2109, "eventhandlerhandl": 2109, "register_event_handl": 2109, "unregister_event_handl": 2109, "tensorboardeventhandl": 2109, "summarywrit": [2109, 2176], "tensorboard": [2109, 2159, 2160], "shader": [2110, 2143], "processor": [2110, 2150, 2195], "metalperformanceshad": 2110, "pytorch_debug_mps_alloc": 2111, "pytorch_mps_log_profile_info": 2111, "mpsprofil": 2111, "logopt": 2111, "pytorch_mps_trace_signpost": 2111, "profileopt": 2111, "signposttyp": 2111, "pytorch_mps_high_watermark_ratio": 2111, "watermark": 2111, "pytorch_mps_low_watermark_ratio": 2111, "pytorch_mps_fast_math": 2111, "shade": 2111, "pytorch_mps_prefer_met": 2111, "pytorch_enable_mps_fallback": 2111, "m_high_watermark_ratio": 2111, "shared_memori": 2114, "abruptli": 2114, "get_all_sharing_strategi": 2114, "get_sharing_strategi": 2114, "set_sharing_strategi": 2114, "new_strategi": 2114, "di": [2114, 2189, 2192, 2193], "abnorm": [2114, 2144], "forev": [2114, 2132], "asap": 2114, "queue_2": 2114, "x_clone": 2114, "segfault": [2114, 2145, 2194], "shm_open": [2114, 2173], "seriou": [2114, 2130, 2194], "torch_shm_manag": 2114, "unnot": 2114, "spawncontext": 2114, "grace_period": 2114, "grace": [2114, 2130, 2166], "has_nam": 2115, "is_shar": [2115, 2173], "is_sparse_csr": [2115, 2155, 2173], "is_tensor": [2115, 2171], "items": [2115, 2155], "unifies_names_from_input_tensor": 2115, "nbyte": [2115, 2155, 2173], "ndimens": 2115, "register_post_accumulate_grad_hook": [2115, 2127], "position": [2115, 2116], "unnam": [2115, 2116], "misalign": 2115, "inher": 2115, "collaps": [2115, 2117, 2155, 2199], "disappear": 2115, "img": [2116, 2176], "renamed_img": 2116, "coexist": 2116, "wildcard": [2116, 2158, 2203], "somewher": [2116, 2140], "scale_channel": 2116, "more_img": 2116, "named_tensor": 2116, "named_img": 2116, "flat_img": 2116, "named_flat_img": 2116, "unflattened_named_img": 2116, "grad_loss": 2116, "8107": 2116, "6357": 2116, "0783": 2116, "rename_map": 2116, "greedili": 2116, "unment": 2116, "49152": 2116, "sentenc": 2117, "audio": [2117, 2127, 2176, 2192], "seamless": 2117, "jag": [2117, 2122, 2191], "njt": [2117, 2122], "nested_tensor": [2117, 2122], "data_layout": 2117, "nt": 2117, "unbindbackwardautogradnestedtensor0": 2117, "as_nested_tensor": 2117, "j1": 2117, "somewhat": [2117, 2122, 2127, 2130, 2171, 2173, 2204], "delin": 2117, "82": 2117, "nested_tensor_from_jag": 2117, "nt1": 2117, "nt2": 2117, "nt3": 2117, "j2": 2117, "j3": 2117, "unintuit": 2117, "thousand": [2117, 2205], "sizeabl": 2117, "9916": 2117, "3363": 2117, "2799": 2117, "3520": 2117, "5896": 2117, "4374": 2117, "0104": 2117, "4841": 2117, "0952": 2117, "2973": 2117, "2516": 2117, "9035": 2117, "2026": 2117, "6858": 2117, "7030": 2117, "3481": 2117, "0236": 2117, "9747": 2117, "0089": 2117, "8396": 2117, "0561": [2117, 2172], "7688": 2117, "3122": 2117, "6107": 2117, "5723": 2117, "3913": 2117, "4954": 2117, "0479": 2117, "7610": 2117, "1345": 2117, "0556": 2117, "3634": [2117, 2142], "7122": 2117, "5921": 2117, "0540": 2117, "5506": 2117, "7608": 2117, "0606": 2117, "5658": 2117, "1934": 2117, "3041": 2117, "1483": 2117, "1284": 2117, "6957": 2117, "flexattent": 2117, "compiled_f": 2117, "compiled_g": 2117, "arcan": 2117, "rarer": 2117, "gotten": [2117, 2127], "_local_scalar_dens": [2117, 2155, 2189, 2199], "capture_scalar_output": [2117, 2204], "capture_dynamic_output_shape_op": 2117, "native_funct": [2117, 2133, 2141, 2199], "yaml": [2117, 2133, 2141, 2199], "_intern": [2117, 2173], "unwrap": [2117, 2194], "batchwis": 2117, "jagged_dim": 2117, "min_seqlen": 2117, "max_seqlen": 2117, "hole": 2117, "sum_b": 2117, "d_n": 2117, "fake_grad": 2117, "6862": 2117, "1282": 2117, "1031": 2117, "0464": 2117, "3276": 2117, "9967": 2117, "0054": 2117, "8972": 2117, "9174": 2117, "4995": 2117, "8546": 2117, "7194": 2117, "2918": 2117, "1846": 2117, "8793": 2117, "5183": 2117, "6447": 2117, "8009": 2117, "8468": 2117, "9832": 2117, "5272": 2117, "pt_infer": 2117, "pt_larg": 2117, "pt_small": 2117, "j4": 2117, "j5": 2117, "kv": [2117, 2122], "narrow_bas": 2117, "nt_narrow": 2117, "bitwidth": [2118, 2142, 2161, 2171], "asymmetr": [2118, 2161, 2164], "alter": [2119, 2126, 2133, 2200], "score_mod": 2122, "block_mask": 2122, "return_ls": 2122, "kernel_opt": 2122, "q_idx": 2122, "k_idx": 2122, "hkv": 2122, "blockspars": 2122, "create_block_mask": 2122, "mask_mod": 2122, "q_len": 2122, "kv_len": 2122, "_compil": 2122, "kv_idx": 2122, "causal_mask": 2122, "8192": 2122, "create_mask": 2122, "mod_fn": 2122, "_score_mod_signatur": 2122, "_mask_mod_signatur": 2122, "create_nested_block_mask": 2122, "q_nt": 2122, "kv_nt": 2122, "and_mask": 2122, "or_mask": 2122, "noop_mask": 2122, "token_q": 2122, "token_kv": 2122, "seq_length": [2122, 2154], "kv_num_block": 2122, "kv_indic": 2122, "full_kv_num_block": 2122, "full_kv_indic": 2122, "q_num_block": 2122, "q_indic": 2122, "full_q_num_block": 2122, "full_q_indic": 2122, "bcsr": 2122, "kv_block_siz": 2122, "q_block_siz": 2122, "num_blocks_in_row": 2122, "max_blocks_in_col": 2122, "dense_mask": 2122, "block_idx": 2122, "dkv": 2122, "from_kv_block": 2122, "kv_block": 2122, "_transposed_ord": 2122, "full_kv_": 2122, "invidu": 2122, "to_str": 2122, "grid_siz": 2122, "nifti": 2122, "attention_bias": 2123, "sacrific": [2124, 2130], "constant_": 2124, "ones_": 2124, "zeros_": 2124, "dirac": 2124, "xavier_uniform_": 2124, "glorot": 2124, "bengio": 2124, "fan": 2124, "_in": 2124, "_out": [2124, 2138, 2199], "Be": [2124, 2154, 2201], "fan_in": 2124, "fan_out": 2124, "xavier_normal_": [2124, 2142], "kaiming_uniform_": 2124, "kaim": 2124, "delv": 2124, "surpass": 2124, "_mode": 2124, "trunc_normal_": 2124, "redrawn": 2124, "sax": 2124, "2013": 2124, "sparse_": 2124, "marten": 2124, "hip": 2125, "scaler": [2126, 2130, 2137], "clip_grad_value_": 2126, "unscale_": 2126, "optimizer2": [2126, 2157], "batch_per_it": 2126, "iters_to_accumul": 2126, "num_proc": 2126, "grad_param": 2126, "grad_norm": 2126, "scaled_grad_param": 2126, "inv_scal": 2126, "get_scal": 2126, "optimizer0": 2126, "output0": 2126, "model0": 2126, "model1": [2126, 2157, 2185], "loss0": 2126, "loss1": 2126, "hundr": [2126, 2140, 2205], "imped": 2126, "poor": [2126, 2127], "dp_model": 2126, "imported_funct": 2126, "mymm": 2126, "myfloat32func": 2126, "fwd_output": 2126, "cleaner": 2127, "mapsto": 2127, "educ": [2127, 2173], "_saved_self": 2127, "convex": 2127, "concav": 2127, "togglabl": 2127, "drawback": 2127, "0011": 2127, "creator": [2127, 2166, 2168], "hogwild": 2127, "train_fn": 2127, "graphtask": 2127, "copyslic": 2127, "mutex": 2127, "curiou": 2127, "\u2102": 2127, "yj": 2127, "holomorph": 2127, "fulfil": [2127, 2134, 2158, 2191], "mathematician": 2127, "studi": [2127, 2159], "beauti": 2127, "0906": 2127, "4835": 2127, "\u211d": 2127, "_output": 2127, "vj": 2127, "handi": [2127, 2130], "selfdeletingtempfil": 2127, "tmp_dir": 2127, "uuid4": 2127, "temp_fil": 2127, "forbidden": 2127, "savedtensor": 2127, "_raw_saved_": 2127, "_raw_saved_self": 2127, "save_on_disk_threshold": 2127, "tensor_or_sctf": 2127, "_saved_oth": 2127, "4th": 2128, "backcompat": 2128, "broadcast_warn": 2128, "userwarn": 2128, "compute_z": 2129, "w_z": 2129, "w_y": 2129, "openmp": [2129, 2148, 2179, 2193, 2195], "tbb": 2129, "aten_thread": 2129, "omp": 2129, "mkl_thread": 2129, "mkldnn_cpu_runtim": 2129, "use_mkldnn": 2129, "use_tbb": 2129, "use_openmp": 2129, "ON": [2129, 2139, 2140], "set_num_interop_thread": 2129, "get_num_interop_thread": 2129, "set_num_thread": [2129, 2144], "get_num_thread": 2129, "omp_num_thread": [2129, 2179], "mkl_num_thread": [2129, 2179], "xeon": [2129, 2201], "e5": 2129, "oversubscript": 2129, "__config__": [2129, 2160], "memory manag": 2130, "optimize pytorch": 2130, "irrespect": 2130, "spread": 2130, "cuda2": [2130, 2139], "broadli": [2130, 2161], "set_float_32_matmul_precis": 2130, "a100": [2130, 2201, 2205], "a_ful": 2130, "10240": 2130, "b_full": 2130, "ab_ful": 2130, "7277": 2130, "ab_tf32": 2130, "016": 2130, "ga100": 2130, "1747": 2130, "relative_error": 2130, "0022": 2130, "ab_fp32": 2130, "0031": 2130, "000039": 2130, "7x": 2130, "globalcontext": 2130, "setallowtf32cubla": 2130, "setallowtf32cudnn": 2130, "bench_gemm_transform": 2130, "allow_fp16_reduc": 2130, "4048": 2130, "1634": 2130, "1639": 2130, "4056": 2130, "1670": 2130, "1661": 2130, "4080": 2130, "1664": 2130, "1658": 2130, "1651": 2130, "4104": 2130, "1677": 2130, "1674": 2130, "4128": 2130, "1796": [2130, 2142], "2519": 2130, "5096": 2130, "2144": 2130, "2149": 2130, "2766": 2130, "5120": 2130, "2142": 2130, "9728": 2130, "3875": 2130, "5779": 2130, "16384": [2130, 2197], "6182": 2130, "9656": 2130, "setallowfp16reductioncubla": 2130, "instabl": 2130, "setallowbf16reductioncubla": 2130, "_all_": 2130, "volta": 2130, "allow_fp16_accumul": 2130, "setallowfp16accumulationcubla": 2130, "invis": [2130, 2192, 2195, 2205], "pointless": 2130, "exploit": 2130, "paragraph": [2130, 2138], "initial_grad": 2130, "memory_alloc": [2130, 2139], "empty_cach": [2130, 2139, 2207], "memory_snapshot": [2130, 2139], "memcheck": 2130, "option2": [2130, 2204], "value2": 2130, "max_split_size_mb": 2130, "mb": 2130, "borderlin": 2130, "memory_summari": 2130, "roundup_power2_divis": 2130, "1280": 2130, "1536": 2130, "1792": 2130, "256mb": 2130, "512mb": 2130, "1gb": [2130, 2202], "knob": [2130, 2191], "max_non_split_rounding_mb": 2130, "1024mb": 2130, "20mb": 2130, "532": 2130, "alow": 2130, "stall": 2130, "garbage_collection_threshold": 2130, "reclaim": [2130, 2189], "release_cached_block": 2130, "unfavor": 2130, "expandable_seg": 2130, "2mb": 2130, "sliver": 2130, "pinned_use_cuda_host_regist": 2130, "cudahostregist": 2130, "cudahostalloc": 2130, "malloc": [2130, 2207], "pinned_num_register_thread": 2130, "pinned_use_background_thread": 2130, "cuda_runtime_api": 2130, "iostream": [2130, 2185], "fpic": 2130, "my_malloc": 2130, "ssize_t": 2130, "ptr": 2130, "cout": [2130, 2185], "endl": [2130, 2140, 2185], "my_fre": 2130, "cudapluggablealloc": 2130, "new_alloc": 2130, "change_current_alloc": 2130, "ncclmemalloc": 2130, "nvlink": [2130, 2166], "nvl": 2130, "cumemcr": 2130, "cu_mem_location_type_host_numa": 2130, "egm": 2130, "nic": 2130, "craft": [2130, 2185], "cudamallocmanag": 2130, "virtual": [2130, 2173], "uvm": 2130, "dl": 2130, "outperform": 2130, "costli": [2130, 2195], "evict": 2130, "_get_default_group": 2130, "nccl_allocator_sourc": 2130, "nccl_alloc_plug": 2130, "size_t": 2130, "ncclresult_t": 2130, "nccl_free_plug": 2130, "ncclmemfre": 2130, "nccl_allocator_libnam": 2130, "nccl_alloc": 2130, "lnccl": 2130, "getenv": [2130, 2140], "_get_backend": 2130, "mem_alloc": 2130, "ncclcommregist": 2130, "register_mem_pool": 2130, "deregister_mem_pool": 2130, "nelem_1mb": 2130, "out_0": 2130, "out_1": 2130, "out_2": 2130, "accomod": 2130, "cu_multicast_granularity_recommend": 2130, "cu_multicast_granularity_minimum": 2130, "_cuda_clearcublasworkspac": [2130, 2139], "lru": 2130, "geometri": 2130, "1023": 2130, "zeta": [2130, 2155, 2172, 2199], "use_pytorch_kernel_cach": 2130, "pytorch_kernel_cache_path": 2130, "store_tru": 2130, "disable_cuda": 2130, "assess": 2130, "cudagetdevicecount": 2130, "cuinit": 2130, "nvmldevicegetcount_v2": 2130, "poison": 2130, "aforement": [2130, 2144], "train_load": [2130, 2137, 2144], "x_gpu": 2130, "x_cpu_long": 2130, "y_cpu": 2130, "y_gpu": 2130, "y_cpu_long": 2130, "new_tensor": 2130, "overus": 2130, "cudagraphlaunch": 2130, "elid": 2130, "versatil": 2130, "static_input": 2130, "static_output": 2130, "realist": 2130, "sophist": [2130, 2157], "register_generator_st": 2130, "d_in": 2130, "d_out": 2130, "640": 2130, "static_target": 2130, "static_y_pr": 2130, "static_loss": 2130, "real_input": [2130, 2194], "real_target": 2130, "refil": 2130, "rejoin": 2130, "cuda_work": 2130, "nsight": [2130, 2202], "reorgan": 2130, "graphabl": 2130, "illeg": [2130, 2191], "needlessli": [2130, 2191], "econom": 2130, "static_out_1": 2130, "g1_workload": 2130, "static_in_1": 2130, "static_out_2": 2130, "g2_workload": 2130, "static_in_2": 2130, "real_data_1": 2130, "real_data_2": 2130, "occasion": [2130, 2171, 2194], "29500": [2132, 2166, 2167], "dive": [2132, 2138, 2158, 2193, 2198], "grad0": 2132, "grad1": 2132, "bucket1": 2132, "bucket0": 2132, "hurt": 2132, "kick": [2132, 2166, 2167, 2201], "earliest": 2132, "unreadi": 2132, "absent": 2132, "perspect": [2132, 2136, 2145, 2167], "hpp": 2132, "processgroupgloo": 2132, "processgroupmpi": 2132, "_sync_param": 2132, "autograd_hook": 2132, "prepare_for_backward": 2132, "dist_ddp": 2132, "optimize_ddp": 2132, "linearfunct": 2133, "grad_bia": 2133, "mulconst": 2133, "mycub": [2133, 2134], "grad_dx": [2133, 2134], "my_cub": [2133, 2134], "input_featur": 2133, "output_featur": 2133, "__array_function__": [2133, 2195], "nep": [2133, 2195], "0018": 2133, "scalartensor": 2133, "handled_funct": 2133, "mandat": 2133, "update_wrapp": 2133, "ensure_tensor": 2133, "metadatatensor": 2133, "__add__": 2133, "subtensor2": 2133, "othersubtensor": 2133, "loggingtensor": 2133, "permiss": 2133, "_metadata": 2133, "ndata": 2133, "ministri": 2133, "silli": 2133, "superclass": 2133, "troublesom": 2133, "face": [2133, 2158, 2176, 2194], "_get_overridable_funct": 2133, "get_overridable_funct": [2133, 2206], "func_dict": 2133, "nn_func": 2133, "labori": 2133, "_get_testing_overrid": 2133, "get_testing_overrid": [2133, 2206], "override_dict": 2133, "dummy_add": 2133, "get_ignored_funct": [2133, 2206], "outdat": [2133, 2205], "zerotensor": 2133, "compositeimplicitautograd": 2133, "func_nam": [2133, 2166], "overload_nam": 2133, "exot": 2133, "zoo": 2133, "torchfunctionmod": [2133, 2204], "resolve_nam": [2133, 2206], "functionlog": 2133, "dispatchlog": 2133, "7164": 2133, "9336": 2133, "4287": 2133, "7989": 2133, "2169": 2133, "7474": 2133, "5624": 2133, "5970": 2133, "4328": 2133, "9794": 2133, "3490": 2133, "8671": 2133, "8573": 2133, "4338": 2133, "4948": 2133, "1249": 2133, "3307": 2133, "2151": 2133, "6018": 2133, "9060": 2133, "2974": 2133, "7708": 2133, "6668": 2133, "0352": 2133, "7948": 2133, "6023": 2133, "4303": 2133, "2036": 2133, "6831": 2133, "8120": 2133, "5949": 2133, "5416": 2133, "3335": 2133, "5897": 2133, "custom_vjp": 2134, "custom_jvp": 2134, "numpysort": 2134, "ind_inv": 2134, "numpytak": 2134, "numpy_sort": 2134, "ggx": 2134, "vmappabl": 2134, "ind_bdim": 2134, "ind_inv_bdim": 2134, "expanded_x": 2134, "expanded_ind": 2134, "expanded_ind_inv": 2134, "new_dim": 2134, "logical_dim": 2134, "maybe_expand_bdim_at_front": 2134, "pseudocod": 2134, "rapidli": [2135, 2144, 2152], "fortun": [2135, 2173, 2205], "abridg": 2135, "total_loss": 2135, "extrud": 2135, "phenomenon": 2135, "plenti": [2135, 2192], "bptt": 2135, "repackag": 2135, "nm": 2135, "blow": 2135, "rememb": [2135, 2144, 2157, 2184], "elf": 2135, "grep": [2135, 2188, 2192], "run_model": 2135, "recoveri": 2135, "data_parallel": 2135, "padded_input": 2135, "packed_input": 2135, "packed_output": 2135, "my_lstm": 2135, "dp_m": 2135, "padding_input": 2135, "flava": 2136, "sooner": 2136, "llm": 2136, "6b": 2136, "2b": 2136, "8gb": [2136, 2151], "1x": 2136, "24gb": 2136, "total_transformer_block_params_in_b": 2136, "dtype_byt": 2136, "gb": 2136, "2x": [2136, 2176, 2198], "record_funct": [2136, 2202], "recordstream": 2136, "flat_param": 2136, "splitwithsizesbackward": 2136, "4gb": 2136, "6gb": 2136, "_another_": 2136, "_could_": 2136, "wsl2": 2137, "embrac": 2137, "pip3": 2137, "whl": 2137, "nightli": [2137, 2201, 2204], "refert": 2137, "cifar10": 2137, "totensor": [2137, 2176], "train_dataset": [2137, 2146], "train_len": 2137, "batch_idx": 2137, "iteration_loss": 2137, "4f": 2137, "optimizer_state_dict": 2137, "fp64": [2137, 2145], "arc": 2137, "use_amp": 2137, "ur": 2138, "ui": [2138, 2176, 2198, 2201], "j_f": 2138, "calculu": 2138, "cw": 2138, "bigger": 2138, "articl": 2138, "blob": [2138, 2140, 2176], "58eb23378f2a376565a66ac32c93a316c45b6131": 2138, "l99": 2138, "l105": 2138, "ds_dx": 2138, "compute_gradi": 2138, "ds_dy": 2138, "conj_w_d": 2138, "w_d": 2138, "d_idx": 2138, "albeit": 2138, "wonder": 2138, "dialect": 2139, "portabl": 2139, "pytorch_no_hip_memory_cach": 2139, "hipblas_workspace_config": 2139, "mi300": 2139, "rocmdoc": 2139, "programming_guid": 2139, "hip_api_guid": 2139, "cuda_vers": 2139, "cudaruntimegetvers": 2139, "cudadrivergetvers": 2139, "hip_vers": 2139, "hipruntimegetvers": 2139, "hipdrivergetvers": 2139, "11000": 2139, "use_rocm": 2139, "40300": 2139, "cmake": [2139, 2148, 2185], "drocm_force_enable_gpu_assert": 2139, "addglobalcallback": 2140, "recordfunct": 2140, "ivalu": [2140, 2141], "threadlocaldebuginfo": 2140, "debuginfoguard": 2140, "recordfunctioncallback": 2140, "onfunctionent": 2140, "onfunctionexit": 2140, "needsinput": 2140, "samplingprob": 2140, "enablerecordfunct": 2140, "cerr": 2140, "broader": [2140, 2180], "inject": [2140, 2186], "setapiusagehandl": 2140, "setapiusagelogg": 2140, "event_nam": 2140, "c10_log_api_usage_onc": 2140, "my_api": 2140, "_log_api_usage_onc": 2140, "akin": [2140, 2185], "jpeg": 2140, "camera": [2140, 2176], "setexportmoduleextrafileshook": 2140, "extrafilesmap": 2140, "producer_info": 2140, "getsourc": 2140, "precompil": 2140, "pyc": 2140, "loos": 2140, "csrc": [2141, 2148, 2185, 2191, 2192], "stableivalu": 2141, "liaison": 2141, "hail": 2141, "reinterpret_cast": 2141, "nullopt": 2141, "nullptr_t": 2141, "raiiath": 2141, "uint64_t": 2141, "atentensorhandl": 2141, "int32_t": 2141, "constantstr": 2141, "aoti_torch_call_dispatch": 2141, "elabor": 2142, "tpu": 2142, "mylinear": 2142, "0413": 2142, "2057": 2142, "0597": 2142, "8247": 2142, "1045": 2142, "4299": 2142, "5457": 2142, "4793": 2142, "8525": 2142, "6749": 2142, "l0": [2142, 2147, 2192], "deeper": [2142, 2158], "bignet": 2142, "big_net": 2142, "dynamicnet": 2142, "dynamic_net": 2142, "2051": 2142, "7601": 2142, "1963": 2142, "4354": 2142, "6598": 2142, "4446": 2142, "4628": 2142, "8774": 2142, "6848": 2142, "5458": 2142, "4647": 2142, "5310": 2142, "0609": 2142, "0940": 2142, "1266": 2142, "0623": 2142, "3508": 2142, "0550": 2142, "5317": 2142, "5562": 2142, "4028": 2142, "6942": 2142, "0140": 2142, "0329": 2142, "1160": 2142, "0434": 2142, "3889": 2142, "1613": 2142, "6340": 2142, "3887": 2142, "9979": 2142, "0767": 2142, "3526": 2142, "8756": 2142, "5847": 2142, "6016": 2142, "1608": 2142, "0829": 2142, "6338": 2142, "9239": 2142, "6943": 2142, "5034": 2142, "0268": 2142, "4489": 2142, "9403": 2142, "1571": [2142, 2147], "2509": 2142, "5052": 2142, "3088": 2142, "4951": 2142, "3381": 2142, "5166": 2142, "beginn": 2142, "examples_nn": 2142, "polynomial_modul": 2142, "teach": 2142, "0013": [2142, 2172], "0030": 2142, "0008": 2142, "modalmodul": 2142, "6614": 2142, "2669": 2142, "0617": 2142, "4519": 2142, "two_layer_net_optim": 2142, "blitz": 2142, "neural_networks_tutori": 2142, "autograd_tutori": 2142, "new_net": 2142, "runningmean": 2142, "1041": 2142, "0647": 2142, "1515": 2142, "m_load": 2142, "unserialized_th": 2142, "statefulmodul": 2142, "param3": 2142, "param_list": 2142, "parameterlist": 2142, "param_dict": 2142, "parameterdict": 2142, "buffer1": 2142, "buffer2": 2142, "buffer3": 2142, "0322": 2142, "9066": 2142, "1409": 2142, "4852": 2142, "6949": 2142, "2911": 2142, "1044": 2142, "4202": 2142, "1953": 2142, "5299": 2142, "8747": 2142, "6289": 2142, "4898": 2142, "6434": 2142, "5187": 2142, "0346": 2142, "4077": 2142, "4324": 2142, "7022": 2142, "3915": 2142, "6176": 2142, "6062": 2142, "5992": 2142, "4452": 2142, "2843": 2142, "3710": 2142, "3947": 2142, "saving_loading_model": 2142, "what_is_state_dict": 2142, "skip_init": 2142, "skip_param_init": 2142, "backward_hook": [2142, 2200], "new_grad_input": 2142, "5059": 2142, "8158": 2142, "2390": 2142, "0043": 2142, "addmmbackward": 2142, "forward_pre_hook_handl": 2142, "5752": 2142, "7421": 2142, "forward_hook_handl": 2142, "0980": 2142, "4666": 2142, "0256": 2142, "4497": 2142, "5046": 2142, "combat": 2142, "mps_devic": 2143, "yourfavoritenet": 2143, "a3c": 2144, "set_start_method": 2144, "simplequeu": 2144, "cope": 2144, "eleg": 2144, "num_process": 2144, "inappropri": 2144, "vcpu": 2144, "htop": 2144, "exceed": [2144, 2151, 2204], "competit": 2144, "oversubscrib": 2144, "mnist_hogwild": 2144, "dataloader_kwarg": 2144, "train_epoch": 2144, "30x": 2144, "boost": [2144, 2188], "754": 2145, "1e20": 2145, "4142e": 2145, "struggl": 2145, "benign": 2145, "v_dot2": 2145, "mfma": 2145, "miopen": 2145, "rocblas_internal_fp16_alt_impl": 2145, "miopen_debug_convolution_attrib_fp16_alt_impl": 2145, "_convbackend": 2145, "slownd": 2145, "slownd_transpos": 2145, "slownd_dil": 2145, "slownd_dilated_transpos": 2145, "convbackend": 2145, "miopendepthwis": 2145, "miopentranspos": 2145, "svd_lowrank": [2146, 2171], "index_add_cuda_": 2146, "1509": 2146, "8027": 2146, "0333": 2146, "1444": 2146, "rese": 2146, "seed_work": 2146, "worker_se": 2146, "tensor_dict": 2147, "loaded_numb": 2147, "loaded_even": 2147, "loaded_smal": 2147, "num_batches_track": 2147, "bn_state_dict": 2147, "new_bn": 2147, "out0_relu": 2147, "1400": 2147, "4563": 2147, "0271": 2147, "4406": 2147, "2827": 2147, "4588": 2147, "2031": 2147, "1316": 2147, "6533": 2147, "3413": 2147, "1112": 2147, "m_state_dict": 2147, "new_m": 2147, "zip64": 2147, "pkl": [2147, 2158], "byteord": 2147, "allowlist": 2147, "_pickl": 2147, "unpicklingerror": 2147, "weightsunpickl": 2147, "__module__": [2147, 2206], "safe_glob": 2147, "get_unsafe_globals_in_checkpoint": 2147, "get_safe_glob": 2147, "clear_safe_glob": 2147, "float32dtyp": 2147, "original_nam": 2147, "controlflowmodul": 2147, "controlflowmodule_trac": 2147, "3793": 2147, "controlflowmodule_script": 2147, "tagger": 2147, "ipu_tag": 2147, "ipu_deseri": 2147, "startswith": [2147, 2155], "get_crc32_opt": 2147, "crc32": 2147, "set_crc32_opt": 2147, "compute_crc32": 2147, "unzip": [2147, 2158], "compuat": 2147, "get_default_load_endian": 2147, "loadendian": 2147, "default_load_endian": 2147, "set_default_load_endian": 2147, "endian": 2147, "get_default_mmap_opt": 2147, "default_mmap_opt": 2147, "set_default_mmap_opt": 2147, "mytensor": 2147, "namedtemporaryfil": 2147, "5024": 2147, "8152": 2147, "5455": 2147, "8234": 2147, "disassembl": 2147, "skip_data": 2147, "materialize_fake_tensor": 2147, "checksum": 2147, "use_pinned_memory_for_d2h": 2147, "pageabl": 2147, "storage_align": 2147, "mmap_flag": 2147, "calculate_storage_offset": 2147, "rem": 2148, "7z": 2148, "curl": 2148, "ossci": 2148, "mkl_2020": 2148, "aoa": 2148, "omkl": 2148, "cuda_prefix": 2148, "cuda102": 2148, "magma_2": 2148, "4_": 2148, "omagma": 2148, "cmake_include_path": 2148, "cd": [2148, 2158, 2185, 2205], "magma_hom": 2148, "studio": 2148, "cmake_gener": 2148, "ffi": 2148, "create_extens": 2148, "_ext": 2148, "define_macro": 2148, "relative_to": 2148, "c99": 2148, "x86_x64": 2148, "packagesnotfounderror": 2148, "anaconda": 2148, "noarch": 2148, "continuum": 2148, "pkg": 2148, "pro": [2148, 2176], "msys2": 2148, "importerror": [2148, 2158], "dll": 2148, "vc2017": 2148, "vc": 2148, "vs2017_runtim": 2148, "mkl_fft": 2148, "intel_openmp": 2148, "vs2017": 2148, "openbla": 2148, "forg": 2148, "emerg": [2148, 2191], "forgotten": 2148, "idiom": 2148, "freeze_support": 2148, "forkingpickl": 2148, "brokenpipeerror": 2148, "errno": 2148, "couldn": [2148, 2154], "torch_14808_1591070686": 2148, "thalloc": 2148, "tdr": 2148, "thcudacheck": 2148, "storageshar": 2148, "microsoft": [2149, 2161], "flavor": 2149, "input_nam": [2149, 2150, 2154, 2156], "polish": [2149, 2150], "upgrad": [2150, 2157, 2178], "onnxscript": [2150, 2152, 2154], "onnxruntim": [2150, 2152, 2154, 2161], "perceptron": 2150, "mlpmodel": 2150, "fc0": 2150, "fc3": 2150, "97": [2150, 2172], "onnx_program": [2150, 2151], "onnxprogram": [2150, 2154], "model_proto": 2150, "modelproto": 2150, "complianc": 2150, "protobuf": 2150, "netron": 2150, "markdown": [2150, 2154], "export_param": [2150, 2154], "output_nam": [2150, 2154, 2156], "dynamic_ax": [2150, 2154, 2156], "keep_initializers_as_input": [2150, 2154, 2156], "external_data": [2150, 2154], "custom_translation_t": [2150, 2154], "dump_exported_program": [2150, 2154], "artifacts_dir": [2150, 2154], "trainingmod": [2150, 2154, 2156], "operator_export_typ": [2150, 2154], "operatorexporttyp": [2150, 2154], "do_constant_fold": [2150, 2154, 2156], "custom_opset": [2150, 2154], "export_modules_as_funct": [2150, 2154], "autograd_inlin": [2150, 2154], "summodul": [2150, 2154], "dim_valu": [2150, 2154], "my_custom_axis_nam": [2150, 2154], "dim_param": [2150, 2154], "sum_dynamic_axes_1": [2150, 2154], "74765": [2150, 2154], "apply_weight": 2150, "initialize_inference_sess": 2150, "_ort_session_initi": 2150, "ort": [2150, 2154], "inferencesess": [2150, 2154], "include_initi": 2150, "is_in_onnx_export": [2150, 2154], "enable_fake_mod": 2150, "torch_doctest_onnx": [2150, 2152], "my_nn_modul": 2150, "my_model_without_initi": 2150, "WITH": 2150, "my_model_with_initi": 2150, "dynamo_export": 2150, "model_kwarg": 2150, "exportopt": 2150, "my_simple_model": 2150, "my_dynamic_model": 2150, "fake_context": 2150, "onnx_registri": 2150, "diagnostic_opt": 2150, "diagnosticopt": 2150, "onnxfakecontext": 2150, "onnxregistri": 2150, "highresnet": 2151, "monai": 2151, "_record_memory_histori": [2151, 2207], "spatial_dim": 2151, "48": [2151, 2186], "torchscript_exporter_highresnet": 2151, "snapshot_nam": 2151, "torchscript_exporter_exampl": 2151, "_dump_snapshot": [2151, 2207], "memory_viz": [2151, 2207], "drag": [2151, 2207], "torchdynamo_exporter_exampl": 2151, "memeori": 2151, "45mb": 2151, "98": 2151, "is_onnxrt_backend_support": 2152, "onnxrt": [2152, 2183], "dummy_input": 2154, "actual_input_1": 2154, "learned_": 2154, "learned_0": 2154, "learned_1": 2154, "learned_2": 2154, "learned_3": 2154, "learned_14": 2154, "learned_15": 2154, "kernel_shap": 2154, "9216": 2154, "check_model": 2154, "printable_graph": 2154, "ort_sess": 2154, "astyp": 2154, "real_seq_length": 2154, "experienc": [2154, 2204], "new_data": 2154, "hope": [2154, 2192, 2198], "symbolic_opset": 2154, "symbolic_opset9": 2154, "_variablefunct": 2154, "pyi": 2154, "checkout": 2154, "___torch_mangle_0": 2154, "alpha_f": 2154, "myrelu": 2154, "value_t": 2154, "pythonop": [2154, 2155], "mylogexp": 2154, "onnx_fallthrough": 2154, "onnx_aten_fallback": 2154, "onnx_opset": 2154, "opset15": 2154, "67326": 2154, "alphax": 2154, "castlik": 2154, "gammax": 2154, "settyp": 2154, "custom_selu": 2154, "jit_util": 2154, "graphcontext": 2154, "onnxscript_op": 2154, "register_custom_op_symbol": 2154, "symbolic_nam": 2154, "symbolic_fn": 2154, "symbolic_help": 2154, "symbolic_foo_forward": 2154, "custom_domain": 2154, "attr1_f": 2154, "attr2_i": 2154, "foo_forward": 2154, "foomodel": 2154, "example_input1": 2154, "caffe2": [2154, 2176], "torch_script_graph": 2154, "unconvertible_op": 2154, "contrib": 2154, "test_aten_embedding_2": 2154, "test_oper": 2154, "unregister_custom_op_symbol": 2154, "select_model_mode_for_export": 2154, "constantchunk": 2155, "__and_": 2155, "__contains_": 2155, "__derive_index": 2155, "__getitem_": 2155, "__interpol": 2155, "__is_": 2155, "__isnot_": 2155, "__lshift_": 2155, "__not_": 2155, "__or_": 2155, "__range_length": 2155, "__rshift_": 2155, "__xor_": 2155, "_cast_byt": 2155, "_cast_char": 2155, "_cast_doubl": 2155, "_cast_float": 2155, "_cast_half": 2155, "_cast_int": 2155, "_cast_long": 2155, "_cast_short": 2155, "_conj": 2155, "_convolution_mod": 2155, "_dim_arang": 2155, "_log_softmax": [2155, 2199], "_pack_padded_sequ": 2155, "_pad_packed_sequ": 2155, "_reshape_from_tensor": 2155, "_sample_dirichlet": 2155, "_set_item": 2155, "_shape_as_tensor": 2155, "_standard_gamma": 2155, "_uniqu": 2155, "_unique2": 2155, "_weight_norm": 2155, "conv1d_relu": 2155, "conv2d_relu": 2155, "conv3d_relu": 2155, "embedding_renorm": 2155, "floordiv": [2155, 2163], "linear_relu": [2155, 2163], "nonzero_numpi": 2155, "numpy_t": 2155, "unchecked_cast": 2155, "unique_dim": 2155, "_c10d_function": 2155, "all_gather_into_tensor_coalesc": 2155, "all_gather_into_tensor_out": 2155, "all_reduce_coalesc": 2155, "reduce_scatter_tensor_coalesc": 2155, "wait_tensor": 2155, "_c10d_functional_autograd": 2155, "_dtensor": 2155, "shard_dim_alltoal": 2155, "_quantiz": 2155, "_wrapped_linear_prepack": 2155, "_wrapped_quantized_linear_prepack": 2155, "conv2d_prepack": 2155, "conv3d_prepack": 2155, "conv_transpose1d_prepack": 2155, "conv_transpose2d_prepack": 2155, "conv_transpose3d_prepack": 2155, "linear_dynam": 2155, "linear_prepack": 2155, "linear_prepack_fp16": 2155, "linear_prepack_fp16_legaci": 2155, "linear_prepack_legaci": 2155, "wrapped_fbgemm_linear_fp16_weight": 2155, "wrapped_fbgemm_pack_gemm_matrix_fp16": 2155, "wrapped_quantized_linear": 2155, "_test": 2155, "get_first": 2155, "compleximplicit": 2155, "floatimplicit": 2155, "intimplicit": 2155, "__iand_": 2155, "__ilshift_": 2155, "__ior_": 2155, "__irshift_": 2155, "__ixor_": 2155, "__round_to_zero_floordiv": 2155, "__upsampl": 2155, "__upsample_bilinear": 2155, "__upsample_nearest": 2155, "_adaptive_avg_pool2d": [2155, 2199], "_adaptive_avg_pool3d": [2155, 2199], "_add_batch_dim": 2155, "_add_relu": 2155, "_addmm_activ": 2155, "_aminmax": 2155, "_amp_foreach_non_finite_check_and_unscal": 2155, "_amp_update_scal": 2155, "_assert_async": 2155, "_assert_tensor_metadata": 2155, "_autocast_to_full_precis": 2155, "_autocast_to_reduced_precis": 2155, "_batch_norm_impl_index": 2155, "_batch_norm_no_upd": 2155, "_batch_norm_with_upd": 2155, "_batch_norm_with_update_funct": 2155, "_cdist_forward": [2155, 2199], "_cholesky_solve_help": 2155, "_choose_qparams_per_tensor": 2155, "_chunk_cat": 2155, "_coalesc": 2155, "_compute_linear_combin": 2155, "_conj_copi": 2155, "_conj_phys": 2155, "_conv_depthwise2d": 2155, "_convert_indices_from_coo_to_csr": 2155, "_convert_indices_from_csr_to_coo": 2155, "_convert_weight_to_int4pack": 2155, "_convert_weight_to_int4pack_for_cpu": 2155, "_copy_from": 2155, "_copy_from_and_res": 2155, "_cslt_compress": 2155, "_cslt_sparse_mm": 2155, "_cslt_sparse_mm_search": 2155, "_ctc_loss": 2155, "_cudnn_ctc_loss": 2155, "_cudnn_init_dropout_st": 2155, "_cudnn_rnn": 2155, "_cudnn_rnn_flatten_weight": 2155, "_cufft_clear_plan_cach": 2155, "_cufft_get_plan_cache_max_s": 2155, "_cufft_get_plan_cache_s": 2155, "_cufft_set_plan_cache_max_s": 2155, "_cummax_help": 2155, "_cummin_help": 2155, "_debug_has_internal_overlap": 2155, "_dimi": 2155, "_dimv": 2155, "_dirichlet_grad": 2155, "_efficient_attention_forward": 2155, "_efficientzerotensor": 2155, "_embedding_bag": [2155, 2199], "_embedding_bag_forward_onli": 2155, "_empty_affine_quant": 2155, "_empty_per_channel_affine_quant": 2155, "_euclidean_dist": 2155, "_fake_quantize_learnable_per_channel_affin": 2155, "_fake_quantize_learnable_per_tensor_affin": 2155, "_fake_quantize_per_tensor_affine_cachemask_tensor_qparam": 2155, "_fft_c2c": 2155, "_fft_c2r": 2155, "_fft_r2c": [2155, 2199], "_fill_mem_eff_dropout_mask": 2155, "_flash_attention_forward": 2155, "_foobar": [2155, 2205], "_foreach_ab": 2155, "_foreach_aco": 2155, "_foreach_add": 2155, "_foreach_addcdiv": 2155, "_foreach_addcmul": 2155, "_foreach_asin": 2155, "_foreach_atan": 2155, "_foreach_ceil": 2155, "_foreach_clamp_max": 2155, "_foreach_clamp_min": 2155, "_foreach_copi": 2155, "_foreach_co": 2155, "_foreach_cosh": 2155, "_foreach_div": 2155, "_foreach_erf": 2155, "_foreach_erfc": 2155, "_foreach_exp": 2155, "_foreach_expm1": 2155, "_foreach_floor": 2155, "_foreach_frac": 2155, "_foreach_lerp": 2155, "_foreach_lgamma": 2155, "_foreach_log": 2155, "_foreach_log10": 2155, "_foreach_log1p": 2155, "_foreach_log2": 2155, "_foreach_max": 2155, "_foreach_maximum": 2155, "_foreach_minimum": 2155, "_foreach_mul": 2155, "_foreach_neg": 2155, "_foreach_norm": 2155, "_foreach_pow": 2155, "_foreach_reciproc": 2155, "_foreach_round": 2155, "_foreach_rsqrt": 2155, "_foreach_sigmoid": 2155, "_foreach_sign": 2155, "_foreach_sin": 2155, "_foreach_sinh": 2155, "_foreach_sqrt": 2155, "_foreach_sub": 2155, "_foreach_tan": 2155, "_foreach_tanh": 2155, "_foreach_trunc": 2155, "_foreach_zero": 2155, "_functional_assert_async": 2155, "_functional_assert_scalar": 2155, "_functional_sym_constrain_rang": 2155, "_functional_sym_constrain_range_for_s": 2155, "_fused_adagrad": 2155, "_fused_adam": 2155, "_fused_adamw": 2155, "_fused_dropout": 2155, "_fused_moving_avg_obs_fq_help": [2155, 2189], "_fused_moving_avg_obs_fq_helper_funct": [2155, 2189], "_fused_sdp_choic": 2155, "_fused_sgd": 2155, "_fw_primal": 2155, "_fw_primal_copi": 2155, "_get_cpu_cap": 2155, "_get_tracing_st": 2155, "_grad_sum_to_s": 2155, "_has_compatible_shallow_copy_typ": 2155, "_has_same_storage_numel": 2155, "_histogramdd_bin_edg": 2155, "_histogramdd_from_bin_ct": 2155, "_histogramdd_from_bin_tensor": 2155, "_index_put_impl": 2155, "_indices_copi": 2155, "_infer_s": 2155, "_int_mm": 2155, "_is_all_tru": 2155, "_is_any_tru": 2155, "_is_zerotensor": 2155, "_jagged_to_padded_dense_forward": 2155, "_lazy_clon": 2155, "_linalg_check_error": 2155, "_linalg_det": 2155, "_linalg_eigh": 2155, "_linalg_eigv": 2155, "_linalg_slogdet": 2155, "_linalg_solve_ex": 2155, "_linalg_svd": 2155, "_list_to_tensor": 2155, "_logcumsumexp": 2155, "_lstm_mp": 2155, "_make_dep_token": 2155, "_make_du": 2155, "_make_dual_copi": 2155, "_make_per_channel_quantized_tensor": 2155, "_make_per_tensor_quantized_tensor": 2155, "_masked_scal": 2155, "_masked_softmax": 2155, "_mixed_dtypes_linear": 2155, "_mkldnn_reshap": 2155, "_mkldnn_transpos": 2155, "_mps_convolut": 2155, "_mps_convolution_transpos": 2155, "_native_batch_norm_legit": [2155, 2199], "_native_batch_norm_legit_no_train": [2155, 2199], "_ncf_unsqueez": 2155, "_ncf_view": 2155, "_neg_view": 2155, "_neg_view_copi": 2155, "_nested_compute_contiguous_strides_offset": 2155, "_nested_from_pad": 2155, "_nested_from_padded_and_nested_exampl": 2155, "_nested_from_padded_tensor": 2155, "_nested_get_jagged_dummi": 2155, "_nested_get_length": 2155, "_nested_get_max_seqlen": 2155, "_nested_get_min_seqlen": 2155, "_nested_get_offset": 2155, "_nested_get_ragged_idx": 2155, "_nested_get_valu": 2155, "_nested_get_values_copi": 2155, "_nested_tensor_from_mask": 2155, "_nested_tensor_from_mask_left_align": 2155, "_nested_tensor_from_tensor_list": 2155, "_nested_tensor_s": 2155, "_nested_tensor_softmax_with_shap": 2155, "_nested_tensor_storage_offset": 2155, "_nested_tensor_strid": 2155, "_nested_view_from_buff": 2155, "_nested_view_from_buffer_copi": 2155, "_nested_view_from_jag": 2155, "_nested_view_from_jagged_copi": 2155, "_new_zeros_with_same_feature_meta": 2155, "_nnpack_avail": 2155, "_nnpack_spatial_convolut": 2155, "_no_grad_embedding_renorm": 2155, "_no_grad_fil": 2155, "_no_grad_norm": 2155, "_no_grad_uniform": 2155, "_no_grad_zero": 2155, "_pack_sequ": 2155, "_pad_circular": 2155, "_pad_enum": 2155, "_padded_dense_to_jagged_forward": 2155, "_pdist_forward": [2155, 2199], "_pin_memori": 2155, "_prelu_kernel": 2155, "_print": 2155, "_propagate_xla_data": 2155, "_remove_batch_dim": 2155, "_reshape_alia": 2155, "_reshape_alias_copi": 2155, "_reshape_copi": 2155, "_resize_output": 2155, "_rowwise_prun": 2155, "_safe_softmax": 2155, "_saturate_weight_to_fp16": 2155, "_scaled_dot_product_attention_math": 2155, "_scaled_dot_product_attention_math_for_mp": 2155, "_scaled_dot_product_cudnn_attent": 2155, "_scaled_dot_product_efficient_attent": 2155, "_scaled_dot_product_flash_attent": 2155, "_scaled_dot_product_flash_attention_for_cpu": 2155, "_scaled_dot_product_fused_attention_overrid": 2155, "_scaled_mm": 2155, "_size_if_not_equ": 2155, "_slow_conv2d_forward": 2155, "_sobol_engine_draw": 2155, "_sobol_engine_ff": 2155, "_sobol_engine_initialize_st": 2155, "_sobol_engine_scrambl": 2155, "_sparse_addmm": 2155, "_sparse_broadcast_to": 2155, "_sparse_broadcast_to_copi": 2155, "_sparse_bsc_tensor_unsaf": 2155, "_sparse_bsr_tensor_unsaf": 2155, "_sparse_compressed_tensor_unsaf": 2155, "_sparse_compressed_tensor_with_dim": 2155, "_sparse_coo_tensor_unsaf": 2155, "_sparse_coo_tensor_with_dim": 2155, "_sparse_coo_tensor_with_dims_and_tensor": 2155, "_sparse_csc_tensor_unsaf": 2155, "_sparse_csr_prod": 2155, "_sparse_csr_sum": 2155, "_sparse_csr_tensor_unsaf": 2155, "_sparse_log_softmax": 2155, "_sparse_mask_project": 2155, "_sparse_mm": 2155, "_sparse_mm_reduce_impl": 2155, "_sparse_semi_structured_addmm": 2155, "_sparse_semi_structured_appli": 2155, "_sparse_semi_structured_apply_dens": 2155, "_sparse_semi_structured_linear": 2155, "_sparse_semi_structured_mm": 2155, "_sparse_semi_structured_til": 2155, "_sparse_softmax": 2155, "_sparse_sparse_matmul": 2155, "_sparse_sum": 2155, "_spdiag": 2155, "_spsolv": 2155, "_standard_gamma_grad": 2155, "_tensor_to_list": 2155, "_test_ambiguous_default": 2155, "_test_autograd_multiple_dispatch": 2155, "_test_autograd_multiple_dispatch_view": 2155, "_test_autograd_multiple_dispatch_view_copi": 2155, "_test_check_tensor": 2155, "_test_functorch_fallback": 2155, "_test_optional_filled_intlist": 2155, "_test_optional_floatlist": 2155, "_test_optional_intlist": 2155, "_test_parallel_materi": 2155, "_test_serialization_subcmul": 2155, "_test_string_default": 2155, "_test_warn_in_autograd": 2155, "_thnn_fused_gru_cel": 2155, "_thnn_fused_lstm_cel": 2155, "_to_copi": [2155, 2199], "_to_cpu": 2155, "_to_dens": 2155, "_to_spars": 2155, "_to_sparse_bsc": 2155, "_to_sparse_bsr": 2155, "_to_sparse_csc": 2155, "_to_sparse_csr": 2155, "_to_sparse_semi_structur": 2155, "_transform_bias_rescale_qkv": 2155, "_transformer_encoder_layer_fwd": 2155, "_trilinear": 2155, "_triton_multi_head_attent": 2155, "_triton_scaled_dot_attent": 2155, "_unpack_du": 2155, "_unsafe_index": 2155, "_unsafe_index_put": 2155, "_unsafe_masked_index": 2155, "_unsafe_masked_index_put_accumul": 2155, "_unsafe_view": 2155, "_unwrap_opt": 2155, "_upsample_bicubic2d_aa": 2155, "_upsample_bilinear2d_aa": 2155, "_upsample_nearest_exact1d": 2155, "_upsample_nearest_exact2d": 2155, "_upsample_nearest_exact3d": 2155, "_use_cudnn_ctc_loss": 2155, "_use_cudnn_rnn_flatten_weight": 2155, "_validate_compressed_sparse_indic": 2155, "_validate_sparse_bsc_tensor_arg": 2155, "_validate_sparse_bsr_tensor_arg": 2155, "_validate_sparse_compressed_tensor_arg": 2155, "_validate_sparse_coo_tensor_arg": 2155, "_validate_sparse_csc_tensor_arg": 2155, "_validate_sparse_csr_tensor_arg": 2155, "_values_copi": 2155, "_weight_int4pack_mm": 2155, "_weight_int4pack_mm_for_cpu": 2155, "_weight_int8pack_mm": 2155, "_weight_norm_interfac": 2155, "capit": 2155, "confirmed_by_own": [2155, 2166], "convolution_overrid": 2155, "copy_sparse_to_spars": 2155, "endswith": 2155, "expandtab": 2155, "fake_quantize_per_channel_affine_cachemask": 2155, "fake_quantize_per_tensor_affine_cachemask": 2155, "fill_diagon": 2155, "glu_jvp": 2155, "has_torch_funct": [2155, 2206], "is_non_overlapping_and_dens": 2155, "is_own": [2155, 2166], "is_strides_like_format": 2155, "isalnum": 2155, "isalpha": 2155, "isdecim": 2155, "isdigit": 2155, "isidentifi": 2155, "islow": 2155, "isnumer": 2155, "isprint": 2155, "isspac": 2155, "istitl": 2155, "isupp": 2155, "lift_fresh": 2155, "ljust": 2155, "local_valu": [2155, 2166], "log_sigmoid_forward": 2155, "lstrip": 2155, "matrix_h": 2155, "nll_loss2d_forward": 2155, "nll_loss_forward": 2155, "normal_funct": 2155, "owner_nam": [2155, 2166], "percentformat": 2155, "quantized_gru": 2155, "quantized_lstm": 2155, "resize_as_spars": 2155, "rfind": 2155, "rindex": 2155, "rjust": 2155, "rpartit": 2155, "rrelu_with_noise_funct": 2155, "rsplit": 2155, "rstrip": 2155, "set_data": 2155, "slow_conv3d_forward": 2155, "sparse_res": 2155, "sparse_resize_and_clear": 2155, "splitlin": 2155, "swapcas": 2155, "sym_numel": [2155, 2199], "sym_storage_offset": [2155, 2199], "sym_strid": [2155, 2199], "unique_dim_consecut": 2155, "zfill": 2155, "_allgather_bas": 2155, "_reduce_scatter_bas": 2155, "allgath": 2155, "allgather_coalesc": 2155, "allgather_into_tensor_coalesc": 2155, "allreduce_coalesc": 2155, "alltoal": 2155, "alltoall_bas": 2155, "recv_any_sourc": 2155, "debugprim": 2155, "load_tensor": 2155, "_alloc_from_pool": 2155, "_mm_plus_mm": 2155, "_reinterpret_tensor": 2155, "accumulate_grad": 2155, "resize_storage_byt": 2155, "copy_to_host": 2155, "metal_prepack": 2155, "conv2d_run": 2155, "linear_run": 2155, "linear_dynamic_fp16": 2155, "linear_relu_dynamic_fp16": 2155, "qconv1d_pointwis": 2155, "qconv2d_pointwis": 2155, "qconv3d_pointwis": 2155, "qconv_prepack": 2155, "qlinear_pointwis": 2155, "qlinear_prepack": 2155, "conv2d_clamp_prepack": 2155, "conv2d_clamp_run": 2155, "conv2d_transpose_clamp_prepack": 2155, "conv2d_transpose_clamp_run": 2155, "linear_clamp_prepack": 2155, "linear_clamp_run": 2155, "unpack_prepacked_sizes_conv2d": 2155, "unpack_prepacked_sizes_linear": 2155, "addstatvalu": 2155, "autogradadd": 2155, "autogradallnonzero": 2155, "autogradallzero": 2155, "autogradanynonzero": 2155, "autogradzero": 2155, "bailout": [2155, 2191], "bailouttempl": 2155, "broadcasts": 2155, "chunksiz": 2155, "differentiablegraph": 2155, "enumnam": 2155, "enumvalu": 2155, "fallbackgraph": 2155, "fusedconcat": 2155, "fusiongroup": 2155, "ifthenels": 2155, "ignoredpythonop": 2155, "mmbatchsid": 2155, "mmtreereduc": 2155, "modulecontainerindex": 2155, "numtotensor": 2155, "raiseexcept": 2155, "reductions": 2155, "requiresgradcheck": 2155, "staticruntimecopyout": 2155, "staticsubgraph": 2155, "stringindex": 2155, "tensorexprdynamicgroup": 2155, "tensorexprdynamicguard": 2155, "tensorexprgroup": 2155, "timepoint": 2155, "tupleindex": 2155, "tupleunpack": 2155, "varconcat": 2155, "varstack": 2155, "awaitable_nowait": 2155, "awaitable_wait": 2155, "is_cpu": 2155, "is_ipu": 2155, "is_maia": 2155, "is_mkldnn": 2155, "is_mp": 2155, "is_mtia": 2155, "is_nest": 2155, "is_quant": 2155, "is_vulkan": 2155, "is_xla": 2155, "is_xpu": 2155, "profile_ivalu": 2155, "rangelist": 2155, "rpc_remot": 2155, "unchecked_unwrap_opt": 2155, "_make_token": [2155, 2199], "_sink_token": [2155, 2199], "bessel_i0": [2155, 2199], "bessel_i1": [2155, 2199], "bessel_j0": [2155, 2172, 2199], "bessel_j1": [2155, 2172, 2199], "broadcast_in_dim": [2155, 2199], "cbrt": [2155, 2199], "collapse_view": [2155, 2199], "convert_element_typ": [2155, 2199], "copy_strid": [2155, 2199], "copy_to": [2155, 2199], "device_put": [2155, 2199], "erf_inv": [2155, 2199], "erfcx": [2155, 2172, 2199], "fft_c2c": [2155, 2199], "fft_c2r": [2155, 2199], "fft_r2c": [2155, 2199], "iota": [2155, 2199], "maximum_valu": [2155, 2199], "minimum_valu": [2155, 2199], "ndtri": [2155, 2172, 2199], "rev": [2155, 2199], "shift_left": [2155, 2199], "shift_right_arithmet": [2155, 2199], "spherical_bessel_j0": [2155, 2172, 2199], "view_of": [2155, 2199], "view_of_dtyp": [2155, 2199], "xor_sum": [2155, 2199], "_call_end_callbacks_on_jit_fut": 2155, "_record_function_ent": 2155, "_record_function_enter_new": 2155, "_record_function_exit": 2155, "_bfloat16quantizedtofloat": 2155, "_floattobfloat16quant": 2155, "add_out": 2155, "add_relu_out": 2155, "add_scalar_out": 2155, "add_scalar_relu": 2155, "add_scalar_relu_out": 2155, "batch_norm1d": 2155, "batch_norm1d_relu": 2155, "batch_norm2d": 2155, "batch_norm2d_relu": 2155, "batch_norm3d": 2155, "batch_norm3d_relu": 2155, "batch_norm_relu": 2155, "cat_out": 2155, "cat_relu": 2155, "cat_relu_out": 2155, "conv1d_dynam": 2155, "conv1d_prepack": 2155, "conv1d_unpack": 2155, "conv2d_add": 2155, "conv2d_add_relu": 2155, "conv2d_dil": 2155, "conv2d_dynam": 2155, "conv2d_group": 2155, "conv2d_output_pad": 2155, "conv2d_pad": 2155, "conv2d_strid": 2155, "conv2d_transpos": 2155, "conv2d_unpack": 2155, "conv2d_unpack_s": 2155, "conv3d_dil": 2155, "conv3d_dynam": 2155, "conv3d_group": 2155, "conv3d_output_pad": 2155, "conv3d_pad": 2155, "conv3d_strid": 2155, "conv3d_transpos": 2155, "conv3d_unpack": 2155, "conv_prepack": 2155, "conv_transpose1d_dynam": 2155, "conv_transpose1d_unpack": 2155, "conv_transpose2d_dil": 2155, "conv_transpose2d_dynam": 2155, "conv_transpose2d_group": 2155, "conv_transpose2d_output_pad": 2155, "conv_transpose2d_pad": 2155, "conv_transpose2d_strid": 2155, "conv_transpose2d_transpos": 2155, "conv_transpose2d_unpack": 2155, "conv_transpose3d_dil": 2155, "conv_transpose3d_dynam": 2155, "conv_transpose3d_group": 2155, "conv_transpose3d_output_pad": 2155, "conv_transpose3d_pad": 2155, "conv_transpose3d_strid": 2155, "conv_transpose3d_transpos": 2155, "conv_transpose3d_unpack": 2155, "conv_unpack": 2155, "embedding_4bit": 2155, "embedding_bag_2bit_prepack": 2155, "embedding_bag_2bit_rowwise_offset": 2155, "embedding_bag_2bit_unpack": 2155, "embedding_bag_4bit": 2155, "embedding_bag_4bit_prepack": 2155, "embedding_bag_4bit_rowwise_offset": 2155, "embedding_bag_4bit_unpack": 2155, "embedding_bag_byt": 2155, "embedding_bag_byte_prepack": 2155, "embedding_bag_byte_rowwise_offset": 2155, "embedding_bag_byte_unpack": 2155, "embedding_bag_prepack": 2155, "embedding_bag_unpack": 2155, "embedding_byt": 2155, "linear_dynamic_fp16_unpacked_weight": 2155, "linear_leaky_relu": 2155, "linear_relu_dynam": 2155, "linear_tanh": 2155, "linear_unpack": 2155, "linear_unpack_fp16": 2155, "linear_with_input_q_dq_qweight_dq_output_fp32": 2155, "linear_with_input_q_dq_qweight_dq_relu_output_fp32": 2155, "make_quantized_cell_param": 2155, "make_quantized_cell_params_dynam": 2155, "make_quantized_cell_params_fp16": 2155, "mul_out": 2155, "mul_relu": 2155, "mul_relu_out": 2155, "mul_scalar_out": 2155, "mul_scalar_relu": 2155, "mul_scalar_relu_out": 2155, "quantized_gru_cell_dynam": 2155, "quantized_lstm_cell_dynam": 2155, "quantized_rnn_relu_cell_dynam": 2155, "quantized_rnn_tanh_cell_dynam": 2155, "rngprim": 2155, "philox_rand": 2155, "qlinear": 2155, "qlinear_dynam": 2155, "qlinear_relu": 2155, "qlinear_relu_dynam": 2155, "qlinear_unpack": 2155, "static_runtim": 2155, "vartupleunpack": 2155, "clamp_nan_to_num": 2155, "create_owned_ref": 2155, "dequantize_copi": 2155, "dict_unpack": 2155, "expand_dims_copi": 2155, "flatten_copi": 2155, "fused_equally_split": 2155, "reshape_copi": 2155, "select_tensor": 2155, "signed_log1p": 2155, "to_copi": 2155, "to_maybe_copy_out": 2155, "symm_mem": 2155, "_async_input_mm": 2155, "memset32": 2155, "multimem_all_reduc": 2155, "multimem_one_shot_all_reduc": 2155, "multimem_one_shot_all_reduce_out": 2155, "one_shot_all_reduc": 2155, "one_shot_all_reduce_out": 2155, "stream_write_value32": 2155, "two_shot_all_reduc": 2155, "input_kwarg": 2156, "fixed_batch_s": 2156, "use_external_data": 2156, "additional_test_input": 2156, "_verificationopt": 2156, "check_export_model_diff": 2156, "graphinfo": 2156, "graphinfoprettyprint": 2156, "onnxtestcaserepro": 2156, "verify_aten_graph": 2156, "var1": 2157, "var2": 2157, "layer0": 2157, "bias_param": 2157, "adadelta": 2157, "adafactor": 2157, "adamax": 2157, "asgd": 2157, "nadam": 2157, "radam": 2157, "rmsprop": 2157, "rprop": 2157, "lrschedul": 2157, "reducelronplateau": 2157, "multisteplr": 2157, "onelayermodel": 2157, "fc": [2157, 2161], "moe": 2157, "model2": [2157, 2185], "twolayermodel": 2157, "adapt_state_dict_id": 2157, "adapted_state_dict": 2157, "lookup_dict": 2157, "clone_deepcopi": 2157, "name_in_load": 2157, "index_in_loaded_list": 2157, "id_in_load": 2157, "model_bypass": 2157, "adapt_state_dict_missing_param": 2157, "names_match": 2157, "g_ind": 2157, "averaged_model": 2157, "textrm": 2157, "_foreach": 2157, "ema_avg": 2157, "averaged_model_paramet": 2157, "model_paramet": 2157, "num_averag": 2157, "test_input": 2157, "secur": 2158, "unpackag": 2158, "exercis": 2158, "my_packag": [2158, 2185], "94304870911616": 2158, "94304900784016": 2158, "extern_modul": 2158, "model_1": 2158, "myzip": 2158, "file_byt": 2158, "writestr": 2158, "new_file_byt": 2158, "vim": 2158, "vimrc": 2158, "bufreadcmd": 2158, "brows": 2158, "amatch": 2158, "vi": 2158, "packageimport": 2158, "queryabl": 2158, "glob": 2158, "packageexport": 2158, "pe": 2158, "save_pickl": 2158, "has_fil": 2158, "importer_file_structur": 2158, "package_a": 2158, "get_rdep": 2158, "all_path": 2158, "dependency_graph_str": 2158, "save_text": 2158, "save_binari": 2158, "my_resourc": 2158, "config_stuff": 2158, "raw_data": 2158, "my_byt": 2158, "complementari": [2158, 2172], "load_pickl": 2158, "load_text": 2158, "load_binari": 2158, "my_tensor": 2158, "__reduce_package__": 2158, "my_str": 2158, "time_import": 2158, "time_export": 2158, "pickler": 2158, "persistent_id": 2158, "persistent_load": 2158, "generated_module_nam": 2158, "get_unique_id": 2158, "clock_gettim": 2158, "unpackage_foo": 2158, "depickl": 2158, "foo_1": 2158, "foo_2": 2158, "foo_packag": 2158, "foo_collect": 2158, "foo1": 2158, "foo2": 2158, "imported_foo": 2158, "9857706": 2158, "650140837": 2158, "652698385": 2158, "__torch_package__": 2158, "is_in_packag": 2158, "userexcept": 2158, "unpackageableexcept": 2158, "loaded_modul": 2158, "import_modul": 2158, "save_source_str": 2158, "save_modul": 2158, "textwrap": 2158, "dedent": 2158, "my_funct": 2158, "is_packag": 2158, "importlib": 2158, "my_pickl": 2158, "get_my_resourc": 2158, "read_text": 2158, "torch_package_import": 2158, "get_my_pickl": 2158, "is_from_packag": 2158, "stdlib": 2158, "my_test": 2158, "f2": 2158, "sys_import": 2158, "script_model": 2158, "mixed_model": 2158, "python_model_with_scripted_submodul": 2158, "loaded_script": 2158, "loaded_mix": 2158, "convention": 2158, "94286146172688": 2158, "94286146172784": 2158, "consult": [2158, 2191, 2204], "essai": 2158, "another_packag": 2158, "pickletool": 2158, "ast": 2158, "deni": 2158, "my_export": 2158, "my_interned_modul": 2158, "package_export": 2158, "my_externed_modul": 2158, "my_mocked_modul": 2158, "unwant": [2158, 2176], "hodg": 2158, "podg": 2158, "bazel": 2158, "buck": 2158, "my_class_inst": 2158, "imported_myclass": 2158, "okai": 2158, "torch_package_0": 2158, "handle_me_this_wai": 2158, "inadvert": 2158, "pun": 2158, "packagingerror": 2158, "dependency_graph": 2158, "emptymatcherror": 2158, "allow_empti": 2158, "_sysimport": 2158, "hermet": 2158, "scan": 2158, "orderedimport": 2158, "add_depend": 2158, "graphviz": 2158, "lang": 2158, "denied_modul": 2158, "my_subpackag": 2158, "digraph": 2158, "externed_modul": 2158, "interned_modul": 2158, "mocked_modul": 2158, "register_extern_hook": 2158, "register_intern_hook": 2158, "register_mock_hook": 2158, "myobject": 2158, "save_source_fil": 2158, "file_or_directori": 2158, "my_subsubpackag": 2158, "file_or_buff": 2158, "module_allow": 2158, "pytorchfileread": 2158, "python_vers": 2158, "is_dir": 2158, "_kinetoprofil": 2159, "execution_trace_observ": 2159, "profileract": 2159, "export_memory_timelin": 2159, "executiontraceobserv": 2159, "add_metadata": 2159, "add_metadata_json": 2159, "unaggreg": 2159, "suffix": [2159, 2176, 2177], "png": 2159, "gzip": 2159, "numbyt": 2159, "increment_vers": 2159, "_memory_profil": 2159, "export_stack": 2159, "self_cuda_time_tot": 2159, "preset_metadata_json": 2159, "preset": 2159, "toggle_collection_dynam": 2159, "code_to_profile_0": 2159, "code_to_profile_1": 2159, "code_to_profile_2": 2159, "row_limit": 2159, "on_trace_readi": 2159, "record_and_sav": 2159, "tensorboard_trace_handl": 2159, "dir_nam": 2159, "logdir": [2159, 2176], "code_to_profil": 2159, "trace_handl": 2159, "test_trace_": 2159, "step_num": 2159, "code_iteration_to_profil": 2159, "register_callback": 2159, "execution_trac": 2159, "test_execution_trace_with_kineto": 2159, "test_profil": 2159, "_itraceobserv": 2159, "get_trace_id": 2159, "set_custom_trace_id_callback": 2159, "skip_first": 2159, "skip_first_wait": 2159, "worker_nam": [2159, 2166], "use_gzip": 2159, "range_push": 2159, "range_pop": 2159, "mobile_optim": 2160, "model_zoo": 2160, "module_track": 2160, "__future__": 2160, "4x": 2161, "88": [2161, 2198], "14k": 2161, "domin": 2161, "previous_layer_fp32": 2161, "linear_fp32": 2161, "activation_fp32": 2161, "next_layer_fp32": 2161, "linear_weight_fp32": 2161, "linear_int8_w_fp32_inp": 2161, "linear_weight_int8": 2161, "ptdq": 2161, "model_fp32": 2161, "model_int8": 2161, "quantize_dynam": 2161, "input_fp32": 2161, "previous_layer_int8": 2161, "linear_with_activation_int8": 2161, "next_layer_int8": 2161, "ptsq": 2161, "minmax": 2161, "l2norm": 2161, "model_fp32_fus": 2161, "fuse_modul": [2161, 2162], "model_fp32_prepar": 2161, "fq": 2161, "prepare_qat": 2161, "training_loop": 2161, "requant": 2161, "linear1": 2161, "custom_qconfig": 2161, "fxptq": 2161, "model_fp": 2161, "usermodel": 2161, "model_to_quant": 2161, "default_dynamic_qconfig": 2161, "model_prepar": 2161, "model_quant": 2161, "model_fus": 2161, "quantize_pt2": 2161, "get_symmetric_quantization_config": 2161, "prepare_qat_pt2": 2161, "per_tensor_symmetr": [2161, 2164], "per_channel_symmetr": [2161, 2164], "per_channel_scal": 2161, "per_channel_zero_point": 2161, "quantized_tensor": 2161, "qengin": 2161, "in4": 2161, "tensorrt": [2161, 2183, 2190, 2195], "fx2trt": 2161, "float_modul": [2161, 2181], "staticquantcustommodul": 2161, "observed_modul": 2161, "default_qconfig": [2161, 2182], "vnni": 2161, "test_quantized_op": 2161, "testquantizedop": 2161, "test_custom_module_lstm": 2161, "test_quantize_fx": 2161, "testquantizefx": 2161, "test_static_lstm": 2161, "some_oper": 2161, "thnn_conv2d_forward": 2161, "quantizedcpu": 2161, "some_qconfig": 2161, "linearpackedparam": 2161, "_modul": 2161, "prepare_orig": 2161, "quantized_orig": 2161, "scripted_quant": 2161, "fp32_op": 2162, "int8_op": 2162, "cooperlak": 2162, "audit": 2162, "op_fp32": 2162, "op_int8": 2162, "_numeric_suit": 2162, "_numeric_suite_fx": 2162, "0x105880340": 2163, "0x11cefb700": 2163, "0x11cefb790": 2163, "num_tensor_args_to_observation_typ": 2163, "convbn1d": 2163, "0x11e7385e0": 2163, "reference_quantized_module_for_root": 2163, "fuse_convtranspose_bn": 2163, "0x11e738790": 2163, "linearbn1d": 2163, "fuse_linear_bn": 2163, "0x11e738700": 2163, "convbn2d": 2163, "convbn3d": 2163, "bnrelu2d": 2163, "bnrelu3d": 2163, "input_type_to_index": 2163, "conv_fus": 2163, "convbnrelu1d": 2163, "convbnrelu2d": 2163, "convbnrelu3d": 2163, "convrelu1d": 2163, "convrelu3d": 2163, "0x11cefb820": 2163, "0x11cefbe50": 2163, "quint4x2": [2163, 2173, 2177, 2178], "embedding_op": 2163, "0x11cefedc0": 2163, "00390625": 2163, "0x11cefe670": 2163, "0x11cefe820": 2163, "0x11cefbd30": 2163, "0x11cefec10": 2163, "0x11d08ad30": 2163, "0x11cefeca0": 2163, "0x11cefe040": 2163, "linear_fus": 2163, "_sequential_wrapper2": 2163, "0x1281c5a60": 2163, "0x11cefbc10": 2163, "0x1281c5af0": 2163, "fuse_conv_bn_relu": 2163, "0x11e738670": 2163, "0x1281c5b80": 2163, "0x1281c5c10": 2163, "0x1281c5ca0": 2163, "0x1281c5d30": 2163, "0x1281c5dc0": 2163, "0x1281c5e50": 2163, "0x1281c5ee0": 2163, "0x1281c5f70": 2163, "0x1281fd040": 2163, "0x1281fd0d0": 2163, "0x11cefbdc0": 2163, "0078125": 2163, "customconfig": 2164, "custom_module_config": 2164, "_caller": 2165, "_devices_kw": 2165, "slowli": 2165, "unind": 2165, "shortcom": 2166, "stitch": 2166, "init_rpc": [2166, 2167], "rpc_backend_opt": 2166, "trainer3": 2166, "parameterserver2": 2166, "backendtyp": 2166, "rpcbackendopt": 2166, "rpcagent": 2166, "transmit": 2166, "calle": [2166, 2168], "_set_rpc_timeout": 2166, "worker0": 2166, "my_script_add": 2166, "wire": 2166, "fut2": 2166, "meth": 2166, "userrref": [2166, 2168], "async_execut": 2166, "paus": 2166, "outmost": 2166, "async_add_chain": 2166, "worker2": 2166, "script_add": 2166, "async_add": 2166, "asyncexecutionclass": 2166, "static_async_add": 2166, "class_async_add": 2166, "ret_fut": 2166, "bound_async_add": 2166, "rpc_timeout": 2166, "incid": [2166, 2168], "multiplex": 2166, "tensorpiperpcbackendopt": 2166, "num_worker_thread": 2166, "device_map": 2166, "_transport": 2166, "tensorpipeag": 2166, "set_device_map": 2166, "intermitt": 2166, "backoff": 2166, "pyrref": 2166, "type_hint": 2166, "_distributed_rpc": 2166, "dist_autograd_ctx_id": 2166, "ctx_id": 2166, "ownerrref": [2166, 2168], "remote_modul": 2166, "forward_async": 2166, "remote_devic": 2166, "workernam": 2166, "ps0": 2166, "remote_linear_modul": 2166, "get_module_rref": 2166, "remote_paramet": 2166, "my_add": [2167, 2206], "t4": 2167, "t5": 2167, "autograd_message_id": 2167, "autograd_context_id": 2167, "send1": 2167, "kickoff": 2167, "recv2": 2167, "heard": 2167, "send2": 2167, "recv1": 2167, "dist_autograd_simpl": 2167, "random_tensor": 2167, "_run_process": 2167, "dst_rank": 2167, "dst_name": 2167, "run_process": 2167, "rrefid": 2168, "transient": 2168, "udf": 2168, "deliveri": 2168, "knowledg": 2168, "danger": 2168, "ancestor": 2168, "trickier": 2168, "forkid": 2168, "ack": 2168, "solid": 2168, "followup": 2168, "lil": 2171, "stark": 2171, "9093": 2171, "1411": 2171, "7568": 2171, "9589": 2171, "2794": 2171, "catastroph": [2171, 2204], "9900": 2171, "metadata_mask": 2171, "rce": 2171, "rc": 2171, "62": 2171, "to_sparse_semi_structur": 2171, "1x4": 2171, "16x16": 2171, "a_spars": 2171, "sparsesemistructuredtensor": 2171, "000": 2171, "400": 2171, "plain_dim_s": 2171, "lp64": 2171, "280": 2171, "310": 2171, "sp": 2171, "9078": 2171, "conception": 2171, "sparsesemistructur": 2171, "spsolv": 2171, "lobpcg": 2171, "geneig": 2171, "pca_lowrank": 2171, "kindli": 2171, "airy_ai": 2172, "airi": 2172, "9635": 2172, "entr": 2172, "3466": 2172, "int_": 2172, "8427": 2172, "4769": 2172, "9213": 2172, "8858": 2172, "7683": 2172, "7481": 2172, "2920": 2172, "int_0": 2172, "gammaln": 2172, "a1": 2172, "a2": 2172, "3528": 2172, "5665": 2172, "6472": 2172, "4335": 2172, "2650": 2172, "2661": 2172, "2796": 2172, "8808": 2172, "3019": 2172, "4658": 2172, "3085": 2172, "2430": 2172, "2070": 2172, "i1": 2172, "5652": 2172, "9534": 2172, "7595": 2172, "2153": 2172, "log_ndtr": 2172, "_ndtr": 2172, "6077": 2172, "7832": 2172, "841": 2172, "6931": 2172, "1728": 2172, "023": 2172, "9331": 2172, "6486": 2172, "1523": 2172, "6516": 2172, "6352": 2172, "6131": 2172, "7169": 2172, "6261": 2172, "displaystyl": 2172, "undefiend": 2172, "6835": 2172, "8474": 2172, "1929": 2172, "7162": 2172, "4180": 2172, "3928": 2172, "4007": 2172, "7586": 2172, "3901": 2172, "5049": 2172, "ndtr": 2172, "0228": 2172, "1587": 2172, "9772": 2172, "9987": 2172, "2p": 2172, "6745": 2172, "64493": 2172, "4041": 2172, "8288": 2172, "4939": 2172, "4091": 2172, "8863": 2172, "771": 2172, "scaled_modified_bessel_k0": 2172, "scaled_modified_bessel_k1": 2172, "2948": 2172, "0267": 2172, "1566": 2172, "9186": 2172, "8631": 2172, "0259": 2172, "1300": 2172, "spheric": 2172, "xlog1pi": 2172, "3863": 2172, "1972": 2172, "6094": 2172, "2189": 2172, "8283": 2172, "7726": 2172, "0986": 2172, "1589": 2172, "hurwitz": 2172, "6449": 2172, "0823": 2172, "interestingli": [2173, 2192], "FOr": 2173, "byteswap": 2173, "complex_doubl": 2173, "_storagebas": 2173, "from_buff": 2173, "is_hpu": 2173, "posix": 2173, "shm_unlink": 2173, "unlink": 2173, "floatstorag": 2173, "intstorag": 2173, "wrap_storag": 2173, "pickle_storage_typ": 2173, "doublestorag": 2173, "halfstorag": 2173, "longstorag": 2173, "shortstorag": 2173, "charstorag": 2173, "bytestorag": 2173, "boolstorag": 2173, "bfloat16storag": 2173, "complexdoublestorag": 2173, "complexfloatstorag": 2173, "quint8storag": 2173, "qint8storag": 2173, "qint32storag": 2173, "quint4x2storag": 2173, "quint2x4storag": 2173, "quint2x4": [2173, 2178], "twelv": 2174, "halftensor": [2174, 2177], "bfloat16tensor": [2174, 2177], "chartensor": [2174, 2177], "shorttensor": [2174, 2177], "binary16": [2174, 2177], "significand": [2174, 2177], "float_tensor": 2174, "double_tensor": 2174, "complex_float_tensor": 2174, "complex_double_tensor": 2174, "int_tensor": 2174, "long_tensor": 2174, "uint_tensor": 2174, "bool_tensor": 2174, "long_zerodim": 2174, "int_zerodim": 2174, "cuda1": 2174, "blogpost": [2175, 2192], "trainset": 2176, "mnist": 2176, "mnist_train": 2176, "trainload": 2176, "grayscal": 2176, "make_grid": 2176, "add_imag": 2176, "add_graph": 2176, "clutter": 2176, "n_iter": [2176, 2204], "purge_step": 2176, "max_queu": 2176, "flush_sec": 2176, "filename_suffix": 2176, "current_datetime_hostnam": 2176, "exp1": 2176, "global_step": 2176, "purg": 2176, "event_file_writ": 2176, "eventfilewrit": 2176, "may04_22": 2176, "54_": 2176, "macbook": 2176, "my_experi": 2176, "lr_0": 2176, "1_batch_16": 2176, "locallr_0": 2176, "scalar_valu": 2176, "walltim": 2176, "new_styl": 2176, "double_precis": 2176, "blobnam": 2176, "simple_valu": 2176, "main_tag": 2176, "tag_scalar_dict": 2176, "run_14h": 2176, "xsinx": 2176, "xcosx": 2176, "tanx": 2176, "add_histogram": 2176, "max_bin": 2176, "img_tensor": 2176, "dataformat": 2176, "chw": 2176, "hwc": 2176, "hw": 2176, "wh": 2176, "3xhxw": 2176, "img_hwc": 2176, "my_imag": 2176, "my_image_hwc": 2176, "img_batch": 2176, "my_image_batch": 2176, "add_figur": 2176, "add_video": 2176, "vid_tensor": 2176, "fp": 2176, "moviepi": 2176, "add_audio": 2176, "snd_tensor": 2176, "sample_r": 2176, "44100": 2176, "add_text": 2176, "text_str": 2176, "input_to_model": 2176, "use_strict_trac": 2176, "add_embed": 2176, "label_img": 2176, "metadata_head": 2176, "projector": 2176, "kwlist": 2176, "add_pr_curv": 2176, "num_threshold": 2176, "pr_curv": 2176, "add_custom_scalar": 2176, "chart": 2176, "categorynam": 2176, "chartnam": 2176, "listofproperti": 2176, "multilin": 2176, "taiwan": 2176, "twse": 2176, "0050": 2176, "2330": 2176, "dow": 2176, "aaa": 2176, "bbb": 2176, "ccc": 2176, "nasdaq": 2176, "add_mesh": 2176, "config_dict": 2176, "threej": 2176, "vertex": 2176, "number_of_vertic": 2176, "vertices_tensor": 2176, "colors_tensor": 2176, "faces_tensor": 2176, "my_mesh": 2176, "add_hparam": 2176, "hparam_dict": 2176, "metric_dict": 2176, "hparam_domain_discret": 2176, "run_nam": 2176, "hparam": 2176, "bsize": 2176, "uint16": [2177, 2195], "uint32": [2177, 2195], "uint64": [2177, 2195], "e4m3": 2177, "e5m2": 2177, "asid": 2177, "58734": 2177, "2209": 2177, "05433": 2177, "tini": [2177, 2178, 2198, 2210], "_like": 2177, "coercion": 2177, "allow_subclass": 2178, "check_devic": 2178, "check_layout": 2178, "6e": 2178, "3e": 2178, "assert_equ": 2178, "000000000000001e": 2178, "1e0": 2178, "argh": 2178, "nfooter": 2178, "66": 2178, "footer": 2178, "make_tensor": 2178, "exclude_zero": 2178, "1205": 2178, "2282": [2178, 2204], "6380": 2178, "assert_allclos": 2178, "check_avail": 2180, "default_gener": 2180, "click": [2180, 2201, 2202], "as_integer_ratio": 2180, "hexadecim": 2180, "is_integ": 2180, "data_dependent_output": 2180, "dynamic_output_shap": 2180, "flexible_layout": 2180, "inplace_view": 2180, "maybe_aliasing_or_mut": 2180, "needs_fixed_stride_ord": 2180, "nondeterministic_bitwis": 2180, "nondeterministic_seed": 2180, "pt2_compliant_tag": 2180, "compare_weight": 2181, "float_dict": 2181, "quantized_dict": 2181, "wt_compare_dict": 2181, "qmodel": 2181, "compute_error": 2181, "weight_dict": 2181, "get_logger_dict": 2181, "shadowlogg": 2181, "outputlogg": [2181, 2182], "target_dict": 2181, "q_modul": 2181, "logger_cl": [2181, 2182], "prepare_model_with_stub": 2181, "module_swap_list": 2181, "q_model": 2181, "ob_dict": 2181, "compare_model_stub": 2181, "quantizablebasicblock": 2181, "get_matching_activ": 2181, "act_dict": 2181, "prepare_model_output": 2181, "compare_model_output": 2181, "act_compare_dict": 2181, "weight_comparison": 2182, "extract_weight": 2182, "extend_logger_results_with_comparison": 2182, "compute_sqnr": 2182, "mp_n": 2182, "mq_n": 2182, "add_logg": 2182, "act_comparison": 2182, "extract_logger_info": 2182, "mp_shadows_mq": 2182, "add_shadow_logg": 2182, "shadow_act_comparison": 2182, "extract_shadow_logger_info": 2182, "ref_node_nam": 2182, "prev_node_nam": 2182, "model_nam": 2182, "ref_nam": 2182, "prev_node_target_typ": 2182, "ref_node_target_typ": 2182, "results_typ": 2182, "index_within_arg": 2182, "index_of_arg": 2182, "qconfig_str": 2182, "outputcomparisonlogg": 2182, "x_ref": 2182, "nstracer": 2182, "skipped_module_nam": 2182, "skipped_module_class": 2182, "model_name_a": 2182, "model_a": 2182, "model_name_b": 2182, "model_b": 2182, "base_name_to_sets_of_related_op": 2182, "unmatchable_types_map": 2182, "op_to_type_to_weight_extraction_fn": 2182, "unmatch": 2182, "nsresultstyp": 2182, "name_a": 2182, "name_b": 2182, "should_log_input": 2182, "model_a_with_logg": 2182, "model_b_with_logg": 2182, "model_name_to_use_for_layer_nam": 2182, "node_type_to_io_type_map": 2182, "model_a_shadows_b": 2182, "model_name_1": 2182, "model_name_2": 2182, "comparison_fn": 2182, "comparison_nam": 2182, "prepare_n_shadows_model": 2182, "qconfig_multi_map": 2182, "custom_prepare_fn": 2182, "custom_prepare_kwarg": 2182, "custom_trac": 2182, "args_kwargs_m": 2182, "op_m": 2182, "output_m": 2182, "op_m_n": 2182, "log_m_n": 2182, "log_m_0": 2182, "qconfig_n": 2182, "args_m": 2182, "op_m_prepared_with_qconfig_n": 2182, "out_m_n": 2182, "kwargs_m": 2182, "docblock": 2182, "loggers_set_en": 2182, "loggers_set_save_activ": 2182, "save_activ": 2182, "convert_n_shadows_model": 2182, "custom_convert_fn": 2182, "custom_convert_kwarg": 2182, "extract_results_n_shadows_model": 2182, "print_comparisons_n_shadows_model": 2182, "compute_normalized_l2_error": 2182, "compute_cosine_similar": 2182, "openai": 2183, "ipex": 2183, "torch_tensorrt": 2183, "tvm": 2183, "apach": 2183, "openvino": 2183, "aotinductor": 2183, "dashboard": [2183, 2193, 2198], "nnmodul": 2183, "_functorch": [2184, 2186], "preempt": 2184, "torch_compile_job_id": 2184, "operation": 2184, "pgo": 2184, "enable_compiler_collect": 2184, "aoti_compile_and_packag": [2185, 2186], "torchinductor_freez": 2185, "batch_dim": 2185, "output_path": 2185, "package_path": [2185, 2186], "getcwd": 2185, "convini": 2185, "aoti_load_packag": [2185, 2186], "aoti_packag": 2185, "model_package_load": 2185, "aotimodelpackageload": 2185, "kcuda": 2185, "cmakelist": 2185, "aoti_exampl": 2185, "cmake_minimum_requir": 2185, "fatal_error": 2185, "find_packag": 2185, "add_execut": 2185, "add_custom_command": 2185, "cmake_current_source_dir": 2185, "target_link_librari": 2185, "set_properti": 2185, "cxx_standard": 2185, "cmake_prefix_path": 2185, "mkdir": 2185, "5184": 2185, "4462": 2185, "4611": 2185, "4744": 2185, "4811": 2185, "4938": 2185, "4193": 2185, "cudafloattyp": 2185, "4883": 2185, "4703": 2185, "minifi": [2185, 2190, 2195], "aoti_runtime_check_input": 2185, "_deprecated_unused_arg": 2185, "_deprecated_unused_kwarg": 2185, "inductor_config": [2185, 2186], "ep1": 2185, "aoti_file1": 2185, "aot_compil": 2185, "ep2": 2185, "aoti_file2": 2185, "package_aoti": 2185, "load_packag": 2185, "compiled_model1": 2185, "compiled_model2": 2185, "_indcutor": 2186, "aot_inductor": 2186, "dump_aoti_minifi": 2186, "minifier_launch": [2186, 2205], "debug_dir_root": [2186, 2205], "inject_relu_bug_testing_onli": 2186, "compile_error": 2186, "compiled_model": 2186, "torchinductor_shangdii": 2186, "fr": 2186, "cfrlf4smkwe4lub4i4cahkrb3qiczhf7hliqqwpewbw3aplj5g3": 2186, "syntaxerror": 2186, "triton_poi_fused_addmm_relu_sigmoid_0": 2186, "in_out_ptr0": 2186, "xnumel": [2186, 2197], "xblock": [2186, 2197], "xoffset": [2186, 2197], "xindex": [2186, 2197], "xmask": [2186, 2197], "tmp0": [2186, 2197], "tmp1": [2186, 2197], "eviction_polici": 2186, "evict_last": 2186, "tmp2": [2186, 2197], "tmp3": 2186, "tmp4": 2186, "w1031": 2186, "612000": 2186, "2861654": 2186, "debug_util": [2186, 2205], "279": 2186, "shangdii": 2186, "torch_compile_debug": [2186, 2195, 2197], "run_2024_10_31_16_21_08_602433": 2186, "pid_2861654": 2186, "inductor_prim": 2186, "_config": 2186, "isolate_fails_code_str": 2186, "0a0": [2186, 2205], "gitcd9c6e9": 2186, "cd9c6e9408dd79175712223895eed36dbdc84f84": 2186, "fri_jan__6_16": 2186, "21_pst_2023": 2186, "v12": 2186, "140": 2186, "cuda_12": 2186, "r12": 2186, "32267302_0": 2186, "pg509": 2186, "210": 2186, "run_2024_11_06_13_52_35_711642": 2186, "pid_3567062": 2186, "config_patch": 2186, "aoti": 2186, "run_repro": 2186, "save_dir": 2186, "check_str": 2186, "938000": 2186, "3598491": 2186, "run_2024_10_31_16_48_02_720863": 2186, "pid_3598491": 2186, "975000": 2186, "aotiminifiererror": 2186, "rand_strid": [2186, 2205], "generate_intermediate_hook": 2186, "run_2024_11_25_13_59_33_102283": 2186, "pid_3658904": 2186, "simd": 2188, "isa": 2188, "amx": 2188, "collect_env": 2188, "avx512f": 2188, "avx512bw": 2188, "avx512_vnni": 2188, "amx_til": 2188, "amx_bf16": 2188, "amx_int8": 2188, "debut": 2189, "cachingalloc": 2189, "cudagraph_tre": 2189, "cudagraph1": 2189, "cudagraph2": 2189, "mut": 2189, "cudagraph_support_input_mut": 2189, "cudagraph_mark_step_begin": 2189, "profit": 2189, "kb": 2189, "550": 2189, "enjoi": [2189, 2204], "cudagraph_skip_dynamic_graph": 2189, "dense_to_jag": 2189, "jagged_to_padded_dens": 2189, "run_and_save_rng_st": 2189, "run_with_rng_st": 2189, "unintend": 2189, "prematur": 2189, "mark_step_begin": 2189, "my_custom_backend": 2190, "f_opt": 2190, "my_compil": [2190, 2193], "torch_dynamo_backend": 2190, "your_modul": 2190, "aot_autograd": 2190, "fw_compil": 2190, "bw_compil": 2190, "make_boxed_func": 2190, "model_opt": 2190, "0x7f1a894649a8": 2190, "mockmodul": 2190, "optimized_mod": 2190, "toy_exampl": [2190, 2193, 2195, 2205], "abs_1": [2190, 2193], "0x7f8d259298a0": 2190, "superior": 2190, "optimize_for_inference_compil": 2190, "code_to_acceler": 2190, "lookup_backend": 2190, "trt_compil": 2190, "inductor_compil": 2190, "recognit": 2191, "induct": 2191, "mark_dynam": [2191, 2192], "shapeenv": [2191, 2194], "reusabl": 2191, "plumb": 2191, "symnodeimpl": 2191, "python_symnod": 2191, "_meta_registr": 2191, "primtorch": [2191, 2194], "apparatu": 2191, "constrain_rang": 2191, "wherebi": 2191, "blame": 2192, "insan": 2192, "backtrac": [2192, 2194, 2205], "blindli": 2192, "arduou": 2192, "l_x_": [2192, 2204], "l_y_": 2192, "l_n_": 2192, "sequel": 2192, "_convert_frame_assert": 2192, "variabletrack": 2192, "listvari": 2192, "constantvari": [2192, 2195, 2204, 2205], "tensorvari": [2192, 2195, 2204, 2205], "variablebuild": 2192, "_wrap": [2192, 2204], "userdefinedobjectvari": 2192, "sourcebuild": 2192, "load_glob": [2192, 2193, 2204], "torchingraphfunctionvari": [2192, 2204], "instructortranslatorbas": 2192, "symbolic_convert": [2192, 2204, 2205], "instructiontranslatorbas": 2192, "build_list": 2192, "inst": [2192, 2204], "popn": 2192, "argval": [2192, 2204], "mutation_typ": 2192, "valuemutationnew": 2192, "instructiontransl": 2192, "wrap_fx_proxi": 2192, "disregard": 2192, "overkil": 2192, "___check_type_id": 2192, "94334122025024": 2192, "9433": 2192, "getitemsourc": 2192, "94439025877664": 2192, "94439025840192": 2192, "saw": 2192, "l_a_": [2192, 2193], "l_b_": [2192, 2193], "__compiled_fn_1": [2192, 2204], "check_tensor": [2192, 2193, 2204], "maybe_mark_dynam": 2192, "mark_stat": 2192, "symnodevari": 2192, "812": 2192, "evaluate_expr": 2192, "django": 2192, "rust": 2192, "choke": 2192, "doctr_det_predictor": 2192, "cv2": 2192, "postprocess": 2192, "confess": 2192, "revisit": 2192, "__compiled_fn_0": [2192, 2193], "load_fast": [2192, 2193, 2204], "store_fast": [2192, 2193, 2204], "graph_out_0": 2192, "load_const": [2192, 2193], "binary_subscr": 2192, "__resume_at_14_1": 2192, "rot_two": 2192, "resume_in_fn": 2192, "__compiled_fn_2": 2192, "unpack_sequ": [2192, 2193], "l6": 2192, "l8": 2192, "l20": 2192, "l22": 2192, "hamper": 2192, "ride": 2192, "demystifi": 2192, "literatur": 2192, "eval_fram": [2192, 2193], "lingo": 2192, "523": 2193, "watch": 2193, "kaichao": 2193, "_dynamo_dynamic_indic": [2193, 2204], "utils_devic": [2193, 2204], "___skip_backend_check": 2193, "___current_backend": 2193, "___lookup_backend": 2193, "140355900538256": 2193, "dispatchkeyset": [2193, 2204], "backendselect": [2193, 2204], "adinplaceorview": [2193, 2204], "autogradcpu": [2193, 2204], "recaptur": 2193, "decompil": 2193, "depyf": 2193, "eval_with_kei": 2193, "0x7f9ca082f8a0": 2193, "load_method": 2193, "binary_add": 2193, "binary_true_divid": 2193, "compare_op": 2193, "pop_jump_if_fals": 2193, "binary_multipli": 2193, "__resume_at_30_1": 2193, "__resume_at_38_2": 2193, "__temp_1": 2193, "youkaichao": 2193, "__resume_at_": 2193, "jump_absolut": 2193, "resume_at": 2193, "_debug_get_cache_entry_list": 2193, "__code__": 2193, "codetyp": 2193, "innermost_fn": 2193, "cache_entri": 2193, "check_fn": 2193, "code_part": 2193, "___guarded_cod": 2193, "___check_global_st": [2193, 2204], "140215810860528": 2193, "___check_tensor": 2193, "tensor_check_nam": 2193, "co_freevar": 2193, "__closure__": 2193, "___is_grad_en": 2193, "___are_deterministic_algorithms_en": 2193, "___is_torch_function_en": 2193, "value_a": 2193, "value_b": 2193, "__self__": 2193, "compiled_exampl": 2193, "get_cache_entri": 2193, "recompile_and_add_another_cache_entri": 2193, "trash": 2194, "subclass_zoo": 2194, "bunch": 2194, "from_real_tensor": 2194, "fakeifi": 2194, "dispatch_devic": 2194, "ly": 2194, "derefer": 2194, "in_kernel_invocation_manag": 2194, "test_fake_tensor": 2194, "fake_mod": 2194, "fake_tensor_convert": 2194, "fake_x": 2194, "fake_i": 2194, "fake_z": 2194, "_guard": 2194, "detect_fake_mod": 2194, "fake_arg": 2194, "unset_fake_temporarili": 2194, "nich": 2194, "faketensorprop": 2194, "fake_tensor_prop": 2194, "propagate_dont_convert_input": 2194, "fake_input": 2194, "real_tensor": 2194, "annoi": 2194, "somehow": 2194, "fakecopymod": 2194, "gave": 2194, "fakeif": 2194, "tension": 2194, "analys": 2194, "metaconvert": 2194, "die": 2194, "evalfram": 2195, "usercod": 2195, "rob": 2195, "diminish": 2195, "vast": 2195, "250k": 2195, "aitempl": 2195, "aot_eag": [2195, 2204, 2205], "compile_tim": [2195, 2202, 2205], "recompile_limit": [2195, 2204, 2205], "troubl": [2195, 2196, 2204], "traffic": 2195, "frozen_toy_exampl": 2195, "multiprocessor": 2195, "some_fun": [2195, 2205], "insurmount": [2195, 2205], "woo": [2195, 2205], "framesummari": [2195, 2205], "generic_jump": [2195, 2205], "torch_dynamo_resume_in_toy_example_at_5": [2195, 2205], "torchdynamo_dynamic_shap": 2195, "cv": 2195, "app": 2195, "unnecessarili": 2195, "cold": [2195, 2201, 2204], "visibli": 2195, "torchdynamo_repro_level": [2195, 2204, 2205], "bisect": [2195, 2205], "torchdynamo_repro_aft": [2195, 2204, 2205], "dramat": [2195, 2205], "allevi": 2195, "wrapper_fn": 2195, "my_fn": 2195, "pitfal": 2195, "_indices_from": 2195, "recarrai": 2195, "float128": 2195, "complex256": 2195, "esoter": 2195, "ufunc": 2195, "poly1d": 2195, "__array_wrap__": 2195, "ctype": 2195, "numpy_fn": 2195, "tweak": 2195, "wrap_numpi": 2195, "charg": 2195, "oop": 2195, "daunt": 2195, "pinpoint": 2195, "discern": 2195, "trace_numpi": 2195, "_numpi": 2195, "uncommon": [2195, 2204], "finer": 2195, "a_fn": [2195, 2196], "aa_fn": [2195, 2196], "ab_fn": [2195, 2196], "unblock": 2196, "nnthi": 2196, "nnnote": 2196, "screen": [2196, 2202], "is_dynamo_compil": 2196, "is_export": 2196, "b_fn": 2196, "new_fn": 2197, "famou": 2197, "crunch": 2197, "torchinductor_": 2197, "your_usernam": 2197, "triton_meta": 2197, "out_ptr0": 2197, "i32": 2197, "mutated_arg_nam": 2197, "attrsdescriptor": 2197, "divisible_by_16": 2197, "equal_to_1": 2197, "triton_": [2197, 2202], "v0": 2197, "opt_model": [2197, 2204], "timm": [2197, 2201], "berttoken": 2197, "bertmodel": 2197, "uncas": 2197, "me": 2197, "encoded_input": 2197, "return_tensor": 2197, "trigonometri": 2197, "skim": 2197, "create_model": 2197, "resnext101_32x8d": 2197, "torchinductor_unique_kernel_nam": 2198, "triton_poi_fused_cat_155": 2198, "poi": 2198, "torchinductor_benchmark_kernel": 2198, "har": 2198, "torchinductor_max_autotun": 2198, "mixnet_l": 2198, "timm_model": 2198, "torchinductor_shunt": 2198, "qz": 2198, "cqz7hvhood7y3psp7fy6msjxsxyli7qiwiybizdwtjw6ffyq5wwd": 2198, "c2a4d8a28b00fcb5586d0e9d9bf77f9f": 2198, "48efc83b12ec3ead950052e4a0220b10": 2198, "compiled_module_profil": 2198, "zoom": [2198, 2202, 2207], "distort": [2198, 2202], "densenet121": 2198, "69": 2198, "cutlass": 2198, "57": 2198, "ff": 2198, "justifi": 2198, "triton_red_fus": 2198, "__native_batch_norm_legit_functional_16": 2198, "cjk2vm3446xrk7rth7hr6pun7xxo3dnzubwcn6ydrpifal4eykrz": 2198, "_adaptive_avg_pool2d_backward": 2199, "no_stat": 2199, "start_step": 2199, "avg_pool2d_backward": 2199, "convolution_backward": 2199, "bias_siz": 2199, "output_mask": 2199, "scalar_mod": 2199, "tensor_mod": 2199, "embedding_dense_backward": 2199, "num_weight": 2199, "max_pool2d_with_indices_backward": 2199, "native_group_norm_backward": 2199, "rstd": 2199, "native_layer_norm_backward": 2199, "tensor_scalar": 2199, "tensor_tensor": 2199, "dim_int": 2199, "dim_intlist": 2199, "broadcast_dimens": 2199, "outer_length": 2199, "orchestr": 2200, "_forward_pre_hook": 2200, "_backward_pre_hook": 2200, "_backward_hook": 2200, "_state_dict_hook": 2200, "load_": 2200, "avoiabl": 2200, "skip_nnmodule_hook_guard": 2200, "pre_backward": 2200, "warn_onc": 2200, "hui": 2201, "night": 2201, "40gb": [2201, 2205], "2ghz": 2201, "torchbench": 2201, "trend": 2201, "droplist": 2201, "with_cudagraph": 2201, "omnitrac": 2202, "model_c": 2202, "fwd_bwd": 2202, "scroll": 2202, "shortcut": 2202, "compiledfunctionbackward": 2202, "ac2g": 2202, "dropdown": 2202, "525": 2202, "_init_for_cuda_graph": 2202, "warmup_compil": 2202, "fn_c": 2202, "trace_compil": 2202, "meanwhil": 2202, "clue": 2202, "synthet": 2202, "modelwithbreak": 2202, "create_sequenti": 2202, "mod1": 2202, "mod2": 2202, "mod3": 2202, "mod4": 2202, "trace_break": 2202, "culaunchkernel": 2202, "cudalaunchkernel": 2202, "unique_kernel_nam": 2202, "sit": 2203, "replace_add_with_mul": 2203, "insert_relu_after_add": 2203, "new_relu_nod": 2203, "replaceaddwithmul": 2203, "transformed_graph_modul": 2203, "replaceaddwithmulsub": 2203, "mul_r": 2203, "removedetachpass": 2203, "args_map": 2203, "_schema": 2203, "kwarg_onli": 2203, "scalartotensorpass": 2203, "try_coerc": 2203, "replace_pattern": 2203, "replaced_pattern": 2203, "replace_pattern_with_filt": 2203, "replacedpattern": 2203, "passmanag": 2203, "pass_manag": 2203, "pm": 2203, "replace_add_with_div": 2203, "replace_div_with_mul": 2203, "run_checks_after_each_pass": 2203, "suppress_check_failur": 2203, "graph_module_out": 2203, "set_check": 2203, "check_div_target": 2203, "add_check": 2203, "subgraphmatch": 2203, "match_output": 2203, "match_placehold": 2203, "remove_overlapping_match": 2203, "ignore_liter": 2203, "matcher_util": 2203, "largemodel": 2203, "_bia": 2203, "large_model_graph": 2203, "patternmodel": 2203, "_weight_1": 2203, "_bias_1": 2203, "pattern_graph": 2203, "subgraph_match": 2203, "match_result": 2203, "internalmatch": 2203, "placeholder_nod": 2203, "returning_nod": 2203, "capabilitybasedpartition": 2203, "operator_support": 2203, "operatorsupportbas": 2203, "allows_single_node_partit": 2203, "non_compute_op": 2203, "_oper": 2203, "allowed_single_node_partition_op": 2203, "is_node_support": 2203, "any_chain": 2203, "addmuloperatorsupport": 2203, "capability_partition": 2203, "op_support": 2203, "partition_list": 2203, "propose_partit": 2203, "fused_graph_modul": 2203, "fuse_partit": 2203, "overcom": 2204, "uncach": 2204, "upward": 2204, "hour": 2204, "playground": 2204, "williamwen": 2204, "635": 2204, "inner_fn": 2204, "2408": 2204, "962": 2204, "997": 2204, "tx": 2204, "831": 2204, "unimpl": 2204, "case_nam": 2204, "tensor_match": 2204, "tree_guard_manag": 2204, "rootguardmanag": 2204, "default_devic": 2204, "output_graph": 2204, "471": 2204, "init_ambient_guard": 2204, "global_st": 2204, "torch_function_mode_stack": 2204, "___check_torch_function_mode_stack": 2204, "guardmanag": 2204, "accessed_bi": 2204, "dictgetitemguardaccessor": 2204, "no_hasattr": 2204, "2718": 2204, "torchdynamo_extended_debug_create_symbol": [2204, 2205], "mit": 2204, "bhack": 2204, "20240609": 2204, "reproduct": 2204, "tracedir": 2204, "upload": [2204, 2207], "trie": 2204, "suspici": 2204, "compilation_metr": 2204, "option1": 2204, "bad1_inn": 2204, "bad1_out": 2204, "bad2_inn": 2204, "bad2_out": 2204, "suppress_error": 2204, "negati": 2204, "torch_dynamo_resume_in_fn_at_6": 2204, "616": 2204, "2288": 2204, "838": 2204, "misc": 2204, "1038": 2204, "527": 2204, "handler_method": 2204, "773": 2204, "method_item": 2204, "304": 2204, "torchdynamo_capture_scalar_output": 2204, "reorderable_logging_funct": 2204, "0x7fd6fd764600": 2204, "accumulated_recompile_limit": 2204, "004782969000000002": 2204, "005314410000000002": 2204, "005904900000000002": 2204, "006561000000000002": 2204, "007290000000000001": 2204, "008100000000000001": 2204, "009000000000000001": 2204, "aot_eager_decomp_partit": 2204, "unfamiliar": 2204, "docker": 2204, "perfect": 2204, "nowadai": 2204, "diagnos": 2204, "starts_lin": 2204, "load_attr": 2204, "nullvari": 2204, "pythonmodulevari": 2204, "0x7f00f6964600": 2204, "lazyvariabletrack": 2204, "userfunctionvari": 2204, "binary_op": 2204, "_lazy_graph_modul": 2204, "store_attr": 2204, "comptim": 2204, "print_bt": 2204, "print_loc": 2204, "print_graph": 2204, "disa": 2204, "bt": 2204, "392": 2204, "826": 2204, "331": 2204, "comptimecontext": 2204, "lazo": 2205, "torchdynamo_verbos": 2205, "replay_record_en": 2205, "torchdynamo_debug_funct": 2205, "test_assertion_error": 2205, "compiled_test_assertion_error": 2205, "convert_fram": 2205, "mlazo": 2205, "837": 2205, "build_map": 2205, "log_level": 2205, "test_backend_error": 2205, "compiled_test_backend_error": 2205, "decomp_fn": 2205, "810": 2205, "repro_aft": 2205, "base_dir": 2205, "gitfddfc44": 2205, "fddfc4488afb207971c54ad4bf58130fdc8a4dc5": 2205, "2022": 2205, "thu_feb_10_18": 2205, "41_pst_2022": 2205, "v11": 2205, "cuda_11": 2205, "r11": 2205, "30978841_0": 2205, "sxm4": 2205, "compile_fx_inn": 2205, "toy_compil": 2205, "run_fwd_maybe_bwd": 2205, "opt_mod": 2205, "rg": 2205, "test_model": 2205, "torch_compile_debug_dir": 2205, "run_2023_03_01_08_20_52_143510": 2205, "pid_180167": 2205, "model__0_forward_1": 2205, "aot_model___0_debug": 2205, "fx_graph_read": 2205, "fx_graph_runn": 2205, "fx_graph_transform": 2205, "ir_post_fus": 2205, "ir_pre_fus": 2205, "fx_graph": 2205, "buf1": 2205, "schedulernod": 2205, "computedbuff": 2205, "memorydep": 2205, "unmet_depend": 2205, "buf0": 2205, "met_depend": 2205, "primals_2": 2205, "buf1_loop_bodi": 2205, "var_rang": 2205, "z0": 2205, "index0": 2205, "index1": 2205, "get_index": 2205, "get_index_1": 2205, "load_1": 2205, "get_index_2": 2205, "compiled_fun": 2205, "hinder": 2205, "explanation_verbos": 2205, "out_guard": 2205, "ops_per_graph": 2205, "compiled_toi": 2205, "torchdynamo_extended_debug_guard_ad": 2205, "u2": 2205, "torchdynamo_extended_debug_cpp": 2205, "torchinductor_force_disable_cach": 2205, "force_disable_cach": 2205, "as_subclass": 2206, "handle_torch_funct": 2206, "public_api": 2206, "relevant_arg": 2206, "has_torch_function_unari": 2206, "is_tensor_lik": 2206, "notatensor": 2206, "tensorlik": 2206, "is_tensor_method_or_properti": 2206, "__get__": 2206, "wrap_torch_funct": 2206, "interactiv": 2207, "viewer": 2207, "run_your_cod": 2207, "my_snapshot": 2207, "javascript": 2207, "pan": 2207, "mous": 2207, "slider": 2207, "b7f064c000000_0": 2207, "7f064c000000": 2207, "max_entri": 2207, "_snapshot": 2207, "_memory_viz": 2207, "2u": 2207, "50n": 2207, "currenli": 2207, "typeddict": 2207, "device_trac": 2207, "traceentri": 2207, "total_s": 2207, "segment_typ": 2207, "allocated_s": 2207, "active_s": 2207, "active_awaiting_fre": 2207, "requested_s": 2207, "active_alloc": 2207, "took": 2207, "free_request": 2207, "free_complet": 2207, "segment_alloc": 2207, "segment_fre": 2207, "coorel": 2207, "device_fre": 2207, "dump_snapshot": 2207, "interplai": 2208, "miscellan": 2208, "torch_nccl_async_error_handl": 2209, "torch_nccl_high_prior": 2209, "torch_nccl_dump_on_timeout": 2209, "torch_nccl_trace_buffer_s": 2209, "torch_nccl_desync_debug": 2209, "desync": 2209, "culprit": 2209, "torch_nccl_enable_tim": 2209, "torch_nccl_enable_monitor": 2209, "torch_nccl_heartbeat_timeout_sec": 2209, "prolong": 2209, "flight": 2209, "ring": 2209, "tracebuff": 2209, "torch_nccl_trace_cpp_stack": 2209, "torch_nccl_coord_check_milsec": 2209, "torch_nccl_wait_timeout_dump_milsec": 2209, "torch_nccl_debug_info_temp_fil": 2209, "torch_nccl_debug_info_pipe_fil": 2209, "torch_nccl_nan_check": 2209, "smallest_norm": 2210, "subnorm": 2210, "denormal_numb": 2210, "tailor": 2212}, "objects": {"": [[2180, 0, 0, "-", "torch"], [2093, 8, 1, "-", "PYTORCH_JIT"]], "torch": [[2173, 1, 1, "", "BFloat16Storage"], [2173, 1, 1, "", "BoolStorage"], [2173, 1, 1, "", "ByteStorage"], [2173, 1, 1, "", "CharStorage"], [2173, 1, 1, "", "ComplexDoubleStorage"], [2173, 1, 1, "", "ComplexFloatStorage"], [2173, 1, 1, "", "DoubleStorage"], [2173, 1, 1, "", "FloatStorage"], [87, 1, 1, "", "Generator"], [2173, 1, 1, "", "HalfStorage"], [2173, 1, 1, "", "IntStorage"], [2173, 1, 1, "", "LongStorage"], [2173, 1, 1, "", "QInt32Storage"], [2173, 1, 1, "", "QInt8Storage"], [2173, 1, 1, "", "QUInt2x4Storage"], [2173, 1, 1, "", "QUInt4x2Storage"], [2173, 1, 1, "", "QUInt8Storage"], [2173, 1, 1, "", "ShortStorage"], [2170, 1, 1, "", "Size"], [88, 1, 1, "", "Stream"], [2180, 1, 1, "", "SymBool"], [2180, 1, 1, "", "SymFloat"], [2180, 1, 1, "", "SymInt"], [2180, 1, 1, "", "Tag"], [2177, 1, 1, "", "Tensor"], [2173, 1, 1, "", "TypedStorage"], [2173, 1, 1, "", "UntypedStorage"], [15, 0, 0, "-", "__config__"], [67, 0, 0, "-", "__future__"], [625, 5, 1, "", "_assert"], [626, 5, 1, "", "_foreach_abs"], [627, 5, 1, "", "_foreach_abs_"], [628, 5, 1, "", "_foreach_acos"], [629, 5, 1, "", "_foreach_acos_"], [630, 5, 1, "", "_foreach_asin"], [631, 5, 1, "", "_foreach_asin_"], [632, 5, 1, "", "_foreach_atan"], [633, 5, 1, "", "_foreach_atan_"], [634, 5, 1, "", "_foreach_ceil"], [635, 5, 1, "", "_foreach_ceil_"], [636, 5, 1, "", "_foreach_cos"], [637, 5, 1, "", "_foreach_cos_"], [638, 5, 1, "", "_foreach_cosh"], [639, 5, 1, "", "_foreach_cosh_"], [640, 5, 1, "", "_foreach_erf"], [641, 5, 1, "", "_foreach_erf_"], [642, 5, 1, "", "_foreach_erfc"], [643, 5, 1, "", "_foreach_erfc_"], [644, 5, 1, "", "_foreach_exp"], [645, 5, 1, "", "_foreach_exp_"], [646, 5, 1, "", "_foreach_expm1"], [647, 5, 1, "", "_foreach_expm1_"], [648, 5, 1, "", "_foreach_floor"], [649, 5, 1, "", "_foreach_floor_"], [650, 5, 1, "", "_foreach_frac"], [651, 5, 1, "", "_foreach_frac_"], [652, 5, 1, "", "_foreach_lgamma"], [653, 5, 1, "", "_foreach_lgamma_"], [654, 5, 1, "", "_foreach_log"], [655, 5, 1, "", "_foreach_log10"], [656, 5, 1, "", "_foreach_log10_"], [657, 5, 1, "", "_foreach_log1p"], [658, 5, 1, "", "_foreach_log1p_"], [659, 5, 1, "", "_foreach_log2"], [660, 5, 1, "", "_foreach_log2_"], [661, 5, 1, "", "_foreach_log_"], [662, 5, 1, "", "_foreach_neg"], [663, 5, 1, "", "_foreach_neg_"], [664, 5, 1, "", "_foreach_reciprocal"], [665, 5, 1, "", "_foreach_reciprocal_"], [666, 5, 1, "", "_foreach_round"], [667, 5, 1, "", "_foreach_round_"], [668, 5, 1, "", "_foreach_sigmoid"], [669, 5, 1, "", "_foreach_sigmoid_"], [670, 5, 1, "", "_foreach_sin"], [671, 5, 1, "", "_foreach_sin_"], [672, 5, 1, "", "_foreach_sinh"], [673, 5, 1, "", "_foreach_sinh_"], [674, 5, 1, "", "_foreach_sqrt"], [675, 5, 1, "", "_foreach_sqrt_"], [676, 5, 1, "", "_foreach_tan"], [677, 5, 1, "", "_foreach_tan_"], [678, 5, 1, "", "_foreach_trunc"], [679, 5, 1, "", "_foreach_trunc_"], [680, 5, 1, "", "_foreach_zero_"], [2102, 0, 0, "-", "_logging"], [682, 5, 1, "", "abs"], [683, 5, 1, "", "absolute"], [0, 0, 0, "-", "accelerator"], [694, 5, 1, "", "acos"], [695, 5, 1, "", "acosh"], [696, 5, 1, "", "add"], [697, 5, 1, "", "addbmm"], [698, 5, 1, "", "addcdiv"], [699, 5, 1, "", "addcmul"], [700, 5, 1, "", "addmm"], [701, 5, 1, "", "addmv"], [702, 5, 1, "", "addr"], [703, 5, 1, "", "adjoint"], [704, 5, 1, "", "all"], [705, 5, 1, "", "allclose"], [706, 5, 1, "", "amax"], [707, 5, 1, "", "amin"], [708, 5, 1, "", "aminmax"], [1, 0, 0, "-", "amp"], [709, 5, 1, "", "angle"], [710, 5, 1, "", "any"], [2161, 0, 0, "-", "ao"], [895, 5, 1, "", "arange"], [896, 5, 1, "", "arccos"], [897, 5, 1, "", "arccosh"], [898, 5, 1, "", "arcsin"], [899, 5, 1, "", "arcsinh"], [900, 5, 1, "", "arctan"], [901, 5, 1, "", "arctan2"], [902, 5, 1, "", "arctanh"], [903, 5, 1, "", "are_deterministic_algorithms_enabled"], [904, 5, 1, "", "argmax"], [905, 5, 1, "", "argmin"], [906, 5, 1, "", "argsort"], [907, 5, 1, "", "argwhere"], [908, 5, 1, "", "as_strided"], [909, 5, 1, "", "as_tensor"], [910, 5, 1, "", "asarray"], [911, 5, 1, "", "asin"], [912, 5, 1, "", "asinh"], [913, 5, 1, "", "atan"], [914, 5, 1, "", "atan2"], [915, 5, 1, "", "atanh"], [916, 5, 1, "", "atleast_1d"], [917, 5, 1, "", "atleast_2d"], [918, 5, 1, "", "atleast_3d"], [1, 1, 1, "", "autocast"], [2, 0, 0, "-", "autograd"], [3, 0, 0, "-", "backends"], [970, 5, 1, "", "baddbmm"], [971, 5, 1, "", "bartlett_window"], [972, 5, 1, "", "bernoulli"], [973, 5, 1, "", "bincount"], [974, 5, 1, "", "bitwise_and"], [975, 5, 1, "", "bitwise_left_shift"], [976, 5, 1, "", "bitwise_not"], [977, 5, 1, "", "bitwise_or"], [978, 5, 1, "", "bitwise_right_shift"], [979, 5, 1, "", "bitwise_xor"], [980, 5, 1, "", "blackman_window"], [981, 5, 1, "", "block_diag"], [982, 5, 1, "", "bmm"], [983, 5, 1, "", "broadcast_shapes"], [984, 5, 1, "", "broadcast_tensors"], [985, 5, 1, "", "broadcast_to"], [986, 5, 1, "", "bucketize"], [987, 5, 1, "", "can_cast"], [988, 5, 1, "", "cartesian_prod"], [989, 5, 1, "", "cat"], [990, 5, 1, "", "cdist"], [991, 5, 1, "", "ceil"], [992, 5, 1, "", "chain_matmul"], [993, 5, 1, "", "cholesky"], [994, 5, 1, "", "cholesky_inverse"], [995, 5, 1, "", "cholesky_solve"], [996, 5, 1, "", "chunk"], [997, 5, 1, "", "clamp"], [998, 5, 1, "", "clip"], [999, 5, 1, "", "clone"], [1000, 5, 1, "", "column_stack"], [1001, 5, 1, "", "combinations"], [1002, 5, 1, "", "compile"], [1003, 5, 1, "", "compiled_with_cxx11_abi"], [2187, 0, 0, "-", "compiler"], [1016, 5, 1, "", "complex"], [1017, 5, 1, "", "concat"], [1018, 5, 1, "", "concatenate"], [1019, 5, 1, "", "cond"], [1020, 5, 1, "", "conj"], [1021, 5, 1, "", "conj_physical"], [2180, 0, 0, "-", "contrib"], [1022, 5, 1, "", "copysign"], [1023, 5, 1, "", "corrcoef"], [1024, 5, 1, "", "cos"], [1025, 5, 1, "", "cosh"], [1026, 5, 1, "", "count_nonzero"], [1027, 5, 1, "", "cov"], [18, 0, 0, "-", "cpu"], [1036, 5, 1, "", "cross"], [19, 0, 0, "-", "cuda"], [1123, 5, 1, "", "cummax"], [1124, 5, 1, "", "cummin"], [1125, 5, 1, "", "cumprod"], [1126, 5, 1, "", "cumsum"], [1127, 5, 1, "", "cumulative_trapezoid"], [1128, 5, 1, "", "deg2rad"], [1129, 5, 1, "", "dequantize"], [1130, 5, 1, "", "det"], [2174, 1, 1, "", "device"], [1131, 5, 1, "", "diag"], [1132, 5, 1, "", "diag_embed"], [1133, 5, 1, "", "diagflat"], [1134, 5, 1, "", "diagonal"], [1135, 5, 1, "", "diagonal_scatter"], [1136, 5, 1, "", "diff"], [1137, 5, 1, "", "digamma"], [1138, 5, 1, "", "dist"], [30, 0, 0, "-", "distributed"], [39, 0, 0, "-", "distributions"], [1139, 5, 1, "", "div"], [1140, 5, 1, "", "divide"], [1141, 5, 1, "", "dot"], [1142, 5, 1, "", "dsplit"], [1143, 5, 1, "", "dstack"], [2174, 1, 1, "", "dtype"], [1144, 5, 1, "", "einsum"], [1145, 5, 1, "", "empty"], [1146, 5, 1, "", "empty_like"], [1147, 5, 1, "", "empty_strided"], [1148, 1, 1, "", "enable_grad"], [1149, 5, 1, "", "eq"], [1150, 5, 1, "", "equal"], [1151, 5, 1, "", "erf"], [1152, 5, 1, "", "erfc"], [1153, 5, 1, "", "erfinv"], [1154, 5, 1, "", "exp"], [1155, 5, 1, "", "exp2"], [1156, 5, 1, "", "expm1"], [56, 0, 0, "-", "export"], [1157, 5, 1, "", "eye"], [1158, 5, 1, "", "fake_quantize_per_channel_affine"], [1159, 5, 1, "", "fake_quantize_per_tensor_affine"], [59, 0, 0, "-", "fft"], [1182, 5, 1, "", "fix"], [1183, 5, 1, "", "flatten"], [1184, 5, 1, "", "flip"], [1185, 5, 1, "", "fliplr"], [1186, 5, 1, "", "flipud"], [1187, 5, 1, "", "float_power"], [1188, 5, 1, "", "floor"], [1189, 5, 1, "", "floor_divide"], [1190, 5, 1, "", "fmax"], [1191, 5, 1, "", "fmin"], [1192, 5, 1, "", "fmod"], [1193, 5, 1, "", "frac"], [1194, 5, 1, "", "frexp"], [1195, 5, 1, "", "from_dlpack"], [1196, 5, 1, "", "from_file"], [1197, 5, 1, "", "from_numpy"], [1198, 5, 1, "", "frombuffer"], [1199, 5, 1, "", "full"], [1200, 5, 1, "", "full_like"], [62, 0, 0, "-", "func"], [2180, 0, 0, "-", "functional"], [68, 0, 0, "-", "futures"], [69, 0, 0, "-", "fx"], [1255, 5, 1, "", "gather"], [1256, 5, 1, "", "gcd"], [1257, 5, 1, "", "ge"], [1258, 5, 1, "", "geqrf"], [1259, 5, 1, "", "ger"], [1260, 5, 1, "", "get_default_device"], [1261, 5, 1, "", "get_default_dtype"], [1262, 5, 1, "", "get_deterministic_debug_mode"], [1263, 5, 1, "", "get_device_module"], [1264, 5, 1, "", "get_float32_matmul_precision"], [1265, 5, 1, "", "get_num_interop_threads"], [1266, 5, 1, "", "get_num_threads"], [1267, 5, 1, "", "get_rng_state"], [1268, 5, 1, "", "gradient"], [1269, 5, 1, "", "greater"], [1270, 5, 1, "", "greater_equal"], [1271, 5, 1, "", "gt"], [1272, 5, 1, "", "hamming_window"], [1273, 5, 1, "", "hann_window"], [1274, 5, 1, "", "heaviside"], [1275, 5, 1, "", "histc"], [1276, 5, 1, "", "histogram"], [1277, 5, 1, "", "histogramdd"], [1278, 5, 1, "", "hsplit"], [1279, 5, 1, "", "hspmm"], [1280, 5, 1, "", "hstack"], [2091, 0, 0, "-", "hub"], [1281, 5, 1, "", "hypot"], [1282, 5, 1, "", "i0"], [1283, 5, 1, "", "igamma"], [1284, 5, 1, "", "igammac"], [1285, 5, 1, "", "imag"], [1286, 5, 1, "", "index_add"], [1287, 5, 1, "", "index_copy"], [1288, 5, 1, "", "index_reduce"], [1289, 5, 1, "", "index_select"], [1290, 5, 1, "", "initial_seed"], [1291, 5, 1, "", "inner"], [1292, 5, 1, "", "inverse"], [1293, 5, 1, "", "is_complex"], [1294, 5, 1, "", "is_conj"], [1295, 5, 1, "", "is_deterministic_algorithms_warn_only_enabled"], [1296, 5, 1, "", "is_floating_point"], [1297, 5, 1, "", "is_grad_enabled"], [1298, 5, 1, "", "is_inference_mode_enabled"], [1299, 5, 1, "", "is_nonzero"], [1300, 5, 1, "", "is_storage"], [1301, 5, 1, "", "is_tensor"], [1302, 5, 1, "", "is_warn_always_enabled"], [1303, 5, 1, "", "isclose"], [1304, 5, 1, "", "isfinite"], [1305, 5, 1, "", "isin"], [1306, 5, 1, "", "isinf"], [1307, 5, 1, "", "isnan"], [1308, 5, 1, "", "isneginf"], [1309, 5, 1, "", "isposinf"], [1310, 5, 1, "", "isreal"], [1311, 5, 1, "", "istft"], [2093, 0, 0, "-", "jit"], [1334, 5, 1, "", "kaiser_window"], [1335, 5, 1, "", "kron"], [1336, 5, 1, "", "kthvalue"], [2174, 1, 1, "", "layout"], [1337, 5, 1, "", "lcm"], [1338, 5, 1, "", "ldexp"], [1339, 5, 1, "", "le"], [1340, 5, 1, "", "lerp"], [1341, 5, 1, "", "less"], [1342, 5, 1, "", "less_equal"], [1343, 5, 1, "", "lgamma"], [2100, 0, 0, "-", "library"], [2101, 0, 0, "-", "linalg"], [1385, 5, 1, "", "linspace"], [1386, 5, 1, "", "load"], [1387, 5, 1, "", "lobpcg"], [1388, 5, 1, "", "log"], [1389, 5, 1, "", "log10"], [1390, 5, 1, "", "log1p"], [1391, 5, 1, "", "log2"], [1392, 5, 1, "", "logaddexp"], [1393, 5, 1, "", "logaddexp2"], [1394, 5, 1, "", "logcumsumexp"], [1395, 5, 1, "", "logdet"], [1396, 5, 1, "", "logical_and"], [1397, 5, 1, "", "logical_not"], [1398, 5, 1, "", "logical_or"], [1399, 5, 1, "", "logical_xor"], [1400, 5, 1, "", "logit"], [1401, 5, 1, "", "logspace"], [1402, 5, 1, "", "logsumexp"], [1403, 5, 1, "", "lt"], [1404, 5, 1, "", "lu"], [1405, 5, 1, "", "lu_solve"], [1406, 5, 1, "", "lu_unpack"], [1407, 5, 1, "", "manual_seed"], [2103, 0, 0, "-", "masked"], [1408, 5, 1, "", "masked_select"], [1409, 5, 1, "", "matmul"], [1410, 5, 1, "", "matrix_exp"], [1411, 5, 1, "", "matrix_power"], [1412, 5, 1, "", "max"], [1413, 5, 1, "", "maximum"], [1414, 5, 1, "", "mean"], [1415, 5, 1, "", "median"], [2174, 1, 1, "", "memory_format"], [1416, 5, 1, "", "meshgrid"], [1417, 5, 1, "", "min"], [1418, 5, 1, "", "minimum"], [1419, 5, 1, "", "mm"], [1420, 5, 1, "", "mode"], [2109, 0, 0, "-", "monitor"], [1421, 5, 1, "", "moveaxis"], [1422, 5, 1, "", "movedim"], [2110, 0, 0, "-", "mps"], [1441, 5, 1, "", "msort"], [2112, 0, 0, "-", "mtia"], [1465, 5, 1, "", "mul"], [1466, 5, 1, "", "multinomial"], [1467, 5, 1, "", "multiply"], [2114, 0, 0, "-", "multiprocessing"], [1468, 5, 1, "", "mv"], [1469, 5, 1, "", "mvlgamma"], [1470, 5, 1, "", "nan_to_num"], [1471, 5, 1, "", "nanmean"], [1472, 5, 1, "", "nanmedian"], [1473, 5, 1, "", "nanquantile"], [1474, 5, 1, "", "nansum"], [1475, 5, 1, "", "narrow"], [1476, 5, 1, "", "narrow_copy"], [1477, 5, 1, "", "ne"], [1478, 5, 1, "", "neg"], [1479, 5, 1, "", "negative"], [2117, 0, 0, "-", "nested"], [1480, 5, 1, "", "nextafter"], [2118, 0, 0, "-", "nn"], [1825, 1, 1, "", "no_grad"], [1826, 5, 1, "", "nonzero"], [1827, 5, 1, "", "norm"], [1828, 5, 1, "", "normal"], [1829, 5, 1, "", "not_equal"], [1830, 5, 1, "", "numel"], [1831, 5, 1, "", "ones"], [1832, 5, 1, "", "ones_like"], [2154, 0, 0, "-", "onnx"], [2157, 0, 0, "-", "optim"], [1879, 5, 1, "", "orgqr"], [1880, 5, 1, "", "ormqr"], [1881, 5, 1, "", "outer"], [2206, 0, 0, "-", "overrides"], [2158, 0, 0, "-", "package"], [1882, 5, 1, "", "pca_lowrank"], [1883, 5, 1, "", "permute"], [1884, 5, 1, "", "pinverse"], [1885, 5, 1, "", "poisson"], [1886, 5, 1, "", "polar"], [1887, 5, 1, "", "polygamma"], [1888, 5, 1, "", "positive"], [1889, 5, 1, "", "pow"], [1890, 5, 1, "", "prod"], [2159, 0, 0, "-", "profiler"], [1891, 5, 1, "", "promote_types"], [1892, 5, 1, "", "qr"], [1893, 5, 1, "", "quantile"], [2164, 0, 0, "-", "quantization"], [1894, 5, 1, "", "quantize_per_channel"], [1895, 5, 1, "", "quantize_per_tensor"], [1896, 5, 1, "", "quantized_batch_norm"], [1897, 5, 1, "", "quantized_max_pool1d"], [1898, 5, 1, "", "quantized_max_pool2d"], [2180, 0, 0, "-", "quasirandom"], [1900, 5, 1, "", "rad2deg"], [1901, 5, 1, "", "rand"], [1902, 5, 1, "", "rand_like"], [1903, 5, 1, "", "randint"], [1904, 5, 1, "", "randint_like"], [1905, 5, 1, "", "randn"], [1906, 5, 1, "", "randn_like"], [2165, 0, 0, "-", "random"], [1907, 5, 1, "", "randperm"], [1908, 5, 1, "", "range"], [1909, 5, 1, "", "ravel"], [1910, 5, 1, "", "real"], [1911, 5, 1, "", "reciprocal"], [1912, 5, 1, "", "remainder"], [1913, 5, 1, "", "renorm"], [1914, 5, 1, "", "repeat_interleave"], [1915, 5, 1, "", "reshape"], [1916, 5, 1, "", "resolve_conj"], [1917, 5, 1, "", "resolve_neg"], [1918, 5, 1, "", "result_type"], [2180, 0, 0, "-", "return_types"], [1919, 5, 1, "", "roll"], [1920, 5, 1, "", "rot90"], [1921, 5, 1, "", "round"], [1922, 5, 1, "", "row_stack"], [1923, 5, 1, "", "rsqrt"], [1924, 5, 1, "", "save"], [1925, 5, 1, "", "scatter"], [1926, 5, 1, "", "scatter_add"], [1927, 5, 1, "", "scatter_reduce"], [1928, 5, 1, "", "searchsorted"], [1929, 5, 1, "", "seed"], [1930, 5, 1, "", "select"], [1931, 5, 1, "", "select_scatter"], [2180, 0, 0, "-", "serialization"], [1932, 5, 1, "", "set_default_device"], [1933, 5, 1, "", "set_default_dtype"], [1934, 5, 1, "", "set_default_tensor_type"], [1935, 5, 1, "", "set_deterministic_debug_mode"], [1936, 5, 1, "", "set_float32_matmul_precision"], [1937, 5, 1, "", "set_flush_denormal"], [1938, 5, 1, "", "set_num_interop_threads"], [1939, 5, 1, "", "set_num_threads"], [1940, 5, 1, "", "set_printoptions"], [1941, 5, 1, "", "set_rng_state"], [1942, 5, 1, "", "set_warn_always"], [1943, 5, 1, "", "sgn"], [1944, 5, 1, "", "sigmoid"], [1945, 5, 1, "", "sign"], [2169, 0, 0, "-", "signal"], [1957, 5, 1, "", "signbit"], [1958, 5, 1, "", "sin"], [1959, 5, 1, "", "sinc"], [1960, 5, 1, "", "sinh"], [1961, 5, 1, "", "slice_scatter"], [1962, 5, 1, "", "slogdet"], [1963, 5, 1, "", "smm"], [1964, 5, 1, "", "softmax"], [1965, 5, 1, "", "sort"], [2171, 0, 0, "-", "sparse"], [1976, 5, 1, "", "sparse_bsc_tensor"], [1977, 5, 1, "", "sparse_bsr_tensor"], [1978, 5, 1, "", "sparse_compressed_tensor"], [1979, 5, 1, "", "sparse_coo_tensor"], [1980, 5, 1, "", "sparse_csc_tensor"], [1981, 5, 1, "", "sparse_csr_tensor"], [2172, 0, 0, "-", "special"], [1982, 5, 1, "", "split"], [1983, 5, 1, "", "sqrt"], [1984, 5, 1, "", "square"], [1985, 5, 1, "", "squeeze"], [1986, 5, 1, "", "sspaddmm"], [1987, 5, 1, "", "stack"], [1988, 5, 1, "", "std"], [1989, 5, 1, "", "std_mean"], [1990, 5, 1, "", "stft"], [2180, 0, 0, "-", "storage"], [1991, 5, 1, "", "sub"], [1992, 5, 1, "", "subtract"], [1993, 5, 1, "", "sum"], [1994, 5, 1, "", "svd"], [1995, 5, 1, "", "svd_lowrank"], [1996, 5, 1, "", "swapaxes"], [1997, 5, 1, "", "swapdims"], [1998, 5, 1, "", "sym_float"], [1999, 5, 1, "", "sym_fresh_size"], [2000, 5, 1, "", "sym_int"], [2001, 5, 1, "", "sym_ite"], [2002, 5, 1, "", "sym_max"], [2003, 5, 1, "", "sym_min"], [2004, 5, 1, "", "sym_not"], [2005, 5, 1, "", "sym_sum"], [2006, 5, 1, "", "t"], [2007, 5, 1, "", "take"], [2008, 5, 1, "", "take_along_dim"], [2009, 5, 1, "", "tan"], [2010, 5, 1, "", "tanh"], [2011, 5, 1, "", "tensor"], [2012, 5, 1, "", "tensor_split"], [2013, 5, 1, "", "tensordot"], [2178, 0, 0, "-", "testing"], [2014, 5, 1, "", "tile"], [2015, 5, 1, "", "topk"], [2180, 0, 0, "-", "torch_version"], [2016, 5, 1, "", "trace"], [2017, 5, 1, "", "transpose"], [2018, 5, 1, "", "trapezoid"], [2019, 5, 1, "", "trapz"], [2020, 5, 1, "", "triangular_solve"], [2021, 5, 1, "", "tril"], [2022, 5, 1, "", "tril_indices"], [2023, 5, 1, "", "triu"], [2024, 5, 1, "", "triu_indices"], [2025, 5, 1, "", "true_divide"], [2026, 5, 1, "", "trunc"], [2180, 0, 0, "-", "types"], [2027, 5, 1, "", "unbind"], [2028, 5, 1, "", "unflatten"], [2029, 5, 1, "", "unique"], [2030, 5, 1, "", "unique_consecutive"], [2031, 5, 1, "", "unravel_index"], [2032, 5, 1, "", "unsqueeze"], [2033, 5, 1, "", "use_deterministic_algorithms"], [2211, 0, 0, "-", "utils"], [2039, 5, 1, "", "vander"], [2040, 5, 1, "", "var"], [2041, 5, 1, "", "var_mean"], [2042, 5, 1, "", "vdot"], [2180, 0, 0, "-", "version"], [2043, 5, 1, "", "view_as_complex"], [2044, 5, 1, "", "view_as_real"], [2045, 5, 1, "", "vmap"], [2046, 5, 1, "", "vsplit"], [2047, 5, 1, "", "vstack"], [2048, 5, 1, "", "where"], [2049, 5, 1, "", "xlogy"], [2212, 0, 0, "-", "xpu"], [2089, 5, 1, "", "zeros"], [2090, 5, 1, "", "zeros_like"]], "torch.BFloat16Storage": [[2173, 2, 1, "", "dtype"]], "torch.BoolStorage": [[2173, 2, 1, "", "dtype"]], "torch.ByteStorage": [[2173, 2, 1, "", "dtype"]], "torch.CharStorage": [[2173, 2, 1, "", "dtype"]], "torch.ComplexDoubleStorage": [[2173, 2, 1, "", "dtype"]], "torch.ComplexFloatStorage": [[2173, 2, 1, "", "dtype"]], "torch.DoubleStorage": [[2173, 2, 1, "", "dtype"]], "torch.Event": [[86, 3, 1, "", "elapsed_time"], [86, 3, 1, "", "query"], [86, 3, 1, "", "record"], [86, 3, 1, "", "synchronize"], [86, 3, 1, "", "wait"]], "torch.FloatStorage": [[2173, 2, 1, "", "dtype"]], "torch.Generator": [[87, 3, 1, "", "clone_state"], [87, 2, 1, "", "device"], [87, 3, 1, "", "get_state"], [87, 3, 1, "", "graphsafe_get_state"], [87, 3, 1, "", "graphsafe_set_state"], [87, 3, 1, "", "initial_seed"], [87, 3, 1, "", "manual_seed"], [87, 3, 1, "", "seed"], [87, 3, 1, "", "set_state"]], "torch.HalfStorage": [[2173, 2, 1, "", "dtype"]], "torch.IntStorage": [[2173, 2, 1, "", "dtype"]], "torch.LongStorage": [[2173, 2, 1, "", "dtype"]], "torch.QInt32Storage": [[2173, 2, 1, "", "dtype"]], "torch.QInt8Storage": [[2173, 2, 1, "", "dtype"]], "torch.QUInt2x4Storage": [[2173, 2, 1, "", "dtype"]], "torch.QUInt4x2Storage": [[2173, 2, 1, "", "dtype"]], "torch.QUInt8Storage": [[2173, 2, 1, "", "dtype"]], "torch.ShortStorage": [[2173, 2, 1, "", "dtype"]], "torch.Size": [[2170, 3, 1, "", "count"], [2170, 3, 1, "", "index"], [2170, 3, 1, "", "numel"]], "torch.Stream": [[88, 3, 1, "", "query"], [88, 3, 1, "", "record_event"], [88, 3, 1, "", "synchronize"], [88, 3, 1, "", "wait_event"], [88, 3, 1, "", "wait_stream"]], "torch.SymFloat": [[2180, 3, 1, "", "as_integer_ratio"], [2180, 3, 1, "", "conjugate"], [2180, 3, 1, "", "hex"], [2180, 3, 1, "", "is_integer"]], "torch.SymInt": [[2180, 3, 1, "", "as_integer_ratio"]], "torch.Tag": [[2180, 4, 1, "", "name"]], "torch.Tensor": [[2177, 2, 1, "", "H"], [2177, 2, 1, "", "T"], [2177, 3, 1, "", "__init__"], [89, 3, 1, "", "abs"], [90, 3, 1, "", "abs_"], [91, 3, 1, "", "absolute"], [92, 3, 1, "", "absolute_"], [93, 3, 1, "", "acos"], [94, 3, 1, "", "acos_"], [95, 3, 1, "", "acosh"], [96, 3, 1, "", "acosh_"], [97, 3, 1, "", "add"], [98, 3, 1, "", "add_"], [99, 3, 1, "", "addbmm"], [100, 3, 1, "", "addbmm_"], [101, 3, 1, "", "addcdiv"], [102, 3, 1, "", "addcdiv_"], [103, 3, 1, "", "addcmul"], [104, 3, 1, "", "addcmul_"], [105, 3, 1, "", "addmm"], [106, 3, 1, "", "addmm_"], [107, 3, 1, "", "addmv"], [108, 3, 1, "", "addmv_"], [109, 3, 1, "", "addr"], [110, 3, 1, "", "addr_"], [111, 3, 1, "", "adjoint"], [2116, 3, 1, "", "align_as"], [2116, 3, 1, "", "align_to"], [112, 3, 1, "", "all"], [113, 3, 1, "", "allclose"], [114, 3, 1, "", "amax"], [115, 3, 1, "", "amin"], [116, 3, 1, "", "aminmax"], [117, 3, 1, "", "angle"], [118, 3, 1, "", "any"], [119, 3, 1, "", "apply_"], [120, 3, 1, "", "arccos"], [121, 3, 1, "", "arccos_"], [122, 3, 1, "", "arccosh"], [123, 3, 1, "", "arccosh_"], [124, 3, 1, "", "arcsin"], [125, 3, 1, "", "arcsin_"], [126, 3, 1, "", "arcsinh"], [127, 3, 1, "", "arcsinh_"], [128, 3, 1, "", "arctan"], [129, 3, 1, "", "arctan2"], [130, 3, 1, "", "arctan2_"], [131, 3, 1, "", "arctan_"], [132, 3, 1, "", "arctanh"], [133, 3, 1, "", "arctanh_"], [134, 3, 1, "", "argmax"], [135, 3, 1, "", "argmin"], [136, 3, 1, "", "argsort"], [137, 3, 1, "", "argwhere"], [138, 3, 1, "", "as_strided"], [139, 3, 1, "", "as_subclass"], [140, 3, 1, "", "asin"], [141, 3, 1, "", "asin_"], [142, 3, 1, "", "asinh"], [143, 3, 1, "", "asinh_"], [144, 3, 1, "", "atan"], [145, 3, 1, "", "atan2"], [146, 3, 1, "", "atan2_"], [147, 3, 1, "", "atan_"], [148, 3, 1, "", "atanh"], [149, 3, 1, "", "atanh_"], [150, 3, 1, "", "backward"], [151, 3, 1, "", "baddbmm"], [152, 3, 1, "", "baddbmm_"], [153, 3, 1, "", "bernoulli"], [154, 3, 1, "", "bernoulli_"], [155, 3, 1, "", "bfloat16"], [156, 3, 1, "", "bincount"], [157, 3, 1, "", "bitwise_and"], [158, 3, 1, "", "bitwise_and_"], [159, 3, 1, "", "bitwise_left_shift"], [160, 3, 1, "", "bitwise_left_shift_"], [161, 3, 1, "", "bitwise_not"], [162, 3, 1, "", "bitwise_not_"], [163, 3, 1, "", "bitwise_or"], [164, 3, 1, "", "bitwise_or_"], [165, 3, 1, "", "bitwise_right_shift"], [166, 3, 1, "", "bitwise_right_shift_"], [167, 3, 1, "", "bitwise_xor"], [168, 3, 1, "", "bitwise_xor_"], [169, 3, 1, "", "bmm"], [170, 3, 1, "", "bool"], [171, 3, 1, "", "broadcast_to"], [172, 3, 1, "", "byte"], [173, 3, 1, "", "cauchy_"], [174, 3, 1, "", "ccol_indices"], [175, 3, 1, "", "cdouble"], [176, 3, 1, "", "ceil"], [177, 3, 1, "", "ceil_"], [178, 3, 1, "", "cfloat"], [179, 3, 1, "", "chalf"], [180, 3, 1, "", "char"], [181, 3, 1, "", "cholesky"], [182, 3, 1, "", "cholesky_inverse"], [183, 3, 1, "", "cholesky_solve"], [184, 3, 1, "", "chunk"], [185, 3, 1, "", "clamp"], [186, 3, 1, "", "clamp_"], [187, 3, 1, "", "clip"], [188, 3, 1, "", "clip_"], [189, 3, 1, "", "clone"], [190, 3, 1, "", "coalesce"], [191, 3, 1, "", "col_indices"], [192, 3, 1, "", "conj"], [193, 3, 1, "", "conj_physical"], [194, 3, 1, "", "conj_physical_"], [195, 3, 1, "", "contiguous"], [196, 3, 1, "", "copy_"], [197, 3, 1, "", "copysign"], [198, 3, 1, "", "copysign_"], [199, 3, 1, "", "corrcoef"], [200, 3, 1, "", "cos"], [201, 3, 1, "", "cos_"], [202, 3, 1, "", "cosh"], [203, 3, 1, "", "cosh_"], [204, 3, 1, "", "count_nonzero"], [205, 3, 1, "", "cov"], [206, 3, 1, "", "cpu"], [207, 3, 1, "", "cross"], [208, 3, 1, "", "crow_indices"], [209, 3, 1, "", "cuda"], [210, 3, 1, "", "cummax"], [211, 3, 1, "", "cummin"], [212, 3, 1, "", "cumprod"], [213, 3, 1, "", "cumprod_"], [214, 3, 1, "", "cumsum"], [215, 3, 1, "", "cumsum_"], [216, 3, 1, "", "data_ptr"], [217, 3, 1, "", "deg2rad"], [218, 3, 1, "", "dense_dim"], [219, 3, 1, "", "dequantize"], [220, 3, 1, "", "det"], [221, 3, 1, "", "detach"], [222, 3, 1, "", "detach_"], [223, 2, 1, "", "device"], [224, 3, 1, "", "diag"], [225, 3, 1, "", "diag_embed"], [226, 3, 1, "", "diagflat"], [227, 3, 1, "", "diagonal"], [228, 3, 1, "", "diagonal_scatter"], [229, 3, 1, "", "diff"], [230, 3, 1, "", "digamma"], [231, 3, 1, "", "digamma_"], [232, 3, 1, "", "dim"], [233, 3, 1, "", "dim_order"], [234, 3, 1, "", "dist"], [235, 3, 1, "", "div"], [236, 3, 1, "", "div_"], [237, 3, 1, "", "divide"], [238, 3, 1, "", "divide_"], [239, 3, 1, "", "dot"], [240, 3, 1, "", "double"], [241, 3, 1, "", "dsplit"], [242, 3, 1, "", "element_size"], [243, 3, 1, "", "eq"], [244, 3, 1, "", "eq_"], [245, 3, 1, "", "equal"], [246, 3, 1, "", "erf"], [247, 3, 1, "", "erf_"], [248, 3, 1, "", "erfc"], [249, 3, 1, "", "erfc_"], [250, 3, 1, "", "erfinv"], [251, 3, 1, "", "erfinv_"], [252, 3, 1, "", "exp"], [253, 3, 1, "", "exp_"], [254, 3, 1, "", "expand"], [255, 3, 1, "", "expand_as"], [256, 3, 1, "", "expm1"], [257, 3, 1, "", "expm1_"], [258, 3, 1, "", "exponential_"], [259, 3, 1, "", "fill_"], [260, 3, 1, "", "fill_diagonal_"], [261, 3, 1, "", "fix"], [262, 3, 1, "", "fix_"], [263, 3, 1, "", "flatten"], [264, 3, 1, "", "flip"], [265, 3, 1, "", "fliplr"], [266, 3, 1, "", "flipud"], [267, 3, 1, "", "float"], [268, 3, 1, "", "float_power"], [269, 3, 1, "", "float_power_"], [270, 3, 1, "", "floor"], [271, 3, 1, "", "floor_"], [272, 3, 1, "", "floor_divide"], [273, 3, 1, "", "floor_divide_"], [274, 3, 1, "", "fmax"], [275, 3, 1, "", "fmin"], [276, 3, 1, "", "fmod"], [277, 3, 1, "", "fmod_"], [278, 3, 1, "", "frac"], [279, 3, 1, "", "frac_"], [280, 3, 1, "", "frexp"], [281, 3, 1, "", "gather"], [282, 3, 1, "", "gcd"], [283, 3, 1, "", "gcd_"], [284, 3, 1, "", "ge"], [285, 3, 1, "", "ge_"], [286, 3, 1, "", "geometric_"], [287, 3, 1, "", "geqrf"], [288, 3, 1, "", "ger"], [289, 3, 1, "", "get_device"], [290, 2, 1, "", "grad"], [291, 3, 1, "", "greater"], [292, 3, 1, "", "greater_"], [293, 3, 1, "", "greater_equal"], [294, 3, 1, "", "greater_equal_"], [295, 3, 1, "", "gt"], [296, 3, 1, "", "gt_"], [297, 3, 1, "", "half"], [298, 3, 1, "", "hardshrink"], [299, 3, 1, "", "heaviside"], [300, 3, 1, "", "histc"], [301, 3, 1, "", "histogram"], [302, 3, 1, "", "hsplit"], [303, 3, 1, "", "hypot"], [304, 3, 1, "", "hypot_"], [305, 3, 1, "", "i0"], [306, 3, 1, "", "i0_"], [307, 3, 1, "", "igamma"], [308, 3, 1, "", "igamma_"], [309, 3, 1, "", "igammac"], [310, 3, 1, "", "igammac_"], [311, 2, 1, "", "imag"], [312, 3, 1, "", "index_add"], [313, 3, 1, "", "index_add_"], [314, 3, 1, "", "index_copy"], [315, 3, 1, "", "index_copy_"], [316, 3, 1, "", "index_fill"], [317, 3, 1, "", "index_fill_"], [318, 3, 1, "", "index_put"], [319, 3, 1, "", "index_put_"], [320, 3, 1, "", "index_reduce"], [321, 3, 1, "", "index_reduce_"], [322, 3, 1, "", "index_select"], [323, 3, 1, "", "indices"], [324, 3, 1, "", "inner"], [325, 3, 1, "", "int"], [326, 3, 1, "", "int_repr"], [327, 3, 1, "", "inverse"], [328, 3, 1, "", "is_coalesced"], [329, 3, 1, "", "is_complex"], [330, 3, 1, "", "is_conj"], [331, 3, 1, "", "is_contiguous"], [332, 2, 1, "", "is_cuda"], [333, 3, 1, "", "is_floating_point"], [334, 3, 1, "", "is_inference"], [335, 2, 1, "", "is_leaf"], [336, 2, 1, "", "is_meta"], [337, 3, 1, "", "is_pinned"], [338, 2, 1, "", "is_quantized"], [339, 3, 1, "", "is_set_to"], [340, 3, 1, "", "is_shared"], [341, 3, 1, "", "is_signed"], [342, 2, 1, "", "is_sparse"], [343, 2, 1, "", "is_sparse_csr"], [344, 3, 1, "", "isclose"], [345, 3, 1, "", "isfinite"], [346, 3, 1, "", "isinf"], [347, 3, 1, "", "isnan"], [348, 3, 1, "", "isneginf"], [349, 3, 1, "", "isposinf"], [350, 3, 1, "", "isreal"], [351, 3, 1, "", "istft"], [352, 3, 1, "", "item"], [353, 2, 1, "", "itemsize"], [354, 3, 1, "", "kthvalue"], [355, 3, 1, "", "lcm"], [356, 3, 1, "", "lcm_"], [357, 3, 1, "", "ldexp"], [358, 3, 1, "", "ldexp_"], [359, 3, 1, "", "le"], [360, 3, 1, "", "le_"], [361, 3, 1, "", "lerp"], [362, 3, 1, "", "lerp_"], [363, 3, 1, "", "less"], [364, 3, 1, "", "less_"], [365, 3, 1, "", "less_equal"], [366, 3, 1, "", "less_equal_"], [367, 3, 1, "", "lgamma"], [368, 3, 1, "", "lgamma_"], [369, 3, 1, "", "log"], [370, 3, 1, "", "log10"], [371, 3, 1, "", "log10_"], [372, 3, 1, "", "log1p"], [373, 3, 1, "", "log1p_"], [374, 3, 1, "", "log2"], [375, 3, 1, "", "log2_"], [376, 3, 1, "", "log_"], [377, 3, 1, "", "log_normal_"], [378, 3, 1, "", "logaddexp"], [379, 3, 1, "", "logaddexp2"], [380, 3, 1, "", "logcumsumexp"], [381, 3, 1, "", "logdet"], [382, 3, 1, "", "logical_and"], [383, 3, 1, "", "logical_and_"], [384, 3, 1, "", "logical_not"], [385, 3, 1, "", "logical_not_"], [386, 3, 1, "", "logical_or"], [387, 3, 1, "", "logical_or_"], [388, 3, 1, "", "logical_xor"], [389, 3, 1, "", "logical_xor_"], [390, 3, 1, "", "logit"], [391, 3, 1, "", "logit_"], [392, 3, 1, "", "logsumexp"], [393, 3, 1, "", "long"], [394, 3, 1, "", "lt"], [395, 3, 1, "", "lt_"], [396, 3, 1, "", "lu"], [397, 3, 1, "", "lu_solve"], [2177, 2, 1, "", "mH"], [2177, 2, 1, "", "mT"], [398, 3, 1, "", "map_"], [399, 3, 1, "", "masked_fill"], [400, 3, 1, "", "masked_fill_"], [401, 3, 1, "", "masked_scatter"], [402, 3, 1, "", "masked_scatter_"], [403, 3, 1, "", "masked_select"], [404, 3, 1, "", "matmul"], [405, 3, 1, "", "matrix_exp"], [406, 3, 1, "", "matrix_power"], [407, 3, 1, "", "max"], [408, 3, 1, "", "maximum"], [409, 3, 1, "", "mean"], [410, 3, 1, "", "median"], [411, 3, 1, "", "min"], [412, 3, 1, "", "minimum"], [413, 3, 1, "", "mm"], [414, 3, 1, "", "mode"], [415, 3, 1, "", "module_load"], [416, 3, 1, "", "moveaxis"], [417, 3, 1, "", "movedim"], [418, 3, 1, "", "msort"], [419, 3, 1, "", "mul"], [420, 3, 1, "", "mul_"], [421, 3, 1, "", "multinomial"], [422, 3, 1, "", "multiply"], [423, 3, 1, "", "multiply_"], [424, 3, 1, "", "mv"], [425, 3, 1, "", "mvlgamma"], [426, 3, 1, "", "mvlgamma_"], [2116, 2, 1, "", "names"], [427, 3, 1, "", "nan_to_num"], [428, 3, 1, "", "nan_to_num_"], [429, 3, 1, "", "nanmean"], [430, 3, 1, "", "nanmedian"], [431, 3, 1, "", "nanquantile"], [432, 3, 1, "", "nansum"], [433, 3, 1, "", "narrow"], [434, 3, 1, "", "narrow_copy"], [435, 2, 1, "", "nbytes"], [436, 2, 1, "", "ndim"], [437, 3, 1, "", "ndimension"], [438, 3, 1, "", "ne"], [439, 3, 1, "", "ne_"], [440, 3, 1, "", "neg"], [441, 3, 1, "", "neg_"], [442, 3, 1, "", "negative"], [443, 3, 1, "", "negative_"], [444, 3, 1, "", "nelement"], [445, 3, 1, "", "new_empty"], [446, 3, 1, "", "new_full"], [447, 3, 1, "", "new_ones"], [448, 3, 1, "", "new_tensor"], [449, 3, 1, "", "new_zeros"], [450, 3, 1, "", "nextafter"], [451, 3, 1, "", "nextafter_"], [452, 3, 1, "", "nonzero"], [453, 3, 1, "", "norm"], [454, 3, 1, "", "normal_"], [455, 3, 1, "", "not_equal"], [456, 3, 1, "", "not_equal_"], [457, 3, 1, "", "numel"], [458, 3, 1, "", "numpy"], [459, 3, 1, "", "orgqr"], [460, 3, 1, "", "ormqr"], [461, 3, 1, "", "outer"], [462, 3, 1, "", "permute"], [463, 3, 1, "", "pin_memory"], [464, 3, 1, "", "pinverse"], [465, 3, 1, "", "polygamma"], [466, 3, 1, "", "polygamma_"], [467, 3, 1, "", "positive"], [468, 3, 1, "", "pow"], [469, 3, 1, "", "pow_"], [470, 3, 1, "", "prod"], [471, 3, 1, "", "put_"], [472, 3, 1, "", "q_per_channel_axis"], [473, 3, 1, "", "q_per_channel_scales"], [474, 3, 1, "", "q_per_channel_zero_points"], [475, 3, 1, "", "q_scale"], [476, 3, 1, "", "q_zero_point"], [477, 3, 1, "", "qr"], [478, 3, 1, "", "qscheme"], [479, 3, 1, "", "quantile"], [480, 3, 1, "", "rad2deg"], [481, 3, 1, "", "random_"], [482, 3, 1, "", "ravel"], [483, 2, 1, "", "real"], [484, 3, 1, "", "reciprocal"], [485, 3, 1, "", "reciprocal_"], [486, 3, 1, "", "record_stream"], [2116, 3, 1, "", "refine_names"], [487, 3, 1, "", "register_hook"], [488, 3, 1, "", "register_post_accumulate_grad_hook"], [489, 3, 1, "", "remainder"], [490, 3, 1, "", "remainder_"], [2116, 3, 1, "", "rename"], [2116, 3, 1, "", "rename_"], [491, 3, 1, "", "renorm"], [492, 3, 1, "", "renorm_"], [493, 3, 1, "", "repeat"], [494, 3, 1, "", "repeat_interleave"], [495, 2, 1, "", "requires_grad"], [496, 3, 1, "", "requires_grad_"], [497, 3, 1, "", "reshape"], [498, 3, 1, "", "reshape_as"], [499, 3, 1, "", "resize_"], [500, 3, 1, "", "resize_as_"], [501, 3, 1, "", "resolve_conj"], [502, 3, 1, "", "resolve_neg"], [503, 3, 1, "", "retain_grad"], [504, 2, 1, "", "retains_grad"], [505, 3, 1, "", "roll"], [506, 3, 1, "", "rot90"], [507, 3, 1, "", "round"], [508, 3, 1, "", "round_"], [509, 3, 1, "", "row_indices"], [510, 3, 1, "", "rsqrt"], [511, 3, 1, "", "rsqrt_"], [512, 3, 1, "", "scatter"], [513, 3, 1, "", "scatter_"], [514, 3, 1, "", "scatter_add"], [515, 3, 1, "", "scatter_add_"], [516, 3, 1, "", "scatter_reduce"], [517, 3, 1, "", "scatter_reduce_"], [518, 3, 1, "", "select"], [519, 3, 1, "", "select_scatter"], [520, 3, 1, "", "set_"], [521, 3, 1, "", "sgn"], [522, 3, 1, "", "sgn_"], [523, 2, 1, "", "shape"], [524, 3, 1, "", "share_memory_"], [525, 3, 1, "", "short"], [526, 3, 1, "", "sigmoid"], [527, 3, 1, "", "sigmoid_"], [528, 3, 1, "", "sign"], [529, 3, 1, "", "sign_"], [530, 3, 1, "", "signbit"], [531, 3, 1, "", "sin"], [532, 3, 1, "", "sin_"], [533, 3, 1, "", "sinc"], [534, 3, 1, "", "sinc_"], [535, 3, 1, "", "sinh"], [536, 3, 1, "", "sinh_"], [537, 3, 1, "", "size"], [538, 3, 1, "", "slice_scatter"], [539, 3, 1, "", "slogdet"], [540, 3, 1, "", "smm"], [541, 3, 1, "", "softmax"], [542, 3, 1, "", "sort"], [543, 3, 1, "", "sparse_dim"], [544, 3, 1, "", "sparse_mask"], [545, 3, 1, "", "sparse_resize_"], [546, 3, 1, "", "sparse_resize_and_clear_"], [547, 3, 1, "", "split"], [548, 3, 1, "", "sqrt"], [549, 3, 1, "", "sqrt_"], [550, 3, 1, "", "square"], [551, 3, 1, "", "square_"], [552, 3, 1, "", "squeeze"], [553, 3, 1, "", "squeeze_"], [554, 3, 1, "", "sspaddmm"], [555, 3, 1, "", "std"], [556, 3, 1, "", "stft"], [557, 3, 1, "", "storage"], [558, 3, 1, "", "storage_offset"], [559, 3, 1, "", "storage_type"], [560, 3, 1, "", "stride"], [561, 3, 1, "", "sub"], [562, 3, 1, "", "sub_"], [563, 3, 1, "", "subtract"], [564, 3, 1, "", "subtract_"], [565, 3, 1, "", "sum"], [566, 3, 1, "", "sum_to_size"], [567, 3, 1, "", "svd"], [568, 3, 1, "", "swapaxes"], [569, 3, 1, "", "swapdims"], [570, 3, 1, "", "t"], [571, 3, 1, "", "t_"], [572, 3, 1, "", "take"], [573, 3, 1, "", "take_along_dim"], [574, 3, 1, "", "tan"], [575, 3, 1, "", "tan_"], [576, 3, 1, "", "tanh"], [577, 3, 1, "", "tanh_"], [578, 3, 1, "", "tensor_split"], [579, 3, 1, "", "tile"], [580, 3, 1, "", "to"], [581, 3, 1, "", "to_dense"], [582, 3, 1, "", "to_mkldnn"], [583, 3, 1, "", "to_sparse"], [584, 3, 1, "", "to_sparse_bsc"], [585, 3, 1, "", "to_sparse_bsr"], [586, 3, 1, "", "to_sparse_coo"], [587, 3, 1, "", "to_sparse_csc"], [588, 3, 1, "", "to_sparse_csr"], [589, 3, 1, "", "tolist"], [590, 3, 1, "", "topk"], [591, 3, 1, "", "trace"], [592, 3, 1, "", "transpose"], [593, 3, 1, "", "transpose_"], [594, 3, 1, "", "triangular_solve"], [595, 3, 1, "", "tril"], [596, 3, 1, "", "tril_"], [597, 3, 1, "", "triu"], [598, 3, 1, "", "triu_"], [599, 3, 1, "", "true_divide"], [600, 3, 1, "", "true_divide_"], [601, 3, 1, "", "trunc"], [602, 3, 1, "", "trunc_"], [603, 3, 1, "", "type"], [604, 3, 1, "", "type_as"], [605, 3, 1, "", "unbind"], [606, 3, 1, "", "unflatten"], [607, 3, 1, "", "unfold"], [608, 3, 1, "", "uniform_"], [609, 3, 1, "", "unique"], [610, 3, 1, "", "unique_consecutive"], [611, 3, 1, "", "unsqueeze"], [612, 3, 1, "", "unsqueeze_"], [613, 3, 1, "", "untyped_storage"], [614, 3, 1, "", "values"], [615, 3, 1, "", "var"], [616, 3, 1, "", "vdot"], [617, 3, 1, "", "view"], [618, 3, 1, "", "view_as"], [619, 3, 1, "", "vsplit"], [620, 3, 1, "", "where"], [621, 3, 1, "", "xlogy"], [622, 3, 1, "", "xlogy_"], [623, 3, 1, "", "xpu"], [624, 3, 1, "", "zero_"]], "torch.TypedStorage": [[2173, 3, 1, "", "bfloat16"], [2173, 3, 1, "", "bool"], [2173, 3, 1, "", "byte"], [2173, 3, 1, "", "char"], [2173, 3, 1, "", "clone"], [2173, 3, 1, "", "complex_double"], [2173, 3, 1, "", "complex_float"], [2173, 3, 1, "", "copy_"], [2173, 3, 1, "", "cpu"], [2173, 3, 1, "", "cuda"], [2173, 3, 1, "", "data_ptr"], [2173, 4, 1, "", "device"], [2173, 3, 1, "", "double"], [2173, 2, 1, "", "dtype"], [2173, 3, 1, "", "element_size"], [2173, 4, 1, "", "filename"], [2173, 3, 1, "", "fill_"], [2173, 3, 1, "", "float"], [2173, 3, 1, "", "float8_e4m3fn"], [2173, 3, 1, "", "float8_e4m3fnuz"], [2173, 3, 1, "", "float8_e5m2"], [2173, 3, 1, "", "float8_e5m2fnuz"], [2173, 3, 1, "", "from_buffer"], [2173, 3, 1, "", "from_file"], [2173, 3, 1, "", "get_device"], [2173, 3, 1, "", "half"], [2173, 3, 1, "", "hpu"], [2173, 3, 1, "", "int"], [2173, 4, 1, "", "is_cuda"], [2173, 4, 1, "", "is_hpu"], [2173, 3, 1, "", "is_pinned"], [2173, 3, 1, "", "is_shared"], [2173, 2, 1, "", "is_sparse"], [2173, 3, 1, "", "long"], [2173, 3, 1, "", "nbytes"], [2173, 3, 1, "", "pickle_storage_type"], [2173, 3, 1, "", "pin_memory"], [2173, 3, 1, "", "resizable"], [2173, 3, 1, "", "resize_"], [2173, 3, 1, "", "share_memory_"], [2173, 3, 1, "", "short"], [2173, 3, 1, "", "size"], [2173, 3, 1, "", "to"], [2173, 3, 1, "", "tolist"], [2173, 3, 1, "", "type"], [2173, 3, 1, "", "untyped"]], "torch.UntypedStorage": [[2173, 3, 1, "", "bfloat16"], [2173, 3, 1, "", "bool"], [2173, 3, 1, "", "byte"], [2173, 3, 1, "", "byteswap"], [2173, 3, 1, "", "char"], [2173, 3, 1, "", "clone"], [2173, 3, 1, "", "complex_double"], [2173, 3, 1, "", "complex_float"], [2173, 3, 1, "", "copy_"], [2173, 3, 1, "", "cpu"], [2173, 3, 1, "", "cuda"], [2173, 3, 1, "", "data_ptr"], [2173, 2, 1, "", "device"], [2173, 3, 1, "", "double"], [2173, 3, 1, "", "element_size"], [2173, 4, 1, "", "filename"], [2173, 3, 1, "", "fill_"], [2173, 3, 1, "", "float"], [2173, 3, 1, "", "float8_e4m3fn"], [2173, 3, 1, "", "float8_e4m3fnuz"], [2173, 3, 1, "", "float8_e5m2"], [2173, 3, 1, "", "float8_e5m2fnuz"], [2173, 3, 1, "", "from_buffer"], [2173, 3, 1, "", "from_file"], [2173, 3, 1, "", "get_device"], [2173, 3, 1, "", "half"], [2173, 3, 1, "", "hpu"], [2173, 3, 1, "", "int"], [2173, 4, 1, "", "is_cuda"], [2173, 4, 1, "", "is_hpu"], [2173, 3, 1, "", "is_pinned"], [2173, 3, 1, "", "is_shared"], [2173, 2, 1, "", "is_sparse"], [2173, 2, 1, "", "is_sparse_csr"], [2173, 3, 1, "", "long"], [2173, 3, 1, "", "mps"], [2173, 3, 1, "", "nbytes"], [2173, 3, 1, "", "new"], [2173, 3, 1, "", "pin_memory"], [2173, 3, 1, "", "resizable"], [2173, 3, 1, "", "resize_"], [2173, 3, 1, "", "share_memory_"], [2173, 3, 1, "", "short"], [2173, 3, 1, "", "size"], [2173, 3, 1, "", "to"], [2173, 3, 1, "", "tolist"], [2173, 3, 1, "", "type"], [2173, 3, 1, "", "untyped"]], "torch.__config__": [[15, 5, 1, "", "parallel_info"], [15, 5, 1, "", "show"]], "torch.__future__": [[67, 5, 1, "", "get_overwrite_module_params_on_conversion"], [67, 5, 1, "", "get_swap_module_params_on_conversion"], [67, 5, 1, "", "set_overwrite_module_params_on_conversion"], [67, 5, 1, "", "set_swap_module_params_on_conversion"]], "torch._higher_order_ops.cond": [[14, 5, 1, "", "cond"]], "torch._inductor": [[2185, 5, 1, "", "aoti_compile_and_package"], [2185, 5, 1, "", "aoti_load_package"]], "torch._library.custom_ops": [[2100, 1, 1, "", "CustomOpDef"]], "torch._library.custom_ops.CustomOpDef": [[2100, 3, 1, "", "set_kernel_enabled"]], "torch._logging": [[681, 5, 1, "", "set_logs"]], "torch.accelerator": [[684, 5, 1, "", "current_accelerator"], [685, 5, 1, "", "current_device_idx"], [686, 5, 1, "", "current_device_index"], [687, 5, 1, "", "current_stream"], [688, 5, 1, "", "device_count"], [689, 5, 1, "", "is_available"], [690, 5, 1, "", "set_device_idx"], [691, 5, 1, "", "set_device_index"], [692, 5, 1, "", "set_stream"], [693, 5, 1, "", "synchronize"]], "torch.amp": [[1, 0, 0, "-", "autocast_mode"], [1, 5, 1, "", "custom_bwd"], [1, 5, 1, "", "custom_fwd"], [1, 0, 0, "-", "grad_scaler"]], "torch.amp.autocast_mode": [[1, 5, 1, "", "is_autocast_available"]], "torch.ao": [[2161, 0, 0, "-", "nn"], [2161, 0, 0, "-", "ns"], [2161, 0, 0, "-", "pruning"], [2161, 0, 0, "-", "quantization"]], "torch.ao.nn": [[2164, 0, 0, "-", "intrinsic"], [2164, 0, 0, "-", "qat"], [2161, 0, 0, "-", "quantizable"], [2161, 0, 0, "-", "quantized"], [2161, 0, 0, "-", "sparse"]], "torch.ao.nn.intrinsic": [[711, 1, 1, "", "BNReLU2d"], [712, 1, 1, "", "BNReLU3d"], [713, 1, 1, "", "ConvBn1d"], [714, 1, 1, "", "ConvBn2d"], [715, 1, 1, "", "ConvBn3d"], [716, 1, 1, "", "ConvBnReLU1d"], [717, 1, 1, "", "ConvBnReLU2d"], [718, 1, 1, "", "ConvBnReLU3d"], [719, 1, 1, "", "ConvReLU1d"], [720, 1, 1, "", "ConvReLU2d"], [721, 1, 1, "", "ConvReLU3d"], [722, 1, 1, "", "LinearReLU"], [2164, 0, 0, "-", "modules"], [2164, 0, 0, "-", "qat"], [2164, 0, 0, "-", "quantized"]], "torch.ao.nn.intrinsic.modules": [[2161, 0, 0, "-", "fused"]], "torch.ao.nn.intrinsic.qat": [[723, 1, 1, "", "ConvBn1d"], [724, 1, 1, "", "ConvBn2d"], [725, 1, 1, "", "ConvBn3d"], [726, 1, 1, "", "ConvBnReLU1d"], [727, 1, 1, "", "ConvBnReLU2d"], [728, 1, 1, "", "ConvBnReLU3d"], [729, 1, 1, "", "ConvReLU2d"], [730, 1, 1, "", "ConvReLU3d"], [731, 1, 1, "", "LinearReLU"], [732, 1, 1, "", "freeze_bn_stats"], [2164, 0, 0, "-", "modules"], [733, 1, 1, "", "update_bn_stats"]], "torch.ao.nn.intrinsic.qat.modules": [[2161, 0, 0, "-", "conv_fused"], [2161, 0, 0, "-", "linear_fused"], [2161, 0, 0, "-", "linear_relu"]], "torch.ao.nn.intrinsic.quantized": [[734, 1, 1, "", "BNReLU2d"], [735, 1, 1, "", "BNReLU3d"], [736, 1, 1, "", "ConvReLU1d"], [737, 1, 1, "", "ConvReLU2d"], [738, 1, 1, "", "ConvReLU3d"], [739, 1, 1, "", "LinearReLU"], [2164, 0, 0, "-", "dynamic"], [2164, 0, 0, "-", "modules"]], "torch.ao.nn.intrinsic.quantized.dynamic": [[740, 1, 1, "", "LinearReLU"], [2164, 0, 0, "-", "modules"]], "torch.ao.nn.intrinsic.quantized.dynamic.modules": [[2161, 0, 0, "-", "linear_relu"]], "torch.ao.nn.intrinsic.quantized.modules": [[2161, 0, 0, "-", "bn_relu"], [2161, 0, 0, "-", "conv_add"], [2161, 0, 0, "-", "conv_relu"], [2161, 0, 0, "-", "linear_relu"]], "torch.ao.nn.qat": [[741, 1, 1, "", "Conv2d"], [742, 1, 1, "", "Conv3d"], [743, 1, 1, "", "Linear"], [2164, 0, 0, "-", "dynamic"], [2164, 0, 0, "-", "modules"]], "torch.ao.nn.qat.Linear": [[743, 3, 1, "", "from_float"]], "torch.ao.nn.qat.dynamic": [[744, 1, 1, "", "Linear"], [2164, 0, 0, "-", "modules"]], "torch.ao.nn.qat.dynamic.modules": [[2161, 0, 0, "-", "linear"]], "torch.ao.nn.qat.modules": [[2161, 0, 0, "-", "conv"], [2161, 0, 0, "-", "embedding_ops"], [2161, 0, 0, "-", "linear"]], "torch.ao.nn.quantizable": [[745, 1, 1, "", "LSTM"], [746, 1, 1, "", "MultiheadAttention"], [2161, 0, 0, "-", "modules"]], "torch.ao.nn.quantizable.MultiheadAttention": [[746, 3, 1, "", "dequantize"], [746, 3, 1, "", "forward"]], "torch.ao.nn.quantizable.modules": [[2161, 0, 0, "-", "activation"], [2161, 0, 0, "-", "rnn"]], "torch.ao.nn.quantized": [[747, 1, 1, "", "BatchNorm2d"], [748, 1, 1, "", "BatchNorm3d"], [749, 1, 1, "", "Conv1d"], [750, 1, 1, "", "Conv2d"], [751, 1, 1, "", "Conv3d"], [752, 1, 1, "", "ConvTranspose1d"], [753, 1, 1, "", "ConvTranspose2d"], [754, 1, 1, "", "ConvTranspose3d"], [755, 1, 1, "", "ELU"], [756, 1, 1, "", "Embedding"], [757, 1, 1, "", "EmbeddingBag"], [758, 1, 1, "", "FXFloatFunctional"], [759, 1, 1, "", "FloatFunctional"], [760, 1, 1, "", "GroupNorm"], [761, 1, 1, "", "Hardswish"], [762, 1, 1, "", "InstanceNorm1d"], [763, 1, 1, "", "InstanceNorm2d"], [764, 1, 1, "", "InstanceNorm3d"], [765, 1, 1, "", "LayerNorm"], [766, 1, 1, "", "LeakyReLU"], [767, 1, 1, "", "Linear"], [768, 1, 1, "", "QFunctional"], [769, 1, 1, "", "ReLU6"], [770, 1, 1, "", "Sigmoid"], [2164, 0, 0, "-", "dynamic"], [2164, 0, 0, "-", "functional"], [2164, 0, 0, "-", "modules"], [2161, 0, 0, "-", "reference"]], "torch.ao.nn.quantized.Conv1d": [[749, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Conv2d": [[750, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Conv3d": [[751, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Embedding": [[756, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.EmbeddingBag": [[757, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Linear": [[767, 3, 1, "", "from_float"], [767, 3, 1, "", "from_reference"]], "torch.ao.nn.quantized.dynamic": [[771, 1, 1, "", "GRU"], [772, 1, 1, "", "GRUCell"], [773, 1, 1, "", "LSTM"], [774, 1, 1, "", "LSTMCell"], [775, 1, 1, "", "Linear"], [776, 1, 1, "", "RNNCell"], [2164, 0, 0, "-", "modules"]], "torch.ao.nn.quantized.dynamic.Linear": [[775, 3, 1, "", "from_float"], [775, 3, 1, "", "from_reference"]], "torch.ao.nn.quantized.dynamic.modules": [[2161, 0, 0, "-", "conv"], [2161, 0, 0, "-", "linear"], [2161, 0, 0, "-", "rnn"]], "torch.ao.nn.quantized.functional": [[777, 1, 1, "", "adaptive_avg_pool2d"], [778, 1, 1, "", "adaptive_avg_pool3d"], [779, 1, 1, "", "avg_pool2d"], [780, 1, 1, "", "avg_pool3d"], [781, 1, 1, "", "celu"], [782, 1, 1, "", "clamp"], [783, 1, 1, "", "conv1d"], [784, 1, 1, "", "conv2d"], [785, 1, 1, "", "conv3d"], [786, 1, 1, "", "elu"], [787, 1, 1, "", "hardsigmoid"], [788, 1, 1, "", "hardswish"], [789, 1, 1, "", "hardtanh"], [790, 1, 1, "", "interpolate"], [791, 1, 1, "", "leaky_relu"], [792, 1, 1, "", "linear"], [793, 1, 1, "", "max_pool1d"], [794, 1, 1, "", "max_pool2d"], [795, 1, 1, "", "threshold"], [796, 1, 1, "", "upsample"], [797, 1, 1, "", "upsample_bilinear"], [798, 1, 1, "", "upsample_nearest"]], "torch.ao.nn.quantized.modules": [[2161, 0, 0, "-", "activation"], [2161, 0, 0, "-", "batchnorm"], [2161, 0, 0, "-", "conv"], [2161, 0, 0, "-", "dropout"], [2161, 0, 0, "-", "embedding_ops"], [2161, 0, 0, "-", "functional_modules"], [2161, 0, 0, "-", "linear"], [2161, 0, 0, "-", "normalization"], [2161, 0, 0, "-", "rnn"], [2161, 0, 0, "-", "utils"]], "torch.ao.nn.quantized.reference": [[2161, 0, 0, "-", "modules"]], "torch.ao.nn.quantized.reference.modules": [[2161, 0, 0, "-", "conv"], [2161, 0, 0, "-", "linear"], [2161, 0, 0, "-", "rnn"], [2161, 0, 0, "-", "sparse"], [2161, 0, 0, "-", "utils"]], "torch.ao.nn.sparse": [[2161, 0, 0, "-", "quantized"]], "torch.ao.nn.sparse.quantized": [[2161, 0, 0, "-", "dynamic"], [2161, 0, 0, "-", "linear"], [2161, 0, 0, "-", "utils"]], "torch.ao.nn.sparse.quantized.dynamic": [[2161, 0, 0, "-", "linear"]], "torch.ao.ns": [[2181, 0, 0, "-", "_numeric_suite"], [2182, 0, 0, "-", "_numeric_suite_fx"], [2161, 0, 0, "-", "fx"]], "torch.ao.ns._numeric_suite": [[2181, 1, 1, "", "Logger"], [2181, 1, 1, "", "OutputLogger"], [2181, 1, 1, "", "Shadow"], [2181, 1, 1, "", "ShadowLogger"], [2181, 5, 1, "", "compare_model_outputs"], [2181, 5, 1, "", "compare_model_stub"], [2181, 5, 1, "", "compare_weights"], [2181, 5, 1, "", "get_logger_dict"], [2181, 5, 1, "", "get_matching_activations"], [2181, 5, 1, "", "prepare_model_outputs"], [2181, 5, 1, "", "prepare_model_with_stubs"]], "torch.ao.ns._numeric_suite.Logger": [[2181, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite.OutputLogger": [[2181, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite.Shadow": [[2181, 3, 1, "", "add"], [2181, 3, 1, "", "add_relu"], [2181, 3, 1, "", "add_scalar"], [2181, 3, 1, "", "cat"], [2181, 3, 1, "", "forward"], [2181, 3, 1, "", "mul"], [2181, 3, 1, "", "mul_scalar"]], "torch.ao.ns._numeric_suite.ShadowLogger": [[2181, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite_fx": [[2182, 1, 1, "", "NSTracer"], [2182, 1, 1, "", "OutputComparisonLogger"], [2182, 1, 1, "", "OutputLogger"], [2182, 5, 1, "", "add_loggers"], [2182, 5, 1, "", "add_shadow_loggers"], [2182, 5, 1, "", "convert_n_shadows_model"], [2182, 5, 1, "", "extend_logger_results_with_comparison"], [2182, 5, 1, "", "extract_logger_info"], [2182, 5, 1, "", "extract_results_n_shadows_model"], [2182, 5, 1, "", "extract_shadow_logger_info"], [2182, 5, 1, "", "extract_weights"], [2182, 5, 1, "", "loggers_set_enabled"], [2182, 5, 1, "", "loggers_set_save_activations"], [2182, 5, 1, "", "prepare_n_shadows_model"], [2182, 5, 1, "", "print_comparisons_n_shadows_model"]], "torch.ao.ns._numeric_suite_fx.NSTracer": [[2182, 3, 1, "", "is_leaf_module"]], "torch.ao.ns._numeric_suite_fx.OutputComparisonLogger": [[2182, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite_fx.OutputLogger": [[2182, 3, 1, "", "forward"]], "torch.ao.ns.fx": [[2161, 0, 0, "-", "graph_matcher"], [2161, 0, 0, "-", "graph_passes"], [2161, 0, 0, "-", "mappings"], [2161, 0, 0, "-", "n_shadows_utils"], [2161, 0, 0, "-", "ns_types"], [2161, 0, 0, "-", "pattern_utils"], [2161, 0, 0, "-", "qconfig_multi_mapping"], [2161, 0, 0, "-", "utils"], [2161, 0, 0, "-", "weight_utils"]], "torch.ao.ns.fx.utils": [[2182, 5, 1, "", "compute_cosine_similarity"], [2182, 5, 1, "", "compute_normalized_l2_error"], [2182, 5, 1, "", "compute_sqnr"]], "torch.ao.pruning": [[2161, 0, 0, "-", "scheduler"], [2161, 0, 0, "-", "sparsifier"]], "torch.ao.pruning.scheduler": [[2161, 0, 0, "-", "base_scheduler"], [2161, 0, 0, "-", "cubic_scheduler"], [2161, 0, 0, "-", "lambda_scheduler"]], "torch.ao.pruning.sparsifier": [[2161, 0, 0, "-", "base_sparsifier"], [2161, 0, 0, "-", "nearly_diagonal_sparsifier"], [2161, 0, 0, "-", "utils"], [2161, 0, 0, "-", "weight_norm_sparsifier"]], "torch.ao.quantization": [[799, 2, 1, "", "CUSTOM_KEY"], [800, 1, 1, "", "DeQuantStub"], [801, 2, 1, "", "NUMERIC_DEBUG_HANDLE_KEY"], [802, 1, 1, "", "QuantStub"], [803, 1, 1, "", "QuantWrapper"], [804, 1, 1, "", "add_quant_dequant"], [2161, 0, 0, "-", "backend_config"], [810, 1, 1, "", "compare_results"], [811, 1, 1, "", "convert"], [812, 1, 1, "", "default_eval_fn"], [813, 1, 1, "", "extract_results_from_loggers"], [2161, 0, 0, "-", "fake_quantize"], [2161, 0, 0, "-", "fuse_modules"], [2161, 0, 0, "-", "fuser_method_mappings"], [2161, 0, 0, "-", "fx"], [834, 1, 1, "", "generate_numeric_debug_handle"], [2161, 0, 0, "-", "observer"], [866, 1, 1, "", "prepare"], [867, 1, 1, "", "prepare_for_propagation_comparison"], [868, 1, 1, "", "prepare_qat"], [869, 1, 1, "", "propagate_qconfig_"], [2164, 0, 0, "-", "pt2e"], [2161, 0, 0, "-", "qconfig"], [2161, 0, 0, "-", "qconfig_mapping"], [2161, 0, 0, "-", "quant_type"], [2161, 0, 0, "-", "quantization_mappings"], [887, 1, 1, "", "quantize"], [888, 1, 1, "", "quantize_dynamic"], [2161, 0, 0, "-", "quantize_fx"], [2161, 0, 0, "-", "quantize_jit"], [2161, 0, 0, "-", "quantize_pt2e"], [893, 1, 1, "", "quantize_qat"], [2164, 0, 0, "-", "quantizer"], [2161, 0, 0, "-", "stubs"], [894, 1, 1, "", "swap_module"], [2161, 0, 0, "-", "utils"]], "torch.ao.quantization.backend_config": [[805, 1, 1, "", "BackendConfig"], [806, 1, 1, "", "BackendPatternConfig"], [807, 1, 1, "", "DTypeConfig"], [808, 1, 1, "", "DTypeWithConstraints"], [809, 1, 1, "", "ObservationType"], [2161, 0, 0, "-", "backend_config"], [2161, 0, 0, "-", "executorch"], [2161, 0, 0, "-", "fbgemm"], [2161, 0, 0, "-", "native"], [2161, 0, 0, "-", "observation_type"], [2161, 0, 0, "-", "onednn"], [2161, 0, 0, "-", "qnnpack"], [2161, 0, 0, "-", "tensorrt"], [2161, 0, 0, "-", "utils"], [2161, 0, 0, "-", "x86"]], "torch.ao.quantization.backend_config.BackendConfig": [[805, 4, 1, "", "configs"], [805, 3, 1, "", "from_dict"], [805, 3, 1, "", "set_backend_pattern_config"], [805, 3, 1, "", "set_backend_pattern_configs"], [805, 3, 1, "", "set_name"], [805, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.BackendPatternConfig": [[806, 3, 1, "", "add_dtype_config"], [806, 3, 1, "", "from_dict"], [806, 3, 1, "", "set_dtype_configs"], [806, 3, 1, "", "set_fused_module"], [806, 3, 1, "", "set_fuser_method"], [806, 3, 1, "", "set_observation_type"], [806, 3, 1, "", "set_pattern"], [806, 3, 1, "", "set_qat_module"], [806, 3, 1, "", "set_reference_quantized_module"], [806, 3, 1, "", "set_root_module"], [806, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.DTypeConfig": [[807, 3, 1, "", "from_dict"], [807, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.ObservationType": [[809, 2, 1, "", "INPUT_OUTPUT_NOT_OBSERVED"], [809, 2, 1, "", "OUTPUT_SHARE_OBSERVER_WITH_INPUT"], [809, 2, 1, "", "OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT"]], "torch.ao.quantization.fake_quantize": [[814, 1, 1, "", "FakeQuantize"], [815, 1, 1, "", "FakeQuantizeBase"], [816, 1, 1, "", "FixedQParamsFakeQuantize"], [817, 1, 1, "", "FusedMovingAvgObsFakeQuantize"], [818, 2, 1, "", "default_fake_quant"], [819, 2, 1, "", "default_fused_act_fake_quant"], [820, 2, 1, "", "default_fused_per_channel_wt_fake_quant"], [821, 2, 1, "", "default_fused_wt_fake_quant"], [822, 2, 1, "", "default_histogram_fake_quant"], [823, 2, 1, "", "default_per_channel_weight_fake_quant"], [824, 2, 1, "", "default_weight_fake_quant"], [825, 1, 1, "", "disable_fake_quant"], [826, 1, 1, "", "disable_observer"], [827, 1, 1, "", "enable_fake_quant"], [828, 1, 1, "", "enable_observer"]], "torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize": [[816, 3, 1, "", "extra_repr"]], "torch.ao.quantization.fuse_modules": [[829, 1, 1, "", "fuse_modules"]], "torch.ao.quantization.fx": [[2161, 0, 0, "-", "convert"], [2161, 0, 0, "-", "custom_config"], [2161, 0, 0, "-", "fuse"], [2161, 0, 0, "-", "fuse_handler"], [2161, 0, 0, "-", "graph_module"], [2161, 0, 0, "-", "lower_to_fbgemm"], [2161, 0, 0, "-", "lower_to_qnnpack"], [2161, 0, 0, "-", "lstm_utils"], [2161, 0, 0, "-", "match_utils"], [2161, 0, 0, "-", "pattern_utils"], [2161, 0, 0, "-", "prepare"], [2161, 0, 0, "-", "qconfig_mapping_utils"], [2161, 0, 0, "-", "quantize_handler"], [2161, 0, 0, "-", "tracer"], [2161, 0, 0, "-", "utils"]], "torch.ao.quantization.fx.custom_config": [[830, 1, 1, "", "ConvertCustomConfig"], [831, 1, 1, "", "FuseCustomConfig"], [832, 1, 1, "", "PrepareCustomConfig"], [833, 1, 1, "", "StandaloneModuleConfigEntry"]], "torch.ao.quantization.fx.custom_config.ConvertCustomConfig": [[830, 3, 1, "", "from_dict"], [830, 3, 1, "", "set_observed_to_quantized_mapping"], [830, 3, 1, "", "set_preserved_attributes"], [830, 3, 1, "", "to_dict"]], "torch.ao.quantization.fx.custom_config.FuseCustomConfig": [[831, 3, 1, "", "from_dict"], [831, 3, 1, "", "set_preserved_attributes"], [831, 3, 1, "", "to_dict"]], "torch.ao.quantization.fx.custom_config.PrepareCustomConfig": [[832, 3, 1, "", "from_dict"], [832, 3, 1, "", "set_float_to_observed_mapping"], [832, 3, 1, "", "set_input_quantized_indexes"], [832, 3, 1, "", "set_non_traceable_module_classes"], [832, 3, 1, "", "set_non_traceable_module_names"], [832, 3, 1, "", "set_output_quantized_indexes"], [832, 3, 1, "", "set_preserved_attributes"], [832, 3, 1, "", "set_standalone_module_class"], [832, 3, 1, "", "set_standalone_module_name"], [832, 3, 1, "", "to_dict"]], "torch.ao.quantization.observer": [[837, 1, 1, "", "HistogramObserver"], [839, 1, 1, "", "MinMaxObserver"], [840, 1, 1, "", "MovingAverageMinMaxObserver"], [841, 1, 1, "", "MovingAveragePerChannelMinMaxObserver"], [842, 1, 1, "", "NoopObserver"], [843, 1, 1, "", "ObserverBase"], [846, 1, 1, "", "PerChannelMinMaxObserver"], [851, 1, 1, "", "PlaceholderObserver"], [852, 1, 1, "", "RecordingObserver"], [855, 2, 1, "", "default_debug_observer"], [856, 2, 1, "", "default_dynamic_quant_observer"], [857, 2, 1, "", "default_float_qparams_observer"], [858, 2, 1, "", "default_histogram_observer"], [859, 2, 1, "", "default_observer"], [860, 2, 1, "", "default_per_channel_weight_observer"], [861, 2, 1, "", "default_placeholder_observer"], [862, 2, 1, "", "default_weight_observer"], [864, 1, 1, "", "get_observer_state_dict"], [865, 1, 1, "", "load_observer_state_dict"]], "torch.ao.quantization.observer.MinMaxObserver": [[839, 3, 1, "", "calculate_qparams"], [839, 3, 1, "", "forward"], [839, 3, 1, "", "reset_min_max_vals"]], "torch.ao.quantization.observer.ObserverBase": [[843, 3, 1, "", "with_args"], [843, 3, 1, "", "with_callable_args"]], "torch.ao.quantization.observer.PerChannelMinMaxObserver": [[846, 3, 1, "", "reset_min_max_vals"]], "torch.ao.quantization.pt2e": [[2161, 0, 0, "-", "duplicate_dq_pass"], [2161, 0, 0, "-", "export_utils"], [2161, 0, 0, "-", "graph_utils"], [2161, 0, 0, "-", "port_metadata_pass"], [2161, 0, 0, "-", "prepare"], [2161, 0, 0, "-", "qat_utils"], [2164, 0, 0, "-", "representation"], [2161, 0, 0, "-", "utils"]], "torch.ao.quantization.pt2e.export_utils": [[870, 1, 1, "", "model_is_exported"]], "torch.ao.quantization.pt2e.representation": [[2161, 0, 0, "-", "rewrite"]], "torch.ao.quantization.qconfig": [[871, 1, 1, "", "QConfig"], [872, 2, 1, "", "default_activation_only_qconfig"], [873, 2, 1, "", "default_debug_qconfig"], [874, 2, 1, "", "default_dynamic_qconfig"], [875, 2, 1, "", "default_per_channel_qconfig"], [876, 2, 1, "", "default_qat_qconfig"], [877, 2, 1, "", "default_qat_qconfig_v2"], [878, 2, 1, "", "default_qconfig"], [879, 2, 1, "", "default_weight_only_qconfig"], [880, 2, 1, "", "float16_dynamic_qconfig"], [881, 2, 1, "", "float16_static_qconfig"], [882, 2, 1, "", "float_qparams_weight_only_qconfig"], [883, 2, 1, "", "per_channel_dynamic_qconfig"]], "torch.ao.quantization.qconfig_mapping": [[884, 1, 1, "", "QConfigMapping"], [885, 1, 1, "", "get_default_qat_qconfig_mapping"], [886, 1, 1, "", "get_default_qconfig_mapping"]], "torch.ao.quantization.qconfig_mapping.QConfigMapping": [[884, 3, 1, "", "from_dict"], [884, 3, 1, "", "set_global"], [884, 3, 1, "", "set_module_name"], [884, 3, 1, "", "set_module_name_object_type_order"], [884, 3, 1, "", "set_module_name_regex"], [884, 3, 1, "", "set_object_type"], [884, 3, 1, "", "to_dict"]], "torch.ao.quantization.quantize_fx": [[889, 1, 1, "", "convert_fx"], [890, 1, 1, "", "fuse_fx"], [891, 1, 1, "", "prepare_fx"], [892, 1, 1, "", "prepare_qat_fx"]], "torch.ao.quantization.quantizer": [[2161, 0, 0, "-", "composable_quantizer"], [2161, 0, 0, "-", "embedding_quantizer"], [2161, 0, 0, "-", "quantizer"], [2161, 0, 0, "-", "utils"], [2161, 0, 0, "-", "x86_inductor_quantizer"], [2161, 0, 0, "-", "xnnpack_quantizer"], [2161, 0, 0, "-", "xnnpack_quantizer_utils"], [2161, 0, 0, "-", "xpu_inductor_quantizer"]], "torch.autograd": [[2, 1, 1, "", "Function"], [2, 0, 0, "-", "anomaly_mode"], [923, 5, 1, "", "backward"], [2, 1, 1, "", "detect_anomaly"], [2, 0, 0, "-", "forward_ad"], [2, 0, 0, "-", "function"], [2, 0, 0, "-", "functional"], [944, 5, 1, "", "grad"], [2, 0, 0, "-", "grad_mode"], [2, 0, 0, "-", "gradcheck"], [2, 0, 0, "-", "graph"], [2, 0, 0, "-", "profiler"], [2, 0, 0, "-", "profiler_legacy"], [2, 0, 0, "-", "profiler_util"], [2, 1, 1, "", "set_detect_anomaly"], [2, 0, 0, "-", "variable"]], "torch.autograd.Function": [[919, 3, 1, "", "backward"], [920, 3, 1, "", "forward"], [921, 3, 1, "", "jvp"], [922, 3, 1, "", "vmap"]], "torch.autograd.forward_ad": [[924, 1, 1, "", "UnpackedDualTensor"], [925, 1, 1, "", "dual_level"], [926, 5, 1, "", "enter_dual_level"], [927, 5, 1, "", "exit_dual_level"], [928, 5, 1, "", "make_dual"], [929, 5, 1, "", "unpack_dual"]], "torch.autograd.forward_ad.UnpackedDualTensor": [[924, 3, 1, "", "count"], [924, 3, 1, "", "index"], [924, 2, 1, "", "primal"], [924, 2, 1, "", "tangent"]], "torch.autograd.function": [[930, 1, 1, "", "BackwardCFunction"], [935, 1, 1, "", "InplaceFunction"], [936, 1, 1, "", "NestedIOFunction"], [937, 5, 1, "", "once_differentiable"]], "torch.autograd.function.BackwardCFunction": [[930, 3, 1, "", "apply"], [930, 3, 1, "", "apply_jvp"], [930, 3, 1, "", "mark_dirty"], [930, 3, 1, "", "mark_non_differentiable"], [930, 3, 1, "", "save_for_backward"], [930, 3, 1, "", "save_for_forward"], [930, 3, 1, "", "set_materialize_grads"]], "torch.autograd.function.FunctionCtx": [[931, 3, 1, "", "mark_dirty"], [932, 3, 1, "", "mark_non_differentiable"], [933, 3, 1, "", "save_for_backward"], [934, 3, 1, "", "set_materialize_grads"]], "torch.autograd.function.InplaceFunction": [[935, 3, 1, "", "backward"], [935, 3, 1, "", "forward"], [935, 3, 1, "", "jvp"], [935, 3, 1, "", "mark_dirty"], [935, 3, 1, "", "mark_non_differentiable"], [935, 3, 1, "", "save_for_backward"], [935, 3, 1, "", "save_for_forward"], [935, 3, 1, "", "set_materialize_grads"], [935, 3, 1, "", "setup_context"], [935, 3, 1, "", "vjp"], [935, 3, 1, "", "vmap"]], "torch.autograd.function.NestedIOFunction": [[936, 3, 1, "", "backward"], [936, 3, 1, "", "backward_extended"], [936, 3, 1, "", "forward"], [936, 3, 1, "", "forward_extended"], [936, 3, 1, "", "jvp"], [936, 3, 1, "", "mark_dirty"], [936, 3, 1, "", "mark_non_differentiable"], [936, 3, 1, "", "save_for_backward"], [936, 3, 1, "", "save_for_forward"], [936, 4, 1, "", "saved_tensors"], [936, 3, 1, "", "set_materialize_grads"], [936, 3, 1, "", "setup_context"], [936, 3, 1, "", "vjp"], [936, 3, 1, "", "vmap"]], "torch.autograd.functional": [[938, 5, 1, "", "hessian"], [939, 5, 1, "", "hvp"], [940, 5, 1, "", "jacobian"], [941, 5, 1, "", "jvp"], [942, 5, 1, "", "vhp"], [943, 5, 1, "", "vjp"]], "torch.autograd.grad_mode": [[945, 1, 1, "", "inference_mode"], [946, 1, 1, "", "set_grad_enabled"], [947, 1, 1, "", "set_multithreading_enabled"]], "torch.autograd.grad_mode.inference_mode": [[945, 3, 1, "", "clone"]], "torch.autograd.grad_mode.set_grad_enabled": [[946, 3, 1, "", "clone"]], "torch.autograd.grad_mode.set_multithreading_enabled": [[947, 3, 1, "", "clone"]], "torch.autograd.gradcheck": [[948, 6, 1, "", "GradcheckError"], [949, 5, 1, "", "gradcheck"], [950, 5, 1, "", "gradgradcheck"]], "torch.autograd.graph": [[2, 1, 1, "", "GradientEdge"], [2, 1, 1, "", "allow_mutation_on_saved_tensors"], [2, 1, 1, "", "disable_saved_tensors_hooks"], [2, 5, 1, "", "get_gradient_edge"], [956, 5, 1, "", "increment_version"], [2, 1, 1, "", "register_multi_grad_hook"], [2, 1, 1, "", "save_on_cpu"], [2, 1, 1, "", "saved_tensors_hooks"]], "torch.autograd.graph.Node": [[951, 3, 1, "", "metadata"], [952, 3, 1, "", "name"], [953, 4, 1, "", "next_functions"], [954, 3, 1, "", "register_hook"], [955, 3, 1, "", "register_prehook"]], "torch.autograd.profiler": [[957, 1, 1, "", "EnforceUnique"], [958, 1, 1, "", "KinetoStepTracker"], [2, 1, 1, "", "emit_itt"], [2, 1, 1, "", "emit_nvtx"], [959, 5, 1, "", "load_nvprof"], [960, 5, 1, "", "parse_nvprof_trace"], [2, 1, 1, "", "profile"], [965, 1, 1, "", "record_function"]], "torch.autograd.profiler.EnforceUnique": [[957, 3, 1, "", "see"]], "torch.autograd.profiler.KinetoStepTracker": [[958, 3, 1, "", "current_step"], [958, 3, 1, "", "erase_step_count"], [958, 3, 1, "", "increment_step"], [958, 3, 1, "", "init_step_count"]], "torch.autograd.profiler.profile": [[961, 3, 1, "", "export_chrome_trace"], [962, 3, 1, "", "key_averages"], [963, 4, 1, "", "self_cpu_time_total"], [964, 3, 1, "", "total_average"]], "torch.autograd.profiler_util": [[966, 1, 1, "", "Interval"], [967, 1, 1, "", "Kernel"], [968, 1, 1, "", "MemRecordsAcc"], [969, 1, 1, "", "StringTable"]], "torch.autograd.profiler_util.Interval": [[966, 3, 1, "", "elapsed_us"]], "torch.autograd.profiler_util.Kernel": [[967, 3, 1, "", "count"], [967, 2, 1, "", "device"], [967, 2, 1, "", "duration"], [967, 3, 1, "", "index"], [967, 2, 1, "", "name"]], "torch.autograd.profiler_util.MemRecordsAcc": [[968, 3, 1, "", "in_interval"]], "torch.autograd.profiler_util.StringTable": [[969, 3, 1, "", "clear"], [969, 3, 1, "", "copy"], [969, 2, 1, "", "default_factory"], [969, 3, 1, "", "fromkeys"], [969, 3, 1, "", "get"], [969, 3, 1, "", "items"], [969, 3, 1, "", "keys"], [969, 3, 1, "", "pop"], [969, 3, 1, "", "popitem"], [969, 3, 1, "", "setdefault"], [969, 3, 1, "", "update"], [969, 3, 1, "", "values"]], "torch.backends": [[3, 0, 0, "-", "cpu"], [3, 0, 0, "-", "cuda"], [3, 0, 0, "-", "cudnn"], [3, 0, 0, "-", "cusparselt"], [3, 0, 0, "-", "kleidiai"], [3, 0, 0, "-", "mha"], [3, 0, 0, "-", "mkl"], [3, 0, 0, "-", "mkldnn"], [3, 0, 0, "-", "mps"], [3, 0, 0, "-", "nnpack"], [3, 0, 0, "-", "openmp"], [3, 0, 0, "-", "opt_einsum"], [3, 0, 0, "-", "quantized"], [3, 0, 0, "-", "xeon"], [3, 0, 0, "-", "xnnpack"]], "torch.backends.cpu": [[3, 5, 1, "", "get_cpu_capability"]], "torch.backends.cuda": [[3, 1, 1, "", "SDPAParams"], [3, 5, 1, "", "allow_fp16_bf16_reduction_math_sdp"], [3, 5, 1, "", "can_use_cudnn_attention"], [3, 5, 1, "", "can_use_efficient_attention"], [3, 5, 1, "", "can_use_flash_attention"], [3, 5, 1, "", "cudnn_sdp_enabled"], [3, 2, 1, "", "cufft_plan_cache"], [3, 5, 1, "", "enable_cudnn_sdp"], [3, 5, 1, "", "enable_flash_sdp"], [3, 5, 1, "", "enable_math_sdp"], [3, 5, 1, "", "enable_mem_efficient_sdp"], [3, 5, 1, "", "flash_sdp_enabled"], [3, 5, 1, "", "fp16_bf16_reduction_math_sdp_allowed"], [3, 5, 1, "", "is_built"], [3, 5, 1, "", "is_flash_attention_available"], [3, 5, 1, "", "math_sdp_enabled"], [3, 5, 1, "", "mem_efficient_sdp_enabled"], [3, 5, 1, "", "preferred_blas_library"], [3, 5, 1, "", "preferred_linalg_library"], [3, 5, 1, "", "sdp_kernel"]], "torch.backends.cuda.cufft_plan_cache": [[3, 3, 1, "", "clear"], [3, 2, 1, "", "max_size"], [3, 2, 1, "", "size"]], "torch.backends.cuda.matmul": [[3, 2, 1, "", "allow_bf16_reduced_precision_reduction"], [3, 2, 1, "", "allow_fp16_reduced_precision_reduction"], [3, 2, 1, "", "allow_tf32"]], "torch.backends.cudnn": [[3, 2, 1, "", "allow_tf32"], [3, 2, 1, "", "benchmark"], [3, 2, 1, "", "benchmark_limit"], [3, 2, 1, "", "deterministic"], [3, 2, 1, "", "enabled"], [3, 5, 1, "", "is_available"], [3, 0, 0, "-", "rnn"], [3, 5, 1, "", "version"]], "torch.backends.cusparselt": [[3, 5, 1, "", "is_available"], [3, 5, 1, "", "version"]], "torch.backends.mha": [[3, 5, 1, "", "get_fastpath_enabled"], [3, 5, 1, "", "set_fastpath_enabled"]], "torch.backends.mkl": [[3, 5, 1, "", "is_available"], [3, 1, 1, "", "verbose"]], "torch.backends.mkldnn": [[3, 5, 1, "", "is_available"], [3, 1, 1, "", "verbose"]], "torch.backends.mps": [[3, 5, 1, "", "is_available"], [3, 5, 1, "", "is_built"]], "torch.backends.nnpack": [[3, 5, 1, "", "flags"], [3, 5, 1, "", "is_available"], [3, 5, 1, "", "set_flags"]], "torch.backends.openmp": [[3, 5, 1, "", "is_available"]], "torch.backends.opt_einsum": [[3, 2, 1, "", "enabled"], [3, 5, 1, "", "get_opt_einsum"], [3, 5, 1, "", "is_available"], [3, 2, 1, "", "strategy"]], "torch.backends.xeon": [[3, 0, 0, "-", "run_cpu"]], "torch.compiler": [[1004, 5, 1, "", "allow_in_graph"], [1005, 5, 1, "", "assume_constant_result"], [1006, 5, 1, "", "compile"], [2184, 0, 0, "-", "config"], [1007, 5, 1, "", "cudagraph_mark_step_begin"], [1008, 5, 1, "", "disable"], [1009, 5, 1, "", "is_compiling"], [1010, 5, 1, "", "is_dynamo_compiling"], [1012, 5, 1, "", "list_backends"], [1013, 5, 1, "", "reset"], [1014, 5, 1, "", "set_stance"], [1015, 5, 1, "", "substitute_in_graph"]], "torch.compiler.config": [[2184, 7, 1, "", "job_id"]], "torch.cpu": [[1029, 1, 1, "", "StreamContext"], [1, 0, 0, "-", "amp"], [1030, 5, 1, "", "current_device"], [1031, 5, 1, "", "current_stream"], [1032, 5, 1, "", "device_count"], [1033, 5, 1, "", "is_available"], [1034, 5, 1, "", "set_device"], [1028, 5, 1, "", "stream"], [1035, 5, 1, "", "synchronize"]], "torch.cpu.amp": [[1, 1, 1, "", "GradScaler"], [1, 1, 1, "", "autocast"], [1, 0, 0, "-", "autocast_mode"], [1, 0, 0, "-", "grad_scaler"]], "torch.cuda": [[1037, 1, 1, "", "CUDAGraph"], [1038, 1, 1, "", "CUDAPluggableAllocator"], [1039, 1, 1, "", "Event"], [1040, 1, 1, "", "ExternalStream"], [1041, 1, 1, "", "MemPool"], [1042, 1, 1, "", "MemPoolContext"], [1043, 6, 1, "", "OutOfMemoryError"], [1045, 1, 1, "", "StreamContext"], [20, 0, 0, "-", "_sanitizer"], [1, 0, 0, "-", "amp"], [1046, 5, 1, "", "caching_allocator_alloc"], [1047, 5, 1, "", "caching_allocator_delete"], [1048, 5, 1, "", "can_device_access_peer"], [1049, 5, 1, "", "change_current_allocator"], [1050, 5, 1, "", "clock_rate"], [19, 0, 0, "-", "comm"], [1057, 5, 1, "", "cudart"], [1058, 5, 1, "", "current_blas_handle"], [1059, 5, 1, "", "current_device"], [1060, 5, 1, "", "current_stream"], [1061, 5, 1, "", "default_stream"], [1062, 1, 1, "", "device"], [1063, 5, 1, "", "device_count"], [1064, 5, 1, "", "device_memory_used"], [1065, 1, 1, "", "device_of"], [1066, 5, 1, "", "empty_cache"], [19, 0, 0, "-", "error"], [19, 0, 0, "-", "gds"], [1067, 5, 1, "", "get_allocator_backend"], [1068, 5, 1, "", "get_arch_list"], [1069, 5, 1, "", "get_device_capability"], [1070, 5, 1, "", "get_device_name"], [1071, 5, 1, "", "get_device_properties"], [1072, 5, 1, "", "get_gencode_flags"], [1073, 5, 1, "", "get_per_process_memory_fraction"], [1074, 5, 1, "", "get_rng_state"], [1075, 5, 1, "", "get_rng_state_all"], [1077, 5, 1, "", "get_sync_debug_mode"], [1078, 1, 1, "", "graph"], [1079, 5, 1, "", "graph_pool_handle"], [19, 0, 0, "-", "graphs"], [1080, 5, 1, "", "init"], [1081, 5, 1, "", "initial_seed"], [1082, 5, 1, "", "ipc_collect"], [1083, 5, 1, "", "is_available"], [1084, 5, 1, "", "is_current_stream_capturing"], [1085, 5, 1, "", "is_initialized"], [19, 0, 0, "-", "jiterator"], [1088, 5, 1, "", "list_gpu_processes"], [1089, 5, 1, "", "make_graphed_callables"], [1090, 5, 1, "", "manual_seed"], [1091, 5, 1, "", "manual_seed_all"], [1092, 5, 1, "", "max_memory_allocated"], [1093, 5, 1, "", "max_memory_cached"], [1094, 5, 1, "", "max_memory_reserved"], [1095, 5, 1, "", "mem_get_info"], [19, 0, 0, "-", "memory"], [1097, 5, 1, "", "memory_allocated"], [1098, 5, 1, "", "memory_cached"], [1099, 5, 1, "", "memory_reserved"], [1100, 5, 1, "", "memory_snapshot"], [1101, 5, 1, "", "memory_stats"], [1102, 5, 1, "", "memory_summary"], [1103, 5, 1, "", "memory_usage"], [19, 0, 0, "-", "nccl"], [19, 0, 0, "-", "nvtx"], [1108, 5, 1, "", "power_draw"], [19, 0, 0, "-", "profiler"], [19, 0, 0, "-", "random"], [1109, 5, 1, "", "reset_max_memory_allocated"], [1110, 5, 1, "", "reset_max_memory_cached"], [1111, 5, 1, "", "reset_peak_memory_stats"], [1112, 5, 1, "", "seed"], [1113, 5, 1, "", "seed_all"], [1114, 5, 1, "", "set_device"], [1115, 5, 1, "", "set_per_process_memory_fraction"], [1116, 5, 1, "", "set_rng_state"], [1117, 5, 1, "", "set_rng_state_all"], [1118, 5, 1, "", "set_stream"], [1119, 5, 1, "", "set_sync_debug_mode"], [19, 0, 0, "-", "sparse"], [1044, 5, 1, "", "stream"], [19, 0, 0, "-", "streams"], [1120, 5, 1, "", "synchronize"], [1121, 5, 1, "", "temperature"], [21, 0, 0, "-", "tunable"], [19, 1, 1, "", "use_mem_pool"], [1122, 5, 1, "", "utilization"]], "torch.cuda.CUDAGraph": [[1037, 3, 1, "", "capture_begin"], [1037, 3, 1, "", "capture_end"], [1037, 3, 1, "", "debug_dump"], [1037, 3, 1, "", "enable_debug_mode"], [1037, 3, 1, "", "pool"], [1037, 3, 1, "", "replay"], [1037, 3, 1, "", "reset"]], "torch.cuda.Event": [[1039, 3, 1, "", "elapsed_time"], [1039, 3, 1, "", "from_ipc_handle"], [1039, 3, 1, "", "ipc_handle"], [1039, 3, 1, "", "query"], [1039, 3, 1, "", "record"], [1039, 3, 1, "", "synchronize"], [1039, 3, 1, "", "wait"]], "torch.cuda.ExternalStream": [[1040, 3, 1, "", "query"], [1040, 3, 1, "", "record_event"], [1040, 3, 1, "", "synchronize"], [1040, 3, 1, "", "wait_event"], [1040, 3, 1, "", "wait_stream"]], "torch.cuda.MemPool": [[1041, 4, 1, "", "allocator"], [1041, 4, 1, "", "id"], [1041, 3, 1, "", "snapshot"], [1041, 3, 1, "", "use_count"]], "torch.cuda.MemPoolContext": [[1042, 3, 1, "", "active_pool"]], "torch.cuda._sanitizer": [[20, 5, 1, "", "enable_cuda_sanitizer"]], "torch.cuda.amp": [[1, 1, 1, "", "GradScaler"], [1, 1, 1, "", "autocast"], [1, 0, 0, "-", "autocast_mode"], [1, 0, 0, "-", "common"], [1, 5, 1, "", "custom_bwd"], [1, 5, 1, "", "custom_fwd"], [1, 0, 0, "-", "grad_scaler"]], "torch.cuda.comm": [[1051, 5, 1, "", "broadcast"], [1052, 5, 1, "", "broadcast_coalesced"], [1053, 5, 1, "", "gather"], [1054, 5, 1, "", "reduce_add"], [1055, 5, 1, "", "reduce_add_coalesced"], [1056, 5, 1, "", "scatter"]], "torch.cuda.jiterator": [[1086, 5, 1, "", "_create_jit_fn"], [1087, 5, 1, "", "_create_multi_output_jit_fn"]], "torch.cuda.memory": [[2207, 5, 1, "", "_dump_snapshot"], [2207, 5, 1, "", "_record_memory_history"], [2207, 5, 1, "", "_snapshot"], [1096, 5, 1, "", "caching_allocator_enable"]], "torch.cuda.nvtx": [[1104, 5, 1, "", "mark"], [1105, 5, 1, "", "range"], [1106, 5, 1, "", "range_pop"], [1107, 5, 1, "", "range_push"]], "torch.cuda.tunable": [[21, 5, 1, "", "enable"], [21, 5, 1, "", "get_filename"], [21, 5, 1, "", "get_max_tuning_duration"], [21, 5, 1, "", "get_max_tuning_iterations"], [21, 5, 1, "", "get_results"], [21, 5, 1, "", "get_validators"], [21, 5, 1, "", "is_enabled"], [21, 5, 1, "", "mgpu_tune_gemm_in_file"], [21, 5, 1, "", "read_file"], [21, 5, 1, "", "record_untuned_enable"], [21, 5, 1, "", "record_untuned_is_enabled"], [21, 5, 1, "", "set_filename"], [21, 5, 1, "", "set_max_tuning_duration"], [21, 5, 1, "", "set_max_tuning_iterations"], [21, 5, 1, "", "tune_gemm_in_file"], [21, 5, 1, "", "tuning_enable"], [21, 5, 1, "", "tuning_is_enabled"], [21, 5, 1, "", "write_file"], [21, 5, 1, "", "write_file_on_exit"]], "torch.distributed": [[30, 1, 1, "", "Backend"], [30, 1, 1, "", "DistBackendError"], [30, 1, 1, "", "DistError"], [30, 1, 1, "", "DistNetworkError"], [30, 1, 1, "", "DistStoreError"], [30, 1, 1, "", "FileStore"], [26, 1, 1, "", "GradBucket"], [30, 1, 1, "", "HashStore"], [30, 1, 1, "", "P2POp"], [30, 1, 1, "", "PrefixStore"], [30, 1, 1, "", "ReduceOp"], [30, 1, 1, "", "Store"], [30, 1, 1, "", "TCPStore"], [30, 1, 1, "", "Work"], [30, 0, 0, "-", "algorithms"], [30, 5, 1, "", "all_gather"], [30, 5, 1, "", "all_gather_into_tensor"], [30, 5, 1, "", "all_gather_object"], [30, 5, 1, "", "all_reduce"], [30, 5, 1, "", "all_to_all"], [30, 5, 1, "", "all_to_all_single"], [30, 0, 0, "-", "argparse_util"], [2166, 0, 0, "-", "autograd"], [30, 5, 1, "", "barrier"], [30, 5, 1, "", "batch_isend_irecv"], [30, 5, 1, "", "breakpoint"], [30, 5, 1, "", "broadcast"], [30, 5, 1, "", "broadcast_object_list"], [30, 0, 0, "-", "c10d_logger"], [32, 0, 0, "-", "checkpoint"], [30, 0, 0, "-", "collective_utils"], [30, 0, 0, "-", "constants"], [30, 0, 0, "-", "device_mesh"], [30, 0, 0, "-", "distributed_c10d"], [30, 0, 0, "-", "elastic"], [60, 0, 0, "-", "fsdp"], [30, 5, 1, "", "gather"], [30, 5, 1, "", "gather_object"], [30, 5, 1, "", "get_backend"], [30, 5, 1, "", "get_global_rank"], [30, 5, 1, "", "get_group_rank"], [30, 5, 1, "", "get_process_group_ranks"], [30, 5, 1, "", "get_rank"], [30, 5, 1, "", "get_world_size"], [30, 5, 1, "", "init_process_group"], [30, 5, 1, "", "irecv"], [30, 5, 1, "", "is_available"], [30, 5, 1, "", "is_gloo_available"], [30, 5, 1, "", "is_initialized"], [30, 5, 1, "", "is_mpi_available"], [30, 5, 1, "", "is_nccl_available"], [30, 5, 1, "", "is_torchelastic_launched"], [30, 5, 1, "", "isend"], [30, 0, 0, "-", "launch"], [30, 0, 0, "-", "launcher"], [30, 0, 0, "-", "logging_handlers"], [30, 5, 1, "", "monitored_barrier"], [30, 5, 1, "", "new_group"], [30, 0, 0, "-", "nn"], [35, 0, 0, "-", "optim"], [36, 0, 0, "-", "pipelining"], [30, 5, 1, "", "recv"], [30, 5, 1, "", "recv_object_list"], [30, 5, 1, "", "reduce"], [30, 1, 1, "", "reduce_op"], [30, 5, 1, "", "reduce_scatter"], [30, 5, 1, "", "reduce_scatter_tensor"], [30, 0, 0, "-", "remote_device"], [30, 0, 0, "-", "rendezvous"], [2166, 0, 0, "-", "rpc"], [52, 0, 0, "-", "run"], [30, 5, 1, "", "scatter"], [30, 5, 1, "", "scatter_object_list"], [30, 5, 1, "", "send"], [30, 5, 1, "", "send_object_list"], [37, 0, 0, "-", "tensor"], [30, 0, 0, "-", "utils"]], "torch.distributed.Backend": [[30, 3, 1, "", "register_backend"]], "torch.distributed.FileStore": [[30, 3, 1, "", "__init__"], [30, 4, 1, "", "path"]], "torch.distributed.GradBucket": [[26, 5, 1, "", "buffer"], [26, 5, 1, "", "gradients"], [26, 5, 1, "", "index"], [26, 5, 1, "", "is_last"], [26, 5, 1, "", "parameters"], [26, 5, 1, "", "set_buffer"]], "torch.distributed.HashStore": [[30, 3, 1, "", "__init__"]], "torch.distributed.PrefixStore": [[30, 3, 1, "", "__init__"], [30, 4, 1, "", "underlying_store"]], "torch.distributed.Store": [[30, 3, 1, "", "__init__"], [30, 3, 1, "", "add"], [30, 3, 1, "", "append"], [30, 3, 1, "", "check"], [30, 3, 1, "", "compare_set"], [30, 3, 1, "", "delete_key"], [30, 3, 1, "", "get"], [30, 3, 1, "", "has_extended_api"], [30, 3, 1, "", "multi_get"], [30, 3, 1, "", "multi_set"], [30, 3, 1, "", "num_keys"], [30, 3, 1, "", "set"], [30, 3, 1, "", "set_timeout"], [30, 4, 1, "", "timeout"], [30, 3, 1, "", "wait"]], "torch.distributed.TCPStore": [[30, 3, 1, "", "__init__"], [30, 4, 1, "", "host"], [30, 4, 1, "", "libuvBackend"], [30, 4, 1, "", "port"]], "torch.distributed.Work": [[30, 3, 1, "", "boxed"], [30, 3, 1, "", "exception"], [30, 3, 1, "", "get_future"], [30, 3, 1, "", "get_future_result"], [30, 3, 1, "", "is_completed"], [30, 3, 1, "", "is_success"], [30, 3, 1, "", "result"], [30, 3, 1, "", "source_rank"], [30, 3, 1, "", "synchronize"], [30, 3, 1, "", "unbox"], [30, 3, 1, "", "wait"]], "torch.distributed.algorithms": [[31, 1, 1, "", "Join"], [31, 1, 1, "", "JoinHook"], [31, 1, 1, "", "Joinable"], [30, 0, 0, "-", "ddp_comm_hooks"], [30, 0, 0, "-", "join"], [30, 0, 0, "-", "model_averaging"]], "torch.distributed.algorithms.Join": [[31, 3, 1, "", "notify_join_context"]], "torch.distributed.algorithms.JoinHook": [[31, 3, 1, "", "main_hook"], [31, 3, 1, "", "post_hook"]], "torch.distributed.algorithms.Joinable": [[31, 4, 1, "", "join_device"], [31, 3, 1, "", "join_hook"], [31, 4, 1, "", "join_process_group"]], "torch.distributed.algorithms.ddp_comm_hooks": [[30, 0, 0, "-", "ddp_zero_hook"], [30, 0, 0, "-", "debugging_hooks"], [30, 0, 0, "-", "default_hooks"], [30, 0, 0, "-", "mixed_precision_hooks"], [30, 0, 0, "-", "optimizer_overlap_hooks"], [30, 0, 0, "-", "post_localSGD_hook"], [30, 0, 0, "-", "powerSGD_hook"], [30, 0, 0, "-", "quantization_hooks"]], "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks": [[26, 5, 1, "", "noop_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.default_hooks": [[26, 5, 1, "", "allreduce_hook"], [26, 5, 1, "", "bf16_compress_hook"], [26, 5, 1, "", "bf16_compress_wrapper"], [26, 5, 1, "", "fp16_compress_hook"], [26, 5, 1, "", "fp16_compress_wrapper"]], "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook": [[26, 1, 1, "", "PowerSGDState"], [26, 5, 1, "", "batched_powerSGD_hook"], [26, 5, 1, "", "powerSGD_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState": [[26, 3, 1, "", "__getstate__"], [26, 3, 1, "", "__setstate__"]], "torch.distributed.algorithms.model_averaging": [[30, 0, 0, "-", "averagers"], [30, 0, 0, "-", "hierarchical_model_averager"], [30, 0, 0, "-", "utils"]], "torch.distributed.autograd": [[2166, 5, 1, "", "backward"], [2166, 1, 1, "", "context"], [2166, 5, 1, "", "get_gradients"]], "torch.distributed.checkpoint": [[32, 1, 1, "", "DefaultLoadPlanner"], [32, 1, 1, "", "DefaultSavePlanner"], [32, 1, 1, "", "FileSystemReader"], [32, 1, 1, "", "FileSystemWriter"], [32, 1, 1, "", "LoadPlan"], [32, 1, 1, "", "LoadPlanner"], [32, 1, 1, "", "ReadItem"], [32, 1, 1, "", "SavePlan"], [32, 1, 1, "", "SavePlanner"], [32, 1, 1, "", "StorageReader"], [32, 1, 1, "", "StorageWriter"], [30, 0, 0, "-", "api"], [30, 0, 0, "-", "default_planner"], [30, 0, 0, "-", "filesystem"], [32, 0, 0, "-", "format_utils"], [32, 0, 0, "-", "logger"], [32, 0, 0, "-", "logging_handlers"], [30, 0, 0, "-", "metadata"], [30, 0, 0, "-", "optimizer"], [30, 0, 0, "-", "planner"], [30, 0, 0, "-", "planner_helpers"], [30, 0, 0, "-", "resharding"], [32, 0, 0, "-", "staging"], [30, 0, 0, "-", "state_dict"], [30, 0, 0, "-", "state_dict_loader"], [30, 0, 0, "-", "state_dict_saver"], [30, 0, 0, "-", "stateful"], [30, 0, 0, "-", "storage"], [30, 0, 0, "-", "utils"]], "torch.distributed.checkpoint.DefaultLoadPlanner": [[32, 3, 1, "", "lookup_tensor"], [32, 3, 1, "", "transform_tensor"]], "torch.distributed.checkpoint.DefaultSavePlanner": [[32, 3, 1, "", "lookup_object"], [32, 3, 1, "", "transform_object"]], "torch.distributed.checkpoint.FileSystemReader": [[32, 4, 1, "", "checkpoint_id"]], "torch.distributed.checkpoint.FileSystemWriter": [[32, 3, 1, "", "stage"]], "torch.distributed.checkpoint.LoadPlanner": [[32, 3, 1, "", "commit_tensor"], [32, 3, 1, "", "create_global_plan"], [32, 3, 1, "", "create_local_plan"], [32, 3, 1, "", "finish_plan"], [32, 3, 1, "", "load_bytes"], [32, 3, 1, "", "resolve_bytes"], [32, 3, 1, "", "resolve_tensor"], [32, 3, 1, "", "set_up_planner"]], "torch.distributed.checkpoint.SavePlanner": [[32, 3, 1, "", "create_global_plan"], [32, 3, 1, "", "create_local_plan"], [32, 3, 1, "", "finish_plan"], [32, 3, 1, "", "resolve_data"], [32, 3, 1, "", "set_up_planner"]], "torch.distributed.checkpoint.StorageReader": [[32, 3, 1, "", "prepare_global_plan"], [32, 3, 1, "", "prepare_local_plan"], [32, 3, 1, "", "read_data"], [32, 3, 1, "", "read_metadata"], [32, 3, 1, "", "reset"], [32, 3, 1, "", "set_up_storage_reader"], [32, 3, 1, "", "validate_checkpoint_id"]], "torch.distributed.checkpoint.StorageWriter": [[32, 3, 1, "", "finish"], [32, 3, 1, "", "prepare_global_plan"], [32, 3, 1, "", "prepare_local_plan"], [32, 3, 1, "", "reset"], [32, 3, 1, "", "set_up_storage_writer"], [32, 3, 1, "", "storage_meta"], [32, 3, 1, "", "validate_checkpoint_id"], [32, 3, 1, "", "write_data"]], "torch.distributed.checkpoint.format_utils": [[32, 1, 1, "", "BroadcastingTorchSaveReader"], [32, 1, 1, "", "DynamicMetaLoadPlanner"], [32, 5, 1, "", "dcp_to_torch_save"], [32, 5, 1, "", "torch_save_to_dcp"]], "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader": [[32, 3, 1, "", "prepare_global_plan"], [32, 3, 1, "", "prepare_local_plan"], [32, 3, 1, "", "read_data"], [32, 3, 1, "", "read_metadata"], [32, 3, 1, "", "reset"], [32, 3, 1, "", "set_up_storage_reader"], [32, 3, 1, "", "validate_checkpoint_id"]], "torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner": [[32, 3, 1, "", "set_up_planner"]], "torch.distributed.checkpoint.planner": [[32, 1, 1, "", "WriteItem"]], "torch.distributed.checkpoint.planner.WriteItem": [[32, 3, 1, "", "tensor_storage_size"]], "torch.distributed.checkpoint.staging": [[32, 1, 1, "", "AsyncStager"], [32, 1, 1, "", "BlockingAsyncStager"]], "torch.distributed.checkpoint.staging.AsyncStager": [[32, 4, 1, "", "should_synchronize_after_execute"], [32, 3, 1, "", "stage"], [32, 3, 1, "", "synchronize_staging"]], "torch.distributed.checkpoint.staging.BlockingAsyncStager": [[32, 3, 1, "", "stage"], [32, 3, 1, "", "synchronize_staging"]], "torch.distributed.checkpoint.state_dict": [[32, 1, 1, "", "StateDictOptions"], [32, 5, 1, "", "get_model_state_dict"], [32, 5, 1, "", "get_optimizer_state_dict"], [32, 5, 1, "", "get_state_dict"], [32, 5, 1, "", "set_model_state_dict"], [32, 5, 1, "", "set_optimizer_state_dict"], [32, 5, 1, "", "set_state_dict"]], "torch.distributed.checkpoint.state_dict_loader": [[32, 5, 1, "", "load"], [32, 5, 1, "", "load_state_dict"]], "torch.distributed.checkpoint.state_dict_saver": [[32, 5, 1, "", "async_save"], [32, 5, 1, "", "save"], [32, 5, 1, "", "save_state_dict"]], "torch.distributed.checkpoint.stateful": [[32, 1, 1, "", "Stateful"]], "torch.distributed.checkpoint.stateful.Stateful": [[32, 3, 1, "", "load_state_dict"], [32, 3, 1, "", "state_dict"]], "torch.distributed.device_mesh": [[30, 1, 1, "", "DeviceMesh"], [30, 5, 1, "", "init_device_mesh"]], "torch.distributed.device_mesh.DeviceMesh": [[30, 3, 1, "", "from_group"], [30, 3, 1, "", "get_all_groups"], [30, 3, 1, "", "get_coordinate"], [30, 3, 1, "", "get_group"], [30, 3, 1, "", "get_local_rank"], [30, 3, 1, "", "get_rank"]], "torch.distributed.distributed_c10d": [[30, 5, 1, "", "is_xccl_available"]], "torch.distributed.elastic": [[41, 0, 0, "-", "agent"], [42, 0, 0, "-", "control_plane"], [45, 0, 0, "-", "events"], [48, 0, 0, "-", "metrics"], [49, 0, 0, "-", "multiprocessing"], [51, 0, 0, "-", "rendezvous"], [54, 0, 0, "-", "timer"], [30, 0, 0, "-", "utils"]], "torch.distributed.elastic.agent": [[41, 0, 0, "-", "server"]], "torch.distributed.elastic.agent.server": [[41, 1, 1, "", "ElasticAgent"], [41, 1, 1, "", "SimpleElasticAgent"], [41, 1, 1, "", "Worker"], [41, 1, 1, "", "WorkerGroup"], [41, 1, 1, "", "WorkerSpec"], [41, 1, 1, "", "WorkerState"], [30, 0, 0, "-", "api"], [41, 0, 0, "-", "health_check_server"], [30, 0, 0, "-", "local_elastic_agent"]], "torch.distributed.elastic.agent.server.ElasticAgent": [[41, 3, 1, "", "get_worker_group"], [41, 3, 1, "", "run"]], "torch.distributed.elastic.agent.server.SimpleElasticAgent": [[41, 3, 1, "", "_assign_worker_ranks"], [41, 3, 1, "", "_exit_barrier"], [41, 3, 1, "", "_initialize_workers"], [41, 3, 1, "", "_monitor_workers"], [41, 3, 1, "", "_rendezvous"], [41, 3, 1, "", "_restart_workers"], [41, 3, 1, "", "_shutdown"], [41, 3, 1, "", "_start_workers"], [41, 3, 1, "", "_stop_workers"]], "torch.distributed.elastic.agent.server.WorkerSpec": [[41, 3, 1, "", "get_entrypoint_name"]], "torch.distributed.elastic.agent.server.WorkerState": [[41, 3, 1, "", "is_running"]], "torch.distributed.elastic.agent.server.api": [[41, 1, 1, "", "RunResult"]], "torch.distributed.elastic.agent.server.health_check_server": [[41, 1, 1, "", "HealthCheckServer"], [41, 5, 1, "", "create_healthcheck_server"]], "torch.distributed.elastic.agent.server.health_check_server.HealthCheckServer": [[41, 3, 1, "", "start"], [41, 3, 1, "", "stop"]], "torch.distributed.elastic.agent.server.local_elastic_agent": [[41, 1, 1, "", "LocalElasticAgent"]], "torch.distributed.elastic.control_plane": [[42, 5, 1, "", "worker_main"]], "torch.distributed.elastic.events": [[30, 0, 0, "-", "api"], [45, 5, 1, "", "construct_and_record_rdzv_event"], [45, 5, 1, "", "get_logging_handler"], [30, 0, 0, "-", "handlers"], [45, 5, 1, "", "record"]], "torch.distributed.elastic.events.api": [[45, 1, 1, "", "Event"], [45, 2, 1, "", "EventMetadataValue"], [45, 1, 1, "", "EventSource"]], "torch.distributed.elastic.metrics": [[30, 0, 0, "-", "api"], [48, 5, 1, "", "configure"], [48, 5, 1, "", "prof"], [48, 5, 1, "", "put_metric"]], "torch.distributed.elastic.metrics.api": [[48, 1, 1, "", "ConsoleMetricHandler"], [48, 1, 1, "", "MetricHandler"], [48, 1, 1, "", "NullMetricHandler"]], "torch.distributed.elastic.multiprocessing": [[30, 0, 0, "-", "api"], [44, 0, 0, "-", "errors"], [30, 0, 0, "-", "redirects"], [49, 5, 1, "", "start_processes"], [53, 0, 0, "-", "subprocess_handler"], [30, 0, 0, "-", "tail_log"]], "torch.distributed.elastic.multiprocessing.api": [[49, 1, 1, "", "DefaultLogsSpecs"], [49, 1, 1, "", "LogsDest"], [49, 1, 1, "", "LogsSpecs"], [49, 1, 1, "", "MultiprocessContext"], [49, 1, 1, "", "PContext"], [49, 1, 1, "", "RunProcsResult"], [49, 1, 1, "", "SubprocessContext"]], "torch.distributed.elastic.multiprocessing.api.DefaultLogsSpecs": [[49, 3, 1, "", "reify"]], "torch.distributed.elastic.multiprocessing.api.LogsSpecs": [[49, 3, 1, "", "reify"]], "torch.distributed.elastic.multiprocessing.errors": [[44, 1, 1, "", "ChildFailedError"], [44, 1, 1, "", "ErrorHandler"], [44, 1, 1, "", "ProcessFailure"], [30, 0, 0, "-", "error_handler"], [30, 0, 0, "-", "handlers"], [44, 5, 1, "", "record"]], "torch.distributed.elastic.multiprocessing.subprocess_handler": [[53, 0, 0, "-", "handlers"], [53, 0, 0, "-", "subprocess_handler"]], "torch.distributed.elastic.multiprocessing.subprocess_handler.handlers": [[53, 5, 1, "", "get_subprocess_handler"]], "torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler": [[53, 1, 1, "", "SubprocessHandler"]], "torch.distributed.elastic.rendezvous": [[51, 1, 1, "", "RendezvousHandler"], [51, 1, 1, "", "RendezvousHandlerRegistry"], [51, 1, 1, "", "RendezvousInfo"], [51, 1, 1, "", "RendezvousParameters"], [30, 0, 0, "-", "api"], [30, 0, 0, "-", "c10d_rendezvous_backend"], [30, 0, 0, "-", "dynamic_rendezvous"], [30, 0, 0, "-", "etcd_rendezvous"], [30, 0, 0, "-", "etcd_rendezvous_backend"], [30, 0, 0, "-", "etcd_server"], [30, 0, 0, "-", "etcd_store"], [51, 0, 0, "-", "registry"], [30, 0, 0, "-", "static_tcp_rendezvous"], [30, 0, 0, "-", "utils"]], "torch.distributed.elastic.rendezvous.RendezvousHandler": [[51, 3, 1, "", "get_backend"], [51, 3, 1, "", "get_run_id"], [51, 3, 1, "", "is_closed"], [51, 3, 1, "", "next_rendezvous"], [51, 3, 1, "", "num_nodes_waiting"], [51, 3, 1, "", "set_closed"], [51, 3, 1, "", "shutdown"], [51, 4, 1, "", "use_agent_store"]], "torch.distributed.elastic.rendezvous.RendezvousParameters": [[51, 3, 1, "", "get"], [51, 3, 1, "", "get_as_bool"], [51, 3, 1, "", "get_as_int"]], "torch.distributed.elastic.rendezvous.api": [[51, 1, 1, "", "RendezvousClosedError"], [51, 1, 1, "", "RendezvousConnectionError"], [51, 1, 1, "", "RendezvousError"], [51, 1, 1, "", "RendezvousGracefulExitError"], [51, 1, 1, "", "RendezvousStateError"], [51, 1, 1, "", "RendezvousStoreInfo"], [51, 1, 1, "", "RendezvousTimeoutError"]], "torch.distributed.elastic.rendezvous.api.RendezvousStoreInfo": [[51, 3, 1, "", "build"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend": [[51, 1, 1, "", "C10dRendezvousBackend"], [51, 5, 1, "", "create_backend"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend": [[51, 3, 1, "", "get_state"], [51, 4, 1, "", "name"], [51, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous": [[51, 1, 1, "", "DynamicRendezvousHandler"], [51, 1, 1, "", "RendezvousBackend"], [51, 1, 1, "", "RendezvousTimeout"], [51, 5, 1, "", "create_handler"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler": [[51, 3, 1, "", "from_backend"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend": [[51, 3, 1, "", "get_state"], [51, 4, 1, "", "name"], [51, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout": [[51, 4, 1, "", "close"], [51, 4, 1, "", "heartbeat"], [51, 4, 1, "", "join"], [51, 4, 1, "", "last_call"]], "torch.distributed.elastic.rendezvous.etcd_server": [[51, 1, 1, "", "EtcdServer"]], "torch.distributed.elastic.timer": [[54, 1, 1, "", "FileTimerClient"], [54, 1, 1, "", "FileTimerServer"], [54, 1, 1, "", "LocalTimerClient"], [54, 1, 1, "", "LocalTimerServer"], [54, 1, 1, "", "TimerClient"], [54, 1, 1, "", "TimerRequest"], [54, 1, 1, "", "TimerServer"], [30, 0, 0, "-", "api"], [54, 5, 1, "", "configure"], [54, 0, 0, "-", "debug_info_logging"], [54, 5, 1, "", "expires"], [30, 0, 0, "-", "file_based_local_timer"], [30, 0, 0, "-", "local_timer"]], "torch.distributed.elastic.timer.TimerClient": [[54, 3, 1, "", "acquire"], [54, 3, 1, "", "release"]], "torch.distributed.elastic.timer.TimerServer": [[54, 3, 1, "", "clear_timers"], [54, 3, 1, "", "get_expired_timers"], [54, 3, 1, "", "register_timers"]], "torch.distributed.elastic.timer.debug_info_logging": [[54, 5, 1, "", "log_debug_info_for_expired_timers"]], "torch.distributed.elastic.utils": [[30, 0, 0, "-", "api"], [30, 0, 0, "-", "data"], [30, 0, 0, "-", "distributed"], [30, 0, 0, "-", "log_level"], [30, 0, 0, "-", "logging"], [30, 0, 0, "-", "store"]], "torch.distributed.elastic.utils.data": [[30, 0, 0, "-", "cycling_iterator"], [30, 0, 0, "-", "elastic_distributed_sampler"]], "torch.distributed.fsdp": [[60, 1, 1, "", "BackwardPrefetch"], [60, 1, 1, "", "CPUOffload"], [34, 1, 1, "", "CPUOffloadPolicy"], [34, 1, 1, "", "FSDPModule"], [60, 1, 1, "", "FullOptimStateDictConfig"], [60, 1, 1, "", "FullStateDictConfig"], [60, 1, 1, "", "FullyShardedDataParallel"], [60, 1, 1, "", "LocalOptimStateDictConfig"], [60, 1, 1, "", "LocalStateDictConfig"], [60, 1, 1, "", "MixedPrecision"], [34, 1, 1, "", "MixedPrecisionPolicy"], [34, 1, 1, "", "OffloadPolicy"], [60, 1, 1, "", "OptimStateDictConfig"], [60, 1, 1, "", "ShardedOptimStateDictConfig"], [60, 1, 1, "", "ShardedStateDictConfig"], [60, 1, 1, "", "ShardingStrategy"], [60, 1, 1, "", "StateDictConfig"], [60, 1, 1, "", "StateDictSettings"], [34, 1, 1, "", "UnshardHandle"], [30, 0, 0, "-", "api"], [34, 5, 1, "", "fully_shard"], [30, 0, 0, "-", "fully_sharded_data_parallel"], [34, 5, 1, "", "register_fsdp_forward_method"], [30, 0, 0, "-", "sharded_grad_scaler"], [30, 0, 0, "-", "wrap"]], "torch.distributed.fsdp.FSDPModule": [[34, 3, 1, "", "reshard"], [34, 3, 1, "", "set_is_last_backward"], [34, 3, 1, "", "set_modules_to_backward_prefetch"], [34, 3, 1, "", "set_modules_to_forward_prefetch"], [34, 3, 1, "", "set_post_optim_event"], [34, 3, 1, "", "set_reduce_scatter_divide_factor"], [34, 3, 1, "", "set_requires_all_reduce"], [34, 3, 1, "", "set_requires_gradient_sync"], [34, 3, 1, "", "set_reshard_after_backward"], [34, 3, 1, "", "set_unshard_in_backward"], [34, 3, 1, "", "unshard"]], "torch.distributed.fsdp.FullyShardedDataParallel": [[60, 3, 1, "", "apply"], [60, 3, 1, "", "check_is_root"], [60, 3, 1, "", "clip_grad_norm_"], [60, 3, 1, "", "flatten_sharded_optim_state_dict"], [60, 3, 1, "", "forward"], [60, 3, 1, "", "fsdp_modules"], [60, 3, 1, "", "full_optim_state_dict"], [60, 3, 1, "", "get_state_dict_type"], [60, 4, 1, "", "module"], [60, 3, 1, "", "named_buffers"], [60, 3, 1, "", "named_parameters"], [60, 3, 1, "", "no_sync"], [60, 3, 1, "", "optim_state_dict"], [60, 3, 1, "", "optim_state_dict_to_load"], [60, 3, 1, "", "register_comm_hook"], [60, 3, 1, "", "rekey_optim_state_dict"], [60, 3, 1, "", "scatter_full_optim_state_dict"], [60, 3, 1, "", "set_state_dict_type"], [60, 3, 1, "", "shard_full_optim_state_dict"], [60, 3, 1, "", "sharded_optim_state_dict"], [60, 3, 1, "", "state_dict_type"], [60, 3, 1, "", "summon_full_params"]], "torch.distributed.fsdp.UnshardHandle": [[34, 3, 1, "", "wait"]], "torch.distributed.launcher": [[30, 0, 0, "-", "api"]], "torch.distributed.nn": [[30, 0, 0, "-", "api"], [30, 0, 0, "-", "functional"], [30, 0, 0, "-", "jit"]], "torch.distributed.nn.api": [[30, 0, 0, "-", "remote_module"]], "torch.distributed.nn.api.remote_module": [[2166, 1, 1, "", "RemoteModule"]], "torch.distributed.nn.api.remote_module.RemoteModule": [[2166, 3, 1, "", "get_module_rref"], [2166, 3, 1, "", "remote_parameters"]], "torch.distributed.nn.jit": [[30, 0, 0, "-", "instantiator"], [30, 0, 0, "-", "templates"]], "torch.distributed.nn.jit.templates": [[30, 0, 0, "-", "remote_module_template"]], "torch.distributed.optim": [[35, 1, 1, "", "DistributedOptimizer"], [35, 1, 1, "", "PostLocalSGDOptimizer"], [35, 1, 1, "", "ZeroRedundancyOptimizer"], [30, 0, 0, "-", "apply_optimizer_in_backward"], [30, 0, 0, "-", "functional_adadelta"], [30, 0, 0, "-", "functional_adagrad"], [30, 0, 0, "-", "functional_adam"], [30, 0, 0, "-", "functional_adamax"], [30, 0, 0, "-", "functional_adamw"], [30, 0, 0, "-", "functional_rmsprop"], [30, 0, 0, "-", "functional_rprop"], [30, 0, 0, "-", "functional_sgd"], [30, 0, 0, "-", "named_optimizer"], [30, 0, 0, "-", "optimizer"], [30, 0, 0, "-", "post_localSGD_optimizer"], [30, 0, 0, "-", "utils"], [30, 0, 0, "-", "zero_redundancy_optimizer"]], "torch.distributed.optim.DistributedOptimizer": [[35, 3, 1, "", "step"]], "torch.distributed.optim.PostLocalSGDOptimizer": [[35, 3, 1, "", "load_state_dict"], [35, 3, 1, "", "state_dict"], [35, 3, 1, "", "step"]], "torch.distributed.optim.ZeroRedundancyOptimizer": [[35, 3, 1, "", "add_param_group"], [35, 3, 1, "", "consolidate_state_dict"], [35, 4, 1, "", "join_device"], [35, 3, 1, "", "join_hook"], [35, 4, 1, "", "join_process_group"], [35, 3, 1, "", "load_state_dict"], [35, 3, 1, "", "state_dict"], [35, 3, 1, "", "step"]], "torch.distributed.pipelining": [[36, 1, 1, "", "Pipe"], [36, 1, 1, "", "SplitPoint"], [36, 0, 0, "-", "microbatch"], [36, 5, 1, "", "pipe_split"], [36, 5, 1, "", "pipeline"], [36, 0, 0, "-", "schedules"], [36, 0, 0, "-", "stage"]], "torch.distributed.pipelining.microbatch": [[36, 1, 1, "", "TensorChunkSpec"], [36, 5, 1, "", "merge_chunks"], [36, 5, 1, "", "split_args_kwargs_into_chunks"]], "torch.distributed.pipelining.schedules": [[36, 1, 1, "", "PipelineScheduleMulti"], [36, 1, 1, "", "PipelineScheduleSingle"], [36, 1, 1, "", "Schedule1F1B"], [36, 1, 1, "", "ScheduleGPipe"], [36, 1, 1, "", "ScheduleInterleaved1F1B"], [36, 1, 1, "", "ScheduleInterleavedZeroBubble"], [36, 1, 1, "", "ScheduleLoopedBFS"], [36, 1, 1, "", "ScheduleZBVZeroBubble"]], "torch.distributed.pipelining.schedules.PipelineScheduleMulti": [[36, 3, 1, "", "step"]], "torch.distributed.pipelining.schedules.PipelineScheduleSingle": [[36, 3, 1, "", "step"]], "torch.distributed.pipelining.stage": [[36, 1, 1, "", "PipelineStage"], [36, 5, 1, "", "build_stage"]], "torch.distributed.rpc": [[2166, 1, 1, "", "BackendType"], [2166, 1, 1, "", "PyRRef"], [2166, 1, 1, "", "RpcBackendOptions"], [2166, 1, 1, "", "TensorPipeRpcBackendOptions"], [2166, 1, 1, "", "WorkerInfo"], [30, 0, 0, "-", "api"], [30, 0, 0, "-", "backend_registry"], [30, 0, 0, "-", "constants"], [30, 0, 0, "-", "functions"], [2166, 5, 1, "", "get_worker_info"], [2166, 5, 1, "", "init_rpc"], [30, 0, 0, "-", "internal"], [30, 0, 0, "-", "options"], [2166, 5, 1, "", "remote"], [2166, 5, 1, "", "rpc_async"], [2166, 5, 1, "", "rpc_sync"], [30, 0, 0, "-", "rref_proxy"], [30, 0, 0, "-", "server_process_global_profiler"], [2166, 5, 1, "", "shutdown"]], "torch.distributed.rpc.PyRRef": [[2166, 3, 1, "", "backward"], [2166, 3, 1, "", "confirmed_by_owner"], [2166, 3, 1, "", "is_owner"], [2166, 3, 1, "", "local_value"], [2166, 3, 1, "", "owner"], [2166, 3, 1, "", "owner_name"], [2166, 3, 1, "", "remote"], [2166, 3, 1, "", "rpc_async"], [2166, 3, 1, "", "rpc_sync"], [2166, 3, 1, "", "to_here"]], "torch.distributed.rpc.RpcBackendOptions": [[2166, 4, 1, "", "init_method"], [2166, 4, 1, "", "rpc_timeout"]], "torch.distributed.rpc.TensorPipeRpcBackendOptions": [[2166, 4, 1, "", "device_maps"], [2166, 4, 1, "", "devices"], [2166, 4, 1, "", "init_method"], [2166, 4, 1, "", "num_worker_threads"], [2166, 4, 1, "", "rpc_timeout"], [2166, 3, 1, "", "set_device_map"], [2166, 3, 1, "", "set_devices"]], "torch.distributed.rpc.WorkerInfo": [[2166, 4, 1, "", "id"], [2166, 4, 1, "", "name"]], "torch.distributed.rpc.functions": [[2166, 5, 1, "", "async_execution"]], "torch.distributed.tensor": [[37, 1, 1, "", "DTensor"], [37, 0, 0, "-", "debug"], [37, 0, 0, "-", "device_mesh"], [37, 5, 1, "", "distribute_module"], [37, 5, 1, "", "distribute_tensor"], [37, 5, 1, "", "empty"], [37, 0, 0, "-", "experimental"], [37, 5, 1, "", "full"], [37, 5, 1, "", "ones"], [38, 0, 0, "-", "parallel"], [37, 0, 0, "-", "placement_types"], [37, 5, 1, "", "rand"], [37, 5, 1, "", "randn"], [37, 5, 1, "", "zeros"]], "torch.distributed.tensor.DTensor": [[37, 4, 1, "", "device_mesh"], [37, 3, 1, "", "from_local"], [37, 3, 1, "", "full_tensor"], [37, 4, 1, "", "placements"], [37, 3, 1, "", "redistribute"], [37, 3, 1, "", "to_local"]], "torch.distributed.tensor.debug": [[37, 1, 1, "", "CommDebugMode"], [37, 5, 1, "", "visualize_sharding"]], "torch.distributed.tensor.debug.CommDebugMode": [[37, 3, 1, "", "generate_comm_debug_tracing_table"], [37, 3, 1, "", "generate_json_dump"], [37, 3, 1, "", "get_comm_counts"], [37, 3, 1, "", "get_parameter_info"], [37, 3, 1, "", "get_sharding_info"], [37, 3, 1, "", "get_total_counts"], [37, 3, 1, "", "log_comm_debug_tracing_table_to_file"]], "torch.distributed.tensor.experimental": [[37, 5, 1, "", "context_parallel"], [37, 5, 1, "", "local_map"], [37, 5, 1, "", "register_sharding"]], "torch.distributed.tensor.parallel": [[38, 1, 1, "", "ColwiseParallel"], [38, 1, 1, "", "PrepareModuleInput"], [38, 1, 1, "", "PrepareModuleOutput"], [38, 1, 1, "", "RowwiseParallel"], [38, 1, 1, "", "SequenceParallel"], [30, 0, 0, "-", "api"], [30, 0, 0, "-", "ddp"], [30, 0, 0, "-", "fsdp"], [30, 0, 0, "-", "input_reshard"], [30, 0, 0, "-", "loss"], [38, 5, 1, "", "loss_parallel"], [38, 5, 1, "", "parallelize_module"], [30, 0, 0, "-", "style"]], "torch.distributed.tensor.placement_types": [[37, 1, 1, "", "Partial"], [37, 1, 1, "", "Placement"], [37, 1, 1, "", "Replicate"], [37, 1, 1, "", "Shard"]], "torch.distributed.tensor.placement_types.Partial": [[37, 2, 1, "", "reduce_op"]], "torch.distributed.tensor.placement_types.Placement": [[37, 3, 1, "", "is_partial"], [37, 3, 1, "", "is_replicate"], [37, 3, 1, "", "is_shard"]], "torch.distributed.tensor.placement_types.Shard": [[37, 2, 1, "", "dim"]], "torch.distributions": [[39, 0, 0, "-", "bernoulli"], [39, 0, 0, "-", "beta"], [39, 0, 0, "-", "binomial"], [39, 0, 0, "-", "categorical"], [39, 0, 0, "-", "cauchy"], [39, 0, 0, "-", "chi2"], [39, 0, 0, "-", "constraint_registry"], [39, 0, 0, "-", "constraints"], [39, 0, 0, "-", "continuous_bernoulli"], [39, 0, 0, "-", "dirichlet"], [39, 0, 0, "-", "distribution"], [39, 0, 0, "-", "exp_family"], [39, 0, 0, "-", "exponential"], [39, 0, 0, "-", "fishersnedecor"], [39, 0, 0, "-", "gamma"], [39, 0, 0, "-", "geometric"], [39, 0, 0, "-", "gumbel"], [39, 0, 0, "-", "half_cauchy"], [39, 0, 0, "-", "half_normal"], [39, 0, 0, "-", "independent"], [39, 0, 0, "-", "inverse_gamma"], [39, 0, 0, "-", "kl"], [39, 0, 0, "-", "kumaraswamy"], [39, 0, 0, "-", "laplace"], [39, 0, 0, "-", "lkj_cholesky"], [39, 0, 0, "-", "log_normal"], [39, 0, 0, "-", "logistic_normal"], [39, 0, 0, "-", "lowrank_multivariate_normal"], [39, 0, 0, "-", "mixture_same_family"], [39, 0, 0, "-", "multinomial"], [39, 0, 0, "-", "multivariate_normal"], [39, 0, 0, "-", "negative_binomial"], [39, 0, 0, "-", "normal"], [39, 0, 0, "-", "one_hot_categorical"], [39, 0, 0, "-", "pareto"], [39, 0, 0, "-", "poisson"], [39, 0, 0, "-", "relaxed_bernoulli"], [39, 0, 0, "-", "relaxed_categorical"], [39, 0, 0, "-", "studentT"], [39, 0, 0, "-", "transformed_distribution"], [39, 0, 0, "-", "transforms"], [39, 0, 0, "-", "uniform"], [39, 0, 0, "-", "utils"], [39, 0, 0, "-", "von_mises"], [39, 0, 0, "-", "weibull"], [39, 0, 0, "-", "wishart"]], "torch.distributions.bernoulli": [[39, 1, 1, "", "Bernoulli"]], "torch.distributions.bernoulli.Bernoulli": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "enumerate_support"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_enumerate_support"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "param_shape"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "sample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.beta": [[39, 1, 1, "", "Beta"]], "torch.distributions.beta.Beta": [[39, 2, 1, "", "arg_constraints"], [39, 4, 1, "", "concentration0"], [39, 4, 1, "", "concentration1"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.binomial": [[39, 1, 1, "", "Binomial"]], "torch.distributions.binomial.Binomial": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "enumerate_support"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_enumerate_support"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "param_shape"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "sample"], [39, 4, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.categorical": [[39, 1, 1, "", "Categorical"]], "torch.distributions.categorical.Categorical": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "enumerate_support"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_enumerate_support"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "param_shape"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "sample"], [39, 4, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.cauchy": [[39, 1, 1, "", "Cauchy"]], "torch.distributions.cauchy.Cauchy": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.chi2": [[39, 1, 1, "", "Chi2"]], "torch.distributions.chi2.Chi2": [[39, 2, 1, "", "arg_constraints"], [39, 4, 1, "", "df"], [39, 3, 1, "", "expand"]], "torch.distributions.constraint_registry": [[39, 1, 1, "", "ConstraintRegistry"]], "torch.distributions.constraint_registry.ConstraintRegistry": [[39, 3, 1, "", "register"]], "torch.distributions.constraints": [[39, 1, 1, "", "Constraint"], [39, 2, 1, "", "cat"], [39, 2, 1, "", "dependent_property"], [39, 2, 1, "", "greater_than"], [39, 2, 1, "", "greater_than_eq"], [39, 2, 1, "", "half_open_interval"], [39, 2, 1, "", "independent"], [39, 2, 1, "", "integer_interval"], [39, 2, 1, "", "interval"], [39, 5, 1, "", "is_dependent"], [39, 2, 1, "", "less_than"], [39, 2, 1, "", "multinomial"], [39, 2, 1, "", "stack"]], "torch.distributions.constraints.Constraint": [[39, 3, 1, "", "check"]], "torch.distributions.continuous_bernoulli": [[39, 1, 1, "", "ContinuousBernoulli"]], "torch.distributions.continuous_bernoulli.ContinuousBernoulli": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "param_shape"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "rsample"], [39, 3, 1, "", "sample"], [39, 4, 1, "", "stddev"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.dirichlet": [[39, 1, 1, "", "Dirichlet"]], "torch.distributions.dirichlet.Dirichlet": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.distribution": [[39, 1, 1, "", "Distribution"]], "torch.distributions.distribution.Distribution": [[39, 4, 1, "", "arg_constraints"], [39, 4, 1, "", "batch_shape"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "enumerate_support"], [39, 4, 1, "", "event_shape"], [39, 3, 1, "", "expand"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "perplexity"], [39, 3, 1, "", "rsample"], [39, 3, 1, "", "sample"], [39, 3, 1, "", "sample_n"], [39, 3, 1, "", "set_default_validate_args"], [39, 4, 1, "", "stddev"], [39, 4, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.exp_family": [[39, 1, 1, "", "ExponentialFamily"]], "torch.distributions.exp_family.ExponentialFamily": [[39, 3, 1, "", "entropy"]], "torch.distributions.exponential": [[39, 1, 1, "", "Exponential"]], "torch.distributions.exponential.Exponential": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 4, 1, "", "stddev"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.fishersnedecor": [[39, 1, 1, "", "FisherSnedecor"]], "torch.distributions.fishersnedecor.FisherSnedecor": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.gamma": [[39, 1, 1, "", "Gamma"]], "torch.distributions.gamma.Gamma": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.geometric": [[39, 1, 1, "", "Geometric"]], "torch.distributions.geometric.Geometric": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "sample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.gumbel": [[39, 1, 1, "", "Gumbel"]], "torch.distributions.gumbel.Gumbel": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "stddev"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.half_cauchy": [[39, 1, 1, "", "HalfCauchy"]], "torch.distributions.half_cauchy.HalfCauchy": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "scale"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.half_normal": [[39, 1, 1, "", "HalfNormal"]], "torch.distributions.half_normal.HalfNormal": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "scale"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.independent": [[39, 1, 1, "", "Independent"]], "torch.distributions.independent.Independent": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "enumerate_support"], [39, 3, 1, "", "expand"], [39, 4, 1, "", "has_enumerate_support"], [39, 4, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 3, 1, "", "sample"], [39, 4, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.inverse_gamma": [[39, 1, 1, "", "InverseGamma"]], "torch.distributions.inverse_gamma.InverseGamma": [[39, 2, 1, "", "arg_constraints"], [39, 4, 1, "", "concentration"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "rate"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.kl": [[39, 5, 1, "", "kl_divergence"], [39, 5, 1, "", "register_kl"]], "torch.distributions.kumaraswamy": [[39, 1, 1, "", "Kumaraswamy"]], "torch.distributions.kumaraswamy.Kumaraswamy": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.laplace": [[39, 1, 1, "", "Laplace"]], "torch.distributions.laplace.Laplace": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 4, 1, "", "stddev"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.lkj_cholesky": [[39, 1, 1, "", "LKJCholesky"]], "torch.distributions.lkj_cholesky.LKJCholesky": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "expand"], [39, 3, 1, "", "log_prob"], [39, 3, 1, "", "sample"], [39, 2, 1, "", "support"]], "torch.distributions.log_normal": [[39, 1, 1, "", "LogNormal"]], "torch.distributions.log_normal.LogNormal": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 4, 1, "", "loc"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "scale"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.lowrank_multivariate_normal": [[39, 1, 1, "", "LowRankMultivariateNormal"]], "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal": [[39, 2, 1, "", "arg_constraints"], [39, 4, 1, "", "covariance_matrix"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "precision_matrix"], [39, 3, 1, "", "rsample"], [39, 4, 1, "", "scale_tril"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.mixture_same_family": [[39, 1, 1, "", "MixtureSameFamily"]], "torch.distributions.mixture_same_family.MixtureSameFamily": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 4, 1, "", "component_distribution"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mixture_distribution"], [39, 3, 1, "", "sample"], [39, 4, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.multinomial": [[39, 1, 1, "", "Multinomial"]], "torch.distributions.multinomial.Multinomial": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "param_shape"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "sample"], [39, 4, 1, "", "support"], [39, 2, 1, "", "total_count"], [39, 4, 1, "", "variance"]], "torch.distributions.multivariate_normal": [[39, 1, 1, "", "MultivariateNormal"]], "torch.distributions.multivariate_normal.MultivariateNormal": [[39, 2, 1, "", "arg_constraints"], [39, 4, 1, "", "covariance_matrix"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "precision_matrix"], [39, 3, 1, "", "rsample"], [39, 4, 1, "", "scale_tril"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.negative_binomial": [[39, 1, 1, "", "NegativeBinomial"]], "torch.distributions.negative_binomial.NegativeBinomial": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "expand"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "param_shape"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "sample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.normal": [[39, 1, 1, "", "Normal"]], "torch.distributions.normal.Normal": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 3, 1, "", "sample"], [39, 4, 1, "", "stddev"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.one_hot_categorical": [[39, 1, 1, "", "OneHotCategorical"]], "torch.distributions.one_hot_categorical.OneHotCategorical": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "enumerate_support"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_enumerate_support"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "param_shape"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "sample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.pareto": [[39, 1, 1, "", "Pareto"]], "torch.distributions.pareto.Pareto": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.poisson": [[39, 1, 1, "", "Poisson"]], "torch.distributions.poisson.Poisson": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "expand"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "sample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.relaxed_bernoulli": [[39, 1, 1, "", "LogitRelaxedBernoulli"], [39, 1, 1, "", "RelaxedBernoulli"]], "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "expand"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "param_shape"], [39, 4, 1, "", "probs"], [39, 3, 1, "", "rsample"], [39, 2, 1, "", "support"]], "torch.distributions.relaxed_bernoulli.RelaxedBernoulli": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "probs"], [39, 2, 1, "", "support"], [39, 4, 1, "", "temperature"]], "torch.distributions.relaxed_categorical": [[39, 1, 1, "", "RelaxedOneHotCategorical"]], "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 4, 1, "", "logits"], [39, 4, 1, "", "probs"], [39, 2, 1, "", "support"], [39, 4, 1, "", "temperature"]], "torch.distributions.studentT": [[39, 1, 1, "", "StudentT"]], "torch.distributions.studentT.StudentT": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.transformed_distribution": [[39, 1, 1, "", "TransformedDistribution"]], "torch.distributions.transformed_distribution.TransformedDistribution": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "expand"], [39, 4, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 3, 1, "", "rsample"], [39, 3, 1, "", "sample"], [39, 4, 1, "", "support"]], "torch.distributions.transforms": [[39, 1, 1, "", "AbsTransform"], [39, 1, 1, "", "AffineTransform"], [39, 1, 1, "", "CatTransform"], [39, 1, 1, "", "ComposeTransform"], [39, 1, 1, "", "CorrCholeskyTransform"], [39, 1, 1, "", "CumulativeDistributionTransform"], [39, 1, 1, "", "ExpTransform"], [39, 1, 1, "", "IndependentTransform"], [39, 1, 1, "", "LowerCholeskyTransform"], [39, 1, 1, "", "PositiveDefiniteTransform"], [39, 1, 1, "", "PowerTransform"], [39, 1, 1, "", "ReshapeTransform"], [39, 1, 1, "", "SigmoidTransform"], [39, 1, 1, "", "SoftmaxTransform"], [39, 1, 1, "", "SoftplusTransform"], [39, 1, 1, "", "StackTransform"], [39, 1, 1, "", "StickBreakingTransform"], [39, 1, 1, "", "TanhTransform"], [39, 1, 1, "", "Transform"]], "torch.distributions.transforms.Transform": [[39, 3, 1, "", "forward_shape"], [39, 4, 1, "", "inv"], [39, 3, 1, "", "inverse_shape"], [39, 3, 1, "", "log_abs_det_jacobian"], [39, 4, 1, "", "sign"]], "torch.distributions.uniform": [[39, 1, 1, "", "Uniform"]], "torch.distributions.uniform.Uniform": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "cdf"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "icdf"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "rsample"], [39, 4, 1, "", "stddev"], [39, 4, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.von_mises": [[39, 1, 1, "", "VonMises"]], "torch.distributions.von_mises.VonMises": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 3, 1, "", "sample"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.weibull": [[39, 1, 1, "", "Weibull"]], "torch.distributions.weibull.Weibull": [[39, 2, 1, "", "arg_constraints"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.distributions.wishart": [[39, 1, 1, "", "Wishart"]], "torch.distributions.wishart.Wishart": [[39, 2, 1, "", "arg_constraints"], [39, 4, 1, "", "covariance_matrix"], [39, 3, 1, "", "entropy"], [39, 3, 1, "", "expand"], [39, 2, 1, "", "has_rsample"], [39, 3, 1, "", "log_prob"], [39, 4, 1, "", "mean"], [39, 4, 1, "", "mode"], [39, 4, 1, "", "precision_matrix"], [39, 3, 1, "", "rsample"], [39, 4, 1, "", "scale_tril"], [39, 2, 1, "", "support"], [39, 4, 1, "", "variance"]], "torch.export": [[56, 2, 1, "", "Constraint"], [56, 1, 1, "", "ExportBackwardSignature"], [56, 1, 1, "", "ExportGraphSignature"], [56, 1, 1, "", "ExportedProgram"], [56, 1, 1, "", "ModuleCallEntry"], [56, 1, 1, "", "ModuleCallSignature"], [56, 0, 0, "-", "custom_obj"], [56, 0, 0, "-", "custom_ops"], [56, 0, 0, "-", "decomp_utils"], [56, 5, 1, "", "dims"], [56, 0, 0, "-", "dynamic_shapes"], [56, 0, 0, "-", "experimental"], [56, 5, 1, "", "export"], [56, 0, 0, "-", "exported_program"], [56, 0, 0, "-", "graph_signature"], [56, 5, 1, "", "load"], [56, 0, 0, "-", "passes"], [56, 5, 1, "", "register_dataclass"], [56, 5, 1, "", "save"], [56, 0, 0, "-", "unflatten"]], "torch.export.ExportedProgram": [[56, 3, 1, "", "buffers"], [56, 3, 1, "", "module"], [56, 3, 1, "", "named_buffers"], [56, 3, 1, "", "named_parameters"], [56, 3, 1, "", "parameters"], [56, 3, 1, "", "run_decompositions"]], "torch.export.decomp_utils": [[56, 1, 1, "", "CustomDecompTable"]], "torch.export.decomp_utils.CustomDecompTable": [[56, 3, 1, "", "copy"], [56, 3, 1, "", "items"], [56, 3, 1, "", "keys"], [56, 3, 1, "", "materialize"], [56, 3, 1, "", "pop"], [56, 3, 1, "", "update"]], "torch.export.dynamic_shapes": [[56, 1, 1, "", "Dim"], [56, 1, 1, "", "ShapesCollection"], [56, 5, 1, "", "refine_dynamic_shapes_from_suggested_fixes"]], "torch.export.dynamic_shapes.ShapesCollection": [[56, 3, 1, "", "dynamic_shapes"]], "torch.export.exported_program": [[56, 5, 1, "", "default_decompositions"]], "torch.export.graph_signature": [[56, 1, 1, "", "CustomObjArgument"], [56, 1, 1, "", "ExportGraphSignature"], [56, 1, 1, "", "InputKind"], [56, 1, 1, "", "InputSpec"], [56, 1, 1, "", "OutputKind"], [56, 1, 1, "", "OutputSpec"], [56, 1, 1, "", "SymBoolArgument"], [56, 1, 1, "", "SymFloatArgument"], [56, 1, 1, "", "SymIntArgument"]], "torch.export.graph_signature.ExportGraphSignature": [[56, 3, 1, "", "get_replace_hook"], [56, 3, 1, "", "replace_all_uses"]], "torch.export.passes": [[56, 5, 1, "", "move_to_device_pass"]], "torch.export.unflatten": [[56, 1, 1, "", "FlatArgsAdapter"], [56, 1, 1, "", "InterpreterModule"], [56, 1, 1, "", "InterpreterModuleDispatcher"], [56, 5, 1, "", "unflatten"]], "torch.export.unflatten.FlatArgsAdapter": [[56, 3, 1, "", "adapt"]], "torch.fft": [[1160, 5, 1, "", "fft"], [1161, 5, 1, "", "fft2"], [1162, 5, 1, "", "fftfreq"], [1163, 5, 1, "", "fftn"], [1164, 5, 1, "", "fftshift"], [1165, 5, 1, "", "hfft"], [1166, 5, 1, "", "hfft2"], [1167, 5, 1, "", "hfftn"], [1168, 5, 1, "", "ifft"], [1169, 5, 1, "", "ifft2"], [1170, 5, 1, "", "ifftn"], [1171, 5, 1, "", "ifftshift"], [1172, 5, 1, "", "ihfft"], [1173, 5, 1, "", "ihfft2"], [1174, 5, 1, "", "ihfftn"], [1175, 5, 1, "", "irfft"], [1176, 5, 1, "", "irfft2"], [1177, 5, 1, "", "irfftn"], [1178, 5, 1, "", "rfft"], [1179, 5, 1, "", "rfft2"], [1180, 5, 1, "", "rfftfreq"], [1181, 5, 1, "", "rfftn"]], "torch.func": [[1201, 5, 1, "", "functional_call"], [1202, 5, 1, "", "functionalize"], [1203, 5, 1, "", "grad"], [1204, 5, 1, "", "grad_and_value"], [1205, 5, 1, "", "hessian"], [1206, 5, 1, "", "jacfwd"], [1207, 5, 1, "", "jacrev"], [1208, 5, 1, "", "jvp"], [1209, 5, 1, "", "linearize"], [1210, 5, 1, "", "replace_all_batch_norm_modules_"], [1211, 5, 1, "", "stack_module_state"], [1212, 5, 1, "", "vjp"], [1213, 5, 1, "", "vmap"]], "torch.futures": [[68, 1, 1, "", "Future"], [68, 5, 1, "", "collect_all"], [68, 5, 1, "", "wait_all"]], "torch.futures.Future": [[68, 3, 1, "", "add_done_callback"], [68, 3, 1, "", "done"], [68, 3, 1, "", "set_exception"], [68, 3, 1, "", "set_result"], [68, 3, 1, "", "then"], [68, 3, 1, "", "value"], [68, 3, 1, "", "wait"]], "torch.fx": [[69, 1, 1, "", "Graph"], [69, 1, 1, "", "GraphModule"], [69, 1, 1, "", "Interpreter"], [69, 1, 1, "", "Node"], [69, 1, 1, "", "Proxy"], [69, 1, 1, "", "Tracer"], [69, 1, 1, "", "Transformer"], [69, 0, 0, "-", "annotate"], [69, 0, 0, "-", "config"], [69, 0, 0, "-", "experimental"], [69, 0, 0, "-", "graph"], [69, 0, 0, "-", "graph_module"], [69, 0, 0, "-", "immutable_collections"], [69, 0, 0, "-", "interpreter"], [69, 0, 0, "-", "node"], [69, 0, 0, "-", "operator_schemas"], [69, 0, 0, "-", "passes"], [69, 0, 0, "-", "proxy"], [69, 5, 1, "", "replace_pattern"], [69, 0, 0, "-", "subgraph_rewriter"], [69, 5, 1, "", "symbolic_trace"], [69, 0, 0, "-", "tensor_type"], [69, 0, 0, "-", "traceback"], [69, 5, 1, "", "wrap"]], "torch.fx.Graph": [[69, 3, 1, "", "__init__"], [69, 3, 1, "", "call_function"], [69, 3, 1, "", "call_method"], [69, 3, 1, "", "call_module"], [69, 3, 1, "", "create_node"], [69, 3, 1, "", "eliminate_dead_code"], [69, 3, 1, "", "erase_node"], [69, 3, 1, "", "find_nodes"], [69, 3, 1, "", "get_attr"], [69, 3, 1, "", "graph_copy"], [69, 3, 1, "", "inserting_after"], [69, 3, 1, "", "inserting_before"], [69, 3, 1, "", "lint"], [69, 3, 1, "", "node_copy"], [69, 4, 1, "", "nodes"], [69, 3, 1, "", "on_generate_code"], [69, 3, 1, "", "output"], [69, 3, 1, "", "output_node"], [69, 3, 1, "", "placeholder"], [69, 3, 1, "", "print_tabular"], [69, 3, 1, "", "process_inputs"], [69, 3, 1, "", "process_outputs"], [69, 3, 1, "", "python_code"], [69, 3, 1, "", "set_codegen"]], "torch.fx.GraphModule": [[69, 3, 1, "", "__init__"], [69, 3, 1, "", "add_submodule"], [69, 4, 1, "", "code"], [69, 3, 1, "", "delete_all_unused_submodules"], [69, 3, 1, "", "delete_submodule"], [69, 4, 1, "", "graph"], [69, 3, 1, "", "print_readable"], [69, 3, 1, "", "recompile"], [69, 3, 1, "", "to_folder"]], "torch.fx.Interpreter": [[69, 3, 1, "", "boxed_run"], [69, 3, 1, "", "call_function"], [69, 3, 1, "", "call_method"], [69, 3, 1, "", "call_module"], [69, 3, 1, "", "fetch_args_kwargs_from_env"], [69, 3, 1, "", "fetch_attr"], [69, 3, 1, "", "get_attr"], [69, 3, 1, "", "map_nodes_to_values"], [69, 3, 1, "", "output"], [69, 3, 1, "", "placeholder"], [69, 3, 1, "", "run"], [69, 3, 1, "", "run_node"]], "torch.fx.Node": [[69, 4, 1, "", "all_input_nodes"], [69, 3, 1, "", "append"], [69, 4, 1, "", "args"], [69, 3, 1, "", "format_node"], [69, 3, 1, "", "insert_arg"], [69, 3, 1, "", "is_impure"], [69, 4, 1, "", "kwargs"], [69, 4, 1, "", "next"], [69, 3, 1, "", "normalized_arguments"], [69, 3, 1, "", "prepend"], [69, 4, 1, "", "prev"], [69, 3, 1, "", "replace_all_uses_with"], [69, 3, 1, "", "replace_input_with"], [69, 4, 1, "", "stack_trace"], [69, 3, 1, "", "update_arg"], [69, 3, 1, "", "update_kwarg"]], "torch.fx.Tracer": [[69, 3, 1, "", "call_module"], [69, 3, 1, "", "create_arg"], [69, 3, 1, "", "create_args_for_root"], [69, 3, 1, "", "create_node"], [69, 3, 1, "", "create_proxy"], [69, 3, 1, "", "get_fresh_qualname"], [69, 3, 1, "", "getattr"], [69, 3, 1, "", "is_leaf_module"], [69, 3, 1, "", "iter"], [69, 3, 1, "", "keys"], [69, 3, 1, "", "path_of_module"], [69, 3, 1, "", "proxy"], [69, 3, 1, "", "to_bool"], [69, 3, 1, "", "trace"]], "torch.fx.Transformer": [[69, 3, 1, "", "call_function"], [69, 3, 1, "", "call_module"], [69, 3, 1, "", "get_attr"], [69, 3, 1, "", "placeholder"], [69, 3, 1, "", "transform"]], "torch.fx.experimental": [[69, 0, 0, "-", "accelerator_partitioner"], [69, 0, 0, "-", "const_fold"], [69, 0, 0, "-", "debug"], [69, 0, 0, "-", "graph_gradual_typechecker"], [69, 0, 0, "-", "merge_matmul"], [69, 0, 0, "-", "meta_tracer"], [69, 0, 0, "-", "migrate_gradual_types"], [69, 0, 0, "-", "normalize"], [69, 0, 0, "-", "optimization"], [69, 0, 0, "-", "partitioner_utils"], [70, 0, 0, "-", "proxy_tensor"], [69, 0, 0, "-", "recording"], [69, 0, 0, "-", "refinement_types"], [69, 0, 0, "-", "rewriter"], [69, 0, 0, "-", "schema_type_annotation"], [69, 0, 0, "-", "sym_node"], [70, 0, 0, "-", "symbolic_shapes"], [69, 0, 0, "-", "unification"], [69, 0, 0, "-", "unify_refinements"], [69, 0, 0, "-", "validator"]], "torch.fx.experimental.migrate_gradual_types": [[69, 0, 0, "-", "constraint"], [69, 0, 0, "-", "constraint_generator"], [69, 0, 0, "-", "constraint_transformation"], [69, 0, 0, "-", "operation"], [69, 0, 0, "-", "transform_to_z3"], [69, 0, 0, "-", "util"], [69, 0, 0, "-", "z3_types"]], "torch.fx.experimental.proxy_tensor": [[1214, 5, 1, "", "get_proxy_mode"], [1215, 5, 1, "", "handle_sym_dispatch"], [1216, 5, 1, "", "make_fx"], [1217, 5, 1, "", "maybe_disable_thunkify"], [1218, 5, 1, "", "maybe_enable_thunkify"]], "torch.fx.experimental.symbolic_shapes": [[1219, 1, 1, "", "CallMethodKey"], [1220, 1, 1, "", "ConvertIntKey"], [1221, 1, 1, "", "DimConstraints"], [1222, 1, 1, "", "DimDynamic"], [1223, 1, 1, "", "DivideByKey"], [1224, 1, 1, "", "EqualityConstraint"], [1225, 1, 1, "", "InnerTensorKey"], [1226, 1, 1, "", "PropagateUnbackedSymInts"], [1227, 1, 1, "", "RelaxedUnspecConstraint"], [1228, 1, 1, "", "ShapeEnv"], [1229, 1, 1, "", "ShapeEnvSettings"], [1230, 1, 1, "", "StatefulSymbolicContext"], [1231, 1, 1, "", "StatelessSymbolicContext"], [1232, 1, 1, "", "StrictMinMaxConstraint"], [1233, 1, 1, "", "SubclassSymbolicContext"], [1234, 1, 1, "", "SymbolicContext"], [1235, 5, 1, "", "canonicalize_bool_expr"], [1236, 5, 1, "", "check_consistent"], [1237, 5, 1, "", "compute_unbacked_bindings"], [1238, 5, 1, "", "constrain_range"], [1239, 5, 1, "", "constrain_unify"], [1240, 5, 1, "", "definitely_false"], [1241, 5, 1, "", "definitely_true"], [1242, 5, 1, "", "guard_size_oblivious"], [1243, 5, 1, "", "has_free_symbols"], [1244, 5, 1, "", "has_free_unbacked_symbols"], [1245, 5, 1, "", "hint_int"], [1246, 5, 1, "", "is_accessor_node"], [1247, 5, 1, "", "is_concrete_bool"], [1248, 5, 1, "", "is_concrete_float"], [1249, 5, 1, "", "is_concrete_int"], [1250, 5, 1, "", "lru_cache"], [1251, 5, 1, "", "rebind_unbacked"], [1252, 5, 1, "", "resolve_unbacked_bindings"], [1253, 5, 1, "", "statically_known_true"], [1254, 5, 1, "", "sym_eq"]], "torch.fx.experimental.symbolic_shapes.CallMethodKey": [[1219, 3, 1, "", "get"]], "torch.fx.experimental.symbolic_shapes.ConvertIntKey": [[1220, 3, 1, "", "get"]], "torch.fx.experimental.symbolic_shapes.DimConstraints": [[1221, 3, 1, "", "add"], [1221, 3, 1, "", "add_equality"], [1221, 3, 1, "", "forced_specializations"], [1221, 3, 1, "", "prettify_results"], [1221, 3, 1, "", "rewrite_with_congruences"], [1221, 3, 1, "", "solve"]], "torch.fx.experimental.symbolic_shapes.DivideByKey": [[1223, 3, 1, "", "get"]], "torch.fx.experimental.symbolic_shapes.InnerTensorKey": [[1225, 3, 1, "", "get"]], "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts": [[1226, 3, 1, "", "boxed_run"], [1226, 3, 1, "", "call_function"], [1226, 3, 1, "", "call_method"], [1226, 3, 1, "", "call_module"], [1226, 3, 1, "", "fetch_args_kwargs_from_env"], [1226, 3, 1, "", "fetch_attr"], [1226, 3, 1, "", "get_attr"], [1226, 3, 1, "", "map_nodes_to_values"], [1226, 3, 1, "", "output"], [1226, 3, 1, "", "placeholder"], [1226, 3, 1, "", "run"], [1226, 3, 1, "", "run_node"]], "torch.fx.experimental.symbolic_shapes.ShapeEnv": [[1228, 3, 1, "", "add_var_to_val"], [1228, 3, 1, "", "bind_symbols"], [1228, 3, 1, "", "bound_sympy"], [1228, 3, 1, "", "check_equal"], [1228, 3, 1, "", "cleanup"], [1228, 3, 1, "", "create_symbol"], [1228, 3, 1, "", "create_symbolic_sizes_strides_storage_offset"], [1228, 3, 1, "", "create_symboolnode"], [1228, 3, 1, "", "create_symfloatnode"], [1228, 3, 1, "", "create_symintnode"], [1228, 3, 1, "", "create_unbacked_symbool"], [1228, 3, 1, "", "create_unbacked_symfloat"], [1228, 3, 1, "", "create_unbacked_symint"], [1228, 3, 1, "", "create_unspecified_symbol"], [1228, 3, 1, "", "create_unspecified_symint_and_symbol"], [1228, 3, 1, "", "defer_runtime_assert"], [1228, 3, 1, "", "deserialize_symexpr"], [1228, 3, 1, "", "evaluate_guards_expression"], [1228, 3, 1, "", "evaluate_guards_for_args"], [1228, 3, 1, "", "evaluate_symexpr"], [1228, 3, 1, "", "format_guards"], [1228, 3, 1, "", "freeze"], [1228, 3, 1, "", "freeze_runtime_asserts"], [1228, 3, 1, "", "get_axioms"], [1228, 3, 1, "", "get_implications"], [1228, 3, 1, "", "get_nontrivial_guards"], [1228, 3, 1, "", "get_pruned_guards"], [1228, 3, 1, "", "ignore_fresh_unbacked_symbols"], [1228, 3, 1, "", "is_unbacked_symint"], [1228, 3, 1, "", "produce_guards"], [1228, 3, 1, "", "produce_guards_expression"], [1228, 3, 1, "", "produce_guards_verbose"], [1228, 3, 1, "", "replace"], [1228, 3, 1, "", "set_unbacked_var_to_val"], [1228, 3, 1, "", "simplify"], [1228, 3, 1, "", "size_hint"], [1228, 3, 1, "", "suppress_guards"]], "torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint": [[1232, 3, 1, "", "render"]], "torch.fx.experimental.unification": [[69, 0, 0, "-", "core"], [69, 0, 0, "-", "dispatch"], [69, 0, 0, "-", "match"], [69, 0, 0, "-", "more"], [69, 0, 0, "-", "multipledispatch"], [69, 0, 0, "-", "unification_tools"], [69, 0, 0, "-", "utils"], [69, 0, 0, "-", "variable"]], "torch.fx.experimental.unification.multipledispatch": [[69, 0, 0, "-", "conflict"], [69, 0, 0, "-", "core"], [69, 0, 0, "-", "dispatcher"], [69, 0, 0, "-", "utils"], [69, 0, 0, "-", "variadic"]], "torch.fx.passes": [[69, 0, 0, "-", "annotate_getitem_nodes"], [69, 0, 0, "-", "backends"], [69, 0, 0, "-", "dialect"], [69, 0, 0, "-", "fake_tensor_prop"], [69, 0, 0, "-", "graph_drawer"], [69, 0, 0, "-", "graph_manipulation"], [69, 0, 0, "-", "graph_transform_observer"], [69, 0, 0, "-", "infra"], [69, 0, 0, "-", "net_min_base"], [69, 0, 0, "-", "operator_support"], [69, 0, 0, "-", "param_fetch"], [69, 0, 0, "-", "pass_manager"], [69, 0, 0, "-", "reinplace"], [69, 0, 0, "-", "runtime_assert"], [69, 0, 0, "-", "shape_prop"], [69, 0, 0, "-", "split_module"], [69, 0, 0, "-", "split_utils"], [69, 0, 0, "-", "splitter_base"], [69, 0, 0, "-", "tests"], [69, 0, 0, "-", "tools_common"], [69, 0, 0, "-", "utils"]], "torch.fx.passes.backends": [[69, 0, 0, "-", "cudagraphs"]], "torch.fx.passes.dialect": [[69, 0, 0, "-", "common"]], "torch.fx.passes.dialect.common": [[69, 0, 0, "-", "cse_pass"]], "torch.fx.passes.infra": [[69, 0, 0, "-", "partitioner"], [69, 0, 0, "-", "pass_base"], [69, 0, 0, "-", "pass_manager"]], "torch.fx.passes.tests": [[69, 0, 0, "-", "test_pass_manager"]], "torch.fx.passes.utils": [[69, 0, 0, "-", "common"], [69, 0, 0, "-", "fuser_utils"], [69, 0, 0, "-", "matcher_utils"], [69, 0, 0, "-", "matcher_with_name_node_map_utils"], [69, 0, 0, "-", "source_matcher_utils"]], "torch.hub": [[2091, 5, 1, "", "download_url_to_file"], [2091, 5, 1, "", "get_dir"], [2091, 5, 1, "", "help"], [2091, 5, 1, "", "list"], [2091, 5, 1, "", "load"], [2091, 5, 1, "", "load_state_dict_from_url"], [2091, 5, 1, "", "set_dir"]], "torch.jit": [[1312, 1, 1, "", "Attribute"], [1313, 1, 1, "", "ScriptFunction"], [1314, 1, 1, "", "ScriptModule"], [1315, 5, 1, "", "annotate"], [2093, 0, 0, "-", "annotations"], [1316, 5, 1, "", "enable_onednn_fusion"], [2093, 5, 1, "", "export"], [1317, 5, 1, "", "fork"], [1318, 5, 1, "", "freeze"], [2093, 0, 0, "-", "frontend"], [2093, 0, 0, "-", "generate_bytecode"], [1319, 5, 1, "", "ignore"], [1320, 5, 1, "", "interface"], [2095, 5, 1, "", "is_scripting"], [2095, 5, 1, "", "is_tracing"], [1321, 5, 1, "", "isinstance"], [1322, 5, 1, "", "load"], [2093, 0, 0, "-", "mobile"], [1323, 5, 1, "", "onednn_fusion_enabled"], [1324, 5, 1, "", "optimize_for_inference"], [2093, 0, 0, "-", "quantized"], [1325, 5, 1, "", "save"], [1326, 5, 1, "", "script"], [1327, 5, 1, "", "script_if_tracing"], [1328, 5, 1, "", "set_fusion_strategy"], [1329, 1, 1, "", "strict_fusion"], [2094, 0, 0, "-", "supported_ops"], [1330, 5, 1, "", "trace"], [1331, 5, 1, "", "trace_module"], [2098, 0, 0, "-", "unsupported_tensor_ops"], [1332, 5, 1, "", "unused"], [1333, 5, 1, "", "wait"]], "torch.jit.Attribute": [[1312, 3, 1, "", "count"], [1312, 3, 1, "", "index"], [1312, 2, 1, "", "type"], [1312, 2, 1, "", "value"]], "torch.jit.ScriptFunction": [[1313, 3, 1, "", "get_debug_state"], [1313, 3, 1, "", "save"], [1313, 3, 1, "", "save_to_buffer"]], "torch.jit.ScriptModule": [[1314, 3, 1, "", "add_module"], [1314, 3, 1, "", "apply"], [1314, 3, 1, "", "bfloat16"], [1314, 3, 1, "", "buffers"], [1314, 3, 1, "", "children"], [1314, 4, 1, "", "code"], [1314, 4, 1, "", "code_with_constants"], [1314, 3, 1, "", "compile"], [1314, 3, 1, "", "cpu"], [1314, 3, 1, "", "cuda"], [1314, 3, 1, "", "double"], [1314, 3, 1, "", "eval"], [1314, 3, 1, "", "extra_repr"], [1314, 3, 1, "", "float"], [1314, 3, 1, "", "get_buffer"], [1314, 3, 1, "", "get_extra_state"], [1314, 3, 1, "", "get_parameter"], [1314, 3, 1, "", "get_submodule"], [1314, 4, 1, "", "graph"], [1314, 3, 1, "", "half"], [1314, 4, 1, "", "inlined_graph"], [1314, 3, 1, "", "ipu"], [1314, 3, 1, "", "load_state_dict"], [1314, 3, 1, "", "modules"], [1314, 3, 1, "", "mtia"], [1314, 3, 1, "", "named_buffers"], [1314, 3, 1, "", "named_children"], [1314, 3, 1, "", "named_modules"], [1314, 3, 1, "", "named_parameters"], [1314, 3, 1, "", "parameters"], [1314, 3, 1, "", "register_backward_hook"], [1314, 3, 1, "", "register_buffer"], [1314, 3, 1, "", "register_forward_hook"], [1314, 3, 1, "", "register_forward_pre_hook"], [1314, 3, 1, "", "register_full_backward_hook"], [1314, 3, 1, "", "register_full_backward_pre_hook"], [1314, 3, 1, "", "register_load_state_dict_post_hook"], [1314, 3, 1, "", "register_load_state_dict_pre_hook"], [1314, 3, 1, "", "register_module"], [1314, 3, 1, "", "register_parameter"], [1314, 3, 1, "", "register_state_dict_post_hook"], [1314, 3, 1, "", "register_state_dict_pre_hook"], [1314, 3, 1, "", "requires_grad_"], [1314, 3, 1, "", "save"], [1314, 3, 1, "", "set_extra_state"], [1314, 3, 1, "", "set_submodule"], [1314, 3, 1, "", "share_memory"], [1314, 3, 1, "", "state_dict"], [1314, 3, 1, "", "to"], [1314, 3, 1, "", "to_empty"], [1314, 3, 1, "", "train"], [1314, 3, 1, "", "type"], [1314, 3, 1, "", "xpu"], [1314, 3, 1, "", "zero_grad"]], "torch.library": [[2100, 1, 1, "", "Library"], [2100, 5, 1, "", "custom_op"], [2100, 5, 1, "", "define"], [2100, 5, 1, "", "fallthrough_kernel"], [2100, 5, 1, "", "get_ctx"], [2100, 5, 1, "", "impl"], [2100, 5, 1, "", "impl_abstract"], [2100, 5, 1, "", "infer_schema"], [2100, 5, 1, "", "opcheck"], [2100, 5, 1, "", "register_autograd"], [2100, 5, 1, "", "register_fake"], [2100, 5, 1, "", "register_kernel"], [2100, 5, 1, "", "register_torch_dispatch"], [2100, 5, 1, "", "register_vmap"], [2100, 5, 1, "", "triton_op"], [2100, 5, 1, "", "wrap_triton"]], "torch.library.Library": [[2100, 3, 1, "", "define"], [2100, 3, 1, "", "fallback"], [2100, 3, 1, "", "impl"]], "torch.linalg": [[1344, 5, 1, "", "cholesky"], [1345, 5, 1, "", "cholesky_ex"], [1346, 5, 1, "", "cond"], [1347, 5, 1, "", "cross"], [1348, 5, 1, "", "det"], [1349, 5, 1, "", "diagonal"], [1350, 5, 1, "", "eig"], [1351, 5, 1, "", "eigh"], [1352, 5, 1, "", "eigvals"], [1353, 5, 1, "", "eigvalsh"], [1354, 5, 1, "", "householder_product"], [1355, 5, 1, "", "inv"], [1356, 5, 1, "", "inv_ex"], [1357, 5, 1, "", "ldl_factor"], [1358, 5, 1, "", "ldl_factor_ex"], [1359, 5, 1, "", "ldl_solve"], [1360, 5, 1, "", "lstsq"], [1361, 5, 1, "", "lu"], [1362, 5, 1, "", "lu_factor"], [1363, 5, 1, "", "lu_factor_ex"], [1364, 5, 1, "", "lu_solve"], [1365, 5, 1, "", "matmul"], [1366, 5, 1, "", "matrix_exp"], [1367, 5, 1, "", "matrix_norm"], [1368, 5, 1, "", "matrix_power"], [1369, 5, 1, "", "matrix_rank"], [1370, 5, 1, "", "multi_dot"], [1371, 5, 1, "", "norm"], [1372, 5, 1, "", "pinv"], [1373, 5, 1, "", "qr"], [1374, 5, 1, "", "slogdet"], [1375, 5, 1, "", "solve"], [1376, 5, 1, "", "solve_ex"], [1377, 5, 1, "", "solve_triangular"], [1378, 5, 1, "", "svd"], [1379, 5, 1, "", "svdvals"], [1380, 5, 1, "", "tensorinv"], [1381, 5, 1, "", "tensorsolve"], [1382, 5, 1, "", "vander"], [1383, 5, 1, "", "vecdot"], [1384, 5, 1, "", "vector_norm"]], "torch.masked": [[2103, 0, 0, "-", "maskedtensor"]], "torch.masked.maskedtensor": [[2103, 0, 0, "-", "binary"], [2103, 0, 0, "-", "core"], [2103, 0, 0, "-", "creation"], [2103, 0, 0, "-", "passthrough"], [2103, 0, 0, "-", "reductions"], [2103, 0, 0, "-", "unary"]], "torch.monitor": [[2109, 1, 1, "", "Aggregation"], [2109, 1, 1, "", "Event"], [2109, 1, 1, "", "EventHandlerHandle"], [2109, 1, 1, "", "Stat"], [2109, 1, 1, "", "TensorboardEventHandler"], [2109, 1, 1, "", "data_value_t"], [2109, 5, 1, "", "log_event"], [2109, 5, 1, "", "register_event_handler"], [2109, 5, 1, "", "unregister_event_handler"]], "torch.monitor.Aggregation": [[2109, 4, 1, "", "name"]], "torch.monitor.Event": [[2109, 3, 1, "", "__init__"], [2109, 4, 1, "", "data"], [2109, 4, 1, "", "name"], [2109, 4, 1, "", "timestamp"]], "torch.monitor.Stat": [[2109, 3, 1, "", "__init__"], [2109, 3, 1, "", "add"], [2109, 4, 1, "", "count"], [2109, 3, 1, "", "get"], [2109, 4, 1, "", "name"]], "torch.monitor.TensorboardEventHandler": [[2109, 3, 1, "", "__init__"]], "torch.mps": [[1423, 5, 1, "", "current_allocated_memory"], [1424, 5, 1, "", "device_count"], [1425, 5, 1, "", "driver_allocated_memory"], [1426, 5, 1, "", "empty_cache"], [2110, 0, 0, "-", "event"], [1428, 5, 1, "", "get_rng_state"], [1429, 5, 1, "", "manual_seed"], [2110, 0, 0, "-", "profiler"], [1436, 5, 1, "", "recommended_max_memory"], [1437, 5, 1, "", "seed"], [1438, 5, 1, "", "set_per_process_memory_fraction"], [1439, 5, 1, "", "set_rng_state"], [1440, 5, 1, "", "synchronize"]], "torch.mps.event": [[1427, 1, 1, "", "Event"]], "torch.mps.event.Event": [[1427, 3, 1, "", "elapsed_time"], [1427, 3, 1, "", "query"], [1427, 3, 1, "", "record"], [1427, 3, 1, "", "synchronize"], [1427, 3, 1, "", "wait"]], "torch.mps.profiler": [[1433, 5, 1, "", "profile"], [1434, 5, 1, "", "start"], [1435, 5, 1, "", "stop"]], "torch.mtia": [[1442, 6, 1, "", "DeferredMtiaCallError"], [1443, 1, 1, "", "Event"], [1445, 1, 1, "", "StreamContext"], [1446, 5, 1, "", "current_device"], [1447, 5, 1, "", "current_stream"], [1448, 5, 1, "", "default_stream"], [1449, 1, 1, "", "device"], [1450, 5, 1, "", "device_count"], [1451, 5, 1, "", "empty_cache"], [1452, 5, 1, "", "get_device_capability"], [1453, 5, 1, "", "get_rng_state"], [1454, 5, 1, "", "init"], [1455, 5, 1, "", "is_available"], [1456, 5, 1, "", "is_initialized"], [2113, 0, 0, "-", "memory"], [1458, 5, 1, "", "memory_stats"], [1460, 5, 1, "", "set_device"], [1461, 5, 1, "", "set_rng_state"], [1462, 5, 1, "", "set_stream"], [1444, 5, 1, "", "stream"], [1464, 5, 1, "", "synchronize"]], "torch.mtia.Event": [[1443, 3, 1, "", "elapsed_time"], [1443, 3, 1, "", "query"], [1443, 3, 1, "", "record"], [1443, 3, 1, "", "synchronize"], [1443, 3, 1, "", "wait"]], "torch.mtia.memory": [[1457, 5, 1, "", "memory_stats"]], "torch.multiprocessing": [[2114, 1, 1, "", "SpawnContext"], [2114, 5, 1, "", "get_all_sharing_strategies"], [2114, 5, 1, "", "get_sharing_strategy"], [2114, 0, 0, "-", "pool"], [2114, 0, 0, "-", "queue"], [2114, 0, 0, "-", "reductions"], [2114, 5, 1, "", "set_sharing_strategy"], [2114, 0, 0, "-", "spawn"]], "torch.multiprocessing.SpawnContext": [[2114, 3, 1, "", "join"]], "torch.multiprocessing.spawn": [[2114, 5, 1, "", "spawn"]], "torch.nested": [[2117, 5, 1, "", "as_nested_tensor"], [2117, 5, 1, "", "masked_select"], [2117, 5, 1, "", "narrow"], [2117, 5, 1, "", "nested_tensor"], [2117, 5, 1, "", "nested_tensor_from_jagged"], [2117, 5, 1, "", "to_padded_tensor"]], "torch.nn": [[1481, 1, 1, "", "AdaptiveAvgPool1d"], [1482, 1, 1, "", "AdaptiveAvgPool2d"], [1483, 1, 1, "", "AdaptiveAvgPool3d"], [1484, 1, 1, "", "AdaptiveLogSoftmaxWithLoss"], [1485, 1, 1, "", "AdaptiveMaxPool1d"], [1486, 1, 1, "", "AdaptiveMaxPool2d"], [1487, 1, 1, "", "AdaptiveMaxPool3d"], [1488, 1, 1, "", "AlphaDropout"], [1489, 1, 1, "", "AvgPool1d"], [1490, 1, 1, "", "AvgPool2d"], [1491, 1, 1, "", "AvgPool3d"], [1492, 1, 1, "", "BCELoss"], [1493, 1, 1, "", "BCEWithLogitsLoss"], [1494, 1, 1, "", "BatchNorm1d"], [1495, 1, 1, "", "BatchNorm2d"], [1496, 1, 1, "", "BatchNorm3d"], [1497, 1, 1, "", "Bilinear"], [1498, 1, 1, "", "CELU"], [1499, 1, 1, "", "CTCLoss"], [1500, 1, 1, "", "ChannelShuffle"], [1501, 1, 1, "", "CircularPad1d"], [1502, 1, 1, "", "CircularPad2d"], [1503, 1, 1, "", "CircularPad3d"], [1504, 1, 1, "", "ConstantPad1d"], [1505, 1, 1, "", "ConstantPad2d"], [1506, 1, 1, "", "ConstantPad3d"], [1507, 1, 1, "", "Conv1d"], [1508, 1, 1, "", "Conv2d"], [1509, 1, 1, "", "Conv3d"], [1510, 1, 1, "", "ConvTranspose1d"], [1511, 1, 1, "", "ConvTranspose2d"], [1512, 1, 1, "", "ConvTranspose3d"], [1513, 1, 1, "", "CosineEmbeddingLoss"], [1514, 1, 1, "", "CosineSimilarity"], [1515, 1, 1, "", "CrossEntropyLoss"], [1516, 1, 1, "", "DataParallel"], [1517, 1, 1, "", "Dropout"], [1518, 1, 1, "", "Dropout1d"], [1519, 1, 1, "", "Dropout2d"], [1520, 1, 1, "", "Dropout3d"], [1521, 1, 1, "", "ELU"], [1522, 1, 1, "", "Embedding"], [1523, 1, 1, "", "EmbeddingBag"], [1524, 1, 1, "", "FeatureAlphaDropout"], [1525, 1, 1, "", "Flatten"], [1526, 1, 1, "", "Fold"], [1527, 1, 1, "", "FractionalMaxPool2d"], [1528, 1, 1, "", "FractionalMaxPool3d"], [1529, 1, 1, "", "GELU"], [1530, 1, 1, "", "GLU"], [1531, 1, 1, "", "GRU"], [1532, 1, 1, "", "GRUCell"], [1533, 1, 1, "", "GaussianNLLLoss"], [1534, 1, 1, "", "GroupNorm"], [1535, 1, 1, "", "Hardshrink"], [1536, 1, 1, "", "Hardsigmoid"], [1537, 1, 1, "", "Hardswish"], [1538, 1, 1, "", "Hardtanh"], [1539, 1, 1, "", "HingeEmbeddingLoss"], [1540, 1, 1, "", "HuberLoss"], [1541, 1, 1, "", "Identity"], [1542, 1, 1, "", "InstanceNorm1d"], [1543, 1, 1, "", "InstanceNorm2d"], [1544, 1, 1, "", "InstanceNorm3d"], [1545, 1, 1, "", "KLDivLoss"], [1546, 1, 1, "", "L1Loss"], [1547, 1, 1, "", "LPPool1d"], [1548, 1, 1, "", "LPPool2d"], [1549, 1, 1, "", "LPPool3d"], [1550, 1, 1, "", "LSTM"], [1551, 1, 1, "", "LSTMCell"], [1552, 1, 1, "", "LayerNorm"], [1553, 1, 1, "", "LazyBatchNorm1d"], [1554, 1, 1, "", "LazyBatchNorm2d"], [1555, 1, 1, "", "LazyBatchNorm3d"], [1556, 1, 1, "", "LazyConv1d"], [1557, 1, 1, "", "LazyConv2d"], [1558, 1, 1, "", "LazyConv3d"], [1559, 1, 1, "", "LazyConvTranspose1d"], [1560, 1, 1, "", "LazyConvTranspose2d"], [1561, 1, 1, "", "LazyConvTranspose3d"], [1562, 1, 1, "", "LazyInstanceNorm1d"], [1563, 1, 1, "", "LazyInstanceNorm2d"], [1564, 1, 1, "", "LazyInstanceNorm3d"], [1565, 1, 1, "", "LazyLinear"], [1566, 1, 1, "", "LeakyReLU"], [1567, 1, 1, "", "Linear"], [1568, 1, 1, "", "LocalResponseNorm"], [1569, 1, 1, "", "LogSigmoid"], [1570, 1, 1, "", "LogSoftmax"], [1571, 1, 1, "", "MSELoss"], [1572, 1, 1, "", "MarginRankingLoss"], [1573, 1, 1, "", "MaxPool1d"], [1574, 1, 1, "", "MaxPool2d"], [1575, 1, 1, "", "MaxPool3d"], [1576, 1, 1, "", "MaxUnpool1d"], [1577, 1, 1, "", "MaxUnpool2d"], [1578, 1, 1, "", "MaxUnpool3d"], [1579, 1, 1, "", "Mish"], [1580, 1, 1, "", "Module"], [1581, 1, 1, "", "ModuleDict"], [1582, 1, 1, "", "ModuleList"], [1583, 1, 1, "", "MultiLabelMarginLoss"], [1584, 1, 1, "", "MultiLabelSoftMarginLoss"], [1585, 1, 1, "", "MultiMarginLoss"], [1586, 1, 1, "", "MultiheadAttention"], [1587, 1, 1, "", "NLLLoss"], [1588, 1, 1, "", "PReLU"], [1589, 1, 1, "", "PairwiseDistance"], [1590, 1, 1, "", "ParameterDict"], [1591, 1, 1, "", "ParameterList"], [1592, 1, 1, "", "PixelShuffle"], [1593, 1, 1, "", "PixelUnshuffle"], [1594, 1, 1, "", "PoissonNLLLoss"], [1595, 1, 1, "", "RMSNorm"], [1596, 1, 1, "", "RNN"], [1597, 1, 1, "", "RNNBase"], [1598, 1, 1, "", "RNNCell"], [1599, 1, 1, "", "RReLU"], [1600, 1, 1, "", "ReLU"], [1601, 1, 1, "", "ReLU6"], [1602, 1, 1, "", "ReflectionPad1d"], [1603, 1, 1, "", "ReflectionPad2d"], [1604, 1, 1, "", "ReflectionPad3d"], [1605, 1, 1, "", "ReplicationPad1d"], [1606, 1, 1, "", "ReplicationPad2d"], [1607, 1, 1, "", "ReplicationPad3d"], [1608, 1, 1, "", "SELU"], [1609, 1, 1, "", "Sequential"], [1610, 1, 1, "", "SiLU"], [1611, 1, 1, "", "Sigmoid"], [1612, 1, 1, "", "SmoothL1Loss"], [1613, 1, 1, "", "SoftMarginLoss"], [1614, 1, 1, "", "Softmax"], [1615, 1, 1, "", "Softmax2d"], [1616, 1, 1, "", "Softmin"], [1617, 1, 1, "", "Softplus"], [1618, 1, 1, "", "Softshrink"], [1619, 1, 1, "", "Softsign"], [1620, 1, 1, "", "SyncBatchNorm"], [1621, 1, 1, "", "Tanh"], [1622, 1, 1, "", "Tanhshrink"], [1623, 1, 1, "", "Threshold"], [1624, 1, 1, "", "Transformer"], [1625, 1, 1, "", "TransformerDecoder"], [1626, 1, 1, "", "TransformerDecoderLayer"], [1627, 1, 1, "", "TransformerEncoder"], [1628, 1, 1, "", "TransformerEncoderLayer"], [1629, 1, 1, "", "TripletMarginLoss"], [1630, 1, 1, "", "TripletMarginWithDistanceLoss"], [1631, 1, 1, "", "Unflatten"], [1632, 1, 1, "", "Unfold"], [1633, 1, 1, "", "Upsample"], [1634, 1, 1, "", "UpsamplingBilinear2d"], [1635, 1, 1, "", "UpsamplingNearest2d"], [1636, 1, 1, "", "ZeroPad1d"], [1637, 1, 1, "", "ZeroPad2d"], [1638, 1, 1, "", "ZeroPad3d"], [2119, 0, 0, "-", "attention"], [2118, 0, 0, "-", "backends"], [2118, 0, 0, "-", "common_types"], [2118, 0, 0, "-", "cpp"], [2118, 0, 0, "-", "functional"], [2118, 0, 0, "-", "grad"], [2118, 0, 0, "-", "init"], [2164, 0, 0, "-", "intrinsic"], [2118, 0, 0, "-", "modules"], [2118, 0, 0, "-", "parallel"], [2118, 0, 0, "-", "parameter"], [2164, 0, 0, "-", "qat"], [2164, 0, 0, "-", "quantizable"], [2164, 0, 0, "-", "quantized"], [2118, 0, 0, "-", "utils"]], "torch.nn.AdaptiveLogSoftmaxWithLoss": [[1484, 3, 1, "", "log_prob"], [1484, 3, 1, "", "predict"]], "torch.nn.Embedding": [[1522, 3, 1, "", "from_pretrained"]], "torch.nn.EmbeddingBag": [[1523, 3, 1, "", "forward"], [1523, 3, 1, "", "from_pretrained"]], "torch.nn.LazyBatchNorm1d": [[1553, 2, 1, "", "cls_to_become"]], "torch.nn.LazyBatchNorm2d": [[1554, 2, 1, "", "cls_to_become"]], "torch.nn.LazyBatchNorm3d": [[1555, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv1d": [[1556, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv2d": [[1557, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv3d": [[1558, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose1d": [[1559, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose2d": [[1560, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose3d": [[1561, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm1d": [[1562, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm2d": [[1563, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm3d": [[1564, 2, 1, "", "cls_to_become"]], "torch.nn.LazyLinear": [[1565, 2, 1, "", "cls_to_become"]], "torch.nn.Module": [[1580, 3, 1, "", "add_module"], [1580, 3, 1, "", "apply"], [1580, 3, 1, "", "bfloat16"], [1580, 3, 1, "", "buffers"], [1580, 3, 1, "", "children"], [1580, 3, 1, "", "compile"], [1580, 3, 1, "", "cpu"], [1580, 3, 1, "", "cuda"], [1580, 3, 1, "", "double"], [1580, 3, 1, "", "eval"], [1580, 3, 1, "", "extra_repr"], [1580, 3, 1, "", "float"], [1580, 3, 1, "", "forward"], [1580, 3, 1, "", "get_buffer"], [1580, 3, 1, "", "get_extra_state"], [1580, 3, 1, "", "get_parameter"], [1580, 3, 1, "", "get_submodule"], [1580, 3, 1, "", "half"], [1580, 3, 1, "", "ipu"], [1580, 3, 1, "", "load_state_dict"], [1580, 3, 1, "", "modules"], [1580, 3, 1, "", "mtia"], [1580, 3, 1, "", "named_buffers"], [1580, 3, 1, "", "named_children"], [1580, 3, 1, "", "named_modules"], [1580, 3, 1, "", "named_parameters"], [1580, 3, 1, "", "parameters"], [1580, 3, 1, "", "register_backward_hook"], [1580, 3, 1, "", "register_buffer"], [1580, 3, 1, "", "register_forward_hook"], [1580, 3, 1, "", "register_forward_pre_hook"], [1580, 3, 1, "", "register_full_backward_hook"], [1580, 3, 1, "", "register_full_backward_pre_hook"], [1580, 3, 1, "", "register_load_state_dict_post_hook"], [1580, 3, 1, "", "register_load_state_dict_pre_hook"], [1580, 3, 1, "", "register_module"], [1580, 3, 1, "", "register_parameter"], [1580, 3, 1, "", "register_state_dict_post_hook"], [1580, 3, 1, "", "register_state_dict_pre_hook"], [1580, 3, 1, "", "requires_grad_"], [1580, 3, 1, "", "set_extra_state"], [1580, 3, 1, "", "set_submodule"], [1580, 3, 1, "", "share_memory"], [1580, 3, 1, "", "state_dict"], [1580, 3, 1, "", "to"], [1580, 3, 1, "", "to_empty"], [1580, 3, 1, "", "train"], [1580, 3, 1, "", "type"], [1580, 3, 1, "", "xpu"], [1580, 3, 1, "", "zero_grad"]], "torch.nn.ModuleDict": [[1581, 3, 1, "", "clear"], [1581, 3, 1, "", "items"], [1581, 3, 1, "", "keys"], [1581, 3, 1, "", "pop"], [1581, 3, 1, "", "update"], [1581, 3, 1, "", "values"]], "torch.nn.ModuleList": [[1582, 3, 1, "", "append"], [1582, 3, 1, "", "extend"], [1582, 3, 1, "", "insert"]], "torch.nn.MultiheadAttention": [[1586, 3, 1, "", "forward"], [1586, 3, 1, "", "merge_masks"]], "torch.nn.ParameterDict": [[1590, 3, 1, "", "clear"], [1590, 3, 1, "", "copy"], [1590, 3, 1, "", "fromkeys"], [1590, 3, 1, "", "get"], [1590, 3, 1, "", "items"], [1590, 3, 1, "", "keys"], [1590, 3, 1, "", "pop"], [1590, 3, 1, "", "popitem"], [1590, 3, 1, "", "setdefault"], [1590, 3, 1, "", "update"], [1590, 3, 1, "", "values"]], "torch.nn.ParameterList": [[1591, 3, 1, "", "append"], [1591, 3, 1, "", "extend"]], "torch.nn.RMSNorm": [[1595, 3, 1, "", "extra_repr"], [1595, 3, 1, "", "forward"], [1595, 3, 1, "", "reset_parameters"]], "torch.nn.RNNBase": [[1597, 3, 1, "", "flatten_parameters"]], "torch.nn.Sequential": [[1609, 3, 1, "", "append"]], "torch.nn.SyncBatchNorm": [[1620, 3, 1, "", "convert_sync_batchnorm"]], "torch.nn.Transformer": [[1624, 3, 1, "", "forward"], [1624, 3, 1, "", "generate_square_subsequent_mask"]], "torch.nn.TransformerDecoder": [[1625, 3, 1, "", "forward"]], "torch.nn.TransformerDecoderLayer": [[1626, 3, 1, "", "forward"]], "torch.nn.TransformerEncoder": [[1627, 3, 1, "", "forward"]], "torch.nn.TransformerEncoderLayer": [[1628, 3, 1, "", "forward"]], "torch.nn.attention": [[1639, 1, 1, "", "SDPBackend"], [2120, 0, 0, "-", "bias"], [2121, 0, 0, "-", "experimental"], [2122, 0, 0, "-", "flex_attention"], [1644, 5, 1, "", "sdpa_kernel"]], "torch.nn.attention.SDPBackend": [[1639, 4, 1, "", "name"]], "torch.nn.attention.bias": [[1640, 1, 1, "", "CausalBias"], [1641, 1, 1, "", "CausalVariant"], [1642, 5, 1, "", "causal_lower_right"], [1643, 5, 1, "", "causal_upper_left"]], "torch.nn.attention.flex_attention": [[2122, 1, 1, "", "BlockMask"], [2122, 5, 1, "", "and_masks"], [2122, 5, 1, "", "create_block_mask"], [2122, 5, 1, "", "create_mask"], [2122, 5, 1, "", "create_nested_block_mask"], [2122, 5, 1, "", "flex_attention"], [2122, 5, 1, "", "noop_mask"], [2122, 5, 1, "", "or_masks"]], "torch.nn.attention.flex_attention.BlockMask": [[2122, 2, 1, "", "BLOCK_SIZE"], [2122, 3, 1, "", "as_tuple"], [2122, 3, 1, "", "from_kv_blocks"], [2122, 2, 1, "", "full_kv_indices"], [2122, 2, 1, "", "full_kv_num_blocks"], [2122, 2, 1, "", "full_q_indices"], [2122, 2, 1, "", "full_q_num_blocks"], [2122, 2, 1, "", "kv_indices"], [2122, 2, 1, "", "kv_num_blocks"], [2122, 2, 1, "", "mask_mod"], [2122, 3, 1, "", "numel"], [2122, 2, 1, "", "q_indices"], [2122, 2, 1, "", "q_num_blocks"], [2122, 2, 1, "", "seq_lengths"], [2122, 4, 1, "", "shape"], [2122, 3, 1, "", "sparsity"], [2122, 3, 1, "", "to"], [2122, 3, 1, "", "to_dense"], [2122, 3, 1, "", "to_string"]], "torch.nn.backends": [[2118, 0, 0, "-", "thnn"]], "torch.nn.functional": [[1645, 5, 1, "", "adaptive_avg_pool1d"], [1646, 5, 1, "", "adaptive_avg_pool2d"], [1647, 5, 1, "", "adaptive_avg_pool3d"], [1648, 5, 1, "", "adaptive_max_pool1d"], [1649, 5, 1, "", "adaptive_max_pool2d"], [1650, 5, 1, "", "adaptive_max_pool3d"], [1651, 5, 1, "", "affine_grid"], [1652, 5, 1, "", "alpha_dropout"], [1653, 5, 1, "", "avg_pool1d"], [1654, 5, 1, "", "avg_pool2d"], [1655, 5, 1, "", "avg_pool3d"], [1656, 5, 1, "", "batch_norm"], [1657, 5, 1, "", "bilinear"], [1658, 5, 1, "", "binary_cross_entropy"], [1659, 5, 1, "", "binary_cross_entropy_with_logits"], [1660, 5, 1, "", "celu"], [1661, 5, 1, "", "conv1d"], [1662, 5, 1, "", "conv2d"], [1663, 5, 1, "", "conv3d"], [1664, 5, 1, "", "conv_transpose1d"], [1665, 5, 1, "", "conv_transpose2d"], [1666, 5, 1, "", "conv_transpose3d"], [1667, 5, 1, "", "cosine_embedding_loss"], [1668, 5, 1, "", "cosine_similarity"], [1669, 5, 1, "", "cross_entropy"], [1670, 5, 1, "", "ctc_loss"], [1671, 5, 1, "", "dropout"], [1672, 5, 1, "", "dropout1d"], [1673, 5, 1, "", "dropout2d"], [1674, 5, 1, "", "dropout3d"], [1675, 5, 1, "", "elu"], [1676, 5, 1, "", "elu_"], [1677, 5, 1, "", "embedding"], [1678, 5, 1, "", "embedding_bag"], [1679, 5, 1, "", "feature_alpha_dropout"], [1680, 5, 1, "", "fold"], [1681, 5, 1, "", "fractional_max_pool2d"], [1682, 5, 1, "", "fractional_max_pool3d"], [1683, 5, 1, "", "gaussian_nll_loss"], [1684, 5, 1, "", "gelu"], [1685, 5, 1, "", "glu"], [1686, 5, 1, "", "grid_sample"], [1687, 5, 1, "", "group_norm"], [1688, 5, 1, "", "gumbel_softmax"], [1689, 5, 1, "", "hardshrink"], [1690, 5, 1, "", "hardsigmoid"], [1691, 5, 1, "", "hardswish"], [1692, 5, 1, "", "hardtanh"], [1693, 5, 1, "", "hardtanh_"], [1694, 5, 1, "", "hinge_embedding_loss"], [1695, 5, 1, "", "huber_loss"], [1696, 5, 1, "", "instance_norm"], [1697, 5, 1, "", "interpolate"], [1698, 5, 1, "", "kl_div"], [1699, 5, 1, "", "l1_loss"], [1700, 5, 1, "", "layer_norm"], [1701, 5, 1, "", "leaky_relu"], [1702, 5, 1, "", "leaky_relu_"], [1703, 5, 1, "", "linear"], [1704, 5, 1, "", "local_response_norm"], [1705, 5, 1, "", "log_softmax"], [1706, 5, 1, "", "logsigmoid"], [1707, 5, 1, "", "lp_pool1d"], [1708, 5, 1, "", "lp_pool2d"], [1709, 5, 1, "", "lp_pool3d"], [1710, 5, 1, "", "margin_ranking_loss"], [1711, 5, 1, "", "max_pool1d"], [1712, 5, 1, "", "max_pool2d"], [1713, 5, 1, "", "max_pool3d"], [1714, 5, 1, "", "max_unpool1d"], [1715, 5, 1, "", "max_unpool2d"], [1716, 5, 1, "", "max_unpool3d"], [1717, 5, 1, "", "mish"], [1718, 5, 1, "", "mse_loss"], [1719, 5, 1, "", "multi_margin_loss"], [1720, 5, 1, "", "multilabel_margin_loss"], [1721, 5, 1, "", "multilabel_soft_margin_loss"], [1722, 5, 1, "", "nll_loss"], [1723, 5, 1, "", "normalize"], [1724, 5, 1, "", "one_hot"], [1725, 5, 1, "", "pad"], [1726, 5, 1, "", "pairwise_distance"], [1727, 5, 1, "", "pdist"], [1728, 5, 1, "", "pixel_shuffle"], [1729, 5, 1, "", "pixel_unshuffle"], [1730, 5, 1, "", "poisson_nll_loss"], [1731, 5, 1, "", "prelu"], [1732, 5, 1, "", "relu"], [1733, 5, 1, "", "relu6"], [1734, 5, 1, "", "relu_"], [1735, 5, 1, "", "rms_norm"], [1736, 5, 1, "", "rrelu"], [1737, 5, 1, "", "rrelu_"], [1738, 5, 1, "", "scaled_dot_product_attention"], [1739, 5, 1, "", "selu"], [1740, 5, 1, "", "sigmoid"], [1741, 5, 1, "", "silu"], [1742, 5, 1, "", "smooth_l1_loss"], [1743, 5, 1, "", "soft_margin_loss"], [1744, 5, 1, "", "softmax"], [1745, 5, 1, "", "softmin"], [1746, 5, 1, "", "softplus"], [1747, 5, 1, "", "softshrink"], [1748, 5, 1, "", "softsign"], [1749, 5, 1, "", "tanh"], [1750, 5, 1, "", "tanhshrink"], [1751, 5, 1, "", "threshold"], [1752, 5, 1, "", "threshold_"], [1754, 5, 1, "", "triplet_margin_loss"], [1755, 5, 1, "", "triplet_margin_with_distance_loss"], [1756, 5, 1, "", "unfold"], [1757, 5, 1, "", "upsample"], [1758, 5, 1, "", "upsample_bilinear"], [1759, 5, 1, "", "upsample_nearest"]], "torch.nn.init": [[2124, 5, 1, "", "calculate_gain"], [2124, 5, 1, "", "constant_"], [2124, 5, 1, "", "dirac_"], [2124, 5, 1, "", "eye_"], [2124, 5, 1, "", "kaiming_normal_"], [2124, 5, 1, "", "kaiming_uniform_"], [2124, 5, 1, "", "normal_"], [2124, 5, 1, "", "ones_"], [2124, 5, 1, "", "orthogonal_"], [2124, 5, 1, "", "sparse_"], [2124, 5, 1, "", "trunc_normal_"], [2124, 5, 1, "", "uniform_"], [2124, 5, 1, "", "xavier_normal_"], [2124, 5, 1, "", "xavier_uniform_"], [2124, 5, 1, "", "zeros_"]], "torch.nn.intrinsic": [[2164, 0, 0, "-", "modules"], [2164, 0, 0, "-", "qat"], [2164, 0, 0, "-", "quantized"]], "torch.nn.intrinsic.modules": [[2161, 0, 0, "-", "fused"]], "torch.nn.intrinsic.qat": [[2164, 0, 0, "-", "modules"]], "torch.nn.intrinsic.qat.modules": [[2161, 0, 0, "-", "conv_fused"], [2161, 0, 0, "-", "linear_fused"], [2161, 0, 0, "-", "linear_relu"]], "torch.nn.intrinsic.quantized": [[2164, 0, 0, "-", "dynamic"], [2164, 0, 0, "-", "modules"]], "torch.nn.intrinsic.quantized.dynamic": [[2164, 0, 0, "-", "modules"]], "torch.nn.intrinsic.quantized.dynamic.modules": [[2161, 0, 0, "-", "linear_relu"]], "torch.nn.intrinsic.quantized.modules": [[2161, 0, 0, "-", "bn_relu"], [2161, 0, 0, "-", "conv_relu"], [2161, 0, 0, "-", "linear_relu"]], "torch.nn.modules": [[2118, 0, 0, "-", "activation"], [2118, 0, 0, "-", "adaptive"], [2118, 0, 0, "-", "batchnorm"], [2118, 0, 0, "-", "channelshuffle"], [2118, 0, 0, "-", "container"], [2118, 0, 0, "-", "conv"], [2118, 0, 0, "-", "distance"], [2118, 0, 0, "-", "dropout"], [2118, 0, 0, "-", "flatten"], [2118, 0, 0, "-", "fold"], [2118, 0, 0, "-", "instancenorm"], [2118, 0, 0, "-", "lazy"], [2118, 0, 0, "-", "linear"], [2118, 0, 0, "-", "loss"], [2118, 0, 0, "-", "module"], [2118, 0, 0, "-", "normalization"], [2118, 0, 0, "-", "padding"], [2118, 0, 0, "-", "pixelshuffle"], [2118, 0, 0, "-", "pooling"], [2118, 0, 0, "-", "rnn"], [2118, 0, 0, "-", "sparse"], [2118, 0, 0, "-", "transformer"], [2118, 0, 0, "-", "upsampling"], [2118, 0, 0, "-", "utils"]], "torch.nn.modules.lazy": [[1760, 1, 1, "", "LazyModuleMixin"]], "torch.nn.modules.lazy.LazyModuleMixin": [[1760, 3, 1, "", "has_uninitialized_params"], [1760, 3, 1, "", "initialize_parameters"]], "torch.nn.modules.module": [[1761, 5, 1, "", "register_module_backward_hook"], [1762, 5, 1, "", "register_module_buffer_registration_hook"], [1763, 5, 1, "", "register_module_forward_hook"], [1764, 5, 1, "", "register_module_forward_pre_hook"], [1765, 5, 1, "", "register_module_full_backward_hook"], [1766, 5, 1, "", "register_module_full_backward_pre_hook"], [1767, 5, 1, "", "register_module_module_registration_hook"], [1768, 5, 1, "", "register_module_parameter_registration_hook"]], "torch.nn.modules.normalization": [[1769, 1, 1, "", "RMSNorm"]], "torch.nn.modules.normalization.RMSNorm": [[1769, 3, 1, "", "extra_repr"], [1769, 3, 1, "", "forward"], [1769, 3, 1, "", "reset_parameters"]], "torch.nn.parallel": [[1770, 1, 1, "", "DistributedDataParallel"], [2118, 0, 0, "-", "comm"], [1753, 5, 1, "", "data_parallel"], [2118, 0, 0, "-", "distributed"], [2118, 0, 0, "-", "parallel_apply"], [2118, 0, 0, "-", "replicate"], [2118, 0, 0, "-", "scatter_gather"]], "torch.nn.parallel.DistributedDataParallel": [[1770, 3, 1, "", "join"], [1770, 3, 1, "", "join_hook"], [1770, 3, 1, "", "no_sync"], [1770, 3, 1, "", "register_comm_hook"]], "torch.nn.parameter": [[1771, 1, 1, "", "Buffer"], [1772, 1, 1, "", "Parameter"], [1773, 1, 1, "", "UninitializedBuffer"], [1774, 1, 1, "", "UninitializedParameter"]], "torch.nn.parameter.UninitializedParameter": [[1774, 2, 1, "", "cls_to_become"]], "torch.nn.qat": [[2164, 0, 0, "-", "dynamic"], [2164, 0, 0, "-", "modules"]], "torch.nn.qat.dynamic": [[2164, 0, 0, "-", "modules"]], "torch.nn.qat.dynamic.modules": [[2161, 0, 0, "-", "linear"]], "torch.nn.qat.modules": [[2161, 0, 0, "-", "conv"], [2161, 0, 0, "-", "embedding_ops"], [2161, 0, 0, "-", "linear"]], "torch.nn.quantizable": [[2164, 0, 0, "-", "modules"]], "torch.nn.quantizable.modules": [[2161, 0, 0, "-", "activation"], [2161, 0, 0, "-", "rnn"]], "torch.nn.quantized": [[2164, 0, 0, "-", "dynamic"], [2161, 0, 0, "-", "functional"], [2164, 0, 0, "-", "modules"]], "torch.nn.quantized.dynamic": [[2164, 0, 0, "-", "modules"]], "torch.nn.quantized.dynamic.modules": [[2161, 0, 0, "-", "conv"], [2161, 0, 0, "-", "linear"], [2161, 0, 0, "-", "rnn"]], "torch.nn.quantized.modules": [[2161, 0, 0, "-", "activation"], [2161, 0, 0, "-", "batchnorm"], [2161, 0, 0, "-", "conv"], [2161, 0, 0, "-", "dropout"], [2161, 0, 0, "-", "embedding_ops"], [2161, 0, 0, "-", "functional_modules"], [2161, 0, 0, "-", "linear"], [2161, 0, 0, "-", "normalization"], [2161, 0, 0, "-", "rnn"], [2161, 0, 0, "-", "utils"]], "torch.nn.utils": [[2118, 0, 0, "-", "clip_grad"], [1775, 5, 1, "", "clip_grad_norm"], [1776, 5, 1, "", "clip_grad_norm_"], [1777, 5, 1, "", "clip_grad_value_"], [1778, 5, 1, "", "clip_grads_with_norm_"], [1779, 5, 1, "", "convert_conv2d_weight_memory_format"], [1780, 5, 1, "", "convert_conv3d_weight_memory_format"], [2118, 0, 0, "-", "convert_parameters"], [1781, 5, 1, "", "fuse_conv_bn_eval"], [1782, 5, 1, "", "fuse_conv_bn_weights"], [1783, 5, 1, "", "fuse_linear_bn_eval"], [1784, 5, 1, "", "fuse_linear_bn_weights"], [2118, 0, 0, "-", "fusion"], [1785, 5, 1, "", "get_total_norm"], [2118, 0, 0, "-", "init"], [2118, 0, 0, "-", "memory_format"], [1786, 5, 1, "", "parameters_to_vector"], [2118, 0, 0, "-", "parametrizations"], [2118, 0, 0, "-", "parametrize"], [2118, 0, 0, "-", "prune"], [1811, 5, 1, "", "remove_spectral_norm"], [1812, 5, 1, "", "remove_weight_norm"], [2118, 0, 0, "-", "rnn"], [1820, 5, 1, "", "skip_init"], [1821, 5, 1, "", "spectral_norm"], [2118, 0, 0, "-", "stateless"], [1823, 5, 1, "", "vector_to_parameters"], [1824, 5, 1, "", "weight_norm"]], "torch.nn.utils.parametrizations": [[1787, 5, 1, "", "orthogonal"], [1788, 5, 1, "", "spectral_norm"], [1789, 5, 1, "", "weight_norm"]], "torch.nn.utils.parametrize": [[1790, 1, 1, "", "ParametrizationList"], [1791, 5, 1, "", "cached"], [1792, 5, 1, "", "is_parametrized"], [1793, 5, 1, "", "register_parametrization"], [1794, 5, 1, "", "remove_parametrizations"]], "torch.nn.utils.parametrize.ParametrizationList": [[1790, 3, 1, "", "right_inverse"]], "torch.nn.utils.prune": [[1795, 1, 1, "", "BasePruningMethod"], [1796, 1, 1, "", "CustomFromMask"], [1798, 1, 1, "", "L1Unstructured"], [1799, 1, 1, "", "LnStructured"], [1800, 1, 1, "", "PruningContainer"], [1801, 1, 1, "", "RandomStructured"], [1802, 1, 1, "", "RandomUnstructured"], [1803, 5, 1, "", "custom_from_mask"], [1804, 5, 1, "", "global_unstructured"], [1797, 5, 1, "", "identity"], [1805, 5, 1, "", "is_pruned"], [1806, 5, 1, "", "l1_unstructured"], [1807, 5, 1, "", "ln_structured"], [1808, 5, 1, "", "random_structured"], [1809, 5, 1, "", "random_unstructured"], [1810, 5, 1, "", "remove"]], "torch.nn.utils.prune.BasePruningMethod": [[1795, 3, 1, "", "apply"], [1795, 3, 1, "", "apply_mask"], [1795, 3, 1, "", "compute_mask"], [1795, 3, 1, "", "prune"], [1795, 3, 1, "", "remove"]], "torch.nn.utils.prune.CustomFromMask": [[1796, 3, 1, "", "apply"], [1796, 3, 1, "", "apply_mask"], [1796, 3, 1, "", "prune"], [1796, 3, 1, "", "remove"]], "torch.nn.utils.prune.L1Unstructured": [[1798, 3, 1, "", "apply"], [1798, 3, 1, "", "apply_mask"], [1798, 3, 1, "", "prune"], [1798, 3, 1, "", "remove"]], "torch.nn.utils.prune.LnStructured": [[1799, 3, 1, "", "apply"], [1799, 3, 1, "", "apply_mask"], [1799, 3, 1, "", "compute_mask"], [1799, 3, 1, "", "prune"], [1799, 3, 1, "", "remove"]], "torch.nn.utils.prune.PruningContainer": [[1800, 3, 1, "", "add_pruning_method"], [1800, 3, 1, "", "apply"], [1800, 3, 1, "", "apply_mask"], [1800, 3, 1, "", "compute_mask"], [1800, 3, 1, "", "prune"], [1800, 3, 1, "", "remove"]], "torch.nn.utils.prune.RandomStructured": [[1801, 3, 1, "", "apply"], [1801, 3, 1, "", "apply_mask"], [1801, 3, 1, "", "compute_mask"], [1801, 3, 1, "", "prune"], [1801, 3, 1, "", "remove"]], "torch.nn.utils.prune.RandomUnstructured": [[1802, 3, 1, "", "apply"], [1802, 3, 1, "", "apply_mask"], [1802, 3, 1, "", "prune"], [1802, 3, 1, "", "remove"]], "torch.nn.utils.rnn": [[1813, 1, 1, "", "PackedSequence"], [1814, 5, 1, "", "pack_padded_sequence"], [1815, 5, 1, "", "pack_sequence"], [1816, 5, 1, "", "pad_packed_sequence"], [1817, 5, 1, "", "pad_sequence"], [1818, 5, 1, "", "unpack_sequence"], [1819, 5, 1, "", "unpad_sequence"]], "torch.nn.utils.rnn.PackedSequence": [[1813, 2, 1, "", "batch_sizes"], [1813, 3, 1, "", "count"], [1813, 2, 1, "", "data"], [1813, 3, 1, "", "index"], [1813, 4, 1, "", "is_cuda"], [1813, 3, 1, "", "is_pinned"], [1813, 2, 1, "", "sorted_indices"], [1813, 3, 1, "", "to"], [1813, 2, 1, "", "unsorted_indices"]], "torch.nn.utils.stateless": [[1822, 5, 1, "", "functional_call"]], "torch.onnx": [[2150, 1, 1, "", "ExportOptions"], [1833, 1, 1, "", "JitScalarType"], [2150, 1, 1, "", "ONNXProgram"], [2150, 1, 1, "", "OnnxExporterError"], [2150, 5, 1, "", "dynamo_export"], [2150, 5, 1, "", "enable_fake_mode"], [2149, 0, 0, "-", "errors"], [2150, 5, 1, "", "export"], [2150, 5, 1, "", "is_in_onnx_export"], [2152, 5, 1, "", "is_onnxrt_backend_supported"], [2149, 0, 0, "-", "operators"], [2154, 5, 1, "", "register_custom_op_symbolic"], [2154, 5, 1, "", "select_model_mode_for_export"], [2149, 0, 0, "-", "symbolic_caffe2"], [2149, 0, 0, "-", "symbolic_helper"], [2149, 0, 0, "-", "symbolic_opset10"], [2149, 0, 0, "-", "symbolic_opset11"], [2149, 0, 0, "-", "symbolic_opset12"], [2149, 0, 0, "-", "symbolic_opset13"], [2149, 0, 0, "-", "symbolic_opset14"], [2149, 0, 0, "-", "symbolic_opset15"], [2149, 0, 0, "-", "symbolic_opset16"], [2149, 0, 0, "-", "symbolic_opset17"], [2149, 0, 0, "-", "symbolic_opset18"], [2149, 0, 0, "-", "symbolic_opset19"], [2149, 0, 0, "-", "symbolic_opset20"], [2149, 0, 0, "-", "symbolic_opset7"], [2149, 0, 0, "-", "symbolic_opset8"], [2149, 0, 0, "-", "symbolic_opset9"], [2154, 5, 1, "", "unregister_custom_op_symbolic"], [2149, 0, 0, "-", "utils"], [2156, 0, 0, "-", "verification"]], "torch.onnx.JitScalarType": [[1833, 3, 1, "", "dtype"], [1833, 3, 1, "", "from_dtype"], [1833, 3, 1, "", "from_onnx_type"], [1833, 3, 1, "", "from_value"], [1833, 3, 1, "", "onnx_compatible"], [1833, 3, 1, "", "onnx_type"], [1833, 3, 1, "", "scalar_name"], [1833, 3, 1, "", "torch_name"]], "torch.onnx.ONNXProgram": [[2150, 3, 1, "", "apply_weights"], [2150, 3, 1, "", "initialize_inference_session"], [2150, 4, 1, "", "model_proto"], [2150, 3, 1, "", "optimize"], [2150, 3, 1, "", "release"], [2150, 3, 1, "", "save"]], "torch.onnx.verification": [[2156, 1, 1, "", "GraphInfo"], [2156, 1, 1, "", "GraphInfoPrettyPrinter"], [2156, 1, 1, "", "OnnxBackend"], [2156, 1, 1, "", "OnnxTestCaseRepro"], [2156, 1, 1, "", "VerificationOptions"], [2156, 1, 1, "", "check_export_model_diff"], [2156, 5, 1, "", "find_mismatch"], [2156, 5, 1, "", "verify"], [2156, 5, 1, "", "verify_aten_graph"]], "torch.onnx.verification.GraphInfo": [[1834, 3, 1, "", "all_mismatch_leaf_graph_info"], [1834, 3, 1, "", "clear"], [1834, 3, 1, "", "essential_node_count"], [1834, 3, 1, "", "essential_node_kinds"], [1834, 3, 1, "", "export_repro"], [1834, 3, 1, "", "find_mismatch"], [1834, 3, 1, "", "find_partition"], [1834, 3, 1, "", "has_mismatch"], [1834, 3, 1, "", "pretty_print_mismatch"], [1834, 3, 1, "", "pretty_print_tree"], [1834, 3, 1, "", "verify_export"]], "torch.optim": [[1836, 1, 1, "", "ASGD"], [1837, 1, 1, "", "Adadelta"], [1838, 1, 1, "", "Adafactor"], [1839, 1, 1, "", "Adagrad"], [1840, 1, 1, "", "Adam"], [1841, 1, 1, "", "AdamW"], [1842, 1, 1, "", "Adamax"], [1843, 1, 1, "", "LBFGS"], [1844, 1, 1, "", "NAdam"], [2157, 1, 1, "", "Optimizer"], [1856, 1, 1, "", "RAdam"], [1857, 1, 1, "", "RMSprop"], [1858, 1, 1, "", "Rprop"], [1859, 1, 1, "", "SGD"], [1860, 1, 1, "", "SparseAdam"], [2157, 0, 0, "-", "adadelta"], [2157, 0, 0, "-", "adagrad"], [2157, 0, 0, "-", "adam"], [2157, 0, 0, "-", "adamax"], [2157, 0, 0, "-", "adamw"], [2157, 0, 0, "-", "asgd"], [2157, 0, 0, "-", "lbfgs"], [2157, 0, 0, "-", "lr_scheduler"], [2157, 0, 0, "-", "nadam"], [2157, 0, 0, "-", "optimizer"], [2157, 0, 0, "-", "radam"], [2157, 0, 0, "-", "rmsprop"], [2157, 0, 0, "-", "rprop"], [2157, 0, 0, "-", "sgd"], [2157, 0, 0, "-", "sparse_adam"], [2157, 0, 0, "-", "swa_utils"]], "torch.optim.ASGD": [[1836, 3, 1, "", "add_param_group"], [1836, 3, 1, "", "load_state_dict"], [1836, 3, 1, "", "register_load_state_dict_post_hook"], [1836, 3, 1, "", "register_load_state_dict_pre_hook"], [1836, 3, 1, "", "register_state_dict_post_hook"], [1836, 3, 1, "", "register_state_dict_pre_hook"], [1836, 3, 1, "", "register_step_post_hook"], [1836, 3, 1, "", "register_step_pre_hook"], [1836, 3, 1, "", "state_dict"], [1836, 3, 1, "", "step"], [1836, 3, 1, "", "zero_grad"]], "torch.optim.Adadelta": [[1837, 3, 1, "", "add_param_group"], [1837, 3, 1, "", "load_state_dict"], [1837, 3, 1, "", "register_load_state_dict_post_hook"], [1837, 3, 1, "", "register_load_state_dict_pre_hook"], [1837, 3, 1, "", "register_state_dict_post_hook"], [1837, 3, 1, "", "register_state_dict_pre_hook"], [1837, 3, 1, "", "register_step_post_hook"], [1837, 3, 1, "", "register_step_pre_hook"], [1837, 3, 1, "", "state_dict"], [1837, 3, 1, "", "step"], [1837, 3, 1, "", "zero_grad"]], "torch.optim.Adafactor": [[1838, 3, 1, "", "add_param_group"], [1838, 3, 1, "", "load_state_dict"], [1838, 3, 1, "", "register_load_state_dict_post_hook"], [1838, 3, 1, "", "register_load_state_dict_pre_hook"], [1838, 3, 1, "", "register_state_dict_post_hook"], [1838, 3, 1, "", "register_state_dict_pre_hook"], [1838, 3, 1, "", "register_step_post_hook"], [1838, 3, 1, "", "register_step_pre_hook"], [1838, 3, 1, "", "state_dict"], [1838, 3, 1, "", "step"], [1838, 3, 1, "", "zero_grad"]], "torch.optim.Adagrad": [[1839, 3, 1, "", "add_param_group"], [1839, 3, 1, "", "load_state_dict"], [1839, 3, 1, "", "register_load_state_dict_post_hook"], [1839, 3, 1, "", "register_load_state_dict_pre_hook"], [1839, 3, 1, "", "register_state_dict_post_hook"], [1839, 3, 1, "", "register_state_dict_pre_hook"], [1839, 3, 1, "", "register_step_post_hook"], [1839, 3, 1, "", "register_step_pre_hook"], [1839, 3, 1, "", "state_dict"], [1839, 3, 1, "", "step"], [1839, 3, 1, "", "zero_grad"]], "torch.optim.Adam": [[1840, 3, 1, "", "add_param_group"], [1840, 3, 1, "", "load_state_dict"], [1840, 3, 1, "", "register_load_state_dict_post_hook"], [1840, 3, 1, "", "register_load_state_dict_pre_hook"], [1840, 3, 1, "", "register_state_dict_post_hook"], [1840, 3, 1, "", "register_state_dict_pre_hook"], [1840, 3, 1, "", "register_step_post_hook"], [1840, 3, 1, "", "register_step_pre_hook"], [1840, 3, 1, "", "state_dict"], [1840, 3, 1, "", "step"], [1840, 3, 1, "", "zero_grad"]], "torch.optim.AdamW": [[1841, 3, 1, "", "add_param_group"], [1841, 3, 1, "", "load_state_dict"], [1841, 3, 1, "", "register_load_state_dict_post_hook"], [1841, 3, 1, "", "register_load_state_dict_pre_hook"], [1841, 3, 1, "", "register_state_dict_post_hook"], [1841, 3, 1, "", "register_state_dict_pre_hook"], [1841, 3, 1, "", "register_step_post_hook"], [1841, 3, 1, "", "register_step_pre_hook"], [1841, 3, 1, "", "state_dict"], [1841, 3, 1, "", "step"], [1841, 3, 1, "", "zero_grad"]], "torch.optim.Adamax": [[1842, 3, 1, "", "add_param_group"], [1842, 3, 1, "", "load_state_dict"], [1842, 3, 1, "", "register_load_state_dict_post_hook"], [1842, 3, 1, "", "register_load_state_dict_pre_hook"], [1842, 3, 1, "", "register_state_dict_post_hook"], [1842, 3, 1, "", "register_state_dict_pre_hook"], [1842, 3, 1, "", "register_step_post_hook"], [1842, 3, 1, "", "register_step_pre_hook"], [1842, 3, 1, "", "state_dict"], [1842, 3, 1, "", "step"], [1842, 3, 1, "", "zero_grad"]], "torch.optim.LBFGS": [[1843, 3, 1, "", "add_param_group"], [1843, 3, 1, "", "load_state_dict"], [1843, 3, 1, "", "register_load_state_dict_post_hook"], [1843, 3, 1, "", "register_load_state_dict_pre_hook"], [1843, 3, 1, "", "register_state_dict_post_hook"], [1843, 3, 1, "", "register_state_dict_pre_hook"], [1843, 3, 1, "", "register_step_post_hook"], [1843, 3, 1, "", "register_step_pre_hook"], [1843, 3, 1, "", "state_dict"], [1843, 3, 1, "", "step"], [1843, 3, 1, "", "zero_grad"]], "torch.optim.NAdam": [[1844, 3, 1, "", "add_param_group"], [1844, 3, 1, "", "load_state_dict"], [1844, 3, 1, "", "register_load_state_dict_post_hook"], [1844, 3, 1, "", "register_load_state_dict_pre_hook"], [1844, 3, 1, "", "register_state_dict_post_hook"], [1844, 3, 1, "", "register_state_dict_pre_hook"], [1844, 3, 1, "", "register_step_post_hook"], [1844, 3, 1, "", "register_step_pre_hook"], [1844, 3, 1, "", "state_dict"], [1844, 3, 1, "", "step"], [1844, 3, 1, "", "zero_grad"]], "torch.optim.Optimizer": [[1845, 3, 1, "", "add_param_group"], [1846, 3, 1, "", "load_state_dict"], [1847, 3, 1, "", "register_load_state_dict_post_hook"], [1848, 3, 1, "", "register_load_state_dict_pre_hook"], [1849, 3, 1, "", "register_state_dict_post_hook"], [1850, 3, 1, "", "register_state_dict_pre_hook"], [1851, 3, 1, "", "register_step_post_hook"], [1852, 3, 1, "", "register_step_pre_hook"], [1853, 3, 1, "", "state_dict"], [1854, 3, 1, "", "step"], [1855, 3, 1, "", "zero_grad"]], "torch.optim.RAdam": [[1856, 3, 1, "", "add_param_group"], [1856, 3, 1, "", "load_state_dict"], [1856, 3, 1, "", "register_load_state_dict_post_hook"], [1856, 3, 1, "", "register_load_state_dict_pre_hook"], [1856, 3, 1, "", "register_state_dict_post_hook"], [1856, 3, 1, "", "register_state_dict_pre_hook"], [1856, 3, 1, "", "register_step_post_hook"], [1856, 3, 1, "", "register_step_pre_hook"], [1856, 3, 1, "", "state_dict"], [1856, 3, 1, "", "step"], [1856, 3, 1, "", "zero_grad"]], "torch.optim.RMSprop": [[1857, 3, 1, "", "add_param_group"], [1857, 3, 1, "", "load_state_dict"], [1857, 3, 1, "", "register_load_state_dict_post_hook"], [1857, 3, 1, "", "register_load_state_dict_pre_hook"], [1857, 3, 1, "", "register_state_dict_post_hook"], [1857, 3, 1, "", "register_state_dict_pre_hook"], [1857, 3, 1, "", "register_step_post_hook"], [1857, 3, 1, "", "register_step_pre_hook"], [1857, 3, 1, "", "state_dict"], [1857, 3, 1, "", "step"], [1857, 3, 1, "", "zero_grad"]], "torch.optim.Rprop": [[1858, 3, 1, "", "add_param_group"], [1858, 3, 1, "", "load_state_dict"], [1858, 3, 1, "", "register_load_state_dict_post_hook"], [1858, 3, 1, "", "register_load_state_dict_pre_hook"], [1858, 3, 1, "", "register_state_dict_post_hook"], [1858, 3, 1, "", "register_state_dict_pre_hook"], [1858, 3, 1, "", "register_step_post_hook"], [1858, 3, 1, "", "register_step_pre_hook"], [1858, 3, 1, "", "state_dict"], [1858, 3, 1, "", "step"], [1858, 3, 1, "", "zero_grad"]], "torch.optim.SGD": [[1859, 3, 1, "", "add_param_group"], [1859, 3, 1, "", "load_state_dict"], [1859, 3, 1, "", "register_load_state_dict_post_hook"], [1859, 3, 1, "", "register_load_state_dict_pre_hook"], [1859, 3, 1, "", "register_state_dict_post_hook"], [1859, 3, 1, "", "register_state_dict_pre_hook"], [1859, 3, 1, "", "register_step_post_hook"], [1859, 3, 1, "", "register_step_pre_hook"], [1859, 3, 1, "", "state_dict"], [1859, 3, 1, "", "step"], [1859, 3, 1, "", "zero_grad"]], "torch.optim.SparseAdam": [[1860, 3, 1, "", "add_param_group"], [1860, 3, 1, "", "load_state_dict"], [1860, 3, 1, "", "register_load_state_dict_post_hook"], [1860, 3, 1, "", "register_load_state_dict_pre_hook"], [1860, 3, 1, "", "register_state_dict_post_hook"], [1860, 3, 1, "", "register_state_dict_pre_hook"], [1860, 3, 1, "", "register_step_post_hook"], [1860, 3, 1, "", "register_step_pre_hook"], [1860, 3, 1, "", "state_dict"], [1860, 3, 1, "", "step"], [1860, 3, 1, "", "zero_grad"]], "torch.optim.lr_scheduler": [[1861, 1, 1, "", "ChainedScheduler"], [1862, 1, 1, "", "ConstantLR"], [1863, 1, 1, "", "CosineAnnealingLR"], [1864, 1, 1, "", "CosineAnnealingWarmRestarts"], [1865, 1, 1, "", "CyclicLR"], [1866, 1, 1, "", "ExponentialLR"], [1867, 1, 1, "", "LRScheduler"], [1868, 1, 1, "", "LambdaLR"], [1869, 1, 1, "", "LinearLR"], [1870, 1, 1, "", "MultiStepLR"], [1871, 1, 1, "", "MultiplicativeLR"], [1872, 1, 1, "", "OneCycleLR"], [1873, 1, 1, "", "PolynomialLR"], [1874, 1, 1, "", "ReduceLROnPlateau"], [1875, 1, 1, "", "SequentialLR"], [1876, 1, 1, "", "StepLR"]], "torch.optim.lr_scheduler.ChainedScheduler": [[1861, 3, 1, "", "get_last_lr"], [1861, 3, 1, "", "get_lr"], [1861, 3, 1, "", "load_state_dict"], [1861, 3, 1, "", "print_lr"], [1861, 3, 1, "", "state_dict"], [1861, 3, 1, "", "step"]], "torch.optim.lr_scheduler.ConstantLR": [[1862, 3, 1, "", "get_last_lr"], [1862, 3, 1, "", "get_lr"], [1862, 3, 1, "", "load_state_dict"], [1862, 3, 1, "", "print_lr"], [1862, 3, 1, "", "state_dict"], [1862, 3, 1, "", "step"]], "torch.optim.lr_scheduler.CosineAnnealingLR": [[1863, 3, 1, "", "get_last_lr"], [1863, 3, 1, "", "get_lr"], [1863, 3, 1, "", "load_state_dict"], [1863, 3, 1, "", "print_lr"], [1863, 3, 1, "", "state_dict"], [1863, 3, 1, "", "step"]], "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts": [[1864, 3, 1, "", "get_last_lr"], [1864, 3, 1, "", "get_lr"], [1864, 3, 1, "", "load_state_dict"], [1864, 3, 1, "", "print_lr"], [1864, 3, 1, "", "state_dict"], [1864, 3, 1, "", "step"]], "torch.optim.lr_scheduler.CyclicLR": [[1865, 3, 1, "", "get_last_lr"], [1865, 3, 1, "", "get_lr"], [1865, 3, 1, "", "load_state_dict"], [1865, 3, 1, "", "print_lr"], [1865, 3, 1, "", "scale_fn"], [1865, 3, 1, "", "step"]], "torch.optim.lr_scheduler.ExponentialLR": [[1866, 3, 1, "", "get_last_lr"], [1866, 3, 1, "", "get_lr"], [1866, 3, 1, "", "load_state_dict"], [1866, 3, 1, "", "print_lr"], [1866, 3, 1, "", "state_dict"], [1866, 3, 1, "", "step"]], "torch.optim.lr_scheduler.LRScheduler": [[1867, 3, 1, "", "get_last_lr"], [1867, 3, 1, "", "get_lr"], [1867, 3, 1, "", "load_state_dict"], [1867, 3, 1, "", "print_lr"], [1867, 3, 1, "", "state_dict"], [1867, 3, 1, "", "step"]], "torch.optim.lr_scheduler.LambdaLR": [[1868, 3, 1, "", "get_last_lr"], [1868, 3, 1, "", "get_lr"], [1868, 3, 1, "", "load_state_dict"], [1868, 3, 1, "", "print_lr"], [1868, 3, 1, "", "state_dict"], [1868, 3, 1, "", "step"]], "torch.optim.lr_scheduler.LinearLR": [[1869, 3, 1, "", "get_last_lr"], [1869, 3, 1, "", "get_lr"], [1869, 3, 1, "", "load_state_dict"], [1869, 3, 1, "", "print_lr"], [1869, 3, 1, "", "state_dict"], [1869, 3, 1, "", "step"]], "torch.optim.lr_scheduler.MultiStepLR": [[1870, 3, 1, "", "get_last_lr"], [1870, 3, 1, "", "get_lr"], [1870, 3, 1, "", "load_state_dict"], [1870, 3, 1, "", "print_lr"], [1870, 3, 1, "", "state_dict"], [1870, 3, 1, "", "step"]], "torch.optim.lr_scheduler.MultiplicativeLR": [[1871, 3, 1, "", "get_last_lr"], [1871, 3, 1, "", "get_lr"], [1871, 3, 1, "", "load_state_dict"], [1871, 3, 1, "", "print_lr"], [1871, 3, 1, "", "state_dict"], [1871, 3, 1, "", "step"]], "torch.optim.lr_scheduler.OneCycleLR": [[1872, 3, 1, "", "get_last_lr"], [1872, 3, 1, "", "get_lr"], [1872, 3, 1, "", "load_state_dict"], [1872, 3, 1, "", "print_lr"], [1872, 3, 1, "", "state_dict"], [1872, 3, 1, "", "step"]], "torch.optim.lr_scheduler.PolynomialLR": [[1873, 3, 1, "", "get_last_lr"], [1873, 3, 1, "", "get_lr"], [1873, 3, 1, "", "load_state_dict"], [1873, 3, 1, "", "print_lr"], [1873, 3, 1, "", "state_dict"], [1873, 3, 1, "", "step"]], "torch.optim.lr_scheduler.ReduceLROnPlateau": [[1874, 3, 1, "", "get_last_lr"], [1874, 3, 1, "", "get_lr"], [1874, 3, 1, "", "load_state_dict"], [1874, 3, 1, "", "print_lr"], [1874, 3, 1, "", "step"]], "torch.optim.lr_scheduler.SequentialLR": [[1875, 3, 1, "", "get_last_lr"], [1875, 3, 1, "", "get_lr"], [1875, 3, 1, "", "load_state_dict"], [1875, 3, 1, "", "print_lr"], [1875, 3, 1, "", "recursive_undo"], [1875, 3, 1, "", "state_dict"], [1875, 3, 1, "", "step"]], "torch.optim.lr_scheduler.StepLR": [[1876, 3, 1, "", "get_last_lr"], [1876, 3, 1, "", "get_lr"], [1876, 3, 1, "", "load_state_dict"], [1876, 3, 1, "", "print_lr"], [1876, 3, 1, "", "state_dict"], [1876, 3, 1, "", "step"]], "torch.optim.swa_utils": [[1877, 1, 1, "", "AveragedModel"], [1878, 1, 1, "", "SWALR"], [2157, 5, 1, "", "get_ema_multi_avg_fn"], [2157, 5, 1, "", "update_bn"]], "torch.optim.swa_utils.AveragedModel": [[1877, 3, 1, "", "add_module"], [1877, 3, 1, "", "apply"], [1877, 3, 1, "", "bfloat16"], [1877, 3, 1, "", "buffers"], [1877, 3, 1, "", "children"], [1877, 3, 1, "", "compile"], [1877, 3, 1, "", "cpu"], [1877, 3, 1, "", "cuda"], [1877, 3, 1, "", "double"], [1877, 3, 1, "", "eval"], [1877, 3, 1, "", "extra_repr"], [1877, 3, 1, "", "float"], [1877, 3, 1, "", "forward"], [1877, 3, 1, "", "get_buffer"], [1877, 3, 1, "", "get_extra_state"], [1877, 3, 1, "", "get_parameter"], [1877, 3, 1, "", "get_submodule"], [1877, 3, 1, "", "half"], [1877, 3, 1, "", "ipu"], [1877, 3, 1, "", "load_state_dict"], [1877, 3, 1, "", "modules"], [1877, 3, 1, "", "mtia"], [1877, 3, 1, "", "named_buffers"], [1877, 3, 1, "", "named_children"], [1877, 3, 1, "", "named_modules"], [1877, 3, 1, "", "named_parameters"], [1877, 3, 1, "", "parameters"], [1877, 3, 1, "", "register_backward_hook"], [1877, 3, 1, "", "register_buffer"], [1877, 3, 1, "", "register_forward_hook"], [1877, 3, 1, "", "register_forward_pre_hook"], [1877, 3, 1, "", "register_full_backward_hook"], [1877, 3, 1, "", "register_full_backward_pre_hook"], [1877, 3, 1, "", "register_load_state_dict_post_hook"], [1877, 3, 1, "", "register_load_state_dict_pre_hook"], [1877, 3, 1, "", "register_module"], [1877, 3, 1, "", "register_parameter"], [1877, 3, 1, "", "register_state_dict_post_hook"], [1877, 3, 1, "", "register_state_dict_pre_hook"], [1877, 3, 1, "", "requires_grad_"], [1877, 3, 1, "", "set_extra_state"], [1877, 3, 1, "", "set_submodule"], [1877, 3, 1, "", "share_memory"], [1877, 3, 1, "", "state_dict"], [1877, 3, 1, "", "to"], [1877, 3, 1, "", "to_empty"], [1877, 3, 1, "", "train"], [1877, 3, 1, "", "type"], [1877, 3, 1, "", "update_parameters"], [1877, 3, 1, "", "xpu"], [1877, 3, 1, "", "zero_grad"]], "torch.optim.swa_utils.SWALR": [[1878, 3, 1, "", "get_last_lr"], [1878, 3, 1, "", "get_lr"], [1878, 3, 1, "", "load_state_dict"], [1878, 3, 1, "", "print_lr"], [1878, 3, 1, "", "state_dict"], [1878, 3, 1, "", "step"]], "torch.overrides": [[2206, 5, 1, "", "get_ignored_functions"], [2206, 5, 1, "", "get_overridable_functions"], [2206, 5, 1, "", "get_testing_overrides"], [2206, 5, 1, "", "handle_torch_function"], [2206, 5, 1, "", "has_torch_function"], [2206, 5, 1, "", "is_tensor_like"], [2206, 5, 1, "", "is_tensor_method_or_property"], [2206, 5, 1, "", "resolve_name"], [2206, 5, 1, "", "wrap_torch_function"]], "torch.package": [[2158, 1, 1, "", "Directory"], [2158, 1, 1, "", "EmptyMatchError"], [2158, 1, 1, "", "PackageExporter"], [2158, 1, 1, "", "PackageImporter"], [2158, 1, 1, "", "PackagingError"], [2158, 0, 0, "-", "analyze"], [2158, 0, 0, "-", "file_structure_representation"], [2158, 0, 0, "-", "find_file_dependencies"], [2158, 0, 0, "-", "glob_group"], [2158, 0, 0, "-", "importer"], [2158, 0, 0, "-", "package_exporter"], [2158, 0, 0, "-", "package_importer"]], "torch.package.Directory": [[2158, 3, 1, "", "has_file"]], "torch.package.PackageExporter": [[2158, 3, 1, "", "__init__"], [2158, 3, 1, "", "add_dependency"], [2158, 3, 1, "", "all_paths"], [2158, 3, 1, "", "close"], [2158, 3, 1, "", "denied_modules"], [2158, 3, 1, "", "deny"], [2158, 3, 1, "", "dependency_graph_string"], [2158, 3, 1, "", "extern"], [2158, 3, 1, "", "externed_modules"], [2158, 3, 1, "", "get_rdeps"], [2158, 3, 1, "", "get_unique_id"], [2158, 3, 1, "", "intern"], [2158, 3, 1, "", "interned_modules"], [2158, 3, 1, "", "mock"], [2158, 3, 1, "", "mocked_modules"], [2158, 3, 1, "", "register_extern_hook"], [2158, 3, 1, "", "register_intern_hook"], [2158, 3, 1, "", "register_mock_hook"], [2158, 3, 1, "", "save_binary"], [2158, 3, 1, "", "save_module"], [2158, 3, 1, "", "save_pickle"], [2158, 3, 1, "", "save_source_file"], [2158, 3, 1, "", "save_source_string"], [2158, 3, 1, "", "save_text"]], "torch.package.PackageImporter": [[2158, 3, 1, "", "__init__"], [2158, 3, 1, "", "file_structure"], [2158, 3, 1, "", "id"], [2158, 3, 1, "", "import_module"], [2158, 3, 1, "", "load_binary"], [2158, 3, 1, "", "load_pickle"], [2158, 3, 1, "", "load_text"], [2158, 3, 1, "", "python_version"]], "torch.package.analyze": [[2158, 0, 0, "-", "find_first_use_of_broken_modules"], [2158, 0, 0, "-", "is_from_package"], [2158, 0, 0, "-", "trace_dependencies"]], "torch.profiler": [[2159, 1, 1, "", "ProfilerAction"], [2159, 1, 1, "", "ProfilerActivity"], [2159, 1, 1, "", "_KinetoProfile"], [2159, 0, 0, "-", "itt"], [2159, 1, 1, "", "profile"], [2159, 0, 0, "-", "profiler"], [2159, 0, 0, "-", "python_tracer"], [2159, 5, 1, "", "schedule"], [2159, 5, 1, "", "tensorboard_trace_handler"]], "torch.profiler.ProfilerActivity": [[2159, 4, 1, "", "name"]], "torch.profiler._KinetoProfile": [[2159, 3, 1, "", "add_metadata"], [2159, 3, 1, "", "add_metadata_json"], [2159, 3, 1, "", "events"], [2159, 3, 1, "", "export_chrome_trace"], [2159, 3, 1, "", "export_memory_timeline"], [2159, 3, 1, "", "export_stacks"], [2159, 3, 1, "", "key_averages"], [2159, 3, 1, "", "preset_metadata_json"], [2159, 3, 1, "", "toggle_collection_dynamic"]], "torch.profiler.itt": [[2159, 5, 1, "", "is_available"], [2159, 5, 1, "", "mark"], [2159, 5, 1, "", "range_pop"], [2159, 5, 1, "", "range_push"]], "torch.profiler.profile": [[2159, 3, 1, "", "get_trace_id"], [2159, 3, 1, "", "set_custom_trace_id_callback"], [2159, 3, 1, "", "step"]], "torch.quantization": [[2161, 0, 0, "-", "fake_quantize"], [2161, 0, 0, "-", "fuse_modules"], [2161, 0, 0, "-", "fuser_method_mappings"], [2164, 0, 0, "-", "fx"], [2161, 0, 0, "-", "observer"], [2161, 0, 0, "-", "qconfig"], [2161, 0, 0, "-", "quant_type"], [2161, 0, 0, "-", "quantization_mappings"], [2161, 0, 0, "-", "quantize"], [2161, 0, 0, "-", "quantize_fx"], [2161, 0, 0, "-", "quantize_jit"], [2161, 0, 0, "-", "stubs"], [2161, 0, 0, "-", "utils"]], "torch.quantization.fx": [[2161, 0, 0, "-", "convert"], [2161, 0, 0, "-", "fuse"], [2161, 0, 0, "-", "fusion_patterns"], [2161, 0, 0, "-", "graph_module"], [2161, 0, 0, "-", "match_utils"], [2161, 0, 0, "-", "pattern_utils"], [2161, 0, 0, "-", "prepare"], [2161, 0, 0, "-", "quantization_patterns"], [2161, 0, 0, "-", "quantization_types"], [2161, 0, 0, "-", "utils"]], "torch.quasirandom": [[1899, 1, 1, "", "SobolEngine"]], "torch.quasirandom.SobolEngine": [[1899, 3, 1, "", "draw"], [1899, 3, 1, "", "draw_base2"], [1899, 3, 1, "", "fast_forward"], [1899, 3, 1, "", "reset"]], "torch.random": [[2165, 5, 1, "", "fork_rng"], [2165, 5, 1, "", "get_rng_state"], [2165, 5, 1, "", "initial_seed"], [2165, 5, 1, "", "manual_seed"], [2165, 5, 1, "", "seed"], [2165, 5, 1, "", "set_rng_state"]], "torch.serialization": [[2147, 5, 1, "", "add_safe_globals"], [2147, 5, 1, "", "clear_safe_globals"], [2147, 5, 1, "", "get_crc32_options"], [2147, 5, 1, "", "get_default_load_endianness"], [2147, 5, 1, "", "get_default_mmap_options"], [2147, 5, 1, "", "get_safe_globals"], [2147, 5, 1, "", "get_unsafe_globals_in_checkpoint"], [2147, 5, 1, "", "register_package"], [2147, 1, 1, "", "safe_globals"], [2147, 5, 1, "", "set_crc32_options"], [2147, 5, 1, "", "set_default_load_endianness"], [2147, 5, 1, "", "set_default_mmap_options"], [2147, 1, 1, "", "skip_data"]], "torch.signal": [[2169, 0, 0, "-", "windows"]], "torch.signal.windows": [[1946, 5, 1, "", "bartlett"], [1947, 5, 1, "", "blackman"], [1948, 5, 1, "", "cosine"], [1949, 5, 1, "", "exponential"], [1950, 5, 1, "", "gaussian"], [1951, 5, 1, "", "general_cosine"], [1952, 5, 1, "", "general_hamming"], [1953, 5, 1, "", "hamming"], [1954, 5, 1, "", "hann"], [1955, 5, 1, "", "kaiser"], [1956, 5, 1, "", "nuttall"], [2180, 0, 0, "-", "windows"]], "torch.sparse": [[1966, 5, 1, "", "addmm"], [1967, 5, 1, "", "as_sparse_gradcheck"], [1968, 1, 1, "", "check_sparse_tensor_invariants"], [1969, 5, 1, "", "log_softmax"], [1970, 5, 1, "", "mm"], [1971, 5, 1, "", "sampled_addmm"], [2180, 0, 0, "-", "semi_structured"], [1972, 5, 1, "", "softmax"], [1973, 5, 1, "", "spdiags"], [1974, 5, 1, "", "spsolve"], [1975, 5, 1, "", "sum"]], "torch.sparse.check_sparse_tensor_invariants": [[1968, 3, 1, "", "disable"], [1968, 3, 1, "", "enable"], [1968, 3, 1, "", "is_enabled"]], "torch.special": [[2172, 5, 1, "", "airy_ai"], [2172, 5, 1, "", "bessel_j0"], [2172, 5, 1, "", "bessel_j1"], [2172, 5, 1, "", "digamma"], [2172, 5, 1, "", "entr"], [2172, 5, 1, "", "erf"], [2172, 5, 1, "", "erfc"], [2172, 5, 1, "", "erfcx"], [2172, 5, 1, "", "erfinv"], [2172, 5, 1, "", "exp2"], [2172, 5, 1, "", "expit"], [2172, 5, 1, "", "expm1"], [2172, 5, 1, "", "gammainc"], [2172, 5, 1, "", "gammaincc"], [2172, 5, 1, "", "gammaln"], [2172, 5, 1, "", "i0"], [2172, 5, 1, "", "i0e"], [2172, 5, 1, "", "i1"], [2172, 5, 1, "", "i1e"], [2172, 5, 1, "", "log1p"], [2172, 5, 1, "", "log_ndtr"], [2172, 5, 1, "", "log_softmax"], [2172, 5, 1, "", "logit"], [2172, 5, 1, "", "logsumexp"], [2172, 5, 1, "", "multigammaln"], [2172, 5, 1, "", "ndtr"], [2172, 5, 1, "", "ndtri"], [2172, 5, 1, "", "polygamma"], [2172, 5, 1, "", "psi"], [2172, 5, 1, "", "round"], [2172, 5, 1, "", "scaled_modified_bessel_k0"], [2172, 5, 1, "", "scaled_modified_bessel_k1"], [2172, 5, 1, "", "sinc"], [2172, 5, 1, "", "softmax"], [2172, 5, 1, "", "spherical_bessel_j0"], [2172, 5, 1, "", "xlog1py"], [2172, 5, 1, "", "xlogy"], [2172, 5, 1, "", "zeta"]], "torch.testing": [[2178, 5, 1, "", "assert_allclose"], [2178, 5, 1, "", "assert_close"], [2178, 5, 1, "", "make_tensor"]], "torch.torch": [[2180, 2, 1, "", "default_generator"], [2210, 1, 1, "", "finfo"], [2210, 1, 1, "", "iinfo"]], "torch.utils": [[2180, 0, 0, "-", "backcompat"], [2211, 0, 0, "-", "backend_registration"], [4, 0, 0, "-", "benchmark"], [5, 0, 0, "-", "bottleneck"], [2211, 0, 0, "-", "bundled_inputs"], [2211, 0, 0, "-", "checkpoint"], [2211, 0, 0, "-", "collect_env"], [2211, 0, 0, "-", "cpp_backtrace"], [2211, 0, 0, "-", "cpp_extension"], [25, 0, 0, "-", "data"], [29, 0, 0, "-", "deterministic"], [2211, 0, 0, "-", "dlpack"], [2211, 0, 0, "-", "file_baton"], [2211, 0, 0, "-", "flop_counter"], [2034, 5, 1, "", "generate_methods_for_privateuse1_backend"], [2035, 5, 1, "", "get_cpp_backtrace"], [2180, 0, 0, "-", "hipify"], [2211, 0, 0, "-", "hooks"], [2099, 0, 0, "-", "jit"], [2211, 0, 0, "-", "mkldnn"], [2211, 0, 0, "-", "mobile_optimizer"], [2180, 0, 0, "-", "model_dump"], [2107, 0, 0, "-", "model_zoo"], [2108, 0, 0, "-", "module_tracker"], [2036, 5, 1, "", "rename_privateuse1_backend"], [2147, 0, 0, "-", "serialization"], [2037, 5, 1, "", "set_module"], [2211, 0, 0, "-", "show_pickle"], [2038, 5, 1, "", "swap_tensors"], [2176, 0, 0, "-", "tensorboard"], [2211, 0, 0, "-", "throughput_benchmark"], [2180, 0, 0, "-", "viz"], [2211, 0, 0, "-", "weak"]], "torch.utils.benchmark": [[4, 1, 1, "", "CallgrindStats"], [4, 1, 1, "", "Compare"], [4, 1, 1, "", "FunctionCounts"], [4, 1, 1, "", "Measurement"], [4, 1, 1, "", "Timer"], [4, 0, 0, "-", "examples"], [4, 0, 0, "-", "op_fuzzers"], [4, 0, 0, "-", "utils"]], "torch.utils.benchmark.CallgrindStats": [[4, 3, 1, "", "as_standardized"], [4, 3, 1, "", "counts"], [4, 3, 1, "", "delta"], [4, 3, 1, "", "stats"]], "torch.utils.benchmark.Compare": [[4, 3, 1, "", "colorize"], [4, 3, 1, "", "extend_results"], [4, 3, 1, "", "highlight_warnings"], [4, 3, 1, "", "print"], [4, 3, 1, "", "trim_significant_figures"]], "torch.utils.benchmark.FunctionCounts": [[4, 3, 1, "", "denoise"], [4, 3, 1, "", "filter"], [4, 3, 1, "", "transform"]], "torch.utils.benchmark.Measurement": [[4, 3, 1, "", "merge"], [4, 4, 1, "", "significant_figures"]], "torch.utils.benchmark.Timer": [[4, 3, 1, "", "adaptive_autorange"], [4, 3, 1, "", "blocked_autorange"], [4, 3, 1, "", "collect_callgrind"], [4, 3, 1, "", "timeit"]], "torch.utils.benchmark.examples": [[2211, 0, 0, "-", "blas_compare_setup"], [2211, 0, 0, "-", "compare"], [2211, 0, 0, "-", "fuzzer"], [2211, 0, 0, "-", "op_benchmark"], [2211, 0, 0, "-", "simple_timeit"], [2211, 0, 0, "-", "spectral_ops_fuzz_test"]], "torch.utils.benchmark.op_fuzzers": [[2211, 0, 0, "-", "binary"], [2211, 0, 0, "-", "sparse_binary"], [2211, 0, 0, "-", "sparse_unary"], [2211, 0, 0, "-", "spectral"], [2211, 0, 0, "-", "unary"]], "torch.utils.benchmark.utils": [[2211, 0, 0, "-", "common"], [2211, 0, 0, "-", "compare"], [2211, 0, 0, "-", "compile"], [2211, 0, 0, "-", "cpp_jit"], [2211, 0, 0, "-", "fuzzer"], [2211, 0, 0, "-", "sparse_fuzzer"], [2211, 0, 0, "-", "timer"], [4, 0, 0, "-", "valgrind_wrapper"]], "torch.utils.benchmark.utils.valgrind_wrapper": [[2211, 0, 0, "-", "timer_interface"]], "torch.utils.checkpoint": [[6, 1, 1, "", "CheckpointPolicy"], [6, 1, 1, "", "SelectiveCheckpointContext"], [6, 5, 1, "", "checkpoint"], [6, 5, 1, "", "checkpoint_sequential"], [6, 5, 1, "", "create_selective_checkpoint_contexts"], [6, 5, 1, "", "set_checkpoint_debug_enabled"]], "torch.utils.cpp_extension": [[16, 5, 1, "", "BuildExtension"], [16, 5, 1, "", "CUDAExtension"], [16, 5, 1, "", "CppExtension"], [16, 5, 1, "", "get_compiler_abi_compatibility_and_version"], [16, 5, 1, "", "include_paths"], [16, 5, 1, "", "is_ninja_available"], [16, 5, 1, "", "load"], [16, 5, 1, "", "load_inline"], [16, 5, 1, "", "verify_ninja_availability"]], "torch.utils.data": [[25, 1, 1, "", "BatchSampler"], [25, 1, 1, "", "ChainDataset"], [25, 1, 1, "", "ConcatDataset"], [25, 1, 1, "", "DataLoader"], [25, 1, 1, "", "Dataset"], [25, 1, 1, "", "IterableDataset"], [25, 1, 1, "", "RandomSampler"], [25, 1, 1, "", "Sampler"], [25, 1, 1, "", "SequentialSampler"], [25, 1, 1, "", "StackDataset"], [25, 1, 1, "", "Subset"], [25, 1, 1, "", "SubsetRandomSampler"], [25, 1, 1, "", "TensorDataset"], [25, 1, 1, "", "WeightedRandomSampler"], [2211, 0, 0, "-", "backward_compatibility"], [2211, 0, 0, "-", "dataloader"], [25, 0, 0, "-", "datapipes"], [2211, 0, 0, "-", "dataset"], [25, 5, 1, "", "default_collate"], [25, 5, 1, "", "default_convert"], [2211, 0, 0, "-", "distributed"], [25, 5, 1, "", "get_worker_info"], [2211, 0, 0, "-", "graph"], [2211, 0, 0, "-", "graph_settings"], [25, 5, 1, "", "random_split"], [2211, 0, 0, "-", "sampler"]], "torch.utils.data._utils.collate": [[25, 5, 1, "", "collate"]], "torch.utils.data.datapipes": [[25, 0, 0, "-", "dataframe"], [2211, 0, 0, "-", "datapipe"], [2211, 0, 0, "-", "gen_pyi"], [25, 0, 0, "-", "iter"], [25, 0, 0, "-", "map"], [25, 0, 0, "-", "utils"]], "torch.utils.data.datapipes.dataframe": [[2211, 0, 0, "-", "dataframe_wrapper"], [2211, 0, 0, "-", "dataframes"], [2211, 0, 0, "-", "datapipes"], [2211, 0, 0, "-", "structures"]], "torch.utils.data.datapipes.iter": [[2211, 0, 0, "-", "callable"], [2211, 0, 0, "-", "combinatorics"], [2211, 0, 0, "-", "combining"], [2211, 0, 0, "-", "filelister"], [2211, 0, 0, "-", "fileopener"], [2211, 0, 0, "-", "grouping"], [2211, 0, 0, "-", "routeddecoder"], [2211, 0, 0, "-", "selecting"], [2211, 0, 0, "-", "sharding"], [2211, 0, 0, "-", "streamreader"], [2211, 0, 0, "-", "utils"]], "torch.utils.data.datapipes.map": [[2211, 0, 0, "-", "callable"], [2211, 0, 0, "-", "combinatorics"], [2211, 0, 0, "-", "combining"], [2211, 0, 0, "-", "grouping"], [2211, 0, 0, "-", "utils"]], "torch.utils.data.datapipes.utils": [[2211, 0, 0, "-", "common"], [2211, 0, 0, "-", "decoder"], [2211, 0, 0, "-", "snapshot"]], "torch.utils.data.distributed": [[25, 1, 1, "", "DistributedSampler"]], "torch.utils.deterministic": [[29, 2, 1, "", "fill_uninitialized_memory"]], "torch.utils.dlpack": [[40, 5, 1, "", "from_dlpack"], [40, 5, 1, "", "to_dlpack"]], "torch.utils.hipify": [[2211, 0, 0, "-", "constants"], [2211, 0, 0, "-", "cuda_to_hip_mappings"], [2211, 0, 0, "-", "hipify_python"], [2211, 0, 0, "-", "version"]], "torch.utils.jit": [[2211, 0, 0, "-", "log_extract"]], "torch.utils.mobile_optimizer": [[2106, 5, 1, "", "optimize_for_mobile"]], "torch.utils.model_zoo": [[2107, 5, 1, "", "load_url"]], "torch.utils.module_tracker": [[2108, 1, 1, "", "ModuleTracker"]], "torch.utils.serialization": [[2147, 0, 0, "-", "config"]], "torch.utils.tensorboard": [[2211, 0, 0, "-", "summary"], [2211, 0, 0, "-", "writer"]], "torch.utils.tensorboard.writer": [[2176, 1, 1, "", "SummaryWriter"]], "torch.utils.tensorboard.writer.SummaryWriter": [[2176, 3, 1, "", "__init__"], [2176, 3, 1, "", "add_audio"], [2176, 3, 1, "", "add_custom_scalars"], [2176, 3, 1, "", "add_embedding"], [2176, 3, 1, "", "add_figure"], [2176, 3, 1, "", "add_graph"], [2176, 3, 1, "", "add_histogram"], [2176, 3, 1, "", "add_hparams"], [2176, 3, 1, "", "add_image"], [2176, 3, 1, "", "add_images"], [2176, 3, 1, "", "add_mesh"], [2176, 3, 1, "", "add_pr_curve"], [2176, 3, 1, "", "add_scalar"], [2176, 3, 1, "", "add_scalars"], [2176, 3, 1, "", "add_text"], [2176, 3, 1, "", "add_video"], [2176, 3, 1, "", "close"], [2176, 3, 1, "", "flush"]], "torch.xpu": [[2050, 1, 1, "", "Event"], [2052, 1, 1, "", "StreamContext"], [2053, 5, 1, "", "current_device"], [2054, 5, 1, "", "current_stream"], [2055, 1, 1, "", "device"], [2056, 5, 1, "", "device_count"], [2057, 1, 1, "", "device_of"], [2058, 5, 1, "", "empty_cache"], [2059, 5, 1, "", "get_arch_list"], [2060, 5, 1, "", "get_device_capability"], [2061, 5, 1, "", "get_device_name"], [2062, 5, 1, "", "get_device_properties"], [2063, 5, 1, "", "get_gencode_flags"], [2064, 5, 1, "", "get_rng_state"], [2065, 5, 1, "", "get_rng_state_all"], [2067, 5, 1, "", "init"], [2068, 5, 1, "", "initial_seed"], [2069, 5, 1, "", "is_available"], [2070, 5, 1, "", "is_initialized"], [2071, 5, 1, "", "manual_seed"], [2072, 5, 1, "", "manual_seed_all"], [2073, 5, 1, "", "max_memory_allocated"], [2074, 5, 1, "", "max_memory_reserved"], [2075, 5, 1, "", "mem_get_info"], [2212, 0, 0, "-", "memory"], [2076, 5, 1, "", "memory_allocated"], [2077, 5, 1, "", "memory_reserved"], [2078, 5, 1, "", "memory_stats"], [2079, 5, 1, "", "memory_stats_as_nested_dict"], [2212, 0, 0, "-", "random"], [2080, 5, 1, "", "reset_accumulated_memory_stats"], [2081, 5, 1, "", "reset_peak_memory_stats"], [2082, 5, 1, "", "seed"], [2083, 5, 1, "", "seed_all"], [2084, 5, 1, "", "set_device"], [2085, 5, 1, "", "set_rng_state"], [2086, 5, 1, "", "set_rng_state_all"], [2087, 5, 1, "", "set_stream"], [2051, 5, 1, "", "stream"], [2212, 0, 0, "-", "streams"], [2088, 5, 1, "", "synchronize"]], "torch.xpu.Event": [[2050, 3, 1, "", "elapsed_time"], [2050, 3, 1, "", "query"], [2050, 3, 1, "", "record"], [2050, 3, 1, "", "synchronize"], [2050, 3, 1, "", "wait"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:property", "5": "py:function", "6": "py:exception", "7": "py:data", "8": "std:envvar"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"], "6": ["py", "exception", "Python exception"], "7": ["py", "data", "Python data"], "8": ["std", "envvar", "environment variable"]}, "titleterms": {"torch": [0, 1, 2, 3, 4, 5, 6, 12, 14, 15, 16, 18, 19, 25, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 52, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 69, 70, 79, 80, 81, 82, 83, 84, 85, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 926, 927, 928, 929, 931, 932, 933, 934, 937, 938, 939, 940, 941, 942, 943, 944, 948, 949, 950, 951, 952, 953, 954, 955, 956, 959, 960, 961, 962, 963, 964, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1063, 1064, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1444, 1446, 1447, 1448, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1791, 1792, 1793, 1794, 1797, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2051, 2053, 2054, 2056, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2096, 2098, 2099, 2100, 2101, 2102, 2103, 2106, 2107, 2108, 2109, 2110, 2112, 2113, 2114, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2130, 2133, 2134, 2137, 2139, 2145, 2147, 2149, 2153, 2154, 2156, 2157, 2158, 2159, 2164, 2165, 2169, 2170, 2171, 2172, 2173, 2174, 2176, 2177, 2178, 2180, 2181, 2182, 2183, 2184, 2185, 2187, 2195, 2196, 2202, 2204, 2206, 2208, 2210, 2211, 2212], "acceler": [0, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 2171, 2180], "automat": [1, 2, 25, 36, 2093, 2126, 2134], "mix": [1, 2093, 2126, 2130], "precis": [1, 2126, 2130, 2145], "packag": [1, 2, 12, 17, 30, 2114, 2148, 2158], "amp": [1, 2130, 2137], "autocast": [1, 2126], "gradient": [1, 2, 66, 1268, 2126, 2127, 2134, 2180, 2195], "scale": [1, 2126, 2140, 2145], "op": [1, 14, 2098, 2100, 2117, 2126, 2153, 2154, 2180, 2204], "refer": [1, 14, 20, 21, 36, 56, 57, 62, 69, 2093, 2095, 2096, 2097, 2109, 2116, 2139, 2150, 2158, 2159, 2161, 2164, 2168, 2177, 2185, 2187, 2207], "elig": 1, "cuda": [1, 3, 12, 19, 20, 22, 209, 1043, 1044, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1063, 1064, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 2114, 2130, 2135, 2139, 2144, 2146, 2148, 2189, 2195, 2202, 2207], "specif": [1, 25, 57, 2171], "behavior": [1, 21, 25, 2127, 2138], "can": [1, 2127, 2135, 2195, 2201], "float16": 1, "float32": 1, "promot": [1, 8], "widest": 1, "input": [1, 21, 56, 58, 2115, 2126, 2138, 2189], "type": [1, 25, 37, 57, 58, 603, 2095, 2096, 2133, 2154, 2158, 2173, 2177, 2210], "prefer": 1, "binary_cross_entropy_with_logit": [1, 1659], "over": [1, 9, 2095], "binary_cross_entropi": [1, 1658], "xpu": [1, 623, 2051, 2053, 2054, 2056, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2212], "experiment": [1, 37, 70, 1214, 1215, 1216, 1217, 1218, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 2101, 2121], "cpu": [1, 3, 12, 18, 206, 1028, 1030, 1031, 1032, 1033, 1034, 1035, 2127, 2129, 2144, 2161, 2188], "bfloat16": [1, 155], "differenti": [2, 2127], "autograd": [2, 12, 13, 17, 65, 919, 920, 921, 922, 923, 926, 927, 928, 929, 931, 932, 933, 934, 937, 938, 939, 940, 941, 942, 943, 944, 948, 949, 950, 951, 952, 953, 954, 955, 956, 959, 960, 961, 962, 963, 964, 2116, 2126, 2127, 2133, 2134, 2154, 2166, 2167], "forward": [2, 920, 2133, 2167], "mode": [2, 52, 63, 414, 1420, 2127, 2133, 2138, 2154, 2161, 2167], "function": [2, 30, 37, 39, 58, 59, 61, 62, 64, 66, 69, 919, 920, 921, 922, 931, 932, 933, 934, 937, 938, 939, 940, 941, 942, 943, 1202, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 2093, 2094, 2095, 2096, 2098, 2101, 2103, 2115, 2117, 2118, 2123, 2126, 2127, 2134, 2138, 2147, 2154, 2164, 2171, 2172, 2195, 2206], "higher": 2, "level": [2, 12, 2100, 2164], "api": [2, 12, 14, 17, 20, 21, 33, 36, 37, 45, 56, 62, 65, 69, 2093, 2096, 2100, 2109, 2116, 2129, 2130, 2133, 2139, 2140, 2150, 2154, 2158, 2159, 2160, 2161, 2164, 2173, 2185, 2187, 2191, 2192, 2194, 2195, 2196, 2207], "local": [2, 2096, 2127, 2180, 2201, 2203], "disabl": [2, 25, 1008, 2093, 2127, 2180, 2195, 2196, 2204], "comput": [2, 66, 2127, 2145, 2167, 2180, 2195], "default": [2, 25, 26, 2095, 2127, 2130, 2138, 2163, 2192], "layout": [2, 2117, 2174], "manual": [2, 36], "In": [2, 9, 2127, 2128, 2180], "place": [2, 65, 2115, 2127, 2128, 2154, 2180], "oper": [2, 12, 21, 26, 30, 56, 58, 65, 85, 2095, 2096, 2101, 2103, 2115, 2116, 2117, 2127, 2131, 2133, 2140, 2148, 2153, 2154, 2155, 2161, 2171, 2177, 2180, 2194, 2202, 2204], "tensor": [2, 13, 17, 37, 38, 56, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 2011, 2094, 2098, 2101, 2104, 2114, 2115, 2116, 2117, 2127, 2133, 2147, 2154, 2161, 2164, 2171, 2174, 2175, 2177, 2180, 2194, 2204], "correct": [2, 69, 2127], "check": [2, 41, 69, 2093, 2127, 2137, 2139, 2201], "variabl": [2, 22, 27, 30, 52, 2093, 2095, 2096, 2105, 2111, 2147, 2179, 2198, 2208, 2209], "deprec": [2, 2150, 2156], "context": [2, 21, 31, 49, 75, 2167], "method": [2, 44, 45, 48, 54, 2094, 2095, 2098, 2154, 2164, 2171], "mixin": 2, "custom": [2, 43, 54, 58, 69, 2096, 2100, 2126, 2130, 2131, 2134, 2142, 2154, 2157, 2158, 2161, 2190, 2204], "util": [2, 4, 5, 6, 12, 16, 25, 29, 30, 36, 40, 62, 64, 1122, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1791, 1792, 1793, 1794, 1797, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 2034, 2035, 2036, 2037, 2038, 2099, 2106, 2107, 2108, 2118, 2119, 2122, 2147, 2157, 2164, 2176, 2180, 2182, 2203, 2211], "numer": [2, 2138, 2145, 2162, 2164], "profil": [2, 30, 959, 960, 961, 962, 963, 964, 1430, 1431, 1432, 1433, 1434, 1435, 2110, 2140, 2142, 2159, 2198, 2202, 2205], "debug": [2, 26, 27, 30, 37, 54, 62, 69, 2093, 2161, 2162, 2185, 2190, 2195, 2204, 2205], "anomali": 2, "detect": 2, "graph": [2, 19, 56, 57, 69, 951, 952, 953, 954, 955, 956, 1078, 2093, 2127, 2130, 2161, 2189, 2192, 2195, 2202, 2203, 2204, 2205], "backend": [3, 30, 51, 52, 2093, 2139, 2143, 2152, 2161, 2163, 2166, 2183, 2188, 2190, 2205], "cudnn": 3, "cusparselt": 3, "mha": 3, "mp": [3, 12, 1423, 1424, 1425, 1426, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 2110, 2111, 2143], "mkl": 3, "mkldnn": [3, 12], "nnpack": 3, "openmp": 3, "opt_einsum": 3, "xeon": 3, "benchmark": [4, 2146, 2198], "bottleneck": 5, "checkpoint": [6, 26, 32], "pytorch": [7, 8, 9, 10, 12, 17, 28, 30, 34, 37, 56, 58, 65, 2092, 2093, 2094, 2098, 2127, 2130, 2131, 2133, 2146, 2147, 2154, 2161, 2164, 2183, 2189, 2200, 2201, 2205, 2209], "govern": [7, 10, 12], "build": [7, 8, 12, 36, 2129, 2140, 2142, 2148], "ci": [7, 12], "how": [7, 26, 36, 63, 2091, 2127, 2133, 2157, 2158, 2193, 2194, 2195, 2201], "add": [7, 10, 97, 696], "new": [7, 8, 10, 2100, 2133], "maintain": [7, 10, 12], "contribut": [8, 2117, 2149], "guid": 8, "process": [8, 10, 25, 49, 2126], "get": [8, 33, 2137, 2147, 2154, 2183, 2195, 2197], "start": [8, 33, 49, 1434, 2137, 2183, 2197, 2205], "propos": 8, "featur": [8, 37, 2140, 2142, 2195], "report": [8, 2135, 2204], "issu": [8, 2093, 2202, 2204], "implement": [8, 36, 41, 51, 54, 58, 2091, 2132, 2138, 2154, 2162, 2164, 2168, 2192, 2194], "fix": [8, 52, 63, 261, 1182], "bug": 8, "ad": [8, 2133, 2154, 2192], "tutori": [8, 12, 2158, 2166], "improv": [8, 2142], "document": [8, 33, 2092], "particip": 8, "onlin": 8, "discuss": 8, "submit": 8, "pull": 8, "request": 8, "open": 8, "review": 8, "code": [8, 69, 2093, 2130, 2137, 2158, 2186, 2195, 2204], "readabl": 8, "test": [8, 2096, 2100, 2133, 2158, 2178, 2201], "case": [8, 2093, 2173], "make": [8, 10, 2189, 2192], "codebas": 8, "more": [8, 56, 61, 2166, 2183], "robust": 8, "triag": 8, "about": [8, 2127, 2166, 2194], "sourc": [8, 2137, 2146, 2148, 2158], "develop": [8, 56, 2125, 2149, 2183], "common": [8, 30, 69, 2140, 2161], "mistak": 8, "To": 8, "avoid": [8, 2144, 2146, 2154, 2158], "frequent": [8, 2093, 2135, 2154, 2161, 2195], "ask": [8, 2093, 2135, 2154, 2161, 2195], "question": [8, 2093, 2135, 2154, 2161, 2195], "On": [8, 26, 2095], "python": [8, 9, 30, 56, 65, 72, 73, 74, 75, 76, 77, 78, 2093, 2094, 2095, 2096, 2097, 2098, 2100, 2133, 2146, 2154, 2160, 2185, 2192], "doc": [8, 12, 2117, 2139], "c": [8, 12, 17, 2100, 2127, 2139, 2147, 2154, 2185], "overview": [8, 20, 21, 56, 69, 2149, 2150, 2158, 2159, 2171, 2190, 2193], "design": [9, 2096, 2132, 2166, 2167, 2168], "philosophi": 9, "principl": [9, 10], "1": [9, 36, 52, 63, 2093, 2134, 2192], "usabl": 9, "perform": [9, 12, 2142, 2147, 2194, 2201, 2202, 2205], "2": [9, 36, 63, 2093, 2130, 2134, 2135, 2161, 2164, 2200, 2201, 2205], "simpl": [9, 2095, 2096, 2142, 2150, 2167, 2204], "easi": 9, "3": [9, 52, 63], "first": [9, 2158], "best": [9, 2130, 2144, 2161, 2188], "class": [9, 37, 44, 69, 2093, 2095, 2096, 2098, 2154, 2157, 2158, 2177], "languag": [9, 2093, 2095, 2096, 2097], "interoper": 9, "mechan": [10, 2117, 2123, 2127, 2138], "summari": [10, 2161, 2204], "modul": [10, 12, 58, 62, 64, 69, 1580, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 2093, 2094, 2095, 2096, 2098, 2118, 2127, 2133, 2142, 2147, 2158, 2161, 2200], "core": [10, 12, 2199], "lead": [10, 12], "bdfl": [10, 12], "nomin": [10, 2096], "confirm": 10, "remov": [10, 1810, 2115], "The": [10, 69, 2096, 2127, 2191], "re": [10, 2158], "scope": 10, "project": 10, "decis": 10, "uncontroversi": 10, "chang": [10, 52, 63, 2137, 2195, 2204], "controversi": 10, "gener": [10, 19, 31, 65, 69, 87, 2128, 2134, 2146, 2161, 2162, 2180, 2192, 2193, 2204, 2207, 2212], "polici": [10, 2191], "faq": [10, 2148], "commun": [11, 19, 26, 30, 37, 2136], "respons": 12, "nn": [12, 62, 64, 1640, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1791, 1792, 1793, 1794, 1797, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 2095, 2096, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2127, 2130, 2133, 2147, 2164, 2171, 2200], "optim": [12, 13, 35, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 2126, 2127, 2130, 2157, 2166, 2167, 2180], "torchdynamo": [12, 2132, 2149, 2150, 2151, 2152, 2189, 2196, 2204, 2205], "torchinductor": [12, 2198, 2201, 2205], "cudagraph": [12, 1037, 2189], "tree": [12, 2189], "pt2": [12, 2164], "dispatch": 12, "export": [12, 56, 57, 58, 2149, 2150, 2151, 2154, 2158, 2161, 2164, 2180, 2185, 2195], "aot": 12, "inductor": 12, "aoti": 12, "runtim": [12, 2129, 2135, 2205], "compil": [12, 64, 1002, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 2117, 2130, 2137, 2183, 2184, 2185, 2187, 2195, 2196, 2202, 2204, 2205], "jit": [12, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1330, 1331, 1332, 1333, 2093, 2096, 2099], "torchscript": [12, 17, 2093, 2094, 2095, 2096, 2098, 2129, 2140, 2149, 2151, 2154, 2155, 2158], "deploi": [12, 28], "distribut": [12, 30, 32, 33, 34, 35, 36, 37, 38, 39, 52, 2118, 2123, 2132, 2139, 2142, 2166, 2167, 2195], "rng": 12, "multiprocess": [12, 49, 2114, 2130, 2144, 2148], "linear": [12, 13, 743, 744, 767, 775, 792, 1209, 1567, 1703, 2118, 2123, 2145, 2171], "algebra": [12, 13, 2145, 2171], "linalg": [12, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 2101, 2145], "spars": [12, 1966, 1967, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 2118, 2123, 2171], "nestedtensor": 12, "nest": [12, 2117], "maskedtensor": [12, 2103], "mask": [12, 2103], "fast": [12, 59, 2138, 2167], "fourier": [12, 59], "transform": [12, 39, 59, 61, 62, 64, 66, 69, 1624, 2118, 2133, 2142, 2195, 2203], "fft": [12, 59, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181], "amd": [12, 2145], "rocm": [12, 21, 2139], "hip": [12, 2139], "tool": [12, 19, 37, 2162, 2171, 2185, 2204], "c10": 12, "onnx": [12, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156], "liteinterpret": 12, "quantiz": [12, 887, 2118, 2142, 2154, 2161, 2162, 2163, 2164], "ao": [12, 2164, 2181, 2182], "window": [12, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2148, 2169], "appl": 12, "m1": 12, "metal": 12, "powerpc": 12, "x86": [12, 2188], "aarch64": 12, "librari": [12, 2100, 2146], "xla": 12, "torchserv": 12, "torchvis": [12, 63], "torchtext": 12, "torchaudio": 12, "torchrec": 12, "torchx": 12, "torchdata": 12, "torcharrow": 12, "executorch": 12, "edg": [12, 2093, 2158], "mobil": 12, "torchtun": 12, "torchchat": 12, "torchcodec": 12, "complex": [13, 1016, 2127, 2138], "number": [13, 19, 52, 2127, 2129, 2135, 2146, 2180, 2212], "creat": [13, 37, 2093, 2100, 2116, 2204], "transit": [13, 52], "from": [13, 37, 52, 64, 69, 2091, 2100, 2115, 2117, 2137, 2148, 2154, 2158], "old": [13, 2205], "represent": 13, "access": [13, 58, 2095, 2158, 2205], "real": [13, 483, 1910, 2138], "imag": [13, 311, 1285], "angl": [13, 117, 709], "ab": [13, 89, 682], "serial": [13, 56, 2147, 2180], "control": [14, 42, 56, 58, 65, 69, 76, 2146, 2180, 2196], "flow": [14, 56, 58, 65, 69, 76, 2161, 2180], "cond": [14, 79, 1019, 1346], "exampl": [14, 36, 46, 56, 69, 2126, 2132, 2133, 2134, 2137, 2150, 2154, 2167, 2186, 2190], "invari": 14, "higher_ord": 14, "__config__": 15, "cpp_extens": 16, "extend": [17, 41, 2100, 2133, 2134, 2205], "extens": [17, 19, 2140, 2148], "author": [17, 69], "model": [17, 36, 56, 58, 78, 2091, 2126, 2135, 2140, 2150, 2157, 2158, 2161, 2164, 2185, 2191, 2197, 2198], "stream": [18, 19, 20, 88, 1028, 1044, 1444, 2051, 2112, 2130, 2212], "event": [18, 19, 43, 45, 86, 1039, 1427, 1443, 2050, 2110, 2112, 2212], "random": [19, 25, 65, 2135, 2146, 2165, 2180, 2212], "collect": [19, 30], "beta": [19, 39], "memori": [19, 25, 1096, 1457, 2113, 2130, 2135, 2139, 2142, 2146, 2151, 2207, 2212], "manag": [19, 31, 75, 2114, 2130, 2139, 2158, 2203, 2212], "nvidia": [19, 2145], "nvtx": [19, 1104, 1105, 1106, 1107], "jiter": [19, 1086, 1087], "tunableop": [19, 21], "sanit": [19, 20], "prototyp": [19, 2161, 2162], "gpudirect": 19, "storag": [19, 557, 2173], "usag": [20, 33, 52, 2117, 2130, 2134, 2140, 2142, 2148, 2151, 2200, 2207], "enabl": [21, 2139, 2204], "tune": [21, 2129], "separ": [21, 2133], "file": [21, 30, 2114, 2147, 2158], "output": [21, 57, 2138, 2192], "A": [21, 69, 2142, 2150, 2192], "note": [21, 52, 2096, 2125, 2130, 2136, 2161, 2166], "current": [21, 2116], "tunabl": 21, "tunablegemm": 21, "environ": [22, 27, 30, 52, 2105, 2111, 2140, 2147, 2158, 2179, 2198, 2208, 2209], "data": [25, 56, 58, 65, 77, 2096, 2117, 2132, 2135, 2154, 2162, 2177, 2204], "dataset": 25, "map": [25, 83, 2139], "style": 25, "iter": [25, 2095], "load": [25, 1322, 1386, 2091, 2147, 2157, 2158, 2161], "order": [25, 2127], "sampler": 25, "batch": [25, 63, 2145, 2157], "non": [25, 56, 58, 69, 2118, 2123, 2127, 2130, 2145, 2158, 2161], "work": [25, 62, 2104, 2126, 2135, 2171, 2194, 2195, 2202], "collate_fn": 25, "singl": [25, 52, 2126], "multi": [25, 30, 52, 2118, 2123], "platform": 25, "pin": [25, 2130], "ddp": 26, "hook": [26, 2127, 2142, 2200], "us": [26, 30, 36, 69, 2095, 2127, 2130, 2133, 2138, 2150, 2154, 2157, 2158, 2161, 2171, 2195, 2197, 2202, 2205, 2207], "what": [26, 36, 57, 61, 63, 66, 2103, 2127, 2158, 2193, 2195, 2201, 2202, 2204], "doe": [26, 36, 2127, 2194, 2195], "powersgd": 26, "state": [26, 58, 2142, 2157, 2158, 2207], "acknowledg": 26, "ha": 28, "been": 28, "move": 28, "multipi": 28, "determinist": 29, "come": [30, 2127], "which": [30, 58, 2127, 2195], "choos": 30, "network": [30, 2130, 2135, 2142], "interfac": [30, 1320, 2139], "other": [30, 2118, 2146, 2158, 2171, 2180, 2194], "nccl": [30, 2130, 2189], "basic": [30, 58, 2096, 2116, 2122, 2134, 2166, 2177, 2202], "initi": [30, 2118, 2142, 2177], "tcp": 30, "share": [30, 2114, 2130, 2158, 2168], "system": [30, 2096, 2114, 2130, 2134], "post": [30, 2161], "shutdown": 30, "reiniti": 30, "group": 30, "devicemesh": [30, 37], "point": [30, 2140], "synchron": [30, 693, 1035, 1120, 1440, 1464, 2088], "asynchron": [30, 2096, 2130, 2144], "kei": [30, 2148], "valu": [30, 58, 81, 614, 2095, 2096, 2145, 2163, 2168], "store": [30, 51], "gpu": [30, 2118, 2123, 2126, 2135, 2137, 2198], "third": 30, "parti": 30, "launch": [30, 52, 2202], "spawn": [30, 2114], "applic": 30, "breakpoint": [30, 2204], "monitor": [30, 2109], "barrier": 30, "torch_distributed_debug": 30, "log": [30, 36, 37, 54, 369, 1388, 2140, 2204], "join": [31, 2180], "addit": [32, 56], "resourc": [32, 2158, 2194], "elast": [33, 41, 52], "advanc": [33, 2142], "plugin": 33, "fsdp": [34, 2136], "fully_shard": 34, "fsdp2": 34, "pipelin": 36, "parallel": [36, 38, 1753, 2130, 2132, 2135, 2180], "why": [36, 61, 66, 2130, 2138, 2158, 2171, 2195], "i": [36, 57, 66, 2103, 2127, 2158, 2193, 2194, 2195, 2201, 2204], "step": [36, 1854, 2157, 2197], "pipelinestag": 36, "pipelineschedul": 36, "execut": [36, 2096, 2127, 2130, 2158, 2195], "option": [36, 58, 63, 2095, 2129, 2148, 2157, 2204], "split": [36, 547, 1982], "hug": 36, "face": 36, "technic": 36, "deep": [36, 56, 2183, 2192], "dive": [36, 56, 2183, 2192], "your": [36, 2158], "own": [36, 2127], "schedul": [36, 2157], "microbatch": 36, "stage": 36, "dtensor": 37, "placement": 37, "differ": [37, 2127, 2130, 2154, 2195], "wai": 37, "logic": [37, 2091, 2095], "factori": [37, 2115], "probabl": 39, "score": 39, "pathwis": 39, "deriv": [39, 2127], "exponentialfamili": 39, "bernoulli": [39, 153, 972], "binomi": 39, "categor": 39, "cauchi": 39, "chi2": 39, "continuousbernoulli": 39, "dirichlet": 39, "exponenti": [39, 1949], "fishersnedecor": 39, "gamma": 39, "geometr": 39, "gumbel": 39, "halfcauchi": 39, "halfnorm": 39, "independ": 39, "inversegamma": 39, "kumaraswami": 39, "lkjcholeski": 39, "laplac": 39, "lognorm": 39, "lowrankmultivariatenorm": 39, "mixturesamefamili": 39, "multinomi": [39, 421, 1466], "multivariatenorm": 39, "negativebinomi": 39, "normal": [39, 1723, 1828, 2118, 2157], "onehotcategor": 39, "pareto": 39, "poisson": [39, 1885], "relaxedbernoulli": 39, "logitrelaxedbernoulli": 39, "relaxedonehotcategor": 39, "studentt": 39, "transformeddistribut": 39, "uniform": 39, "vonmis": 39, "weibul": 39, "wishart": 39, "kl": 39, "diverg": [39, 2098], "constraint": [39, 2130], "registri": [39, 51], "dlpack": 40, "agent": 41, "server": [41, 51, 54], "concept": 41, "watchdog": 41, "health": 41, "plane": 42, "launcher": [43, 2186], "rendezv": [43, 51, 52], "handler": [43, 48, 51, 2135], "metric": [43, 48], "error": [44, 2135, 2148, 2161, 2162, 2204, 2205], "propag": [44, 58, 2116], "object": [45, 78, 2158], "torchelast": 47, "kubernet": 47, "multipl": [49, 2126, 2130, 2133], "worker": [49, 52, 2135], "quickstart": 50, "dataclass": 51, "except": [51, 2135], "dynam": [51, 56, 58, 65, 69, 80, 81, 2161, 2164, 2189, 2191, 2194, 2204], "c10d": 51, "etcd": 51, "legaci": [51, 2173], "torchrun": 52, "node": [52, 57, 951, 952, 953, 954, 955, 2127], "stack": [52, 1987, 2161], "fault": 52, "toler": 52, "size": [52, 537, 2136, 2170, 2204], "failur": 52, "min": [52, 411, 1417], "max": [52, 407, 1412], "4": [52, 63], "up": [52, 2195], "membership": [52, 2096], "definit": [52, 2096], "deploy": [52, 2140], "import": [52, 2091, 2148, 2158, 2194], "notic": [52, 2091], "subprocess": [53, 2114], "handl": [53, 2195], "retriev": 53, "subprocesshandl": 53, "expir": 54, "timer": 54, "client": 54, "write": [54, 69, 2127, 2154, 2203], "info": [54, 2210], "train": [55, 56, 2126, 2137, 2142, 2144, 2161, 2195], "script": [55, 1326, 2093, 2148, 2154], "exist": 56, "framework": [56, 2158, 2166], "an": [56, 2091, 2154, 2157, 2158], "strict": [56, 58], "infer": [56, 2116, 2127, 2129, 2137, 2147, 2185], "express": [56, 2095, 2096], "special": [56, 2096, 2127, 2172, 2173, 2192], "shape": [56, 58, 65, 80, 523, 2117, 2154, 2189, 2191, 2192, 2194, 2204], "primit": [56, 2096], "contain": [56, 2118], "limit": [56, 65, 69, 2091, 2134, 2154, 2189, 2196, 2200, 2204], "break": [56, 2095, 2096, 2192, 2195, 2202, 2204, 2205], "depend": [56, 58, 65, 2117, 2150, 2158, 2167, 2204], "miss": 56, "fake": [56, 58, 2194], "meta": [56, 2096, 2104], "abstract": 56, "kernel": [56, 967, 2139, 2161, 2198, 2202], "read": [56, 58, 61, 2154, 2183, 2201], "link": 56, "user": [56, 2158, 2168, 2183], "ir": [57, 2199, 2203], "assumpt": [57, 2168], "exportedprogram": 57, "call_funct": 57, "metadata": [57, 951, 2140], "placehold": 57, "get_attr": 57, "symint": [57, 2191], "faketensor": 57, "pytre": 57, "abl": 57, "program": [58, 2096, 2130], "trace": [58, 69, 591, 1330, 2016, 2093, 2154, 2159, 2161, 2195, 2196, 2202, 2204], "v": [58, 2154, 2204], "static": [58, 69, 2154, 2161, 2192], "ar": [58, 61, 66, 2091, 2127, 2158, 2192, 2195], "symbol": [58, 69, 2154, 2161, 2180, 2192], "back": 58, "unback": [58, 2191], "guard": [58, 2191, 2192, 2193, 2204], "assert": [58, 72, 2096, 2139], "allow": 58, "updat": 58, "rule": [58, 2096, 2116, 2134], "effect": 58, "helper": 59, "fullyshardeddataparallel": 60, "func": [61, 62, 64, 66, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 2133, 2134, 2195], "compos": [61, 66, 2190], "patch": [63, 2158], "norm": [63, 453, 1371, 1827], "": [63, 2158, 2195, 2201], "happen": 63, "batchnorm": 63, "paramet": [63, 1772, 2095, 2157], "functorch": [63, 64], "eval": [63, 2127], "migrat": [64, 2093], "make_funct": 64, "combine_state_for_ensembl": 64, "ux": 65, "vmap": [65, 66, 922, 1213, 2045, 2133, 2134, 2195], "mutat": [65, 84, 2180, 2189], "arbitrari": [65, 2158], "structur": [65, 77, 2096, 2117, 2171], "out": [65, 2115, 2135], "item": [65, 352], "nonzero": [65, 452, 1826], "friend": 65, "whirlwind": 66, "tour": 66, "grad": [66, 290, 944, 1203, 2127, 2130, 2195], "auto": 66, "vector": 66, "vjp": [66, 943, 1212], "jacobian": [66, 940], "product": [66, 2101, 2145, 2195], "jvp": [66, 921, 941, 1208, 2134], "jacrev": [66, 1207], "jacfwd": [66, 1206], "hessian": [66, 938, 1205], "__future__": 67, "futur": 68, "fx": [69, 70, 1214, 1215, 1216, 1217, 1218, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 2142, 2161, 2164, 2182], "quick": 69, "primer": 69, "manipul": [69, 2116, 2117], "direct": 69, "subgraph": [69, 2203], "rewrit": [69, 2203], "With": [69, 2098], "replace_pattern": 69, "proxi": 69, "retrac": 69, "interpret": [69, 2093], "pattern": [69, 2095, 2154, 2158], "introduct": [69, 2103, 2117, 2161, 2192], "pitfal": [69, 2154], "pdb": 69, "print": [69, 2095, 2096, 2204], "to_fold": 69, "graphmodul": 69, "avail": [69, 2137], "debugg": [69, 2164], "tracer": [69, 2093], "leaf": 69, "miscellanea": 69, "symbolic_shap": [70, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254], "proxy_tensor": [70, 1214, 1215, 1216, 1217, 1218], "exportdb": 71, "tag": [71, 2180], "support": [71, 2094, 2096, 2103, 2115, 2116, 2117, 2134, 2154, 2155, 2161, 2171, 2189, 2195, 2200], "list_unpack": [71, 76, 77], "specialized_attribut": 71, "static_for_loop": [71, 76], "cond_closed_over_vari": [71, 74, 79], "fn_with_kwarg": [71, 77], "constrain_as_value_exampl": [71, 81, 82], "dynamic_shape_sl": [71, 80], "cond_branch_nonlocal_vari": [71, 79, 80], "autograd_funct": 71, "type_reflection_method": [71, 73], "cond_operand": [71, 79, 80], "decor": 71, "dynamic_shape_view": [71, 80], "dynamic_shape_map": [71, 80, 83], "nested_funct": [71, 74], "dynamic_shape_constructor": [71, 80], "dynamic_shape_if_guard": [71, 76, 80], "assume_constant_result": [71, 82, 1005], "cond_branch_class_method": [71, 79, 80], "class_method": 71, "pytree_flatten": 71, "scalar_output": [71, 80], "cond_pred": [71, 79, 80], "dynamic_shape_assert": [71, 72], "tensor_setattr": [71, 73], "constrain_as_size_exampl": [71, 81, 82], "static_if": [71, 76], "dictionari": [71, 77, 2096], "list_contain": [71, 72, 77, 80], "user_input_mut": [71, 84], "null_context_manag": [71, 75], "cond_branch_nested_funct": [71, 79, 80], "Not": [71, 2098], "yet": 71, "unsupported_oper": [71, 85], "optional_input": [71, 78], "dynamic_shape_round": [71, 73, 80], "model_attr_mut": [71, 78], "builtin": [73, 2094], "closur": [74, 2157], "escap": [82, 2195], "hatch": [82, 2195], "abs_": 90, "absolut": [91, 683], "absolute_": 92, "aco": [93, 694], "acos_": 94, "acosh": [95, 695], "acosh_": 96, "add_": 98, "addbmm": [99, 697], "addbmm_": 100, "addcdiv": [101, 698], "addcdiv_": 102, "addcmul": [103, 699], "addcmul_": 104, "addmm": [105, 700, 1966], "addmm_": 106, "addmv": [107, 701], "addmv_": 108, "addr": [109, 702], "addr_": 110, "adjoint": [111, 703], "all": [112, 704, 2133, 2154, 2157], "allclos": [113, 705], "amax": [114, 706], "amin": [115, 707], "aminmax": [116, 708], "ani": [118, 710, 2096, 2195, 2201], "apply_": 119, "arcco": [120, 896], "arccos_": 121, "arccosh": [122, 897], "arccosh_": 123, "arcsin": [124, 898], "arcsin_": 125, "arcsinh": [126, 899], "arcsinh_": 127, "arctan": [128, 900], "arctan2": [129, 901], "arctan2_": 130, "arctan_": 131, "arctanh": [132, 902], "arctanh_": 133, "argmax": [134, 904], "argmin": [135, 905], "argsort": [136, 906], "argwher": [137, 907], "as_strid": [138, 908], "as_subclass": 139, "asin": [140, 911], "asin_": 141, "asinh": [142, 912], "asinh_": 143, "atan": [144, 913], "atan2": [145, 914], "atan2_": 146, "atan_": 147, "atanh": [148, 915], "atanh_": 149, "backward": [150, 919, 923, 2127, 2128, 2130, 2138, 2167], "baddbmm": [151, 970], "baddbmm_": 152, "bernoulli_": 154, "bincount": [156, 973], "bitwise_and": [157, 974], "bitwise_and_": 158, "bitwise_left_shift": [159, 975], "bitwise_left_shift_": 160, "bitwise_not": [161, 976], "bitwise_not_": 162, "bitwise_or": [163, 977], "bitwise_or_": 164, "bitwise_right_shift": [165, 978], "bitwise_right_shift_": 166, "bitwise_xor": [167, 979], "bitwise_xor_": 168, "bmm": [169, 982], "bool": 170, "broadcast_to": [171, 985], "byte": 172, "cauchy_": 173, "ccol_indic": 174, "cdoubl": 175, "ceil": [176, 991], "ceil_": 177, "cfloat": 178, "chalf": 179, "char": 180, "choleski": [181, 993, 1344], "cholesky_invers": [182, 994], "cholesky_solv": [183, 995], "chunk": [184, 996], "clamp": [185, 782, 997], "clamp_": 186, "clip": [187, 998, 2126], "clip_": 188, "clone": [189, 999], "coalesc": 190, "col_indic": 191, "conj": [192, 1020], "conj_phys": [193, 1021], "conj_physical_": 194, "contigu": 195, "copy_": 196, "copysign": [197, 1022], "copysign_": 198, "corrcoef": [199, 1023], "co": [200, 1024], "cos_": 201, "cosh": [202, 1025], "cosh_": 203, "count_nonzero": [204, 1026], "cov": [205, 1027], "cross": [207, 1036, 1347, 2127], "crow_indic": 208, "cummax": [210, 1123], "cummin": [211, 1124], "cumprod": [212, 1125], "cumprod_": 213, "cumsum": [214, 1126], "cumsum_": 215, "data_ptr": 216, "deg2rad": [217, 1128], "dense_dim": 218, "dequant": [219, 1129, 2161], "det": [220, 1130, 1348], "detach": 221, "detach_": 222, "devic": [223, 1062, 1449, 2055, 2104, 2130, 2145, 2174], "diag": [224, 1131], "diag_emb": [225, 1132], "diagflat": [226, 1133], "diagon": [227, 1134, 1349], "diagonal_scatt": [228, 1135], "diff": [229, 1136], "digamma": [230, 1137], "digamma_": 231, "dim": [232, 2115], "dim_ord": 233, "dist": [234, 1138], "div": [235, 1139, 2147], "div_": 236, "divid": [237, 1140], "divide_": 238, "dot": [239, 1141, 2145], "doubl": 240, "dsplit": [241, 1142], "element_s": 242, "eq": [243, 1149], "eq_": 244, "equal": [245, 1150], "erf": [246, 1151], "erf_": 247, "erfc": [248, 1152], "erfc_": 249, "erfinv": [250, 1153], "erfinv_": 251, "exp": [252, 1154], "exp_": 253, "expand": 254, "expand_a": 255, "expm1": [256, 1156], "expm1_": 257, "exponential_": 258, "fill_": 259, "fill_diagonal_": 260, "fix_": 262, "flatten": [263, 1183, 1525], "flip": [264, 1184], "fliplr": [265, 1185], "flipud": [266, 1186], "float": [267, 2147], "float_pow": [268, 1187], "float_power_": 269, "floor": [270, 1188], "floor_": 271, "floor_divid": [272, 1189], "floor_divide_": 273, "fmax": [274, 1190], "fmin": [275, 1191], "fmod": [276, 1192], "fmod_": 277, "frac": [278, 1193], "frac_": 279, "frexp": [280, 1194], "gather": [281, 1053, 1255], "gcd": [282, 1256], "gcd_": 283, "ge": [284, 1257], "ge_": 285, "geometric_": 286, "geqrf": [287, 1258], "ger": [288, 1259], "get_devic": 289, "greater": [291, 1269], "greater_": 292, "greater_equ": [293, 1270], "greater_equal_": 294, "gt": [295, 1271], "gt_": 296, "half": 297, "hardshrink": [298, 1535, 1689], "heavisid": [299, 1274], "histc": [300, 1275], "histogram": [301, 1276], "hsplit": [302, 1278], "hypot": [303, 1281], "hypot_": 304, "i0": [305, 1282], "i0_": 306, "igamma": [307, 1283], "igamma_": 308, "igammac": [309, 1284], "igammac_": 310, "index_add": [312, 1286], "index_add_": 313, "index_copi": [314, 1287], "index_copy_": 315, "index_fil": 316, "index_fill_": 317, "index_put": 318, "index_put_": 319, "index_reduc": [320, 1288], "index_reduce_": 321, "index_select": [322, 1289], "indic": [323, 2092], "inner": [324, 1291], "int": [325, 2192], "int_repr": 326, "invers": [327, 1292, 2101], "is_coalesc": 328, "is_complex": [329, 1293], "is_conj": [330, 1294], "is_contigu": 331, "is_cuda": 332, "is_floating_point": [333, 1296], "is_infer": 334, "is_leaf": 335, "is_meta": 336, "is_pin": 337, "is_quant": 338, "is_set_to": 339, "is_shar": 340, "is_sign": 341, "is_spars": 342, "is_sparse_csr": 343, "isclos": [344, 1303], "isfinit": [345, 1304], "isinf": [346, 1306], "isnan": [347, 1307], "isneginf": [348, 1308], "isposinf": [349, 1309], "isreal": [350, 1310], "istft": [351, 1311], "items": 353, "kthvalu": [354, 1336], "lcm": [355, 1337], "lcm_": 356, "ldexp": [357, 1338], "ldexp_": 358, "le": [359, 1339], "le_": 360, "lerp": [361, 1340], "lerp_": 362, "less": [363, 1341], "less_": 364, "less_equ": [365, 1342], "less_equal_": 366, "lgamma": [367, 1343], "lgamma_": 368, "log10": [370, 1389], "log10_": 371, "log1p": [372, 1390], "log1p_": 373, "log2": [374, 1391], "log2_": 375, "log_": 376, "log_normal_": 377, "logaddexp": [378, 1392], "logaddexp2": [379, 1393], "logcumsumexp": [380, 1394], "logdet": [381, 1395], "logical_and": [382, 1396], "logical_and_": 383, "logical_not": [384, 1397], "logical_not_": 385, "logical_or": [386, 1398], "logical_or_": 387, "logical_xor": [388, 1399], "logical_xor_": 389, "logit": [390, 1400], "logit_": 391, "logsumexp": [392, 1402], "long": 393, "lt": [394, 1403], "lt_": 395, "lu": [396, 1361, 1404], "lu_solv": [397, 1364, 1405], "map_": 398, "masked_fil": 399, "masked_fill_": 400, "masked_scatt": 401, "masked_scatter_": 402, "masked_select": [403, 1408], "matmul": [404, 1365, 1409], "matrix_exp": [405, 1366, 1410], "matrix_pow": [406, 1368, 1411], "maximum": [408, 1413], "mean": [409, 1414], "median": [410, 1415], "minimum": [412, 1418, 2137], "mm": [413, 1419, 1970], "module_load": 415, "moveaxi": [416, 1421], "movedim": [417, 1422], "msort": [418, 1441], "mul": [419, 1465], "mul_": 420, "multipli": [422, 1467], "multiply_": 423, "mv": [424, 1468], "mvlgamma": [425, 1469], "mvlgamma_": 426, "nan_to_num": [427, 1470], "nan_to_num_": 428, "nanmean": [429, 1471], "nanmedian": [430, 1472], "nanquantil": [431, 1473], "nansum": [432, 1474], "narrow": [433, 1475], "narrow_copi": [434, 1476], "nbyte": 435, "ndim": 436, "ndimens": 437, "ne": [438, 1477], "ne_": 439, "neg": [440, 442, 1478, 1479], "neg_": 441, "negative_": 443, "nelement": 444, "new_empti": 445, "new_ful": 446, "new_on": 447, "new_tensor": 448, "new_zero": 449, "nextaft": [450, 1480], "nextafter_": 451, "normal_": 454, "not_equ": [455, 1829], "not_equal_": 456, "numel": [457, 1830], "numpi": [458, 2154, 2195], "orgqr": [459, 1879], "ormqr": [460, 1880], "outer": [461, 1881], "permut": [462, 1883, 2115], "pin_memori": 463, "pinvers": [464, 1884], "polygamma": [465, 1887], "polygamma_": 466, "posit": [467, 1888], "pow": [468, 1889], "pow_": 469, "prod": [470, 1890], "put_": 471, "q_per_channel_axi": 472, "q_per_channel_scal": 473, "q_per_channel_zero_point": 474, "q_scale": 475, "q_zero_point": 476, "qr": [477, 1373, 1892], "qscheme": 478, "quantil": [479, 1893], "rad2deg": [480, 1900], "random_": 481, "ravel": [482, 1909], "reciproc": [484, 1911], "reciprocal_": 485, "record_stream": 486, "register_hook": [487, 954], "register_post_accumulate_grad_hook": 488, "remaind": [489, 1912], "remainder_": 490, "renorm": [491, 1913], "renorm_": 492, "repeat": 493, "repeat_interleav": [494, 1914], "requires_grad": [495, 2127], "requires_grad_": 496, "reshap": [497, 1915], "reshape_a": 498, "resize_": 499, "resize_as_": 500, "resolve_conj": [501, 1916], "resolve_neg": [502, 1917], "retain_grad": 503, "retains_grad": 504, "roll": [505, 1919], "rot90": [506, 1920], "round": [507, 1921], "round_": 508, "row_indic": 509, "rsqrt": [510, 1923], "rsqrt_": 511, "scatter": [512, 1056, 1925], "scatter_": 513, "scatter_add": [514, 1926], "scatter_add_": 515, "scatter_reduc": [516, 1927], "scatter_reduce_": 517, "select": [518, 1930, 2103], "select_scatt": [519, 1931], "set_": 520, "sgn": [521, 1943], "sgn_": 522, "share_memory_": 524, "short": 525, "sigmoid": [526, 770, 1611, 1740, 1944], "sigmoid_": 527, "sign": [528, 1945], "sign_": 529, "signbit": [530, 1957], "sin": [531, 1958], "sin_": 532, "sinc": [533, 1959], "sinc_": 534, "sinh": [535, 1960], "sinh_": 536, "slice_scatt": [538, 1961], "slogdet": [539, 1374, 1962], "smm": [540, 1963], "softmax": [541, 1614, 1744, 1964, 1972], "sort": [542, 1965], "sparse_dim": 543, "sparse_mask": 544, "sparse_resize_": 545, "sparse_resize_and_clear_": 546, "sqrt": [548, 1983], "sqrt_": 549, "squar": [550, 1984], "square_": 551, "squeez": [552, 1985], "squeeze_": 553, "sspaddmm": [554, 1986], "std": [555, 1988], "stft": [556, 1990], "storage_offset": 558, "storage_typ": 559, "stride": 560, "sub": [561, 1991], "sub_": 562, "subtract": [563, 1992], "subtract_": 564, "sum": [565, 1975, 1993, 2118], "sum_to_s": 566, "svd": [567, 1378, 1994], "swapax": [568, 1996], "swapdim": [569, 1997], "t": [570, 2006, 2096, 2135, 2195], "t_": 571, "take": [572, 2007, 2157], "take_along_dim": [573, 2008], "tan": [574, 2009], "tan_": 575, "tanh": [576, 1621, 1749, 2010], "tanh_": 577, "tensor_split": [578, 2012], "tile": [579, 2014], "to_dens": 581, "to_mkldnn": 582, "to_spars": 583, "to_sparse_bsc": 584, "to_sparse_bsr": 585, "to_sparse_coo": 586, "to_sparse_csc": 587, "to_sparse_csr": 588, "tolist": 589, "topk": [590, 2015], "transpos": [592, 2017], "transpose_": 593, "triangular_solv": [594, 2020], "tril": [595, 2021], "tril_": 596, "triu": [597, 2023], "triu_": 598, "true_divid": [599, 2025], "true_divide_": 600, "trunc": [601, 2026], "trunc_": 602, "type_a": 604, "unbind": [605, 2027], "unflatten": [606, 1631, 2028], "unfold": [607, 1632, 1756], "uniform_": 608, "uniqu": [609, 2029], "unique_consecut": [610, 2030], "unsqueez": [611, 2032], "unsqueeze_": 612, "untyped_storag": 613, "var": [615, 2040], "vdot": [616, 2042], "view": [617, 2103, 2117, 2147, 2175, 2202], "view_a": 618, "vsplit": [619, 2046], "where": [620, 2048, 2091, 2204], "xlogi": [621, 2049], "xlogy_": 622, "zero_": 624, "_assert": 625, "_foreach_ab": 626, "_foreach_abs_": 627, "_foreach_aco": 628, "_foreach_acos_": 629, "_foreach_asin": 630, "_foreach_asin_": 631, "_foreach_atan": 632, "_foreach_atan_": 633, "_foreach_ceil": 634, "_foreach_ceil_": 635, "_foreach_co": 636, "_foreach_cos_": 637, "_foreach_cosh": 638, "_foreach_cosh_": 639, "_foreach_erf": 640, "_foreach_erf_": 641, "_foreach_erfc": 642, "_foreach_erfc_": 643, "_foreach_exp": 644, "_foreach_exp_": 645, "_foreach_expm1": 646, "_foreach_expm1_": 647, "_foreach_floor": 648, "_foreach_floor_": 649, "_foreach_frac": 650, "_foreach_frac_": 651, "_foreach_lgamma": 652, "_foreach_lgamma_": 653, "_foreach_log": 654, "_foreach_log10": 655, "_foreach_log10_": 656, "_foreach_log1p": 657, "_foreach_log1p_": 658, "_foreach_log2": 659, "_foreach_log2_": 660, "_foreach_log_": 661, "_foreach_neg": 662, "_foreach_neg_": 663, "_foreach_reciproc": 664, "_foreach_reciprocal_": 665, "_foreach_round": 666, "_foreach_round_": 667, "_foreach_sigmoid": 668, "_foreach_sigmoid_": 669, "_foreach_sin": 670, "_foreach_sin_": 671, "_foreach_sinh": 672, "_foreach_sinh_": 673, "_foreach_sqrt": 674, "_foreach_sqrt_": 675, "_foreach_tan": 676, "_foreach_tan_": 677, "_foreach_trunc": 678, "_foreach_trunc_": 679, "_foreach_zero_": 680, "_log": [681, 2102], "set_log": 681, "current_acceler": 684, "current_device_idx": 685, "current_device_index": 686, "current_stream": [687, 1031, 1060, 1447, 2054], "device_count": [688, 1032, 1063, 1424, 1450, 2056], "is_avail": [689, 1033, 1083, 1455, 2069], "set_device_idx": 690, "set_device_index": 691, "set_stream": [692, 1118, 1462, 2087], "bnrelu2d": [711, 734], "bnrelu3d": [712, 735], "convbn1d": [713, 723], "convbn2d": [714, 724], "convbn3d": [715, 725], "convbnrelu1d": [716, 726], "convbnrelu2d": [717, 727], "convbnrelu3d": [718, 728], "convrelu1d": [719, 736], "convrelu2d": [720, 729, 737], "convrelu3d": [721, 730, 738], "linearrelu": [722, 731, 739, 740], "freeze_bn_stat": 732, "update_bn_stat": 733, "conv2d": [741, 750, 784, 1508, 1662], "conv3d": [742, 751, 785, 1509, 1663], "lstm": [745, 773, 1550, 2146], "multiheadattent": [746, 1586], "batchnorm2d": [747, 1495], "batchnorm3d": [748, 1496], "conv1d": [749, 783, 1507, 1661], "convtranspose1d": [752, 1510], "convtranspose2d": [753, 1511], "convtranspose3d": [754, 1512], "elu": [755, 786, 1521, 1675], "embed": [756, 1522, 1677], "embeddingbag": [757, 1523], "fxfloatfunct": 758, "floatfunct": 759, "groupnorm": [760, 1534], "hardswish": [761, 788, 1537, 1691], "instancenorm1d": [762, 1542], "instancenorm2d": [763, 1543], "instancenorm3d": [764, 1544], "layernorm": [765, 1552], "leakyrelu": [766, 1566], "qfunction": 768, "relu6": [769, 1601, 1733], "gru": [771, 1531], "grucel": [772, 1532], "lstmcell": [774, 1551], "rnncell": [776, 1598], "adaptive_avg_pool2d": [777, 1646], "adaptive_avg_pool3d": [778, 1647], "avg_pool2d": [779, 1654], "avg_pool3d": [780, 1655], "celu": [781, 1498, 1660], "hardsigmoid": [787, 1536, 1690], "hardtanh": [789, 1538, 1692], "interpol": [790, 1697], "leaky_relu": [791, 1701], "max_pool1d": [793, 1711], "max_pool2d": [794, 1712], "threshold": [795, 1623, 1751], "upsampl": [796, 1633, 1757], "upsample_bilinear": [797, 1758], "upsample_nearest": [798, 1759], "custom_kei": 799, "dequantstub": 800, "numeric_debug_handle_kei": 801, "quantstub": 802, "quantwrapp": 803, "add_quant_dequ": 804, "backendconfig": 805, "backendpatternconfig": 806, "dtypeconfig": 807, "dtypewithconstraint": 808, "observationtyp": 809, "compare_result": 810, "convert": [811, 2194], "default_eval_fn": 812, "extract_results_from_logg": 813, "fakequant": [814, 2161], "fakequantizebas": 815, "fixedqparamsfakequant": 816, "fusedmovingavgobsfakequant": 817, "default_fake_qu": 818, "default_fused_act_fake_qu": 819, "default_fused_per_channel_wt_fake_qu": 820, "default_fused_wt_fake_qu": 821, "default_histogram_fake_qu": 822, "default_per_channel_weight_fake_qu": 823, "default_weight_fake_qu": 824, "disable_fake_qu": 825, "disable_observ": 826, "enable_fake_qu": 827, "enable_observ": 828, "fuse_modul": 829, "convertcustomconfig": 830, "fusecustomconfig": 831, "preparecustomconfig": 832, "standalonemoduleconfigentri": 833, "generate_numeric_debug_handl": 834, "affinequantizedobserverbas": 835, "granular": 836, "histogramobserv": 837, "mappingtyp": 838, "minmaxobserv": 839, "movingaverageminmaxobserv": 840, "movingaverageperchannelminmaxobserv": 841, "noopobserv": 842, "observerbas": 843, "peraxi": 844, "perblock": 845, "perchannelminmaxobserv": 846, "pergroup": 847, "perrow": 848, "pertensor": 849, "pertoken": 850, "placeholderobserv": 851, "recordingobserv": 852, "torchaodtyp": 853, "zeropointdomain": 854, "default_debug_observ": 855, "default_dynamic_quant_observ": 856, "default_float_qparams_observ": 857, "default_histogram_observ": 858, "default_observ": 859, "default_per_channel_weight_observ": 860, "default_placeholder_observ": 861, "default_weight_observ": 862, "get_block_s": 863, "get_observer_state_dict": 864, "load_observer_state_dict": 865, "prepar": [866, 2161, 2164], "prepare_for_propagation_comparison": 867, "prepare_qat": 868, "propagate_qconfig": 869, "model_is_export": 870, "qconfig": [871, 2161, 2164], "default_activation_only_qconfig": 872, "default_debug_qconfig": 873, "default_dynamic_qconfig": 874, "default_per_channel_qconfig": 875, "default_qat_qconfig": 876, "default_qat_qconfig_v2": 877, "default_qconfig": 878, "default_weight_only_qconfig": 879, "float16_dynamic_qconfig": 880, "float16_static_qconfig": 881, "float_qparams_weight_only_qconfig": 882, "per_channel_dynamic_qconfig": 883, "qconfigmap": 884, "get_default_qat_qconfig_map": 885, "get_default_qconfig_map": 886, "quantize_dynam": 888, "convert_fx": 889, "fuse_fx": 890, "prepare_fx": 891, "prepare_qat_fx": 892, "quantize_qat": 893, "swap_modul": 894, "arang": 895, "are_deterministic_algorithms_en": 903, "as_tensor": 909, "asarrai": 910, "atleast_1d": 916, "atleast_2d": 917, "atleast_3d": 918, "unpackeddualtensor": 924, "dual_level": 925, "forward_ad": [926, 927, 928, 929], "enter_dual_level": 926, "exit_dual_level": 927, "make_du": 928, "unpack_du": 929, "backwardcfunct": 930, "functionctx": [931, 932, 933, 934], "mark_dirti": 931, "mark_non_differenti": 932, "save_for_backward": 933, "set_materialize_grad": 934, "inplacefunct": 935, "nestediofunct": 936, "once_differenti": 937, "hvp": 939, "vhp": 942, "inference_mod": 945, "set_grad_en": 946, "set_multithreading_en": 947, "gradcheck": [948, 949, 950, 2138], "gradcheckerror": 948, "gradgradcheck": [950, 2138], "name": [952, 2095, 2115, 2116, 2157], "next_funct": 953, "register_prehook": 955, "increment_vers": 956, "enforceuniqu": 957, "kinetosteptrack": 958, "load_nvprof": 959, "parse_nvprof_trac": 960, "export_chrome_trac": 961, "key_averag": 962, "self_cpu_time_tot": 963, "total_averag": 964, "record_funct": 965, "interv": 966, "memrecordsacc": 968, "stringtabl": 969, "bartlett_window": 971, "blackman_window": 980, "block_diag": 981, "broadcast_shap": 983, "broadcast_tensor": 984, "bucket": 986, "can_cast": 987, "cartesian_prod": 988, "cat": 989, "cdist": 990, "chain_matmul": 992, "column_stack": 1000, "combin": [1001, 2133], "compiled_with_cxx11_abi": 1003, "allow_in_graph": [1004, 2196], "cudagraph_mark_step_begin": 1007, "is_compil": 1009, "is_dynamo_compil": 1010, "is_export": 1011, "list_backend": 1012, "reset": 1013, "set_stanc": 1014, "substitute_in_graph": 1015, "concat": 1017, "concaten": 1018, "streamcontext": [1029, 1045, 1445, 2052], "current_devic": [1030, 1059, 1446, 2053], "set_devic": [1034, 1114, 1460, 2084], "cudapluggablealloc": 1038, "externalstream": 1040, "mempool": 1041, "mempoolcontext": 1042, "outofmemoryerror": 1043, "caching_allocator_alloc": 1046, "caching_allocator_delet": 1047, "can_device_access_p": 1048, "change_current_alloc": 1049, "clock_rat": 1050, "comm": [1051, 1052, 1053, 1054, 1055, 1056], "broadcast": [1051, 2128], "broadcast_coalesc": 1052, "reduce_add": 1054, "reduce_add_coalesc": 1055, "cudart": 1057, "current_blas_handl": 1058, "default_stream": [1061, 1448], "device_memory_us": 1064, "device_of": [1065, 2057], "empty_cach": [1066, 1426, 1451, 2058], "get_allocator_backend": 1067, "get_arch_list": [1068, 2059], "get_device_cap": [1069, 1452, 2060], "get_device_nam": [1070, 2061], "get_device_properti": [1071, 2062], "get_gencode_flag": [1072, 2063], "get_per_process_memory_fract": 1073, "get_rng_stat": [1074, 1267, 1428, 1453, 2064], "get_rng_state_al": [1075, 2065], "get_stream_from_extern": [1076, 2066], "get_sync_debug_mod": 1077, "graph_pool_handl": 1079, "init": [1080, 1454, 2067, 2124], "initial_se": [1081, 1290, 2068], "ipc_collect": 1082, "is_current_stream_captur": 1084, "is_initi": [1085, 1456, 2070], "_create_jit_fn": 1086, "_create_multi_output_jit_fn": 1087, "list_gpu_process": 1088, "make_graphed_cal": 1089, "manual_se": [1090, 1407, 1429, 2071], "manual_seed_al": [1091, 2072], "max_memory_alloc": [1092, 2073], "max_memory_cach": 1093, "max_memory_reserv": [1094, 2074], "mem_get_info": [1095, 2075], "caching_allocator_en": 1096, "memory_alloc": [1097, 2076], "memory_cach": 1098, "memory_reserv": [1099, 2077], "memory_snapshot": 1100, "memory_stat": [1101, 1457, 1458, 2078], "memory_summari": 1102, "memory_usag": 1103, "mark": 1104, "rang": [1105, 1908, 2095], "range_pop": 1106, "range_push": 1107, "power_draw": 1108, "reset_max_memory_alloc": 1109, "reset_max_memory_cach": 1110, "reset_peak_memory_stat": [1111, 2081], "seed": [1112, 1437, 1929, 2082], "seed_al": [1113, 2083], "set_per_process_memory_fract": [1115, 1438], "set_rng_stat": [1116, 1439, 1461, 1941, 2085], "set_rng_state_al": [1117, 2086], "set_sync_debug_mod": 1119, "temperatur": 1121, "cumulative_trapezoid": 1127, "dstack": 1143, "einsum": 1144, "empti": 1145, "empty_lik": 1146, "empty_strid": 1147, "enable_grad": 1148, "exp2": 1155, "ey": 1157, "fake_quantize_per_channel_affin": 1158, "fake_quantize_per_tensor_affin": 1159, "fft2": 1161, "fftfreq": 1162, "fftn": 1163, "fftshift": 1164, "hfft": 1165, "hfft2": 1166, "hfftn": 1167, "ifft": 1168, "ifft2": 1169, "ifftn": 1170, "ifftshift": 1171, "ihfft": 1172, "ihfft2": 1173, "ihfftn": 1174, "irfft": 1175, "irfft2": 1176, "irfftn": 1177, "rfft": 1178, "rfft2": 1179, "rfftfreq": 1180, "rfftn": 1181, "from_dlpack": 1195, "from_fil": 1196, "from_numpi": 1197, "frombuff": 1198, "full": [1199, 2130, 2147], "full_lik": 1200, "functional_cal": [1201, 1822], "grad_and_valu": 1204, "replace_all_batch_norm_modules_": 1210, "stack_module_st": 1211, "get_proxy_mod": 1214, "handle_sym_dispatch": 1215, "make_fx": 1216, "maybe_disable_thunkifi": 1217, "maybe_enable_thunkifi": 1218, "callmethodkei": 1219, "convertintkei": 1220, "dimconstraint": 1221, "dimdynam": [1222, 2191], "dividebykei": 1223, "equalityconstraint": 1224, "innertensorkei": 1225, "propagateunbackedsymint": 1226, "relaxedunspecconstraint": 1227, "shapeenv": 1228, "shapeenvset": 1229, "statefulsymboliccontext": 1230, "statelesssymboliccontext": 1231, "strictminmaxconstraint": 1232, "subclasssymboliccontext": 1233, "symboliccontext": 1234, "canonicalize_bool_expr": 1235, "check_consist": 1236, "compute_unbacked_bind": 1237, "constrain_rang": 1238, "constrain_unifi": 1239, "definitely_fals": 1240, "definitely_tru": 1241, "guard_size_oblivi": 1242, "has_free_symbol": 1243, "has_free_unbacked_symbol": 1244, "hint_int": 1245, "is_accessor_nod": 1246, "is_concrete_bool": 1247, "is_concrete_float": 1248, "is_concrete_int": 1249, "lru_cach": 1250, "rebind_unback": 1251, "resolve_unbacked_bind": 1252, "statically_known_tru": 1253, "sym_eq": 1254, "get_default_devic": 1260, "get_default_dtyp": 1261, "get_deterministic_debug_mod": 1262, "get_device_modul": 1263, "get_float32_matmul_precis": 1264, "get_num_interop_thread": 1265, "get_num_thread": 1266, "hamming_window": 1272, "hann_window": 1273, "histogramdd": 1277, "hspmm": 1279, "hstack": 1280, "is_deterministic_algorithms_warn_only_en": 1295, "is_grad_en": 1297, "is_inference_mode_en": 1298, "is_nonzero": 1299, "is_storag": 1300, "is_tensor": 1301, "is_warn_always_en": 1302, "isin": 1305, "attribut": [1312, 2093, 2095, 2096, 2098, 2174], "scriptfunct": 1313, "scriptmodul": [1314, 2147], "annot": [1315, 2096], "enable_onednn_fus": 1316, "fork": 1317, "freez": 1318, "ignor": 1319, "isinst": 1321, "onednn_fusion_en": 1323, "optimize_for_infer": 1324, "save": [1325, 1924, 2091, 2127, 2140, 2147, 2161], "script_if_trac": 1327, "set_fusion_strategi": 1328, "strict_fus": 1329, "trace_modul": 1331, "unus": 1332, "wait": 1333, "kaiser_window": 1334, "kron": 1335, "cholesky_ex": 1345, "eig": 1350, "eigh": 1351, "eigval": 1352, "eigvalsh": 1353, "householder_product": 1354, "inv": 1355, "inv_ex": 1356, "ldl_factor": 1357, "ldl_factor_ex": 1358, "ldl_solv": 1359, "lstsq": 1360, "lu_factor": 1362, "lu_factor_ex": 1363, "matrix_norm": 1367, "matrix_rank": 1369, "multi_dot": 1370, "pinv": 1372, "solv": 1375, "solve_ex": 1376, "solve_triangular": 1377, "svdval": 1379, "tensorinv": 1380, "tensorsolv": 1381, "vander": [1382, 2039], "vecdot": 1383, "vector_norm": 1384, "linspac": 1385, "lobpcg": 1387, "logspac": 1401, "lu_unpack": 1406, "meshgrid": 1416, "current_allocated_memori": 1423, "driver_allocated_memori": 1425, "is_capturing_met": 1430, "is_metal_capture_en": 1431, "metal_captur": 1432, "stop": 1435, "recommended_max_memori": 1436, "mtia": [1442, 1444, 1446, 1447, 1448, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 2112, 2113], "deferredmtiacallerror": 1442, "record_memory_histori": 1459, "snapshot": [1463, 2207], "adaptiveavgpool1d": 1481, "adaptiveavgpool2d": 1482, "adaptiveavgpool3d": 1483, "adaptivelogsoftmaxwithloss": 1484, "adaptivemaxpool1d": 1485, "adaptivemaxpool2d": 1486, "adaptivemaxpool3d": 1487, "alphadropout": 1488, "avgpool1d": 1489, "avgpool2d": 1490, "avgpool3d": 1491, "bceloss": 1492, "bcewithlogitsloss": 1493, "batchnorm1d": 1494, "bilinear": [1497, 1657], "ctcloss": 1499, "channelshuffl": 1500, "circularpad1d": 1501, "circularpad2d": 1502, "circularpad3d": 1503, "constantpad1d": 1504, "constantpad2d": 1505, "constantpad3d": 1506, "cosineembeddingloss": 1513, "cosinesimilar": 1514, "crossentropyloss": 1515, "dataparallel": [1516, 2118, 2123, 2126, 2130], "dropout": [1517, 1671, 2118, 2123], "dropout1d": [1518, 1672], "dropout2d": [1519, 1673], "dropout3d": [1520, 1674], "featurealphadropout": 1524, "fold": [1526, 1680], "fractionalmaxpool2d": 1527, "fractionalmaxpool3d": 1528, "gelu": [1529, 1684], "glu": [1530, 1685], "gaussiannllloss": 1533, "hingeembeddingloss": 1539, "huberloss": 1540, "ident": [1541, 1797, 2096, 2135], "kldivloss": 1545, "l1loss": 1546, "lppool1d": 1547, "lppool2d": 1548, "lppool3d": 1549, "lazybatchnorm1d": 1553, "lazybatchnorm2d": 1554, "lazybatchnorm3d": 1555, "lazyconv1d": 1556, "lazyconv2d": 1557, "lazyconv3d": 1558, "lazyconvtranspose1d": 1559, "lazyconvtranspose2d": 1560, "lazyconvtranspose3d": 1561, "lazyinstancenorm1d": 1562, "lazyinstancenorm2d": 1563, "lazyinstancenorm3d": 1564, "lazylinear": 1565, "localresponsenorm": 1568, "logsigmoid": [1569, 1706], "logsoftmax": 1570, "mseloss": 1571, "marginrankingloss": 1572, "maxpool1d": 1573, "maxpool2d": 1574, "maxpool3d": 1575, "maxunpool1d": 1576, "maxunpool2d": 1577, "maxunpool3d": 1578, "mish": [1579, 1717], "moduledict": [1581, 2096], "modulelist": [1582, 2095, 2096], "multilabelmarginloss": 1583, "multilabelsoftmarginloss": 1584, "multimarginloss": 1585, "nllloss": 1587, "prelu": [1588, 1731], "pairwisedist": 1589, "parameterdict": 1590, "parameterlist": 1591, "pixelshuffl": 1592, "pixelunshuffl": 1593, "poissonnllloss": 1594, "rmsnorm": [1595, 1769], "rnn": [1596, 1814, 1815, 1816, 1817, 1818, 1819, 2146], "rnnbase": 1597, "rrelu": [1599, 1736], "relu": [1600, 1732], "reflectionpad1d": 1602, "reflectionpad2d": 1603, "reflectionpad3d": 1604, "replicationpad1d": 1605, "replicationpad2d": 1606, "replicationpad3d": 1607, "selu": [1608, 1739], "sequenti": 1609, "silu": [1610, 1741], "smoothl1loss": 1612, "softmarginloss": 1613, "softmax2d": 1615, "softmin": [1616, 1745], "softplu": [1617, 1746], "softshrink": [1618, 1747], "softsign": [1619, 1748], "syncbatchnorm": 1620, "tanhshrink": [1622, 1750], "transformerdecod": 1625, "transformerdecoderlay": 1626, "transformerencod": 1627, "transformerencoderlay": 1628, "tripletmarginloss": 1629, "tripletmarginwithdistanceloss": 1630, "upsamplingbilinear2d": 1634, "upsamplingnearest2d": 1635, "zeropad1d": 1636, "zeropad2d": 1637, "zeropad3d": 1638, "sdpbackend": 1639, "attent": [1640, 1642, 1643, 1644, 2117, 2119, 2120, 2121, 2122, 2123, 2145], "bia": [1640, 1642, 1643, 2120], "causalbia": [1640, 2120], "causalvari": 1641, "causal_lower_right": 1642, "causal_upper_left": 1643, "sdpa_kernel": 1644, "adaptive_avg_pool1d": 1645, "adaptive_max_pool1d": 1648, "adaptive_max_pool2d": 1649, "adaptive_max_pool3d": 1650, "affine_grid": 1651, "alpha_dropout": 1652, "avg_pool1d": 1653, "batch_norm": 1656, "conv_transpose1d": 1664, "conv_transpose2d": 1665, "conv_transpose3d": 1666, "cosine_embedding_loss": 1667, "cosine_similar": 1668, "cross_entropi": 1669, "ctc_loss": 1670, "elu_": 1676, "embedding_bag": 1678, "feature_alpha_dropout": 1679, "fractional_max_pool2d": 1681, "fractional_max_pool3d": 1682, "gaussian_nll_loss": 1683, "grid_sampl": 1686, "group_norm": 1687, "gumbel_softmax": 1688, "hardtanh_": 1693, "hinge_embedding_loss": 1694, "huber_loss": 1695, "instance_norm": 1696, "kl_div": 1698, "l1_loss": 1699, "layer_norm": 1700, "leaky_relu_": 1702, "local_response_norm": 1704, "log_softmax": [1705, 1969], "lp_pool1d": 1707, "lp_pool2d": 1708, "lp_pool3d": 1709, "margin_ranking_loss": 1710, "max_pool3d": 1713, "max_unpool1d": 1714, "max_unpool2d": 1715, "max_unpool3d": 1716, "mse_loss": 1718, "multi_margin_loss": 1719, "multilabel_margin_loss": 1720, "multilabel_soft_margin_loss": 1721, "nll_loss": 1722, "one_hot": 1724, "pad": [1725, 2117, 2118], "pairwise_dist": 1726, "pdist": 1727, "pixel_shuffl": 1728, "pixel_unshuffl": 1729, "poisson_nll_loss": 1730, "relu_": 1734, "rms_norm": 1735, "rrelu_": 1737, "scaled_dot_product_attent": 1738, "smooth_l1_loss": 1742, "soft_margin_loss": 1743, "threshold_": 1752, "data_parallel": [1753, 2123], "triplet_margin_loss": 1754, "triplet_margin_with_distance_loss": 1755, "lazymodulemixin": 1760, "register_module_backward_hook": 1761, "register_module_buffer_registration_hook": 1762, "register_module_forward_hook": 1763, "register_module_forward_pre_hook": 1764, "register_module_full_backward_hook": 1765, "register_module_full_backward_pre_hook": 1766, "register_module_module_registration_hook": 1767, "register_module_parameter_registration_hook": 1768, "distributeddataparallel": [1770, 2126, 2130, 2132], "buffer": [1771, 2130, 2136, 2144], "uninitializedbuff": 1773, "uninitializedparamet": 1774, "clip_grad_norm": 1775, "clip_grad_norm_": 1776, "clip_grad_value_": 1777, "clip_grads_with_norm_": 1778, "convert_conv2d_weight_memory_format": 1779, "convert_conv3d_weight_memory_format": 1780, "fuse_conv_bn_ev": 1781, "fuse_conv_bn_weight": 1782, "fuse_linear_bn_ev": 1783, "fuse_linear_bn_weight": 1784, "get_total_norm": 1785, "parameters_to_vector": 1786, "parametr": [1787, 1788, 1789, 1791, 1792, 1793, 1794, 2142], "orthogon": 1787, "spectral_norm": [1788, 1821], "weight_norm": [1789, 1824], "parametrizationlist": 1790, "cach": [1791, 2091, 2130, 2139, 2204, 2205], "is_parametr": 1792, "register_parametr": 1793, "remove_parametr": 1794, "basepruningmethod": 1795, "customfrommask": 1796, "prune": [1797, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 2142], "l1unstructur": 1798, "lnstructur": 1799, "pruningcontain": 1800, "randomstructur": 1801, "randomunstructur": 1802, "custom_from_mask": 1803, "global_unstructur": 1804, "is_prun": 1805, "l1_unstructur": 1806, "ln_structur": 1807, "random_structur": 1808, "random_unstructur": 1809, "remove_spectral_norm": 1811, "remove_weight_norm": 1812, "packedsequ": 1813, "pack_padded_sequ": 1814, "pack_sequ": 1815, "pad_packed_sequ": 1816, "pad_sequ": 1817, "unpack_sequ": 1818, "unpad_sequ": 1819, "skip_init": 1820, "stateless": 1822, "vector_to_paramet": 1823, "no_grad": 1825, "ones": [1831, 2195], "ones_lik": 1832, "jitscalartyp": 1833, "graphinfo": 1834, "verificationopt": 1835, "asgd": 1836, "adadelta": 1837, "adafactor": 1838, "adagrad": 1839, "adam": 1840, "adamw": 1841, "adamax": 1842, "lbfg": 1843, "nadam": 1844, "add_param_group": 1845, "load_state_dict": 1846, "register_load_state_dict_post_hook": 1847, "register_load_state_dict_pre_hook": 1848, "register_state_dict_post_hook": 1849, "register_state_dict_pre_hook": 1850, "register_step_post_hook": 1851, "register_step_pre_hook": 1852, "state_dict": [1853, 2200], "zero_grad": 1855, "radam": 1856, "rmsprop": 1857, "rprop": 1858, "sgd": 1859, "sparseadam": 1860, "chainedschedul": 1861, "constantlr": 1862, "cosineannealinglr": 1863, "cosineannealingwarmrestart": 1864, "cycliclr": 1865, "exponentiallr": 1866, "lrschedul": 1867, "lambdalr": 1868, "linearlr": 1869, "multisteplr": 1870, "multiplicativelr": 1871, "onecyclelr": 1872, "polynomiallr": 1873, "reducelronplateau": 1874, "sequentiallr": 1875, "steplr": 1876, "averagedmodel": 1877, "swalr": 1878, "pca_lowrank": 1882, "polar": 1886, "promote_typ": 1891, "quantize_per_channel": 1894, "quantize_per_tensor": 1895, "quantized_batch_norm": 1896, "quantized_max_pool1d": 1897, "quantized_max_pool2d": 1898, "sobolengin": 1899, "rand": 1901, "rand_lik": 1902, "randint": 1903, "randint_lik": 1904, "randn": 1905, "randn_lik": 1906, "randperm": 1907, "result_typ": 1918, "row_stack": 1922, "searchsort": 1928, "set_default_devic": 1932, "set_default_dtyp": 1933, "set_default_tensor_typ": 1934, "set_deterministic_debug_mod": 1935, "set_float32_matmul_precis": 1936, "set_flush_denorm": 1937, "set_num_interop_thread": 1938, "set_num_thread": 1939, "set_printopt": 1940, "set_warn_alwai": 1942, "signal": [1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 2169], "bartlett": 1946, "blackman": 1947, "cosin": 1948, "gaussian": 1950, "general_cosin": 1951, "general_ham": 1952, "ham": 1953, "hann": 1954, "kaiser": 1955, "nuttal": 1956, "as_sparse_gradcheck": 1967, "check_sparse_tensor_invari": 1968, "sampled_addmm": 1971, "spdiag": 1973, "spsolv": 1974, "sparse_bsc_tensor": 1976, "sparse_bsr_tensor": 1977, "sparse_compressed_tensor": 1978, "sparse_coo_tensor": 1979, "sparse_csc_tensor": 1980, "sparse_csr_tensor": 1981, "std_mean": 1989, "svd_lowrank": 1995, "sym_float": 1998, "sym_fresh_s": 1999, "sym_int": 2000, "sym_it": 2001, "sym_max": 2002, "sym_min": 2003, "sym_not": 2004, "sym_sum": 2005, "tensordot": 2013, "trapezoid": 2018, "trapz": 2019, "tril_indic": 2022, "triu_indic": 2024, "unravel_index": 2031, "use_deterministic_algorithm": 2033, "generate_methods_for_privateuse1_backend": 2034, "get_cpp_backtrac": 2035, "rename_privateuse1_backend": 2036, "set_modul": 2037, "swap_tensor": 2038, "var_mean": 2041, "view_as_complex": 2043, "view_as_r": 2044, "vstack": 2047, "memory_stats_as_nested_dict": 2079, "reset_accumulated_memory_stat": 2080, "zero": [2089, 2171], "zeros_lik": 2090, "hub": 2091, "publish": 2091, "entrypoint": 2091, "run": [2091, 2201], "my": [2091, 2127, 2135, 2158, 2195, 2201], "download": 2091, "known": [2091, 2093], "tabl": [2092, 2147], "built": [2093, 2094, 2096, 2154], "comparison": [2093, 2095, 2096, 2180, 2189], "inspect": [2093, 2150, 2193], "warn": 2093, "appendix": [2093, 2096], "recurs": 2093, "constant": [2093, 2095, 2180, 2204], "fusion": 2093, "math": [2094, 2180], "unsupport": [2095, 2096, 2098, 2154, 2155], "construct": [2095, 2096, 2098, 2117, 2157, 2171], "refin": [2095, 2096], "enum": [2095, 2096], "tupl": [2095, 2096], "liter": [2095, 2096], "list": [2095, 2096, 2154], "dict": [2095, 2157], "arithmet": [2095, 2096], "subscript": [2095, 2096], "slice": [2095, 2096, 2145, 2180], "call": [2095, 2096, 2133, 2134, 2195], "ternari": [2095, 2096], "cast": 2095, "statement": [2095, 2096], "assign": [2095, 2096], "match": [2095, 2116], "If": 2095, "while": [2095, 2096], "loop": 2095, "For": 2095, "continu": [2095, 2096], "return": [2095, 2096, 2135, 2168], "resolut": [2095, 2096], "lookup": 2095, "defin": [2095, 2133, 2134], "terminologi": [2096, 2204], "instanc": 2096, "when": [2096, 2127, 2133, 2150, 2154, 2161, 2171, 2195], "signatur": 2096, "expr": 2096, "convers": [2096, 2117, 2150], "atom": 2096, "identifi": [2096, 2195, 2205], "parenthes": 2096, "form": 2096, "displai": 2096, "primari": 2096, "power": 2096, "unari": [2096, 2103, 2171], "bitwis": 2096, "binari": [2096, 2103, 2137], "shift": 2096, "boolean": 2096, "condit": 2096, "augment": 2096, "rais": 2096, "del": 2096, "pass": [2096, 2130, 2144, 2161, 2167, 2203], "compound": 2096, "els": 2096, "getattr": 2096, "hasattr": 2096, "zip": [2096, 2158], "enumer": 2096, "remot": [2096, 2168], "procedur": 2096, "coverag": [2097, 2115, 2133], "properti": [2098, 2101], "correctli": 2098, "bound": 2098, "schema": 2098, "between": [2098, 2158, 2195], "low": 2100, "matrix": [2101, 2161], "decomposit": 2101, "solver": 2101, "misc": 2101, "motiv": [2103, 2191, 2194], "reduct": [2103, 2130, 2145, 2180], "idiom": 2104, "miscellan": 2105, "mobile_optim": 2106, "model_zoo": 2107, "module_track": 2108, "strategi": [2114, 2157], "descriptor": 2114, "file_descriptor": 2114, "file_system": 2114, "keep": [2115, 2158], "dimens": [2115, 2116], "unifi": 2115, "contract": 2115, "awai": 2115, "variant": 2115, "semant": [2116, 2128, 2130, 2139, 2147], "explicit": 2116, "align": 2116, "subsystem": 2116, "constitu": 2117, "troubleshoot": [2117, 2147, 2185, 2204, 2205], "unimpl": 2117, "rag": 2117, "incompat": 2117, "within": 2117, "detail": [2117, 2122, 2194], "convolut": [2118, 2123, 2145, 2146], "layer": 2118, "pool": [2118, 2123], "activ": [2118, 2123, 2207], "weight": [2118, 2157], "nonlinear": 2118, "recurr": [2118, 2135], "distanc": [2118, 2123], "loss": [2118, 2123, 2126], "vision": [2118, 2123], "shuffl": 2118, "lazi": 2118, "alias": 2118, "submodul": 2119, "flex_attent": 2122, "blockmask": 2122, "typic": 2126, "unscal": 2126, "accumul": 2126, "penalti": 2126, "one": 2126, "per": [2126, 2157], "need": [2126, 2195], "particular": [2126, 2127], "dtype": [2126, 2147, 2164, 2174], "encod": 2127, "histori": [2127, 2207], "set": [2127, 2154, 2204], "No": 2127, "evalu": [2127, 2138, 2192], "multithread": 2127, "concurr": 2127, "determin": [2127, 2146], "retain": 2127, "thread": [2127, 2129, 2179], "safeti": 2127, "wirting": 2127, "calculu": 2127, "pictur": 2127, "conjug": 2127, "formula": 2127, "domain": 2127, "regist": [2127, 2190], "whether": [2127, 2158], "fire": 2127, "modifi": 2127, "compat": 2128, "tensorfloat": [2130, 2139, 2145], "32": [2130, 2139, 2145, 2148], "tf32": [2130, 2139, 2145], "amper": [2130, 2145], "later": [2130, 2145, 2158], "reduc": [2130, 2145], "fp16": [2130, 2145], "gemm": [2130, 2145], "bf16": [2130, 2145], "accmumul": 2130, "bc": 2130, "pytorch_cuda_alloc_conf": 2130, "alloc": [2130, 2135, 2207], "same": 2130, "cubla": 2130, "workspac": [2130, 2139], "cufft": 2130, "plan": [2130, 2139], "just": 2130, "time": [2130, 2185, 2198, 2202, 2204, 2205], "practic": [2130, 2144, 2161, 2188], "agnost": 2130, "instead": 2130, "whole": [2130, 2195], "captur": 2130, "partial": 2130, "9": 2130, "6": 2130, "across": [2130, 2147], "land": 2131, "page": 2131, "intern": [2132, 2154, 2158, 2191, 2193], "processgroup": 2132, "ddpoptim": 2132, "setup_context": 2133, "like": [2133, 2158], "subclass": [2133, 2194], "wrapper": 2133, "__torch_function__": 2133, "overrid": [2133, 2206], "nativ": [2133, 2161, 2163], "__torch_dispatch__": 2133, "convent": 2133, "anoth": 2134, "specifi": 2134, "gotcha": 2134, "staticmethod": 2134, "isn": 2135, "freed": 2135, "properli": 2135, "loader": 2135, "doesn": 2135, "prefetch": 2136, "nuanc": 2136, "payload": 2136, "intel": [2137, 2159], "hardwar": [2137, 2161], "prerequisit": 2137, "softwar": 2137, "instal": [2137, 2148], "fp32": 2137, "notat": 2138, "background": [2138, 2167, 2168, 2189], "inform": [2138, 2166, 2203], "analyt": 2138, "u": 2138, "reus": [2139, 2144], "hipbla": 2139, "hipfft": 2139, "rocfft": 2139, "larg": 2140, "fleet": 2140, "wide": 2140, "attach": 2140, "consider": 2140, "libtorch": 2141, "stabl": 2141, "abi": 2141, "block": 2142, "neural": 2142, "tip": [2144, 2162], "fight": 2144, "deadlock": 2144, "through": 2144, "queue": 2144, "e": 2144, "g": 2144, "hogwild": 2144, "oversubscript": 2144, "accuraci": [2145, 2161, 2162, 2205], "extrem": 2145, "finit": 2145, "sdpa": 2145, "instinct": 2145, "mi200": 2145, "reproduc": [2146, 2204], "nondeterminist": 2146, "algorithm": [2146, 2157, 2167], "fill": 2146, "uniniti": 2146, "dataload": 2146, "content": [2147, 2158], "preserv": [2147, 2171], "format": [2147, 2158], "weights_onli": 2147, "true": 2147, "unsaf": 2147, "global": [2147, 2158], "them": [2147, 2158], "version": 2147, "integ": 2147, "divis": 2147, "alwai": [2147, 2192], "config": [2147, 2184], "includ": [2148, 2158], "compon": 2148, "speed": [2148, 2195], "One": [2148, 2203], "cffi": 2148, "cpp": 2148, "found": 2148, "win": 2148, "channel": 2148, "without": 2148, "claus": 2148, "protect": 2148, "broken": 2148, "pipe": 2148, "driver": 2148, "shut": 2148, "down": 2148, "ipc": 2148, "base": [2149, 2150, 2151, 2154, 2157, 2203], "gui": 2150, "fail": 2150, "understand": [2151, 2202, 2207], "alexnet": 2154, "index": [2154, 2180], "aten": [2154, 2199, 2203], "inlin": 2154, "discov": 2154, "unconvert": 2154, "onc": 2154, "verif": 2156, "adjust": 2157, "learn": 2157, "rate": 2157, "averag": 2157, "swa": 2157, "ema": 2157, "care": 2157, "put": 2157, "togeth": 2157, "do": [2158, 2193, 2195], "see": [2158, 2195], "insid": [2158, 2195], "treat": 2158, "archiv": 2158, "file_structur": 2158, "given": 2158, "wa": 2158, "distinguish": 2158, "explan": 2158, "find": [2158, 2202], "analyz": 2158, "extern": 2158, "mock": 2158, "refactor": 2158, "sharp": 2158, "isol": 2158, "each": [2158, 2194], "mangl": 2158, "instrument": 2159, "technologi": 2159, "eager": 2161, "awar": 2161, "mainten": 2161, "engin": 2161, "observ": [2161, 2164], "configur": [2161, 2163], "insensit": 2162, "int8": 2162, "sensit": 2162, "top": 2164, "quantize_fx": 2164, "qconfig_map": 2164, "backend_config": 2164, "custom_config": 2164, "pt2e": 2164, "0": [2164, 2192, 2200, 2201, 2205], "export_util": 2164, "relat": [2164, 2194, 2204], "fake_quant": 2164, "intrins": 2164, "qat": 2164, "scheme": 2164, "rpc": 2166, "tensorpip": 2166, "rref": [2166, 2168], "remotemodul": 2166, "record": 2167, "dure": 2167, "smart": 2167, "end": 2167, "protocol": 2168, "lifetim": 2168, "reason": [2168, 2189], "scenario": 2168, "owner": 2168, "argument": 2168, "sparsiti": 2171, "semi": 2171, "coo": 2171, "hybrid": 2171, "uncoalesc": 2171, "compress": 2171, "csr": 2171, "csc": 2171, "bsr": 2171, "bsc": 2171, "untyp": 2173, "memory_format": 2174, "tensorboard": 2176, "creation": 2180, "sampl": 2180, "quasi": 2180, "pointwis": 2180, "spectral": 2180, "bla": 2180, "lapack": 2180, "foreach": 2180, "path": 2180, "n": [2181, 2182], "_numeric_suit": 2181, "_numeric_suite_fx": 2182, "howto": 2183, "vendor": 2183, "aotinductor": [2185, 2186], "ahead": 2185, "Of": 2185, "ed": 2185, "minifi": [2186, 2204, 2205], "result": [2186, 2195], "integr": 2189, "callabl": 2189, "previou": 2189, "skip": 2189, "after": 2190, "aotautograd": [2190, 2204], "speedi": 2190, "abridg": 2191, "public": 2191, "overal": [2191, 2194], "architectur": [2191, 2194], "dynamo": [2192, 2193, 2204], "gentl": 2192, "pep": 2192, "523": 2192, "frame": 2192, "cpython": 2192, "sound": 2192, "duck": 2192, "complet": 2192, "conclus": 2192, "footnot": 2192, "artifact": 2193, "bit": 2194, "individu": [2194, 2198], "characterist": 2194, "interact": 2194, "you": 2195, "still": 2195, "crash": 2195, "slow": 2195, "recompil": [2195, 2204, 2205], "am": 2195, "speedup": 2195, "caus": [2195, 2205], "didn": 2195, "incorrect": [2195, 2204], "oom": 2195, "besid": 2195, "via": 2195, "under": 2195, "some": 2195, "did": 2195, "fine": [2195, 2196], "grain": [2195, 2196], "_dynamo": [2195, 2196], "disallow_in_graph": [2195, 2196], "_dynamo_skip": 2195, "pretrain": 2197, "next": 2197, "relev": 2198, "breakdown": 2198, "triton": 2198, "prim": 2199, "nnmodul": 2200, "__call__": 2200, "dashboard": 2201, "measur": 2201, "pr": 2201, "affect": 2201, "befor": 2201, "merg": 2201, "around": 2202, "region": 2202, "compiledfunct": 2202, "overhead": 2202, "x": 2203, "none": 2203, "partition": 2203, "matcher": 2203, "capabl": 2203, "expect": 2204, "tlpars": 2204, "torch_trac": 2204, "torch_log": 2204, "workaround": 2204, "appli": 2204, "suppress": 2204, "resolv": 2204, "deal": 2204, "wrap": 2204, "ablat": 2204, "bisect": 2204, "deeper": 2204, "bytecod": 2204, "articl": 2204, "titl": 2205, "diagnos": 2205, "torch_compile_debug": 2205, "excess": 2205, "cold": 2205, "corrupt": 2205, "visual": 2207, "timelin": 2207, "processgroupnccl": 2209, "finfo": 2210, "iinfo": 2210}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx": 57}, "alltitles": {"torch.Tensor.mul_": [[420, "torch-tensor-mul"]], "torch.Tensor.logaddexp": [[378, "torch-tensor-logaddexp"]], "torch.Tensor.logsumexp": [[392, "torch-tensor-logsumexp"]], "torch.Tensor.logical_xor_": [[389, "torch-tensor-logical-xor"]], "torch.Tensor.long": [[393, "torch-tensor-long"]], "torch.Tensor.lt_": [[395, "torch-tensor-lt"]], "torch.Tensor.logical_and_": [[383, "torch-tensor-logical-and"]], "torch.Tensor.masked_select": [[403, "torch-tensor-masked-select"]], "torch.Tensor.msort": [[418, "torch-tensor-msort"]], "torch.Tensor.masked_fill": [[399, "torch-tensor-masked-fill"]], "torch.Tensor.matmul": [[404, "torch-tensor-matmul"]], "torch.Tensor.max": [[407, "torch-tensor-max"]], "torch.Tensor.map_": [[398, "torch-tensor-map"]], "torch.Tensor.mean": [[409, "torch-tensor-mean"]], "torch.Tensor.median": [[410, "torch-tensor-median"]], "torch.Tensor.logdet": [[381, "torch-tensor-logdet"]], "torch.Tensor.logical_and": [[382, "torch-tensor-logical-and"]], "torch.Tensor.multinomial": [[421, "torch-tensor-multinomial"]], "torch.Tensor.lt": [[394, "torch-tensor-lt"]], "torch.Tensor.logical_xor": [[388, "torch-tensor-logical-xor"]], "torch.Tensor.movedim": [[417, "torch-tensor-movedim"]], "torch.Tensor.moveaxis": [[416, "torch-tensor-moveaxis"]], "torch.Tensor.logical_not": [[384, "torch-tensor-logical-not"]], "torch.Tensor.min": [[411, "torch-tensor-min"]], "torch.Tensor.logcumsumexp": [[380, "torch-tensor-logcumsumexp"]], "torch.Tensor.logaddexp2": [[379, "torch-tensor-logaddexp2"]], "torch.Tensor.mode": [[414, "torch-tensor-mode"]], "torch.Tensor.log_normal_": [[377, "torch-tensor-log-normal"]], "torch.Tensor.matrix_power": [[406, "torch-tensor-matrix-power"]], "torch.Tensor.multiply": [[422, "torch-tensor-multiply"]], "torch.Tensor.masked_scatter": [[401, "torch-tensor-masked-scatter"]], "torch.Tensor.log_": [[376, "torch-tensor-log"]], "torch.Tensor.logical_not_": [[385, "torch-tensor-logical-not"]], "torch.Tensor.lu_solve": [[397, "torch-tensor-lu-solve"]], "torch.Tensor.module_load": [[415, "torch-tensor-module-load"]], "torch.Tensor.masked_scatter_": [[402, "torch-tensor-masked-scatter"]], "torch.Tensor.mm": [[413, "torch-tensor-mm"]], "torch.Tensor.mul": [[419, "torch-tensor-mul"]], "torch.Tensor.logit": [[390, "torch-tensor-logit"]], "torch.Tensor.masked_fill_": [[400, "torch-tensor-masked-fill"]], "torch.Tensor.matrix_exp": [[405, "torch-tensor-matrix-exp"]], "torch.Tensor.maximum": [[408, "torch-tensor-maximum"]], "torch.Tensor.lu": [[396, "torch-tensor-lu"]], "torch.Tensor.logical_or_": [[387, "torch-tensor-logical-or"]], "torch.Tensor.logical_or": [[386, "torch-tensor-logical-or"]], "torch.Tensor.logit_": [[391, "torch-tensor-logit"]], "torch.Tensor.minimum": [[412, "torch-tensor-minimum"]], "torch.Tensor.acosh_": [[96, "torch-tensor-acosh"]], "torch.Tensor.arctan2_": [[130, "torch-tensor-arctan2"]], "torch.Tensor.addr_": [[110, "torch-tensor-addr"]], "torch.Tensor.apply_": [[119, "torch-tensor-apply"]], "torch.Tensor.addmm_": [[106, "torch-tensor-addmm"]], "torch.Tensor.addr": [[109, "torch-tensor-addr"]], "torch.Tensor.arccos_": [[121, "torch-tensor-arccos"]], "torch.Tensor.as_subclass": [[139, "torch-tensor-as-subclass"]], "torch.Tensor.asin": [[140, "torch-tensor-asin"]], "torch.Tensor.arctanh": [[132, "torch-tensor-arctanh"]], "torch.Tensor.arctan": [[128, "torch-tensor-arctan"]], "torch.Tensor.argwhere": [[137, "torch-tensor-argwhere"]], "torch.Tensor.addcmul": [[103, "torch-tensor-addcmul"]], "torch.Tensor.arctan_": [[131, "torch-tensor-arctan"]], "torch.Tensor.addmm": [[105, "torch-tensor-addmm"]], "torch.Tensor.arcsin_": [[125, "torch-tensor-arcsin"]], "torch.Tensor.addbmm_": [[100, "torch-tensor-addbmm"]], "torch.Tensor.addcdiv": [[101, "torch-tensor-addcdiv"]], "torch.Tensor.arcsinh": [[126, "torch-tensor-arcsinh"]], "torch.Tensor.aminmax": [[116, "torch-tensor-aminmax"]], "torch.Tensor.arcsin": [[124, "torch-tensor-arcsin"]], "torch.Tensor.arctan2": [[129, "torch-tensor-arctan2"]], "torch.Tensor.amax": [[114, "torch-tensor-amax"]], "torch.Tensor.acosh": [[95, "torch-tensor-acosh"]], "torch.Tensor.addcdiv_": [[102, "torch-tensor-addcdiv"]], "torch.Tensor.amin": [[115, "torch-tensor-amin"]], "torch.Tensor.arccos": [[120, "torch-tensor-arccos"]], "torch.Tensor.all": [[112, "torch-tensor-all"]], "torch.Tensor.add": [[97, "torch-tensor-add"]], "torch.Tensor.arcsinh_": [[127, "torch-tensor-arcsinh"]], "torch.Tensor.addmv_": [[108, "torch-tensor-addmv"]], "torch.Tensor.addcmul_": [[104, "torch-tensor-addcmul"]], "torch.Tensor.arccosh": [[122, "torch-tensor-arccosh"]], "torch.Tensor.add_": [[98, "torch-tensor-add"]], "torch.Tensor.argsort": [[136, "torch-tensor-argsort"]], "torch.Tensor.argmax": [[134, "torch-tensor-argmax"]], "torch.Tensor.arctanh_": [[133, "torch-tensor-arctanh"]], "torch.Tensor.argmin": [[135, "torch-tensor-argmin"]], "torch.Tensor.adjoint": [[111, "torch-tensor-adjoint"]], "torch.Tensor.arccosh_": [[123, "torch-tensor-arccosh"]], "torch.Tensor.as_strided": [[138, "torch-tensor-as-strided"]], "torch.Tensor.acos_": [[94, "torch-tensor-acos"]], "torch.Tensor.addmv": [[107, "torch-tensor-addmv"]], "torch.Tensor.any": [[118, "torch-tensor-any"]], "torch.Tensor.allclose": [[113, "torch-tensor-allclose"]], "torch.Tensor.angle": [[117, "torch-tensor-angle"]], "torch.Tensor.addbmm": [[99, "torch-tensor-addbmm"]], "torch.Tensor.bitwise_not_": [[162, "torch-tensor-bitwise-not"]], "torch.Tensor.bitwise_and_": [[158, "torch-tensor-bitwise-and"]], "torch.Tensor.bitwise_left_shift": [[159, "torch-tensor-bitwise-left-shift"]], "torch.Tensor.atan": [[144, "torch-tensor-atan"]], "torch.Tensor.cauchy_": [[173, "torch-tensor-cauchy"]], "torch.Tensor.baddbmm_": [[152, "torch-tensor-baddbmm"]], "torch.Tensor.bfloat16": [[155, "torch-tensor-bfloat16"]], "torch.Tensor.ceil": [[176, "torch-tensor-ceil"]], "torch.Tensor.asin_": [[141, "torch-tensor-asin"]], "torch.Tensor.atan2_": [[146, "torch-tensor-atan2"]], "torch.Tensor.backward": [[150, "torch-tensor-backward"]], "torch.Tensor.bool": [[170, "torch-tensor-bool"]], "torch.Tensor.asinh": [[142, "torch-tensor-asinh"]], "torch.Tensor.bernoulli": [[153, "torch-tensor-bernoulli"]], "torch.Tensor.cholesky_solve": [[183, "torch-tensor-cholesky-solve"]], "torch.Tensor.bitwise_right_shift": [[165, "torch-tensor-bitwise-right-shift"]], "torch.Tensor.bitwise_or_": [[164, "torch-tensor-bitwise-or"]], "torch.Tensor.ccol_indices": [[174, "torch-tensor-ccol-indices"]], "torch.Tensor.atanh": [[148, "torch-tensor-atanh"]], "torch.Tensor.char": [[180, "torch-tensor-char"]], "torch.Tensor.chunk": [[184, "torch-tensor-chunk"]], "torch.Tensor.clamp": [[185, "torch-tensor-clamp"]], "torch.Tensor.ceil_": [[177, "torch-tensor-ceil"]], "torch.Tensor.bitwise_and": [[157, "torch-tensor-bitwise-and"]], "torch.Tensor.asinh_": [[143, "torch-tensor-asinh"]], "torch.Tensor.bitwise_or": [[163, "torch-tensor-bitwise-or"]], "torch.Tensor.byte": [[172, "torch-tensor-byte"]], "torch.Tensor.chalf": [[179, "torch-tensor-chalf"]], "torch.Tensor.clip": [[187, "torch-tensor-clip"]], "torch.Tensor.atan_": [[147, "torch-tensor-atan"]], "torch.Tensor.bitwise_right_shift_": [[166, "torch-tensor-bitwise-right-shift"]], "torch.Tensor.atan2": [[145, "torch-tensor-atan2"]], "torch.Tensor.bitwise_xor_": [[168, "torch-tensor-bitwise-xor"]], "torch.Tensor.bmm": [[169, "torch-tensor-bmm"]], "torch.Tensor.atanh_": [[149, "torch-tensor-atanh"]], "torch.Tensor.broadcast_to": [[171, "torch-tensor-broadcast-to"]], "torch.Tensor.bernoulli_": [[154, "torch-tensor-bernoulli"]], "torch.Tensor.bitwise_xor": [[167, "torch-tensor-bitwise-xor"]], "torch.Tensor.cdouble": [[175, "torch-tensor-cdouble"]], "torch.Tensor.baddbmm": [[151, "torch-tensor-baddbmm"]], "torch.Tensor.bincount": [[156, "torch-tensor-bincount"]], "torch.Tensor.bitwise_left_shift_": [[160, "torch-tensor-bitwise-left-shift"]], "torch.Tensor.cholesky_inverse": [[182, "torch-tensor-cholesky-inverse"]], "torch.Tensor.clamp_": [[186, "torch-tensor-clamp"]], "torch.Tensor.bitwise_not": [[161, "torch-tensor-bitwise-not"]], "torch.Tensor.cfloat": [[178, "torch-tensor-cfloat"]], "torch.Tensor.cholesky": [[181, "torch-tensor-cholesky"]], "torch.Tensor.diag_embed": [[225, "torch-tensor-diag-embed"]], "torch.Tensor.copysign_": [[198, "torch-tensor-copysign"]], "torch.Tensor.cumsum": [[214, "torch-tensor-cumsum"]], "torch.Tensor.conj": [[192, "torch-tensor-conj"]], "torch.Tensor.contiguous": [[195, "torch-tensor-contiguous"]], "torch.Tensor.diagflat": [[226, "torch-tensor-diagflat"]], "torch.Tensor.dist": [[234, "torch-tensor-dist"]], "torch.Tensor.det": [[220, "torch-tensor-det"]], "torch.Tensor.cummin": [[211, "torch-tensor-cummin"]], "torch.Tensor.device": [[223, "torch-tensor-device"]], "torch.Tensor.cov": [[205, "torch-tensor-cov"]], "torch.Tensor.dim": [[232, "torch-tensor-dim"]], "torch.Tensor.cross": [[207, "torch-tensor-cross"]], "torch.Tensor.cosh_": [[203, "torch-tensor-cosh"]], "torch.Tensor.cosh": [[202, "torch-tensor-cosh"]], "torch.Tensor.diagonal_scatter": [[228, "torch-tensor-diagonal-scatter"]], "torch.Tensor.cumprod": [[212, "torch-tensor-cumprod"]], "torch.Tensor.cos_": [[201, "torch-tensor-cos"]], "torch.Tensor.crow_indices": [[208, "torch-tensor-crow-indices"]], "torch.Tensor.coalesce": [[190, "torch-tensor-coalesce"]], "torch.Tensor.dequantize": [[219, "torch-tensor-dequantize"]], "torch.Tensor.detach": [[221, "torch-tensor-detach"]], "torch.Tensor.diagonal": [[227, "torch-tensor-diagonal"]], "torch.Tensor.count_nonzero": [[204, "torch-tensor-count-nonzero"]], "torch.Tensor.diag": [[224, "torch-tensor-diag"]], "torch.Tensor.cpu": [[206, "torch-tensor-cpu"]], "torch.Tensor.clone": [[189, "torch-tensor-clone"]], "torch.Tensor.cummax": [[210, "torch-tensor-cummax"]], "torch.Tensor.cumprod_": [[213, "torch-tensor-cumprod"]], "torch.Tensor.diff": [[229, "torch-tensor-diff"]], "torch.Tensor.digamma": [[230, "torch-tensor-digamma"]], "torch.Tensor.conj_physical": [[193, "torch-tensor-conj-physical"]], "torch.Tensor.cos": [[200, "torch-tensor-cos"]], "torch.Tensor.corrcoef": [[199, "torch-tensor-corrcoef"]], "torch.Tensor.data_ptr": [[216, "torch-tensor-data-ptr"]], "torch.Tensor.copy_": [[196, "torch-tensor-copy"]], "torch.Tensor.cuda": [[209, "torch-tensor-cuda"]], "torch.Tensor.dim_order": [[233, "torch-tensor-dim-order"]], "torch.Tensor.copysign": [[197, "torch-tensor-copysign"]], "torch.Tensor.conj_physical_": [[194, "torch-tensor-conj-physical"]], "torch.Tensor.detach_": [[222, "torch-tensor-detach"]], "torch.Tensor.dense_dim": [[218, "torch-tensor-dense-dim"]], "torch.Tensor.digamma_": [[231, "torch-tensor-digamma"]], "torch.Tensor.cumsum_": [[215, "torch-tensor-cumsum"]], "torch.Tensor.clip_": [[188, "torch-tensor-clip"]], "torch.Tensor.deg2rad": [[217, "torch-tensor-deg2rad"]], "torch.Tensor.col_indices": [[191, "torch-tensor-col-indices"]], "torch.Tensor.expand": [[254, "torch-tensor-expand"]], "torch.Tensor.div_": [[236, "torch-tensor-div"]], "torch.Tensor.gather": [[281, "torch-tensor-gather"]], "torch.Tensor.fmin": [[275, "torch-tensor-fmin"]], "torch.Tensor.erf_": [[247, "torch-tensor-erf"]], "torch.Tensor.double": [[240, "torch-tensor-double"]], "torch.Tensor.fmod": [[276, "torch-tensor-fmod"]], "torch.Tensor.expm1_": [[257, "torch-tensor-expm1"]], "torch.Tensor.fill_diagonal_": [[260, "torch-tensor-fill-diagonal"]], "torch.Tensor.erfinv_": [[251, "torch-tensor-erfinv"]], "torch.Tensor.floor_": [[271, "torch-tensor-floor"]], "torch.Tensor.erfc": [[248, "torch-tensor-erfc"]], "torch.Tensor.expand_as": [[255, "torch-tensor-expand-as"]], "torch.Tensor.flatten": [[263, "torch-tensor-flatten"]], "torch.Tensor.float_power_": [[269, "torch-tensor-float-power"]], "torch.Tensor.erf": [[246, "torch-tensor-erf"]], "torch.Tensor.expm1": [[256, "torch-tensor-expm1"]], "torch.Tensor.exp": [[252, "torch-tensor-exp"]], "torch.Tensor.flip": [[264, "torch-tensor-flip"]], "torch.Tensor.divide_": [[238, "torch-tensor-divide"]], "torch.Tensor.divide": [[237, "torch-tensor-divide"]], "torch.Tensor.element_size": [[242, "torch-tensor-element-size"]], "torch.Tensor.frac": [[278, "torch-tensor-frac"]], "torch.Tensor.fmod_": [[277, "torch-tensor-fmod"]], "torch.Tensor.floor_divide": [[272, "torch-tensor-floor-divide"]], "torch.Tensor.erfinv": [[250, "torch-tensor-erfinv"]], "torch.Tensor.flipud": [[266, "torch-tensor-flipud"]], "torch.Tensor.fmax": [[274, "torch-tensor-fmax"]], "torch.Tensor.eq_": [[244, "torch-tensor-eq"]], "torch.Tensor.dot": [[239, "torch-tensor-dot"]], "torch.Tensor.frac_": [[279, "torch-tensor-frac"]], "torch.Tensor.exp_": [[253, "torch-tensor-exp"]], "torch.Tensor.erfc_": [[249, "torch-tensor-erfc"]], "torch.Tensor.dsplit": [[241, "torch-tensor-dsplit"]], "torch.Tensor.fix_": [[262, "torch-tensor-fix"]], "torch.Tensor.fliplr": [[265, "torch-tensor-fliplr"]], "torch.Tensor.exponential_": [[258, "torch-tensor-exponential"]], "torch.Tensor.floor_divide_": [[273, "torch-tensor-floor-divide"]], "torch.Tensor.float": [[267, "torch-tensor-float"]], "torch.Tensor.floor": [[270, "torch-tensor-floor"]], "torch.Tensor.equal": [[245, "torch-tensor-equal"]], "torch.Tensor.fill_": [[259, "torch-tensor-fill"]], "torch.Tensor.fix": [[261, "torch-tensor-fix"]], "torch.Tensor.float_power": [[268, "torch-tensor-float-power"]], "torch.Tensor.eq": [[243, "torch-tensor-eq"]], "torch.Tensor.frexp": [[280, "torch-tensor-frexp"]], "torch.Tensor.div": [[235, "torch-tensor-div"]], "torch.Tensor.ger": [[288, "torch-tensor-ger"]], "torch.Tensor.gcd_": [[283, "torch-tensor-gcd"]], "torch.Tensor.index_select": [[322, "torch-tensor-index-select"]], "torch.Tensor.hardshrink": [[298, "torch-tensor-hardshrink"]], "torch.Tensor.igamma_": [[308, "torch-tensor-igamma"]], "torch.Tensor.imag": [[311, "torch-tensor-imag"]], "torch.Tensor.index_put": [[318, "torch-tensor-index-put"]], "torch.Tensor.hypot": [[303, "torch-tensor-hypot"]], "torch.Tensor.inner": [[324, "torch-tensor-inner"]], "torch.Tensor.greater_": [[292, "torch-tensor-greater"]], "torch.Tensor.indices": [[323, "torch-tensor-indices"]], "torch.Tensor.i0_": [[306, "torch-tensor-i0"]], "torch.Tensor.is_coalesced": [[328, "torch-tensor-is-coalesced"]], "torch.Tensor.index_fill": [[316, "torch-tensor-index-fill"]], "torch.Tensor.index_add": [[312, "torch-tensor-index-add"]], "torch.Tensor.index_copy_": [[315, "torch-tensor-index-copy"]], "torch.Tensor.geqrf": [[287, "torch-tensor-geqrf"]], "torch.Tensor.ge": [[284, "torch-tensor-ge"]], "torch.Tensor.index_fill_": [[317, "torch-tensor-index-fill"]], "torch.Tensor.hsplit": [[302, "torch-tensor-hsplit"]], "torch.Tensor.index_reduce": [[320, "torch-tensor-index-reduce"]], "torch.Tensor.inverse": [[327, "torch-tensor-inverse"]], "torch.Tensor.get_device": [[289, "torch-tensor-get-device"]], "torch.Tensor.half": [[297, "torch-tensor-half"]], "torch.Tensor.i0": [[305, "torch-tensor-i0"]], "torch.Tensor.int": [[325, "torch-tensor-int"]], "torch.Tensor.grad": [[290, "torch-tensor-grad"]], "torch.Tensor.gt_": [[296, "torch-tensor-gt"]], "torch.Tensor.greater_equal_": [[294, "torch-tensor-greater-equal"]], "torch.Tensor.heaviside": [[299, "torch-tensor-heaviside"]], "torch.Tensor.igamma": [[307, "torch-tensor-igamma"]], "torch.Tensor.gcd": [[282, "torch-tensor-gcd"]], "torch.Tensor.gt": [[295, "torch-tensor-gt"]], "torch.Tensor.hypot_": [[304, "torch-tensor-hypot"]], "torch.Tensor.igammac": [[309, "torch-tensor-igammac"]], "torch.Tensor.greater": [[291, "torch-tensor-greater"]], "torch.Tensor.histogram": [[301, "torch-tensor-histogram"]], "torch.Tensor.int_repr": [[326, "torch-tensor-int-repr"]], "torch.Tensor.geometric_": [[286, "torch-tensor-geometric"]], "torch.Tensor.histc": [[300, "torch-tensor-histc"]], "torch.Tensor.igammac_": [[310, "torch-tensor-igammac"]], "torch.Tensor.ge_": [[285, "torch-tensor-ge"]], "torch.Tensor.greater_equal": [[293, "torch-tensor-greater-equal"]], "torch.Tensor.index_copy": [[314, "torch-tensor-index-copy"]], "torch.Tensor.index_put_": [[319, "torch-tensor-index-put"]], "torch.Tensor.index_reduce_": [[321, "torch-tensor-index-reduce"]], "torch.Tensor.index_add_": [[313, "torch-tensor-index-add"]], "torch.Tensor.is_sparse_csr": [[343, "torch-tensor-is-sparse-csr"]], "torch.Tensor.is_meta": [[336, "torch-tensor-is-meta"]], "torch.Tensor.le_": [[360, "torch-tensor-le"]], "torch.Tensor.log10_": [[371, "torch-tensor-log10"]], "torch.Tensor.lcm_": [[356, "torch-tensor-lcm"]], "torch.Tensor.log10": [[370, "torch-tensor-log10"]], "torch.Tensor.is_contiguous": [[331, "torch-tensor-is-contiguous"]], "torch.Tensor.is_sparse": [[342, "torch-tensor-is-sparse"]], "torch.Tensor.is_leaf": [[335, "torch-tensor-is-leaf"]], "torch.Tensor.is_quantized": [[338, "torch-tensor-is-quantized"]], "torch.Tensor.is_conj": [[330, "torch-tensor-is-conj"]], "torch.Tensor.log1p_": [[373, "torch-tensor-log1p"]], "torch.Tensor.lcm": [[355, "torch-tensor-lcm"]], "torch.Tensor.less_": [[364, "torch-tensor-less"]], "torch.Tensor.is_signed": [[341, "torch-tensor-is-signed"]], "torch.Tensor.itemsize": [[353, "torch-tensor-itemsize"]], "torch.Tensor.lgamma_": [[368, "torch-tensor-lgamma"]], "torch.Tensor.ldexp": [[357, "torch-tensor-ldexp"]], "torch.Tensor.lgamma": [[367, "torch-tensor-lgamma"]], "torch.Tensor.isnan": [[347, "torch-tensor-isnan"]], "torch.Tensor.log2_": [[375, "torch-tensor-log2"]], "torch.Tensor.is_cuda": [[332, "torch-tensor-is-cuda"]], "torch.Tensor.isneginf": [[348, "torch-tensor-isneginf"]], "torch.Tensor.isreal": [[350, "torch-tensor-isreal"]], "torch.Tensor.less_equal": [[365, "torch-tensor-less-equal"]], "torch.Tensor.isposinf": [[349, "torch-tensor-isposinf"]], "torch.Tensor.less_equal_": [[366, "torch-tensor-less-equal"]], "torch.Tensor.isclose": [[344, "torch-tensor-isclose"]], "torch.Tensor.lerp": [[361, "torch-tensor-lerp"]], "torch.Tensor.item": [[352, "torch-tensor-item"]], "torch.Tensor.kthvalue": [[354, "torch-tensor-kthvalue"]], "torch.Tensor.less": [[363, "torch-tensor-less"]], "torch.Tensor.log1p": [[372, "torch-tensor-log1p"]], "torch.Tensor.is_complex": [[329, "torch-tensor-is-complex"]], "torch.Tensor.is_floating_point": [[333, "torch-tensor-is-floating-point"]], "torch.Tensor.istft": [[351, "torch-tensor-istft"]], "torch.Tensor.ldexp_": [[358, "torch-tensor-ldexp"]], "torch.Tensor.is_set_to": [[339, "torch-tensor-is-set-to"]], "torch.Tensor.isfinite": [[345, "torch-tensor-isfinite"]], "torch.Tensor.log2": [[374, "torch-tensor-log2"]], "torch.Tensor.is_pinned": [[337, "torch-tensor-is-pinned"]], "torch.Tensor.log": [[369, "torch-tensor-log"]], "torch.Tensor.is_shared": [[340, "torch-tensor-is-shared"]], "torch.Tensor.isinf": [[346, "torch-tensor-isinf"]], "torch.Tensor.lerp_": [[362, "torch-tensor-lerp"]], "torch.Tensor.le": [[359, "torch-tensor-le"]], "torch.Tensor.is_inference": [[334, "torch-tensor-is-inference"]], "torch.Tensor.polygamma": [[465, "torch-tensor-polygamma"]], "torch.Tensor.new_zeros": [[449, "torch-tensor-new-zeros"]], "torch.Tensor.nonzero": [[452, "torch-tensor-nonzero"]], "torch.Tensor.orgqr": [[459, "torch-tensor-orgqr"]], "torch.Tensor.outer": [[461, "torch-tensor-outer"]], "torch.Tensor.nanmean": [[429, "torch-tensor-nanmean"]], "torch.Tensor.ndimension": [[437, "torch-tensor-ndimension"]], "torch.Tensor.pin_memory": [[463, "torch-tensor-pin-memory"]], "torch.Tensor.ne_": [[439, "torch-tensor-ne"]], "torch.Tensor.nan_to_num_": [[428, "torch-tensor-nan-to-num"]], "torch.Tensor.nextafter_": [[451, "torch-tensor-nextafter"]], "torch.Tensor.nanmedian": [[430, "torch-tensor-nanmedian"]], "torch.Tensor.nextafter": [[450, "torch-tensor-nextafter"]], "torch.Tensor.nelement": [[444, "torch-tensor-nelement"]], "torch.Tensor.norm": [[453, "torch-tensor-norm"]], "torch.Tensor.numel": [[457, "torch-tensor-numel"]], "torch.Tensor.nan_to_num": [[427, "torch-tensor-nan-to-num"]], "torch.Tensor.ormqr": [[460, "torch-tensor-ormqr"]], "torch.Tensor.narrow": [[433, "torch-tensor-narrow"]], "torch.Tensor.ne": [[438, "torch-tensor-ne"]], "torch.Tensor.ndim": [[436, "torch-tensor-ndim"]], "torch.Tensor.negative_": [[443, "torch-tensor-negative"]], "torch.Tensor.numpy": [[458, "torch-tensor-numpy"]], "torch.Tensor.negative": [[442, "torch-tensor-negative"]], "torch.Tensor.nbytes": [[435, "torch-tensor-nbytes"]], "torch.Tensor.new_ones": [[447, "torch-tensor-new-ones"]], "torch.Tensor.mvlgamma_": [[426, "torch-tensor-mvlgamma"]], "torch.Tensor.nansum": [[432, "torch-tensor-nansum"]], "torch.Tensor.normal_": [[454, "torch-tensor-normal"]], "torch.Tensor.positive": [[467, "torch-tensor-positive"]], "torch.Tensor.neg": [[440, "torch-tensor-neg"]], "torch.Tensor.new_full": [[446, "torch-tensor-new-full"]], "torch.Tensor.polygamma_": [[466, "torch-tensor-polygamma"]], "torch.Tensor.not_equal_": [[456, "torch-tensor-not-equal"]], "torch.Tensor.pow": [[468, "torch-tensor-pow"]], "torch.Tensor.permute": [[462, "torch-tensor-permute"]], "torch.Tensor.multiply_": [[423, "torch-tensor-multiply"]], "torch.Tensor.new_empty": [[445, "torch-tensor-new-empty"]], "torch.Tensor.mvlgamma": [[425, "torch-tensor-mvlgamma"]], "torch.Tensor.pinverse": [[464, "torch-tensor-pinverse"]], "torch.Tensor.neg_": [[441, "torch-tensor-neg"]], "torch.Tensor.not_equal": [[455, "torch-tensor-not-equal"]], "torch.Tensor.nanquantile": [[431, "torch-tensor-nanquantile"]], "torch.Tensor.pow_": [[469, "torch-tensor-pow"]], "torch.Tensor.mv": [[424, "torch-tensor-mv"]], "torch.Tensor.narrow_copy": [[434, "torch-tensor-narrow-copy"]], "torch.Tensor.new_tensor": [[448, "torch-tensor-new-tensor"]], "torch.xpu": [[2212, "module-torch.xpu"]], "Random Number Generator": [[2212, "random-number-generator"], [19, "random-number-generator"]], "Streams and events": [[2212, "streams-and-events"], [2112, "streams-and-events"], [19, "streams-and-events"], [18, "streams-and-events"]], "Memory management": [[2212, "memory-management"], [2130, "memory-management"], [2139, "memory-management"], [19, "memory-management"]], "Type Info": [[2210, "type-info"]], "torch.finfo": [[2210, "torch-finfo"]], "torch.iinfo": [[2210, "torch-iinfo"]], "PYTORCH ProcessGroupNCCL Environment Variables": [[2209, "pytorch-processgroupnccl-environment-variables"]], "torch.utils": [[2211, "module-torch.utils"]], "torch.sparse_compressed_tensor": [[1978, "torch-sparse-compressed-tensor"]], "torch.stft": [[1990, "torch-stft"]], "torch.sparse.spsolve": [[1974, "torch-sparse-spsolve"]], "torch.sym_min": [[2003, "torch-sym-min"]], "torch.svd_lowrank": [[1995, "torch-svd-lowrank"]], "torch.sparse_csr_tensor": [[1981, "torch-sparse-csr-tensor"]], "torch.square": [[1984, "torch-square"]], "torch.std": [[1988, "torch-std"]], "torch.tile": [[2014, "torch-tile"]], "torch.sym_int": [[2000, "torch-sym-int"]], "torch.trace": [[2016, "torch-trace"]], "torch.std_mean": [[1989, "torch-std-mean"]], "torch.sym_ite": [[2001, "torch-sym-ite"]], "torch.tensor": [[2011, "torch-tensor"]], "torch.transpose": [[2017, "torch-transpose"]], "torch.topk": [[2015, "torch-topk"]], "torch.svd": [[1994, "torch-svd"]], "torch.trapz": [[2019, "torch-trapz"]], "torch.sym_float": [[1998, "torch-sym-float"]], "torch.sum": [[1993, "torch-sum"]], "torch.sym_not": [[2004, "torch-sym-not"]], "torch.take_along_dim": [[2008, "torch-take-along-dim"]], "torch.split": [[1982, "torch-split"]], "torch.sparse.sum": [[1975, "torch-sparse-sum"]], "torch.sqrt": [[1983, "torch-sqrt"]], "torch.sparse_bsr_tensor": [[1977, "torch-sparse-bsr-tensor"]], "torch.triangular_solve": [[2020, "torch-triangular-solve"]], "torch.sspaddmm": [[1986, "torch-sspaddmm"]], "torch.tensordot": [[2013, "torch-tensordot"]], "torch.t": [[2006, "torch-t"]], "torch.sym_fresh_size": [[1999, "torch-sym-fresh-size"]], "torch.squeeze": [[1985, "torch-squeeze"]], "torch.take": [[2007, "torch-take"]], "torch.tensor_split": [[2012, "torch-tensor-split"]], "torch.sym_sum": [[2005, "torch-sym-sum"]], "torch.sparse_bsc_tensor": [[1976, "torch-sparse-bsc-tensor"]], "torch.tan": [[2009, "torch-tan"]], "torch.swapdims": [[1997, "torch-swapdims"]], "torch.tanh": [[2010, "torch-tanh"]], "torch.sparse_csc_tensor": [[1980, "torch-sparse-csc-tensor"]], "torch.stack": [[1987, "torch-stack"]], "torch.sub": [[1991, "torch-sub"]], "torch.trapezoid": [[2018, "torch-trapezoid"]], "torch.sym_max": [[2002, "torch-sym-max"]], "torch.subtract": [[1992, "torch-subtract"]], "torch.sparse_coo_tensor": [[1979, "torch-sparse-coo-tensor"]], "torch.swapaxes": [[1996, "torch-swapaxes"]], "torch.vmap": [[2045, "torch-vmap"]], "torch.vstack": [[2047, "torch-vstack"]], "torch.tril_indices": [[2022, "torch-tril-indices"]], "torch.utils.rename_privateuse1_backend": [[2036, "torch-utils-rename-privateuse1-backend"]], "torch.where": [[2048, "torch-where"]], "torch.utils.get_cpp_backtrace": [[2035, "torch-utils-get-cpp-backtrace"]], "device": [[2055, "device"], [1449, "device"], [1062, "device"]], "torch.xpu.get_arch_list": [[2059, "torch-xpu-get-arch-list"]], "torch.tril": [[2021, "torch-tril"]], "torch.xpu.empty_cache": [[2058, "torch-xpu-empty-cache"]], "torch.xpu.get_device_capability": [[2060, "torch-xpu-get-device-capability"]], "torch.utils.swap_tensors": [[2038, "torch-utils-swap-tensors"]], "torch.xpu.current_stream": [[2054, "torch-xpu-current-stream"]], "torch.true_divide": [[2025, "torch-true-divide"]], "torch.vander": [[2039, "torch-vander"]], "torch.xpu.get_rng_state": [[2064, "torch-xpu-get-rng-state"]], "torch.xpu.get_gencode_flags": [[2063, "torch-xpu-get-gencode-flags"]], "torch.unbind": [[2027, "torch-unbind"]], "torch.vsplit": [[2046, "torch-vsplit"]], "torch.view_as_complex": [[2043, "torch-view-as-complex"]], "torch.var_mean": [[2041, "torch-var-mean"]], "torch.xpu.init": [[2067, "torch-xpu-init"]], "torch.var": [[2040, "torch-var"]], "torch.use_deterministic_algorithms": [[2033, "torch-use-deterministic-algorithms"]], "Event": [[2050, "event"], [86, "event"], [1443, "event"], [1427, "event"], [1039, "event"]], "torch.xpu.get_stream_from_external": [[2066, "torch-xpu-get-stream-from-external"]], "torch.xpu.current_device": [[2053, "torch-xpu-current-device"]], "torch.xpu.get_rng_state_all": [[2065, "torch-xpu-get-rng-state-all"]], "torch.utils.set_module": [[2037, "torch-utils-set-module"]], "StreamContext": [[2052, "streamcontext"], [1445, "streamcontext"], [1045, "streamcontext"], [1029, "streamcontext"]], "torch.utils.generate_methods_for_privateuse1_backend": [[2034, "torch-utils-generate-methods-for-privateuse1-backend"]], "torch.view_as_real": [[2044, "torch-view-as-real"]], "torch.xpu.get_device_properties": [[2062, "torch-xpu-get-device-properties"]], "torch.unique": [[2029, "torch-unique"]], "torch.unravel_index": [[2031, "torch-unravel-index"]], "torch.xpu.stream": [[2051, "torch-xpu-stream"]], "torch.xpu.get_device_name": [[2061, "torch-xpu-get-device-name"]], "torch.xpu.device_count": [[2056, "torch-xpu-device-count"]], "torch.xlogy": [[2049, "torch-xlogy"]], "device_of": [[2057, "device-of"], [1065, "device-of"]], "torch.triu": [[2023, "torch-triu"]], "torch.trunc": [[2026, "torch-trunc"]], "torch.unique_consecutive": [[2030, "torch-unique-consecutive"]], "torch.unflatten": [[2028, "torch-unflatten"]], "torch.triu_indices": [[2024, "torch-triu-indices"]], "torch.vdot": [[2042, "torch-vdot"]], "torch.unsqueeze": [[2032, "torch-unsqueeze"]], "torch.select": [[1930, "torch-select"]], "torch.scatter_reduce": [[1927, "torch-scatter-reduce"]], "torch.signal.windows.hann": [[1954, "torch-signal-windows-hann"]], "torch.signal.windows.blackman": [[1947, "torch-signal-windows-blackman"]], "torch.set_flush_denormal": [[1937, "torch-set-flush-denormal"]], "torch.set_warn_always": [[1942, "torch-set-warn-always"]], "torch.set_num_interop_threads": [[1938, "torch-set-num-interop-threads"]], "torch.signal.windows.bartlett": [[1946, "torch-signal-windows-bartlett"]], "torch.set_deterministic_debug_mode": [[1935, "torch-set-deterministic-debug-mode"]], "torch.signal.windows.hamming": [[1953, "torch-signal-windows-hamming"]], "torch.signal.windows.nuttall": [[1956, "torch-signal-windows-nuttall"]], "torch.sinc": [[1959, "torch-sinc"]], "torch.sinh": [[1960, "torch-sinh"]], "torch.sort": [[1965, "torch-sort"]], "torch.set_default_device": [[1932, "torch-set-default-device"]], "torch.signbit": [[1957, "torch-signbit"]], "torch.signal.windows.exponential": [[1949, "torch-signal-windows-exponential"]], "torch.sparse.mm": [[1970, "torch-sparse-mm"]], "torch.set_float32_matmul_precision": [[1936, "torch-set-float32-matmul-precision"]], "torch.softmax": [[1964, "torch-softmax"]], "torch.sparse.softmax": [[1972, "torch-sparse-softmax"]], "torch.sparse.spdiags": [[1973, "torch-sparse-spdiags"]], "torch.sign": [[1945, "torch-sign"]], "torch.signal.windows.kaiser": [[1955, "torch-signal-windows-kaiser"]], "torch.sin": [[1958, "torch-sin"]], "torch.sparse.addmm": [[1966, "torch-sparse-addmm"]], "torch.signal.windows.cosine": [[1948, "torch-signal-windows-cosine"]], "torch.slogdet": [[1962, "torch-slogdet"]], "torch.set_rng_state": [[1941, "torch-set-rng-state"]], "torch.set_default_tensor_type": [[1934, "torch-set-default-tensor-type"]], "torch.sparse.as_sparse_gradcheck": [[1967, "torch-sparse-as-sparse-gradcheck"]], "torch.seed": [[1929, "torch-seed"]], "torch.signal.windows.general_hamming": [[1952, "torch-signal-windows-general-hamming"]], "torch.slice_scatter": [[1961, "torch-slice-scatter"]], "check_sparse_tensor_invariants": [[1968, "check-sparse-tensor-invariants"]], "torch.sparse.log_softmax": [[1969, "torch-sparse-log-softmax"]], "torch.signal.windows.gaussian": [[1950, "torch-signal-windows-gaussian"]], "torch.set_num_threads": [[1939, "torch-set-num-threads"]], "torch.signal.windows.general_cosine": [[1951, "torch-signal-windows-general-cosine"]], "torch.select_scatter": [[1931, "torch-select-scatter"]], "torch.sparse.sampled_addmm": [[1971, "torch-sparse-sampled-addmm"]], "torch.searchsorted": [[1928, "torch-searchsorted"]], "torch.smm": [[1963, "torch-smm"]], "torch.set_default_dtype": [[1933, "torch-set-default-dtype"]], "torch.sigmoid": [[1944, "torch-sigmoid"]], "torch.sgn": [[1943, "torch-sgn"]], "torch.set_printoptions": [[1940, "torch-set-printoptions"]], "torch.randn": [[1905, "torch-randn"]], "torch.range": [[1908, "torch-range"]], "torch.reshape": [[1915, "torch-reshape"]], "torch.rand_like": [[1902, "torch-rand-like"]], "torch.positive": [[1888, "torch-positive"]], "torch.real": [[1910, "torch-real"]], "torch.roll": [[1919, "torch-roll"]], "torch.scatter": [[1925, "torch-scatter"]], "torch.rot90": [[1920, "torch-rot90"]], "torch.result_type": [[1918, "torch-result-type"]], "torch.quantile": [[1893, "torch-quantile"]], "torch.quantized_max_pool1d": [[1897, "torch-quantized-max-pool1d"]], "torch.pow": [[1889, "torch-pow"]], "torch.pca_lowrank": [[1882, "torch-pca-lowrank"]], "torch.permute": [[1883, "torch-permute"]], "torch.rad2deg": [[1900, "torch-rad2deg"]], "torch.scatter_add": [[1926, "torch-scatter-add"]], "torch.prod": [[1890, "torch-prod"]], "torch.promote_types": [[1891, "torch-promote-types"]], "torch.ormqr": [[1880, "torch-ormqr"]], "torch.quantize_per_tensor": [[1895, "torch-quantize-per-tensor"]], "torch.renorm": [[1913, "torch-renorm"]], "torch.quantize_per_channel": [[1894, "torch-quantize-per-channel"]], "torch.quantized_max_pool2d": [[1898, "torch-quantized-max-pool2d"]], "torch.qr": [[1892, "torch-qr"]], "torch.remainder": [[1912, "torch-remainder"]], "torch.save": [[1924, "torch-save"]], "torch.quantized_batch_norm": [[1896, "torch-quantized-batch-norm"]], "torch.repeat_interleave": [[1914, "torch-repeat-interleave"]], "torch.reciprocal": [[1911, "torch-reciprocal"]], "torch.randn_like": [[1906, "torch-randn-like"]], "torch.resolve_neg": [[1917, "torch-resolve-neg"]], "torch.randint": [[1903, "torch-randint"]], "torch.outer": [[1881, "torch-outer"]], "torch.pinverse": [[1884, "torch-pinverse"]], "torch.randperm": [[1907, "torch-randperm"]], "torch.randint_like": [[1904, "torch-randint-like"]], "torch.ravel": [[1909, "torch-ravel"]], "torch.round": [[1921, "torch-round"]], "torch.rsqrt": [[1923, "torch-rsqrt"]], "SobolEngine": [[1899, "sobolengine"]], "torch.polygamma": [[1887, "torch-polygamma"]], "torch.rand": [[1901, "torch-rand"]], "torch.row_stack": [[1922, "torch-row-stack"]], "torch.resolve_conj": [[1916, "torch-resolve-conj"]], "torch.poisson": [[1885, "torch-poisson"]], "torch.polar": [[1886, "torch-polar"]], "UninitializedParameter": [[1774, "uninitializedparameter"]], "torch.nn.utils.convert_conv3d_weight_memory_format": [[1780, "torch-nn-utils-convert-conv3d-weight-memory-format"]], "torch.nn.utils.clip_grad_norm_": [[1776, "torch-nn-utils-clip-grad-norm"]], "torch.nn.functional.upsample": [[1757, "torch-nn-functional-upsample"]], "torch.nn.functional.softplus": [[1746, "torch-nn-functional-softplus"]], "torch.nn.utils.fuse_linear_bn_eval": [[1783, "torch-nn-utils-fuse-linear-bn-eval"]], "torch.nn.functional.silu": [[1741, "torch-nn-functional-silu"]], "LazyModuleMixin": [[1760, "lazymodulemixin"]], "torch.nn.functional.soft_margin_loss": [[1743, "torch-nn-functional-soft-margin-loss"]], "torch.nn.utils.get_total_norm": [[1785, "torch-nn-utils-get-total-norm"]], "torch.nn.functional.upsample_nearest": [[1759, "torch-nn-functional-upsample-nearest"]], "Parameter": [[1772, "parameter"]], "torch.nn.modules.module.register_module_parameter_registration_hook": [[1768, "torch-nn-modules-module-register-module-parameter-registration-hook"]], "torch.nn.functional.smooth_l1_loss": [[1742, "torch-nn-functional-smooth-l1-loss"]], "torch.nn.modules.module.register_module_full_backward_pre_hook": [[1766, "torch-nn-modules-module-register-module-full-backward-pre-hook"]], "torch.nn.modules.module.register_module_forward_pre_hook": [[1764, "torch-nn-modules-module-register-module-forward-pre-hook"]], "torch.nn.functional.triplet_margin_with_distance_loss": [[1755, "torch-nn-functional-triplet-margin-with-distance-loss"]], "torch.nn.functional.upsample_bilinear": [[1758, "torch-nn-functional-upsample-bilinear"]], "torch.nn.utils.fuse_linear_bn_weights": [[1784, "torch-nn-utils-fuse-linear-bn-weights"]], "torch.nn.functional.softmax": [[1744, "torch-nn-functional-softmax"]], "torch.nn.functional.tanhshrink": [[1750, "torch-nn-functional-tanhshrink"]], "torch.nn.utils.clip_grad_value_": [[1777, "torch-nn-utils-clip-grad-value"]], "torch.nn.utils.clip_grads_with_norm_": [[1778, "torch-nn-utils-clip-grads-with-norm"]], "torch.nn.functional.threshold_": [[1752, "torch-nn-functional-threshold"]], "torch.nn.functional.softshrink": [[1747, "torch-nn-functional-softshrink"]], "torch.nn.utils.convert_conv2d_weight_memory_format": [[1779, "torch-nn-utils-convert-conv2d-weight-memory-format"]], "torch.nn.modules.module.register_module_full_backward_hook": [[1765, "torch-nn-modules-module-register-module-full-backward-hook"]], "torch.nn.modules.module.register_module_module_registration_hook": [[1767, "torch-nn-modules-module-register-module-module-registration-hook"]], "RMSNorm": [[1769, "rmsnorm"], [1595, "rmsnorm"]], "torch.nn.functional.sigmoid": [[1740, "torch-nn-functional-sigmoid"]], "torch.nn.functional.threshold": [[1751, "torch-nn-functional-threshold"]], "torch.nn.utils.fuse_conv_bn_eval": [[1781, "torch-nn-utils-fuse-conv-bn-eval"]], "torch.nn.functional.softsign": [[1748, "torch-nn-functional-softsign"]], "UninitializedBuffer": [[1773, "uninitializedbuffer"]], "torch.nn.functional.unfold": [[1756, "torch-nn-functional-unfold"]], "torch.nn.modules.module.register_module_backward_hook": [[1761, "torch-nn-modules-module-register-module-backward-hook"]], "torch.nn.functional.triplet_margin_loss": [[1754, "torch-nn-functional-triplet-margin-loss"]], "torch.nn.functional.selu": [[1739, "torch-nn-functional-selu"]], "torch.nn.utils.fuse_conv_bn_weights": [[1782, "torch-nn-utils-fuse-conv-bn-weights"]], "torch.nn.functional.softmin": [[1745, "torch-nn-functional-softmin"]], "torch.nn.functional.torch.nn.parallel.data_parallel": [[1753, "torch-nn-functional-torch-nn-parallel-data-parallel"]], "torch.nn.modules.module.register_module_buffer_registration_hook": [[1762, "torch-nn-modules-module-register-module-buffer-registration-hook"]], "torch.nn.utils.clip_grad_norm": [[1775, "torch-nn-utils-clip-grad-norm"]], "DistributedDataParallel": [[1770, "distributeddataparallel"], [2132, "distributeddataparallel"]], "torch.nn.modules.module.register_module_forward_hook": [[1763, "torch-nn-modules-module-register-module-forward-hook"]], "torch.nn.functional.tanh": [[1749, "torch-nn-functional-tanh"]], "Buffer": [[1771, "buffer"]], "torch.xpu.memory_reserved": [[2077, "torch-xpu-memory-reserved"]], "torch.linalg": [[2101, "torch-linalg"]], "Matrix Properties": [[2101, "matrix-properties"]], "Decompositions": [[2101, "decompositions"]], "Solvers": [[2101, "solvers"]], "Inverses": [[2101, "inverses"]], "Matrix Functions": [[2101, "matrix-functions"]], "Matrix Products": [[2101, "matrix-products"]], "Tensor Operations": [[2101, "tensor-operations"]], "Misc": [[2101, "misc"]], "Experimental Functions": [[2101, "experimental-functions"]], "torch.xpu.seed": [[2082, "torch-xpu-seed"]], "torch.xpu.manual_seed_all": [[2072, "torch-xpu-manual-seed-all"]], "torch.xpu.set_rng_state": [[2085, "torch-xpu-set-rng-state"]], "TorchScript Language Reference": [[2096, "torchscript-language-reference"], [2095, "torchscript-language-reference"]], "Terminology": [[2096, "terminology"], [2204, "terminology"]], "Type System": [[2096, "id1"]], "TorchScript Types": [[2096, "torchscript-types"]], "Meta Types": [[2096, "meta-types"]], "Any Type": [[2096, "any-type"]], "Operators Supported for Any Type": [[2096, "operators-supported-for-any-type"]], "Design Notes": [[2096, "design-notes"], [2166, "design-notes"]], "Primitive Types": [[2096, "primitive-types"]], "Structural Types": [[2096, "structural-types"]], "Nominal Types": [[2096, "nominal-types"]], "Built-in Class": [[2096, "built-in-class"]], "Special Note on torch.nn.ModuleList and torch.nn.ModuleDict": [[2096, "special-note-on-torch-nn-modulelist-and-torch-nn-moduledict"]], "Custom Class": [[2096, "custom-class"]], "Enum Type": [[2096, "enum-type"]], "TorchScript Module Class": [[2096, "torchscript-module-class"]], "Module Instance Class": [[2096, "module-instance-class"]], "Type Annotation": [[2096, "type-annotation"]], "When to Annotate Types": [[2096, "when-to-annotate-types"]], "Annotate Function Signature": [[2096, "annotate-function-signature"]], "Annotate Variables and Data Attributes": [[2096, "annotate-variables-and-data-attributes"]], "Local Variables": [[2096, "local-variables"]], "Instance Data Attributes": [[2096, "instance-data-attributes"]], "Type Annotation APIs": [[2096, "type-annotation-apis"]], "torch.jit.annotate(T, expr)": [[2096, "torch-jit-annotate-t-expr"]], "Type Annotation Appendix": [[2096, "type-annotation-appendix"]], "TorchScript Type System Definition": [[2096, "torchscript-type-system-definition"]], "Unsupported Typing Constructs": [[2096, "unsupported-typing-constructs"], [2095, "unsupported-typing-constructs"]], "Expressions": [[2096, "expressions"], [2095, "expressions"]], "Arithmetic Conversions": [[2096, "arithmetic-conversions"]], "Atoms": [[2096, "atoms"]], "Identifiers": [[2096, "identifiers"]], "Literals": [[2096, "literals"], [2095, "literals"]], "Parenthesized Forms": [[2096, "parenthesized-forms"]], "List and Dictionary Displays": [[2096, "list-and-dictionary-displays"]], "Primaries": [[2096, "primaries"]], "Attribute References": [[2096, "attribute-references"]], "Subscriptions": [[2096, "subscriptions"]], "Slicings": [[2096, "slicings"]], "Calls": [[2096, "calls"]], "Power Operator": [[2096, "power-operator"]], "Unary and Arithmetic Bitwise Operations": [[2096, "unary-and-arithmetic-bitwise-operations"]], "Binary Arithmetic Operations": [[2096, "binary-arithmetic-operations"]], "Shifting Operations": [[2096, "shifting-operations"]], "Binary Bitwise Operations": [[2096, "binary-bitwise-operations"]], "Comparisons": [[2096, "comparisons"], [2189, "comparisons"]], "Value Comparisons": [[2096, "value-comparisons"]], "Membership Test Operations": [[2096, "membership-test-operations"]], "Identity Comparisons": [[2096, "identity-comparisons"]], "Boolean Operations": [[2096, "boolean-operations"]], "Conditional Expressions": [[2096, "conditional-expressions"]], "Expression Lists": [[2096, "expression-lists"]], "Simple Statements": [[2096, "simple-statements"]], "Expression Statements": [[2096, "expression-statements"]], "Assignment Statements": [[2096, "assignment-statements"]], "Augmented Assignment Statements": [[2096, "augmented-assignment-statements"]], "Annotated Assignment Statements": [[2096, "annotated-assignment-statements"]], "The raise Statement": [[2096, "the-raise-statement"]], "The assert Statement": [[2096, "the-assert-statement"]], "The return Statement": [[2096, "the-return-statement"]], "The del Statement": [[2096, "the-del-statement"]], "The pass Statement": [[2096, "the-pass-statement"]], "The print Statement": [[2096, "the-print-statement"]], "The break Statement": [[2096, "the-break-statement"]], "The continue Statement:": [[2096, "the-continue-statement"]], "Compound Statements": [[2096, "compound-statements"]], "The if Statement": [[2096, "the-if-statement"]], "Basic if/else Statement": [[2096, "basic-if-else-statement"]], "Ternary if/else Statement": [[2096, "ternary-if-else-statement"]], "The while Statement": [[2096, "the-while-statement"]], "The for-in Statement": [[2096, "the-for-in-statement"]], "The with Statement": [[2096, "the-with-statement"]], "The tuple Statement": [[2096, "the-tuple-statement"]], "The getattr Statement": [[2096, "the-getattr-statement"]], "The hasattr Statement": [[2096, "the-hasattr-statement"]], "The zip Statement": [[2096, "the-zip-statement"]], "The enumerate Statement": [[2096, "the-enumerate-statement"]], "Python Values": [[2096, "python-values"]], "Resolution Rules": [[2096, "resolution-rules"]], "Python Built-in Functions Support": [[2096, "python-built-in-functions-support"]], "TorchScript Support for Python Built-in Functions": [[2096, "id5"]], "Python Built-in Values Support": [[2096, "python-built-in-values-support"]], "TorchScript Support for Python Built-in Values": [[2096, "id6"]], "torch.* APIs": [[2096, "torch-apis"]], "Remote Procedure Calls": [[2096, "remote-procedure-calls"]], "Asynchronous Execution": [[2096, "asynchronous-execution"]], "Type Annotations": [[2096, "type-annotations"]], "Meta Programming": [[2096, "meta-programming"]], "Type Refinement": [[2096, "type-refinement"]], "Meta device": [[2104, "meta-device"]], "Idioms for working with meta tensors": [[2104, "idioms-for-working-with-meta-tensors"]], "torch.xpu.memory_stats": [[2078, "torch-xpu-memory-stats"]], "torch.xpu.memory_allocated": [[2076, "torch-xpu-memory-allocated"]], "Miscellaneous Environment Variables": [[2105, "miscellaneous-environment-variables"]], "torch.xpu.set_rng_state_all": [[2086, "torch-xpu-set-rng-state-all"]], "torch.mtia.memory": [[2113, "torch-mtia-memory"]], "torch.xpu.max_memory_allocated": [[2073, "torch-xpu-max-memory-allocated"]], "TorchScript Unsupported PyTorch Constructs": [[2098, "torchscript-unsupported-pytorch-constructs"]], "Torch and Tensor Unsupported Attributes": [[2098, "torch-and-tensor-unsupported-attributes"]], "Unsupported Tensor Methods": [[2098, "unsupported-tensor-methods"]], "Unsupported Tensor Properties": [[2098, "unsupported-tensor-properties"]], "Functions Not Correctly Bound on Torch": [[2098, "functions-not-correctly-bound-on-torch"]], "Ops With Divergent Schemas Between Torch & Python": [[2098, "ops-with-divergent-schemas-between-torch-python"]], "PyTorch Unsupported Modules and Classes": [[2098, "pytorch-unsupported-modules-and-classes"]], "torch.utils.module_tracker": [[2108, "module-torch.utils.module_tracker"]], "torch.utils.mobile_optimizer": [[2106, "torch-utils-mobile-optimizer"]], "torch.zeros": [[2089, "torch-zeros"]], "torch.zeros_like": [[2090, "torch-zeros-like"]], "MPS Environment Variables": [[2111, "mps-environment-variables"]], "torch.masked": [[2103, "torch-masked"]], "Introduction": [[2103, "introduction"], [69, "introduction"], [2117, "introduction"]], "Motivation": [[2103, "motivation"], [2194, "motivation"], [2191, "motivation"]], "What is a MaskedTensor?": [[2103, "what-is-a-maskedtensor"]], "Supported Operators": [[2103, "supported-operators"]], "Unary Operators": [[2103, "unary-operators"]], "Binary Operators": [[2103, "binary-operators"]], "Reductions": [[2103, "reductions"]], "View and select functions": [[2103, "view-and-select-functions"]], "Multiprocessing package - torch.multiprocessing": [[2114, "module-torch.multiprocessing"]], "Strategy management": [[2114, "strategy-management"]], "Sharing CUDA tensors": [[2114, "sharing-cuda-tensors"]], "Sharing strategies": [[2114, "sharing-strategies"]], "File descriptor - file_descriptor": [[2114, "file-descriptor-file-descriptor"]], "File system - file_system": [[2114, "file-system-file-system"]], "Spawning subprocesses": [[2114, "spawning-subprocesses"]], "torch.xpu.memory_stats_as_nested_dict": [[2079, "torch-xpu-memory-stats-as-nested-dict"]], "torch.xpu.reset_peak_memory_stats": [[2081, "torch-xpu-reset-peak-memory-stats"]], "torch.xpu.max_memory_reserved": [[2074, "torch-xpu-max-memory-reserved"]], "torch.xpu.set_device": [[2084, "torch-xpu-set-device"]], "Python Language Reference Coverage": [[2097, "python-language-reference-coverage"]], "torch.hub": [[2091, "torch-hub"]], "Publishing models": [[2091, "publishing-models"]], "How to implement an entrypoint?": [[2091, "how-to-implement-an-entrypoint"]], "Important Notice": [[2091, "important-notice"]], "Loading models from Hub": [[2091, "loading-models-from-hub"]], "Running a loaded model:": [[2091, "running-a-loaded-model"]], "Where are my downloaded models saved?": [[2091, "where-are-my-downloaded-models-saved"]], "Caching logic": [[2091, "caching-logic"]], "Known limitations:": [[2091, "known-limitations"]], "torch.mtia": [[2112, "torch-mtia"]], "torch.library": [[2100, "module-torch.library"]], "Testing custom ops": [[2100, "testing-custom-ops"]], "Creating new custom ops in Python": [[2100, "creating-new-custom-ops-in-python"]], "Extending custom ops (created from Python or C++)": [[2100, "extending-custom-ops-created-from-python-or-c"]], "Low-level APIs": [[2100, "low-level-apis"]], "torch.xpu.initial_seed": [[2068, "torch-xpu-initial-seed"]], "torch.xpu.set_stream": [[2087, "torch-xpu-set-stream"]], "torch.monitor": [[2109, "torch-monitor"]], "API Reference": [[2109, "module-torch.monitor"], [69, "api-reference"], [56, "module-torch.export"], [2185, "api-reference"], [2159, "api-reference"], [2150, "api-reference"], [2158, "api-reference"], [20, "api-reference"], [14, "api-reference"], [36, "module-torch.distributed.pipelining"], [21, "api-reference"]], "torch.xpu.manual_seed": [[2071, "torch-xpu-manual-seed"]], "torch.utils.model_zoo": [[2107, "torch-utils-model-zoo"]], "torch.xpu.mem_get_info": [[2075, "torch-xpu-mem-get-info"]], "torch.mps": [[2110, "module-torch.mps"]], "MPS Profiler": [[2110, "mps-profiler"]], "MPS Event": [[2110, "mps-event"]], "torch.xpu.is_available": [[2069, "torch-xpu-is-available"]], "TorchScript": [[2093, "torchscript"]], "Creating TorchScript Code": [[2093, "creating-torchscript-code"]], "Mixing Tracing and Scripting": [[2093, "mixing-tracing-and-scripting"]], "TorchScript Language": [[2093, "torchscript-language"]], "Built-in Functions and Modules": [[2093, "built-in-functions-and-modules"]], "PyTorch Functions and Modules": [[2093, "pytorch-functions-and-modules"]], "Python Functions and Modules": [[2093, "python-functions-and-modules"]], "Python Language Reference Comparison": [[2093, "python-language-reference-comparison"]], "Debugging": [[2093, "debugging"], [69, "debugging"], [37, "module-torch.distributed.tensor.debug"]], "Disable JIT for Debugging": [[2093, "disable-jit-for-debugging"]], "Inspecting Code": [[2093, "inspecting-code"]], "Interpreting Graphs": [[2093, "interpreting-graphs"]], "Tracer": [[2093, "tracer"]], "Tracing Edge Cases": [[2093, "tracing-edge-cases"]], "Automatic Trace Checking": [[2093, "automatic-trace-checking"]], "Tracer Warnings": [[2093, "tracer-warnings"]], "Frequently Asked Questions": [[2093, "frequently-asked-questions"], [2195, "frequently-asked-questions"], [2161, "frequently-asked-questions"], [2154, "frequently-asked-questions"], [2135, "frequently-asked-questions"], [8, "frequently-asked-questions"]], "Known Issues": [[2093, "known-issues"]], "Appendix": [[2093, "appendix"]], "Migrating to PyTorch 1.2 Recursive Scripting API": [[2093, "migrating-to-pytorch-1-2-recursive-scripting-api"]], "Modules": [[2093, "modules"], [2142, "modules"]], "Functions": [[2093, "functions"], [2095, "functions"], [2172, "functions"], [2206, "functions"], [2154, "functions"]], "TorchScript Classes": [[2093, "torchscript-classes"], [2095, "id2"]], "Attributes": [[2093, "attributes"]], "Constants": [[2093, "constants"], [2180, "constants"]], "Variables": [[2093, "variables"], [2095, "variables"]], "Fusion Backends": [[2093, "fusion-backends"]], "References": [[2093, "references"], [57, "references"]], "TorchScript Builtins": [[2094, "torchscript-builtins"]], "Supported Tensor Methods": [[2094, "supported-tensor-methods"]], "Supported PyTorch Functions": [[2094, "supported-pytorch-functions"]], "TorchScript Builtin Functions": [[2094, "torchscript-builtin-functions"]], "Python Built-in Functions": [[2094, "python-built-in-functions"]], "math Module": [[2094, "math-module"]], "PyTorch documentation": [[2092, "pytorch-documentation"]], "Indices and tables": [[2092, "indices-and-tables"]], "torch.xpu.is_initialized": [[2070, "torch-xpu-is-initialized"]], "torch.xpu.seed_all": [[2083, "torch-xpu-seed-all"]], "torch._logging": [[2102, "torch-logging"]], "torch.xpu.reset_accumulated_memory_stats": [[2080, "torch-xpu-reset-accumulated-memory-stats"]], "JIT Utils - torch.utils.jit": [[2099, "module-torch.utils.jit"]], "Types": [[2095, "supported-type"], [2154, "types"]], "Default Types": [[2095, "default-types"]], "Optional Type Refinement": [[2095, "optional-type-refinement"]], "TorchScript Enums": [[2095, "id4"]], "Named Tuples": [[2095, "named-tuples"]], "Iterables": [[2095, "iterables"]], "List Construction": [[2095, "list-construction"]], "Tuple Construction": [[2095, "tuple-construction"]], "Dict Construction": [[2095, "dict-construction"]], "Arithmetic Operators": [[2095, "arithmetic-operators"]], "Comparison Operators": [[2095, "comparison-operators"]], "Logical Operators": [[2095, "logical-operators"]], "Subscripts and Slicing": [[2095, "subscripts-and-slicing"]], "Function Calls": [[2095, "function-calls"]], "Method Calls": [[2095, "method-calls"]], "Ternary Expressions": [[2095, "ternary-expressions"]], "Casts": [[2095, "casts"]], "Accessing Module Parameters": [[2095, "accessing-module-parameters"]], "Statements": [[2095, "statements"]], "Simple Assignments": [[2095, "simple-assignments"]], "Pattern Matching Assignments": [[2095, "pattern-matching-assignments"]], "Print Statements": [[2095, "print-statements"]], "If Statements": [[2095, "if-statements"]], "While Loops": [[2095, "while-loops"]], "For loops with range": [[2095, "for-loops-with-range"]], "For loops over tuples": [[2095, "for-loops-over-tuples"]], "For loops over constant nn.ModuleList": [[2095, "for-loops-over-constant-nn-modulelist"]], "Break and Continue": [[2095, "break-and-continue"]], "Return": [[2095, "return"]], "Variable Resolution": [[2095, "variable-resolution"]], "Use of Python Values": [[2095, "use-of-python-values"]], "Attribute Lookup On Python Modules": [[2095, "attribute-lookup-on-python-modules"]], "Python-defined Constants": [[2095, "python-defined-constants"]], "Module Attributes": [[2095, "module-attributes"]], "torch.xpu.synchronize": [[2088, "torch-xpu-synchronize"]], "torch.nn.utils.rnn.pack_padded_sequence": [[1814, "torch-nn-utils-rnn-pack-padded-sequence"]], "LnStructured": [[1799, "lnstructured"]], "torch.not_equal": [[1829, "torch-not-equal"]], "torch.nonzero": [[1826, "torch-nonzero"]], "torch.nn.utils.parametrize.is_parametrized": [[1792, "torch-nn-utils-parametrize-is-parametrized"]], "torch.ones_like": [[1832, "torch-ones-like"]], "torch.nn.utils.prune.custom_from_mask": [[1803, "torch-nn-utils-prune-custom-from-mask"]], "torch.nn.utils.prune.remove": [[1810, "torch-nn-utils-prune-remove"]], "torch.nn.utils.remove_spectral_norm": [[1811, "torch-nn-utils-remove-spectral-norm"]], "torch.normal": [[1828, "torch-normal"]], "torch.nn.utils.vector_to_parameters": [[1823, "torch-nn-utils-vector-to-parameters"]], "torch.numel": [[1830, "torch-numel"]], "torch.norm": [[1827, "torch-norm"]], "torch.nn.utils.parameters_to_vector": [[1786, "torch-nn-utils-parameters-to-vector"]], "BasePruningMethod": [[1795, "basepruningmethod"]], "torch.nn.utils.remove_weight_norm": [[1812, "torch-nn-utils-remove-weight-norm"]], "torch.nn.utils.rnn.unpad_sequence": [[1819, "torch-nn-utils-rnn-unpad-sequence"]], "torch.nn.utils.rnn.pack_sequence": [[1815, "torch-nn-utils-rnn-pack-sequence"]], "no_grad": [[1825, "no-grad"]], "torch.nn.utils.prune.identity": [[1797, "torch-nn-utils-prune-identity"]], "torch.nn.utils.spectral_norm": [[1821, "torch-nn-utils-spectral-norm"]], "torch.nn.utils.parametrize.cached": [[1791, "torch-nn-utils-parametrize-cached"]], "RandomStructured": [[1801, "randomstructured"]], "torch.nn.utils.parametrizations.weight_norm": [[1789, "torch-nn-utils-parametrizations-weight-norm"]], "torch.nn.utils.stateless.functional_call": [[1822, "torch-nn-utils-stateless-functional-call"]], "torch.nn.utils.parametrize.register_parametrization": [[1793, "torch-nn-utils-parametrize-register-parametrization"]], "torch.nn.utils.rnn.pad_packed_sequence": [[1816, "torch-nn-utils-rnn-pad-packed-sequence"]], "PruningContainer": [[1800, "pruningcontainer"]], "torch.nn.utils.prune.random_unstructured": [[1809, "torch-nn-utils-prune-random-unstructured"]], "PackedSequence": [[1813, "packedsequence"]], "torch.nn.utils.prune.random_structured": [[1808, "torch-nn-utils-prune-random-structured"]], "torch.nn.utils.prune.global_unstructured": [[1804, "torch-nn-utils-prune-global-unstructured"]], "torch.nn.utils.prune.is_pruned": [[1805, "torch-nn-utils-prune-is-pruned"]], "torch.nn.utils.parametrize.remove_parametrizations": [[1794, "torch-nn-utils-parametrize-remove-parametrizations"]], "L1Unstructured": [[1798, "l1unstructured"]], "RandomUnstructured": [[1802, "randomunstructured"]], "CustomFromMask": [[1796, "customfrommask"]], "torch.nn.utils.rnn.pad_sequence": [[1817, "torch-nn-utils-rnn-pad-sequence"]], "torch.nn.utils.parametrizations.orthogonal": [[1787, "torch-nn-utils-parametrizations-orthogonal"]], "torch.nn.utils.prune.l1_unstructured": [[1806, "torch-nn-utils-prune-l1-unstructured"]], "torch.nn.utils.rnn.unpack_sequence": [[1818, "torch-nn-utils-rnn-unpack-sequence"]], "torch.nn.utils.prune.ln_structured": [[1807, "torch-nn-utils-prune-ln-structured"]], "ParametrizationList": [[1790, "parametrizationlist"]], "torch.ones": [[1831, "torch-ones"]], "torch.nn.utils.skip_init": [[1820, "torch-nn-utils-skip-init"]], "torch.nn.utils.parametrizations.spectral_norm": [[1788, "torch-nn-utils-parametrizations-spectral-norm"]], "torch.nn.utils.weight_norm": [[1824, "torch-nn-utils-weight-norm"]], "torch.nn.functional.pdist": [[1727, "torch-nn-functional-pdist"]], "torch.nn.functional.instance_norm": [[1696, "torch-nn-functional-instance-norm"]], "torch.nn.functional.leaky_relu_": [[1702, "torch-nn-functional-leaky-relu"]], "torch.nn.functional.max_pool3d": [[1713, "torch-nn-functional-max-pool3d"]], "torch.nn.functional.multi_margin_loss": [[1719, "torch-nn-functional-multi-margin-loss"]], "torch.nn.functional.multilabel_soft_margin_loss": [[1721, "torch-nn-functional-multilabel-soft-margin-loss"]], "torch.nn.functional.scaled_dot_product_attention": [[1738, "torch-nn-functional-scaled-dot-product-attention"]], "torch.nn.functional.layer_norm": [[1700, "torch-nn-functional-layer-norm"]], "torch.nn.functional.max_pool2d": [[1712, "torch-nn-functional-max-pool2d"]], "torch.nn.functional.pixel_shuffle": [[1728, "torch-nn-functional-pixel-shuffle"]], "torch.nn.functional.leaky_relu": [[1701, "torch-nn-functional-leaky-relu"]], "torch.nn.functional.poisson_nll_loss": [[1730, "torch-nn-functional-poisson-nll-loss"]], "torch.nn.functional.prelu": [[1731, "torch-nn-functional-prelu"]], "torch.nn.functional.relu": [[1732, "torch-nn-functional-relu"]], "torch.nn.functional.rrelu": [[1736, "torch-nn-functional-rrelu"]], "torch.nn.functional.log_softmax": [[1705, "torch-nn-functional-log-softmax"]], "torch.nn.functional.max_unpool1d": [[1714, "torch-nn-functional-max-unpool1d"]], "torch.nn.functional.margin_ranking_loss": [[1710, "torch-nn-functional-margin-ranking-loss"]], "torch.nn.functional.mish": [[1717, "torch-nn-functional-mish"]], "torch.nn.functional.relu6": [[1733, "torch-nn-functional-relu6"]], "torch.nn.functional.multilabel_margin_loss": [[1720, "torch-nn-functional-multilabel-margin-loss"]], "torch.nn.functional.hardtanh_": [[1693, "torch-nn-functional-hardtanh"]], "torch.nn.functional.rms_norm": [[1735, "torch-nn-functional-rms-norm"]], "torch.nn.functional.pixel_unshuffle": [[1729, "torch-nn-functional-pixel-unshuffle"]], "torch.nn.functional.mse_loss": [[1718, "torch-nn-functional-mse-loss"]], "torch.nn.functional.pad": [[1725, "torch-nn-functional-pad"]], "torch.nn.functional.linear": [[1703, "torch-nn-functional-linear"]], "torch.nn.functional.pairwise_distance": [[1726, "torch-nn-functional-pairwise-distance"]], "torch.nn.functional.lp_pool1d": [[1707, "torch-nn-functional-lp-pool1d"]], "torch.nn.functional.normalize": [[1723, "torch-nn-functional-normalize"]], "torch.nn.functional.max_unpool2d": [[1715, "torch-nn-functional-max-unpool2d"]], "torch.nn.functional.kl_div": [[1698, "torch-nn-functional-kl-div"]], "torch.nn.functional.huber_loss": [[1695, "torch-nn-functional-huber-loss"]], "torch.nn.functional.interpolate": [[1697, "torch-nn-functional-interpolate"]], "torch.nn.functional.rrelu_": [[1737, "torch-nn-functional-rrelu"]], "torch.nn.functional.relu_": [[1734, "torch-nn-functional-relu"]], "torch.nn.functional.hardtanh": [[1692, "torch-nn-functional-hardtanh"]], "torch.nn.functional.max_pool1d": [[1711, "torch-nn-functional-max-pool1d"]], "torch.nn.functional.logsigmoid": [[1706, "torch-nn-functional-logsigmoid"]], "torch.nn.functional.max_unpool3d": [[1716, "torch-nn-functional-max-unpool3d"]], "torch.nn.functional.hinge_embedding_loss": [[1694, "torch-nn-functional-hinge-embedding-loss"]], "torch.nn.functional.lp_pool2d": [[1708, "torch-nn-functional-lp-pool2d"]], "torch.nn.functional.one_hot": [[1724, "torch-nn-functional-one-hot"]], "torch.nn.functional.l1_loss": [[1699, "torch-nn-functional-l1-loss"]], "torch.nn.functional.nll_loss": [[1722, "torch-nn-functional-nll-loss"]], "torch.nn.functional.local_response_norm": [[1704, "torch-nn-functional-local-response-norm"]], "torch.nn.functional.lp_pool3d": [[1709, "torch-nn-functional-lp-pool3d"]], "torch.nn.functional.conv3d": [[1663, "torch-nn-functional-conv3d"]], "torch.nn.functional.alpha_dropout": [[1652, "torch-nn-functional-alpha-dropout"]], "torch.nn.functional.gaussian_nll_loss": [[1683, "torch-nn-functional-gaussian-nll-loss"]], "torch.nn.functional.group_norm": [[1687, "torch-nn-functional-group-norm"]], "torch.nn.functional.hardswish": [[1691, "torch-nn-functional-hardswish"]], "torch.nn.functional.elu_": [[1676, "torch-nn-functional-elu"]], "torch.nn.functional.avg_pool3d": [[1655, "torch-nn-functional-avg-pool3d"]], "torch.nn.functional.hardsigmoid": [[1690, "torch-nn-functional-hardsigmoid"]], "torch.nn.functional.hardshrink": [[1689, "torch-nn-functional-hardshrink"]], "torch.nn.functional.adaptive_avg_pool1d": [[1645, "torch-nn-functional-adaptive-avg-pool1d"]], "torch.nn.functional.conv_transpose1d": [[1664, "torch-nn-functional-conv-transpose1d"]], "torch.nn.functional.adaptive_max_pool1d": [[1648, "torch-nn-functional-adaptive-max-pool1d"]], "torch.nn.functional.ctc_loss": [[1670, "torch-nn-functional-ctc-loss"]], "torch.nn.functional.avg_pool2d": [[1654, "torch-nn-functional-avg-pool2d"]], "torch.nn.functional.cross_entropy": [[1669, "torch-nn-functional-cross-entropy"]], "torch.nn.functional.batch_norm": [[1656, "torch-nn-functional-batch-norm"]], "torch.nn.functional.dropout3d": [[1674, "torch-nn-functional-dropout3d"]], "torch.nn.functional.feature_alpha_dropout": [[1679, "torch-nn-functional-feature-alpha-dropout"]], "torch.nn.functional.celu": [[1660, "torch-nn-functional-celu"]], "torch.nn.functional.cosine_similarity": [[1668, "torch-nn-functional-cosine-similarity"]], "torch.nn.functional.fold": [[1680, "torch-nn-functional-fold"]], "torch.nn.functional.fractional_max_pool2d": [[1681, "torch-nn-functional-fractional-max-pool2d"]], "torch.nn.functional.fractional_max_pool3d": [[1682, "torch-nn-functional-fractional-max-pool3d"]], "torch.nn.functional.conv2d": [[1662, "torch-nn-functional-conv2d"]], "torch.nn.functional.conv1d": [[1661, "torch-nn-functional-conv1d"]], "torch.nn.functional.adaptive_avg_pool3d": [[1647, "torch-nn-functional-adaptive-avg-pool3d"]], "torch.nn.functional.cosine_embedding_loss": [[1667, "torch-nn-functional-cosine-embedding-loss"]], "torch.nn.functional.dropout2d": [[1673, "torch-nn-functional-dropout2d"]], "torch.nn.functional.adaptive_avg_pool2d": [[1646, "torch-nn-functional-adaptive-avg-pool2d"]], "torch.nn.functional.dropout1d": [[1672, "torch-nn-functional-dropout1d"]], "torch.nn.functional.adaptive_max_pool2d": [[1649, "torch-nn-functional-adaptive-max-pool2d"]], "torch.nn.functional.glu": [[1685, "torch-nn-functional-glu"]], "torch.nn.functional.elu": [[1675, "torch-nn-functional-elu"]], "torch.nn.functional.affine_grid": [[1651, "torch-nn-functional-affine-grid"]], "torch.nn.functional.embedding_bag": [[1678, "torch-nn-functional-embedding-bag"]], "torch.nn.functional.avg_pool1d": [[1653, "torch-nn-functional-avg-pool1d"]], "torch.nn.functional.bilinear": [[1657, "torch-nn-functional-bilinear"]], "torch.nn.functional.grid_sample": [[1686, "torch-nn-functional-grid-sample"]], "torch.nn.functional.conv_transpose2d": [[1665, "torch-nn-functional-conv-transpose2d"]], "torch.nn.functional.adaptive_max_pool3d": [[1650, "torch-nn-functional-adaptive-max-pool3d"]], "torch.nn.functional.gelu": [[1684, "torch-nn-functional-gelu"]], "torch.nn.functional.conv_transpose3d": [[1666, "torch-nn-functional-conv-transpose3d"]], "torch.nn.functional.binary_cross_entropy_with_logits": [[1659, "torch-nn-functional-binary-cross-entropy-with-logits"]], "torch.nn.functional.embedding": [[1677, "torch-nn-functional-embedding"]], "torch.nn.functional.dropout": [[1671, "torch-nn-functional-dropout"]], "torch.nn.functional.binary_cross_entropy": [[1658, "torch-nn-functional-binary-cross-entropy"]], "torch.nn.functional.gumbel_softmax": [[1688, "torch-nn-functional-gumbel-softmax"]], "python.assert": [[72, "python-assert"]], "dynamic_shape_assert": [[72, "dynamic-shape-assert"], [71, "dynamic-shape-assert"]], "list_contains": [[72, "list-contains"], [71, "list-contains"], [77, "list-contains"], [80, "list-contains"]], "torch.fx.experimental": [[70, "torch-fx-experimental"]], "torch.fx.experimental.symbolic_shapes": [[70, "module-torch.fx.experimental.symbolic_shapes"]], "torch.fx.experimental.proxy_tensor": [[70, "module-torch.fx.experimental.proxy_tensor"]], "torch.escape-hatch": [[82, "torch-escape-hatch"]], "constrain_as_value_example": [[82, "constrain-as-value-example"], [81, "constrain-as-value-example"], [71, "constrain-as-value-example"]], "assume_constant_result": [[82, "assume-constant-result"], [71, "assume-constant-result"]], "constrain_as_size_example": [[82, "constrain-as-size-example"], [81, "constrain-as-size-example"], [71, "constrain-as-size-example"]], "Expiration Timers": [[54, "module-torch.distributed.elastic.timer"]], "Client Methods": [[54, "client-methods"]], "Server/Client Implementations": [[54, "server-client-implementations"]], "Writing a custom timer server/client": [[54, "writing-a-custom-timer-server-client"]], "Debug info logging": [[54, "module-torch.distributed.elastic.timer.debug_info_logging"]], "python.context-manager": [[75, "python-context-manager"]], "null_context_manager": [[75, "null-context-manager"], [71, "null-context-manager"]], "torch.export IR Specification": [[57, "torch-export-ir-specification"]], "Assumptions": [[57, "assumptions"], [2168, "assumptions"]], "What is Export IR": [[57, "what-is-export-ir"]], "ExportedProgram": [[57, "exportedprogram"]], "Graph": [[57, "graph"]], "Node": [[57, "node"]], "call_function": [[57, "call-function"]], "Metadata": [[57, "metadata"]], "placeholder": [[57, "placeholder"]], "output": [[57, "output"]], "get_attr": [[57, "get-attr"]], "SymInt": [[57, "symint"]], "FakeTensor": [[57, "faketensor"]], "Pytree-able Types": [[57, "pytree-able-types"]], "torchrun (Elastic Launch)": [[52, "module-torch.distributed.run"]], "Transitioning from torch.distributed.launch to torchrun": [[52, "transitioning-from-torch-distributed-launch-to-torchrun"]], "Usage": [[52, "usage"], [20, "usage"], [33, null]], "Single-node multi-worker": [[52, "single-node-multi-worker"]], "Stacked single-node multi-worker": [[52, "stacked-single-node-multi-worker"]], "Fault tolerant (fixed sized number of workers, no elasticity, tolerates 3 failures)": [[52, "fault-tolerant-fixed-sized-number-of-workers-no-elasticity-tolerates-3-failures"]], "Elastic (min=1, max=4, tolerates up to 3 membership changes or failures)": [[52, "elastic-min-1-max-4-tolerates-up-to-3-membership-changes-or-failures"]], "Note on rendezvous backend": [[52, "note-on-rendezvous-backend"]], "Definitions": [[52, "definitions"]], "Environment Variables": [[52, "environment-variables"], [2147, "environment-variables"]], "Deployment": [[52, "deployment"]], "Failure Modes": [[52, "failure-modes"]], "Membership Changes": [[52, "membership-changes"]], "Important Notices": [[52, "important-notices"]], "Migrating from functorch to torch.func": [[64, "migrating-from-functorch-to-torch-func"]], "function transforms": [[64, "function-transforms"]], "NN module utilities": [[64, "nn-module-utilities"]], "functorch.make_functional": [[64, "functorch-make-functional"]], "functorch.combine_state_for_ensemble": [[64, "functorch-combine-state-for-ensemble"]], "functorch.compile": [[64, "functorch-compile"]], "torch.cond": [[79, "torch-cond"], [1019, "torch-cond"]], "cond_closed_over_variable": [[79, "cond-closed-over-variable"], [71, "cond-closed-over-variable"], [74, "cond-closed-over-variable"]], "cond_branch_nonlocal_variables": [[79, "cond-branch-nonlocal-variables"], [71, "cond-branch-nonlocal-variables"], [80, "cond-branch-nonlocal-variables"]], "cond_operands": [[79, "cond-operands"], [71, "cond-operands"], [80, "cond-operands"]], "cond_branch_class_method": [[79, "cond-branch-class-method"], [71, "cond-branch-class-method"], [80, "cond-branch-class-method"]], "cond_predicate": [[79, "cond-predicate"], [71, "cond-predicate"], [80, "cond-predicate"]], "cond_branch_nested_function": [[79, "cond-branch-nested-function"], [71, "cond-branch-nested-function"], [80, "cond-branch-nested-function"]], "torch.dynamic-value": [[81, "torch-dynamic-value"]], "torch.Tensor.acos": [[93, "torch-tensor-acos"]], "Quickstart": [[50, "quickstart"]], "torch.export Programming Model": [[58, "torch-export-programming-model"]], "Basics of Tracing": [[58, "basics-of-tracing"]], "Strict vs. Non-Strict Tracing": [[58, "strict-vs-non-strict-tracing"]], "Values: Static vs. Dynamic": [[58, "values-static-vs-dynamic"]], "Static Values": [[58, "static-values"]], "Dynamic Values": [[58, "dynamic-values"]], "Which values are static vs. dynamic?": [[58, "which-values-are-static-vs-dynamic"]], "Input types": [[58, "input-types"]], "Custom Input Types": [[58, "custom-input-types"]], "Optional input types": [[58, "optional-input-types"]], "Control Flow: Static vs. Dynamic": [[58, "control-flow-static-vs-dynamic"]], "Static Control Flow": [[58, "static-control-flow"], [69, "static-control-flow"]], "Dynamic Control Flow: Shape-Dependent vs. Data-Dependent": [[58, "dynamic-control-flow-shape-dependent-vs-data-dependent"]], "Dynamic Shape-Dependent Control Flow": [[58, "dynamic-shape-dependent-control-flow"]], "Dynamic Data-Dependent Control Flow": [[58, "dynamic-data-dependent-control-flow"]], "Basics of Symbolic Shapes": [[58, "basics-of-symbolic-shapes"]], "Fake Implementations of PyTorch Operators": [[58, "fake-implementations-of-pytorch-operators"]], "Shape Propagation: Backed vs. Unbacked Dynamic Shapes": [[58, "shape-propagation-backed-vs-unbacked-dynamic-shapes"]], "Control Flow: Guards and Assertions": [[58, "control-flow-guards-and-assertions"]], "Allowed PyTorch operators": [[58, "allowed-pytorch-operators"]], "Custom operators": [[58, "custom-operators"], [2154, "custom-operators"]], "Module State: Reads vs. Updates": [[58, "module-state-reads-vs-updates"]], "Access rules": [[58, "access-rules"]], "Effects of functionalization": [[58, "effects-of-functionalization"]], "torch.__future__": [[67, "module-torch.__future__"]], "torch.futures": [[68, "torch-futures"]], "torch.fx": [[69, "torch-fx"]], "Overview": [[69, "module-torch.fx"], [56, "overview"], [2190, "overview"], [2159, "module-torch.profiler"], [2150, "overview"], [2149, "overview"], [20, "module-torch.cuda._sanitizer"], [21, "module-torch.cuda.tunable"]], "Writing Transformations": [[69, "writing-transformations"]], "A Quick Primer on Graphs": [[69, "a-quick-primer-on-graphs"]], "Graph Manipulation": [[69, "graph-manipulation"]], "Direct Graph Manipulation": [[69, "direct-graph-manipulation"]], "Subgraph Rewriting With replace_pattern()": [[69, "subgraph-rewriting-with-replace-pattern"]], "Graph Manipulation Examples": [[69, "graph-manipulation-examples"]], "Proxy/Retracing": [[69, "proxy-retracing"]], "The Interpreter Pattern": [[69, "the-interpreter-pattern"]], "Examples of the Interpreter Pattern": [[69, "examples-of-the-interpreter-pattern"]], "Common Pitfalls in Transform Authoring": [[69, "common-pitfalls-in-transform-authoring"]], "Checking Correctness of Modules": [[69, "checking-correctness-of-modules"]], "Debugging the Generated Code": [[69, "debugging-the-generated-code"]], "Use pdb": [[69, "use-pdb"]], "Print the Generated Code": [[69, "print-the-generated-code"]], "Use the to_folder Function From GraphModule": [[69, "use-the-to-folder-function-from-graphmodule"]], "Debugging the Transformation": [[69, "debugging-the-transformation"]], "Available Debuggers": [[69, "available-debuggers"]], "Limitations of Symbolic Tracing": [[69, "limitations-of-symbolic-tracing"]], "Dynamic Control Flow": [[69, "dynamic-control-flow"]], "Non-torch Functions": [[69, "non-torch-functions"]], "Customizing Tracing with the Tracer class": [[69, "customizing-tracing-with-the-tracer-class"]], "Leaf Modules": [[69, "leaf-modules"]], "Miscellanea": [[69, "miscellanea"]], "torch.func": [[61, "torch-func"]], "What are composable function transforms?": [[61, "what-are-composable-function-transforms"]], "Why composable function transforms?": [[61, "why-composable-function-transforms"], [66, "why-composable-function-transforms"]], "Read More": [[61, "read-more"], [56, "read-more"], [2183, "read-more"]], "Rendezvous": [[51, "module-torch.distributed.elastic.rendezvous"]], "Registry": [[51, "registry"]], "Handler": [[51, "handler"]], "Dataclasses": [[51, "dataclasses"]], "Exceptions": [[51, "exceptions"]], "Implementations": [[51, "implementations"], [41, "implementations"]], "Dynamic Rendezvous": [[51, "dynamic-rendezvous"]], "C10d Backend": [[51, "c10d-backend"]], "Etcd Backend": [[51, "etcd-backend"]], "Etcd Rendezvous (Legacy)": [[51, "etcd-rendezvous-legacy"]], "Etcd Store": [[51, "etcd-store"]], "Etcd Server": [[51, "etcd-server"]], "Train script": [[55, "train-script"]], "torch.mutation": [[84, "torch-mutation"]], "user_input_mutation": [[84, "user-input-mutation"], [71, "user-input-mutation"]], "torch.map": [[83, "torch-map"]], "dynamic_shape_map": [[83, "dynamic-shape-map"], [71, "dynamic-shape-map"], [80, "dynamic-shape-map"]], "Generator": [[87, "generator"]], "torch.Tensor.absolute": [[91, "torch-tensor-absolute"]], "Multiprocessing": [[49, "module-torch.distributed.elastic.multiprocessing"], [12, "multiprocessing"]], "Starting Multiple Workers": [[49, "starting-multiple-workers"]], "Process Context": [[49, "process-context"]], "torch.Tensor.abs_": [[90, "torch-tensor-abs"]], "python.control-flow": [[76, "python-control-flow"]], "list_unpack": [[76, "list-unpack"], [71, "list-unpack"], [77, "list-unpack"]], "static_for_loop": [[76, "static-for-loop"], [71, "static-for-loop"]], "dynamic_shape_if_guard": [[76, "dynamic-shape-if-guard"], [71, "dynamic-shape-if-guard"], [80, "dynamic-shape-if-guard"]], "static_if": [[76, "static-if"], [71, "static-if"]], "UX Limitations": [[65, "ux-limitations"]], "General limitations": [[65, "general-limitations"]], "torch.autograd APIs": [[65, "torch-autograd-apis"]], "vmap limitations": [[65, "vmap-limitations"]], "Mutation: Arbitrary mutation of Python data structures": [[65, "mutation-arbitrary-mutation-of-python-data-structures"]], "Mutation: in-place PyTorch Operations": [[65, "mutation-in-place-pytorch-operations"]], "Mutation: out= PyTorch Operations": [[65, "mutation-out-pytorch-operations"]], "Data-dependent Python control flow": [[65, "data-dependent-python-control-flow"]], "Data-dependent operations (.item())": [[65, "data-dependent-operations-item"]], "Dynamic shape operations (nonzero and friends)": [[65, "dynamic-shape-operations-nonzero-and-friends"]], "Randomness": [[65, "randomness"]], "TorchElastic Kubernetes": [[47, "torchelastic-kubernetes"]], "ExportDB": [[71, "exportdb"]], "Tags": [[71, null]], "Supported": [[71, "supported"]], "specialized_attribute": [[71, "specialized-attribute"]], "fn_with_kwargs": [[71, "fn-with-kwargs"], [77, "fn-with-kwargs"]], "dynamic_shape_slicing": [[71, "dynamic-shape-slicing"], [80, "dynamic-shape-slicing"]], "autograd_function": [[71, "autograd-function"]], "type_reflection_method": [[71, "type-reflection-method"], [73, "type-reflection-method"]], "decorator": [[71, "decorator"]], "dynamic_shape_view": [[71, "dynamic-shape-view"], [80, "dynamic-shape-view"]], "nested_function": [[71, "nested-function"], [74, "nested-function"]], "dynamic_shape_constructor": [[71, "dynamic-shape-constructor"], [80, "dynamic-shape-constructor"]], "class_method": [[71, "class-method"]], "pytree_flatten": [[71, "pytree-flatten"]], "scalar_output": [[71, "scalar-output"], [80, "scalar-output"]], "tensor_setattr": [[71, "tensor-setattr"], [73, "tensor-setattr"]], "dictionary": [[71, "dictionary"], [77, "dictionary"]], "Not Supported Yet": [[71, "not-supported-yet"]], "unsupported_operator": [[71, "unsupported-operator"], [85, "unsupported-operator"]], "optional_input": [[71, "optional-input"], [78, "optional-input"]], "dynamic_shape_round": [[71, "dynamic-shape-round"], [80, "dynamic-shape-round"], [73, "dynamic-shape-round"]], "model_attr_mutation": [[71, "model-attr-mutation"], [78, "model-attr-mutation"]], "FullyShardedDataParallel": [[60, "module-torch.distributed.fsdp"]], "python.closure": [[74, "python-closure"]], "torch.operator": [[85, "torch-operator"]], "torch.Tensor.absolute_": [[92, "torch-tensor-absolute"]], "torch.Tensor.abs": [[89, "torch-tensor-abs"]], "torch.export": [[56, "torch-export"]], "Existing frameworks": [[56, "existing-frameworks"]], "Exporting a PyTorch Model": [[56, "exporting-a-pytorch-model"]], "An Example": [[56, "an-example"]], "Non-Strict Export": [[56, "non-strict-export"]], "Export for Training and Inference": [[56, "export-for-training-and-inference"]], "Expressing Dynamism": [[56, "expressing-dynamism"]], "Serialization": [[56, "serialization"], [2180, "serialization"], [13, "serialization"]], "Specializations": [[56, "specializations"]], "Input Tensor Shapes": [[56, "input-tensor-shapes"]], "Python Primitives": [[56, "python-primitives"]], "Python Containers": [[56, "python-containers"]], "Limitations of torch.export": [[56, "limitations-of-torch-export"]], "Graph Breaks": [[56, "graph-breaks"], [2205, "graph-breaks"], [2195, "graph-breaks"]], "Data/Shape-Dependent Control Flow": [[56, "data-shape-dependent-control-flow"]], "Missing Fake/Meta/Abstract Kernels for Operators": [[56, "missing-fake-meta-abstract-kernels-for-operators"]], "Additional Links for Export Users": [[56, null]], "Deep Dive for PyTorch Developers": [[56, null], [2183, null]], "torch.fft": [[59, "torch-fft"]], "Fast Fourier Transforms": [[59, "fast-fourier-transforms"]], "Helper Functions": [[59, "helper-functions"]], "Patching Batch Norm": [[63, "patching-batch-norm"]], "What\u2019s happening?": [[63, "what-s-happening"]], "How to fix": [[63, "how-to-fix"]], "Option 1: Change the BatchNorm": [[63, "option-1-change-the-batchnorm"]], "Option 2: torchvision parameter": [[63, "option-2-torchvision-parameter"]], "Option 3: functorch\u2019s patching": [[63, "option-3-functorch-s-patching"]], "Option 4: eval mode": [[63, "option-4-eval-mode"]], "torch.func Whirlwind Tour": [[66, "torch-func-whirlwind-tour"]], "What is torch.func?": [[66, "what-is-torch-func"]], "What are the transforms?": [[66, "what-are-the-transforms"]], "grad() (gradient computation)": [[66, "grad-gradient-computation"]], "vmap() (auto-vectorization)": [[66, "vmap-auto-vectorization"]], "vjp() (vector-Jacobian product)": [[66, "vjp-vector-jacobian-product"]], "jvp() (Jacobian-vector product)": [[66, "jvp-jacobian-vector-product"]], "jacrev(), jacfwd(), and hessian()": [[66, "jacrev-jacfwd-and-hessian"]], "python.object-model": [[78, "python-object-model"]], "python.data-structure": [[77, "python-data-structure"]], "torch.dynamic-shape": [[80, "torch-dynamic-shape"]], "python.builtin": [[73, "python-builtin"]], "torch.func API Reference": [[62, "module-torch.func"]], "Function Transforms": [[62, "function-transforms"]], "Utilities for working with torch.nn.Modules": [[62, "utilities-for-working-with-torch-nn-modules"]], "Debug utilities": [[62, "debug-utilities"]], "Metrics": [[48, "module-torch.distributed.elastic.metrics"]], "Metric Handlers": [[48, "metric-handlers"]], "Methods": [[48, "methods"]], "Subprocess Handling": [[53, "module-torch.distributed.elastic.multiprocessing.subprocess_handler"]], "Retrieve SubprocessHandler": [[53, "retrieve-subprocesshandler"]], "SubprocessHandler": [[53, "subprocesshandler"]], "Stream": [[88, "stream"]], "AdamW": [[1841, "adamw"]], "torch.optim.Optimizer.load_state_dict": [[1846, "torch-optim-optimizer-load-state-dict"]], "SequentialLR": [[1875, "sequentiallr"]], "torch.optim.Optimizer.register_load_state_dict_pre_hook": [[1848, "torch-optim-optimizer-register-load-state-dict-pre-hook"]], "RMSprop": [[1857, "rmsprop"]], "Adam": [[1840, "adam"]], "SGD": [[1859, "sgd"]], "StepLR": [[1876, "steplr"]], "torch.optim.Optimizer.register_step_post_hook": [[1851, "torch-optim-optimizer-register-step-post-hook"]], "SparseAdam": [[1860, "sparseadam"]], "Adadelta": [[1837, "adadelta"]], "ChainedScheduler": [[1861, "chainedscheduler"]], "LBFGS": [[1843, "lbfgs"]], "Adagrad": [[1839, "adagrad"]], "CosineAnnealingWarmRestarts": [[1864, "cosineannealingwarmrestarts"]], "Rprop": [[1858, "rprop"]], "GraphInfo": [[1834, "graphinfo"]], "LRScheduler": [[1867, "lrscheduler"]], "SWALR": [[1878, "swalr"]], "CyclicLR": [[1865, "cycliclr"]], "PolynomialLR": [[1873, "polynomiallr"]], "JitScalarType": [[1833, "jitscalartype"]], "Adafactor": [[1838, "adafactor"]], "torch.optim.Optimizer.state_dict": [[1853, "torch-optim-optimizer-state-dict"]], "torch.optim.Optimizer.register_state_dict_post_hook": [[1849, "torch-optim-optimizer-register-state-dict-post-hook"]], "torch.optim.Optimizer.zero_grad": [[1855, "torch-optim-optimizer-zero-grad"]], "MultiplicativeLR": [[1871, "multiplicativelr"]], "ExponentialLR": [[1866, "exponentiallr"]], "MultiStepLR": [[1870, "multisteplr"]], "ASGD": [[1836, "asgd"]], "torch.orgqr": [[1879, "torch-orgqr"]], "torch.optim.Optimizer.register_state_dict_pre_hook": [[1850, "torch-optim-optimizer-register-state-dict-pre-hook"]], "RAdam": [[1856, "radam"]], "torch.optim.Optimizer.step": [[1854, "torch-optim-optimizer-step"]], "OneCycleLR": [[1872, "onecyclelr"]], "AveragedModel": [[1877, "averagedmodel"]], "torch.optim.Optimizer.add_param_group": [[1845, "torch-optim-optimizer-add-param-group"]], "ConstantLR": [[1862, "constantlr"]], "torch.optim.Optimizer.register_step_pre_hook": [[1852, "torch-optim-optimizer-register-step-pre-hook"]], "torch.optim.Optimizer.register_load_state_dict_post_hook": [[1847, "torch-optim-optimizer-register-load-state-dict-post-hook"]], "CosineAnnealingLR": [[1863, "cosineannealinglr"]], "VerificationOptions": [[1835, "verificationoptions"]], "Adamax": [[1842, "adamax"]], "LambdaLR": [[1868, "lambdalr"]], "LinearLR": [[1869, "linearlr"]], "NAdam": [[1844, "nadam"]], "ReduceLROnPlateau": [[1874, "reducelronplateau"]], "torch.mm": [[1419, "torch-mm"]], "torch.mean": [[1414, "torch-mean"]], "torch.mode": [[1420, "torch-mode"]], "torch.mps.current_allocated_memory": [[1423, "torch-mps-current-allocated-memory"]], "torch.mps.profiler.stop": [[1435, "torch-mps-profiler-stop"]], "torch.matrix_power": [[1411, "torch-matrix-power"]], "torch.mps.manual_seed": [[1429, "torch-mps-manual-seed"]], "torch.mtia.current_device": [[1446, "torch-mtia-current-device"]], "torch.mps.device_count": [[1424, "torch-mps-device-count"]], "torch.mps.profiler.metal_capture": [[1432, "torch-mps-profiler-metal-capture"]], "torch.mps.profiler.profile": [[1433, "torch-mps-profiler-profile"]], "torch.mtia.is_initialized": [[1456, "torch-mtia-is-initialized"]], "torch.mtia.current_stream": [[1447, "torch-mtia-current-stream"]], "torch.mtia.DeferredMtiaCallError": [[1442, "torch-mtia-deferredmtiacallerror"]], "torch.median": [[1415, "torch-median"]], "torch.mps.set_rng_state": [[1439, "torch-mps-set-rng-state"]], "torch.mtia.device_count": [[1450, "torch-mtia-device-count"]], "torch.mps.profiler.start": [[1434, "torch-mps-profiler-start"]], "torch.mps.profiler.is_capturing_metal": [[1430, "torch-mps-profiler-is-capturing-metal"]], "torch.mtia.init": [[1454, "torch-mtia-init"]], "torch.msort": [[1441, "torch-msort"]], "torch.mps.seed": [[1437, "torch-mps-seed"]], "torch.movedim": [[1422, "torch-movedim"]], "torch.mps.driver_allocated_memory": [[1425, "torch-mps-driver-allocated-memory"]], "torch.matrix_exp": [[1410, "torch-matrix-exp"]], "torch.minimum": [[1418, "torch-minimum"]], "torch.mtia.is_available": [[1455, "torch-mtia-is-available"]], "torch.mps.recommended_max_memory": [[1436, "torch-mps-recommended-max-memory"]], "torch.mps.profiler.is_metal_capture_enabled": [[1431, "torch-mps-profiler-is-metal-capture-enabled"]], "torch.moveaxis": [[1421, "torch-moveaxis"]], "torch.mps.empty_cache": [[1426, "torch-mps-empty-cache"]], "torch.mps.set_per_process_memory_fraction": [[1438, "torch-mps-set-per-process-memory-fraction"]], "torch.meshgrid": [[1416, "torch-meshgrid"]], "torch.mtia.stream": [[1444, "torch-mtia-stream"]], "torch.mps.get_rng_state": [[1428, "torch-mps-get-rng-state"]], "torch.mtia.default_stream": [[1448, "torch-mtia-default-stream"]], "torch.max": [[1412, "torch-max"]], "torch.min": [[1417, "torch-min"]], "torch.mtia.get_device_capability": [[1452, "torch-mtia-get-device-capability"]], "torch.mtia.get_rng_state": [[1453, "torch-mtia-get-rng-state"]], "torch.mps.synchronize": [[1440, "torch-mps-synchronize"]], "torch.mtia.empty_cache": [[1451, "torch-mtia-empty-cache"]], "torch.maximum": [[1413, "torch-maximum"]], "RNNCell": [[1598, "rnncell"], [776, "rnncell"]], "Softshrink": [[1618, "softshrink"]], "ReLU6": [[1601, "relu6"], [769, "relu6"]], "Threshold": [[1623, "threshold"]], "Sequential": [[1609, "sequential"]], "Upsample": [[1633, "upsample"]], "torch.nn.attention.bias.CausalBias": [[1640, "torch-nn-attention-bias-causalbias"]], "ZeroPad1d": [[1636, "zeropad1d"]], "SmoothL1Loss": [[1612, "smoothl1loss"]], "TransformerDecoderLayer": [[1626, "transformerdecoderlayer"]], "Transformer": [[1624, "transformer"], [2203, "transformer"]], "TransformerDecoder": [[1625, "transformerdecoder"]], "SyncBatchNorm": [[1620, "syncbatchnorm"]], "torch.nn.attention.bias.causal_upper_left": [[1643, "torch-nn-attention-bias-causal-upper-left"]], "ReflectionPad1d": [[1602, "reflectionpad1d"]], "ZeroPad2d": [[1637, "zeropad2d"]], "TripletMarginLoss": [[1629, "tripletmarginloss"]], "TransformerEncoderLayer": [[1628, "transformerencoderlayer"]], "SELU": [[1608, "selu"]], "ReflectionPad3d": [[1604, "reflectionpad3d"]], "ReplicationPad3d": [[1607, "replicationpad3d"]], "ZeroPad3d": [[1638, "zeropad3d"]], "torch.nn.attention.bias.causal_lower_right": [[1642, "torch-nn-attention-bias-causal-lower-right"]], "Unflatten": [[1631, "unflatten"]], "Softmax2d": [[1615, "softmax2d"]], "Softmin": [[1616, "softmin"]], "Softplus": [[1617, "softplus"]], "CausalVariant": [[1641, "causalvariant"]], "RReLU": [[1599, "rrelu"]], "Softmax": [[1614, "softmax"]], "TripletMarginWithDistanceLoss": [[1630, "tripletmarginwithdistanceloss"]], "UpsamplingNearest2d": [[1635, "upsamplingnearest2d"]], "Tanhshrink": [[1622, "tanhshrink"]], "SiLU": [[1610, "silu"]], "TransformerEncoder": [[1627, "transformerencoder"]], "torch.nn.attention.sdpa_kernel": [[1644, "torch-nn-attention-sdpa-kernel"]], "ReplicationPad1d": [[1605, "replicationpad1d"]], "SoftMarginLoss": [[1613, "softmarginloss"]], "Tanh": [[1621, "tanh"]], "SDPBackend": [[1639, "sdpbackend"]], "UpsamplingBilinear2d": [[1634, "upsamplingbilinear2d"]], "Sigmoid": [[1611, "sigmoid"], [770, "sigmoid"]], "Softsign": [[1619, "softsign"]], "ReplicationPad2d": [[1606, "replicationpad2d"]], "ReLU": [[1600, "relu"]], "ReflectionPad2d": [[1603, "reflectionpad2d"]], "Unfold": [[1632, "unfold"]], "Dropout": [[1517, "dropout"]], "GRUCell": [[1532, "grucell"], [772, "grucell"]], "L1Loss": [[1546, "l1loss"]], "Dropout2d": [[1519, "dropout2d"]], "EmbeddingBag": [[1523, "embeddingbag"], [757, "embeddingbag"]], "Hardtanh": [[1538, "hardtanh"]], "GaussianNLLLoss": [[1533, "gaussiannllloss"]], "FractionalMaxPool3d": [[1528, "fractionalmaxpool3d"]], "GroupNorm": [[1534, "groupnorm"], [760, "groupnorm"]], "KLDivLoss": [[1545, "kldivloss"]], "Dropout3d": [[1520, "dropout3d"]], "Hardswish": [[1537, "hardswish"], [761, "hardswish"]], "ConvTranspose3d": [[1512, "convtranspose3d"], [754, "convtranspose3d"]], "CrossEntropyLoss": [[1515, "crossentropyloss"]], "HuberLoss": [[1540, "huberloss"]], "HingeEmbeddingLoss": [[1539, "hingeembeddingloss"]], "ConvTranspose1d": [[1510, "convtranspose1d"], [752, "convtranspose1d"]], "Conv1d": [[1507, "conv1d"], [749, "conv1d"]], "Identity": [[1541, "identity"]], "Conv3d": [[1509, "conv3d"], [742, "conv3d"], [751, "conv3d"]], "ELU": [[1521, "elu"], [755, "elu"]], "LSTM": [[1550, "lstm"], [773, "lstm"], [745, "lstm"]], "Fold": [[1526, "fold"]], "GRU": [[1531, "gru"], [771, "gru"]], "ConstantPad1d": [[1504, "constantpad1d"]], "Hardsigmoid": [[1536, "hardsigmoid"]], "GELU": [[1529, "gelu"]], "FeatureAlphaDropout": [[1524, "featurealphadropout"]], "Hardshrink": [[1535, "hardshrink"]], "Dropout1d": [[1518, "dropout1d"]], "DataParallel": [[1516, "dataparallel"]], "LPPool2d": [[1548, "lppool2d"]], "Embedding": [[1522, "embedding"], [756, "embedding"]], "InstanceNorm2d": [[1543, "instancenorm2d"], [763, "instancenorm2d"]], "CosineEmbeddingLoss": [[1513, "cosineembeddingloss"]], "ConvTranspose2d": [[1511, "convtranspose2d"], [753, "convtranspose2d"]], "ConstantPad2d": [[1505, "constantpad2d"]], "CosineSimilarity": [[1514, "cosinesimilarity"]], "InstanceNorm3d": [[1544, "instancenorm3d"], [764, "instancenorm3d"]], "GLU": [[1530, "glu"]], "FractionalMaxPool2d": [[1527, "fractionalmaxpool2d"]], "InstanceNorm1d": [[1542, "instancenorm1d"], [762, "instancenorm1d"]], "LPPool1d": [[1547, "lppool1d"]], "ConstantPad3d": [[1506, "constantpad3d"]], "Flatten": [[1525, "flatten"]], "Conv2d": [[1508, "conv2d"], [741, "conv2d"], [750, "conv2d"]], "LPPool3d": [[1549, "lppool3d"]], "LazyLinear": [[1565, "lazylinear"]], "Linear": [[1567, "linear"], [767, "linear"], [775, "linear"], [743, "linear"], [744, "linear"]], "PairwiseDistance": [[1589, "pairwisedistance"]], "PixelShuffle": [[1592, "pixelshuffle"]], "Mish": [[1579, "mish"]], "RNN": [[1596, "rnn"]], "MarginRankingLoss": [[1572, "marginrankingloss"]], "LazyBatchNorm1d": [[1553, "lazybatchnorm1d"]], "ModuleList": [[1582, "modulelist"]], "NLLLoss": [[1587, "nllloss"]], "MSELoss": [[1571, "mseloss"]], "MaxPool2d": [[1574, "maxpool2d"]], "PReLU": [[1588, "prelu"]], "ParameterList": [[1591, "parameterlist"]], "LeakyReLU": [[1566, "leakyrelu"], [766, "leakyrelu"]], "MultiLabelMarginLoss": [[1583, "multilabelmarginloss"]], "LazyConv2d": [[1557, "lazyconv2d"]], "LazyBatchNorm2d": [[1554, "lazybatchnorm2d"]], "MaxUnpool1d": [[1576, "maxunpool1d"]], "LSTMCell": [[1551, "lstmcell"], [774, "lstmcell"]], "LazyInstanceNorm3d": [[1564, "lazyinstancenorm3d"]], "ParameterDict": [[1590, "parameterdict"]], "MultiLabelSoftMarginLoss": [[1584, "multilabelsoftmarginloss"]], "LazyInstanceNorm2d": [[1563, "lazyinstancenorm2d"]], "Module": [[1580, "module"]], "MaxPool3d": [[1575, "maxpool3d"]], "MaxPool1d": [[1573, "maxpool1d"]], "RNNBase": [[1597, "rnnbase"]], "LayerNorm": [[1552, "layernorm"], [765, "layernorm"]], "LazyConvTranspose2d": [[1560, "lazyconvtranspose2d"]], "LocalResponseNorm": [[1568, "localresponsenorm"]], "MultiMarginLoss": [[1585, "multimarginloss"]], "MultiheadAttention": [[1586, "multiheadattention"], [746, "multiheadattention"]], "LazyConv1d": [[1556, "lazyconv1d"]], "LogSigmoid": [[1569, "logsigmoid"]], "LazyConv3d": [[1558, "lazyconv3d"]], "PixelUnshuffle": [[1593, "pixelunshuffle"]], "ModuleDict": [[1581, "moduledict"]], "LazyBatchNorm3d": [[1555, "lazybatchnorm3d"]], "MaxUnpool2d": [[1577, "maxunpool2d"]], "PoissonNLLLoss": [[1594, "poissonnllloss"]], "LazyInstanceNorm1d": [[1562, "lazyinstancenorm1d"]], "MaxUnpool3d": [[1578, "maxunpool3d"]], "LazyConvTranspose1d": [[1559, "lazyconvtranspose1d"]], "LogSoftmax": [[1570, "logsoftmax"]], "LazyConvTranspose3d": [[1561, "lazyconvtranspose3d"]], "torch.mtia.memory.memory_stats": [[1457, "torch-mtia-memory-memory-stats"]], "torch.nansum": [[1474, "torch-nansum"]], "ChannelShuffle": [[1500, "channelshuffle"]], "CircularPad3d": [[1503, "circularpad3d"]], "torch.nanmean": [[1471, "torch-nanmean"]], "AlphaDropout": [[1488, "alphadropout"]], "torch.nanquantile": [[1473, "torch-nanquantile"]], "torch.mvlgamma": [[1469, "torch-mvlgamma"]], "AdaptiveAvgPool1d": [[1481, "adaptiveavgpool1d"]], "torch.nan_to_num": [[1470, "torch-nan-to-num"]], "AdaptiveMaxPool2d": [[1486, "adaptivemaxpool2d"]], "CircularPad1d": [[1501, "circularpad1d"]], "BCELoss": [[1492, "bceloss"]], "torch.narrow_copy": [[1476, "torch-narrow-copy"]], "torch.nanmedian": [[1472, "torch-nanmedian"]], "torch.nextafter": [[1480, "torch-nextafter"]], "AdaptiveMaxPool3d": [[1487, "adaptivemaxpool3d"]], "BCEWithLogitsLoss": [[1493, "bcewithlogitsloss"]], "torch.mtia.set_device": [[1460, "torch-mtia-set-device"]], "AvgPool3d": [[1491, "avgpool3d"]], "AdaptiveLogSoftmaxWithLoss": [[1484, "adaptivelogsoftmaxwithloss"]], "AdaptiveMaxPool1d": [[1485, "adaptivemaxpool1d"]], "CircularPad2d": [[1502, "circularpad2d"]], "BatchNorm2d": [[1495, "batchnorm2d"], [747, "batchnorm2d"]], "torch.mtia.set_stream": [[1462, "torch-mtia-set-stream"]], "torch.narrow": [[1475, "torch-narrow"]], "torch.negative": [[1479, "torch-negative"]], "torch.mul": [[1465, "torch-mul"]], "Bilinear": [[1497, "bilinear"]], "BatchNorm1d": [[1494, "batchnorm1d"]], "CTCLoss": [[1499, "ctcloss"]], "torch.multinomial": [[1466, "torch-multinomial"]], "BatchNorm3d": [[1496, "batchnorm3d"], [748, "batchnorm3d"]], "AvgPool1d": [[1489, "avgpool1d"]], "torch.mtia.snapshot": [[1463, "torch-mtia-snapshot"]], "torch.mtia.memory_stats": [[1458, "torch-mtia-memory-stats"]], "torch.mtia.record_memory_history": [[1459, "torch-mtia-record-memory-history"]], "torch.neg": [[1478, "torch-neg"]], "CELU": [[1498, "celu"]], "AdaptiveAvgPool2d": [[1482, "adaptiveavgpool2d"]], "torch.ne": [[1477, "torch-ne"]], "torch.mtia.synchronize": [[1464, "torch-mtia-synchronize"]], "torch.mtia.set_rng_state": [[1461, "torch-mtia-set-rng-state"]], "torch.mv": [[1468, "torch-mv"]], "AvgPool2d": [[1490, "avgpool2d"]], "torch.multiply": [[1467, "torch-multiply"]], "AdaptiveAvgPool3d": [[1483, "adaptiveavgpool3d"]], "torch.linalg.slogdet": [[1374, "torch-linalg-slogdet"]], "torch.matmul": [[1409, "torch-matmul"]], "torch.linalg.tensorinv": [[1380, "torch-linalg-tensorinv"]], "torch.logcumsumexp": [[1394, "torch-logcumsumexp"]], "torch.linalg.matrix_power": [[1368, "torch-linalg-matrix-power"]], "torch.linalg.matmul": [[1365, "torch-linalg-matmul"]], "torch.linalg.vecdot": [[1383, "torch-linalg-vecdot"]], "torch.log1p": [[1390, "torch-log1p"]], "torch.linalg.solve_ex": [[1376, "torch-linalg-solve-ex"]], "torch.logit": [[1400, "torch-logit"]], "torch.logical_xor": [[1399, "torch-logical-xor"]], "torch.linalg.qr": [[1373, "torch-linalg-qr"]], "torch.linalg.lu_solve": [[1364, "torch-linalg-lu-solve"]], "torch.linalg.lu_factor_ex": [[1363, "torch-linalg-lu-factor-ex"]], "torch.logsumexp": [[1402, "torch-logsumexp"]], "torch.linalg.pinv": [[1372, "torch-linalg-pinv"]], "torch.linalg.multi_dot": [[1370, "torch-linalg-multi-dot"]], "torch.linspace": [[1385, "torch-linspace"]], "torch.linalg.svdvals": [[1379, "torch-linalg-svdvals"]], "torch.lt": [[1403, "torch-lt"]], "torch.linalg.matrix_exp": [[1366, "torch-linalg-matrix-exp"]], "torch.logspace": [[1401, "torch-logspace"]], "torch.linalg.solve": [[1375, "torch-linalg-solve"]], "torch.linalg.norm": [[1371, "torch-linalg-norm"]], "torch.logaddexp2": [[1393, "torch-logaddexp2"]], "torch.lu_unpack": [[1406, "torch-lu-unpack"]], "torch.logdet": [[1395, "torch-logdet"]], "torch.masked_select": [[1408, "torch-masked-select"]], "torch.load": [[1386, "torch-load"]], "torch.log2": [[1391, "torch-log2"]], "torch.logaddexp": [[1392, "torch-logaddexp"]], "torch.lobpcg": [[1387, "torch-lobpcg"]], "torch.lu_solve": [[1405, "torch-lu-solve"]], "torch.linalg.vander": [[1382, "torch-linalg-vander"]], "torch.linalg.vector_norm": [[1384, "torch-linalg-vector-norm"]], "torch.logical_not": [[1397, "torch-logical-not"]], "torch.logical_or": [[1398, "torch-logical-or"]], "torch.manual_seed": [[1407, "torch-manual-seed"]], "torch.log10": [[1389, "torch-log10"]], "torch.log": [[1388, "torch-log"]], "torch.linalg.matrix_rank": [[1369, "torch-linalg-matrix-rank"]], "torch.linalg.svd": [[1378, "torch-linalg-svd"]], "torch.logical_and": [[1396, "torch-logical-and"]], "torch.lu": [[1404, "torch-lu"]], "torch.linalg.solve_triangular": [[1377, "torch-linalg-solve-triangular"]], "torch.linalg.matrix_norm": [[1367, "torch-linalg-matrix-norm"]], "torch.linalg.tensorsolve": [[1381, "torch-linalg-tensorsolve"]], "torch.jit.trace": [[1330, "torch-jit-trace"]], "torch.jit.optimize_for_inference": [[1324, "torch-jit-optimize-for-inference"]], "torch.jit.isinstance": [[1321, "torch-jit-isinstance"]], "torch.jit.script_if_tracing": [[1327, "torch-jit-script-if-tracing"]], "torch.linalg.eigvalsh": [[1353, "torch-linalg-eigvalsh"]], "torch.linalg.det": [[1348, "torch-linalg-det"]], "torch.jit.onednn_fusion_enabled": [[1323, "torch-jit-onednn-fusion-enabled"]], "torch.jit.load": [[1322, "torch-jit-load"]], "torch.linalg.eig": [[1350, "torch-linalg-eig"]], "strict_fusion": [[1329, "strict-fusion"]], "torch.kron": [[1335, "torch-kron"]], "torch.linalg.inv_ex": [[1356, "torch-linalg-inv-ex"]], "torch.linalg.lu_factor": [[1362, "torch-linalg-lu-factor"]], "torch.linalg.eigh": [[1351, "torch-linalg-eigh"]], "torch.linalg.ldl_solve": [[1359, "torch-linalg-ldl-solve"]], "torch.linalg.ldl_factor": [[1357, "torch-linalg-ldl-factor"]], "torch.jit.interface": [[1320, "torch-jit-interface"]], "torch.linalg.lu": [[1361, "torch-linalg-lu"]], "torch.jit.save": [[1325, "torch-jit-save"]], "torch.linalg.lstsq": [[1360, "torch-linalg-lstsq"]], "torch.jit.freeze": [[1318, "torch-jit-freeze"]], "torch.lgamma": [[1343, "torch-lgamma"]], "torch.linalg.householder_product": [[1354, "torch-linalg-householder-product"]], "torch.jit.wait": [[1333, "torch-jit-wait"]], "torch.jit.ignore": [[1319, "torch-jit-ignore"]], "torch.linalg.eigvals": [[1352, "torch-linalg-eigvals"]], "torch.less_equal": [[1342, "torch-less-equal"]], "torch.jit.enable_onednn_fusion": [[1316, "torch-jit-enable-onednn-fusion"]], "torch.kthvalue": [[1336, "torch-kthvalue"]], "torch.jit.script": [[1326, "torch-jit-script"]], "torch.linalg.inv": [[1355, "torch-linalg-inv"]], "torch.jit.fork": [[1317, "torch-jit-fork"]], "torch.linalg.cond": [[1346, "torch-linalg-cond"]], "torch.jit.unused": [[1332, "torch-jit-unused"]], "torch.linalg.cholesky_ex": [[1345, "torch-linalg-cholesky-ex"]], "torch.le": [[1339, "torch-le"]], "torch.ldexp": [[1338, "torch-ldexp"]], "torch.less": [[1341, "torch-less"]], "torch.jit.set_fusion_strategy": [[1328, "torch-jit-set-fusion-strategy"]], "torch.jit.trace_module": [[1331, "torch-jit-trace-module"]], "torch.kaiser_window": [[1334, "torch-kaiser-window"]], "torch.linalg.cholesky": [[1344, "torch-linalg-cholesky"]], "torch.lcm": [[1337, "torch-lcm"]], "torch.linalg.cross": [[1347, "torch-linalg-cross"]], "torch.linalg.diagonal": [[1349, "torch-linalg-diagonal"]], "torch.linalg.ldl_factor_ex": [[1358, "torch-linalg-ldl-factor-ex"]], "torch.lerp": [[1340, "torch-lerp"]], "torch.is_inference_mode_enabled": [[1298, "torch-is-inference-mode-enabled"]], "torch.initial_seed": [[1290, "torch-initial-seed"]], "torch.is_floating_point": [[1296, "torch-is-floating-point"]], "torch.jit.annotate": [[1315, "torch-jit-annotate"]], "torch.hsplit": [[1278, "torch-hsplit"]], "Attribute": [[1312, "attribute"]], "torch.is_conj": [[1294, "torch-is-conj"]], "torch.isnan": [[1307, "torch-isnan"]], "torch.istft": [[1311, "torch-istft"]], "torch.hypot": [[1281, "torch-hypot"]], "torch.inverse": [[1292, "torch-inverse"]], "torch.isposinf": [[1309, "torch-isposinf"]], "torch.index_add": [[1286, "torch-index-add"]], "torch.hspmm": [[1279, "torch-hspmm"]], "torch.hamming_window": [[1272, "torch-hamming-window"]], "torch.isinf": [[1306, "torch-isinf"]], "torch.igamma": [[1283, "torch-igamma"]], "torch.heaviside": [[1274, "torch-heaviside"]], "torch.is_deterministic_algorithms_warn_only_enabled": [[1295, "torch-is-deterministic-algorithms-warn-only-enabled"]], "torch.index_copy": [[1287, "torch-index-copy"]], "torch.greater": [[1269, "torch-greater"]], "torch.histc": [[1275, "torch-histc"]], "torch.histogramdd": [[1277, "torch-histogramdd"]], "torch.isclose": [[1303, "torch-isclose"]], "ScriptModule": [[1314, "scriptmodule"]], "torch.i0": [[1282, "torch-i0"]], "torch.is_complex": [[1293, "torch-is-complex"]], "torch.is_grad_enabled": [[1297, "torch-is-grad-enabled"]], "torch.is_storage": [[1300, "torch-is-storage"]], "torch.gt": [[1271, "torch-gt"]], "torch.histogram": [[1276, "torch-histogram"]], "torch.is_warn_always_enabled": [[1302, "torch-is-warn-always-enabled"]], "torch.hstack": [[1280, "torch-hstack"]], "torch.greater_equal": [[1270, "torch-greater-equal"]], "torch.igammac": [[1284, "torch-igammac"]], "torch.is_tensor": [[1301, "torch-is-tensor"]], "torch.index_reduce": [[1288, "torch-index-reduce"]], "torch.is_nonzero": [[1299, "torch-is-nonzero"]], "torch.hann_window": [[1273, "torch-hann-window"]], "torch.isfinite": [[1304, "torch-isfinite"]], "torch.isreal": [[1310, "torch-isreal"]], "torch.imag": [[1285, "torch-imag"]], "torch.index_select": [[1289, "torch-index-select"]], "torch.isneginf": [[1308, "torch-isneginf"]], "torch.isin": [[1305, "torch-isin"]], "torch.inner": [[1291, "torch-inner"]], "ScriptFunction": [[1313, "scriptfunction"]], "torch.fft.ihfftn": [[1174, "torch-fft-ihfftn"]], "torch.diagonal": [[1134, "torch-diagonal"]], "torch.fake_quantize_per_tensor_affine": [[1159, "torch-fake-quantize-per-tensor-affine"]], "torch.deg2rad": [[1128, "torch-deg2rad"]], "torch.einsum": [[1144, "torch-einsum"]], "torch.empty": [[1145, "torch-empty"]], "torch.det": [[1130, "torch-det"]], "torch.dequantize": [[1129, "torch-dequantize"]], "torch.erfc": [[1152, "torch-erfc"]], "torch.digamma": [[1137, "torch-digamma"]], "torch.erfinv": [[1153, "torch-erfinv"]], "torch.dot": [[1141, "torch-dot"]], "torch.fft.hfftn": [[1167, "torch-fft-hfftn"]], "torch.exp": [[1154, "torch-exp"]], "torch.dstack": [[1143, "torch-dstack"]], "torch.fft.fftshift": [[1164, "torch-fft-fftshift"]], "torch.diag": [[1131, "torch-diag"]], "torch.empty_like": [[1146, "torch-empty-like"]], "torch.fft.fft2": [[1161, "torch-fft-fft2"]], "torch.div": [[1139, "torch-div"]], "torch.dsplit": [[1142, "torch-dsplit"]], "torch.fake_quantize_per_channel_affine": [[1158, "torch-fake-quantize-per-channel-affine"]], "torch.fft.ihfft2": [[1173, "torch-fft-ihfft2"]], "torch.equal": [[1150, "torch-equal"]], "torch.exp2": [[1155, "torch-exp2"]], "torch.fft.ifft2": [[1169, "torch-fft-ifft2"]], "torch.fft.ihfft": [[1172, "torch-fft-ihfft"]], "torch.diff": [[1136, "torch-diff"]], "torch.diagonal_scatter": [[1135, "torch-diagonal-scatter"]], "torch.eq": [[1149, "torch-eq"]], "torch.fft.hfft": [[1165, "torch-fft-hfft"]], "torch.expm1": [[1156, "torch-expm1"]], "torch.eye": [[1157, "torch-eye"]], "torch.fft.fftfreq": [[1162, "torch-fft-fftfreq"]], "torch.diagflat": [[1133, "torch-diagflat"]], "torch.fft.ifft": [[1168, "torch-fft-ifft"]], "torch.erf": [[1151, "torch-erf"]], "torch.fft.fftn": [[1163, "torch-fft-fftn"]], "torch.fft.hfft2": [[1166, "torch-fft-hfft2"]], "torch.divide": [[1140, "torch-divide"]], "torch.fft.fft": [[1160, "torch-fft-fft"]], "enable_grad": [[1148, "enable-grad"]], "torch.fft.ifftn": [[1170, "torch-fft-ifftn"]], "torch.fft.ifftshift": [[1171, "torch-fft-ifftshift"]], "torch.dist": [[1138, "torch-dist"]], "torch.diag_embed": [[1132, "torch-diag-embed"]], "torch.empty_strided": [[1147, "torch-empty-strided"]], "torch.func.linearize": [[1209, "torch-func-linearize"]], "torch.fx.experimental.proxy_tensor.maybe_enable_thunkify": [[1218, "torch-fx-experimental-proxy-tensor-maybe-enable-thunkify"]], "torch.frexp": [[1194, "torch-frexp"]], "torch.full_like": [[1200, "torch-full-like"]], "torch.fft.rfft": [[1178, "torch-fft-rfft"]], "torch.func.functional_call": [[1201, "torch-func-functional-call"]], "torch.fft.rfft2": [[1179, "torch-fft-rfft2"]], "torch.flipud": [[1186, "torch-flipud"]], "torch.func.grad_and_value": [[1204, "torch-func-grad-and-value"]], "torch.fx.experimental.proxy_tensor.make_fx": [[1216, "torch-fx-experimental-proxy-tensor-make-fx"]], "torch.func.vjp": [[1212, "torch-func-vjp"]], "torch.fmax": [[1190, "torch-fmax"]], "torch.flip": [[1184, "torch-flip"]], "torch.fft.irfft2": [[1176, "torch-fft-irfft2"]], "torch.fx.experimental.proxy_tensor.get_proxy_mode": [[1214, "torch-fx-experimental-proxy-tensor-get-proxy-mode"]], "torch.float_power": [[1187, "torch-float-power"]], "torch.frombuffer": [[1198, "torch-frombuffer"]], "torch.fx.experimental.proxy_tensor.handle_sym_dispatch": [[1215, "torch-fx-experimental-proxy-tensor-handle-sym-dispatch"]], "torch.func.replace_all_batch_norm_modules_": [[1210, "torch-func-replace-all-batch-norm-modules"]], "torch.func.functionalize": [[1202, "torch-func-functionalize"]], "ConvertIntKey": [[1220, "convertintkey"]], "torch.from_file": [[1196, "torch-from-file"]], "torch.fft.rfftn": [[1181, "torch-fft-rfftn"]], "torch.from_dlpack": [[1195, "torch-from-dlpack"]], "DimConstraints": [[1221, "dimconstraints"]], "torch.fmod": [[1192, "torch-fmod"]], "torch.floor_divide": [[1189, "torch-floor-divide"]], "torch.from_numpy": [[1197, "torch-from-numpy"]], "torch.full": [[1199, "torch-full"]], "torch.fx.experimental.proxy_tensor.maybe_disable_thunkify": [[1217, "torch-fx-experimental-proxy-tensor-maybe-disable-thunkify"]], "torch.fft.irfft": [[1175, "torch-fft-irfft"]], "CallMethodKey": [[1219, "callmethodkey"]], "torch.fix": [[1182, "torch-fix"]], "torch.flatten": [[1183, "torch-flatten"]], "torch.func.jvp": [[1208, "torch-func-jvp"]], "torch.func.stack_module_state": [[1211, "torch-func-stack-module-state"]], "torch.func.vmap": [[1213, "torch-func-vmap"]], "torch.fft.irfftn": [[1177, "torch-fft-irfftn"]], "torch.fft.rfftfreq": [[1180, "torch-fft-rfftfreq"]], "torch.func.jacrev": [[1207, "torch-func-jacrev"]], "torch.floor": [[1188, "torch-floor"]], "torch.func.jacfwd": [[1206, "torch-func-jacfwd"]], "torch.fmin": [[1191, "torch-fmin"]], "torch.func.grad": [[1203, "torch-func-grad"]], "torch.fliplr": [[1185, "torch-fliplr"]], "torch.frac": [[1193, "torch-frac"]], "torch.func.hessian": [[1205, "torch-func-hessian"]], "torch.get_float32_matmul_precision": [[1264, "torch-get-float32-matmul-precision"]], "torch.fx.experimental.symbolic_shapes.has_free_unbacked_symbols": [[1244, "torch-fx-experimental-symbolic-shapes-has-free-unbacked-symbols"]], "DivideByKey": [[1223, "dividebykey"]], "torch.fx.experimental.symbolic_shapes.hint_int": [[1245, "torch-fx-experimental-symbolic-shapes-hint-int"]], "torch.get_device_module": [[1263, "torch-get-device-module"]], "torch.fx.experimental.symbolic_shapes.definitely_false": [[1240, "torch-fx-experimental-symbolic-shapes-definitely-false"]], "StrictMinMaxConstraint": [[1232, "strictminmaxconstraint"]], "torch.fx.experimental.symbolic_shapes.rebind_unbacked": [[1251, "torch-fx-experimental-symbolic-shapes-rebind-unbacked"]], "PropagateUnbackedSymInts": [[1226, "propagateunbackedsymints"]], "torch.geqrf": [[1258, "torch-geqrf"]], "InnerTensorKey": [[1225, "innertensorkey"]], "torch.fx.experimental.symbolic_shapes.lru_cache": [[1250, "torch-fx-experimental-symbolic-shapes-lru-cache"]], "torch.fx.experimental.symbolic_shapes.constrain_range": [[1238, "torch-fx-experimental-symbolic-shapes-constrain-range"]], "torch.fx.experimental.symbolic_shapes.check_consistent": [[1236, "torch-fx-experimental-symbolic-shapes-check-consistent"]], "torch.ger": [[1259, "torch-ger"]], "torch.gcd": [[1256, "torch-gcd"]], "RelaxedUnspecConstraint": [[1227, "relaxedunspecconstraint"]], "torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr": [[1235, "torch-fx-experimental-symbolic-shapes-canonicalize-bool-expr"]], "torch.fx.experimental.symbolic_shapes.resolve_unbacked_bindings": [[1252, "torch-fx-experimental-symbolic-shapes-resolve-unbacked-bindings"]], "ShapeEnvSettings": [[1229, "shapeenvsettings"]], "torch.fx.experimental.symbolic_shapes.definitely_true": [[1241, "torch-fx-experimental-symbolic-shapes-definitely-true"]], "torch.get_num_threads": [[1266, "torch-get-num-threads"]], "torch.gradient": [[1268, "torch-gradient"]], "DimDynamic": [[1222, "dimdynamic"]], "torch.fx.experimental.symbolic_shapes.is_concrete_int": [[1249, "torch-fx-experimental-symbolic-shapes-is-concrete-int"]], "EqualityConstraint": [[1224, "equalityconstraint"]], "torch.get_default_dtype": [[1261, "torch-get-default-dtype"]], "StatefulSymbolicContext": [[1230, "statefulsymboliccontext"]], "torch.fx.experimental.symbolic_shapes.guard_size_oblivious": [[1242, "torch-fx-experimental-symbolic-shapes-guard-size-oblivious"]], "torch.fx.experimental.symbolic_shapes.constrain_unify": [[1239, "torch-fx-experimental-symbolic-shapes-constrain-unify"]], "ShapeEnv": [[1228, "shapeenv"]], "torch.gather": [[1255, "torch-gather"]], "SubclassSymbolicContext": [[1233, "subclasssymboliccontext"]], "torch.fx.experimental.symbolic_shapes.sym_eq": [[1254, "torch-fx-experimental-symbolic-shapes-sym-eq"]], "torch.get_rng_state": [[1267, "torch-get-rng-state"]], "torch.get_default_device": [[1260, "torch-get-default-device"]], "SymbolicContext": [[1234, "symboliccontext"]], "torch.get_num_interop_threads": [[1265, "torch-get-num-interop-threads"]], "torch.fx.experimental.symbolic_shapes.is_concrete_float": [[1248, "torch-fx-experimental-symbolic-shapes-is-concrete-float"]], "torch.fx.experimental.symbolic_shapes.has_free_symbols": [[1243, "torch-fx-experimental-symbolic-shapes-has-free-symbols"]], "torch.fx.experimental.symbolic_shapes.is_accessor_node": [[1246, "torch-fx-experimental-symbolic-shapes-is-accessor-node"]], "torch.ge": [[1257, "torch-ge"]], "torch.fx.experimental.symbolic_shapes.is_concrete_bool": [[1247, "torch-fx-experimental-symbolic-shapes-is-concrete-bool"]], "StatelessSymbolicContext": [[1231, "statelesssymboliccontext"]], "torch.get_deterministic_debug_mode": [[1262, "torch-get-deterministic-debug-mode"]], "torch.fx.experimental.symbolic_shapes.compute_unbacked_bindings": [[1237, "torch-fx-experimental-symbolic-shapes-compute-unbacked-bindings"]], "torch.fx.experimental.symbolic_shapes.statically_known_true": [[1253, "torch-fx-experimental-symbolic-shapes-statically-known-true"]], "torch.ao.ns._numeric_suite": [[2181, "torch-ao-ns-numeric-suite"]], "IRs": [[2199, "irs"]], "Core Aten IR": [[2199, "core-aten-ir"]], "Prims IR": [[2199, "prims-ir"]], "PyTorch 2.0 Troubleshooting (old)": [[2205, "pytorch-2-0-troubleshooting-old"]], "Title": [[2205, "id1"]], "Diagnosing Runtime Errors": [[2205, "diagnosing-runtime-errors"]], "Torchdynamo Errors": [[2205, "torchdynamo-errors"]], "Diagnosing TorchInductor Errors": [[2205, "diagnosing-torchinductor-errors"]], "Minifying TorchInductor Errors": [[2205, "minifying-torchinductor-errors"]], "Minifying Backend Compiler Errors": [[2205, "minifying-backend-compiler-errors"]], "Performance Profiling": [[2205, "performance-profiling"]], "Accessing TorchDynamo Profiler": [[2205, "accessing-torchdynamo-profiler"]], "TorchInductor Debugging using TORCH_COMPILE_DEBUG": [[2205, "torchinductor-debugging-using-torch-compile-debug"]], "Identifying the Cause of a Graph Break": [[2205, "identifying-the-cause-of-a-graph-break"]], "Excessive Recompilation": [[2205, "excessive-recompilation"]], "Accuracy Debugging": [[2205, "accuracy-debugging"]], "Extended Debugging": [[2205, "extended-debugging"]], "Cold Start Timing and Cache Corruption Debugging": [[2205, "cold-start-timing-and-cache-corruption-debugging"]], "torch.ao.ns._numeric_suite_fx": [[2182, "torch-ao-ns-numeric-suite-fx"]], "torch.ao.ns.fx.utils": [[2182, "torch-ao-ns-fx-utils"]], "PyTorch 2.0 NNModule Support": [[2200, "pytorch-2-0-nnmodule-support"]], "NNModule Hooks Support": [[2200, "nnmodule-hooks-support"]], "nn.Module.__call__ Hooks Usage and limitations": [[2200, "nn-module-call-hooks-usage-and-limitations"]], "state_dict Hooks": [[2200, "state-dict-hooks"]], "TorchInductor GPU Profiling": [[2198, "torchinductor-gpu-profiling"]], "Relevant Environment Variables": [[2198, "relevant-environment-variables"]], "Breakdown Model GPU Time": [[2198, "breakdown-model-gpu-time"]], "Benchmark Individual Triton Kernel": [[2198, "benchmark-individual-triton-kernel"]], "Threading Environment Variables": [[2179, "threading-environment-variables"]], "Quantization Accuracy Debugging": [[2162, "quantization-accuracy-debugging"], [2161, "quantization-accuracy-debugging"]], "Data insensitive error": [[2162, "data-insensitive-error"]], "General tips": [[2162, "general-tips"]], "Int8 quantization tips": [[2162, "int8-quantization-tips"]], "Data sensitive error": [[2162, "data-sensitive-error"]], "Implementation error": [[2162, "implementation-error"]], "Numerical Debugging Tooling (prototype)": [[2162, "numerical-debugging-tooling-prototype"]], "torch.special": [[2172, "torch-special"]], "Torch Environment Variables": [[2208, "torch-environment-variables"]], "Understanding CUDA Memory Usage": [[2207, "understanding-cuda-memory-usage"]], "Generating a Snapshot": [[2207, "generating-a-snapshot"]], "Using the visualizer": [[2207, "using-the-visualizer"]], "Active Memory Timeline": [[2207, "active-memory-timeline"]], "Allocator State History": [[2207, "allocator-state-history"]], "Snapshot API Reference": [[2207, "snapshot-api-reference"]], "Writing Graph Transformations on ATen IR": [[2203, "writing-graph-transformations-on-aten-ir"]], "Passes": [[2203, "passes"]], "One-to-One Pass": [[2203, "one-to-one-pass"]], "One-to-X Pass": [[2203, "one-to-x-pass"]], "One-to-None Pass": [[2203, "one-to-none-pass"]], "Utilizing Local Information": [[2203, "utilizing-local-information"]], "Subgraph Rewriter": [[2203, "subgraph-rewriter"]], "Pass Manager": [[2203, "pass-manager"]], "Partitioner": [[2203, "partitioner"]], "Subgraph Matcher": [[2203, "subgraph-matcher"]], "Capability Based Partitioner": [[2203, "capability-based-partitioner"]], "torch.compiler.config": [[2184, "module-torch.compiler.config"]], "Dynamo Deep-Dive": [[2192, "dynamo-deep-dive"]], "A Gentle Introduction to Dynamo": [[2192, "a-gentle-introduction-to-dynamo"]], "PEP 523: Adding a frame evaluation API to CPython": [[2192, "pep-523-adding-a-frame-evaluation-api-to-cpython"]], "Implementing CPython in Python": [[2192, "implementing-cpython-in-python"]], "Generating the Output Graph": [[2192, "generating-the-output-graph"]], "Making Dynamo Sound: Guards": [[2192, "making-dynamo-sound-guards"]], "Symbolic Shapes": [[2192, "symbolic-shapes"]], "Static by default": [[2192, "static-by-default"]], "0, 1 are always specialized": [[2192, "are-always-specialized"]], "Duck shaping": [[2192, "duck-shaping"]], "Guards on symbolic ints": [[2192, "guards-on-symbolic-ints"]], "Making Dynamo Complete: Graph Breaks": [[2192, "making-dynamo-complete-graph-breaks"]], "Conclusion": [[2192, "conclusion"]], "Footnotes": [[2192, "footnotes"]], "PyTorch 2.0 Performance Dashboard": [[2201, "pytorch-2-0-performance-dashboard"]], "How to read the dashboard?": [[2201, "how-to-read-the-dashboard"]], "What is measured on the dashboard?": [[2201, "what-is-measured-on-the-dashboard"]], "Can I check if my PR affects TorchInductor\u2019s performance on the dashboard before merging?": [[2201, "can-i-check-if-my-pr-affects-torchinductor-s-performance-on-the-dashboard-before-merging"]], "How can I run any performance test locally?": [[2201, "how-can-i-run-any-performance-test-locally"]], "Tensor Attributes": [[2174, "tensor-attributes"]], "torch.dtype": [[2174, "torch-dtype"]], "torch.device": [[2174, "torch-device"]], "torch.layout": [[2174, "torch-layout"]], "torch.memory_format": [[2174, "torch-memory-format"]], "Distributed RPC Framework": [[2166, "distributed-rpc-framework"]], "Basics": [[2166, "basics"], [2122, "basics"], [30, "basics"]], "RPC": [[2166, "rpc"]], "Backends": [[2166, "backends"], [30, "backends"]], "TensorPipe Backend": [[2166, "tensorpipe-backend"]], "RRef": [[2166, "rref"]], "More Information about RRef": [[2166, null]], "RemoteModule": [[2166, "remotemodule"]], "Distributed Autograd Framework": [[2166, "distributed-autograd-framework"]], "More Information about RPC Autograd": [[2166, null]], "Distributed Optimizer": [[2166, "distributed-optimizer"], [2167, "distributed-optimizer"]], "Tutorials": [[2166, "tutorials"], [2158, "tutorials"], [8, "tutorials"]], "Quantization API Reference": [[2164, "quantization-api-reference"], [2161, "quantization-api-reference"]], "torch.ao.quantization": [[2164, "torch-ao-quantization"]], "Top level APIs": [[2164, "top-level-apis"]], "Preparing model for quantization": [[2164, "preparing-model-for-quantization"]], "Utility functions": [[2164, "utility-functions"], [2147, "utility-functions"]], "torch.ao.quantization.quantize_fx": [[2164, "torch-ao-quantization-quantize-fx"]], "torch.ao.quantization.qconfig_mapping": [[2164, "torch-ao-quantization-qconfig-mapping"]], "torch.ao.quantization.backend_config": [[2164, "torch-ao-quantization-backend-config"]], "torch.ao.quantization.fx.custom_config": [[2164, "torch-ao-quantization-fx-custom-config"]], "torch.ao.quantization.quantizer": [[2164, "module-torch.ao.quantization.quantizer"]], "torch.ao.quantization.pt2e (quantization in pytorch 2.0 export implementation)": [[2164, "module-torch.ao.quantization.pt2e"]], "torch.ao.quantization.pt2e.export_utils": [[2164, "torch-ao-quantization-pt2e-export-utils"]], "PT2 Export (pt2e) Numeric Debugger": [[2164, "pt2-export-pt2e-numeric-debugger"]], "torch (quantization related functions)": [[2164, "torch-quantization-related-functions"]], "torch.Tensor (quantization related methods)": [[2164, "torch-tensor-quantization-related-methods"]], "torch.ao.quantization.observer": [[2164, "torch-ao-quantization-observer"]], "torch.ao.quantization.fake_quantize": [[2164, "torch-ao-quantization-fake-quantize"]], "torch.ao.quantization.qconfig": [[2164, "torch-ao-quantization-qconfig"]], "torch.ao.nn.intrinsic": [[2164, "module-torch.ao.nn.intrinsic"]], "torch.ao.nn.intrinsic.qat": [[2164, "module-torch.ao.nn.intrinsic.qat"]], "torch.ao.nn.intrinsic.quantized": [[2164, "module-torch.ao.nn.intrinsic.quantized"]], "torch.ao.nn.intrinsic.quantized.dynamic": [[2164, "module-torch.ao.nn.intrinsic.quantized.dynamic"]], "torch.ao.nn.qat": [[2164, "module-torch.ao.nn.qat"]], "torch.ao.nn.qat.dynamic": [[2164, "module-torch.ao.nn.qat.dynamic"]], "torch.ao.nn.quantized": [[2164, "module-torch.ao.nn.quantized.modules"]], "torch.ao.nn.quantized.functional": [[2164, "module-torch.ao.nn.quantized.functional"]], "torch.ao.nn.quantizable": [[2164, "torch-ao-nn-quantizable"]], "torch.ao.nn.quantized.dynamic": [[2164, "module-torch.ao.nn.quantized.dynamic"]], "Quantized dtypes and quantization schemes": [[2164, "quantized-dtypes-and-quantization-schemes"]], "torch.compiler": [[2183, "torch-compiler"]], "Getting Started for PyTorch Users": [[2183, null]], "HowTo for PyTorch Backend Vendors": [[2183, null]], "torch.Storage": [[2173, "torch-storage"]], "Untyped Storage API": [[2173, "untyped-storage-api"]], "Special cases": [[2173, "special-cases"]], "Legacy Typed Storage": [[2173, "legacy-typed-storage"]], "Tensor Views": [[2175, "tensor-views"]], "torch.overrides": [[2206, "module-torch.overrides"]], "torch.testing": [[2178, "module-torch.testing"]], "Dynamo Overview": [[2193, "dynamo-overview"]], "Dynamo Internals": [[2193, "dynamo-internals"]], "What is a guard?": [[2193, "what-is-a-guard"]], "What is Dynamo doing?": [[2193, "what-is-dynamo-doing"]], "How to inspect artifacts generated by Dynamo?": [[2193, "how-to-inspect-artifacts-generated-by-dynamo"]], "Distributed Autograd Design": [[2167, "distributed-autograd-design"]], "Background": [[2167, "background"], [2168, "background"], [2189, "background"]], "Autograd recording during the forward pass": [[2167, "autograd-recording-during-the-forward-pass"]], "Distributed Autograd Context": [[2167, "distributed-autograd-context"]], "Distributed Backward Pass": [[2167, "distributed-backward-pass"]], "Computing dependencies": [[2167, "computing-dependencies"]], "FAST mode algorithm": [[2167, "fast-mode-algorithm"]], "SMART mode algorithm": [[2167, "smart-mode-algorithm"]], "Simple end to end example": [[2167, "simple-end-to-end-example"]], "torch.utils.tensorboard": [[2176, "module-torch.utils.tensorboard"]], "Getting Started": [[2197, "getting-started"], [8, "getting-started"]], "Using a pretrained model": [[2197, "using-a-pretrained-model"]], "Next Steps": [[2197, "next-steps"]], "Custom Backends": [[2190, "custom-backends"]], "Registering Custom Backends": [[2190, "registering-custom-backends"]], "Custom Backends after AOTAutograd": [[2190, "custom-backends-after-aotautograd"]], "Examples": [[2190, "examples"], [2137, "examples"], [46, "examples"], [14, "examples"]], "Debugging Backend": [[2190, "debugging-backend"]], "Speedy Backend": [[2190, "speedy-backend"]], "Composable Backends": [[2190, "composable-backends"]], "Does torch.compile support training?": [[2195, "does-torch-compile-support-training"]], "Do you support Distributed code?": [[2195, "do-you-support-distributed-code"]], "Do I still need to export whole graphs?": [[2195, "do-i-still-need-to-export-whole-graphs"]], "Why is my code crashing?": [[2195, "why-is-my-code-crashing"]], "Why is compilation slow?": [[2195, "why-is-compilation-slow"]], "Why are you recompiling in production?": [[2195, "why-are-you-recompiling-in-production"]], "How are you speeding up my code?": [[2195, "how-are-you-speeding-up-my-code"]], "Why am I not seeing speedups?": [[2195, "why-am-i-not-seeing-speedups"]], "Identifying the cause of a graph break": [[2195, "identifying-the-cause-of-a-graph-break"]], "Why didn\u2019t my code recompile when I changed it?": [[2195, "why-didnt-my-code-recompile-when-i-changed-it"]], "Why am I getting incorrect results?": [[2195, "why-am-i-getting-incorrect-results"]], "Why am I getting OOMs?": [[2195, "why-am-i-getting-ooms"]], "Does torch.func work with torch.compile (for grad and vmap transforms)?": [[2195, "does-torch-func-work-with-torch-compile-for-grad-and-vmap-transforms"]], "Calling torch.func transform inside of a function handled with torch.compile": [[2195, "calling-torch-func-transform-inside-of-a-function-handled-with-torch-compile"]], "Compiling torch.func.grad with torch.compile": [[2195, "compiling-torch-func-grad-with-torch-compile"]], "Compiling torch.vmap with torch.compile": [[2195, "compiling-torch-vmap-with-torch-compile"]], "Compiling functions besides the ones which are supported (escape hatch)": [[2195, "compiling-functions-besides-the-ones-which-are-supported-escape-hatch"]], "Does NumPy work with torch.compile?": [[2195, "does-numpy-work-with-torch-compile"]], "Which NumPy features does torch.compile support?": [[2195, "which-numpy-features-does-torch-compile-support"]], "Can I compile NumPy code using torch.compile?": [[2195, "can-i-compile-numpy-code-using-torch-compile"]], "Can I execute NumPy code on CUDA and compute gradients via torch.compile?": [[2195, "can-i-execute-numpy-code-on-cuda-and-compute-gradients-via-torch-compile"]], "How do I debug NumPy code under torch.compile?": [[2195, "how-do-i-debug-numpy-code-under-torch-compile"]], "I torch.compile some NumPy code and I did not see any speed-up.": [[2195, "i-torch-compile-some-numpy-code-and-i-did-not-see-any-speed-up"]], "Which API to use for fine grain tracing?": [[2195, "which-api-to-use-for-fine-grain-tracing"]], "How do I graph break on a function?": [[2195, "how-do-i-graph-break-on-a-function"]], "What\u2019s the difference between torch._dynamo.disable and torch._dynamo.disallow_in_graph": [[2195, "what-s-the-difference-between-torch-dynamo-disable-and-torch-dynamo-disallow-in-graph"]], "What\u2019s the difference between torch._dynamo.disable and torch._dynamo_skip": [[2195, "what-s-the-difference-between-torch-dynamo-disable-and-torch-dynamo-skip"]], "Fake tensor": [[2194, "fake-tensor"]], "Related work": [[2194, "related-work"]], "Overall architecture": [[2194, "overall-architecture"], [2191, "overall-architecture"]], "API: the important bits": [[2194, "api-the-important-bits"]], "Details": [[2194, "details"], [2122, "details"]], "About the tensor subclass": [[2194, "about-the-tensor-subclass"]], "How is each individual operator implemented?": [[2194, "how-is-each-individual-operator-implemented"]], "How does the converter work?": [[2194, "how-does-the-converter-work"]], "Performance characteristics": [[2194, "performance-characteristics"]], "Fake tensor of fake tensor?": [[2194, "fake-tensor-of-fake-tensor"]], "Interaction with dynamic shapes": [[2194, "interaction-with-dynamic-shapes"]], "Other resources": [[2194, "other-resources"]], "torch.random": [[2165, "module-torch.random"]], "Remote Reference Protocol": [[2168, "remote-reference-protocol"]], "RRef Lifetime": [[2168, "rref-lifetime"]], "Design Reasoning": [[2168, "design-reasoning"]], "Implementation": [[2168, "implementation"], [2132, "implementation"]], "Protocol Scenarios": [[2168, "protocol-scenarios"]], "User Share RRef with Owner as Return Value": [[2168, "user-share-rref-with-owner-as-return-value"]], "User Share RRef with Owner as Argument": [[2168, "user-share-rref-with-owner-as-argument"]], "Owner Share RRef with User": [[2168, "owner-share-rref-with-user"]], "User Share RRef with User": [[2168, "user-share-rref-with-user"]], "torch.Tensor": [[2177, "torch-tensor"]], "Data types": [[2177, "data-types"]], "Initializing and basic operations": [[2177, "initializing-and-basic-operations"]], "Tensor class reference": [[2177, "tensor-class-reference"]], "CUDAGraph Trees": [[2189, "cudagraph-trees"]], "CUDAGraph": [[2189, "cudagraph"], [1037, "cudagraph"]], "PyTorch CUDAGraph Integration": [[2189, "pytorch-cudagraph-integration"]], "Make Graphed Callables": [[2189, "make-graphed-callables"]], "TorchDynamo Previous CUDA Graphs Integration": [[2189, "torchdynamo-previous-cuda-graphs-integration"]], "CUDAGraph Trees Integration": [[2189, "cudagraph-trees-integration"]], "Input Mutation Support": [[2189, "input-mutation-support"]], "Dynamic Shape Support": [[2189, "dynamic-shape-support"]], "NCCL Support": [[2189, "nccl-support"]], "Reasons for Skipping CUDAGraph": [[2189, "reasons-for-skipping-cudagraph"]], "Limitations": [[2189, "limitations"], [2196, "limitations"], [2154, "limitations"]], "Best Practices for Backends": [[2188, "best-practices-for-backends"]], "x86 CPU": [[2188, "x86-cpu"], [12, "x86-cpu"]], "Dynamic shapes": [[2191, "dynamic-shapes"]], "Abridged public API": [[2191, "abridged-public-api"]], "The Guard Model": [[2191, "the-guard-model"]], "Abridged internal API": [[2191, "abridged-internal-api"]], "DimDynamic policy": [[2191, "dimdynamic-policy"]], "Unbacked SymInts": [[2191, "unbacked-symints"]], "Quantization Backend Configuration": [[2163, "quantization-backend-configuration"], [2161, "quantization-backend-configuration"]], "Default values for native configurations": [[2163, "default-values-for-native-configurations"]], "torch.Size": [[2170, "torch-size"]], "AOTInductor Minifier": [[2186, "aotinductor-minifier"]], "Example Code": [[2186, "example-code"]], "Minifier Launcher": [[2186, "minifier-launcher"]], "Minified Result": [[2186, "minified-result"]], "torch.compile Troubleshooting": [[2204, "torch-compile-troubleshooting"]], "Setting Expectations": [[2204, "setting-expectations"]], "Compile times": [[2204, "compile-times"]], "Graph break": [[2204, "graph-break"]], "Guards": [[2204, "guards"]], "Recompilation": [[2204, "recompilation"]], "Dynamic Shapes": [[2204, "dynamic-shapes"]], "Logging Tools": [[2204, "logging-tools"]], "tlparse / TORCH_TRACE": [[2204, "tlparse-torch-trace"]], "TORCH_LOGS": [[2204, "torch-logs"]], "tlparse vs. TORCH_LOGS": [[2204, "tlparse-vs-torch-logs"]], "Simple Workarounds": [[2204, "simple-workarounds"]], "Where to apply torch.compile?": [[2204, "where-to-apply-torch-compile"]], "Disabling and Suppressing Errors": [[2204, "disabling-and-suppressing-errors"]], "Resolving graph breaks": [[2204, "resolving-graph-breaks"]], "Data-dependent operations": [[2204, "data-dependent-operations"]], "Custom ops": [[2204, "custom-ops"]], "Printing": [[2204, "printing"]], "Incorrect code": [[2204, "incorrect-code"]], "Dealing with recompilations": [[2204, "dealing-with-recompilations"]], "Is dynamic shapes enabled?": [[2204, "is-dynamic-shapes-enabled"]], "Changing the cache size limit": [[2204, "changing-the-cache-size-limit"]], "Wrapping constants with tensors": [[2204, "wrapping-constants-with-tensors"]], "Reporting Issues": [[2204, "reporting-issues"], [8, "reporting-issues"]], "Ablation": [[2204, "ablation"]], "Bisecting": [[2204, "bisecting"]], "Creating a reproducer": [[2204, "creating-a-reproducer"]], "Minifier": [[2204, "minifier"]], "Debugging Deeper": [[2204, "debugging-deeper"]], "TorchDynamo": [[2204, "torchdynamo"], [12, "torchdynamo"]], "Logging what Dynamo is tracing": [[2204, "logging-what-dynamo-is-tracing"]], "Breakpointing Dynamo tracing": [[2204, "breakpointing-dynamo-tracing"]], "Bytecode generation errors": [[2204, "bytecode-generation-errors"]], "AOTAutograd": [[2204, "aotautograd"]], "Summary of TORCH_LOGS options": [[2204, "summary-of-torch-logs-options"]], "Related Articles": [[2204, "related-articles"]], "torch.signal": [[2169, "module-torch.signal"]], "torch.signal.windows": [[2169, "module-torch.signal.windows"]], "AOTInductor: Ahead-Of-Time Compilation for Torch.Export-ed Models": [[2185, "aotinductor-ahead-of-time-compilation-for-torch-export-ed-models"]], "Model Compilation": [[2185, "model-compilation"]], "Inference in Python": [[2185, "inference-in-python"]], "Inference in C++": [[2185, "inference-in-c"]], "Troubleshooting": [[2185, "troubleshooting"], [2117, "troubleshooting"]], "Debugging Tools": [[2185, null], [37, "debugging-tools"]], "TorchDynamo APIs for fine-grained tracing": [[2196, "torchdynamo-apis-for-fine-grained-tracing"]], "TorchDynamo APIs to control fine-grained tracing": [[2196, "id1"]], "torch.compiler.disable": [[2196, "torch-compiler-disable"], [1008, "torch-compiler-disable"]], "torch._dynamo.disallow_in_graph": [[2196, "torch-dynamo-disallow-in-graph"]], "torch.compiler.allow_in_graph": [[2196, "torch-compiler-allow-in-graph"], [1004, "torch-compiler-allow-in-graph"]], "torch.sparse": [[2171, "torch-sparse"]], "Why and when to use sparsity": [[2171, "why-and-when-to-use-sparsity"]], "Functionality overview": [[2171, "functionality-overview"]], "Operator overview": [[2171, "operator-overview"]], "Sparse Semi-Structured Tensors": [[2171, "sparse-semi-structured-tensors"]], "Constructing Sparse Semi-Structured Tensors": [[2171, "constructing-sparse-semi-structured-tensors"]], "Sparse Semi-Structured Tensor Operations": [[2171, "sparse-semi-structured-tensor-operations"]], "Accelerating nn.Linear with semi-structured sparsity": [[2171, "accelerating-nn-linear-with-semi-structured-sparsity"]], "Sparse COO tensors": [[2171, "sparse-coo-tensors"]], "Construction": [[2171, "construction"], [2117, "construction"]], "Sparse hybrid COO tensors": [[2171, "sparse-hybrid-coo-tensors"]], "Uncoalesced sparse COO tensors": [[2171, "uncoalesced-sparse-coo-tensors"]], "Working with sparse COO tensors": [[2171, "working-with-sparse-coo-tensors"]], "Sparse Compressed Tensors": [[2171, "sparse-compressed-tensors"]], "Sparse CSR Tensor": [[2171, "sparse-csr-tensor"]], "Construction of CSR tensors": [[2171, "construction-of-csr-tensors"]], "CSR Tensor Operations": [[2171, "csr-tensor-operations"]], "Sparse CSC Tensor": [[2171, "sparse-csc-tensor"]], "Construction of CSC tensors": [[2171, "construction-of-csc-tensors"]], "Sparse BSR Tensor": [[2171, "sparse-bsr-tensor"]], "Construction of BSR tensors": [[2171, "construction-of-bsr-tensors"]], "Sparse BSC Tensor": [[2171, "sparse-bsc-tensor"]], "Construction of BSC tensors": [[2171, "construction-of-bsc-tensors"]], "Tools for working with sparse compressed tensors": [[2171, "tools-for-working-with-sparse-compressed-tensors"]], "Construction of sparse compressed tensors": [[2171, "construction-of-sparse-compressed-tensors"]], "Supported operations": [[2171, "supported-operations"]], "Linear Algebra operations": [[2171, "linear-algebra-operations"]], "Tensor methods and sparse": [[2171, "tensor-methods-and-sparse"]], "Torch functions specific to sparse Tensors": [[2171, "torch-functions-specific-to-sparse-tensors"]], "Other functions": [[2171, "other-functions"]], "Zero-preserving unary functions": [[2171, "zero-preserving-unary-functions"]], "torch": [[2180, "module-torch"]], "Tensors": [[2180, "tensors"]], "Creation Ops": [[2180, "creation-ops"]], "Indexing, Slicing, Joining, Mutating Ops": [[2180, "indexing-slicing-joining-mutating-ops"]], "Accelerators": [[2180, "accelerators"]], "Generators": [[2180, "generators"]], "Random sampling": [[2180, "random-sampling"]], "In-place random sampling": [[2180, "in-place-random-sampling"]], "Quasi-random sampling": [[2180, "quasi-random-sampling"]], "Parallelism": [[2180, "parallelism"]], "Locally disabling gradient computation": [[2180, "locally-disabling-gradient-computation"], [2127, "locally-disabling-gradient-computation"], [2, "locally-disabling-gradient-computation"]], "Math operations": [[2180, "math-operations"]], "Pointwise Ops": [[2180, "pointwise-ops"]], "Reduction Ops": [[2180, "reduction-ops"]], "Comparison Ops": [[2180, "comparison-ops"]], "Spectral Ops": [[2180, "spectral-ops"]], "Other Operations": [[2180, "other-operations"]], "BLAS and LAPACK Operations": [[2180, "blas-and-lapack-operations"]], "Foreach Operations": [[2180, "foreach-operations"]], "Utilities": [[2180, "utilities"], [2118, "module-torch.nn.utils"]], "Symbolic Numbers": [[2180, "symbolic-numbers"]], "Export Path": [[2180, "export-path"]], "Control Flow": [[2180, "control-flow"]], "Optimizations": [[2180, "optimizations"]], "Operator Tags": [[2180, "operator-tags"]], "Profiling to understand torch.compile performance": [[2202, "profiling-to-understand-torch-compile-performance"]], "What to use torch.profiler for:": [[2202, "what-to-use-torch-profiler-for"]], "Basics of using torch.profiler and viewing traces": [[2202, "basics-of-using-torch-profiler-and-viewing-traces"]], "Working around CUDA Graph profiling issues": [[2202, "working-around-cuda-graph-profiling-issues"]], "Understanding compilation time": [[2202, "understanding-compilation-time"]], "Finding graph breaks: \u201cTorch-Compiled Region\u201d and \u201cCompiledFunction\u201d": [[2202, "finding-graph-breaks-torch-compiled-region-and-compiledfunction"]], "Operator Kernels": [[2202, "operator-kernels"]], "Launch overhead": [[2202, "launch-overhead"]], "torch.compiler API reference": [[2187, "torch-compiler-api-reference"]], "Extending PyTorch": [[2133, "extending-pytorch"]], "Adding new operators": [[2133, "adding-new-operators"]], "Extending torch.autograd": [[2133, "extending-torch-autograd"]], "When to use": [[2133, "when-to-use"]], "When not to use": [[2133, "when-not-to-use"]], "How to use": [[2133, "how-to-use"]], "Example": [[2133, "example"], [2132, "example"]], "Combined or separate forward() and setup_context()": [[2133, "combined-or-separate-forward-and-setup-context"]], "Forward mode AD": [[2133, "forward-mode-ad"]], "torch.func transforms and/or torch.vmap()": [[2133, "torch-func-transforms-and-or-torch-vmap"]], "Extending torch.nn": [[2133, "extending-torch-nn"]], "Adding a Module": [[2133, "adding-a-module"]], "Extending torch Python API": [[2133, "extending-torch-python-api"]], "Extending torch with a Tensor-like type": [[2133, "extending-torch-with-a-tensor-like-type"]], "Subclassing torch.Tensor": [[2133, "subclassing-torch-tensor"]], "Extending torch with a Tensor wrapper type": [[2133, "extending-torch-with-a-tensor-wrapper-type"]], "Operations on multiple types that define __torch_function__": [[2133, "operations-on-multiple-types-that-define-torch-function"]], "Testing Coverage of Overrides for the PyTorch API": [[2133, "testing-coverage-of-overrides-for-the-pytorch-api"]], "Extending torch native API": [[2133, "extending-torch-native-api"]], "__torch_dispatch__ calling convention": [[2133, "torch-dispatch-calling-convention"]], "Extending all torch API with Modes": [[2133, "extending-all-torch-api-with-modes"]], "torch.profiler": [[2159, "torch-profiler"]], "Intel Instrumentation and Tracing Technology APIs": [[2159, "intel-instrumentation-and-tracing-technology-apis"]], "A Simple Custom Module": [[2142, "a-simple-custom-module"]], "Modules as Building Blocks": [[2142, "modules-as-building-blocks"]], "Neural Network Training with Modules": [[2142, "neural-network-training-with-modules"]], "Module State": [[2142, "module-state"]], "Module Initialization": [[2142, "module-initialization"]], "Module Hooks": [[2142, "module-hooks"]], "Advanced Features": [[2142, "advanced-features"]], "Distributed Training": [[2142, "distributed-training"]], "Profiling Performance": [[2142, "profiling-performance"]], "Improving Performance with Quantization": [[2142, "improving-performance-with-quantization"]], "Improving Memory Usage with Pruning": [[2142, "improving-memory-usage-with-pruning"]], "Parametrizations": [[2142, "parametrizations"]], "Transforming Modules with FX": [[2142, "transforming-modules-with-fx"]], "Getting Started on Intel GPU": [[2137, "getting-started-on-intel-gpu"]], "Hardware Prerequisite": [[2137, "hardware-prerequisite"]], "Software Prerequisite": [[2137, "software-prerequisite"]], "Installation": [[2137, "installation"], [2148, "installation"]], "Binaries": [[2137, "binaries"]], "From Source": [[2137, "from-source"]], "Check availability for Intel GPU": [[2137, "check-availability-for-intel-gpu"]], "Minimum Code Change": [[2137, "minimum-code-change"]], "Inference Examples": [[2137, "inference-examples"]], "Inference with FP32": [[2137, "inference-with-fp32"]], "Inference with AMP": [[2137, "inference-with-amp"]], "Inference with torch.compile": [[2137, "inference-with-torch-compile"]], "Training Examples": [[2137, "training-examples"]], "Train with FP32": [[2137, "train-with-fp32"]], "Train with AMP": [[2137, "train-with-amp"]], "Train with torch.compile": [[2137, "train-with-torch-compile"]], "Named Tensors": [[2116, "named-tensors"]], "Creating named tensors": [[2116, "creating-named-tensors"]], "Named dimensions": [[2116, "named-dimensions"]], "Name propagation semantics": [[2116, "name-propagation-semantics"]], "match semantics": [[2116, "match-semantics"]], "Basic name inference rules": [[2116, "basic-name-inference-rules"]], "Explicit alignment by names": [[2116, "explicit-alignment-by-names"]], "Manipulating dimensions": [[2116, "manipulating-dimensions"]], "Autograd support": [[2116, "autograd-support"]], "Currently supported operations and subsystems": [[2116, "currently-supported-operations-and-subsystems"]], "Operators": [[2116, "operators"], [2153, "operators"]], "Subsystems": [[2116, "subsystems"]], "Named tensor API reference": [[2116, "named-tensor-api-reference"]], "Reproducibility": [[2146, "reproducibility"]], "Controlling sources of randomness": [[2146, "controlling-sources-of-randomness"]], "PyTorch random number generator": [[2146, "pytorch-random-number-generator"]], "Python": [[2146, "python"]], "Random number generators in other libraries": [[2146, "random-number-generators-in-other-libraries"]], "CUDA convolution benchmarking": [[2146, "cuda-convolution-benchmarking"]], "Avoiding nondeterministic algorithms": [[2146, "avoiding-nondeterministic-algorithms"]], "CUDA convolution determinism": [[2146, "cuda-convolution-determinism"]], "CUDA RNN and LSTM": [[2146, "cuda-rnn-and-lstm"]], "Filling uninitialized memory": [[2146, "filling-uninitialized-memory"]], "DataLoader": [[2146, "dataloader"]], "Distributed Data Parallel": [[2132, "distributed-data-parallel"]], "Internal Design": [[2132, "internal-design"]], "ProcessGroup": [[2132, "processgroup"]], "TorchDynamo DDPOptimizer": [[2132, "id1"]], "TorchDynamo-based ONNX Exporter": [[2150, "torchdynamo-based-onnx-exporter"], [2149, "torchdynamo-based-onnx-exporter"]], "Dependencies": [[2150, "dependencies"]], "A simple example": [[2150, "a-simple-example"]], "Inspecting the ONNX model using GUI": [[2150, "inspecting-the-onnx-model-using-gui"]], "When the conversion fails": [[2150, "when-the-conversion-fails"]], "Deprecated": [[2150, "deprecated"], [2156, "deprecated"]], "LibTorch Stable ABI": [[2141, "libtorch-stable-abi"]], "CPU threading and TorchScript inference": [[2129, "cpu-threading-and-torchscript-inference"]], "Build options": [[2129, "build-options"]], "Runtime API": [[2129, "runtime-api"]], "Tuning the number of threads": [[2129, "tuning-the-number-of-threads"]], "torch.nested": [[2117, "module-torch.nested"]], "Data Layout and Shape": [[2117, "data-layout-and-shape"]], "Supported Operations": [[2117, "supported-operations"], [2115, "id1"]], "Viewing nested tensor constituents": [[2117, "viewing-nested-tensor-constituents"]], "Conversions to / from padded": [[2117, "conversions-to-from-padded"]], "Shape manipulations": [[2117, "shape-manipulations"]], "Attention mechanisms": [[2117, "attention-mechanisms"]], "Usage with torch.compile": [[2117, "usage-with-torch-compile"]], "Unimplemented ops": [[2117, "unimplemented-ops"]], "Ragged structure incompatibility": [[2117, "ragged-structure-incompatibility"]], "Data dependent operation within torch.compile": [[2117, "data-dependent-operation-within-torch-compile"]], "Contributions": [[2117, "contributions"]], "Detailed Docs for Construction and Conversion Functions": [[2117, "detailed-docs-for-construction-and-conversion-functions"]], "Multiprocessing best practices": [[2144, "multiprocessing-best-practices"]], "CUDA in multiprocessing": [[2144, "cuda-in-multiprocessing"]], "Best practices and tips": [[2144, "best-practices-and-tips"]], "Avoiding and fighting deadlocks": [[2144, "avoiding-and-fighting-deadlocks"]], "Reuse buffers passed through a Queue": [[2144, "reuse-buffers-passed-through-a-queue"]], "Asynchronous multiprocess training (e.g. Hogwild)": [[2144, "asynchronous-multiprocess-training-e-g-hogwild"]], "Hogwild": [[2144, "hogwild"]], "CPU in multiprocessing": [[2144, "cpu-in-multiprocessing"]], "CPU oversubscription": [[2144, "cpu-oversubscription"]], "Avoid CPU oversubscription": [[2144, "avoid-cpu-oversubscription"]], "Features for large-scale deployments": [[2140, "features-for-large-scale-deployments"]], "Fleet-wide operator profiling": [[2140, "fleet-wide-operator-profiling"]], "API usage logging": [[2140, "api-usage-logging"]], "Attaching metadata to saved TorchScript models": [[2140, "attaching-metadata-to-saved-torchscript-models"]], "Build environment considerations": [[2140, "build-environment-considerations"]], "Common extension points": [[2140, "common-extension-points"]], "torch.onnx.ops": [[2153, "torch-onnx-ops"]], "Numerical accuracy": [[2145, "numerical-accuracy"]], "Batched computations or slice computations": [[2145, "batched-computations-or-slice-computations"]], "Extremal values": [[2145, "extremal-values"]], "Linear algebra (torch.linalg)": [[2145, "linear-algebra-torch-linalg"]], "Non-finite values": [[2145, "non-finite-values"]], "Extremal values in linalg": [[2145, "extremal-values-in-linalg"]], "TensorFloat-32(TF32) on Nvidia Ampere (and later) devices": [[2145, "tensorfloat-32-tf32-on-nvidia-ampere-and-later-devices"]], "Reduced Precision Reduction for FP16 and BF16 GEMMs": [[2145, "reduced-precision-reduction-for-fp16-and-bf16-gemms"]], "Reduced Precision Reduction for FP16 and BF16 in Scaled Dot Product Attention (SDPA)": [[2145, "reduced-precision-reduction-for-fp16-and-bf16-in-scaled-dot-product-attention-sdpa"]], "Reduced Precision FP16 and BF16 GEMMs and Convolutions on AMD Instinct MI200 devices": [[2145, "reduced-precision-fp16-and-bf16-gemms-and-convolutions-on-amd-instinct-mi200-devices"]], "Developer Notes": [[2125, "developer-notes"]], "Serialization semantics": [[2147, "serialization-semantics"]], "Table of Contents": [[2147, "table-of-contents"]], "Saving and loading tensors": [[2147, "saving-and-loading-tensors"]], "Saving and loading tensors preserves views": [[2147, "saving-and-loading-tensors-preserves-views"]], "Saving and loading torch.nn.Modules": [[2147, "saving-and-loading-torch-nn-modules"]], "Serialized file format for torch.save": [[2147, "serialized-file-format-for-torch-save"]], "torch.load with weights_only=True": [[2147, "torch-load-with-weights-only-true"]], "Troubleshooting weights_only": [[2147, "troubleshooting-weights-only"]], "Getting unsafe globals": [[2147, "getting-unsafe-globals"]], "Serializing torch.nn.Modules and loading them in C++": [[2147, "serializing-torch-nn-modules-and-loading-them-in-c"]], "Saving and loading ScriptModules across PyTorch versions": [[2147, "saving-and-loading-scriptmodules-across-pytorch-versions"]], "torch.div performing integer division": [[2147, "torch-div-performing-integer-division"]], "torch.full always inferring a float dtype": [[2147, "torch-full-always-inferring-a-float-dtype"]], "Config": [[2147, "module-torch.utils.serialization"]], "Quantization": [[2161, "module-torch.ao.quantization"]], "Introduction to Quantization": [[2161, "introduction-to-quantization"]], "Quantization API Summary": [[2161, "quantization-api-summary"]], "Eager Mode Quantization": [[2161, "eager-mode-quantization"]], "Post Training Dynamic Quantization": [[2161, "post-training-dynamic-quantization"]], "Post Training Static Quantization": [[2161, "post-training-static-quantization"]], "Quantization Aware Training for Static Quantization": [[2161, "quantization-aware-training-for-static-quantization"]], "Model Preparation for Eager Mode Static Quantization": [[2161, "model-preparation-for-eager-mode-static-quantization"]], "(Prototype - maintenance mode) FX Graph Mode Quantization": [[2161, "prototype-maintenance-mode-fx-graph-mode-quantization"]], "(Prototype) PyTorch 2 Export Quantization": [[2161, "prototype-pytorch-2-export-quantization"]], "Quantization Stack": [[2161, "quantization-stack"]], "Quantized Model": [[2161, "quantized-model"]], "Quantized Tensor": [[2161, "quantized-tensor"]], "Quantize and Dequantize": [[2161, "quantize-and-dequantize"]], "Quantized Operators/Modules": [[2161, "quantized-operators-modules"]], "Quantized Engine": [[2161, "quantized-engine"]], "Quantization Flow": [[2161, "quantization-flow"]], "Observer and FakeQuantize": [[2161, "observer-and-fakequantize"]], "QConfig": [[2161, "qconfig"], [871, "qconfig"]], "General Quantization Flow": [[2161, "general-quantization-flow"]], "Quantization Support Matrix": [[2161, "quantization-support-matrix"]], "Quantization Mode Support": [[2161, "quantization-mode-support"]], "Quantization Flow Support": [[2161, "quantization-flow-support"]], "Backend/Hardware Support": [[2161, "backend-hardware-support"]], "Note for native CPU backends": [[2161, "note-for-native-cpu-backends"]], "Operator Support": [[2161, "operator-support"]], "Quantization Customizations": [[2161, "quantization-customizations"]], "Quantization Custom Module API": [[2161, "quantization-custom-module-api"]], "Best Practices": [[2161, "best-practices"]], "Common Errors": [[2161, "common-errors"]], "Passing a non-quantized Tensor into a quantized kernel": [[2161, "passing-a-non-quantized-tensor-into-a-quantized-kernel"]], "Passing a quantized Tensor into a non-quantized kernel": [[2161, "passing-a-quantized-tensor-into-a-non-quantized-kernel"]], "Saving and Loading Quantized models": [[2161, "saving-and-loading-quantized-models"]], "Symbolic Trace Error when using FX Graph Mode Quantization": [[2161, "symbolic-trace-error-when-using-fx-graph-mode-quantization"]], "FSDP Notes": [[2136, "fsdp-notes"]], "FSDP Prefetch Nuances": [[2136, "fsdp-prefetch-nuances"]], "Communication payload size": [[2136, "communication-payload-size"]], "FSDP buffers sizes": [[2136, "fsdp-buffers-sizes"]], "torch.nn.attention": [[2119, "module-torch.nn.attention"]], "Utils": [[2119, "utils"]], "Submodules": [[2119, "submodules"]], "ONNX supported TorchScript operators": [[2155, "onnx-supported-torchscript-operators"]], "Supported operators": [[2155, "supported-operators"]], "ONNX support for TorchScript operators": [[2155, "id1"]], "Unsupported operators": [[2155, "unsupported-operators"], [2155, "id2"]], "Broadcasting semantics": [[2128, "broadcasting-semantics"]], "General semantics": [[2128, "general-semantics"]], "In-place semantics": [[2128, "in-place-semantics"]], "Backwards compatibility": [[2128, "backwards-compatibility"]], "torch.nn.attention.experimental": [[2121, "module-torch.nn.attention.experimental"]], "Gradcheck mechanics": [[2138, "gradcheck-mechanics"]], "Notations and background information": [[2138, "notations-and-background-information"]], "Default backward mode gradcheck behavior": [[2138, "default-backward-mode-gradcheck-behavior"]], "Real-to-real functions": [[2138, "real-to-real-functions"]], "Default real input numerical evaluation": [[2138, "default-real-input-numerical-evaluation"]], "Default real input analytical evaluation": [[2138, "default-real-input-analytical-evaluation"]], "Complex-to-real functions": [[2138, "complex-to-real-functions"]], "Default complex input numerical evaluation": [[2138, "default-complex-input-numerical-evaluation"]], "Default complex input analytical evaluation": [[2138, "default-complex-input-analytical-evaluation"]], "Functions with complex outputs": [[2138, "functions-with-complex-outputs"]], "Fast backward mode gradcheck": [[2138, "fast-backward-mode-gradcheck"]], "Fast gradcheck for real-to-real functions": [[2138, "fast-gradcheck-for-real-to-real-functions"]], "Fast gradcheck for complex-to-real functions": [[2138, "fast-gradcheck-for-complex-to-real-functions"]], "Fast complex input numerical evaluation": [[2138, "fast-complex-input-numerical-evaluation"]], "Fast complex input analytical evaluation": [[2138, "fast-complex-input-analytical-evaluation"]], "Why not use a complex u": [[2138, "why-not-use-a-complex-u"]], "Fast gradcheck for functions with complex outputs": [[2138, "fast-gradcheck-for-functions-with-complex-outputs"]], "Gradgradcheck implementation": [[2138, "gradgradcheck-implementation"]], "Understanding TorchDynamo-based ONNX Exporter Memory Usage": [[2151, "understanding-torchdynamo-based-onnx-exporter-memory-usage"]], "TorchScript-based exporter": [[2151, "torchscript-based-exporter"]], "TorchDynamo-based exporter": [[2151, "torchdynamo-based-exporter"]], "torch.nn": [[2118, "module-torch.nn"], [2118, "id1"]], "Containers": [[2118, "containers"]], "Convolution Layers": [[2118, "convolution-layers"]], "Pooling layers": [[2118, "pooling-layers"]], "Padding Layers": [[2118, "padding-layers"]], "Non-linear Activations (weighted sum, nonlinearity)": [[2118, "non-linear-activations-weighted-sum-nonlinearity"]], "Non-linear Activations (other)": [[2118, "non-linear-activations-other"]], "Normalization Layers": [[2118, "normalization-layers"]], "Recurrent Layers": [[2118, "recurrent-layers"]], "Transformer Layers": [[2118, "transformer-layers"]], "Linear Layers": [[2118, "linear-layers"]], "Dropout Layers": [[2118, "dropout-layers"]], "Sparse Layers": [[2118, "sparse-layers"]], "Distance Functions": [[2118, "distance-functions"]], "Loss Functions": [[2118, "loss-functions"]], "Vision Layers": [[2118, "vision-layers"]], "Shuffle Layers": [[2118, "shuffle-layers"]], "DataParallel Layers (multi-GPU, distributed)": [[2118, "module-torch.nn.parallel"]], "Quantized Functions": [[2118, "quantized-functions"]], "Lazy Modules Initialization": [[2118, "lazy-modules-initialization"]], "Aliases": [[2118, "aliases"]], "Automatic Mixed Precision examples": [[2126, "automatic-mixed-precision-examples"]], "Typical Mixed Precision Training": [[2126, "typical-mixed-precision-training"]], "Working with Unscaled Gradients": [[2126, "working-with-unscaled-gradients"]], "Gradient clipping": [[2126, "gradient-clipping"]], "Working with Scaled Gradients": [[2126, "working-with-scaled-gradients"]], "Gradient accumulation": [[2126, "gradient-accumulation"]], "Gradient penalty": [[2126, "gradient-penalty"]], "Working with Multiple Models, Losses, and Optimizers": [[2126, "working-with-multiple-models-losses-and-optimizers"]], "Working with Multiple GPUs": [[2126, "working-with-multiple-gpus"]], "DataParallel in a single process": [[2126, "dataparallel-in-a-single-process"]], "DistributedDataParallel, one GPU per process": [[2126, "distributeddataparallel-one-gpu-per-process"]], "DistributedDataParallel, multiple GPUs per process": [[2126, "distributeddataparallel-multiple-gpus-per-process"]], "Autocast and Custom Autograd Functions": [[2126, "autocast-and-custom-autograd-functions"]], "Functions with multiple inputs or autocastable ops": [[2126, "functions-with-multiple-inputs-or-autocastable-ops"]], "Functions that need a particular dtype": [[2126, "functions-that-need-a-particular-dtype"]], "torch.onnx": [[2149, "torch-onnx"]], "TorchScript-based ONNX Exporter": [[2149, "torchscript-based-onnx-exporter"], [2154, "torchscript-based-onnx-exporter"]], "Contributing / Developing": [[2149, "contributing-developing"]], "torch.optim": [[2157, "module-torch.optim"]], "How to use an optimizer": [[2157, "how-to-use-an-optimizer"]], "Constructing it": [[2157, "constructing-it"]], "Per-parameter options": [[2157, "per-parameter-options"]], "Taking an optimization step": [[2157, "taking-an-optimization-step"]], "optimizer.step()": [[2157, "optimizer-step"]], "optimizer.step(closure)": [[2157, "optimizer-step-closure"]], "Base class": [[2157, "base-class"]], "Algorithms": [[2157, "algorithms"]], "How to adjust learning rate": [[2157, "how-to-adjust-learning-rate"]], "How to utilize named parameters to load optimizer state dict": [[2157, "how-to-utilize-named-parameters-to-load-optimizer-state-dict"]], "Weight Averaging (SWA and EMA)": [[2157, "weight-averaging-swa-and-ema"]], "Constructing averaged models": [[2157, "constructing-averaged-models"]], "Custom averaging strategies": [[2157, "custom-averaging-strategies"]], "SWA learning rate schedules": [[2157, "swa-learning-rate-schedules"]], "Taking care of batch normalization": [[2157, "taking-care-of-batch-normalization"]], "Putting it all together: SWA": [[2157, "putting-it-all-together-swa"]], "Putting it all together: EMA": [[2157, "putting-it-all-together-ema"]], "Autograd mechanics": [[2127, "autograd-mechanics"]], "How autograd encodes the history": [[2127, "how-autograd-encodes-the-history"]], "Saved tensors": [[2127, "saved-tensors"]], "Gradients for non-differentiable functions": [[2127, "gradients-for-non-differentiable-functions"]], "Setting requires_grad": [[2127, "setting-requires-grad"]], "Grad Modes": [[2127, "grad-modes"]], "Default Mode (Grad Mode)": [[2127, "default-mode-grad-mode"]], "No-grad Mode": [[2127, "no-grad-mode"]], "Inference Mode": [[2127, "inference-mode"]], "Evaluation Mode (nn.Module.eval())": [[2127, "evaluation-mode-nn-module-eval"]], "In-place operations with autograd": [[2127, "in-place-operations-with-autograd"]], "In-place correctness checks": [[2127, "in-place-correctness-checks"], [2, "in-place-correctness-checks"]], "Multithreaded Autograd": [[2127, "multithreaded-autograd"]], "Concurrency on CPU": [[2127, "concurrency-on-cpu"]], "Non-determinism": [[2127, "non-determinism"]], "Graph retaining": [[2127, "graph-retaining"]], "Thread Safety on Autograd Node": [[2127, "thread-safety-on-autograd-node"]], "No thread safety on C++ hooks": [[2127, "no-thread-safety-on-c-hooks"]], "Autograd for Complex Numbers": [[2127, "autograd-for-complex-numbers"]], "What are complex derivatives?": [[2127, "what-are-complex-derivatives"]], "Wirtinger Calculus comes into the picture \u2026": [[2127, "wirtinger-calculus-comes-into-the-picture"]], "How is Wirtinger Calculus useful in optimization?": [[2127, "how-is-wirtinger-calculus-useful-in-optimization"]], "How does PyTorch compute the conjugate Wirtinger derivative?": [[2127, "how-does-pytorch-compute-the-conjugate-wirtinger-derivative"]], "How can I write my own derivative formula for a complex function?": [[2127, "how-can-i-write-my-own-derivative-formula-for-a-complex-function"]], "What about cross-domain functions?": [[2127, "what-about-cross-domain-functions"]], "Hooks for saved tensors": [[2127, "hooks-for-saved-tensors"]], "Registering hooks for a saved tensor": [[2127, "registering-hooks-for-a-saved-tensor"]], "Registering default hooks for saved tensors": [[2127, "registering-default-hooks-for-saved-tensors"]], "Backward Hooks execution": [[2127, "backward-hooks-execution"]], "Whether a particular hook will be fired": [[2127, "whether-a-particular-hook-will-be-fired"]], "The order in which the different hooks are fired": [[2127, "the-order-in-which-the-different-hooks-are-fired"]], "Special hooks": [[2127, "special-hooks"]], "Behavior of Tensor hooks when Tensor is modified in-place": [[2127, "behavior-of-tensor-hooks-when-tensor-is-modified-in-place"]], "PyTorch Custom Operators Landing Page": [[2131, "pytorch-custom-operators-landing-page"]], "torch.package": [[2158, "torch-package"]], "Packaging your first model": [[2158, "packaging-your-first-model"]], "How do I\u2026": [[2158, "how-do-i"]], "See what is inside a package?": [[2158, "see-what-is-inside-a-package"]], "Treat the package like a ZIP archive": [[2158, "treat-the-package-like-a-zip-archive"]], "Use the file_structure() API": [[2158, "use-the-file-structure-api"]], "See why a given module was included as a dependency?": [[2158, "see-why-a-given-module-was-included-as-a-dependency"]], "Include arbitrary resources with my package and access them later?": [[2158, "include-arbitrary-resources-with-my-package-and-access-them-later"]], "Customize how a class is packaged?": [[2158, "customize-how-a-class-is-packaged"]], "Test in my source code whether or not it is executing inside a package?": [[2158, "test-in-my-source-code-whether-or-not-it-is-executing-inside-a-package"]], "Patch code into a package?": [[2158, "patch-code-into-a-package"]], "Access package contents from packaged code?": [[2158, "access-package-contents-from-packaged-code"]], "Distinguish between packaged code and non-packaged code?": [[2158, "distinguish-between-packaged-code-and-non-packaged-code"]], "Re-export an imported object?": [[2158, "re-export-an-imported-object"]], "Package a TorchScript module?": [[2158, "package-a-torchscript-module"]], "Explanation": [[2158, "explanation"]], "torch.package Format Overview": [[2158, "torch-package-format-overview"]], "Framework files": [[2158, "framework-files"]], "User files": [[2158, "user-files"]], "How torch.package finds your code\u2019s dependencies": [[2158, "how-torch-package-finds-your-code-s-dependencies"]], "Analyzing an object\u2019s dependencies": [[2158, "analyzing-an-object-s-dependencies"]], "Analyzing a module\u2019s dependencies": [[2158, "analyzing-a-module-s-dependencies"]], "Dependency Management": [[2158, "dependency-management"]], "intern": [[2158, "intern"]], "extern": [[2158, "extern"]], "mock": [[2158, "mock"]], "Refactoring": [[2158, "refactoring"]], "Patterns": [[2158, "patterns"]], "torch.package sharp edges": [[2158, "torch-package-sharp-edges"]], "Avoid global state in your modules": [[2158, "avoid-global-state-in-your-modules"]], "Types are not shared between packages and the loading environment": [[2158, "types-are-not-shared-between-packages-and-the-loading-environment"]], "How torch.package keeps packages isolated from each other": [[2158, "how-torch-package-keeps-packages-isolated-from-each-other"]], "Mangling": [[2158, "mangling"]], "CUDA semantics": [[2130, "cuda-semantics"]], "TensorFloat-32 (TF32) on Ampere (and later) devices": [[2130, "tensorfloat-32-tf32-on-ampere-and-later-devices"]], "Reduced Precision Reduction in FP16 GEMMs": [[2130, "reduced-precision-reduction-in-fp16-gemms"]], "Reduced Precision Reduction in BF16 GEMMs": [[2130, "reduced-precision-reduction-in-bf16-gemms"]], "Full FP16 Accmumulation in FP16 GEMMs": [[2130, "full-fp16-accmumulation-in-fp16-gemms"]], "Asynchronous execution": [[2130, "asynchronous-execution"]], "CUDA streams": [[2130, "cuda-streams"]], "Stream semantics of backward passes": [[2130, "stream-semantics-of-backward-passes"]], "BC note: Using grads on the default stream": [[2130, "bc-note-using-grads-on-the-default-stream"]], "Optimizing memory usage  with PYTORCH_CUDA_ALLOC_CONF": [[2130, "optimizing-memory-usage-with-pytorch-cuda-alloc-conf"]], "Using custom memory allocators for CUDA": [[2130, "using-custom-memory-allocators-for-cuda"]], "Mixing different CUDA system allocators in the same program": [[2130, "mixing-different-cuda-system-allocators-in-the-same-program"]], "cuBLAS workspaces": [[2130, "cublas-workspaces"]], "cuFFT plan cache": [[2130, "cufft-plan-cache"]], "Just-in-Time Compilation": [[2130, "just-in-time-compilation"]], "Best practices": [[2130, "best-practices"]], "Device-agnostic code": [[2130, "device-agnostic-code"]], "Use pinned memory buffers": [[2130, "use-pinned-memory-buffers"]], "Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel": [[2130, "use-nn-parallel-distributeddataparallel-instead-of-multiprocessing-or-nn-dataparallel"]], "CUDA Graphs": [[2130, "cuda-graphs"]], "Why CUDA Graphs?": [[2130, "why-cuda-graphs"]], "PyTorch API": [[2130, "pytorch-api"]], "Constraints": [[2130, "constraints"], [39, "module-torch.distributions.constraints"]], "Non-constraints": [[2130, "non-constraints"]], "Whole-network capture": [[2130, "whole-network-capture"]], "Partial-network capture": [[2130, "partial-network-capture"]], "Usage with torch.cuda.amp": [[2130, "usage-with-torch-cuda-amp"]], "Usage with multiple streams": [[2130, "usage-with-multiple-streams"]], "Usage with DistributedDataParallel": [[2130, "usage-with-distributeddataparallel"]], "NCCL < 2.9.6": [[2130, "nccl-2-9-6"]], "NCCL >= 2.9.6": [[2130, "id5"]], "Graph memory management": [[2130, "graph-memory-management"]], "Sharing memory across captures": [[2130, "sharing-memory-across-captures"]], "HIP (ROCm) semantics": [[2139, "hip-rocm-semantics"]], "HIP Interfaces Reuse the CUDA Interfaces": [[2139, "hip-interfaces-reuse-the-cuda-interfaces"]], "Checking for HIP": [[2139, "checking-for-hip"]], "TensorFloat-32(TF32) on ROCm": [[2139, "tensorfloat-32-tf32-on-rocm"]], "hipBLAS workspaces": [[2139, "hipblas-workspaces"]], "hipFFT/rocFFT plan cache": [[2139, "hipfft-rocfft-plan-cache"]], "torch.distributed backends": [[2139, "torch-distributed-backends"]], "CUDA API to HIP API mappings in C++": [[2139, "cuda-api-to-hip-api-mappings-in-c"]], "Refer to CUDA Semantics doc": [[2139, "refer-to-cuda-semantics-doc"]], "Enabling kernel asserts": [[2139, "enabling-kernel-asserts"]], "Example: AlexNet from PyTorch to ONNX": [[2154, "example-alexnet-from-pytorch-to-onnx"]], "Tracing vs Scripting": [[2154, "tracing-vs-scripting"]], "Avoiding Pitfalls": [[2154, "avoiding-pitfalls"]], "Avoid NumPy and built-in Python types": [[2154, "avoid-numpy-and-built-in-python-types"]], "Avoid Tensor.data": [[2154, "avoid-tensor-data"]], "Avoid in-place operations when using tensor.shape in tracing mode": [[2154, "avoid-in-place-operations-when-using-tensor-shape-in-tracing-mode"]], "Differences in Operator Implementations": [[2154, "differences-in-operator-implementations"]], "Unsupported Tensor Indexing Patterns": [[2154, "unsupported-tensor-indexing-patterns"]], "Reads / Gets": [[2154, "reads-gets"]], "Writes / Sets": [[2154, "writes-sets"]], "Adding support for operators": [[2154, "adding-support-for-operators"]], "ONNX exporter internals": [[2154, "onnx-exporter-internals"]], "ATen operators": [[2154, "aten-operators"]], "List of supported operators": [[2154, "list-of-supported-operators"]], "Adding support for an aten or quantized operator": [[2154, "adding-support-for-an-aten-or-quantized-operator"]], "torch.autograd.Functions": [[2154, "torch-autograd-functions"]], "Static Symbolic Method": [[2154, "static-symbolic-method"]], "Inline Autograd Function": [[2154, "inline-autograd-function"]], "ONNX-script functions": [[2154, "onnx-script-functions"]], "C++ Operators": [[2154, "c-operators"]], "Discovering all unconvertible ATen ops at once": [[2154, "discovering-all-unconvertible-aten-ops-at-once"]], "Python API": [[2154, "module-torch.onnx"], [2160, "python-api"]], "Classes": [[2154, "classes"]], "Named Tensors operator coverage": [[2115, "named-tensors-operator-coverage"]], "Keeps input names": [[2115, "keeps-input-names"]], "Removes dimensions": [[2115, "removes-dimensions"]], "Unifies names from inputs": [[2115, "unifies-names-from-inputs"]], "Permutes dimensions": [[2115, "permutes-dimensions"]], "Contracts away dims": [[2115, "contracts-away-dims"]], "Factory functions": [[2115, "factory-functions"]], "out function and in-place variants": [[2115, "out-function-and-in-place-variants"]], "torch.nn.attention.flex_attention": [[2122, "module-torch.nn.attention.flex_attention"]], "BlockMask Utilities": [[2122, "blockmask-utilities"]], "BlockMask": [[2122, "blockmask"]], "Extending torch.func with autograd.Function": [[2134, "extending-torch-func-with-autograd-function"]], "Basic Usage": [[2134, "basic-usage"]], "Example 1: autograd.Function calls into another system": [[2134, "example-1-autograd-function-calls-into-another-system"]], "Example 2: autograd.Function specifies custom gradient rules": [[2134, "example-2-autograd-function-specifies-custom-gradient-rules"]], "Limitations and gotchas": [[2134, "limitations-and-gotchas"]], "torch.vmap() Support": [[2134, "torch-vmap-support"]], "Automatically generate a vmap rule": [[2134, "automatically-generate-a-vmap-rule"]], "Defining the vmap staticmethod": [[2134, "defining-the-vmap-staticmethod"]], "torch.func.jvp() Support": [[2134, "torch-func-jvp-support"]], "torch.nn.functional": [[2123, "torch-nn-functional"]], "Convolution functions": [[2123, "convolution-functions"]], "Pooling functions": [[2123, "pooling-functions"]], "Attention Mechanisms": [[2123, "attention-mechanisms"]], "Non-linear activation functions": [[2123, "non-linear-activation-functions"]], "Linear functions": [[2123, "linear-functions"]], "Dropout functions": [[2123, "dropout-functions"]], "Sparse functions": [[2123, "sparse-functions"]], "Distance functions": [[2123, "distance-functions"]], "Loss functions": [[2123, "loss-functions"]], "Vision functions": [[2123, "vision-functions"]], "DataParallel functions (multi-GPU, distributed)": [[2123, "dataparallel-functions-multi-gpu-distributed"]], "data_parallel": [[2123, "data-parallel"]], "torch.onnx.verification": [[2156, "module-torch.onnx.verification"]], "My model reports \u201ccuda runtime error(2): out of memory\u201d": [[2135, "my-model-reports-cuda-runtime-error-2-out-of-memory"]], "My GPU memory isn\u2019t freed properly": [[2135, "my-gpu-memory-isn-t-freed-properly"]], "My out of memory exception handler can\u2019t allocate memory": [[2135, "my-out-of-memory-exception-handler-can-t-allocate-memory"]], "My data loader workers return identical random numbers": [[2135, "my-data-loader-workers-return-identical-random-numbers"]], "My recurrent network doesn\u2019t work with data parallelism": [[2135, "my-recurrent-network-doesn-t-work-with-data-parallelism"]], "torch.nn.init": [[2124, "torch-nn-init"]], "Windows FAQ": [[2148, "windows-faq"]], "Building from source": [[2148, "building-from-source"]], "Include optional components": [[2148, "include-optional-components"]], "Speeding CUDA build for Windows": [[2148, "speeding-cuda-build-for-windows"]], "One key install script": [[2148, "one-key-install-script"]], "Extension": [[2148, "extension"]], "CFFI Extension": [[2148, "cffi-extension"]], "Cpp Extension": [[2148, "cpp-extension"]], "Package not found in win-32 channel.": [[2148, "package-not-found-in-win-32-channel"]], "Import error": [[2148, "import-error"]], "Usage (multiprocessing)": [[2148, "usage-multiprocessing"]], "Multiprocessing error without if-clause protection": [[2148, "multiprocessing-error-without-if-clause-protection"]], "Multiprocessing error \u201cBroken pipe\u201d": [[2148, "multiprocessing-error-broken-pipe"]], "Multiprocessing error \u201cdriver shut down\u201d": [[2148, "multiprocessing-error-driver-shut-down"]], "CUDA IPC operations": [[2148, "cuda-ipc-operations"]], "torch.nn.attention.bias": [[2120, "module-torch.nn.attention.bias"]], "CausalBias": [[2120, "causalbias"]], "ONNX Backend for TorchDynamo": [[2152, "onnx-backend-for-torchdynamo"]], "MPS backend": [[2143, "mps-backend"]], "torch.cuda.memory_cached": [[1098, "torch-cuda-memory-cached"]], "torch.cuda.jiterator._create_multi_output_jit_fn": [[1087, "torch-cuda-jiterator-create-multi-output-jit-fn"]], "torch.cuda.synchronize": [[1120, "torch-cuda-synchronize"]], "torch.cuda.reset_peak_memory_stats": [[1111, "torch-cuda-reset-peak-memory-stats"]], "torch.cuda.memory_stats": [[1101, "torch-cuda-memory-stats"]], "torch.cuda.jiterator._create_jit_fn": [[1086, "torch-cuda-jiterator-create-jit-fn"]], "torch.cuda.nvtx.mark": [[1104, "torch-cuda-nvtx-mark"]], "torch.cuda.set_device": [[1114, "torch-cuda-set-device"]], "torch.cuda.reset_max_memory_cached": [[1110, "torch-cuda-reset-max-memory-cached"]], "torch.cuda.mem_get_info": [[1095, "torch-cuda-mem-get-info"]], "torch.cuda.max_memory_cached": [[1093, "torch-cuda-max-memory-cached"]], "torch.cuda.temperature": [[1121, "torch-cuda-temperature"]], "torch.cuda.initial_seed": [[1081, "torch-cuda-initial-seed"]], "torch.cuda.is_initialized": [[1085, "torch-cuda-is-initialized"]], "torch.cuda.nvtx.range_push": [[1107, "torch-cuda-nvtx-range-push"]], "torch.cuda.set_rng_state": [[1116, "torch-cuda-set-rng-state"]], "torch.cuda.set_rng_state_all": [[1117, "torch-cuda-set-rng-state-all"]], "torch.cuda.memory_snapshot": [[1100, "torch-cuda-memory-snapshot"]], "torch.cuda.list_gpu_processes": [[1088, "torch-cuda-list-gpu-processes"]], "torch.cuda.utilization": [[1122, "torch-cuda-utilization"]], "torch.cuda.seed_all": [[1113, "torch-cuda-seed-all"]], "torch.cuda.is_current_stream_capturing": [[1084, "torch-cuda-is-current-stream-capturing"]], "torch.cummax": [[1123, "torch-cummax"]], "torch.cuda.memory.caching_allocator_enable": [[1096, "torch-cuda-memory-caching-allocator-enable"]], "torch.cuda.make_graphed_callables": [[1089, "torch-cuda-make-graphed-callables"]], "torch.cuda.reset_max_memory_allocated": [[1109, "torch-cuda-reset-max-memory-allocated"]], "torch.cuda.ipc_collect": [[1082, "torch-cuda-ipc-collect"]], "torch.cuda.memory_usage": [[1103, "torch-cuda-memory-usage"]], "torch.cuda.memory_reserved": [[1099, "torch-cuda-memory-reserved"]], "torch.cuda.max_memory_allocated": [[1092, "torch-cuda-max-memory-allocated"]], "torch.cuda.nvtx.range": [[1105, "torch-cuda-nvtx-range"]], "torch.cuda.is_available": [[1083, "torch-cuda-is-available"]], "torch.cumsum": [[1126, "torch-cumsum"]], "torch.cumulative_trapezoid": [[1127, "torch-cumulative-trapezoid"]], "torch.cuda.set_per_process_memory_fraction": [[1115, "torch-cuda-set-per-process-memory-fraction"]], "torch.cuda.manual_seed_all": [[1091, "torch-cuda-manual-seed-all"]], "torch.cuda.nvtx.range_pop": [[1106, "torch-cuda-nvtx-range-pop"]], "torch.cummin": [[1124, "torch-cummin"]], "torch.cuda.manual_seed": [[1090, "torch-cuda-manual-seed"]], "torch.cuda.set_sync_debug_mode": [[1119, "torch-cuda-set-sync-debug-mode"]], "torch.cumprod": [[1125, "torch-cumprod"]], "torch.cuda.power_draw": [[1108, "torch-cuda-power-draw"]], "torch.cuda.seed": [[1112, "torch-cuda-seed"]], "torch.cuda.max_memory_reserved": [[1094, "torch-cuda-max-memory-reserved"]], "torch.cuda.memory_summary": [[1102, "torch-cuda-memory-summary"]], "torch.cuda.memory_allocated": [[1097, "torch-cuda-memory-allocated"]], "torch.cuda.set_stream": [[1118, "torch-cuda-set-stream"]], "torch.cpu.set_device": [[1034, "torch-cpu-set-device"]], "MemPool": [[1041, "mempool"]], "torch.cuda.comm.broadcast_coalesced": [[1052, "torch-cuda-comm-broadcast-coalesced"]], "torch.cuda.get_arch_list": [[1068, "torch-cuda-get-arch-list"]], "torch.cuda.comm.broadcast": [[1051, "torch-cuda-comm-broadcast"]], "torch.cuda.cudart": [[1057, "torch-cuda-cudart"]], "torch.cuda.current_blas_handle": [[1058, "torch-cuda-current-blas-handle"]], "torch.cuda.clock_rate": [[1050, "torch-cuda-clock-rate"]], "torch.cross": [[1036, "torch-cross"]], "torch.cuda.comm.gather": [[1053, "torch-cuda-comm-gather"]], "torch.cuda.caching_allocator_delete": [[1047, "torch-cuda-caching-allocator-delete"]], "torch.cuda.default_stream": [[1061, "torch-cuda-default-stream"]], "torch.cuda.get_device_capability": [[1069, "torch-cuda-get-device-capability"]], "torch.cuda.caching_allocator_alloc": [[1046, "torch-cuda-caching-allocator-alloc"]], "torch.cuda.current_stream": [[1060, "torch-cuda-current-stream"]], "torch.cuda.get_rng_state_all": [[1075, "torch-cuda-get-rng-state-all"]], "torch.cuda.get_stream_from_external": [[1076, "torch-cuda-get-stream-from-external"]], "torch.cuda.get_device_properties": [[1071, "torch-cuda-get-device-properties"]], "torch.cuda.comm.reduce_add": [[1054, "torch-cuda-comm-reduce-add"]], "torch.cuda.empty_cache": [[1066, "torch-cuda-empty-cache"]], "torch.cuda.change_current_allocator": [[1049, "torch-cuda-change-current-allocator"]], "torch.cuda.get_device_name": [[1070, "torch-cuda-get-device-name"]], "torch.cuda.can_device_access_peer": [[1048, "torch-cuda-can-device-access-peer"]], "graph": [[1078, "graph"]], "torch.cuda.graph_pool_handle": [[1079, "torch-cuda-graph-pool-handle"]], "torch.cuda.get_rng_state": [[1074, "torch-cuda-get-rng-state"]], "CUDAPluggableAllocator": [[1038, "cudapluggableallocator"]], "torch.cuda.init": [[1080, "torch-cuda-init"]], "torch.cuda.comm.reduce_add_coalesced": [[1055, "torch-cuda-comm-reduce-add-coalesced"]], "torch.cuda.device_count": [[1063, "torch-cuda-device-count"]], "torch.cuda.device_memory_used": [[1064, "torch-cuda-device-memory-used"]], "MemPoolContext": [[1042, "mempoolcontext"]], "torch.cpu.synchronize": [[1035, "torch-cpu-synchronize"]], "torch.cuda.OutOfMemoryError": [[1043, "torch-cuda-outofmemoryerror"]], "torch.cuda.current_device": [[1059, "torch-cuda-current-device"]], "torch.cuda.stream": [[1044, "torch-cuda-stream"]], "torch.cuda.get_sync_debug_mode": [[1077, "torch-cuda-get-sync-debug-mode"]], "torch.cuda.get_per_process_memory_fraction": [[1073, "torch-cuda-get-per-process-memory-fraction"]], "torch.cuda.get_gencode_flags": [[1072, "torch-cuda-get-gencode-flags"]], "torch.cuda.comm.scatter": [[1056, "torch-cuda-comm-scatter"]], "torch.cuda.get_allocator_backend": [[1067, "torch-cuda-get-allocator-backend"]], "ExternalStream": [[1040, "externalstream"]], "torch.concatenate": [[1018, "torch-concatenate"]], "torch.complex": [[1016, "torch-complex"]], "torch.copysign": [[1022, "torch-copysign"]], "torch.clamp": [[997, "torch-clamp"]], "torch.corrcoef": [[1023, "torch-corrcoef"]], "torch.compiler.reset": [[1013, "torch-compiler-reset"]], "torch.compiler.set_stance": [[1014, "torch-compiler-set-stance"]], "torch.clone": [[999, "torch-clone"]], "torch.compiler.cudagraph_mark_step_begin": [[1007, "torch-compiler-cudagraph-mark-step-begin"]], "torch.cpu.stream": [[1028, "torch-cpu-stream"]], "torch.cholesky": [[993, "torch-cholesky"]], "torch.compiler.substitute_in_graph": [[1015, "torch-compiler-substitute-in-graph"]], "torch.cholesky_inverse": [[994, "torch-cholesky-inverse"]], "torch.compiler.is_exporting": [[1011, "torch-compiler-is-exporting"]], "torch.cos": [[1024, "torch-cos"]], "torch.column_stack": [[1000, "torch-column-stack"]], "torch.compiled_with_cxx11_abi": [[1003, "torch-compiled-with-cxx11-abi"]], "torch.compiler.is_compiling": [[1009, "torch-compiler-is-compiling"]], "torch.compiler.compile": [[1006, "torch-compiler-compile"]], "torch.can_cast": [[987, "torch-can-cast"]], "torch.count_nonzero": [[1026, "torch-count-nonzero"]], "torch.chunk": [[996, "torch-chunk"]], "torch.cosh": [[1025, "torch-cosh"]], "torch.concat": [[1017, "torch-concat"]], "torch.cpu.current_stream": [[1031, "torch-cpu-current-stream"]], "torch.compiler.assume_constant_result": [[1005, "torch-compiler-assume-constant-result"]], "torch.combinations": [[1001, "torch-combinations"]], "torch.conj_physical": [[1021, "torch-conj-physical"]], "torch.compile": [[1002, "torch-compile"]], "torch.cpu.device_count": [[1032, "torch-cpu-device-count"]], "torch.cpu.is_available": [[1033, "torch-cpu-is-available"]], "torch.compiler.list_backends": [[1012, "torch-compiler-list-backends"]], "torch.cat": [[989, "torch-cat"]], "torch.conj": [[1020, "torch-conj"]], "torch.cpu.current_device": [[1030, "torch-cpu-current-device"]], "torch.cartesian_prod": [[988, "torch-cartesian-prod"]], "torch.compiler.is_dynamo_compiling": [[1010, "torch-compiler-is-dynamo-compiling"]], "torch.cholesky_solve": [[995, "torch-cholesky-solve"]], "torch.cdist": [[990, "torch-cdist"]], "torch.clip": [[998, "torch-clip"]], "torch.ceil": [[991, "torch-ceil"]], "torch.chain_matmul": [[992, "torch-chain-matmul"]], "torch.cov": [[1027, "torch-cov"]], "torch.utils.bottleneck": [[5, "module-torch.utils.bottleneck"]], "Distributed Optimizers": [[35, "distributed-optimizers"]], "PyTorch Governance | Maintainers": [[12, "pytorch-governance-maintainers"]], "Responsibilities": [[12, "responsibilities"]], "Lead Core Maintainer (BDFL)": [[12, "lead-core-maintainer-bdfl"], [10, "lead-core-maintainer-bdfl"]], "Core Maintainers": [[12, "core-maintainers"], [10, "core-maintainers"]], "Module-level maintainers": [[12, "module-level-maintainers"]], "NN APIs (torch.nn)": [[12, "nn-apis-torch-nn"]], "Optimizers (torch.optim)": [[12, "optimizers-torch-optim"]], "Autograd (torch.autograd)": [[12, "autograd-torch-autograd"]], "TorchInductor": [[12, "torchinductor"]], "Cudagraph Tree": [[12, "cudagraph-tree"]], "PT2 Dispatcher": [[12, "pt2-dispatcher"]], "PT2 Export (torch.export)": [[12, "pt2-export-torch-export"]], "AOT Inductor (AOTI) & AOTI Runtime": [[12, "aot-inductor-aoti-aoti-runtime"]], "Compilers (JIT / TorchScript / Package / Deploy)": [[12, "compilers-jit-torchscript-package-deploy"]], "Distributions & RNG": [[12, "distributions-rng"]], "Distributed": [[12, "distributed"]], "Linear Algebra (torch.linalg)": [[12, "linear-algebra-torch-linalg"]], "Sparse (torch.sparse)": [[12, "sparse-torch-sparse"]], "NestedTensor (torch.nested)": [[12, "nestedtensor-torch-nested"]], "MaskedTensor (torch.masked)": [[12, "maskedtensor-torch-masked"]], "Fast Fourier Transform (torch.fft)": [[12, "fast-fourier-transform-torch-fft"]], "MKLDNN": [[12, "mkldnn"]], "CUDA": [[12, "cuda"]], "AMD/ROCm/HIP": [[12, "amd-rocm-hip"]], "Build + CI": [[12, "build-ci"]], "Performance Tools": [[12, "performance-tools"]], "C++ API": [[12, "c-api"]], "C10 utils and operator dispatch": [[12, "c10-utils-and-operator-dispatch"]], "ONNX exporter": [[12, "onnx-exporter"]], "LiteInterpreter": [[12, "liteinterpreter"]], "Quantization (torch/ao)": [[12, "quantization-torch-ao"]], "Windows": [[12, "windows"]], "Apple M1/MPS/Metal": [[12, "apple-m1-mps-metal"]], "PowerPC": [[12, "powerpc"]], "AArch64 CPU": [[12, "aarch64-cpu"]], "Docs / Tutorials": [[12, "docs-tutorials"]], "Library-level maintainers": [[12, "library-level-maintainers"]], "XLA": [[12, "xla"]], "TorchServe": [[12, "torchserve"]], "TorchVision": [[12, "torchvision"]], "TorchText": [[12, "torchtext"]], "TorchAudio": [[12, "torchaudio"]], "TorchRec": [[12, "torchrec"]], "TorchX": [[12, "torchx"]], "TorchData": [[12, "torchdata"]], "TorchArrow": [[12, "torcharrow"]], "ExecuTorch (Edge, Mobile)": [[12, "executorch-edge-mobile"]], "TorchTune": [[12, "torchtune"]], "TorchChat": [[12, "torchchat"]], "TorchCodec": [[12, "torchcodec"]], "Error Propagation": [[44, "module-torch.distributed.elastic.multiprocessing.errors"]], "Methods and Classes": [[44, "methods-and-classes"]], "Automatic differentiation package - torch.autograd": [[2, "module-torch.autograd"]], "Forward-mode Automatic Differentiation": [[2, "forward-mode-automatic-differentiation"]], "Functional higher level API": [[2, "functional-higher-level-api"]], "Default gradient layouts": [[2, "default-gradient-layouts"]], "Manual gradient layouts": [[2, "manual-gradient-layouts"]], "In-place operations on Tensors": [[2, "in-place-operations-on-tensors"]], "Variable (deprecated)": [[2, "variable-deprecated"]], "Tensor autograd functions": [[2, "tensor-autograd-functions"]], "Function": [[2, "function"]], "Context method mixins": [[2, "context-method-mixins"]], "Custom Function utilities": [[2, "custom-function-utilities"]], "Numerical gradient checking": [[2, "module-torch.autograd.gradcheck"]], "Profiler": [[2, "profiler"]], "Debugging and anomaly detection": [[2, "debugging-and-anomaly-detection"]], "Autograd graph": [[2, "autograd-graph"]], "torch.cuda": [[19, "module-torch.cuda"]], "Communication collectives": [[19, "communication-collectives"]], "Graphs (beta)": [[19, "graphs-beta"]], "NVIDIA Tools Extension (NVTX)": [[19, "nvidia-tools-extension-nvtx"]], "Jiterator (beta)": [[19, "jiterator-beta"]], "TunableOp": [[19, "tunableop"], [21, "tunableop"]], "Stream Sanitizer (prototype)": [[19, "stream-sanitizer-prototype"]], "GPUDirect Storage (prototype)": [[19, "gpudirect-storage-prototype"]], "CUDA Stream Sanitizer": [[20, "cuda-stream-sanitizer"]], "Tensor Parallelism - torch.distributed.tensor.parallel": [[38, "tensor-parallelism-torch-distributed-tensor-parallel"]], "PyTorch Governance | Build + CI": [[7, "pytorch-governance-build-ci"]], "How to Add a New Maintainer": [[7, "how-to-add-a-new-maintainer"]], "Customization": [[43, "customization"]], "Launcher": [[43, "launcher"]], "Rendezvous Handler": [[43, "rendezvous-handler"]], "Metric Handler": [[43, "metric-handler"]], "Events Handler": [[43, "events-handler"]], "torch.accelerator": [[0, "module-torch.accelerator"]], "Automatic Mixed Precision package - torch.amp": [[1, "automatic-mixed-precision-package-torch-amp"]], "Autocasting": [[1, "autocasting"]], "Gradient Scaling": [[1, "gradient-scaling"]], "Autocast Op Reference": [[1, "autocast-op-reference"]], "Op Eligibility": [[1, "op-eligibility"]], "CUDA Op-Specific Behavior": [[1, "cuda-op-specific-behavior"]], "CUDA Ops that can autocast to float16": [[1, "cuda-ops-that-can-autocast-to-float16"]], "CUDA Ops that can autocast to float32": [[1, "cuda-ops-that-can-autocast-to-float32"]], "CUDA Ops that promote to the widest input type": [[1, "cuda-ops-that-promote-to-the-widest-input-type"]], "Prefer binary_cross_entropy_with_logits over binary_cross_entropy": [[1, "prefer-binary-cross-entropy-with-logits-over-binary-cross-entropy"]], "XPU Op-Specific Behavior (Experimental)": [[1, "xpu-op-specific-behavior-experimental"]], "XPU Ops that can autocast to float16": [[1, "xpu-ops-that-can-autocast-to-float16"]], "XPU Ops that can autocast to float32": [[1, "xpu-ops-that-can-autocast-to-float32"]], "XPU Ops that promote to the widest input type": [[1, "xpu-ops-that-promote-to-the-widest-input-type"]], "CPU Op-Specific Behavior": [[1, "cpu-op-specific-behavior"]], "CPU Ops that can autocast to bfloat16": [[1, "cpu-ops-that-can-autocast-to-bfloat16"]], "CPU Ops that can autocast to float32": [[1, "cpu-ops-that-can-autocast-to-float32"]], "CPU Ops that promote to the widest input type": [[1, "cpu-ops-that-promote-to-the-widest-input-type"]], "PyTorch Governance | Mechanics": [[10, "pytorch-governance-mechanics"]], "Summary": [[10, "summary"]], "Module Maintainers": [[10, "module-maintainers"]], "Nominating, Confirming and Removing Maintainers": [[10, "nominating-confirming-and-removing-maintainers"]], "The Principles": [[10, "the-principles"]], "The Process for Nomination": [[10, "the-process-for-nomination"]], "The Process for Removal": [[10, "the-process-for-removal"]], "Nominating Core Maintainers": [[10, "nominating-core-maintainers"]], "Removing the Lead Core Maintainer and Nominating a New Lead Core Maintainer": [[10, "removing-the-lead-core-maintainer-and-nominating-a-new-lead-core-maintainer"]], "Add, Remove, and Re-Scope Modules and Projects": [[10, "add-remove-and-re-scope-modules-and-projects"]], "Decision Making": [[10, "decision-making"]], "Uncontroversial Changes": [[10, "uncontroversial-changes"]], "Controversial Decision Process": [[10, "controversial-decision-process"]], "General Project Policies": [[10, "general-project-policies"]], "FAQ": [[10, "faq"]], "Community": [[11, "community"]], "torch.cpu": [[18, "module-torch.cpu"]], "Generic Join Context Manager": [[31, "generic-join-context-manager"]], "Elastic Agent": [[41, "module-torch.distributed.elastic.agent"]], "Server": [[41, "module-torch.distributed.elastic.agent.server"]], "Concepts": [[41, "concepts"]], "Extending the Agent": [[41, "extending-the-agent"]], "Watchdog in the Agent": [[41, "watchdog-in-the-agent"]], "Health Check Server": [[41, "health-check-server"]], "Control Flow - Cond": [[14, "control-flow-cond"]], "Invariants of torch.ops.higher_order.cond": [[14, "invariants-of-torch-ops-higher-order-cond"]], "torch::deploy has been moved to pytorch/multipy": [[28, "torch-deploy-has-been-moved-to-pytorch-multipy"]], "torch.utils.dlpack": [[40, "torch-utils-dlpack"]], "torch.utils.cpp_extension": [[16, "torch-utils-cpp-extension"]], "Complex Numbers": [[13, "complex-numbers"]], "Creating Complex Tensors": [[13, "creating-complex-tensors"]], "Transition from the old representation": [[13, "transition-from-the-old-representation"]], "Accessing real and imag": [[13, "accessing-real-and-imag"]], "Angle and abs": [[13, "angle-and-abs"]], "Linear Algebra": [[13, "linear-algebra"]], "Autograd": [[13, "autograd"]], "Optimizers": [[13, "optimizers"]], "PyTorch Contribution Guide": [[8, "pytorch-contribution-guide"]], "Contribution Process": [[8, "contribution-process"]], "Proposing New Features": [[8, "proposing-new-features"]], "Implementing Features or Fixing Bugs": [[8, "implementing-features-or-fixing-bugs"]], "Adding Tutorials": [[8, "adding-tutorials"]], "Improving Documentation & Tutorials": [[8, "improving-documentation-tutorials"]], "Participating in Online Discussions": [[8, "participating-in-online-discussions"]], "Submitting Pull Requests to Fix Open Issues": [[8, "submitting-pull-requests-to-fix-open-issues"]], "Reviewing Open Pull Requests": [[8, "reviewing-open-pull-requests"]], "Improving Code Readability": [[8, "improving-code-readability"]], "Adding Test Cases to Make the Codebase More Robust": [[8, "adding-test-cases-to-make-the-codebase-more-robust"]], "Promoting PyTorch": [[8, "promoting-pytorch"]], "Triaging Issues": [[8, "triaging-issues"]], "About Open Source Development": [[8, "about-open-source-development"]], "Common Mistakes To Avoid": [[8, "common-mistakes-to-avoid"]], "On Documentation": [[8, "on-documentation"]], "Python Docs": [[8, "python-docs"]], "C++ Docs": [[8, "c-docs"]], "Tutorials Build Overview": [[8, "tutorials-build-overview"]], "Contributing a New Tutorial": [[8, "contributing-a-new-tutorial"]], "torch.utils.checkpoint": [[6, "torch-utils-checkpoint"]], "C++": [[17, "c"]], "TorchScript C++ API": [[17, "torchscript-c-api"]], "Extending PyTorch and TorchScript with C++ Extensions": [[17, "extending-pytorch-and-torchscript-with-c-extensions"]], "Tensor and Autograd in C++": [[17, "tensor-and-autograd-in-c"]], "Authoring Models in C++": [[17, "authoring-models-in-c"]], "Packaging for C++": [[17, "packaging-for-c"]], "DDP Communication Hooks": [[26, "ddp-communication-hooks"]], "How to Use a Communication Hook?": [[26, "how-to-use-a-communication-hook"]], "What Does a Communication Hook Operate On?": [[26, "what-does-a-communication-hook-operate-on"]], "Default Communication Hooks": [[26, "default-communication-hooks"]], "PowerSGD Communication Hook": [[26, "powersgd-communication-hook"]], "PowerSGD State": [[26, "powersgd-state"]], "PowerSGD Hooks": [[26, "powersgd-hooks"]], "Debugging Communication Hooks": [[26, "debugging-communication-hooks"]], "Checkpointing of Communication Hooks": [[26, "checkpointing-of-communication-hooks"]], "Acknowledgements": [[26, "acknowledgements"]], "torch.distributed.fsdp.fully_shard": [[34, "torch-distributed-fsdp-fully-shard"]], "PyTorch FSDP2 (fully_shard)": [[34, "pytorch-fsdp2-fully-shard"]], "Events": [[45, "module-torch.distributed.elastic.events"]], "API Methods": [[45, "api-methods"]], "Event Objects": [[45, "event-objects"]], "torch.distributed.tensor": [[37, "torch-distributed-tensor"]], "PyTorch DTensor (Distributed Tensor)": [[37, "pytorch-dtensor-distributed-tensor"]], "DTensor Class APIs": [[37, "dtensor-class-apis"]], "DeviceMesh as the distributed communicator": [[37, "devicemesh-as-the-distributed-communicator"]], "DTensor Placement Types": [[37, "module-torch.distributed.tensor.placement_types"]], "Different ways to create a DTensor": [[37, "different-ways-to-create-a-dtensor"]], "Create DTensor from a logical torch.Tensor": [[37, "create-dtensor-from-a-logical-torch-tensor"]], "DTensor Factory Functions": [[37, "dtensor-factory-functions"]], "Logging": [[37, "logging"], [36, "logging"], [30, "logging"]], "Experimental Features": [[37, "experimental-features"]], "CUDA Environment Variables": [[22, "cuda-environment-variables"]], "Distributed Checkpoint - torch.distributed.checkpoint": [[32, "distributed-checkpoint-torch-distributed-checkpoint"]], "Additional resources:": [[32, "additional-resources"]], "torch.backends": [[3, "module-torch.backends"]], "torch.backends.cpu": [[3, "module-torch.backends.cpu"]], "torch.backends.cuda": [[3, "module-torch.backends.cuda"]], "torch.backends.cudnn": [[3, "module-torch.backends.cudnn"]], "torch.backends.cusparselt": [[3, "module-torch.backends.cusparselt"]], "torch.backends.mha": [[3, "module-torch.backends.mha"]], "torch.backends.mps": [[3, "module-torch.backends.mps"]], "torch.backends.mkl": [[3, "module-torch.backends.mkl"]], "torch.backends.mkldnn": [[3, "module-torch.backends.mkldnn"]], "torch.backends.nnpack": [[3, "module-torch.backends.nnpack"]], "torch.backends.openmp": [[3, "module-torch.backends.openmp"]], "torch.backends.opt_einsum": [[3, "module-torch.backends.opt_einsum"]], "torch.backends.xeon": [[3, "module-torch.backends.xeon"]], "Pipeline Parallelism": [[36, "pipeline-parallelism"]], "Why Pipeline Parallel?": [[36, "why-pipeline-parallel"]], "What is torch.distributed.pipelining?": [[36, "what-is-torch-distributed-pipelining"]], "Step 1: build PipelineStage": [[36, "step-1-build-pipelinestage"]], "Step 2: use PipelineSchedule for execution": [[36, "step-2-use-pipelineschedule-for-execution"]], "Options for Splitting a Model": [[36, "options-for-splitting-a-model"]], "Option 1: splitting a model manually": [[36, "option-1-splitting-a-model-manually"]], "Option 2: splitting a model automatically": [[36, "option-2-splitting-a-model-automatically"]], "Hugging Face Examples": [[36, "hugging-face-examples"]], "Technical Deep Dive": [[36, "technical-deep-dive"]], "How does the pipeline API split a model?": [[36, "how-does-the-pipeline-api-split-a-model"]], "Implementing Your Own Schedule": [[36, "implementing-your-own-schedule"]], "Model Split APIs": [[36, "model-split-apis"]], "Microbatch Utilities": [[36, "module-torch.distributed.pipelining.microbatch"]], "Pipeline Stages": [[36, "module-torch.distributed.pipelining.stage"]], "Pipeline Schedules": [[36, "module-torch.distributed.pipelining.schedules"]], "PyTorch Design Philosophy": [[9, "pytorch-design-philosophy"]], "Design Principles": [[9, "design-principles"]], "Principle 1: Usability over Performance": [[9, "principle-1-usability-over-performance"]], "Principle 2: Simple Over Easy": [[9, "principle-2-simple-over-easy"]], "Principle 3: Python First with Best In Class Language Interoperability": [[9, "principle-3-python-first-with-best-in-class-language-interoperability"]], "Torch Distributed Elastic": [[33, "torch-distributed-elastic"]], "Get Started": [[33, "get-started"]], "Documentation": [[33, "documentation"]], "API": [[33, null]], "Advanced": [[33, null]], "Plugins": [[33, null]], "Benchmark Utils - torch.utils.benchmark": [[4, "module-torch.utils.benchmark"]], "Probability distributions - torch.distributions": [[39, "module-torch.distributions"]], "Score function": [[39, "score-function"]], "Pathwise derivative": [[39, "pathwise-derivative"]], "Distribution": [[39, "distribution"]], "ExponentialFamily": [[39, "exponentialfamily"]], "Bernoulli": [[39, "bernoulli"]], "Beta": [[39, "beta"]], "Binomial": [[39, "binomial"]], "Categorical": [[39, "categorical"]], "Cauchy": [[39, "cauchy"]], "Chi2": [[39, "chi2"]], "ContinuousBernoulli": [[39, "continuousbernoulli"]], "Dirichlet": [[39, "dirichlet"]], "Exponential": [[39, "exponential"]], "FisherSnedecor": [[39, "fishersnedecor"]], "Gamma": [[39, "gamma"]], "Geometric": [[39, "geometric"]], "Gumbel": [[39, "gumbel"]], "HalfCauchy": [[39, "halfcauchy"]], "HalfNormal": [[39, "halfnormal"]], "Independent": [[39, "independent"]], "InverseGamma": [[39, "inversegamma"]], "Kumaraswamy": [[39, "kumaraswamy"]], "LKJCholesky": [[39, "lkjcholesky"]], "Laplace": [[39, "laplace"]], "LogNormal": [[39, "lognormal"]], "LowRankMultivariateNormal": [[39, "lowrankmultivariatenormal"]], "MixtureSameFamily": [[39, "mixturesamefamily"]], "Multinomial": [[39, "multinomial"]], "MultivariateNormal": [[39, "multivariatenormal"]], "NegativeBinomial": [[39, "negativebinomial"]], "Normal": [[39, "normal"]], "OneHotCategorical": [[39, "onehotcategorical"]], "Pareto": [[39, "pareto"]], "Poisson": [[39, "poisson"]], "RelaxedBernoulli": [[39, "relaxedbernoulli"]], "LogitRelaxedBernoulli": [[39, "logitrelaxedbernoulli"]], "RelaxedOneHotCategorical": [[39, "relaxedonehotcategorical"]], "StudentT": [[39, "studentt"]], "TransformedDistribution": [[39, "transformeddistribution"]], "Uniform": [[39, "uniform"]], "VonMises": [[39, "vonmises"]], "Weibull": [[39, "weibull"]], "Wishart": [[39, "wishart"]], "KL Divergence": [[39, "module-torch.distributions.kl"]], "Transforms": [[39, "module-torch.distributions.transforms"]], "Constraint Registry": [[39, "module-torch.distributions.constraint_registry"]], "Debugging Environment Variables": [[27, "debugging-environment-variables"]], "Control Plane": [[42, "module-torch.distributed.elastic.control_plane"]], "Enabling TunableOp and Tuning Separately": [[21, "enabling-tunableop-and-tuning-separately"]], "File Input and Output": [[21, "file-input-and-output"]], "A Note on Tuning Behavior": [[21, "a-note-on-tuning-behavior"]], "Current Tunable Operators": [[21, "current-tunable-operators"]], "TunableGemm for ROCm": [[21, "tunablegemm-for-rocm"]], "Tuning Context": [[21, "tuning-context"]], "torch.utils.deterministic": [[29, "module-torch.utils.deterministic"]], "torch.__config__": [[15, "module-torch.__config__"]], "Distributed communication package - torch.distributed": [[30, "distributed-communication-package-torch-distributed"]], "Backends that come with PyTorch": [[30, "backends-that-come-with-pytorch"]], "Which backend to use?": [[30, "which-backend-to-use"]], "Common environment variables": [[30, "common-environment-variables"]], "Choosing the network interface to use": [[30, "choosing-the-network-interface-to-use"]], "Other NCCL environment variables": [[30, "other-nccl-environment-variables"]], "Initialization": [[30, "initialization"]], "TCP initialization": [[30, "tcp-initialization"]], "Shared file-system initialization": [[30, "shared-file-system-initialization"]], "Environment variable initialization": [[30, "environment-variable-initialization"]], "Post-Initialization": [[30, "post-initialization"]], "Shutdown": [[30, "shutdown"]], "Reinitialization": [[30, "reinitialization"]], "Groups": [[30, "groups"]], "DeviceMesh": [[30, "devicemesh"]], "Point-to-point communication": [[30, "point-to-point-communication"]], "Synchronous and asynchronous collective operations": [[30, "synchronous-and-asynchronous-collective-operations"]], "Collective functions": [[30, "collective-functions"]], "Distributed Key-Value Store": [[30, "distributed-key-value-store"]], "Profiling Collective Communication": [[30, "profiling-collective-communication"]], "Multi-GPU collective functions": [[30, "multi-gpu-collective-functions"]], "Third-party backends": [[30, "third-party-backends"]], "Launch utility": [[30, "launch-utility"]], "Spawn utility": [[30, "spawn-utility"]], "Debugging torch.distributed applications": [[30, "debugging-torch-distributed-applications"]], "Python Breakpoint": [[30, "python-breakpoint"]], "Monitored Barrier": [[30, "monitored-barrier"]], "TORCH_DISTRIBUTED_DEBUG": [[30, "torch-distributed-debug"]], "torch.utils.data": [[25, "module-torch.utils.data"]], "Dataset Types": [[25, "dataset-types"]], "Map-style datasets": [[25, "map-style-datasets"]], "Iterable-style datasets": [[25, "iterable-style-datasets"]], "Data Loading Order and Sampler": [[25, "data-loading-order-and-sampler"]], "Loading Batched and Non-Batched Data": [[25, "loading-batched-and-non-batched-data"]], "Automatic batching (default)": [[25, "automatic-batching-default"]], "Disable automatic batching": [[25, "disable-automatic-batching"]], "Working with collate_fn": [[25, "working-with-collate-fn"]], "Single- and Multi-process Data Loading": [[25, "single-and-multi-process-data-loading"]], "Single-process data loading (default)": [[25, "single-process-data-loading-default"]], "Multi-process data loading": [[25, "multi-process-data-loading"]], "Platform-specific behaviors": [[25, "platform-specific-behaviors"]], "Randomness in multi-process data loading": [[25, "randomness-in-multi-process-data-loading"]], "Memory Pinning": [[25, "memory-pinning"]], "torch.autograd.gradcheck.GradcheckError": [[948, "torch-autograd-gradcheck-gradcheckerror"]], "torch.autograd.profiler.profile.total_average": [[964, "torch-autograd-profiler-profile-total-average"]], "torch.autograd.functional.jacobian": [[940, "torch-autograd-functional-jacobian"]], "torch.autograd.gradcheck.gradgradcheck": [[950, "torch-autograd-gradcheck-gradgradcheck"]], "torch.broadcast_tensors": [[984, "torch-broadcast-tensors"]], "torch.autograd.gradcheck.gradcheck": [[949, "torch-autograd-gradcheck-gradcheck"]], "Kernel": [[967, "kernel"]], "torch.bitwise_xor": [[979, "torch-bitwise-xor"]], "torch.blackman_window": [[980, "torch-blackman-window"]], "torch.autograd.profiler.profile.key_averages": [[962, "torch-autograd-profiler-profile-key-averages"]], "torch.autograd.functional.vjp": [[943, "torch-autograd-functional-vjp"]], "torch.bartlett_window": [[971, "torch-bartlett-window"]], "record_function": [[965, "record-function"]], "torch.autograd.graph.Node.register_prehook": [[955, "torch-autograd-graph-node-register-prehook"]], "torch.autograd.graph.Node.metadata": [[951, "torch-autograd-graph-node-metadata"]], "torch.autograd.profiler.profile.self_cpu_time_total": [[963, "torch-autograd-profiler-profile-self-cpu-time-total"]], "set_grad_enabled": [[946, "set-grad-enabled"]], "Interval": [[966, "interval"]], "MemRecordsAcc": [[968, "memrecordsacc"]], "torch.bitwise_and": [[974, "torch-bitwise-and"]], "torch.autograd.graph.Node.name": [[952, "torch-autograd-graph-node-name"]], "torch.bitwise_left_shift": [[975, "torch-bitwise-left-shift"]], "EnforceUnique": [[957, "enforceunique"]], "torch.autograd.profiler.parse_nvprof_trace": [[960, "torch-autograd-profiler-parse-nvprof-trace"]], "StringTable": [[969, "stringtable"]], "torch.bitwise_right_shift": [[978, "torch-bitwise-right-shift"]], "torch.bucketize": [[986, "torch-bucketize"]], "torch.bitwise_or": [[977, "torch-bitwise-or"]], "torch.bmm": [[982, "torch-bmm"]], "torch.autograd.functional.vhp": [[942, "torch-autograd-functional-vhp"]], "torch.baddbmm": [[970, "torch-baddbmm"]], "torch.bernoulli": [[972, "torch-bernoulli"]], "torch.autograd.functional.jvp": [[941, "torch-autograd-functional-jvp"]], "torch.autograd.graph.Node.register_hook": [[954, "torch-autograd-graph-node-register-hook"]], "torch.broadcast_to": [[985, "torch-broadcast-to"]], "inference_mode": [[945, "inference-mode"]], "torch.bincount": [[973, "torch-bincount"]], "torch.block_diag": [[981, "torch-block-diag"]], "KinetoStepTracker": [[958, "kinetosteptracker"]], "torch.autograd.grad": [[944, "torch-autograd-grad"]], "set_multithreading_enabled": [[947, "set-multithreading-enabled"]], "torch.autograd.graph.increment_version": [[956, "torch-autograd-graph-increment-version"]], "torch.autograd.graph.Node.next_functions": [[953, "torch-autograd-graph-node-next-functions"]], "torch.bitwise_not": [[976, "torch-bitwise-not"]], "torch.autograd.profiler.profile.export_chrome_trace": [[961, "torch-autograd-profiler-profile-export-chrome-trace"]], "torch.autograd.profiler.load_nvprof": [[959, "torch-autograd-profiler-load-nvprof"]], "torch.broadcast_shapes": [[983, "torch-broadcast-shapes"]], "torch.argmax": [[904, "torch-argmax"]], "torch.autograd.forward_ad.make_dual": [[928, "torch-autograd-forward-ad-make-dual"]], "BackwardCFunction": [[930, "backwardcfunction"]], "torch.arccos": [[896, "torch-arccos"]], "torch.autograd.Function.forward": [[920, "torch-autograd-function-forward"]], "torch.autograd.function.FunctionCtx.save_for_backward": [[933, "torch-autograd-function-functionctx-save-for-backward"]], "torch.are_deterministic_algorithms_enabled": [[903, "torch-are-deterministic-algorithms-enabled"]], "torch.autograd.forward_ad.enter_dual_level": [[926, "torch-autograd-forward-ad-enter-dual-level"]], "torch.argmin": [[905, "torch-argmin"]], "UnpackedDualTensor": [[924, "unpackeddualtensor"]], "torch.as_tensor": [[909, "torch-as-tensor"]], "torch.autograd.Function.vmap": [[922, "torch-autograd-function-vmap"]], "InplaceFunction": [[935, "inplacefunction"]], "torch.arctan": [[900, "torch-arctan"]], "torch.argsort": [[906, "torch-argsort"]], "torch.autograd.forward_ad.unpack_dual": [[929, "torch-autograd-forward-ad-unpack-dual"]], "torch.atan": [[913, "torch-atan"]], "torch.arccosh": [[897, "torch-arccosh"]], "torch.autograd.functional.hvp": [[939, "torch-autograd-functional-hvp"]], "torch.autograd.Function.backward": [[919, "torch-autograd-function-backward"]], "torch.autograd.function.FunctionCtx.set_materialize_grads": [[934, "torch-autograd-function-functionctx-set-materialize-grads"]], "torch.arcsin": [[898, "torch-arcsin"]], "NestedIOFunction": [[936, "nestediofunction"]], "torch.autograd.Function.jvp": [[921, "torch-autograd-function-jvp"]], "torch.arcsinh": [[899, "torch-arcsinh"]], "torch.autograd.function.FunctionCtx.mark_dirty": [[931, "torch-autograd-function-functionctx-mark-dirty"]], "torch.arctan2": [[901, "torch-arctan2"]], "torch.argwhere": [[907, "torch-argwhere"]], "torch.atleast_3d": [[918, "torch-atleast-3d"]], "torch.arctanh": [[902, "torch-arctanh"]], "torch.autograd.function.once_differentiable": [[937, "torch-autograd-function-once-differentiable"]], "torch.as_strided": [[908, "torch-as-strided"]], "torch.atanh": [[915, "torch-atanh"]], "quantize_qat": [[893, "quantize-qat"]], "torch.asarray": [[910, "torch-asarray"]], "torch.autograd.forward_ad.exit_dual_level": [[927, "torch-autograd-forward-ad-exit-dual-level"]], "torch.atleast_2d": [[917, "torch-atleast-2d"]], "torch.autograd.functional.hessian": [[938, "torch-autograd-functional-hessian"]], "torch.atleast_1d": [[916, "torch-atleast-1d"]], "torch.asin": [[911, "torch-asin"]], "torch.atan2": [[914, "torch-atan2"]], "torch.autograd.function.FunctionCtx.mark_non_differentiable": [[932, "torch-autograd-function-functionctx-mark-non-differentiable"]], "swap_module": [[894, "swap-module"]], "torch.asinh": [[912, "torch-asinh"]], "dual_level": [[925, "dual-level"]], "torch.arange": [[895, "torch-arange"]], "torch.autograd.backward": [[923, "torch-autograd-backward"]], "default_qat_qconfig_v2": [[877, "default-qat-qconfig-v2"]], "default_activation_only_qconfig": [[872, "default-activation-only-qconfig"]], "default_per_channel_qconfig": [[875, "default-per-channel-qconfig"]], "fuse_fx": [[890, "fuse-fx"]], "prepare_qat": [[868, "prepare-qat"]], "default_observer": [[859, "default-observer"]], "default_placeholder_observer": [[861, "default-placeholder-observer"]], "propagate_qconfig": [[869, "propagate-qconfig"]], "PerGroup": [[847, "pergroup"]], "convert_fx": [[889, "convert-fx"]], "default_weight_observer": [[862, "default-weight-observer"]], "RecordingObserver": [[852, "recordingobserver"]], "default_qconfig": [[878, "default-qconfig"]], "default_dynamic_qconfig": [[874, "default-dynamic-qconfig"]], "quantize": [[887, "quantize"]], "get_observer_state_dict": [[864, "get-observer-state-dict"]], "prepare_for_propagation_comparison": [[867, "prepare-for-propagation-comparison"]], "default_debug_qconfig": [[873, "default-debug-qconfig"]], "prepare_qat_fx": [[892, "prepare-qat-fx"]], "PerChannelMinMaxObserver": [[846, "perchannelminmaxobserver"]], "quantize_dynamic": [[888, "quantize-dynamic"]], "float16_static_qconfig": [[881, "float16-static-qconfig"]], "QConfigMapping": [[884, "qconfigmapping"]], "float16_dynamic_qconfig": [[880, "float16-dynamic-qconfig"]], "get_default_qat_qconfig_mapping": [[885, "get-default-qat-qconfig-mapping"]], "TorchAODType": [[853, "torchaodtype"]], "default_debug_observer": [[855, "default-debug-observer"]], "default_weight_only_qconfig": [[879, "default-weight-only-qconfig"]], "PerToken": [[850, "pertoken"]], "default_qat_qconfig": [[876, "default-qat-qconfig"]], "PerRow": [[848, "perrow"]], "model_is_exported": [[870, "model-is-exported"]], "get_default_qconfig_mapping": [[886, "get-default-qconfig-mapping"]], "prepare": [[866, "prepare"]], "default_per_channel_weight_observer": [[860, "default-per-channel-weight-observer"]], "float_qparams_weight_only_qconfig": [[882, "float-qparams-weight-only-qconfig"]], "PlaceholderObserver": [[851, "placeholderobserver"]], "get_block_size": [[863, "get-block-size"]], "per_channel_dynamic_qconfig": [[883, "per-channel-dynamic-qconfig"]], "default_dynamic_quant_observer": [[856, "default-dynamic-quant-observer"]], "default_histogram_observer": [[858, "default-histogram-observer"]], "PerTensor": [[849, "pertensor"]], "default_float_qparams_observer": [[857, "default-float-qparams-observer"]], "load_observer_state_dict": [[865, "load-observer-state-dict"]], "prepare_fx": [[891, "prepare-fx"]], "ZeroPointDomain": [[854, "zeropointdomain"]], "QuantStub": [[802, "quantstub"]], "DTypeConfig": [[807, "dtypeconfig"]], "MinMaxObserver": [[839, "minmaxobserver"]], "default_per_channel_weight_fake_quant": [[823, "default-per-channel-weight-fake-quant"]], "QuantWrapper": [[803, "quantwrapper"]], "FuseCustomConfig": [[831, "fusecustomconfig"]], "NUMERIC_DEBUG_HANDLE_KEY": [[801, "numeric-debug-handle-key"]], "disable_fake_quant": [[825, "disable-fake-quant"]], "generate_numeric_debug_handle": [[834, "generate-numeric-debug-handle"]], "BackendConfig": [[805, "backendconfig"]], "HistogramObserver": [[837, "histogramobserver"]], "PerBlock": [[845, "perblock"]], "ConvertCustomConfig": [[830, "convertcustomconfig"]], "FakeQuantize": [[814, "fakequantize"]], "default_weight_fake_quant": [[824, "default-weight-fake-quant"]], "NoopObserver": [[842, "noopobserver"]], "FusedMovingAvgObsFakeQuantize": [[817, "fusedmovingavgobsfakequantize"]], "MovingAveragePerChannelMinMaxObserver": [[841, "movingaverageperchannelminmaxobserver"]], "BackendPatternConfig": [[806, "backendpatternconfig"]], "DeQuantStub": [[800, "dequantstub"]], "PrepareCustomConfig": [[832, "preparecustomconfig"]], "DTypeWithConstraints": [[808, "dtypewithconstraints"]], "FixedQParamsFakeQuantize": [[816, "fixedqparamsfakequantize"]], "default_fused_per_channel_wt_fake_quant": [[820, "default-fused-per-channel-wt-fake-quant"]], "fuse_modules": [[829, "fuse-modules"]], "AffineQuantizedObserverBase": [[835, "affinequantizedobserverbase"]], "MovingAverageMinMaxObserver": [[840, "movingaverageminmaxobserver"]], "PerAxis": [[844, "peraxis"]], "StandaloneModuleConfigEntry": [[833, "standalonemoduleconfigentry"]], "default_eval_fn": [[812, "default-eval-fn"]], "default_fused_wt_fake_quant": [[821, "default-fused-wt-fake-quant"]], "FakeQuantizeBase": [[815, "fakequantizebase"]], "default_histogram_fake_quant": [[822, "default-histogram-fake-quant"]], "add_quant_dequant": [[804, "add-quant-dequant"]], "default_fused_act_fake_quant": [[819, "default-fused-act-fake-quant"]], "MappingType": [[838, "mappingtype"]], "default_fake_quant": [[818, "default-fake-quant"]], "convert": [[811, "convert"]], "compare_results": [[810, "compare-results"]], "ObservationType": [[809, "observationtype"]], "disable_observer": [[826, "disable-observer"]], "Granularity": [[836, "granularity"]], "CUSTOM_KEY": [[799, "custom-key"]], "ObserverBase": [[843, "observerbase"]], "enable_fake_quant": [[827, "enable-fake-quant"]], "extract_results_from_loggers": [[813, "extract-results-from-loggers"]], "enable_observer": [[828, "enable-observer"]], "FXFloatFunctional": [[758, "fxfloatfunctional"]], "upsample": [[796, "upsample"]], "avg_pool2d": [[779, "avg-pool2d"]], "max_pool1d": [[793, "max-pool1d"]], "celu": [[781, "celu"]], "conv3d": [[785, "conv3d"]], "conv1d": [[783, "conv1d"]], "upsample_bilinear": [[797, "upsample-bilinear"]], "avg_pool3d": [[780, "avg-pool3d"]], "hardsigmoid": [[787, "hardsigmoid"]], "elu": [[786, "elu"]], "hardswish": [[788, "hardswish"]], "conv2d": [[784, "conv2d"]], "adaptive_avg_pool2d": [[777, "adaptive-avg-pool2d"]], "interpolate": [[790, "interpolate"]], "adaptive_avg_pool3d": [[778, "adaptive-avg-pool3d"]], "upsample_nearest": [[798, "upsample-nearest"]], "FloatFunctional": [[759, "floatfunctional"]], "hardtanh": [[789, "hardtanh"]], "threshold": [[795, "threshold"]], "QFunctional": [[768, "qfunctional"]], "leaky_relu": [[791, "leaky-relu"]], "linear": [[792, "linear"]], "max_pool2d": [[794, "max-pool2d"]], "clamp": [[782, "clamp"]], "torch.angle": [[709, "torch-angle"]], "torch.aminmax": [[708, "torch-aminmax"]], "BNReLU3d": [[712, "bnrelu3d"], [735, "bnrelu3d"]], "ConvBn1d": [[713, "convbn1d"], [723, "convbn1d"]], "ConvReLU2d": [[720, "convrelu2d"], [737, "convrelu2d"], [729, "convrelu2d"]], "ConvBnReLU2d": [[717, "convbnrelu2d"], [727, "convbnrelu2d"]], "ConvBn2d": [[724, "convbn2d"], [714, "convbn2d"]], "LinearReLU": [[739, "linearrelu"], [731, "linearrelu"], [740, "linearrelu"], [722, "linearrelu"]], "ConvReLU3d": [[730, "convrelu3d"], [721, "convrelu3d"], [738, "convrelu3d"]], "ConvBn3d": [[725, "convbn3d"], [715, "convbn3d"]], "BNReLU2d": [[711, "bnrelu2d"], [734, "bnrelu2d"]], "update_bn_stats": [[733, "update-bn-stats"]], "torch.amax": [[706, "torch-amax"]], "torch.any": [[710, "torch-any"]], "ConvReLU1d": [[736, "convrelu1d"], [719, "convrelu1d"]], "ConvBnReLU1d": [[726, "convbnrelu1d"], [716, "convbnrelu1d"]], "freeze_bn_stats": [[732, "freeze-bn-stats"]], "torch.allclose": [[705, "torch-allclose"]], "torch.amin": [[707, "torch-amin"]], "ConvBnReLU3d": [[728, "convbnrelu3d"], [718, "convbnrelu3d"]], "torch._foreach_zero_": [[680, "torch-foreach-zero"]], "torch._foreach_sigmoid_": [[669, "torch-foreach-sigmoid"]], "torch._foreach_sinh": [[672, "torch-foreach-sinh"]], "torch.abs": [[682, "torch-abs"]], "torch._foreach_tan_": [[677, "torch-foreach-tan"]], "torch.acosh": [[695, "torch-acosh"]], "torch._foreach_sinh_": [[673, "torch-foreach-sinh"]], "torch.addcmul": [[699, "torch-addcmul"]], "torch._foreach_sin_": [[671, "torch-foreach-sin"]], "torch.accelerator.current_accelerator": [[684, "torch-accelerator-current-accelerator"]], "torch._foreach_trunc": [[678, "torch-foreach-trunc"]], "torch.addmm": [[700, "torch-addmm"]], "torch.accelerator.set_stream": [[692, "torch-accelerator-set-stream"]], "torch._foreach_sigmoid": [[668, "torch-foreach-sigmoid"]], "torch.addbmm": [[697, "torch-addbmm"]], "torch.adjoint": [[703, "torch-adjoint"]], "torch.addmv": [[701, "torch-addmv"]], "torch.addcdiv": [[698, "torch-addcdiv"]], "torch.accelerator.is_available": [[689, "torch-accelerator-is-available"]], "torch._foreach_log2": [[659, "torch-foreach-log2"]], "torch._foreach_round": [[666, "torch-foreach-round"]], "torch.all": [[704, "torch-all"]], "torch._foreach_sqrt_": [[675, "torch-foreach-sqrt"]], "torch._logging.set_logs": [[681, "torch-logging-set-logs"]], "torch._foreach_round_": [[667, "torch-foreach-round"]], "torch._foreach_log1p_": [[658, "torch-foreach-log1p"]], "torch._foreach_neg": [[662, "torch-foreach-neg"]], "torch._foreach_neg_": [[663, "torch-foreach-neg"]], "torch.add": [[696, "torch-add"]], "torch._foreach_sqrt": [[674, "torch-foreach-sqrt"]], "torch.acos": [[694, "torch-acos"]], "torch.accelerator.current_stream": [[687, "torch-accelerator-current-stream"]], "torch.accelerator.current_device_idx": [[685, "torch-accelerator-current-device-idx"]], "torch._foreach_reciprocal_": [[665, "torch-foreach-reciprocal"]], "torch.accelerator.synchronize": [[693, "torch-accelerator-synchronize"]], "torch.accelerator.device_count": [[688, "torch-accelerator-device-count"]], "torch.accelerator.set_device_index": [[691, "torch-accelerator-set-device-index"]], "torch.accelerator.set_device_idx": [[690, "torch-accelerator-set-device-idx"]], "torch._foreach_tan": [[676, "torch-foreach-tan"]], "torch._foreach_sin": [[670, "torch-foreach-sin"]], "torch.accelerator.current_device_index": [[686, "torch-accelerator-current-device-index"]], "torch.addr": [[702, "torch-addr"]], "torch._foreach_log2_": [[660, "torch-foreach-log2"]], "torch._foreach_trunc_": [[679, "torch-foreach-trunc"]], "torch.absolute": [[683, "torch-absolute"]], "torch._foreach_log_": [[661, "torch-foreach-log"]], "torch._foreach_reciprocal": [[664, "torch-foreach-reciprocal"]], "torch._foreach_lgamma": [[652, "torch-foreach-lgamma"]], "torch._foreach_atan": [[632, "torch-foreach-atan"]], "torch.Tensor.view": [[617, "torch-tensor-view"]], "torch.Tensor.xlogy_": [[622, "torch-tensor-xlogy"]], "torch.Tensor.zero_": [[624, "torch-tensor-zero"]], "torch.Tensor.xlogy": [[621, "torch-tensor-xlogy"]], "torch.Tensor.unsqueeze_": [[612, "torch-tensor-unsqueeze"]], "torch._foreach_abs_": [[627, "torch-foreach-abs"]], "torch.Tensor.untyped_storage": [[613, "torch-tensor-untyped-storage"]], "torch._foreach_atan_": [[633, "torch-foreach-atan"]], "torch.Tensor.view_as": [[618, "torch-tensor-view-as"]], "torch._foreach_cosh_": [[639, "torch-foreach-cosh"]], "torch.Tensor.vdot": [[616, "torch-tensor-vdot"]], "torch._foreach_frac_": [[651, "torch-foreach-frac"]], "torch.Tensor.unsqueeze": [[611, "torch-tensor-unsqueeze"]], "torch._foreach_exp_": [[645, "torch-foreach-exp"]], "torch._foreach_cos": [[636, "torch-foreach-cos"]], "torch._foreach_floor_": [[649, "torch-foreach-floor"]], "torch._foreach_log1p": [[657, "torch-foreach-log1p"]], "torch._foreach_frac": [[650, "torch-foreach-frac"]], "torch.Tensor.var": [[615, "torch-tensor-var"]], "torch._foreach_log10_": [[656, "torch-foreach-log10"]], "torch._foreach_erf_": [[641, "torch-foreach-erf"]], "torch._foreach_acos_": [[629, "torch-foreach-acos"]], "torch._foreach_erf": [[640, "torch-foreach-erf"]], "torch.Tensor.vsplit": [[619, "torch-tensor-vsplit"]], "torch._foreach_cos_": [[637, "torch-foreach-cos"]], "torch._foreach_lgamma_": [[653, "torch-foreach-lgamma"]], "torch._foreach_ceil": [[634, "torch-foreach-ceil"]], "torch.Tensor.xpu": [[623, "torch-tensor-xpu"]], "torch._foreach_ceil_": [[635, "torch-foreach-ceil"]], "torch.Tensor.where": [[620, "torch-tensor-where"]], "torch._foreach_erfc": [[642, "torch-foreach-erfc"]], "torch._foreach_log": [[654, "torch-foreach-log"]], "torch._foreach_acos": [[628, "torch-foreach-acos"]], "torch._foreach_log10": [[655, "torch-foreach-log10"]], "torch._assert": [[625, "torch-assert"]], "torch._foreach_erfc_": [[643, "torch-foreach-erfc"]], "torch._foreach_cosh": [[638, "torch-foreach-cosh"]], "torch._foreach_floor": [[648, "torch-foreach-floor"]], "torch._foreach_asin_": [[631, "torch-foreach-asin"]], "torch._foreach_exp": [[644, "torch-foreach-exp"]], "torch._foreach_expm1_": [[647, "torch-foreach-expm1"]], "torch._foreach_abs": [[626, "torch-foreach-abs"]], "torch._foreach_asin": [[630, "torch-foreach-asin"]], "torch._foreach_expm1": [[646, "torch-foreach-expm1"]], "torch.Tensor.values": [[614, "torch-tensor-values"]], "torch.Tensor.swapdims": [[569, "torch-tensor-swapdims"]], "torch.Tensor.tolist": [[589, "torch-tensor-tolist"]], "torch.Tensor.transpose": [[592, "torch-tensor-transpose"]], "torch.Tensor.transpose_": [[593, "torch-tensor-transpose"]], "torch.Tensor.to_dense": [[581, "torch-tensor-to-dense"]], "torch.Tensor.tan_": [[575, "torch-tensor-tan"]], "torch.Tensor.topk": [[590, "torch-tensor-topk"]], "torch.Tensor.tensor_split": [[578, "torch-tensor-tensor-split"]], "torch.Tensor.sum": [[565, "torch-tensor-sum"]], "torch.Tensor.tanh": [[576, "torch-tensor-tanh"]], "torch.Tensor.take_along_dim": [[573, "torch-tensor-take-along-dim"]], "torch.Tensor.subtract_": [[564, "torch-tensor-subtract"]], "torch.Tensor.trace": [[591, "torch-tensor-trace"]], "torch.Tensor.t_": [[571, "torch-tensor-t"]], "torch.Tensor.trunc": [[601, "torch-tensor-trunc"]], "torch.Tensor.type": [[603, "torch-tensor-type"]], "torch.Tensor.true_divide": [[599, "torch-tensor-true-divide"]], "torch.Tensor.true_divide_": [[600, "torch-tensor-true-divide"]], "torch.Tensor.svd": [[567, "torch-tensor-svd"]], "torch.Tensor.unbind": [[605, "torch-tensor-unbind"]], "torch.Tensor.to_sparse_csr": [[588, "torch-tensor-to-sparse-csr"]], "torch.Tensor.type_as": [[604, "torch-tensor-type-as"]], "torch.Tensor.unfold": [[607, "torch-tensor-unfold"]], "torch.Tensor.tril": [[595, "torch-tensor-tril"]], "torch.Tensor.to_sparse": [[583, "torch-tensor-to-sparse"]], "torch.Tensor.trunc_": [[602, "torch-tensor-trunc"]], "torch.Tensor.to": [[580, "torch-tensor-to"]], "torch.Tensor.triangular_solve": [[594, "torch-tensor-triangular-solve"]], "torch.Tensor.swapaxes": [[568, "torch-tensor-swapaxes"]], "torch.Tensor.to_sparse_csc": [[587, "torch-tensor-to-sparse-csc"]], "torch.Tensor.triu_": [[598, "torch-tensor-triu"]], "torch.Tensor.t": [[570, "torch-tensor-t"]], "torch.Tensor.unflatten": [[606, "torch-tensor-unflatten"]], "torch.Tensor.uniform_": [[608, "torch-tensor-uniform"]], "torch.Tensor.triu": [[597, "torch-tensor-triu"]], "torch.Tensor.sum_to_size": [[566, "torch-tensor-sum-to-size"]], "torch.Tensor.tile": [[579, "torch-tensor-tile"]], "torch.Tensor.to_sparse_bsc": [[584, "torch-tensor-to-sparse-bsc"]], "torch.Tensor.to_sparse_coo": [[586, "torch-tensor-to-sparse-coo"]], "torch.Tensor.take": [[572, "torch-tensor-take"]], "torch.Tensor.tril_": [[596, "torch-tensor-tril"]], "torch.Tensor.unique_consecutive": [[610, "torch-tensor-unique-consecutive"]], "torch.Tensor.to_mkldnn": [[582, "torch-tensor-to-mkldnn"]], "torch.Tensor.to_sparse_bsr": [[585, "torch-tensor-to-sparse-bsr"]], "torch.Tensor.tanh_": [[577, "torch-tensor-tanh"]], "torch.Tensor.unique": [[609, "torch-tensor-unique"]], "torch.Tensor.tan": [[574, "torch-tensor-tan"]], "torch.Tensor.sgn": [[521, "torch-tensor-sgn"]], "torch.Tensor.select_scatter": [[519, "torch-tensor-select-scatter"]], "torch.Tensor.short": [[525, "torch-tensor-short"]], "torch.Tensor.squeeze_": [[553, "torch-tensor-squeeze"]], "torch.Tensor.std": [[555, "torch-tensor-std"]], "torch.Tensor.sin": [[531, "torch-tensor-sin"]], "torch.Tensor.sign": [[528, "torch-tensor-sign"]], "torch.Tensor.signbit": [[530, "torch-tensor-signbit"]], "torch.Tensor.squeeze": [[552, "torch-tensor-squeeze"]], "torch.Tensor.shape": [[523, "torch-tensor-shape"]], "torch.Tensor.share_memory_": [[524, "torch-tensor-share-memory"]], "torch.Tensor.sparse_resize_and_clear_": [[546, "torch-tensor-sparse-resize-and-clear"]], "torch.Tensor.subtract": [[563, "torch-tensor-subtract"]], "torch.Tensor.sqrt_": [[549, "torch-tensor-sqrt"]], "torch.Tensor.sort": [[542, "torch-tensor-sort"]], "torch.Tensor.square": [[550, "torch-tensor-square"]], "torch.Tensor.stride": [[560, "torch-tensor-stride"]], "torch.Tensor.sinc_": [[534, "torch-tensor-sinc"]], "torch.Tensor.scatter_reduce_": [[517, "torch-tensor-scatter-reduce"]], "torch.Tensor.sinh_": [[536, "torch-tensor-sinh"]], "torch.Tensor.sigmoid_": [[527, "torch-tensor-sigmoid"]], "torch.Tensor.split": [[547, "torch-tensor-split"]], "torch.Tensor.sub_": [[562, "torch-tensor-sub"]], "torch.Tensor.sinc": [[533, "torch-tensor-sinc"]], "torch.Tensor.set_": [[520, "torch-tensor-set"]], "torch.Tensor.softmax": [[541, "torch-tensor-softmax"]], "torch.Tensor.sparse_resize_": [[545, "torch-tensor-sparse-resize"]], "torch.Tensor.sparse_dim": [[543, "torch-tensor-sparse-dim"]], "torch.Tensor.sqrt": [[548, "torch-tensor-sqrt"]], "torch.Tensor.smm": [[540, "torch-tensor-smm"]], "torch.Tensor.storage_offset": [[558, "torch-tensor-storage-offset"]], "torch.Tensor.sinh": [[535, "torch-tensor-sinh"]], "torch.Tensor.sspaddmm": [[554, "torch-tensor-sspaddmm"]], "torch.Tensor.slice_scatter": [[538, "torch-tensor-slice-scatter"]], "torch.Tensor.sigmoid": [[526, "torch-tensor-sigmoid"]], "torch.Tensor.square_": [[551, "torch-tensor-square"]], "torch.Tensor.storage": [[557, "torch-tensor-storage"]], "torch.Tensor.slogdet": [[539, "torch-tensor-slogdet"]], "torch.Tensor.select": [[518, "torch-tensor-select"]], "torch.Tensor.sub": [[561, "torch-tensor-sub"]], "torch.Tensor.stft": [[556, "torch-tensor-stft"]], "torch.Tensor.sgn_": [[522, "torch-tensor-sgn"]], "torch.Tensor.sparse_mask": [[544, "torch-tensor-sparse-mask"]], "torch.Tensor.size": [[537, "torch-tensor-size"]], "torch.Tensor.storage_type": [[559, "torch-tensor-storage-type"]], "torch.Tensor.sign_": [[529, "torch-tensor-sign"]], "torch.Tensor.sin_": [[532, "torch-tensor-sin"]], "torch.Tensor.scatter_add_": [[515, "torch-tensor-scatter-add"]], "torch.Tensor.remainder": [[489, "torch-tensor-remainder"]], "torch.Tensor.round_": [[508, "torch-tensor-round"]], "torch.Tensor.put_": [[471, "torch-tensor-put"]], "torch.Tensor.random_": [[481, "torch-tensor-random"]], "torch.Tensor.requires_grad_": [[496, "torch-tensor-requires-grad"]], "torch.Tensor.rot90": [[506, "torch-tensor-rot90"]], "torch.Tensor.register_hook": [[487, "torch-tensor-register-hook"]], "torch.Tensor.scatter_": [[513, "torch-tensor-scatter"]], "torch.Tensor.q_zero_point": [[476, "torch-tensor-q-zero-point"]], "torch.Tensor.record_stream": [[486, "torch-tensor-record-stream"]], "torch.Tensor.scatter_reduce": [[516, "torch-tensor-scatter-reduce"]], "torch.Tensor.renorm_": [[492, "torch-tensor-renorm"]], "torch.Tensor.real": [[483, "torch-tensor-real"]], "torch.Tensor.q_scale": [[475, "torch-tensor-q-scale"]], "torch.Tensor.rsqrt_": [[511, "torch-tensor-rsqrt"]], "torch.Tensor.quantile": [[479, "torch-tensor-quantile"]], "torch.Tensor.retain_grad": [[503, "torch-tensor-retain-grad"]], "torch.Tensor.resolve_neg": [[502, "torch-tensor-resolve-neg"]], "torch.Tensor.row_indices": [[509, "torch-tensor-row-indices"]], "torch.Tensor.register_post_accumulate_grad_hook": [[488, "torch-tensor-register-post-accumulate-grad-hook"]], "torch.Tensor.requires_grad": [[495, "torch-tensor-requires-grad"]], "torch.Tensor.resolve_conj": [[501, "torch-tensor-resolve-conj"]], "torch.Tensor.ravel": [[482, "torch-tensor-ravel"]], "torch.Tensor.qscheme": [[478, "torch-tensor-qscheme"]], "torch.Tensor.repeat": [[493, "torch-tensor-repeat"]], "torch.Tensor.reshape": [[497, "torch-tensor-reshape"]], "torch.Tensor.resize_": [[499, "torch-tensor-resize"]], "torch.Tensor.rsqrt": [[510, "torch-tensor-rsqrt"]], "torch.Tensor.q_per_channel_axis": [[472, "torch-tensor-q-per-channel-axis"]], "torch.Tensor.q_per_channel_scales": [[473, "torch-tensor-q-per-channel-scales"]], "torch.Tensor.round": [[507, "torch-tensor-round"]], "torch.Tensor.reshape_as": [[498, "torch-tensor-reshape-as"]], "torch.Tensor.qr": [[477, "torch-tensor-qr"]], "torch.Tensor.q_per_channel_zero_points": [[474, "torch-tensor-q-per-channel-zero-points"]], "torch.Tensor.rad2deg": [[480, "torch-tensor-rad2deg"]], "torch.Tensor.renorm": [[491, "torch-tensor-renorm"]], "torch.Tensor.prod": [[470, "torch-tensor-prod"]], "torch.Tensor.roll": [[505, "torch-tensor-roll"]], "torch.Tensor.repeat_interleave": [[494, "torch-tensor-repeat-interleave"]], "torch.Tensor.scatter": [[512, "torch-tensor-scatter"]], "torch.Tensor.retains_grad": [[504, "torch-tensor-retains-grad"]], "torch.Tensor.reciprocal": [[484, "torch-tensor-reciprocal"]], "torch.Tensor.resize_as_": [[500, "torch-tensor-resize-as"]], "torch.Tensor.scatter_add": [[514, "torch-tensor-scatter-add"]], "torch.Tensor.reciprocal_": [[485, "torch-tensor-reciprocal"]], "torch.Tensor.remainder_": [[490, "torch-tensor-remainder"]]}, "indexentries": {"module": [[0, "module-torch.accelerator"], [1, "module-torch.amp"], [1, "module-torch.amp.autocast_mode"], [1, "module-torch.amp.grad_scaler"], [1, "module-torch.cpu.amp"], [1, "module-torch.cpu.amp.autocast_mode"], [1, "module-torch.cpu.amp.grad_scaler"], [1, "module-torch.cuda.amp"], [1, "module-torch.cuda.amp.autocast_mode"], [1, "module-torch.cuda.amp.common"], [1, "module-torch.cuda.amp.grad_scaler"], [2, "module-torch.autograd"], [2, "module-torch.autograd.anomaly_mode"], [2, "module-torch.autograd.forward_ad"], [2, "module-torch.autograd.function"], [2, "module-torch.autograd.functional"], [2, "module-torch.autograd.grad_mode"], [2, "module-torch.autograd.gradcheck"], [2, "module-torch.autograd.graph"], [2, "module-torch.autograd.profiler"], [2, "module-torch.autograd.profiler_legacy"], [2, "module-torch.autograd.profiler_util"], [2, "module-torch.autograd.variable"], [3, "module-torch.backends"], [3, "module-torch.backends.cpu"], [3, "module-torch.backends.cuda"], [3, "module-torch.backends.cudnn"], [3, "module-torch.backends.cudnn.rnn"], [3, "module-torch.backends.cusparselt"], [3, "module-torch.backends.kleidiai"], [3, "module-torch.backends.mha"], [3, "module-torch.backends.mkl"], [3, "module-torch.backends.mkldnn"], [3, "module-torch.backends.mps"], [3, "module-torch.backends.nnpack"], [3, "module-torch.backends.openmp"], [3, "module-torch.backends.opt_einsum"], [3, "module-torch.backends.quantized"], [3, "module-torch.backends.xeon"], [3, "module-torch.backends.xeon.run_cpu"], [3, "module-torch.backends.xnnpack"], [4, "module-torch.utils.benchmark"], [4, "module-torch.utils.benchmark.examples"], [4, "module-torch.utils.benchmark.op_fuzzers"], [4, "module-torch.utils.benchmark.utils"], [4, "module-torch.utils.benchmark.utils.valgrind_wrapper"], [5, "module-torch.utils.bottleneck"], [15, "module-torch.__config__"], [18, "module-torch.cpu"], [19, "module-torch.cuda"], [19, "module-torch.cuda.comm"], [19, "module-torch.cuda.error"], [19, "module-torch.cuda.gds"], [19, "module-torch.cuda.graphs"], [19, "module-torch.cuda.jiterator"], [19, "module-torch.cuda.memory"], [19, "module-torch.cuda.nccl"], [19, "module-torch.cuda.nvtx"], [19, "module-torch.cuda.profiler"], [19, "module-torch.cuda.random"], [19, "module-torch.cuda.sparse"], [19, "module-torch.cuda.streams"], [20, "module-torch.cuda._sanitizer"], [21, "module-torch.cuda.tunable"], [25, "module-torch.utils.data"], [25, "module-torch.utils.data.datapipes"], [25, "module-torch.utils.data.datapipes.dataframe"], [25, "module-torch.utils.data.datapipes.iter"], [25, "module-torch.utils.data.datapipes.map"], [25, "module-torch.utils.data.datapipes.utils"], [29, "module-torch.utils.deterministic"], [30, "module-torch.distributed"], [30, "module-torch.distributed.algorithms"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks.ddp_zero_hook"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks.default_hooks"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks.post_localSGD_hook"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook"], [30, "module-torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks"], [30, "module-torch.distributed.algorithms.join"], [30, "module-torch.distributed.algorithms.model_averaging"], [30, "module-torch.distributed.algorithms.model_averaging.averagers"], [30, "module-torch.distributed.algorithms.model_averaging.hierarchical_model_averager"], [30, "module-torch.distributed.algorithms.model_averaging.utils"], [30, "module-torch.distributed.argparse_util"], [30, "module-torch.distributed.c10d_logger"], [30, "module-torch.distributed.checkpoint.api"], [30, "module-torch.distributed.checkpoint.default_planner"], [30, "module-torch.distributed.checkpoint.filesystem"], [30, "module-torch.distributed.checkpoint.metadata"], [30, "module-torch.distributed.checkpoint.optimizer"], [30, "module-torch.distributed.checkpoint.planner"], [30, "module-torch.distributed.checkpoint.planner_helpers"], [30, "module-torch.distributed.checkpoint.resharding"], [30, "module-torch.distributed.checkpoint.state_dict"], [30, "module-torch.distributed.checkpoint.state_dict_loader"], [30, "module-torch.distributed.checkpoint.state_dict_saver"], [30, "module-torch.distributed.checkpoint.stateful"], [30, "module-torch.distributed.checkpoint.storage"], [30, "module-torch.distributed.checkpoint.utils"], [30, "module-torch.distributed.collective_utils"], [30, "module-torch.distributed.constants"], [30, "module-torch.distributed.device_mesh"], [30, "module-torch.distributed.distributed_c10d"], [30, "module-torch.distributed.elastic"], [30, "module-torch.distributed.elastic.agent.server.api"], [30, "module-torch.distributed.elastic.agent.server.local_elastic_agent"], [30, "module-torch.distributed.elastic.events.api"], [30, "module-torch.distributed.elastic.events.handlers"], [30, "module-torch.distributed.elastic.metrics.api"], [30, "module-torch.distributed.elastic.multiprocessing.api"], [30, "module-torch.distributed.elastic.multiprocessing.errors.error_handler"], [30, "module-torch.distributed.elastic.multiprocessing.errors.handlers"], [30, "module-torch.distributed.elastic.multiprocessing.redirects"], [30, "module-torch.distributed.elastic.multiprocessing.tail_log"], [30, "module-torch.distributed.elastic.rendezvous.api"], [30, "module-torch.distributed.elastic.rendezvous.c10d_rendezvous_backend"], [30, "module-torch.distributed.elastic.rendezvous.dynamic_rendezvous"], [30, "module-torch.distributed.elastic.rendezvous.etcd_rendezvous"], [30, "module-torch.distributed.elastic.rendezvous.etcd_rendezvous_backend"], [30, "module-torch.distributed.elastic.rendezvous.etcd_server"], [30, "module-torch.distributed.elastic.rendezvous.etcd_store"], [30, "module-torch.distributed.elastic.rendezvous.static_tcp_rendezvous"], [30, "module-torch.distributed.elastic.rendezvous.utils"], [30, "module-torch.distributed.elastic.timer.api"], [30, "module-torch.distributed.elastic.timer.file_based_local_timer"], [30, "module-torch.distributed.elastic.timer.local_timer"], [30, "module-torch.distributed.elastic.utils"], [30, "module-torch.distributed.elastic.utils.api"], [30, "module-torch.distributed.elastic.utils.data"], [30, "module-torch.distributed.elastic.utils.data.cycling_iterator"], [30, "module-torch.distributed.elastic.utils.data.elastic_distributed_sampler"], [30, "module-torch.distributed.elastic.utils.distributed"], [30, "module-torch.distributed.elastic.utils.log_level"], [30, "module-torch.distributed.elastic.utils.logging"], [30, "module-torch.distributed.elastic.utils.store"], [30, "module-torch.distributed.fsdp.api"], [30, "module-torch.distributed.fsdp.fully_sharded_data_parallel"], [30, "module-torch.distributed.fsdp.sharded_grad_scaler"], [30, "module-torch.distributed.fsdp.wrap"], [30, "module-torch.distributed.launch"], [30, "module-torch.distributed.launcher"], [30, "module-torch.distributed.launcher.api"], [30, "module-torch.distributed.logging_handlers"], [30, "module-torch.distributed.nn"], [30, "module-torch.distributed.nn.api"], [30, "module-torch.distributed.nn.api.remote_module"], [30, "module-torch.distributed.nn.functional"], [30, "module-torch.distributed.nn.jit"], [30, "module-torch.distributed.nn.jit.instantiator"], [30, "module-torch.distributed.nn.jit.templates"], [30, "module-torch.distributed.nn.jit.templates.remote_module_template"], [30, "module-torch.distributed.optim.apply_optimizer_in_backward"], [30, "module-torch.distributed.optim.functional_adadelta"], [30, "module-torch.distributed.optim.functional_adagrad"], [30, "module-torch.distributed.optim.functional_adam"], [30, "module-torch.distributed.optim.functional_adamax"], [30, "module-torch.distributed.optim.functional_adamw"], [30, "module-torch.distributed.optim.functional_rmsprop"], [30, "module-torch.distributed.optim.functional_rprop"], [30, "module-torch.distributed.optim.functional_sgd"], [30, "module-torch.distributed.optim.named_optimizer"], [30, "module-torch.distributed.optim.optimizer"], [30, "module-torch.distributed.optim.post_localSGD_optimizer"], [30, "module-torch.distributed.optim.utils"], [30, "module-torch.distributed.optim.zero_redundancy_optimizer"], [30, "module-torch.distributed.remote_device"], [30, "module-torch.distributed.rendezvous"], [30, "module-torch.distributed.rpc.api"], [30, "module-torch.distributed.rpc.backend_registry"], [30, "module-torch.distributed.rpc.constants"], [30, "module-torch.distributed.rpc.functions"], [30, "module-torch.distributed.rpc.internal"], [30, "module-torch.distributed.rpc.options"], [30, "module-torch.distributed.rpc.rref_proxy"], [30, "module-torch.distributed.rpc.server_process_global_profiler"], [30, "module-torch.distributed.tensor.parallel.api"], [30, "module-torch.distributed.tensor.parallel.ddp"], [30, "module-torch.distributed.tensor.parallel.fsdp"], [30, "module-torch.distributed.tensor.parallel.input_reshard"], [30, "module-torch.distributed.tensor.parallel.loss"], [30, "module-torch.distributed.tensor.parallel.style"], [30, "module-torch.distributed.utils"], [32, "module-torch.distributed.checkpoint"], [32, "module-torch.distributed.checkpoint.format_utils"], [32, "module-torch.distributed.checkpoint.logger"], [32, "module-torch.distributed.checkpoint.logging_handlers"], [32, "module-torch.distributed.checkpoint.staging"], [35, "module-torch.distributed.optim"], [36, "module-torch.distributed.pipelining"], [36, "module-torch.distributed.pipelining.microbatch"], [36, "module-torch.distributed.pipelining.schedules"], [36, "module-torch.distributed.pipelining.stage"], [37, "module-torch.distributed.tensor"], [37, "module-torch.distributed.tensor.debug"], [37, "module-torch.distributed.tensor.device_mesh"], [37, "module-torch.distributed.tensor.experimental"], [37, "module-torch.distributed.tensor.placement_types"], [38, "module-torch.distributed.tensor.parallel"], [39, "module-torch.distributions"], [39, "module-torch.distributions.bernoulli"], [39, "module-torch.distributions.beta"], [39, "module-torch.distributions.binomial"], [39, "module-torch.distributions.categorical"], [39, "module-torch.distributions.cauchy"], [39, "module-torch.distributions.chi2"], [39, "module-torch.distributions.constraint_registry"], [39, "module-torch.distributions.constraints"], [39, "module-torch.distributions.continuous_bernoulli"], [39, "module-torch.distributions.dirichlet"], [39, "module-torch.distributions.distribution"], [39, "module-torch.distributions.exp_family"], [39, "module-torch.distributions.exponential"], [39, "module-torch.distributions.fishersnedecor"], [39, "module-torch.distributions.gamma"], [39, "module-torch.distributions.geometric"], [39, "module-torch.distributions.gumbel"], [39, "module-torch.distributions.half_cauchy"], [39, "module-torch.distributions.half_normal"], [39, "module-torch.distributions.independent"], [39, "module-torch.distributions.inverse_gamma"], [39, "module-torch.distributions.kl"], [39, "module-torch.distributions.kumaraswamy"], [39, "module-torch.distributions.laplace"], [39, "module-torch.distributions.lkj_cholesky"], [39, "module-torch.distributions.log_normal"], [39, "module-torch.distributions.logistic_normal"], [39, "module-torch.distributions.lowrank_multivariate_normal"], [39, "module-torch.distributions.mixture_same_family"], [39, "module-torch.distributions.multinomial"], [39, "module-torch.distributions.multivariate_normal"], [39, "module-torch.distributions.negative_binomial"], [39, "module-torch.distributions.normal"], [39, "module-torch.distributions.one_hot_categorical"], [39, "module-torch.distributions.pareto"], [39, "module-torch.distributions.poisson"], [39, "module-torch.distributions.relaxed_bernoulli"], [39, "module-torch.distributions.relaxed_categorical"], [39, "module-torch.distributions.studentT"], [39, "module-torch.distributions.transformed_distribution"], [39, "module-torch.distributions.transforms"], [39, "module-torch.distributions.uniform"], [39, "module-torch.distributions.utils"], [39, "module-torch.distributions.von_mises"], [39, "module-torch.distributions.weibull"], [39, "module-torch.distributions.wishart"], [41, "module-torch.distributed.elastic.agent"], [41, "module-torch.distributed.elastic.agent.server"], [41, "module-torch.distributed.elastic.agent.server.health_check_server"], [42, "module-torch.distributed.elastic.control_plane"], [44, "module-torch.distributed.elastic.multiprocessing.errors"], [45, "module-torch.distributed.elastic.events"], [48, "module-torch.distributed.elastic.metrics"], [49, "module-torch.distributed.elastic.multiprocessing"], [51, "module-torch.distributed.elastic.rendezvous"], [51, "module-torch.distributed.elastic.rendezvous.registry"], [52, "module-torch.distributed.run"], [53, "module-torch.distributed.elastic.multiprocessing.subprocess_handler"], [53, "module-torch.distributed.elastic.multiprocessing.subprocess_handler.handlers"], [53, "module-torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler"], [54, "module-torch.distributed.elastic.timer"], [54, "module-torch.distributed.elastic.timer.debug_info_logging"], [56, "module-torch.export"], [56, "module-torch.export.custom_obj"], [56, "module-torch.export.custom_ops"], [56, "module-torch.export.decomp_utils"], [56, "module-torch.export.dynamic_shapes"], [56, "module-torch.export.experimental"], [56, "module-torch.export.exported_program"], [56, "module-torch.export.graph_signature"], [56, "module-torch.export.passes"], [56, "module-torch.export.unflatten"], [59, "module-torch.fft"], [60, "module-torch.distributed.fsdp"], [62, "module-torch.func"], [67, "module-torch.__future__"], [68, "module-torch.futures"], [69, "module-torch.fx"], [69, "module-torch.fx.annotate"], [69, "module-torch.fx.config"], [69, "module-torch.fx.experimental"], [69, "module-torch.fx.experimental.accelerator_partitioner"], [69, "module-torch.fx.experimental.const_fold"], [69, "module-torch.fx.experimental.debug"], [69, "module-torch.fx.experimental.graph_gradual_typechecker"], [69, "module-torch.fx.experimental.merge_matmul"], [69, "module-torch.fx.experimental.meta_tracer"], [69, "module-torch.fx.experimental.migrate_gradual_types"], [69, "module-torch.fx.experimental.migrate_gradual_types.constraint"], [69, "module-torch.fx.experimental.migrate_gradual_types.constraint_generator"], [69, "module-torch.fx.experimental.migrate_gradual_types.constraint_transformation"], [69, "module-torch.fx.experimental.migrate_gradual_types.operation"], [69, "module-torch.fx.experimental.migrate_gradual_types.transform_to_z3"], [69, "module-torch.fx.experimental.migrate_gradual_types.util"], [69, "module-torch.fx.experimental.migrate_gradual_types.z3_types"], [69, "module-torch.fx.experimental.normalize"], [69, "module-torch.fx.experimental.optimization"], [69, "module-torch.fx.experimental.partitioner_utils"], [69, "module-torch.fx.experimental.recording"], [69, "module-torch.fx.experimental.refinement_types"], [69, "module-torch.fx.experimental.rewriter"], [69, "module-torch.fx.experimental.schema_type_annotation"], [69, "module-torch.fx.experimental.sym_node"], [69, "module-torch.fx.experimental.unification"], [69, "module-torch.fx.experimental.unification.core"], [69, "module-torch.fx.experimental.unification.dispatch"], [69, "module-torch.fx.experimental.unification.match"], [69, "module-torch.fx.experimental.unification.more"], [69, "module-torch.fx.experimental.unification.multipledispatch"], [69, "module-torch.fx.experimental.unification.multipledispatch.conflict"], [69, "module-torch.fx.experimental.unification.multipledispatch.core"], [69, "module-torch.fx.experimental.unification.multipledispatch.dispatcher"], [69, "module-torch.fx.experimental.unification.multipledispatch.utils"], [69, "module-torch.fx.experimental.unification.multipledispatch.variadic"], [69, "module-torch.fx.experimental.unification.unification_tools"], [69, "module-torch.fx.experimental.unification.utils"], [69, "module-torch.fx.experimental.unification.variable"], [69, "module-torch.fx.experimental.unify_refinements"], [69, "module-torch.fx.experimental.validator"], [69, "module-torch.fx.graph"], [69, "module-torch.fx.graph_module"], [69, "module-torch.fx.immutable_collections"], [69, "module-torch.fx.interpreter"], [69, "module-torch.fx.node"], [69, "module-torch.fx.operator_schemas"], [69, "module-torch.fx.passes"], [69, "module-torch.fx.passes.annotate_getitem_nodes"], [69, "module-torch.fx.passes.backends"], [69, "module-torch.fx.passes.backends.cudagraphs"], [69, "module-torch.fx.passes.dialect"], [69, "module-torch.fx.passes.dialect.common"], [69, "module-torch.fx.passes.dialect.common.cse_pass"], [69, "module-torch.fx.passes.fake_tensor_prop"], [69, "module-torch.fx.passes.graph_drawer"], [69, "module-torch.fx.passes.graph_manipulation"], [69, "module-torch.fx.passes.graph_transform_observer"], [69, "module-torch.fx.passes.infra"], [69, "module-torch.fx.passes.infra.partitioner"], [69, "module-torch.fx.passes.infra.pass_base"], [69, "module-torch.fx.passes.infra.pass_manager"], [69, "module-torch.fx.passes.net_min_base"], [69, "module-torch.fx.passes.operator_support"], [69, "module-torch.fx.passes.param_fetch"], [69, "module-torch.fx.passes.pass_manager"], [69, "module-torch.fx.passes.reinplace"], [69, "module-torch.fx.passes.runtime_assert"], [69, "module-torch.fx.passes.shape_prop"], [69, "module-torch.fx.passes.split_module"], [69, "module-torch.fx.passes.split_utils"], [69, "module-torch.fx.passes.splitter_base"], [69, "module-torch.fx.passes.tests"], [69, "module-torch.fx.passes.tests.test_pass_manager"], [69, "module-torch.fx.passes.tools_common"], [69, "module-torch.fx.passes.utils"], [69, "module-torch.fx.passes.utils.common"], [69, "module-torch.fx.passes.utils.fuser_utils"], [69, "module-torch.fx.passes.utils.matcher_utils"], [69, "module-torch.fx.passes.utils.matcher_with_name_node_map_utils"], [69, "module-torch.fx.passes.utils.source_matcher_utils"], [69, "module-torch.fx.proxy"], [69, "module-torch.fx.subgraph_rewriter"], [69, "module-torch.fx.tensor_type"], [69, "module-torch.fx.traceback"], [70, "module-torch.fx.experimental.proxy_tensor"], [70, "module-torch.fx.experimental.symbolic_shapes"], [2091, "module-torch.hub"], [2093, "module-torch.jit"], [2093, "module-torch.jit.annotations"], [2093, "module-torch.jit.frontend"], [2093, "module-torch.jit.generate_bytecode"], [2093, "module-torch.jit.mobile"], [2093, "module-torch.jit.quantized"], [2094, "module-torch.jit.supported_ops"], [2098, "module-torch.jit.unsupported_tensor_ops"], [2099, "module-torch.utils.jit"], [2100, "module-torch.library"], [2101, "module-torch.linalg"], [2102, "module-torch._logging"], [2103, "module-torch.masked"], [2103, "module-torch.masked.maskedtensor"], [2103, "module-torch.masked.maskedtensor.binary"], [2103, "module-torch.masked.maskedtensor.core"], [2103, "module-torch.masked.maskedtensor.creation"], [2103, "module-torch.masked.maskedtensor.passthrough"], [2103, "module-torch.masked.maskedtensor.reductions"], [2103, "module-torch.masked.maskedtensor.unary"], [2107, "module-torch.utils.model_zoo"], [2108, "module-torch.utils.module_tracker"], [2109, "module-torch.monitor"], [2110, "module-torch.mps"], [2110, "module-torch.mps.event"], [2110, "module-torch.mps.profiler"], [2112, "module-torch.mtia"], [2113, "module-torch.mtia.memory"], [2114, "module-torch.multiprocessing"], [2114, "module-torch.multiprocessing.pool"], [2114, "module-torch.multiprocessing.queue"], [2114, "module-torch.multiprocessing.reductions"], [2114, "module-torch.multiprocessing.spawn"], [2117, "module-torch.nested"], [2118, "module-torch.nn"], [2118, "module-torch.nn.backends"], [2118, "module-torch.nn.backends.thnn"], [2118, "module-torch.nn.common_types"], [2118, "module-torch.nn.cpp"], [2118, "module-torch.nn.functional"], [2118, "module-torch.nn.grad"], [2118, "module-torch.nn.init"], [2118, "module-torch.nn.modules"], [2118, "module-torch.nn.modules.activation"], [2118, "module-torch.nn.modules.adaptive"], [2118, "module-torch.nn.modules.batchnorm"], [2118, "module-torch.nn.modules.channelshuffle"], [2118, "module-torch.nn.modules.container"], [2118, "module-torch.nn.modules.conv"], [2118, "module-torch.nn.modules.distance"], [2118, "module-torch.nn.modules.dropout"], [2118, "module-torch.nn.modules.flatten"], [2118, "module-torch.nn.modules.fold"], [2118, "module-torch.nn.modules.instancenorm"], [2118, "module-torch.nn.modules.lazy"], [2118, "module-torch.nn.modules.linear"], [2118, "module-torch.nn.modules.loss"], [2118, "module-torch.nn.modules.module"], [2118, "module-torch.nn.modules.normalization"], [2118, "module-torch.nn.modules.padding"], [2118, "module-torch.nn.modules.pixelshuffle"], [2118, "module-torch.nn.modules.pooling"], [2118, "module-torch.nn.modules.rnn"], [2118, "module-torch.nn.modules.sparse"], [2118, "module-torch.nn.modules.transformer"], [2118, "module-torch.nn.modules.upsampling"], [2118, "module-torch.nn.modules.utils"], [2118, "module-torch.nn.parallel"], [2118, "module-torch.nn.parallel.comm"], [2118, "module-torch.nn.parallel.distributed"], [2118, "module-torch.nn.parallel.parallel_apply"], [2118, "module-torch.nn.parallel.replicate"], [2118, "module-torch.nn.parallel.scatter_gather"], [2118, "module-torch.nn.parameter"], [2118, "module-torch.nn.utils"], [2118, "module-torch.nn.utils.clip_grad"], [2118, "module-torch.nn.utils.convert_parameters"], [2118, "module-torch.nn.utils.fusion"], [2118, "module-torch.nn.utils.init"], [2118, "module-torch.nn.utils.memory_format"], [2118, "module-torch.nn.utils.parametrizations"], [2118, "module-torch.nn.utils.parametrize"], [2118, "module-torch.nn.utils.prune"], [2118, "module-torch.nn.utils.rnn"], [2118, "module-torch.nn.utils.stateless"], [2119, "module-torch.nn.attention"], [2120, "module-torch.nn.attention.bias"], [2121, "module-torch.nn.attention.experimental"], [2122, "module-torch.nn.attention.flex_attention"], [2147, "module-torch.utils.serialization"], [2147, "module-torch.utils.serialization.config"], [2149, "module-torch.onnx.errors"], [2149, "module-torch.onnx.operators"], [2149, "module-torch.onnx.symbolic_caffe2"], [2149, "module-torch.onnx.symbolic_helper"], [2149, "module-torch.onnx.symbolic_opset10"], [2149, "module-torch.onnx.symbolic_opset11"], [2149, "module-torch.onnx.symbolic_opset12"], [2149, "module-torch.onnx.symbolic_opset13"], [2149, "module-torch.onnx.symbolic_opset14"], [2149, "module-torch.onnx.symbolic_opset15"], [2149, "module-torch.onnx.symbolic_opset16"], [2149, "module-torch.onnx.symbolic_opset17"], [2149, "module-torch.onnx.symbolic_opset18"], [2149, "module-torch.onnx.symbolic_opset19"], [2149, "module-torch.onnx.symbolic_opset20"], [2149, "module-torch.onnx.symbolic_opset7"], [2149, "module-torch.onnx.symbolic_opset8"], [2149, "module-torch.onnx.symbolic_opset9"], [2149, "module-torch.onnx.utils"], [2154, "module-torch.onnx"], [2156, "module-torch.onnx.verification"], [2157, "module-torch.optim"], [2157, "module-torch.optim.adadelta"], [2157, "module-torch.optim.adagrad"], [2157, "module-torch.optim.adam"], [2157, "module-torch.optim.adamax"], [2157, "module-torch.optim.adamw"], [2157, "module-torch.optim.asgd"], [2157, "module-torch.optim.lbfgs"], [2157, "module-torch.optim.lr_scheduler"], [2157, "module-torch.optim.nadam"], [2157, "module-torch.optim.optimizer"], [2157, "module-torch.optim.radam"], [2157, "module-torch.optim.rmsprop"], [2157, "module-torch.optim.rprop"], [2157, "module-torch.optim.sgd"], [2157, "module-torch.optim.sparse_adam"], [2157, "module-torch.optim.swa_utils"], [2158, "module-torch.package"], [2158, "module-torch.package.analyze"], [2158, "module-torch.package.analyze.find_first_use_of_broken_modules"], [2158, "module-torch.package.analyze.is_from_package"], [2158, "module-torch.package.analyze.trace_dependencies"], [2158, "module-torch.package.file_structure_representation"], [2158, "module-torch.package.find_file_dependencies"], [2158, "module-torch.package.glob_group"], [2158, "module-torch.package.importer"], [2158, "module-torch.package.package_exporter"], [2158, "module-torch.package.package_importer"], [2159, "module-torch.profiler"], [2159, "module-torch.profiler.itt"], [2159, "module-torch.profiler.profiler"], [2159, "module-torch.profiler.python_tracer"], [2161, "module-torch.ao"], [2161, "module-torch.ao.nn"], [2161, "module-torch.ao.nn.intrinsic.modules.fused"], [2161, "module-torch.ao.nn.intrinsic.qat.modules.conv_fused"], [2161, "module-torch.ao.nn.intrinsic.qat.modules.linear_fused"], [2161, "module-torch.ao.nn.intrinsic.qat.modules.linear_relu"], [2161, "module-torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu"], [2161, "module-torch.ao.nn.intrinsic.quantized.modules.bn_relu"], [2161, "module-torch.ao.nn.intrinsic.quantized.modules.conv_add"], [2161, "module-torch.ao.nn.intrinsic.quantized.modules.conv_relu"], [2161, "module-torch.ao.nn.intrinsic.quantized.modules.linear_relu"], [2161, "module-torch.ao.nn.qat.dynamic.modules.linear"], [2161, "module-torch.ao.nn.qat.modules.conv"], [2161, "module-torch.ao.nn.qat.modules.embedding_ops"], [2161, "module-torch.ao.nn.qat.modules.linear"], [2161, "module-torch.ao.nn.quantizable"], [2161, "module-torch.ao.nn.quantizable.modules"], [2161, "module-torch.ao.nn.quantizable.modules.activation"], [2161, "module-torch.ao.nn.quantizable.modules.rnn"], [2161, "module-torch.ao.nn.quantized"], [2161, "module-torch.ao.nn.quantized.dynamic.modules.conv"], [2161, "module-torch.ao.nn.quantized.dynamic.modules.linear"], [2161, "module-torch.ao.nn.quantized.dynamic.modules.rnn"], [2161, "module-torch.ao.nn.quantized.modules.activation"], [2161, "module-torch.ao.nn.quantized.modules.batchnorm"], [2161, "module-torch.ao.nn.quantized.modules.conv"], [2161, "module-torch.ao.nn.quantized.modules.dropout"], [2161, "module-torch.ao.nn.quantized.modules.embedding_ops"], [2161, "module-torch.ao.nn.quantized.modules.functional_modules"], [2161, "module-torch.ao.nn.quantized.modules.linear"], [2161, "module-torch.ao.nn.quantized.modules.normalization"], [2161, "module-torch.ao.nn.quantized.modules.rnn"], [2161, "module-torch.ao.nn.quantized.modules.utils"], [2161, "module-torch.ao.nn.quantized.reference"], [2161, "module-torch.ao.nn.quantized.reference.modules"], [2161, "module-torch.ao.nn.quantized.reference.modules.conv"], [2161, "module-torch.ao.nn.quantized.reference.modules.linear"], [2161, "module-torch.ao.nn.quantized.reference.modules.rnn"], [2161, "module-torch.ao.nn.quantized.reference.modules.sparse"], [2161, "module-torch.ao.nn.quantized.reference.modules.utils"], [2161, "module-torch.ao.nn.sparse"], [2161, "module-torch.ao.nn.sparse.quantized"], [2161, "module-torch.ao.nn.sparse.quantized.dynamic"], [2161, "module-torch.ao.nn.sparse.quantized.dynamic.linear"], [2161, "module-torch.ao.nn.sparse.quantized.linear"], [2161, "module-torch.ao.nn.sparse.quantized.utils"], [2161, "module-torch.ao.ns"], [2161, "module-torch.ao.ns.fx"], [2161, "module-torch.ao.ns.fx.graph_matcher"], [2161, "module-torch.ao.ns.fx.graph_passes"], [2161, "module-torch.ao.ns.fx.mappings"], [2161, "module-torch.ao.ns.fx.n_shadows_utils"], [2161, "module-torch.ao.ns.fx.ns_types"], [2161, "module-torch.ao.ns.fx.pattern_utils"], [2161, "module-torch.ao.ns.fx.qconfig_multi_mapping"], [2161, "module-torch.ao.ns.fx.utils"], [2161, "module-torch.ao.ns.fx.weight_utils"], [2161, "module-torch.ao.pruning"], [2161, "module-torch.ao.pruning.scheduler"], [2161, "module-torch.ao.pruning.scheduler.base_scheduler"], [2161, "module-torch.ao.pruning.scheduler.cubic_scheduler"], [2161, "module-torch.ao.pruning.scheduler.lambda_scheduler"], [2161, "module-torch.ao.pruning.sparsifier"], [2161, "module-torch.ao.pruning.sparsifier.base_sparsifier"], [2161, "module-torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier"], [2161, "module-torch.ao.pruning.sparsifier.utils"], [2161, "module-torch.ao.pruning.sparsifier.weight_norm_sparsifier"], [2161, "module-torch.ao.quantization"], [2161, "module-torch.ao.quantization.backend_config"], [2161, "module-torch.ao.quantization.backend_config.backend_config"], [2161, "module-torch.ao.quantization.backend_config.executorch"], [2161, "module-torch.ao.quantization.backend_config.fbgemm"], [2161, "module-torch.ao.quantization.backend_config.native"], [2161, "module-torch.ao.quantization.backend_config.observation_type"], [2161, "module-torch.ao.quantization.backend_config.onednn"], [2161, "module-torch.ao.quantization.backend_config.qnnpack"], [2161, "module-torch.ao.quantization.backend_config.tensorrt"], [2161, "module-torch.ao.quantization.backend_config.utils"], [2161, "module-torch.ao.quantization.backend_config.x86"], [2161, "module-torch.ao.quantization.fake_quantize"], [2161, "module-torch.ao.quantization.fuse_modules"], [2161, "module-torch.ao.quantization.fuser_method_mappings"], [2161, "module-torch.ao.quantization.fx"], [2161, "module-torch.ao.quantization.fx.convert"], [2161, "module-torch.ao.quantization.fx.custom_config"], [2161, "module-torch.ao.quantization.fx.fuse"], [2161, "module-torch.ao.quantization.fx.fuse_handler"], [2161, "module-torch.ao.quantization.fx.graph_module"], [2161, "module-torch.ao.quantization.fx.lower_to_fbgemm"], [2161, "module-torch.ao.quantization.fx.lower_to_qnnpack"], [2161, "module-torch.ao.quantization.fx.lstm_utils"], [2161, "module-torch.ao.quantization.fx.match_utils"], [2161, "module-torch.ao.quantization.fx.pattern_utils"], [2161, "module-torch.ao.quantization.fx.prepare"], [2161, "module-torch.ao.quantization.fx.qconfig_mapping_utils"], [2161, "module-torch.ao.quantization.fx.quantize_handler"], [2161, "module-torch.ao.quantization.fx.tracer"], [2161, "module-torch.ao.quantization.fx.utils"], [2161, "module-torch.ao.quantization.observer"], [2161, "module-torch.ao.quantization.pt2e.duplicate_dq_pass"], [2161, "module-torch.ao.quantization.pt2e.export_utils"], [2161, "module-torch.ao.quantization.pt2e.graph_utils"], [2161, "module-torch.ao.quantization.pt2e.port_metadata_pass"], [2161, "module-torch.ao.quantization.pt2e.prepare"], [2161, "module-torch.ao.quantization.pt2e.qat_utils"], [2161, "module-torch.ao.quantization.pt2e.representation.rewrite"], [2161, "module-torch.ao.quantization.pt2e.utils"], [2161, "module-torch.ao.quantization.qconfig"], [2161, "module-torch.ao.quantization.qconfig_mapping"], [2161, "module-torch.ao.quantization.quant_type"], [2161, "module-torch.ao.quantization.quantization_mappings"], [2161, "module-torch.ao.quantization.quantize_fx"], [2161, "module-torch.ao.quantization.quantize_jit"], [2161, "module-torch.ao.quantization.quantize_pt2e"], [2161, "module-torch.ao.quantization.quantizer.composable_quantizer"], [2161, "module-torch.ao.quantization.quantizer.embedding_quantizer"], [2161, "module-torch.ao.quantization.quantizer.quantizer"], [2161, "module-torch.ao.quantization.quantizer.utils"], [2161, "module-torch.ao.quantization.quantizer.x86_inductor_quantizer"], [2161, "module-torch.ao.quantization.quantizer.xnnpack_quantizer"], [2161, "module-torch.ao.quantization.quantizer.xnnpack_quantizer_utils"], [2161, "module-torch.ao.quantization.quantizer.xpu_inductor_quantizer"], [2161, "module-torch.ao.quantization.stubs"], [2161, "module-torch.ao.quantization.utils"], [2161, "module-torch.nn.intrinsic.modules.fused"], [2161, "module-torch.nn.intrinsic.qat.modules.conv_fused"], [2161, "module-torch.nn.intrinsic.qat.modules.linear_fused"], [2161, "module-torch.nn.intrinsic.qat.modules.linear_relu"], [2161, "module-torch.nn.intrinsic.quantized.dynamic.modules.linear_relu"], [2161, "module-torch.nn.intrinsic.quantized.modules.bn_relu"], [2161, "module-torch.nn.intrinsic.quantized.modules.conv_relu"], [2161, "module-torch.nn.intrinsic.quantized.modules.linear_relu"], [2161, "module-torch.nn.qat.dynamic.modules.linear"], [2161, "module-torch.nn.qat.modules.conv"], [2161, "module-torch.nn.qat.modules.embedding_ops"], [2161, "module-torch.nn.qat.modules.linear"], [2161, "module-torch.nn.quantizable.modules.activation"], [2161, "module-torch.nn.quantizable.modules.rnn"], [2161, "module-torch.nn.quantized.dynamic.modules.conv"], [2161, "module-torch.nn.quantized.dynamic.modules.linear"], [2161, "module-torch.nn.quantized.dynamic.modules.rnn"], [2161, "module-torch.nn.quantized.functional"], [2161, "module-torch.nn.quantized.modules.activation"], [2161, "module-torch.nn.quantized.modules.batchnorm"], [2161, "module-torch.nn.quantized.modules.conv"], [2161, "module-torch.nn.quantized.modules.dropout"], [2161, "module-torch.nn.quantized.modules.embedding_ops"], [2161, "module-torch.nn.quantized.modules.functional_modules"], [2161, "module-torch.nn.quantized.modules.linear"], [2161, "module-torch.nn.quantized.modules.normalization"], [2161, "module-torch.nn.quantized.modules.rnn"], [2161, "module-torch.nn.quantized.modules.utils"], [2161, "module-torch.quantization.fake_quantize"], [2161, "module-torch.quantization.fuse_modules"], [2161, "module-torch.quantization.fuser_method_mappings"], [2161, "module-torch.quantization.fx.convert"], [2161, "module-torch.quantization.fx.fuse"], [2161, "module-torch.quantization.fx.fusion_patterns"], [2161, "module-torch.quantization.fx.graph_module"], [2161, "module-torch.quantization.fx.match_utils"], [2161, "module-torch.quantization.fx.pattern_utils"], [2161, "module-torch.quantization.fx.prepare"], [2161, "module-torch.quantization.fx.quantization_patterns"], [2161, "module-torch.quantization.fx.quantization_types"], [2161, "module-torch.quantization.fx.utils"], [2161, "module-torch.quantization.observer"], [2161, "module-torch.quantization.qconfig"], [2161, "module-torch.quantization.quant_type"], [2161, "module-torch.quantization.quantization_mappings"], [2161, "module-torch.quantization.quantize"], [2161, "module-torch.quantization.quantize_fx"], [2161, "module-torch.quantization.quantize_jit"], [2161, "module-torch.quantization.stubs"], [2161, "module-torch.quantization.utils"], [2164, "module-torch.ao.nn.intrinsic"], [2164, "module-torch.ao.nn.intrinsic.modules"], [2164, "module-torch.ao.nn.intrinsic.qat"], [2164, "module-torch.ao.nn.intrinsic.qat.modules"], [2164, "module-torch.ao.nn.intrinsic.quantized"], [2164, "module-torch.ao.nn.intrinsic.quantized.dynamic"], [2164, "module-torch.ao.nn.intrinsic.quantized.dynamic.modules"], [2164, "module-torch.ao.nn.intrinsic.quantized.modules"], [2164, "module-torch.ao.nn.qat"], [2164, "module-torch.ao.nn.qat.dynamic"], [2164, "module-torch.ao.nn.qat.dynamic.modules"], [2164, "module-torch.ao.nn.qat.modules"], [2164, "module-torch.ao.nn.quantized.dynamic"], [2164, "module-torch.ao.nn.quantized.dynamic.modules"], [2164, "module-torch.ao.nn.quantized.functional"], [2164, "module-torch.ao.nn.quantized.modules"], [2164, "module-torch.ao.quantization.pt2e"], [2164, "module-torch.ao.quantization.pt2e.representation"], [2164, "module-torch.ao.quantization.quantizer"], [2164, "module-torch.nn.intrinsic"], [2164, "module-torch.nn.intrinsic.modules"], [2164, "module-torch.nn.intrinsic.qat"], [2164, "module-torch.nn.intrinsic.qat.modules"], [2164, "module-torch.nn.intrinsic.quantized"], [2164, "module-torch.nn.intrinsic.quantized.dynamic"], [2164, "module-torch.nn.intrinsic.quantized.dynamic.modules"], [2164, "module-torch.nn.intrinsic.quantized.modules"], [2164, "module-torch.nn.qat"], [2164, "module-torch.nn.qat.dynamic"], [2164, "module-torch.nn.qat.dynamic.modules"], [2164, "module-torch.nn.qat.modules"], [2164, "module-torch.nn.quantizable"], [2164, "module-torch.nn.quantizable.modules"], [2164, "module-torch.nn.quantized"], [2164, "module-torch.nn.quantized.dynamic"], [2164, "module-torch.nn.quantized.dynamic.modules"], [2164, "module-torch.nn.quantized.modules"], [2164, "module-torch.quantization"], [2164, "module-torch.quantization.fx"], [2165, "module-torch.random"], [2166, "module-torch.distributed.autograd"], [2166, "module-torch.distributed.rpc"], [2169, "module-torch.signal"], [2169, "module-torch.signal.windows"], [2171, "module-torch.sparse"], [2172, "module-torch.special"], [2176, "module-torch.utils.tensorboard"], [2178, "module-torch.testing"], [2180, "module-torch"], [2180, "module-torch.contrib"], [2180, "module-torch.functional"], [2180, "module-torch.quasirandom"], [2180, "module-torch.return_types"], [2180, "module-torch.serialization"], [2180, "module-torch.signal.windows.windows"], [2180, "module-torch.sparse.semi_structured"], [2180, "module-torch.storage"], [2180, "module-torch.torch_version"], [2180, "module-torch.types"], [2180, "module-torch.utils.backcompat"], [2180, "module-torch.utils.hipify"], [2180, "module-torch.utils.model_dump"], [2180, "module-torch.utils.viz"], [2180, "module-torch.version"], [2181, "module-torch.ao.ns._numeric_suite"], [2182, "module-torch.ao.ns._numeric_suite_fx"], [2184, "module-torch.compiler.config"], [2187, "module-torch.compiler"], [2206, "module-torch.overrides"], [2211, "module-torch.utils"], [2211, "module-torch.utils.backend_registration"], [2211, "module-torch.utils.benchmark.examples.blas_compare_setup"], [2211, "module-torch.utils.benchmark.examples.compare"], [2211, "module-torch.utils.benchmark.examples.fuzzer"], [2211, "module-torch.utils.benchmark.examples.op_benchmark"], [2211, "module-torch.utils.benchmark.examples.simple_timeit"], [2211, "module-torch.utils.benchmark.examples.spectral_ops_fuzz_test"], [2211, "module-torch.utils.benchmark.op_fuzzers.binary"], [2211, "module-torch.utils.benchmark.op_fuzzers.sparse_binary"], [2211, "module-torch.utils.benchmark.op_fuzzers.sparse_unary"], [2211, "module-torch.utils.benchmark.op_fuzzers.spectral"], [2211, "module-torch.utils.benchmark.op_fuzzers.unary"], [2211, "module-torch.utils.benchmark.utils.common"], [2211, "module-torch.utils.benchmark.utils.compare"], [2211, "module-torch.utils.benchmark.utils.compile"], [2211, "module-torch.utils.benchmark.utils.cpp_jit"], [2211, "module-torch.utils.benchmark.utils.fuzzer"], [2211, "module-torch.utils.benchmark.utils.sparse_fuzzer"], [2211, "module-torch.utils.benchmark.utils.timer"], [2211, "module-torch.utils.benchmark.utils.valgrind_wrapper.timer_interface"], [2211, "module-torch.utils.bundled_inputs"], [2211, "module-torch.utils.checkpoint"], [2211, "module-torch.utils.collect_env"], [2211, "module-torch.utils.cpp_backtrace"], [2211, "module-torch.utils.cpp_extension"], [2211, "module-torch.utils.data.backward_compatibility"], [2211, "module-torch.utils.data.dataloader"], [2211, "module-torch.utils.data.datapipes.dataframe.dataframe_wrapper"], [2211, "module-torch.utils.data.datapipes.dataframe.dataframes"], [2211, "module-torch.utils.data.datapipes.dataframe.datapipes"], [2211, "module-torch.utils.data.datapipes.dataframe.structures"], [2211, "module-torch.utils.data.datapipes.datapipe"], [2211, "module-torch.utils.data.datapipes.gen_pyi"], [2211, "module-torch.utils.data.datapipes.iter.callable"], [2211, "module-torch.utils.data.datapipes.iter.combinatorics"], [2211, "module-torch.utils.data.datapipes.iter.combining"], [2211, "module-torch.utils.data.datapipes.iter.filelister"], [2211, "module-torch.utils.data.datapipes.iter.fileopener"], [2211, "module-torch.utils.data.datapipes.iter.grouping"], [2211, "module-torch.utils.data.datapipes.iter.routeddecoder"], [2211, "module-torch.utils.data.datapipes.iter.selecting"], [2211, "module-torch.utils.data.datapipes.iter.sharding"], [2211, "module-torch.utils.data.datapipes.iter.streamreader"], [2211, "module-torch.utils.data.datapipes.iter.utils"], [2211, "module-torch.utils.data.datapipes.map.callable"], [2211, "module-torch.utils.data.datapipes.map.combinatorics"], [2211, "module-torch.utils.data.datapipes.map.combining"], [2211, "module-torch.utils.data.datapipes.map.grouping"], [2211, "module-torch.utils.data.datapipes.map.utils"], [2211, "module-torch.utils.data.datapipes.utils.common"], [2211, "module-torch.utils.data.datapipes.utils.decoder"], [2211, "module-torch.utils.data.datapipes.utils.snapshot"], [2211, "module-torch.utils.data.dataset"], [2211, "module-torch.utils.data.distributed"], [2211, "module-torch.utils.data.graph"], [2211, "module-torch.utils.data.graph_settings"], [2211, "module-torch.utils.data.sampler"], [2211, "module-torch.utils.dlpack"], [2211, "module-torch.utils.file_baton"], [2211, "module-torch.utils.flop_counter"], [2211, "module-torch.utils.hipify.constants"], [2211, "module-torch.utils.hipify.cuda_to_hip_mappings"], [2211, "module-torch.utils.hipify.hipify_python"], [2211, "module-torch.utils.hipify.version"], [2211, "module-torch.utils.hooks"], [2211, "module-torch.utils.jit.log_extract"], [2211, "module-torch.utils.mkldnn"], [2211, "module-torch.utils.mobile_optimizer"], [2211, "module-torch.utils.show_pickle"], [2211, "module-torch.utils.tensorboard.summary"], [2211, "module-torch.utils.tensorboard.writer"], [2211, "module-torch.utils.throughput_benchmark"], [2211, "module-torch.utils.weak"], [2212, "module-torch.xpu"], [2212, "module-torch.xpu.memory"], [2212, "module-torch.xpu.random"], [2212, "module-torch.xpu.streams"]], "torch.accelerator": [[0, "module-torch.accelerator"]], "gradscaler (class in torch.cpu.amp)": [[1, "torch.cpu.amp.GradScaler"]], "gradscaler (class in torch.cuda.amp)": [[1, "torch.cuda.amp.GradScaler"]], "autocast (class in torch)": [[1, "torch.autocast"]], "autocast (class in torch.cpu.amp)": [[1, "torch.cpu.amp.autocast"]], "autocast (class in torch.cuda.amp)": [[1, "torch.cuda.amp.autocast"]], "custom_bwd() (in module torch.amp)": [[1, "torch.amp.custom_bwd"]], "custom_bwd() (in module torch.cuda.amp)": [[1, "torch.cuda.amp.custom_bwd"]], "custom_fwd() (in module torch.amp)": [[1, "torch.amp.custom_fwd"]], "custom_fwd() (in module torch.cuda.amp)": [[1, "torch.cuda.amp.custom_fwd"]], "is_autocast_available() (in module torch.amp.autocast_mode)": [[1, "torch.amp.autocast_mode.is_autocast_available"]], "torch.amp": [[1, "module-torch.amp"]], "torch.amp.autocast_mode": [[1, "module-torch.amp.autocast_mode"]], "torch.amp.grad_scaler": [[1, "module-torch.amp.grad_scaler"]], "torch.cpu.amp": [[1, "module-torch.cpu.amp"]], "torch.cpu.amp.autocast_mode": [[1, "module-torch.cpu.amp.autocast_mode"]], "torch.cpu.amp.grad_scaler": [[1, "module-torch.cpu.amp.grad_scaler"]], "torch.cuda.amp": [[1, "module-torch.cuda.amp"]], "torch.cuda.amp.autocast_mode": [[1, "module-torch.cuda.amp.autocast_mode"]], "torch.cuda.amp.common": [[1, "module-torch.cuda.amp.common"]], "torch.cuda.amp.grad_scaler": [[1, "module-torch.cuda.amp.grad_scaler"]], "function (class in torch.autograd)": [[2, "torch.autograd.Function"]], "gradientedge (class in torch.autograd.graph)": [[2, "torch.autograd.graph.GradientEdge"]], "allow_mutation_on_saved_tensors (class in torch.autograd.graph)": [[2, "torch.autograd.graph.allow_mutation_on_saved_tensors"]], "detect_anomaly (class in torch.autograd)": [[2, "torch.autograd.detect_anomaly"]], "disable_saved_tensors_hooks (class in torch.autograd.graph)": [[2, "torch.autograd.graph.disable_saved_tensors_hooks"]], "emit_itt (class in torch.autograd.profiler)": [[2, "torch.autograd.profiler.emit_itt"]], "emit_nvtx (class in torch.autograd.profiler)": [[2, "torch.autograd.profiler.emit_nvtx"]], "get_gradient_edge() (in module torch.autograd.graph)": [[2, "torch.autograd.graph.get_gradient_edge"]], "profile (class in torch.autograd.profiler)": [[2, "torch.autograd.profiler.profile"]], "register_multi_grad_hook (class in torch.autograd.graph)": [[2, "torch.autograd.graph.register_multi_grad_hook"]], "save_on_cpu (class in torch.autograd.graph)": [[2, "torch.autograd.graph.save_on_cpu"]], "saved_tensors_hooks (class in torch.autograd.graph)": [[2, "torch.autograd.graph.saved_tensors_hooks"]], "set_detect_anomaly (class in torch.autograd)": [[2, "torch.autograd.set_detect_anomaly"]], "torch.autograd": [[2, "module-torch.autograd"]], "torch.autograd.anomaly_mode": [[2, "module-torch.autograd.anomaly_mode"]], "torch.autograd.forward_ad": [[2, "module-torch.autograd.forward_ad"]], "torch.autograd.function": [[2, "module-torch.autograd.function"]], "torch.autograd.functional": [[2, "module-torch.autograd.functional"]], "torch.autograd.grad_mode": [[2, "module-torch.autograd.grad_mode"]], "torch.autograd.gradcheck": [[2, "module-torch.autograd.gradcheck"]], "torch.autograd.graph": [[2, "module-torch.autograd.graph"]], "torch.autograd.profiler": [[2, "module-torch.autograd.profiler"]], "torch.autograd.profiler_legacy": [[2, "module-torch.autograd.profiler_legacy"]], "torch.autograd.profiler_util": [[2, "module-torch.autograd.profiler_util"]], "torch.autograd.variable": [[2, "module-torch.autograd.variable"]], "sdpaparams (class in torch.backends.cuda)": [[3, "torch.backends.cuda.SDPAParams"]], "allow_bf16_reduced_precision_reduction (in module torch.backends.cuda.matmul)": [[3, "torch.backends.cuda.matmul.allow_bf16_reduced_precision_reduction"]], "allow_fp16_bf16_reduction_math_sdp() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.allow_fp16_bf16_reduction_math_sdp"]], "allow_fp16_reduced_precision_reduction (in module torch.backends.cuda.matmul)": [[3, "torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction"]], "allow_tf32 (in module torch.backends.cuda.matmul)": [[3, "torch.backends.cuda.matmul.allow_tf32"]], "allow_tf32 (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.allow_tf32"]], "benchmark (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.benchmark"]], "benchmark_limit (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.benchmark_limit"]], "can_use_cudnn_attention() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.can_use_cudnn_attention"]], "can_use_efficient_attention() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.can_use_efficient_attention"]], "can_use_flash_attention() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.can_use_flash_attention"]], "clear() (in module torch.backends.cuda.cufft_plan_cache)": [[3, "torch.backends.cuda.cufft_plan_cache.clear"]], "cudnn_sdp_enabled() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.cudnn_sdp_enabled"]], "cufft_plan_cache (in module torch.backends.cuda)": [[3, "torch.backends.cuda.cufft_plan_cache"]], "deterministic (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.deterministic"]], "enable_cudnn_sdp() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.enable_cudnn_sdp"]], "enable_flash_sdp() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.enable_flash_sdp"]], "enable_math_sdp() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.enable_math_sdp"]], "enable_mem_efficient_sdp() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.enable_mem_efficient_sdp"]], "enabled (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.enabled"]], "enabled (in module torch.backends.opt_einsum)": [[3, "torch.backends.opt_einsum.enabled"]], "flags() (in module torch.backends.nnpack)": [[3, "torch.backends.nnpack.flags"]], "flash_sdp_enabled() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.flash_sdp_enabled"]], "fp16_bf16_reduction_math_sdp_allowed() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.fp16_bf16_reduction_math_sdp_allowed"]], "get_cpu_capability() (in module torch.backends.cpu)": [[3, "torch.backends.cpu.get_cpu_capability"]], "get_fastpath_enabled() (in module torch.backends.mha)": [[3, "torch.backends.mha.get_fastpath_enabled"]], "get_opt_einsum() (in module torch.backends.opt_einsum)": [[3, "torch.backends.opt_einsum.get_opt_einsum"]], "is_available() (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.is_available"]], "is_available() (in module torch.backends.cusparselt)": [[3, "torch.backends.cusparselt.is_available"]], "is_available() (in module torch.backends.mkl)": [[3, "torch.backends.mkl.is_available"]], "is_available() (in module torch.backends.mkldnn)": [[3, "torch.backends.mkldnn.is_available"]], "is_available() (in module torch.backends.mps)": [[3, "torch.backends.mps.is_available"]], "is_available() (in module torch.backends.nnpack)": [[3, "torch.backends.nnpack.is_available"]], "is_available() (in module torch.backends.openmp)": [[3, "torch.backends.openmp.is_available"]], "is_available() (in module torch.backends.opt_einsum)": [[3, "torch.backends.opt_einsum.is_available"]], "is_built() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.is_built"]], "is_built() (in module torch.backends.mps)": [[3, "torch.backends.mps.is_built"]], "is_flash_attention_available() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.is_flash_attention_available"]], "math_sdp_enabled() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.math_sdp_enabled"]], "max_size (in module torch.backends.cuda.cufft_plan_cache)": [[3, "torch.backends.cuda.cufft_plan_cache.max_size"]], "mem_efficient_sdp_enabled() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.mem_efficient_sdp_enabled"]], "preferred_blas_library() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.preferred_blas_library"]], "preferred_linalg_library() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.preferred_linalg_library"]], "sdp_kernel() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.sdp_kernel"]], "set_fastpath_enabled() (in module torch.backends.mha)": [[3, "torch.backends.mha.set_fastpath_enabled"]], "set_flags() (in module torch.backends.nnpack)": [[3, "torch.backends.nnpack.set_flags"]], "size (in module torch.backends.cuda.cufft_plan_cache)": [[3, "torch.backends.cuda.cufft_plan_cache.size"]], "strategy (in module torch.backends.opt_einsum)": [[3, "torch.backends.opt_einsum.strategy"]], "torch.backends": [[3, "module-torch.backends"]], "torch.backends.cpu": [[3, "module-torch.backends.cpu"]], "torch.backends.cuda": [[3, "module-torch.backends.cuda"]], "torch.backends.cudnn": [[3, "module-torch.backends.cudnn"]], "torch.backends.cudnn.rnn": [[3, "module-torch.backends.cudnn.rnn"]], "torch.backends.cusparselt": [[3, "module-torch.backends.cusparselt"]], "torch.backends.kleidiai": [[3, "module-torch.backends.kleidiai"]], "torch.backends.mha": [[3, "module-torch.backends.mha"]], "torch.backends.mkl": [[3, "module-torch.backends.mkl"]], "torch.backends.mkldnn": [[3, "module-torch.backends.mkldnn"]], "torch.backends.mps": [[3, "module-torch.backends.mps"]], "torch.backends.nnpack": [[3, "module-torch.backends.nnpack"]], "torch.backends.openmp": [[3, "module-torch.backends.openmp"]], "torch.backends.opt_einsum": [[3, "module-torch.backends.opt_einsum"]], "torch.backends.quantized": [[3, "module-torch.backends.quantized"]], "torch.backends.xeon": [[3, "module-torch.backends.xeon"]], "torch.backends.xeon.run_cpu": [[3, "module-torch.backends.xeon.run_cpu"]], "torch.backends.xnnpack": [[3, "module-torch.backends.xnnpack"]], "verbose (class in torch.backends.mkl)": [[3, "torch.backends.mkl.verbose"]], "verbose (class in torch.backends.mkldnn)": [[3, "torch.backends.mkldnn.verbose"]], "version() (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.version"]], "version() (in module torch.backends.cusparselt)": [[3, "torch.backends.cusparselt.version"]], "callgrindstats (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.CallgrindStats"]], "compare (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.Compare"]], "functioncounts (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.FunctionCounts"]], "measurement (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.Measurement"]], "timer (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.Timer"]], "adaptive_autorange() (torch.utils.benchmark.timer method)": [[4, "torch.utils.benchmark.Timer.adaptive_autorange"]], "as_standardized() (torch.utils.benchmark.callgrindstats method)": [[4, "torch.utils.benchmark.CallgrindStats.as_standardized"]], "blocked_autorange() (torch.utils.benchmark.timer method)": [[4, "torch.utils.benchmark.Timer.blocked_autorange"]], "collect_callgrind() (torch.utils.benchmark.timer method)": [[4, "torch.utils.benchmark.Timer.collect_callgrind"]], "colorize() (torch.utils.benchmark.compare method)": [[4, "torch.utils.benchmark.Compare.colorize"]], "counts() (torch.utils.benchmark.callgrindstats method)": [[4, "torch.utils.benchmark.CallgrindStats.counts"]], "delta() (torch.utils.benchmark.callgrindstats method)": [[4, "torch.utils.benchmark.CallgrindStats.delta"]], "denoise() (torch.utils.benchmark.functioncounts method)": [[4, "torch.utils.benchmark.FunctionCounts.denoise"]], "extend_results() (torch.utils.benchmark.compare method)": [[4, "torch.utils.benchmark.Compare.extend_results"]], "filter() (torch.utils.benchmark.functioncounts method)": [[4, "torch.utils.benchmark.FunctionCounts.filter"]], "highlight_warnings() (torch.utils.benchmark.compare method)": [[4, "torch.utils.benchmark.Compare.highlight_warnings"]], "merge() (torch.utils.benchmark.measurement static method)": [[4, "torch.utils.benchmark.Measurement.merge"]], "print() (torch.utils.benchmark.compare method)": [[4, "torch.utils.benchmark.Compare.print"]], "significant_figures (torch.utils.benchmark.measurement property)": [[4, "torch.utils.benchmark.Measurement.significant_figures"]], "stats() (torch.utils.benchmark.callgrindstats method)": [[4, "torch.utils.benchmark.CallgrindStats.stats"]], "timeit() (torch.utils.benchmark.timer method)": [[4, "torch.utils.benchmark.Timer.timeit"]], "torch.utils.benchmark": [[4, "module-torch.utils.benchmark"]], "torch.utils.benchmark.examples": [[4, "module-torch.utils.benchmark.examples"]], "torch.utils.benchmark.op_fuzzers": [[4, "module-torch.utils.benchmark.op_fuzzers"]], "torch.utils.benchmark.utils": [[4, "module-torch.utils.benchmark.utils"]], "torch.utils.benchmark.utils.valgrind_wrapper": [[4, "module-torch.utils.benchmark.utils.valgrind_wrapper"]], "transform() (torch.utils.benchmark.functioncounts method)": [[4, "torch.utils.benchmark.FunctionCounts.transform"]], "trim_significant_figures() (torch.utils.benchmark.compare method)": [[4, "torch.utils.benchmark.Compare.trim_significant_figures"]], "torch.utils.bottleneck": [[5, "module-torch.utils.bottleneck"]], "checkpointpolicy (class in torch.utils.checkpoint)": [[6, "torch.utils.checkpoint.CheckpointPolicy"]], "selectivecheckpointcontext (class in torch.utils.checkpoint)": [[6, "torch.utils.checkpoint.SelectiveCheckpointContext"]], "checkpoint() (in module torch.utils.checkpoint)": [[6, "torch.utils.checkpoint.checkpoint"]], "checkpoint_sequential() (in module torch.utils.checkpoint)": [[6, "torch.utils.checkpoint.checkpoint_sequential"]], "create_selective_checkpoint_contexts() (in module torch.utils.checkpoint)": [[6, "torch.utils.checkpoint.create_selective_checkpoint_contexts"]], "set_checkpoint_debug_enabled() (in module torch.utils.checkpoint)": [[6, "torch.utils.checkpoint.set_checkpoint_debug_enabled"]], "cond() (in module torch._higher_order_ops.cond)": [[14, "torch._higher_order_ops.cond.cond"]], "parallel_info() (in module torch.__config__)": [[15, "torch.__config__.parallel_info"]], "show() (in module torch.__config__)": [[15, "torch.__config__.show"]], "torch.__config__": [[15, "module-torch.__config__"]], "buildextension() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.BuildExtension"]], "cudaextension() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.CUDAExtension"]], "cppextension() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.CppExtension"]], "get_compiler_abi_compatibility_and_version() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.get_compiler_abi_compatibility_and_version"]], "include_paths() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.include_paths"]], "is_ninja_available() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.is_ninja_available"]], "load() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.load"]], "load_inline() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.load_inline"]], "verify_ninja_availability() (in module torch.utils.cpp_extension)": [[16, "torch.utils.cpp_extension.verify_ninja_availability"]], "torch.cpu": [[18, "module-torch.cpu"]], "torch.cuda": [[19, "module-torch.cuda"]], "torch.cuda.comm": [[19, "module-torch.cuda.comm"]], "torch.cuda.error": [[19, "module-torch.cuda.error"]], "torch.cuda.gds": [[19, "module-torch.cuda.gds"]], "torch.cuda.graphs": [[19, "module-torch.cuda.graphs"]], "torch.cuda.jiterator": [[19, "module-torch.cuda.jiterator"]], "torch.cuda.memory": [[19, "module-torch.cuda.memory"]], "torch.cuda.nccl": [[19, "module-torch.cuda.nccl"]], "torch.cuda.nvtx": [[19, "module-torch.cuda.nvtx"]], "torch.cuda.profiler": [[19, "module-torch.cuda.profiler"]], "torch.cuda.random": [[19, "module-torch.cuda.random"]], "torch.cuda.sparse": [[19, "module-torch.cuda.sparse"]], "torch.cuda.streams": [[19, "module-torch.cuda.streams"]], "use_mem_pool (class in torch.cuda)": [[19, "torch.cuda.use_mem_pool"]], "enable_cuda_sanitizer() (in module torch.cuda._sanitizer)": [[20, "torch.cuda._sanitizer.enable_cuda_sanitizer"]], "torch.cuda._sanitizer": [[20, "module-torch.cuda._sanitizer"]], "enable() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.enable"]], "get_filename() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.get_filename"]], "get_max_tuning_duration() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.get_max_tuning_duration"]], "get_max_tuning_iterations() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.get_max_tuning_iterations"]], "get_results() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.get_results"]], "get_validators() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.get_validators"]], "is_enabled() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.is_enabled"]], "mgpu_tune_gemm_in_file() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.mgpu_tune_gemm_in_file"]], "read_file() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.read_file"]], "record_untuned_enable() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.record_untuned_enable"]], "record_untuned_is_enabled() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.record_untuned_is_enabled"]], "set_filename() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.set_filename"]], "set_max_tuning_duration() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.set_max_tuning_duration"]], "set_max_tuning_iterations() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.set_max_tuning_iterations"]], "torch.cuda.tunable": [[21, "module-torch.cuda.tunable"]], "tune_gemm_in_file() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.tune_gemm_in_file"]], "tuning_enable() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.tuning_enable"]], "tuning_is_enabled() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.tuning_is_enabled"]], "write_file() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.write_file"]], "write_file_on_exit() (in module torch.cuda.tunable)": [[21, "torch.cuda.tunable.write_file_on_exit"]], "batchsampler (class in torch.utils.data)": [[25, "torch.utils.data.BatchSampler"]], "chaindataset (class in torch.utils.data)": [[25, "torch.utils.data.ChainDataset"]], "concatdataset (class in torch.utils.data)": [[25, "torch.utils.data.ConcatDataset"]], "dataloader (class in torch.utils.data)": [[25, "torch.utils.data.DataLoader"]], "dataset (class in torch.utils.data)": [[25, "torch.utils.data.Dataset"]], "distributedsampler (class in torch.utils.data.distributed)": [[25, "torch.utils.data.distributed.DistributedSampler"]], "iterabledataset (class in torch.utils.data)": [[25, "torch.utils.data.IterableDataset"]], "randomsampler (class in torch.utils.data)": [[25, "torch.utils.data.RandomSampler"]], "sampler (class in torch.utils.data)": [[25, "torch.utils.data.Sampler"]], "sequentialsampler (class in torch.utils.data)": [[25, "torch.utils.data.SequentialSampler"]], "stackdataset (class in torch.utils.data)": [[25, "torch.utils.data.StackDataset"]], "subset (class in torch.utils.data)": [[25, "torch.utils.data.Subset"]], "subsetrandomsampler (class in torch.utils.data)": [[25, "torch.utils.data.SubsetRandomSampler"]], "tensordataset (class in torch.utils.data)": [[25, "torch.utils.data.TensorDataset"]], "weightedrandomsampler (class in torch.utils.data)": [[25, "torch.utils.data.WeightedRandomSampler"]], "collate() (in module torch.utils.data._utils.collate)": [[25, "torch.utils.data._utils.collate.collate"]], "default_collate() (in module torch.utils.data)": [[25, "torch.utils.data.default_collate"]], "default_convert() (in module torch.utils.data)": [[25, "torch.utils.data.default_convert"]], "get_worker_info() (in module torch.utils.data)": [[25, "torch.utils.data.get_worker_info"]], "random_split() (in module torch.utils.data)": [[25, "torch.utils.data.random_split"]], "torch.utils.data": [[25, "module-torch.utils.data"]], "torch.utils.data.datapipes": [[25, "module-torch.utils.data.datapipes"]], "torch.utils.data.datapipes.dataframe": [[25, "module-torch.utils.data.datapipes.dataframe"]], "torch.utils.data.datapipes.iter": [[25, "module-torch.utils.data.datapipes.iter"]], "torch.utils.data.datapipes.map": [[25, "module-torch.utils.data.datapipes.map"]], "torch.utils.data.datapipes.utils": [[25, "module-torch.utils.data.datapipes.utils"]], "gradbucket (class in torch.distributed)": [[26, "torch.distributed.GradBucket"]], "powersgdstate (class in torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState"]], "__getstate__() (torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook.powersgdstate method)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState.__getstate__"]], "__setstate__() (torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook.powersgdstate method)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState.__setstate__"]], "allreduce_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.allreduce_hook"]], "batched_powersgd_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.batched_powerSGD_hook"]], "bf16_compress_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_hook"]], "bf16_compress_wrapper() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_wrapper"]], "buffer() (in module torch.distributed.gradbucket)": [[26, "torch.distributed.GradBucket.buffer"]], "fp16_compress_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_hook"]], "fp16_compress_wrapper() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_wrapper"]], "gradients() (in module torch.distributed.gradbucket)": [[26, "torch.distributed.GradBucket.gradients"]], "index() (in module torch.distributed.gradbucket)": [[26, "torch.distributed.GradBucket.index"]], "is_last() (in module torch.distributed.gradbucket)": [[26, "torch.distributed.GradBucket.is_last"]], "noop_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks.noop_hook"]], "parameters() (in module torch.distributed.gradbucket)": [[26, "torch.distributed.GradBucket.parameters"]], "powersgd_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook)": [[26, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.powerSGD_hook"]], "set_buffer() (in module torch.distributed.gradbucket)": [[26, "torch.distributed.GradBucket.set_buffer"]], "fill_uninitialized_memory (in module torch.utils.deterministic)": [[29, "torch.utils.deterministic.fill_uninitialized_memory"]], "torch.utils.deterministic": [[29, "module-torch.utils.deterministic"]], "backend (class in torch.distributed)": [[30, "torch.distributed.Backend"]], "devicemesh (class in torch.distributed.device_mesh)": [[30, "torch.distributed.device_mesh.DeviceMesh"]], "distbackenderror (class in torch.distributed)": [[30, "torch.distributed.DistBackendError"]], "disterror (class in torch.distributed)": [[30, "torch.distributed.DistError"]], "distnetworkerror (class in torch.distributed)": [[30, "torch.distributed.DistNetworkError"]], "diststoreerror (class in torch.distributed)": [[30, "torch.distributed.DistStoreError"]], "filestore (class in torch.distributed)": [[30, "torch.distributed.FileStore"]], "hashstore (class in torch.distributed)": [[30, "torch.distributed.HashStore"]], "p2pop (class in torch.distributed)": [[30, "torch.distributed.P2POp"]], "prefixstore (class in torch.distributed)": [[30, "torch.distributed.PrefixStore"]], "reduceop (class in torch.distributed)": [[30, "torch.distributed.ReduceOp"]], "store (class in torch.distributed)": [[30, "torch.distributed.Store"]], "tcpstore (class in torch.distributed)": [[30, "torch.distributed.TCPStore"]], "work (class in torch.distributed)": [[30, "torch.distributed.Work"]], "__init__() (torch.distributed.filestore method)": [[30, "torch.distributed.FileStore.__init__"]], "__init__() (torch.distributed.hashstore method)": [[30, "torch.distributed.HashStore.__init__"]], "__init__() (torch.distributed.prefixstore method)": [[30, "torch.distributed.PrefixStore.__init__"]], "__init__() (torch.distributed.store method)": [[30, "torch.distributed.Store.__init__"]], "__init__() (torch.distributed.tcpstore method)": [[30, "torch.distributed.TCPStore.__init__"]], "add() (torch.distributed.store method)": [[30, "torch.distributed.Store.add"]], "all_gather() (in module torch.distributed)": [[30, "torch.distributed.all_gather"]], "all_gather_into_tensor() (in module torch.distributed)": [[30, "torch.distributed.all_gather_into_tensor"]], "all_gather_object() (in module torch.distributed)": [[30, "torch.distributed.all_gather_object"]], "all_reduce() (in module torch.distributed)": [[30, "torch.distributed.all_reduce"]], "all_to_all() (in module torch.distributed)": [[30, "torch.distributed.all_to_all"]], "all_to_all_single() (in module torch.distributed)": [[30, "torch.distributed.all_to_all_single"]], "append() (torch.distributed.store method)": [[30, "torch.distributed.Store.append"]], "barrier() (in module torch.distributed)": [[30, "torch.distributed.barrier"]], "batch_isend_irecv() (in module torch.distributed)": [[30, "torch.distributed.batch_isend_irecv"]], "boxed() (torch.distributed.work method)": [[30, "torch.distributed.Work.boxed"]], "breakpoint() (in module torch.distributed)": [[30, "torch.distributed.breakpoint"]], "broadcast() (in module torch.distributed)": [[30, "torch.distributed.broadcast"]], "broadcast_object_list() (in module torch.distributed)": [[30, "torch.distributed.broadcast_object_list"]], "check() (torch.distributed.store method)": [[30, "torch.distributed.Store.check"]], "compare_set() (torch.distributed.store method)": [[30, "torch.distributed.Store.compare_set"]], "delete_key() (torch.distributed.store method)": [[30, "torch.distributed.Store.delete_key"]], "exception() (torch.distributed.work method)": [[30, "torch.distributed.Work.exception"]], "from_group() (torch.distributed.device_mesh.devicemesh static method)": [[30, "torch.distributed.device_mesh.DeviceMesh.from_group"]], "gather() (in module torch.distributed)": [[30, "torch.distributed.gather"]], "gather_object() (in module torch.distributed)": [[30, "torch.distributed.gather_object"]], "get() (torch.distributed.store method)": [[30, "torch.distributed.Store.get"]], "get_all_groups() (torch.distributed.device_mesh.devicemesh method)": [[30, "torch.distributed.device_mesh.DeviceMesh.get_all_groups"]], "get_backend() (in module torch.distributed)": [[30, "torch.distributed.get_backend"]], "get_coordinate() (torch.distributed.device_mesh.devicemesh method)": [[30, "torch.distributed.device_mesh.DeviceMesh.get_coordinate"]], "get_future() (torch.distributed.work method)": [[30, "torch.distributed.Work.get_future"]], "get_future_result() (torch.distributed.work method)": [[30, "torch.distributed.Work.get_future_result"]], "get_global_rank() (in module torch.distributed)": [[30, "torch.distributed.get_global_rank"]], "get_group() (torch.distributed.device_mesh.devicemesh method)": [[30, "torch.distributed.device_mesh.DeviceMesh.get_group"]], "get_group_rank() (in module torch.distributed)": [[30, "torch.distributed.get_group_rank"]], "get_local_rank() (torch.distributed.device_mesh.devicemesh method)": [[30, "torch.distributed.device_mesh.DeviceMesh.get_local_rank"]], "get_process_group_ranks() (in module torch.distributed)": [[30, "torch.distributed.get_process_group_ranks"]], "get_rank() (in module torch.distributed)": [[30, "torch.distributed.get_rank"]], "get_rank() (torch.distributed.device_mesh.devicemesh method)": [[30, "torch.distributed.device_mesh.DeviceMesh.get_rank"]], "get_world_size() (in module torch.distributed)": [[30, "torch.distributed.get_world_size"]], "has_extended_api() (torch.distributed.store method)": [[30, "torch.distributed.Store.has_extended_api"]], "host (torch.distributed.tcpstore property)": [[30, "torch.distributed.TCPStore.host"]], "init_device_mesh() (in module torch.distributed.device_mesh)": [[30, "torch.distributed.device_mesh.init_device_mesh"]], "init_process_group() (in module torch.distributed)": [[30, "torch.distributed.init_process_group"]], "irecv() (in module torch.distributed)": [[30, "torch.distributed.irecv"]], "is_available() (in module torch.distributed)": [[30, "torch.distributed.is_available"]], "is_completed() (torch.distributed.work method)": [[30, "torch.distributed.Work.is_completed"]], "is_gloo_available() (in module torch.distributed)": [[30, "torch.distributed.is_gloo_available"]], "is_initialized() (in module torch.distributed)": [[30, "torch.distributed.is_initialized"]], "is_mpi_available() (in module torch.distributed)": [[30, "torch.distributed.is_mpi_available"]], "is_nccl_available() (in module torch.distributed)": [[30, "torch.distributed.is_nccl_available"]], "is_success() (torch.distributed.work method)": [[30, "torch.distributed.Work.is_success"]], "is_torchelastic_launched() (in module torch.distributed)": [[30, "torch.distributed.is_torchelastic_launched"]], "is_xccl_available() (in module torch.distributed.distributed_c10d)": [[30, "torch.distributed.distributed_c10d.is_xccl_available"]], "isend() (in module torch.distributed)": [[30, "torch.distributed.isend"]], "libuvbackend (torch.distributed.tcpstore property)": [[30, "torch.distributed.TCPStore.libuvBackend"]], "monitored_barrier() (in module torch.distributed)": [[30, "torch.distributed.monitored_barrier"]], "multi_get() (torch.distributed.store method)": [[30, "torch.distributed.Store.multi_get"]], "multi_set() (torch.distributed.store method)": [[30, "torch.distributed.Store.multi_set"]], "new_group() (in module torch.distributed)": [[30, "torch.distributed.new_group"]], "num_keys() (torch.distributed.store method)": [[30, "torch.distributed.Store.num_keys"]], "path (torch.distributed.filestore property)": [[30, "torch.distributed.FileStore.path"]], "port (torch.distributed.tcpstore property)": [[30, "torch.distributed.TCPStore.port"]], "recv() (in module torch.distributed)": [[30, "torch.distributed.recv"]], "recv_object_list() (in module torch.distributed)": [[30, "torch.distributed.recv_object_list"]], "reduce() (in module torch.distributed)": [[30, "torch.distributed.reduce"]], "reduce_op (class in torch.distributed)": [[30, "torch.distributed.reduce_op"]], "reduce_scatter() (in module torch.distributed)": [[30, "torch.distributed.reduce_scatter"]], "reduce_scatter_tensor() (in module torch.distributed)": [[30, "torch.distributed.reduce_scatter_tensor"]], "register_backend() (torch.distributed.backend class method)": [[30, "torch.distributed.Backend.register_backend"]], "result() (torch.distributed.work method)": [[30, "torch.distributed.Work.result"]], "scatter() (in module torch.distributed)": [[30, "torch.distributed.scatter"]], "scatter_object_list() (in module torch.distributed)": [[30, "torch.distributed.scatter_object_list"]], "send() (in module torch.distributed)": [[30, "torch.distributed.send"]], "send_object_list() (in module torch.distributed)": [[30, "torch.distributed.send_object_list"]], "set() (torch.distributed.store method)": [[30, "torch.distributed.Store.set"]], "set_timeout() (torch.distributed.store method)": [[30, "torch.distributed.Store.set_timeout"]], "source_rank() (torch.distributed.work method)": [[30, "torch.distributed.Work.source_rank"]], "synchronize() (torch.distributed.work method)": [[30, "torch.distributed.Work.synchronize"]], "timeout (torch.distributed.store property)": [[30, "torch.distributed.Store.timeout"]], "torch.distributed": [[30, "module-torch.distributed"]], "torch.distributed.algorithms": [[30, "module-torch.distributed.algorithms"]], "torch.distributed.algorithms.ddp_comm_hooks": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks"]], "torch.distributed.algorithms.ddp_comm_hooks.ddp_zero_hook": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks.ddp_zero_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks"]], "torch.distributed.algorithms.ddp_comm_hooks.default_hooks": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks.default_hooks"]], "torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks"]], "torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks"]], "torch.distributed.algorithms.ddp_comm_hooks.post_localsgd_hook": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks.post_localSGD_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks": [[30, "module-torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks"]], "torch.distributed.algorithms.join": [[30, "module-torch.distributed.algorithms.join"]], "torch.distributed.algorithms.model_averaging": [[30, "module-torch.distributed.algorithms.model_averaging"]], "torch.distributed.algorithms.model_averaging.averagers": [[30, "module-torch.distributed.algorithms.model_averaging.averagers"]], "torch.distributed.algorithms.model_averaging.hierarchical_model_averager": [[30, "module-torch.distributed.algorithms.model_averaging.hierarchical_model_averager"]], "torch.distributed.algorithms.model_averaging.utils": [[30, "module-torch.distributed.algorithms.model_averaging.utils"]], "torch.distributed.argparse_util": [[30, "module-torch.distributed.argparse_util"]], "torch.distributed.c10d_logger": [[30, "module-torch.distributed.c10d_logger"]], "torch.distributed.checkpoint.api": [[30, "module-torch.distributed.checkpoint.api"]], "torch.distributed.checkpoint.default_planner": [[30, "module-torch.distributed.checkpoint.default_planner"]], "torch.distributed.checkpoint.filesystem": [[30, "module-torch.distributed.checkpoint.filesystem"]], "torch.distributed.checkpoint.metadata": [[30, "module-torch.distributed.checkpoint.metadata"]], "torch.distributed.checkpoint.optimizer": [[30, "module-torch.distributed.checkpoint.optimizer"]], "torch.distributed.checkpoint.planner": [[30, "module-torch.distributed.checkpoint.planner"]], "torch.distributed.checkpoint.planner_helpers": [[30, "module-torch.distributed.checkpoint.planner_helpers"]], "torch.distributed.checkpoint.resharding": [[30, "module-torch.distributed.checkpoint.resharding"]], "torch.distributed.checkpoint.state_dict": [[30, "module-torch.distributed.checkpoint.state_dict"]], "torch.distributed.checkpoint.state_dict_loader": [[30, "module-torch.distributed.checkpoint.state_dict_loader"]], "torch.distributed.checkpoint.state_dict_saver": [[30, "module-torch.distributed.checkpoint.state_dict_saver"]], "torch.distributed.checkpoint.stateful": [[30, "module-torch.distributed.checkpoint.stateful"]], "torch.distributed.checkpoint.storage": [[30, "module-torch.distributed.checkpoint.storage"]], "torch.distributed.checkpoint.utils": [[30, "module-torch.distributed.checkpoint.utils"]], "torch.distributed.collective_utils": [[30, "module-torch.distributed.collective_utils"]], "torch.distributed.constants": [[30, "module-torch.distributed.constants"]], "torch.distributed.device_mesh": [[30, "module-torch.distributed.device_mesh"]], "torch.distributed.distributed_c10d": [[30, "module-torch.distributed.distributed_c10d"]], "torch.distributed.elastic": [[30, "module-torch.distributed.elastic"]], "torch.distributed.elastic.agent.server.api": [[30, "module-torch.distributed.elastic.agent.server.api"]], "torch.distributed.elastic.agent.server.local_elastic_agent": [[30, "module-torch.distributed.elastic.agent.server.local_elastic_agent"]], "torch.distributed.elastic.events.api": [[30, "module-torch.distributed.elastic.events.api"]], "torch.distributed.elastic.events.handlers": [[30, "module-torch.distributed.elastic.events.handlers"]], "torch.distributed.elastic.metrics.api": [[30, "module-torch.distributed.elastic.metrics.api"]], "torch.distributed.elastic.multiprocessing.api": [[30, "module-torch.distributed.elastic.multiprocessing.api"]], "torch.distributed.elastic.multiprocessing.errors.error_handler": [[30, "module-torch.distributed.elastic.multiprocessing.errors.error_handler"]], "torch.distributed.elastic.multiprocessing.errors.handlers": [[30, "module-torch.distributed.elastic.multiprocessing.errors.handlers"]], "torch.distributed.elastic.multiprocessing.redirects": [[30, "module-torch.distributed.elastic.multiprocessing.redirects"]], "torch.distributed.elastic.multiprocessing.tail_log": [[30, "module-torch.distributed.elastic.multiprocessing.tail_log"]], "torch.distributed.elastic.rendezvous.api": [[30, "module-torch.distributed.elastic.rendezvous.api"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend": [[30, "module-torch.distributed.elastic.rendezvous.c10d_rendezvous_backend"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous": [[30, "module-torch.distributed.elastic.rendezvous.dynamic_rendezvous"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous": [[30, "module-torch.distributed.elastic.rendezvous.etcd_rendezvous"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend": [[30, "module-torch.distributed.elastic.rendezvous.etcd_rendezvous_backend"]], "torch.distributed.elastic.rendezvous.etcd_server": [[30, "module-torch.distributed.elastic.rendezvous.etcd_server"]], "torch.distributed.elastic.rendezvous.etcd_store": [[30, "module-torch.distributed.elastic.rendezvous.etcd_store"]], "torch.distributed.elastic.rendezvous.static_tcp_rendezvous": [[30, "module-torch.distributed.elastic.rendezvous.static_tcp_rendezvous"]], "torch.distributed.elastic.rendezvous.utils": [[30, "module-torch.distributed.elastic.rendezvous.utils"]], "torch.distributed.elastic.timer.api": [[30, "module-torch.distributed.elastic.timer.api"]], "torch.distributed.elastic.timer.file_based_local_timer": [[30, "module-torch.distributed.elastic.timer.file_based_local_timer"]], "torch.distributed.elastic.timer.local_timer": [[30, "module-torch.distributed.elastic.timer.local_timer"]], "torch.distributed.elastic.utils": [[30, "module-torch.distributed.elastic.utils"]], "torch.distributed.elastic.utils.api": [[30, "module-torch.distributed.elastic.utils.api"]], "torch.distributed.elastic.utils.data": [[30, "module-torch.distributed.elastic.utils.data"]], "torch.distributed.elastic.utils.data.cycling_iterator": [[30, "module-torch.distributed.elastic.utils.data.cycling_iterator"]], "torch.distributed.elastic.utils.data.elastic_distributed_sampler": [[30, "module-torch.distributed.elastic.utils.data.elastic_distributed_sampler"]], "torch.distributed.elastic.utils.distributed": [[30, "module-torch.distributed.elastic.utils.distributed"]], "torch.distributed.elastic.utils.log_level": [[30, "module-torch.distributed.elastic.utils.log_level"]], "torch.distributed.elastic.utils.logging": [[30, "module-torch.distributed.elastic.utils.logging"]], "torch.distributed.elastic.utils.store": [[30, "module-torch.distributed.elastic.utils.store"]], "torch.distributed.fsdp.api": [[30, "module-torch.distributed.fsdp.api"]], "torch.distributed.fsdp.fully_sharded_data_parallel": [[30, "module-torch.distributed.fsdp.fully_sharded_data_parallel"]], "torch.distributed.fsdp.sharded_grad_scaler": [[30, "module-torch.distributed.fsdp.sharded_grad_scaler"]], "torch.distributed.fsdp.wrap": [[30, "module-torch.distributed.fsdp.wrap"]], "torch.distributed.launch": [[30, "module-torch.distributed.launch"]], "torch.distributed.launcher": [[30, "module-torch.distributed.launcher"]], "torch.distributed.launcher.api": [[30, "module-torch.distributed.launcher.api"]], "torch.distributed.logging_handlers": [[30, "module-torch.distributed.logging_handlers"]], "torch.distributed.nn": [[30, "module-torch.distributed.nn"]], "torch.distributed.nn.api": [[30, "module-torch.distributed.nn.api"]], "torch.distributed.nn.api.remote_module": [[30, "module-torch.distributed.nn.api.remote_module"]], "torch.distributed.nn.functional": [[30, "module-torch.distributed.nn.functional"]], "torch.distributed.nn.jit": [[30, "module-torch.distributed.nn.jit"]], "torch.distributed.nn.jit.instantiator": [[30, "module-torch.distributed.nn.jit.instantiator"]], "torch.distributed.nn.jit.templates": [[30, "module-torch.distributed.nn.jit.templates"]], "torch.distributed.nn.jit.templates.remote_module_template": [[30, "module-torch.distributed.nn.jit.templates.remote_module_template"]], "torch.distributed.optim.apply_optimizer_in_backward": [[30, "module-torch.distributed.optim.apply_optimizer_in_backward"]], "torch.distributed.optim.functional_adadelta": [[30, "module-torch.distributed.optim.functional_adadelta"]], "torch.distributed.optim.functional_adagrad": [[30, "module-torch.distributed.optim.functional_adagrad"]], "torch.distributed.optim.functional_adam": [[30, "module-torch.distributed.optim.functional_adam"]], "torch.distributed.optim.functional_adamax": [[30, "module-torch.distributed.optim.functional_adamax"]], "torch.distributed.optim.functional_adamw": [[30, "module-torch.distributed.optim.functional_adamw"]], "torch.distributed.optim.functional_rmsprop": [[30, "module-torch.distributed.optim.functional_rmsprop"]], "torch.distributed.optim.functional_rprop": [[30, "module-torch.distributed.optim.functional_rprop"]], "torch.distributed.optim.functional_sgd": [[30, "module-torch.distributed.optim.functional_sgd"]], "torch.distributed.optim.named_optimizer": [[30, "module-torch.distributed.optim.named_optimizer"]], "torch.distributed.optim.optimizer": [[30, "module-torch.distributed.optim.optimizer"]], "torch.distributed.optim.post_localsgd_optimizer": [[30, "module-torch.distributed.optim.post_localSGD_optimizer"]], "torch.distributed.optim.utils": [[30, "module-torch.distributed.optim.utils"]], "torch.distributed.optim.zero_redundancy_optimizer": [[30, "module-torch.distributed.optim.zero_redundancy_optimizer"]], "torch.distributed.remote_device": [[30, "module-torch.distributed.remote_device"]], "torch.distributed.rendezvous": [[30, "module-torch.distributed.rendezvous"]], "torch.distributed.rpc.api": [[30, "module-torch.distributed.rpc.api"]], "torch.distributed.rpc.backend_registry": [[30, "module-torch.distributed.rpc.backend_registry"]], "torch.distributed.rpc.constants": [[30, "module-torch.distributed.rpc.constants"]], "torch.distributed.rpc.functions": [[30, "module-torch.distributed.rpc.functions"]], "torch.distributed.rpc.internal": [[30, "module-torch.distributed.rpc.internal"]], "torch.distributed.rpc.options": [[30, "module-torch.distributed.rpc.options"]], "torch.distributed.rpc.rref_proxy": [[30, "module-torch.distributed.rpc.rref_proxy"]], "torch.distributed.rpc.server_process_global_profiler": [[30, "module-torch.distributed.rpc.server_process_global_profiler"]], "torch.distributed.tensor.parallel.api": [[30, "module-torch.distributed.tensor.parallel.api"]], "torch.distributed.tensor.parallel.ddp": [[30, "module-torch.distributed.tensor.parallel.ddp"]], "torch.distributed.tensor.parallel.fsdp": [[30, "module-torch.distributed.tensor.parallel.fsdp"]], "torch.distributed.tensor.parallel.input_reshard": [[30, "module-torch.distributed.tensor.parallel.input_reshard"]], "torch.distributed.tensor.parallel.loss": [[30, "module-torch.distributed.tensor.parallel.loss"]], "torch.distributed.tensor.parallel.style": [[30, "module-torch.distributed.tensor.parallel.style"]], "torch.distributed.utils": [[30, "module-torch.distributed.utils"]], "unbox() (torch.distributed.work static method)": [[30, "torch.distributed.Work.unbox"]], "underlying_store (torch.distributed.prefixstore property)": [[30, "torch.distributed.PrefixStore.underlying_store"]], "wait() (torch.distributed.store method)": [[30, "torch.distributed.Store.wait"]], "wait() (torch.distributed.work method)": [[30, "torch.distributed.Work.wait"]], "join (class in torch.distributed.algorithms)": [[31, "torch.distributed.algorithms.Join"]], "joinhook (class in torch.distributed.algorithms)": [[31, "torch.distributed.algorithms.JoinHook"]], "joinable (class in torch.distributed.algorithms)": [[31, "torch.distributed.algorithms.Joinable"]], "join_device (torch.distributed.algorithms.joinable property)": [[31, "torch.distributed.algorithms.Joinable.join_device"]], "join_hook() (torch.distributed.algorithms.joinable method)": [[31, "torch.distributed.algorithms.Joinable.join_hook"]], "join_process_group (torch.distributed.algorithms.joinable property)": [[31, "torch.distributed.algorithms.Joinable.join_process_group"]], "main_hook() (torch.distributed.algorithms.joinhook method)": [[31, "torch.distributed.algorithms.JoinHook.main_hook"]], "notify_join_context() (torch.distributed.algorithms.join static method)": [[31, "torch.distributed.algorithms.Join.notify_join_context"]], "post_hook() (torch.distributed.algorithms.joinhook method)": [[31, "torch.distributed.algorithms.JoinHook.post_hook"]], "asyncstager (class in torch.distributed.checkpoint.staging)": [[32, "torch.distributed.checkpoint.staging.AsyncStager"]], "blockingasyncstager (class in torch.distributed.checkpoint.staging)": [[32, "torch.distributed.checkpoint.staging.BlockingAsyncStager"]], "broadcastingtorchsavereader (class in torch.distributed.checkpoint.format_utils)": [[32, "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader"]], "defaultloadplanner (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.DefaultLoadPlanner"]], "defaultsaveplanner (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.DefaultSavePlanner"]], "dynamicmetaloadplanner (class in torch.distributed.checkpoint.format_utils)": [[32, "torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner"]], "filesystemreader (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.FileSystemReader"]], "filesystemwriter (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.FileSystemWriter"]], "loadplan (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.LoadPlan"]], "loadplanner (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.LoadPlanner"]], "readitem (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.ReadItem"]], "saveplan (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.SavePlan"]], "saveplanner (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.SavePlanner"]], "statedictoptions (class in torch.distributed.checkpoint.state_dict)": [[32, "torch.distributed.checkpoint.state_dict.StateDictOptions"]], "stateful (class in torch.distributed.checkpoint.stateful)": [[32, "torch.distributed.checkpoint.stateful.Stateful"]], "storagereader (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.StorageReader"]], "storagewriter (class in torch.distributed.checkpoint)": [[32, "torch.distributed.checkpoint.StorageWriter"]], "writeitem (class in torch.distributed.checkpoint.planner)": [[32, "torch.distributed.checkpoint.planner.WriteItem"]], "async_save() (in module torch.distributed.checkpoint.state_dict_saver)": [[32, "torch.distributed.checkpoint.state_dict_saver.async_save"]], "checkpoint_id (torch.distributed.checkpoint.filesystemreader property)": [[32, "torch.distributed.checkpoint.FileSystemReader.checkpoint_id"]], "commit_tensor() (torch.distributed.checkpoint.loadplanner method)": [[32, "torch.distributed.checkpoint.LoadPlanner.commit_tensor"]], "create_global_plan() (torch.distributed.checkpoint.loadplanner method)": [[32, "torch.distributed.checkpoint.LoadPlanner.create_global_plan"]], "create_global_plan() (torch.distributed.checkpoint.saveplanner method)": [[32, "torch.distributed.checkpoint.SavePlanner.create_global_plan"]], "create_local_plan() (torch.distributed.checkpoint.loadplanner method)": [[32, "torch.distributed.checkpoint.LoadPlanner.create_local_plan"]], "create_local_plan() (torch.distributed.checkpoint.saveplanner method)": [[32, "torch.distributed.checkpoint.SavePlanner.create_local_plan"]], "dcp_to_torch_save() (in module torch.distributed.checkpoint.format_utils)": [[32, "torch.distributed.checkpoint.format_utils.dcp_to_torch_save"]], "finish() (torch.distributed.checkpoint.storagewriter method)": [[32, "torch.distributed.checkpoint.StorageWriter.finish"]], "finish_plan() (torch.distributed.checkpoint.loadplanner method)": [[32, "torch.distributed.checkpoint.LoadPlanner.finish_plan"]], "finish_plan() (torch.distributed.checkpoint.saveplanner method)": [[32, "torch.distributed.checkpoint.SavePlanner.finish_plan"]], "get_model_state_dict() (in module torch.distributed.checkpoint.state_dict)": [[32, "torch.distributed.checkpoint.state_dict.get_model_state_dict"]], "get_optimizer_state_dict() (in module torch.distributed.checkpoint.state_dict)": [[32, "torch.distributed.checkpoint.state_dict.get_optimizer_state_dict"]], "get_state_dict() (in module torch.distributed.checkpoint.state_dict)": [[32, "torch.distributed.checkpoint.state_dict.get_state_dict"]], "load() (in module torch.distributed.checkpoint.state_dict_loader)": [[32, "torch.distributed.checkpoint.state_dict_loader.load"]], "load_bytes() (torch.distributed.checkpoint.loadplanner method)": [[32, "torch.distributed.checkpoint.LoadPlanner.load_bytes"]], "load_state_dict() (in module torch.distributed.checkpoint.state_dict_loader)": [[32, "torch.distributed.checkpoint.state_dict_loader.load_state_dict"]], "load_state_dict() (torch.distributed.checkpoint.stateful.stateful method)": [[32, "torch.distributed.checkpoint.stateful.Stateful.load_state_dict"]], "lookup_object() (torch.distributed.checkpoint.defaultsaveplanner method)": [[32, "torch.distributed.checkpoint.DefaultSavePlanner.lookup_object"]], "lookup_tensor() (torch.distributed.checkpoint.defaultloadplanner method)": [[32, "torch.distributed.checkpoint.DefaultLoadPlanner.lookup_tensor"]], "prepare_global_plan() (torch.distributed.checkpoint.storagereader method)": [[32, "torch.distributed.checkpoint.StorageReader.prepare_global_plan"]], "prepare_global_plan() (torch.distributed.checkpoint.storagewriter method)": [[32, "torch.distributed.checkpoint.StorageWriter.prepare_global_plan"]], "prepare_global_plan() (torch.distributed.checkpoint.format_utils.broadcastingtorchsavereader method)": [[32, "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.prepare_global_plan"]], "prepare_local_plan() (torch.distributed.checkpoint.storagereader method)": [[32, "torch.distributed.checkpoint.StorageReader.prepare_local_plan"]], "prepare_local_plan() (torch.distributed.checkpoint.storagewriter method)": [[32, "torch.distributed.checkpoint.StorageWriter.prepare_local_plan"]], "prepare_local_plan() (torch.distributed.checkpoint.format_utils.broadcastingtorchsavereader method)": [[32, "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.prepare_local_plan"]], "read_data() (torch.distributed.checkpoint.storagereader method)": [[32, "torch.distributed.checkpoint.StorageReader.read_data"]], "read_data() (torch.distributed.checkpoint.format_utils.broadcastingtorchsavereader method)": [[32, "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.read_data"]], "read_metadata() (torch.distributed.checkpoint.storagereader method)": [[32, "torch.distributed.checkpoint.StorageReader.read_metadata"]], "read_metadata() (torch.distributed.checkpoint.format_utils.broadcastingtorchsavereader method)": [[32, "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.read_metadata"]], "reset() (torch.distributed.checkpoint.storagereader method)": [[32, "torch.distributed.checkpoint.StorageReader.reset"]], "reset() (torch.distributed.checkpoint.storagewriter method)": [[32, "torch.distributed.checkpoint.StorageWriter.reset"]], "reset() (torch.distributed.checkpoint.format_utils.broadcastingtorchsavereader method)": [[32, "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.reset"]], "resolve_bytes() (torch.distributed.checkpoint.loadplanner method)": [[32, "torch.distributed.checkpoint.LoadPlanner.resolve_bytes"]], "resolve_data() (torch.distributed.checkpoint.saveplanner method)": [[32, "torch.distributed.checkpoint.SavePlanner.resolve_data"]], "resolve_tensor() (torch.distributed.checkpoint.loadplanner method)": [[32, "torch.distributed.checkpoint.LoadPlanner.resolve_tensor"]], "save() (in module torch.distributed.checkpoint.state_dict_saver)": [[32, "torch.distributed.checkpoint.state_dict_saver.save"]], "save_state_dict() (in module torch.distributed.checkpoint.state_dict_saver)": [[32, "torch.distributed.checkpoint.state_dict_saver.save_state_dict"]], "set_model_state_dict() (in module torch.distributed.checkpoint.state_dict)": [[32, "torch.distributed.checkpoint.state_dict.set_model_state_dict"]], "set_optimizer_state_dict() (in module torch.distributed.checkpoint.state_dict)": [[32, "torch.distributed.checkpoint.state_dict.set_optimizer_state_dict"]], "set_state_dict() (in module torch.distributed.checkpoint.state_dict)": [[32, "torch.distributed.checkpoint.state_dict.set_state_dict"]], "set_up_planner() (torch.distributed.checkpoint.loadplanner method)": [[32, "torch.distributed.checkpoint.LoadPlanner.set_up_planner"]], "set_up_planner() (torch.distributed.checkpoint.saveplanner method)": [[32, "torch.distributed.checkpoint.SavePlanner.set_up_planner"]], "set_up_planner() (torch.distributed.checkpoint.format_utils.dynamicmetaloadplanner method)": [[32, "torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner.set_up_planner"]], "set_up_storage_reader() (torch.distributed.checkpoint.storagereader method)": [[32, "torch.distributed.checkpoint.StorageReader.set_up_storage_reader"]], "set_up_storage_reader() (torch.distributed.checkpoint.format_utils.broadcastingtorchsavereader method)": [[32, "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.set_up_storage_reader"]], "set_up_storage_writer() (torch.distributed.checkpoint.storagewriter method)": [[32, "torch.distributed.checkpoint.StorageWriter.set_up_storage_writer"]], "should_synchronize_after_execute (torch.distributed.checkpoint.staging.asyncstager property)": [[32, "torch.distributed.checkpoint.staging.AsyncStager.should_synchronize_after_execute"]], "stage() (torch.distributed.checkpoint.filesystemwriter method)": [[32, "torch.distributed.checkpoint.FileSystemWriter.stage"]], "stage() (torch.distributed.checkpoint.staging.asyncstager method)": [[32, "torch.distributed.checkpoint.staging.AsyncStager.stage"]], "stage() (torch.distributed.checkpoint.staging.blockingasyncstager method)": [[32, "torch.distributed.checkpoint.staging.BlockingAsyncStager.stage"]], "state_dict() (torch.distributed.checkpoint.stateful.stateful method)": [[32, "torch.distributed.checkpoint.stateful.Stateful.state_dict"]], "storage_meta() (torch.distributed.checkpoint.storagewriter method)": [[32, "torch.distributed.checkpoint.StorageWriter.storage_meta"]], "synchronize_staging() (torch.distributed.checkpoint.staging.asyncstager method)": [[32, "torch.distributed.checkpoint.staging.AsyncStager.synchronize_staging"]], "synchronize_staging() (torch.distributed.checkpoint.staging.blockingasyncstager method)": [[32, "torch.distributed.checkpoint.staging.BlockingAsyncStager.synchronize_staging"]], "tensor_storage_size() (torch.distributed.checkpoint.planner.writeitem method)": [[32, "torch.distributed.checkpoint.planner.WriteItem.tensor_storage_size"]], "torch.distributed.checkpoint": [[32, "module-torch.distributed.checkpoint"]], "torch.distributed.checkpoint.format_utils": [[32, "module-torch.distributed.checkpoint.format_utils"]], "torch.distributed.checkpoint.logger": [[32, "module-torch.distributed.checkpoint.logger"]], "torch.distributed.checkpoint.logging_handlers": [[32, "module-torch.distributed.checkpoint.logging_handlers"]], "torch.distributed.checkpoint.staging": [[32, "module-torch.distributed.checkpoint.staging"]], "torch_save_to_dcp() (in module torch.distributed.checkpoint.format_utils)": [[32, "torch.distributed.checkpoint.format_utils.torch_save_to_dcp"]], "transform_object() (torch.distributed.checkpoint.defaultsaveplanner method)": [[32, "torch.distributed.checkpoint.DefaultSavePlanner.transform_object"]], "transform_tensor() (torch.distributed.checkpoint.defaultloadplanner method)": [[32, "torch.distributed.checkpoint.DefaultLoadPlanner.transform_tensor"]], "validate_checkpoint_id() (torch.distributed.checkpoint.storagereader class method)": [[32, "torch.distributed.checkpoint.StorageReader.validate_checkpoint_id"]], "validate_checkpoint_id() (torch.distributed.checkpoint.storagewriter class method)": [[32, "torch.distributed.checkpoint.StorageWriter.validate_checkpoint_id"]], "validate_checkpoint_id() (torch.distributed.checkpoint.format_utils.broadcastingtorchsavereader class method)": [[32, "torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.validate_checkpoint_id"]], "write_data() (torch.distributed.checkpoint.storagewriter method)": [[32, "torch.distributed.checkpoint.StorageWriter.write_data"]], "cpuoffloadpolicy (class in torch.distributed.fsdp)": [[34, "torch.distributed.fsdp.CPUOffloadPolicy"]], "fsdpmodule (class in torch.distributed.fsdp)": [[34, "torch.distributed.fsdp.FSDPModule"]], "mixedprecisionpolicy (class in torch.distributed.fsdp)": [[34, "torch.distributed.fsdp.MixedPrecisionPolicy"]], "offloadpolicy (class in torch.distributed.fsdp)": [[34, "torch.distributed.fsdp.OffloadPolicy"]], "unshardhandle (class in torch.distributed.fsdp)": [[34, "torch.distributed.fsdp.UnshardHandle"]], "fully_shard() (in module torch.distributed.fsdp)": [[34, "torch.distributed.fsdp.fully_shard"]], "register_fsdp_forward_method() (in module torch.distributed.fsdp)": [[34, "torch.distributed.fsdp.register_fsdp_forward_method"]], "reshard() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.reshard"]], "set_is_last_backward() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_is_last_backward"]], "set_modules_to_backward_prefetch() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_modules_to_backward_prefetch"]], "set_modules_to_forward_prefetch() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_modules_to_forward_prefetch"]], "set_post_optim_event() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_post_optim_event"]], "set_reduce_scatter_divide_factor() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_reduce_scatter_divide_factor"]], "set_requires_all_reduce() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_requires_all_reduce"]], "set_requires_gradient_sync() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_requires_gradient_sync"]], "set_reshard_after_backward() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_reshard_after_backward"]], "set_unshard_in_backward() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.set_unshard_in_backward"]], "unshard() (torch.distributed.fsdp.fsdpmodule method)": [[34, "torch.distributed.fsdp.FSDPModule.unshard"]], "wait() (torch.distributed.fsdp.unshardhandle method)": [[34, "torch.distributed.fsdp.UnshardHandle.wait"]], "distributedoptimizer (class in torch.distributed.optim)": [[35, "torch.distributed.optim.DistributedOptimizer"]], "postlocalsgdoptimizer (class in torch.distributed.optim)": [[35, "torch.distributed.optim.PostLocalSGDOptimizer"]], "zeroredundancyoptimizer (class in torch.distributed.optim)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer"]], "add_param_group() (torch.distributed.optim.zeroredundancyoptimizer method)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer.add_param_group"]], "consolidate_state_dict() (torch.distributed.optim.zeroredundancyoptimizer method)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer.consolidate_state_dict"]], "join_device (torch.distributed.optim.zeroredundancyoptimizer property)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer.join_device"]], "join_hook() (torch.distributed.optim.zeroredundancyoptimizer method)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer.join_hook"]], "join_process_group (torch.distributed.optim.zeroredundancyoptimizer property)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer.join_process_group"]], "load_state_dict() (torch.distributed.optim.postlocalsgdoptimizer method)": [[35, "torch.distributed.optim.PostLocalSGDOptimizer.load_state_dict"]], "load_state_dict() (torch.distributed.optim.zeroredundancyoptimizer method)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer.load_state_dict"]], "state_dict() (torch.distributed.optim.postlocalsgdoptimizer method)": [[35, "torch.distributed.optim.PostLocalSGDOptimizer.state_dict"]], "state_dict() (torch.distributed.optim.zeroredundancyoptimizer method)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer.state_dict"]], "step() (torch.distributed.optim.distributedoptimizer method)": [[35, "torch.distributed.optim.DistributedOptimizer.step"]], "step() (torch.distributed.optim.postlocalsgdoptimizer method)": [[35, "torch.distributed.optim.PostLocalSGDOptimizer.step"]], "step() (torch.distributed.optim.zeroredundancyoptimizer method)": [[35, "torch.distributed.optim.ZeroRedundancyOptimizer.step"]], "torch.distributed.optim": [[35, "module-torch.distributed.optim"]], "pipe (class in torch.distributed.pipelining)": [[36, "torch.distributed.pipelining.Pipe"]], "pipelineschedulemulti (class in torch.distributed.pipelining.schedules)": [[36, "torch.distributed.pipelining.schedules.PipelineScheduleMulti"]], "pipelineschedulesingle (class in torch.distributed.pipelining.schedules)": [[36, "torch.distributed.pipelining.schedules.PipelineScheduleSingle"]], "pipelinestage (class in torch.distributed.pipelining.stage)": [[36, "torch.distributed.pipelining.stage.PipelineStage"]], "schedule1f1b (class in torch.distributed.pipelining.schedules)": [[36, "torch.distributed.pipelining.schedules.Schedule1F1B"]], "schedulegpipe (class in torch.distributed.pipelining.schedules)": [[36, "torch.distributed.pipelining.schedules.ScheduleGPipe"]], "scheduleinterleaved1f1b (class in torch.distributed.pipelining.schedules)": [[36, "torch.distributed.pipelining.schedules.ScheduleInterleaved1F1B"]], "scheduleinterleavedzerobubble (class in torch.distributed.pipelining.schedules)": [[36, "torch.distributed.pipelining.schedules.ScheduleInterleavedZeroBubble"]], "scheduleloopedbfs (class in torch.distributed.pipelining.schedules)": [[36, "torch.distributed.pipelining.schedules.ScheduleLoopedBFS"]], "schedulezbvzerobubble (class in torch.distributed.pipelining.schedules)": [[36, "torch.distributed.pipelining.schedules.ScheduleZBVZeroBubble"]], "splitpoint (class in torch.distributed.pipelining)": [[36, "torch.distributed.pipelining.SplitPoint"]], "tensorchunkspec (class in torch.distributed.pipelining.microbatch)": [[36, "torch.distributed.pipelining.microbatch.TensorChunkSpec"]], "build_stage() (in module torch.distributed.pipelining.stage)": [[36, "torch.distributed.pipelining.stage.build_stage"]], "merge_chunks() (in module torch.distributed.pipelining.microbatch)": [[36, "torch.distributed.pipelining.microbatch.merge_chunks"]], "pipe_split() (in module torch.distributed.pipelining)": [[36, "torch.distributed.pipelining.pipe_split"]], "pipeline() (in module torch.distributed.pipelining)": [[36, "torch.distributed.pipelining.pipeline"]], "split_args_kwargs_into_chunks() (in module torch.distributed.pipelining.microbatch)": [[36, "torch.distributed.pipelining.microbatch.split_args_kwargs_into_chunks"]], "step() (torch.distributed.pipelining.schedules.pipelineschedulemulti method)": [[36, "torch.distributed.pipelining.schedules.PipelineScheduleMulti.step"]], "step() (torch.distributed.pipelining.schedules.pipelineschedulesingle method)": [[36, "torch.distributed.pipelining.schedules.PipelineScheduleSingle.step"]], "torch.distributed.pipelining": [[36, "module-torch.distributed.pipelining"]], "torch.distributed.pipelining.microbatch": [[36, "module-torch.distributed.pipelining.microbatch"]], "torch.distributed.pipelining.schedules": [[36, "module-torch.distributed.pipelining.schedules"]], "torch.distributed.pipelining.stage": [[36, "module-torch.distributed.pipelining.stage"]], "commdebugmode (class in torch.distributed.tensor.debug)": [[37, "torch.distributed.tensor.debug.CommDebugMode"]], "dtensor (class in torch.distributed.tensor)": [[37, "torch.distributed.tensor.DTensor"]], "partial (class in torch.distributed.tensor.placement_types)": [[37, "torch.distributed.tensor.placement_types.Partial"]], "placement (class in torch.distributed.tensor.placement_types)": [[37, "torch.distributed.tensor.placement_types.Placement"]], "replicate (class in torch.distributed.tensor.placement_types)": [[37, "torch.distributed.tensor.placement_types.Replicate"]], "shard (class in torch.distributed.tensor.placement_types)": [[37, "torch.distributed.tensor.placement_types.Shard"]], "context_parallel() (in module torch.distributed.tensor.experimental)": [[37, "torch.distributed.tensor.experimental.context_parallel"]], "device_mesh (torch.distributed.tensor.dtensor property)": [[37, "torch.distributed.tensor.DTensor.device_mesh"]], "dim (torch.distributed.tensor.placement_types.shard attribute)": [[37, "torch.distributed.tensor.placement_types.Shard.dim"]], "distribute_module() (in module torch.distributed.tensor)": [[37, "torch.distributed.tensor.distribute_module"]], "distribute_tensor() (in module torch.distributed.tensor)": [[37, "torch.distributed.tensor.distribute_tensor"]], "empty() (in module torch.distributed.tensor)": [[37, "torch.distributed.tensor.empty"]], "from_local() (torch.distributed.tensor.dtensor static method)": [[37, "torch.distributed.tensor.DTensor.from_local"]], "full() (in module torch.distributed.tensor)": [[37, "torch.distributed.tensor.full"]], "full_tensor() (torch.distributed.tensor.dtensor method)": [[37, "torch.distributed.tensor.DTensor.full_tensor"]], "generate_comm_debug_tracing_table() (torch.distributed.tensor.debug.commdebugmode method)": [[37, "torch.distributed.tensor.debug.CommDebugMode.generate_comm_debug_tracing_table"]], "generate_json_dump() (torch.distributed.tensor.debug.commdebugmode method)": [[37, "torch.distributed.tensor.debug.CommDebugMode.generate_json_dump"]], "get_comm_counts() (torch.distributed.tensor.debug.commdebugmode method)": [[37, "torch.distributed.tensor.debug.CommDebugMode.get_comm_counts"]], "get_parameter_info() (torch.distributed.tensor.debug.commdebugmode method)": [[37, "torch.distributed.tensor.debug.CommDebugMode.get_parameter_info"]], "get_sharding_info() (torch.distributed.tensor.debug.commdebugmode method)": [[37, "torch.distributed.tensor.debug.CommDebugMode.get_sharding_info"]], "get_total_counts() (torch.distributed.tensor.debug.commdebugmode method)": [[37, "torch.distributed.tensor.debug.CommDebugMode.get_total_counts"]], "is_partial() (torch.distributed.tensor.placement_types.placement method)": [[37, "torch.distributed.tensor.placement_types.Placement.is_partial"]], "is_replicate() (torch.distributed.tensor.placement_types.placement method)": [[37, "torch.distributed.tensor.placement_types.Placement.is_replicate"]], "is_shard() (torch.distributed.tensor.placement_types.placement method)": [[37, "torch.distributed.tensor.placement_types.Placement.is_shard"]], "local_map() (in module torch.distributed.tensor.experimental)": [[37, "torch.distributed.tensor.experimental.local_map"]], "log_comm_debug_tracing_table_to_file() (torch.distributed.tensor.debug.commdebugmode method)": [[37, "torch.distributed.tensor.debug.CommDebugMode.log_comm_debug_tracing_table_to_file"]], "ones() (in module torch.distributed.tensor)": [[37, "torch.distributed.tensor.ones"]], "placements (torch.distributed.tensor.dtensor property)": [[37, "torch.distributed.tensor.DTensor.placements"]], "rand() (in module torch.distributed.tensor)": [[37, "torch.distributed.tensor.rand"]], "randn() (in module torch.distributed.tensor)": [[37, "torch.distributed.tensor.randn"]], "redistribute() (torch.distributed.tensor.dtensor method)": [[37, "torch.distributed.tensor.DTensor.redistribute"]], "reduce_op (torch.distributed.tensor.placement_types.partial attribute)": [[37, "torch.distributed.tensor.placement_types.Partial.reduce_op"]], "register_sharding() (in module torch.distributed.tensor.experimental)": [[37, "torch.distributed.tensor.experimental.register_sharding"]], "to_local() (torch.distributed.tensor.dtensor method)": [[37, "torch.distributed.tensor.DTensor.to_local"]], "torch.distributed.tensor": [[37, "module-torch.distributed.tensor"]], "torch.distributed.tensor.debug": [[37, "module-torch.distributed.tensor.debug"]], "torch.distributed.tensor.device_mesh": [[37, "module-torch.distributed.tensor.device_mesh"]], "torch.distributed.tensor.experimental": [[37, "module-torch.distributed.tensor.experimental"]], "torch.distributed.tensor.placement_types": [[37, "module-torch.distributed.tensor.placement_types"]], "visualize_sharding() (in module torch.distributed.tensor.debug)": [[37, "torch.distributed.tensor.debug.visualize_sharding"]], "zeros() (in module torch.distributed.tensor)": [[37, "torch.distributed.tensor.zeros"]], "colwiseparallel (class in torch.distributed.tensor.parallel)": [[38, "torch.distributed.tensor.parallel.ColwiseParallel"]], "preparemoduleinput (class in torch.distributed.tensor.parallel)": [[38, "torch.distributed.tensor.parallel.PrepareModuleInput"]], "preparemoduleoutput (class in torch.distributed.tensor.parallel)": [[38, "torch.distributed.tensor.parallel.PrepareModuleOutput"]], "rowwiseparallel (class in torch.distributed.tensor.parallel)": [[38, "torch.distributed.tensor.parallel.RowwiseParallel"]], "sequenceparallel (class in torch.distributed.tensor.parallel)": [[38, "torch.distributed.tensor.parallel.SequenceParallel"]], "loss_parallel() (in module torch.distributed.tensor.parallel)": [[38, "torch.distributed.tensor.parallel.loss_parallel"]], "parallelize_module() (in module torch.distributed.tensor.parallel)": [[38, "torch.distributed.tensor.parallel.parallelize_module"]], "torch.distributed.tensor.parallel": [[38, "module-torch.distributed.tensor.parallel"]], "abstransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.AbsTransform"]], "affinetransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.AffineTransform"]], "bernoulli (class in torch.distributions.bernoulli)": [[39, "torch.distributions.bernoulli.Bernoulli"]], "beta (class in torch.distributions.beta)": [[39, "torch.distributions.beta.Beta"]], "binomial (class in torch.distributions.binomial)": [[39, "torch.distributions.binomial.Binomial"]], "cattransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.CatTransform"]], "categorical (class in torch.distributions.categorical)": [[39, "torch.distributions.categorical.Categorical"]], "cauchy (class in torch.distributions.cauchy)": [[39, "torch.distributions.cauchy.Cauchy"]], "chi2 (class in torch.distributions.chi2)": [[39, "torch.distributions.chi2.Chi2"]], "composetransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.ComposeTransform"]], "constraint (class in torch.distributions.constraints)": [[39, "torch.distributions.constraints.Constraint"]], "constraintregistry (class in torch.distributions.constraint_registry)": [[39, "torch.distributions.constraint_registry.ConstraintRegistry"]], "continuousbernoulli (class in torch.distributions.continuous_bernoulli)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli"]], "corrcholeskytransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.CorrCholeskyTransform"]], "cumulativedistributiontransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.CumulativeDistributionTransform"]], "dirichlet (class in torch.distributions.dirichlet)": [[39, "torch.distributions.dirichlet.Dirichlet"]], "distribution (class in torch.distributions.distribution)": [[39, "torch.distributions.distribution.Distribution"]], "exptransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.ExpTransform"]], "exponential (class in torch.distributions.exponential)": [[39, "torch.distributions.exponential.Exponential"]], "exponentialfamily (class in torch.distributions.exp_family)": [[39, "torch.distributions.exp_family.ExponentialFamily"]], "fishersnedecor (class in torch.distributions.fishersnedecor)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor"]], "gamma (class in torch.distributions.gamma)": [[39, "torch.distributions.gamma.Gamma"]], "geometric (class in torch.distributions.geometric)": [[39, "torch.distributions.geometric.Geometric"]], "gumbel (class in torch.distributions.gumbel)": [[39, "torch.distributions.gumbel.Gumbel"]], "halfcauchy (class in torch.distributions.half_cauchy)": [[39, "torch.distributions.half_cauchy.HalfCauchy"]], "halfnormal (class in torch.distributions.half_normal)": [[39, "torch.distributions.half_normal.HalfNormal"]], "independent (class in torch.distributions.independent)": [[39, "torch.distributions.independent.Independent"]], "independenttransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.IndependentTransform"]], "inversegamma (class in torch.distributions.inverse_gamma)": [[39, "torch.distributions.inverse_gamma.InverseGamma"]], "kumaraswamy (class in torch.distributions.kumaraswamy)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy"]], "lkjcholesky (class in torch.distributions.lkj_cholesky)": [[39, "torch.distributions.lkj_cholesky.LKJCholesky"]], "laplace (class in torch.distributions.laplace)": [[39, "torch.distributions.laplace.Laplace"]], "lognormal (class in torch.distributions.log_normal)": [[39, "torch.distributions.log_normal.LogNormal"]], "logitrelaxedbernoulli (class in torch.distributions.relaxed_bernoulli)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli"]], "lowrankmultivariatenormal (class in torch.distributions.lowrank_multivariate_normal)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal"]], "lowercholeskytransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.LowerCholeskyTransform"]], "mixturesamefamily (class in torch.distributions.mixture_same_family)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily"]], "multinomial (class in torch.distributions.multinomial)": [[39, "torch.distributions.multinomial.Multinomial"]], "multivariatenormal (class in torch.distributions.multivariate_normal)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal"]], "negativebinomial (class in torch.distributions.negative_binomial)": [[39, "torch.distributions.negative_binomial.NegativeBinomial"]], "normal (class in torch.distributions.normal)": [[39, "torch.distributions.normal.Normal"]], "onehotcategorical (class in torch.distributions.one_hot_categorical)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical"]], "pareto (class in torch.distributions.pareto)": [[39, "torch.distributions.pareto.Pareto"]], "poisson (class in torch.distributions.poisson)": [[39, "torch.distributions.poisson.Poisson"]], "positivedefinitetransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.PositiveDefiniteTransform"]], "powertransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.PowerTransform"]], "relaxedbernoulli (class in torch.distributions.relaxed_bernoulli)": [[39, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli"]], "relaxedonehotcategorical (class in torch.distributions.relaxed_categorical)": [[39, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical"]], "reshapetransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.ReshapeTransform"]], "sigmoidtransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.SigmoidTransform"]], "softmaxtransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.SoftmaxTransform"]], "softplustransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.SoftplusTransform"]], "stacktransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.StackTransform"]], "stickbreakingtransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.StickBreakingTransform"]], "studentt (class in torch.distributions.studentt)": [[39, "torch.distributions.studentT.StudentT"]], "tanhtransform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.TanhTransform"]], "transform (class in torch.distributions.transforms)": [[39, "torch.distributions.transforms.Transform"]], "transformeddistribution (class in torch.distributions.transformed_distribution)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution"]], "uniform (class in torch.distributions.uniform)": [[39, "torch.distributions.uniform.Uniform"]], "vonmises (class in torch.distributions.von_mises)": [[39, "torch.distributions.von_mises.VonMises"]], "weibull (class in torch.distributions.weibull)": [[39, "torch.distributions.weibull.Weibull"]], "wishart (class in torch.distributions.wishart)": [[39, "torch.distributions.wishart.Wishart"]], "arg_constraints (torch.distributions.bernoulli.bernoulli attribute)": [[39, "torch.distributions.bernoulli.Bernoulli.arg_constraints"]], "arg_constraints (torch.distributions.beta.beta attribute)": [[39, "torch.distributions.beta.Beta.arg_constraints"]], "arg_constraints (torch.distributions.binomial.binomial attribute)": [[39, "torch.distributions.binomial.Binomial.arg_constraints"]], "arg_constraints (torch.distributions.categorical.categorical attribute)": [[39, "torch.distributions.categorical.Categorical.arg_constraints"]], "arg_constraints (torch.distributions.cauchy.cauchy attribute)": [[39, "torch.distributions.cauchy.Cauchy.arg_constraints"]], "arg_constraints (torch.distributions.chi2.chi2 attribute)": [[39, "torch.distributions.chi2.Chi2.arg_constraints"]], "arg_constraints (torch.distributions.continuous_bernoulli.continuousbernoulli attribute)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.arg_constraints"]], "arg_constraints (torch.distributions.dirichlet.dirichlet attribute)": [[39, "torch.distributions.dirichlet.Dirichlet.arg_constraints"]], "arg_constraints (torch.distributions.distribution.distribution property)": [[39, "torch.distributions.distribution.Distribution.arg_constraints"]], "arg_constraints (torch.distributions.exponential.exponential attribute)": [[39, "torch.distributions.exponential.Exponential.arg_constraints"]], "arg_constraints (torch.distributions.fishersnedecor.fishersnedecor attribute)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints"]], "arg_constraints (torch.distributions.gamma.gamma attribute)": [[39, "torch.distributions.gamma.Gamma.arg_constraints"]], "arg_constraints (torch.distributions.geometric.geometric attribute)": [[39, "torch.distributions.geometric.Geometric.arg_constraints"]], "arg_constraints (torch.distributions.gumbel.gumbel attribute)": [[39, "torch.distributions.gumbel.Gumbel.arg_constraints"]], "arg_constraints (torch.distributions.half_cauchy.halfcauchy attribute)": [[39, "torch.distributions.half_cauchy.HalfCauchy.arg_constraints"]], "arg_constraints (torch.distributions.half_normal.halfnormal attribute)": [[39, "torch.distributions.half_normal.HalfNormal.arg_constraints"]], "arg_constraints (torch.distributions.independent.independent attribute)": [[39, "torch.distributions.independent.Independent.arg_constraints"]], "arg_constraints (torch.distributions.inverse_gamma.inversegamma attribute)": [[39, "torch.distributions.inverse_gamma.InverseGamma.arg_constraints"]], "arg_constraints (torch.distributions.kumaraswamy.kumaraswamy attribute)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy.arg_constraints"]], "arg_constraints (torch.distributions.laplace.laplace attribute)": [[39, "torch.distributions.laplace.Laplace.arg_constraints"]], "arg_constraints (torch.distributions.lkj_cholesky.lkjcholesky attribute)": [[39, "torch.distributions.lkj_cholesky.LKJCholesky.arg_constraints"]], "arg_constraints (torch.distributions.log_normal.lognormal attribute)": [[39, "torch.distributions.log_normal.LogNormal.arg_constraints"]], "arg_constraints (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal attribute)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.arg_constraints"]], "arg_constraints (torch.distributions.mixture_same_family.mixturesamefamily attribute)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.arg_constraints"]], "arg_constraints (torch.distributions.multinomial.multinomial attribute)": [[39, "torch.distributions.multinomial.Multinomial.arg_constraints"]], "arg_constraints (torch.distributions.multivariate_normal.multivariatenormal attribute)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints"]], "arg_constraints (torch.distributions.negative_binomial.negativebinomial attribute)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.arg_constraints"]], "arg_constraints (torch.distributions.normal.normal attribute)": [[39, "torch.distributions.normal.Normal.arg_constraints"]], "arg_constraints (torch.distributions.one_hot_categorical.onehotcategorical attribute)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints"]], "arg_constraints (torch.distributions.pareto.pareto attribute)": [[39, "torch.distributions.pareto.Pareto.arg_constraints"]], "arg_constraints (torch.distributions.poisson.poisson attribute)": [[39, "torch.distributions.poisson.Poisson.arg_constraints"]], "arg_constraints (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli attribute)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.arg_constraints"]], "arg_constraints (torch.distributions.relaxed_bernoulli.relaxedbernoulli attribute)": [[39, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints"]], "arg_constraints (torch.distributions.relaxed_categorical.relaxedonehotcategorical attribute)": [[39, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints"]], "arg_constraints (torch.distributions.studentt.studentt attribute)": [[39, "torch.distributions.studentT.StudentT.arg_constraints"]], "arg_constraints (torch.distributions.transformed_distribution.transformeddistribution attribute)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints"]], "arg_constraints (torch.distributions.uniform.uniform attribute)": [[39, "torch.distributions.uniform.Uniform.arg_constraints"]], "arg_constraints (torch.distributions.von_mises.vonmises attribute)": [[39, "torch.distributions.von_mises.VonMises.arg_constraints"]], "arg_constraints (torch.distributions.weibull.weibull attribute)": [[39, "torch.distributions.weibull.Weibull.arg_constraints"]], "arg_constraints (torch.distributions.wishart.wishart attribute)": [[39, "torch.distributions.wishart.Wishart.arg_constraints"]], "batch_shape (torch.distributions.distribution.distribution property)": [[39, "torch.distributions.distribution.Distribution.batch_shape"]], "cat (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.cat"]], "cdf() (torch.distributions.cauchy.cauchy method)": [[39, "torch.distributions.cauchy.Cauchy.cdf"]], "cdf() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.cdf"]], "cdf() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.cdf"]], "cdf() (torch.distributions.exponential.exponential method)": [[39, "torch.distributions.exponential.Exponential.cdf"]], "cdf() (torch.distributions.gamma.gamma method)": [[39, "torch.distributions.gamma.Gamma.cdf"]], "cdf() (torch.distributions.half_cauchy.halfcauchy method)": [[39, "torch.distributions.half_cauchy.HalfCauchy.cdf"]], "cdf() (torch.distributions.half_normal.halfnormal method)": [[39, "torch.distributions.half_normal.HalfNormal.cdf"]], "cdf() (torch.distributions.laplace.laplace method)": [[39, "torch.distributions.laplace.Laplace.cdf"]], "cdf() (torch.distributions.mixture_same_family.mixturesamefamily method)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.cdf"]], "cdf() (torch.distributions.normal.normal method)": [[39, "torch.distributions.normal.Normal.cdf"]], "cdf() (torch.distributions.transformed_distribution.transformeddistribution method)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.cdf"]], "cdf() (torch.distributions.uniform.uniform method)": [[39, "torch.distributions.uniform.Uniform.cdf"]], "check() (torch.distributions.constraints.constraint method)": [[39, "torch.distributions.constraints.Constraint.check"]], "component_distribution (torch.distributions.mixture_same_family.mixturesamefamily property)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.component_distribution"]], "concentration (torch.distributions.inverse_gamma.inversegamma property)": [[39, "torch.distributions.inverse_gamma.InverseGamma.concentration"]], "concentration0 (torch.distributions.beta.beta property)": [[39, "torch.distributions.beta.Beta.concentration0"]], "concentration1 (torch.distributions.beta.beta property)": [[39, "torch.distributions.beta.Beta.concentration1"]], "covariance_matrix (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.covariance_matrix"]], "covariance_matrix (torch.distributions.multivariate_normal.multivariatenormal property)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix"]], "covariance_matrix (torch.distributions.wishart.wishart property)": [[39, "torch.distributions.wishart.Wishart.covariance_matrix"]], "dependent_property (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.dependent_property"]], "df (torch.distributions.chi2.chi2 property)": [[39, "torch.distributions.chi2.Chi2.df"]], "entropy() (torch.distributions.bernoulli.bernoulli method)": [[39, "torch.distributions.bernoulli.Bernoulli.entropy"]], "entropy() (torch.distributions.beta.beta method)": [[39, "torch.distributions.beta.Beta.entropy"]], "entropy() (torch.distributions.binomial.binomial method)": [[39, "torch.distributions.binomial.Binomial.entropy"]], "entropy() (torch.distributions.categorical.categorical method)": [[39, "torch.distributions.categorical.Categorical.entropy"]], "entropy() (torch.distributions.cauchy.cauchy method)": [[39, "torch.distributions.cauchy.Cauchy.entropy"]], "entropy() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.entropy"]], "entropy() (torch.distributions.dirichlet.dirichlet method)": [[39, "torch.distributions.dirichlet.Dirichlet.entropy"]], "entropy() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.entropy"]], "entropy() (torch.distributions.exp_family.exponentialfamily method)": [[39, "torch.distributions.exp_family.ExponentialFamily.entropy"]], "entropy() (torch.distributions.exponential.exponential method)": [[39, "torch.distributions.exponential.Exponential.entropy"]], "entropy() (torch.distributions.gamma.gamma method)": [[39, "torch.distributions.gamma.Gamma.entropy"]], "entropy() (torch.distributions.geometric.geometric method)": [[39, "torch.distributions.geometric.Geometric.entropy"]], "entropy() (torch.distributions.gumbel.gumbel method)": [[39, "torch.distributions.gumbel.Gumbel.entropy"]], "entropy() (torch.distributions.half_cauchy.halfcauchy method)": [[39, "torch.distributions.half_cauchy.HalfCauchy.entropy"]], "entropy() (torch.distributions.half_normal.halfnormal method)": [[39, "torch.distributions.half_normal.HalfNormal.entropy"]], "entropy() (torch.distributions.independent.independent method)": [[39, "torch.distributions.independent.Independent.entropy"]], "entropy() (torch.distributions.inverse_gamma.inversegamma method)": [[39, "torch.distributions.inverse_gamma.InverseGamma.entropy"]], "entropy() (torch.distributions.kumaraswamy.kumaraswamy method)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy.entropy"]], "entropy() (torch.distributions.laplace.laplace method)": [[39, "torch.distributions.laplace.Laplace.entropy"]], "entropy() (torch.distributions.log_normal.lognormal method)": [[39, "torch.distributions.log_normal.LogNormal.entropy"]], "entropy() (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal method)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy"]], "entropy() (torch.distributions.multinomial.multinomial method)": [[39, "torch.distributions.multinomial.Multinomial.entropy"]], "entropy() (torch.distributions.multivariate_normal.multivariatenormal method)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.entropy"]], "entropy() (torch.distributions.normal.normal method)": [[39, "torch.distributions.normal.Normal.entropy"]], "entropy() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.entropy"]], "entropy() (torch.distributions.pareto.pareto method)": [[39, "torch.distributions.pareto.Pareto.entropy"]], "entropy() (torch.distributions.studentt.studentt method)": [[39, "torch.distributions.studentT.StudentT.entropy"]], "entropy() (torch.distributions.uniform.uniform method)": [[39, "torch.distributions.uniform.Uniform.entropy"]], "entropy() (torch.distributions.weibull.weibull method)": [[39, "torch.distributions.weibull.Weibull.entropy"]], "entropy() (torch.distributions.wishart.wishart method)": [[39, "torch.distributions.wishart.Wishart.entropy"]], "enumerate_support() (torch.distributions.bernoulli.bernoulli method)": [[39, "torch.distributions.bernoulli.Bernoulli.enumerate_support"]], "enumerate_support() (torch.distributions.binomial.binomial method)": [[39, "torch.distributions.binomial.Binomial.enumerate_support"]], "enumerate_support() (torch.distributions.categorical.categorical method)": [[39, "torch.distributions.categorical.Categorical.enumerate_support"]], "enumerate_support() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.enumerate_support"]], "enumerate_support() (torch.distributions.independent.independent method)": [[39, "torch.distributions.independent.Independent.enumerate_support"]], "enumerate_support() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support"]], "event_shape (torch.distributions.distribution.distribution property)": [[39, "torch.distributions.distribution.Distribution.event_shape"]], "expand() (torch.distributions.bernoulli.bernoulli method)": [[39, "torch.distributions.bernoulli.Bernoulli.expand"]], "expand() (torch.distributions.beta.beta method)": [[39, "torch.distributions.beta.Beta.expand"]], "expand() (torch.distributions.binomial.binomial method)": [[39, "torch.distributions.binomial.Binomial.expand"]], "expand() (torch.distributions.categorical.categorical method)": [[39, "torch.distributions.categorical.Categorical.expand"]], "expand() (torch.distributions.cauchy.cauchy method)": [[39, "torch.distributions.cauchy.Cauchy.expand"]], "expand() (torch.distributions.chi2.chi2 method)": [[39, "torch.distributions.chi2.Chi2.expand"]], "expand() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.expand"]], "expand() (torch.distributions.dirichlet.dirichlet method)": [[39, "torch.distributions.dirichlet.Dirichlet.expand"]], "expand() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.expand"]], "expand() (torch.distributions.exponential.exponential method)": [[39, "torch.distributions.exponential.Exponential.expand"]], "expand() (torch.distributions.fishersnedecor.fishersnedecor method)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.expand"]], "expand() (torch.distributions.gamma.gamma method)": [[39, "torch.distributions.gamma.Gamma.expand"]], "expand() (torch.distributions.geometric.geometric method)": [[39, "torch.distributions.geometric.Geometric.expand"]], "expand() (torch.distributions.gumbel.gumbel method)": [[39, "torch.distributions.gumbel.Gumbel.expand"]], "expand() (torch.distributions.half_cauchy.halfcauchy method)": [[39, "torch.distributions.half_cauchy.HalfCauchy.expand"]], "expand() (torch.distributions.half_normal.halfnormal method)": [[39, "torch.distributions.half_normal.HalfNormal.expand"]], "expand() (torch.distributions.independent.independent method)": [[39, "torch.distributions.independent.Independent.expand"]], "expand() (torch.distributions.inverse_gamma.inversegamma method)": [[39, "torch.distributions.inverse_gamma.InverseGamma.expand"]], "expand() (torch.distributions.kumaraswamy.kumaraswamy method)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy.expand"]], "expand() (torch.distributions.laplace.laplace method)": [[39, "torch.distributions.laplace.Laplace.expand"]], "expand() (torch.distributions.lkj_cholesky.lkjcholesky method)": [[39, "torch.distributions.lkj_cholesky.LKJCholesky.expand"]], "expand() (torch.distributions.log_normal.lognormal method)": [[39, "torch.distributions.log_normal.LogNormal.expand"]], "expand() (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal method)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand"]], "expand() (torch.distributions.mixture_same_family.mixturesamefamily method)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.expand"]], "expand() (torch.distributions.multinomial.multinomial method)": [[39, "torch.distributions.multinomial.Multinomial.expand"]], "expand() (torch.distributions.multivariate_normal.multivariatenormal method)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.expand"]], "expand() (torch.distributions.negative_binomial.negativebinomial method)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.expand"]], "expand() (torch.distributions.normal.normal method)": [[39, "torch.distributions.normal.Normal.expand"]], "expand() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.expand"]], "expand() (torch.distributions.pareto.pareto method)": [[39, "torch.distributions.pareto.Pareto.expand"]], "expand() (torch.distributions.poisson.poisson method)": [[39, "torch.distributions.poisson.Poisson.expand"]], "expand() (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli method)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand"]], "expand() (torch.distributions.relaxed_bernoulli.relaxedbernoulli method)": [[39, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand"]], "expand() (torch.distributions.relaxed_categorical.relaxedonehotcategorical method)": [[39, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand"]], "expand() (torch.distributions.studentt.studentt method)": [[39, "torch.distributions.studentT.StudentT.expand"]], "expand() (torch.distributions.transformed_distribution.transformeddistribution method)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.expand"]], "expand() (torch.distributions.uniform.uniform method)": [[39, "torch.distributions.uniform.Uniform.expand"]], "expand() (torch.distributions.von_mises.vonmises method)": [[39, "torch.distributions.von_mises.VonMises.expand"]], "expand() (torch.distributions.weibull.weibull method)": [[39, "torch.distributions.weibull.Weibull.expand"]], "expand() (torch.distributions.wishart.wishart method)": [[39, "torch.distributions.wishart.Wishart.expand"]], "forward_shape() (torch.distributions.transforms.transform method)": [[39, "torch.distributions.transforms.Transform.forward_shape"]], "greater_than (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.greater_than"]], "greater_than_eq (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.greater_than_eq"]], "half_open_interval (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.half_open_interval"]], "has_enumerate_support (torch.distributions.bernoulli.bernoulli attribute)": [[39, "torch.distributions.bernoulli.Bernoulli.has_enumerate_support"]], "has_enumerate_support (torch.distributions.binomial.binomial attribute)": [[39, "torch.distributions.binomial.Binomial.has_enumerate_support"]], "has_enumerate_support (torch.distributions.categorical.categorical attribute)": [[39, "torch.distributions.categorical.Categorical.has_enumerate_support"]], "has_enumerate_support (torch.distributions.independent.independent property)": [[39, "torch.distributions.independent.Independent.has_enumerate_support"]], "has_enumerate_support (torch.distributions.one_hot_categorical.onehotcategorical attribute)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support"]], "has_rsample (torch.distributions.beta.beta attribute)": [[39, "torch.distributions.beta.Beta.has_rsample"]], "has_rsample (torch.distributions.cauchy.cauchy attribute)": [[39, "torch.distributions.cauchy.Cauchy.has_rsample"]], "has_rsample (torch.distributions.continuous_bernoulli.continuousbernoulli attribute)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.has_rsample"]], "has_rsample (torch.distributions.dirichlet.dirichlet attribute)": [[39, "torch.distributions.dirichlet.Dirichlet.has_rsample"]], "has_rsample (torch.distributions.exponential.exponential attribute)": [[39, "torch.distributions.exponential.Exponential.has_rsample"]], "has_rsample (torch.distributions.fishersnedecor.fishersnedecor attribute)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.has_rsample"]], "has_rsample (torch.distributions.gamma.gamma attribute)": [[39, "torch.distributions.gamma.Gamma.has_rsample"]], "has_rsample (torch.distributions.half_cauchy.halfcauchy attribute)": [[39, "torch.distributions.half_cauchy.HalfCauchy.has_rsample"]], "has_rsample (torch.distributions.half_normal.halfnormal attribute)": [[39, "torch.distributions.half_normal.HalfNormal.has_rsample"]], "has_rsample (torch.distributions.independent.independent property)": [[39, "torch.distributions.independent.Independent.has_rsample"]], "has_rsample (torch.distributions.inverse_gamma.inversegamma attribute)": [[39, "torch.distributions.inverse_gamma.InverseGamma.has_rsample"]], "has_rsample (torch.distributions.kumaraswamy.kumaraswamy attribute)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy.has_rsample"]], "has_rsample (torch.distributions.laplace.laplace attribute)": [[39, "torch.distributions.laplace.Laplace.has_rsample"]], "has_rsample (torch.distributions.log_normal.lognormal attribute)": [[39, "torch.distributions.log_normal.LogNormal.has_rsample"]], "has_rsample (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal attribute)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.has_rsample"]], "has_rsample (torch.distributions.mixture_same_family.mixturesamefamily attribute)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.has_rsample"]], "has_rsample (torch.distributions.multivariate_normal.multivariatenormal attribute)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.has_rsample"]], "has_rsample (torch.distributions.normal.normal attribute)": [[39, "torch.distributions.normal.Normal.has_rsample"]], "has_rsample (torch.distributions.relaxed_bernoulli.relaxedbernoulli attribute)": [[39, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample"]], "has_rsample (torch.distributions.relaxed_categorical.relaxedonehotcategorical attribute)": [[39, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample"]], "has_rsample (torch.distributions.studentt.studentt attribute)": [[39, "torch.distributions.studentT.StudentT.has_rsample"]], "has_rsample (torch.distributions.transformed_distribution.transformeddistribution property)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.has_rsample"]], "has_rsample (torch.distributions.uniform.uniform attribute)": [[39, "torch.distributions.uniform.Uniform.has_rsample"]], "has_rsample (torch.distributions.von_mises.vonmises attribute)": [[39, "torch.distributions.von_mises.VonMises.has_rsample"]], "has_rsample (torch.distributions.wishart.wishart attribute)": [[39, "torch.distributions.wishart.Wishart.has_rsample"]], "icdf() (torch.distributions.cauchy.cauchy method)": [[39, "torch.distributions.cauchy.Cauchy.icdf"]], "icdf() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.icdf"]], "icdf() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.icdf"]], "icdf() (torch.distributions.exponential.exponential method)": [[39, "torch.distributions.exponential.Exponential.icdf"]], "icdf() (torch.distributions.half_cauchy.halfcauchy method)": [[39, "torch.distributions.half_cauchy.HalfCauchy.icdf"]], "icdf() (torch.distributions.half_normal.halfnormal method)": [[39, "torch.distributions.half_normal.HalfNormal.icdf"]], "icdf() (torch.distributions.laplace.laplace method)": [[39, "torch.distributions.laplace.Laplace.icdf"]], "icdf() (torch.distributions.normal.normal method)": [[39, "torch.distributions.normal.Normal.icdf"]], "icdf() (torch.distributions.transformed_distribution.transformeddistribution method)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.icdf"]], "icdf() (torch.distributions.uniform.uniform method)": [[39, "torch.distributions.uniform.Uniform.icdf"]], "independent (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.independent"]], "integer_interval (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.integer_interval"]], "interval (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.interval"]], "inv (torch.distributions.transforms.transform property)": [[39, "torch.distributions.transforms.Transform.inv"]], "inverse_shape() (torch.distributions.transforms.transform method)": [[39, "torch.distributions.transforms.Transform.inverse_shape"]], "is_dependent() (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.is_dependent"]], "kl_divergence() (in module torch.distributions.kl)": [[39, "torch.distributions.kl.kl_divergence"]], "less_than (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.less_than"]], "loc (torch.distributions.log_normal.lognormal property)": [[39, "torch.distributions.log_normal.LogNormal.loc"]], "log_abs_det_jacobian() (torch.distributions.transforms.transform method)": [[39, "torch.distributions.transforms.Transform.log_abs_det_jacobian"]], "log_prob() (torch.distributions.bernoulli.bernoulli method)": [[39, "torch.distributions.bernoulli.Bernoulli.log_prob"]], "log_prob() (torch.distributions.beta.beta method)": [[39, "torch.distributions.beta.Beta.log_prob"]], "log_prob() (torch.distributions.binomial.binomial method)": [[39, "torch.distributions.binomial.Binomial.log_prob"]], "log_prob() (torch.distributions.categorical.categorical method)": [[39, "torch.distributions.categorical.Categorical.log_prob"]], "log_prob() (torch.distributions.cauchy.cauchy method)": [[39, "torch.distributions.cauchy.Cauchy.log_prob"]], "log_prob() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.log_prob"]], "log_prob() (torch.distributions.dirichlet.dirichlet method)": [[39, "torch.distributions.dirichlet.Dirichlet.log_prob"]], "log_prob() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.log_prob"]], "log_prob() (torch.distributions.exponential.exponential method)": [[39, "torch.distributions.exponential.Exponential.log_prob"]], "log_prob() (torch.distributions.fishersnedecor.fishersnedecor method)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.log_prob"]], "log_prob() (torch.distributions.gamma.gamma method)": [[39, "torch.distributions.gamma.Gamma.log_prob"]], "log_prob() (torch.distributions.geometric.geometric method)": [[39, "torch.distributions.geometric.Geometric.log_prob"]], "log_prob() (torch.distributions.gumbel.gumbel method)": [[39, "torch.distributions.gumbel.Gumbel.log_prob"]], "log_prob() (torch.distributions.half_cauchy.halfcauchy method)": [[39, "torch.distributions.half_cauchy.HalfCauchy.log_prob"]], "log_prob() (torch.distributions.half_normal.halfnormal method)": [[39, "torch.distributions.half_normal.HalfNormal.log_prob"]], "log_prob() (torch.distributions.independent.independent method)": [[39, "torch.distributions.independent.Independent.log_prob"]], "log_prob() (torch.distributions.laplace.laplace method)": [[39, "torch.distributions.laplace.Laplace.log_prob"]], "log_prob() (torch.distributions.lkj_cholesky.lkjcholesky method)": [[39, "torch.distributions.lkj_cholesky.LKJCholesky.log_prob"]], "log_prob() (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal method)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob"]], "log_prob() (torch.distributions.mixture_same_family.mixturesamefamily method)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.log_prob"]], "log_prob() (torch.distributions.multinomial.multinomial method)": [[39, "torch.distributions.multinomial.Multinomial.log_prob"]], "log_prob() (torch.distributions.multivariate_normal.multivariatenormal method)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.log_prob"]], "log_prob() (torch.distributions.negative_binomial.negativebinomial method)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.log_prob"]], "log_prob() (torch.distributions.normal.normal method)": [[39, "torch.distributions.normal.Normal.log_prob"]], "log_prob() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.log_prob"]], "log_prob() (torch.distributions.poisson.poisson method)": [[39, "torch.distributions.poisson.Poisson.log_prob"]], "log_prob() (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli method)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob"]], "log_prob() (torch.distributions.studentt.studentt method)": [[39, "torch.distributions.studentT.StudentT.log_prob"]], "log_prob() (torch.distributions.transformed_distribution.transformeddistribution method)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.log_prob"]], "log_prob() (torch.distributions.uniform.uniform method)": [[39, "torch.distributions.uniform.Uniform.log_prob"]], "log_prob() (torch.distributions.von_mises.vonmises method)": [[39, "torch.distributions.von_mises.VonMises.log_prob"]], "log_prob() (torch.distributions.wishart.wishart method)": [[39, "torch.distributions.wishart.Wishart.log_prob"]], "logits (torch.distributions.bernoulli.bernoulli property)": [[39, "torch.distributions.bernoulli.Bernoulli.logits"]], "logits (torch.distributions.binomial.binomial property)": [[39, "torch.distributions.binomial.Binomial.logits"]], "logits (torch.distributions.categorical.categorical property)": [[39, "torch.distributions.categorical.Categorical.logits"]], "logits (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.logits"]], "logits (torch.distributions.geometric.geometric property)": [[39, "torch.distributions.geometric.Geometric.logits"]], "logits (torch.distributions.multinomial.multinomial property)": [[39, "torch.distributions.multinomial.Multinomial.logits"]], "logits (torch.distributions.negative_binomial.negativebinomial property)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.logits"]], "logits (torch.distributions.one_hot_categorical.onehotcategorical property)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.logits"]], "logits (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli property)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits"]], "logits (torch.distributions.relaxed_bernoulli.relaxedbernoulli property)": [[39, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits"]], "logits (torch.distributions.relaxed_categorical.relaxedonehotcategorical property)": [[39, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits"]], "mean (torch.distributions.bernoulli.bernoulli property)": [[39, "torch.distributions.bernoulli.Bernoulli.mean"]], "mean (torch.distributions.beta.beta property)": [[39, "torch.distributions.beta.Beta.mean"]], "mean (torch.distributions.binomial.binomial property)": [[39, "torch.distributions.binomial.Binomial.mean"]], "mean (torch.distributions.categorical.categorical property)": [[39, "torch.distributions.categorical.Categorical.mean"]], "mean (torch.distributions.cauchy.cauchy property)": [[39, "torch.distributions.cauchy.Cauchy.mean"]], "mean (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.mean"]], "mean (torch.distributions.dirichlet.dirichlet property)": [[39, "torch.distributions.dirichlet.Dirichlet.mean"]], "mean (torch.distributions.distribution.distribution property)": [[39, "torch.distributions.distribution.Distribution.mean"]], "mean (torch.distributions.exponential.exponential property)": [[39, "torch.distributions.exponential.Exponential.mean"]], "mean (torch.distributions.fishersnedecor.fishersnedecor property)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.mean"]], "mean (torch.distributions.gamma.gamma property)": [[39, "torch.distributions.gamma.Gamma.mean"]], "mean (torch.distributions.geometric.geometric property)": [[39, "torch.distributions.geometric.Geometric.mean"]], "mean (torch.distributions.gumbel.gumbel property)": [[39, "torch.distributions.gumbel.Gumbel.mean"]], "mean (torch.distributions.half_cauchy.halfcauchy property)": [[39, "torch.distributions.half_cauchy.HalfCauchy.mean"]], "mean (torch.distributions.half_normal.halfnormal property)": [[39, "torch.distributions.half_normal.HalfNormal.mean"]], "mean (torch.distributions.independent.independent property)": [[39, "torch.distributions.independent.Independent.mean"]], "mean (torch.distributions.inverse_gamma.inversegamma property)": [[39, "torch.distributions.inverse_gamma.InverseGamma.mean"]], "mean (torch.distributions.kumaraswamy.kumaraswamy property)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy.mean"]], "mean (torch.distributions.laplace.laplace property)": [[39, "torch.distributions.laplace.Laplace.mean"]], "mean (torch.distributions.log_normal.lognormal property)": [[39, "torch.distributions.log_normal.LogNormal.mean"]], "mean (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mean"]], "mean (torch.distributions.mixture_same_family.mixturesamefamily property)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.mean"]], "mean (torch.distributions.multinomial.multinomial property)": [[39, "torch.distributions.multinomial.Multinomial.mean"]], "mean (torch.distributions.multivariate_normal.multivariatenormal property)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.mean"]], "mean (torch.distributions.negative_binomial.negativebinomial property)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.mean"]], "mean (torch.distributions.normal.normal property)": [[39, "torch.distributions.normal.Normal.mean"]], "mean (torch.distributions.one_hot_categorical.onehotcategorical property)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.mean"]], "mean (torch.distributions.pareto.pareto property)": [[39, "torch.distributions.pareto.Pareto.mean"]], "mean (torch.distributions.poisson.poisson property)": [[39, "torch.distributions.poisson.Poisson.mean"]], "mean (torch.distributions.studentt.studentt property)": [[39, "torch.distributions.studentT.StudentT.mean"]], "mean (torch.distributions.uniform.uniform property)": [[39, "torch.distributions.uniform.Uniform.mean"]], "mean (torch.distributions.von_mises.vonmises property)": [[39, "torch.distributions.von_mises.VonMises.mean"]], "mean (torch.distributions.weibull.weibull property)": [[39, "torch.distributions.weibull.Weibull.mean"]], "mean (torch.distributions.wishart.wishart property)": [[39, "torch.distributions.wishart.Wishart.mean"]], "mixture_distribution (torch.distributions.mixture_same_family.mixturesamefamily property)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.mixture_distribution"]], "mode (torch.distributions.bernoulli.bernoulli property)": [[39, "torch.distributions.bernoulli.Bernoulli.mode"]], "mode (torch.distributions.beta.beta property)": [[39, "torch.distributions.beta.Beta.mode"]], "mode (torch.distributions.binomial.binomial property)": [[39, "torch.distributions.binomial.Binomial.mode"]], "mode (torch.distributions.categorical.categorical property)": [[39, "torch.distributions.categorical.Categorical.mode"]], "mode (torch.distributions.cauchy.cauchy property)": [[39, "torch.distributions.cauchy.Cauchy.mode"]], "mode (torch.distributions.dirichlet.dirichlet property)": [[39, "torch.distributions.dirichlet.Dirichlet.mode"]], "mode (torch.distributions.distribution.distribution property)": [[39, "torch.distributions.distribution.Distribution.mode"]], "mode (torch.distributions.exponential.exponential property)": [[39, "torch.distributions.exponential.Exponential.mode"]], "mode (torch.distributions.fishersnedecor.fishersnedecor property)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.mode"]], "mode (torch.distributions.gamma.gamma property)": [[39, "torch.distributions.gamma.Gamma.mode"]], "mode (torch.distributions.geometric.geometric property)": [[39, "torch.distributions.geometric.Geometric.mode"]], "mode (torch.distributions.gumbel.gumbel property)": [[39, "torch.distributions.gumbel.Gumbel.mode"]], "mode (torch.distributions.half_cauchy.halfcauchy property)": [[39, "torch.distributions.half_cauchy.HalfCauchy.mode"]], "mode (torch.distributions.half_normal.halfnormal property)": [[39, "torch.distributions.half_normal.HalfNormal.mode"]], "mode (torch.distributions.independent.independent property)": [[39, "torch.distributions.independent.Independent.mode"]], "mode (torch.distributions.inverse_gamma.inversegamma property)": [[39, "torch.distributions.inverse_gamma.InverseGamma.mode"]], "mode (torch.distributions.kumaraswamy.kumaraswamy property)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy.mode"]], "mode (torch.distributions.laplace.laplace property)": [[39, "torch.distributions.laplace.Laplace.mode"]], "mode (torch.distributions.log_normal.lognormal property)": [[39, "torch.distributions.log_normal.LogNormal.mode"]], "mode (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mode"]], "mode (torch.distributions.multivariate_normal.multivariatenormal property)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.mode"]], "mode (torch.distributions.negative_binomial.negativebinomial property)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.mode"]], "mode (torch.distributions.normal.normal property)": [[39, "torch.distributions.normal.Normal.mode"]], "mode (torch.distributions.one_hot_categorical.onehotcategorical property)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.mode"]], "mode (torch.distributions.pareto.pareto property)": [[39, "torch.distributions.pareto.Pareto.mode"]], "mode (torch.distributions.poisson.poisson property)": [[39, "torch.distributions.poisson.Poisson.mode"]], "mode (torch.distributions.studentt.studentt property)": [[39, "torch.distributions.studentT.StudentT.mode"]], "mode (torch.distributions.uniform.uniform property)": [[39, "torch.distributions.uniform.Uniform.mode"]], "mode (torch.distributions.von_mises.vonmises property)": [[39, "torch.distributions.von_mises.VonMises.mode"]], "mode (torch.distributions.weibull.weibull property)": [[39, "torch.distributions.weibull.Weibull.mode"]], "mode (torch.distributions.wishart.wishart property)": [[39, "torch.distributions.wishart.Wishart.mode"]], "multinomial (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.multinomial"]], "param_shape (torch.distributions.bernoulli.bernoulli property)": [[39, "torch.distributions.bernoulli.Bernoulli.param_shape"]], "param_shape (torch.distributions.binomial.binomial property)": [[39, "torch.distributions.binomial.Binomial.param_shape"]], "param_shape (torch.distributions.categorical.categorical property)": [[39, "torch.distributions.categorical.Categorical.param_shape"]], "param_shape (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.param_shape"]], "param_shape (torch.distributions.multinomial.multinomial property)": [[39, "torch.distributions.multinomial.Multinomial.param_shape"]], "param_shape (torch.distributions.negative_binomial.negativebinomial property)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.param_shape"]], "param_shape (torch.distributions.one_hot_categorical.onehotcategorical property)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.param_shape"]], "param_shape (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli property)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.param_shape"]], "perplexity() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.perplexity"]], "precision_matrix (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.precision_matrix"]], "precision_matrix (torch.distributions.multivariate_normal.multivariatenormal property)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix"]], "precision_matrix (torch.distributions.wishart.wishart property)": [[39, "torch.distributions.wishart.Wishart.precision_matrix"]], "probs (torch.distributions.bernoulli.bernoulli property)": [[39, "torch.distributions.bernoulli.Bernoulli.probs"]], "probs (torch.distributions.binomial.binomial property)": [[39, "torch.distributions.binomial.Binomial.probs"]], "probs (torch.distributions.categorical.categorical property)": [[39, "torch.distributions.categorical.Categorical.probs"]], "probs (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.probs"]], "probs (torch.distributions.geometric.geometric property)": [[39, "torch.distributions.geometric.Geometric.probs"]], "probs (torch.distributions.multinomial.multinomial property)": [[39, "torch.distributions.multinomial.Multinomial.probs"]], "probs (torch.distributions.negative_binomial.negativebinomial property)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.probs"]], "probs (torch.distributions.one_hot_categorical.onehotcategorical property)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.probs"]], "probs (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli property)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs"]], "probs (torch.distributions.relaxed_bernoulli.relaxedbernoulli property)": [[39, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs"]], "probs (torch.distributions.relaxed_categorical.relaxedonehotcategorical property)": [[39, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs"]], "rate (torch.distributions.inverse_gamma.inversegamma property)": [[39, "torch.distributions.inverse_gamma.InverseGamma.rate"]], "register() (torch.distributions.constraint_registry.constraintregistry method)": [[39, "torch.distributions.constraint_registry.ConstraintRegistry.register"]], "register_kl() (in module torch.distributions.kl)": [[39, "torch.distributions.kl.register_kl"]], "rsample() (torch.distributions.beta.beta method)": [[39, "torch.distributions.beta.Beta.rsample"]], "rsample() (torch.distributions.cauchy.cauchy method)": [[39, "torch.distributions.cauchy.Cauchy.rsample"]], "rsample() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.rsample"]], "rsample() (torch.distributions.dirichlet.dirichlet method)": [[39, "torch.distributions.dirichlet.Dirichlet.rsample"]], "rsample() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.rsample"]], "rsample() (torch.distributions.exponential.exponential method)": [[39, "torch.distributions.exponential.Exponential.rsample"]], "rsample() (torch.distributions.fishersnedecor.fishersnedecor method)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.rsample"]], "rsample() (torch.distributions.gamma.gamma method)": [[39, "torch.distributions.gamma.Gamma.rsample"]], "rsample() (torch.distributions.independent.independent method)": [[39, "torch.distributions.independent.Independent.rsample"]], "rsample() (torch.distributions.laplace.laplace method)": [[39, "torch.distributions.laplace.Laplace.rsample"]], "rsample() (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal method)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample"]], "rsample() (torch.distributions.multivariate_normal.multivariatenormal method)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.rsample"]], "rsample() (torch.distributions.normal.normal method)": [[39, "torch.distributions.normal.Normal.rsample"]], "rsample() (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli method)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample"]], "rsample() (torch.distributions.studentt.studentt method)": [[39, "torch.distributions.studentT.StudentT.rsample"]], "rsample() (torch.distributions.transformed_distribution.transformeddistribution method)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.rsample"]], "rsample() (torch.distributions.uniform.uniform method)": [[39, "torch.distributions.uniform.Uniform.rsample"]], "rsample() (torch.distributions.wishart.wishart method)": [[39, "torch.distributions.wishart.Wishart.rsample"]], "sample() (torch.distributions.bernoulli.bernoulli method)": [[39, "torch.distributions.bernoulli.Bernoulli.sample"]], "sample() (torch.distributions.binomial.binomial method)": [[39, "torch.distributions.binomial.Binomial.sample"]], "sample() (torch.distributions.categorical.categorical method)": [[39, "torch.distributions.categorical.Categorical.sample"]], "sample() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.sample"]], "sample() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.sample"]], "sample() (torch.distributions.geometric.geometric method)": [[39, "torch.distributions.geometric.Geometric.sample"]], "sample() (torch.distributions.independent.independent method)": [[39, "torch.distributions.independent.Independent.sample"]], "sample() (torch.distributions.lkj_cholesky.lkjcholesky method)": [[39, "torch.distributions.lkj_cholesky.LKJCholesky.sample"]], "sample() (torch.distributions.mixture_same_family.mixturesamefamily method)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.sample"]], "sample() (torch.distributions.multinomial.multinomial method)": [[39, "torch.distributions.multinomial.Multinomial.sample"]], "sample() (torch.distributions.negative_binomial.negativebinomial method)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.sample"]], "sample() (torch.distributions.normal.normal method)": [[39, "torch.distributions.normal.Normal.sample"]], "sample() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.sample"]], "sample() (torch.distributions.poisson.poisson method)": [[39, "torch.distributions.poisson.Poisson.sample"]], "sample() (torch.distributions.transformed_distribution.transformeddistribution method)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.sample"]], "sample() (torch.distributions.von_mises.vonmises method)": [[39, "torch.distributions.von_mises.VonMises.sample"]], "sample_n() (torch.distributions.distribution.distribution method)": [[39, "torch.distributions.distribution.Distribution.sample_n"]], "scale (torch.distributions.half_cauchy.halfcauchy property)": [[39, "torch.distributions.half_cauchy.HalfCauchy.scale"]], "scale (torch.distributions.half_normal.halfnormal property)": [[39, "torch.distributions.half_normal.HalfNormal.scale"]], "scale (torch.distributions.log_normal.lognormal property)": [[39, "torch.distributions.log_normal.LogNormal.scale"]], "scale_tril (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.scale_tril"]], "scale_tril (torch.distributions.multivariate_normal.multivariatenormal property)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"]], "scale_tril (torch.distributions.wishart.wishart property)": [[39, "torch.distributions.wishart.Wishart.scale_tril"]], "set_default_validate_args() (torch.distributions.distribution.distribution static method)": [[39, "torch.distributions.distribution.Distribution.set_default_validate_args"]], "sign (torch.distributions.transforms.transform property)": [[39, "torch.distributions.transforms.Transform.sign"]], "stack (in module torch.distributions.constraints)": [[39, "torch.distributions.constraints.stack"]], "stddev (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.stddev"]], "stddev (torch.distributions.distribution.distribution property)": [[39, "torch.distributions.distribution.Distribution.stddev"]], "stddev (torch.distributions.exponential.exponential property)": [[39, "torch.distributions.exponential.Exponential.stddev"]], "stddev (torch.distributions.gumbel.gumbel property)": [[39, "torch.distributions.gumbel.Gumbel.stddev"]], "stddev (torch.distributions.laplace.laplace property)": [[39, "torch.distributions.laplace.Laplace.stddev"]], "stddev (torch.distributions.normal.normal property)": [[39, "torch.distributions.normal.Normal.stddev"]], "stddev (torch.distributions.uniform.uniform property)": [[39, "torch.distributions.uniform.Uniform.stddev"]], "support (torch.distributions.bernoulli.bernoulli attribute)": [[39, "torch.distributions.bernoulli.Bernoulli.support"]], "support (torch.distributions.beta.beta attribute)": [[39, "torch.distributions.beta.Beta.support"]], "support (torch.distributions.binomial.binomial property)": [[39, "torch.distributions.binomial.Binomial.support"]], "support (torch.distributions.categorical.categorical property)": [[39, "torch.distributions.categorical.Categorical.support"]], "support (torch.distributions.cauchy.cauchy attribute)": [[39, "torch.distributions.cauchy.Cauchy.support"]], "support (torch.distributions.continuous_bernoulli.continuousbernoulli attribute)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.support"]], "support (torch.distributions.dirichlet.dirichlet attribute)": [[39, "torch.distributions.dirichlet.Dirichlet.support"]], "support (torch.distributions.distribution.distribution property)": [[39, "torch.distributions.distribution.Distribution.support"]], "support (torch.distributions.exponential.exponential attribute)": [[39, "torch.distributions.exponential.Exponential.support"]], "support (torch.distributions.fishersnedecor.fishersnedecor attribute)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.support"]], "support (torch.distributions.gamma.gamma attribute)": [[39, "torch.distributions.gamma.Gamma.support"]], "support (torch.distributions.geometric.geometric attribute)": [[39, "torch.distributions.geometric.Geometric.support"]], "support (torch.distributions.gumbel.gumbel attribute)": [[39, "torch.distributions.gumbel.Gumbel.support"]], "support (torch.distributions.half_cauchy.halfcauchy attribute)": [[39, "torch.distributions.half_cauchy.HalfCauchy.support"]], "support (torch.distributions.half_normal.halfnormal attribute)": [[39, "torch.distributions.half_normal.HalfNormal.support"]], "support (torch.distributions.independent.independent property)": [[39, "torch.distributions.independent.Independent.support"]], "support (torch.distributions.inverse_gamma.inversegamma attribute)": [[39, "torch.distributions.inverse_gamma.InverseGamma.support"]], "support (torch.distributions.kumaraswamy.kumaraswamy attribute)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy.support"]], "support (torch.distributions.laplace.laplace attribute)": [[39, "torch.distributions.laplace.Laplace.support"]], "support (torch.distributions.lkj_cholesky.lkjcholesky attribute)": [[39, "torch.distributions.lkj_cholesky.LKJCholesky.support"]], "support (torch.distributions.log_normal.lognormal attribute)": [[39, "torch.distributions.log_normal.LogNormal.support"]], "support (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal attribute)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.support"]], "support (torch.distributions.mixture_same_family.mixturesamefamily property)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.support"]], "support (torch.distributions.multinomial.multinomial property)": [[39, "torch.distributions.multinomial.Multinomial.support"]], "support (torch.distributions.multivariate_normal.multivariatenormal attribute)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.support"]], "support (torch.distributions.negative_binomial.negativebinomial attribute)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.support"]], "support (torch.distributions.normal.normal attribute)": [[39, "torch.distributions.normal.Normal.support"]], "support (torch.distributions.one_hot_categorical.onehotcategorical attribute)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.support"]], "support (torch.distributions.pareto.pareto property)": [[39, "torch.distributions.pareto.Pareto.support"]], "support (torch.distributions.poisson.poisson attribute)": [[39, "torch.distributions.poisson.Poisson.support"]], "support (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli attribute)": [[39, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.support"]], "support (torch.distributions.relaxed_bernoulli.relaxedbernoulli attribute)": [[39, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support"]], "support (torch.distributions.relaxed_categorical.relaxedonehotcategorical attribute)": [[39, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support"]], "support (torch.distributions.studentt.studentt attribute)": [[39, "torch.distributions.studentT.StudentT.support"]], "support (torch.distributions.transformed_distribution.transformeddistribution property)": [[39, "torch.distributions.transformed_distribution.TransformedDistribution.support"]], "support (torch.distributions.uniform.uniform property)": [[39, "torch.distributions.uniform.Uniform.support"]], "support (torch.distributions.von_mises.vonmises attribute)": [[39, "torch.distributions.von_mises.VonMises.support"]], "support (torch.distributions.weibull.weibull attribute)": [[39, "torch.distributions.weibull.Weibull.support"]], "support (torch.distributions.wishart.wishart attribute)": [[39, "torch.distributions.wishart.Wishart.support"]], "temperature (torch.distributions.relaxed_bernoulli.relaxedbernoulli property)": [[39, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature"]], "temperature (torch.distributions.relaxed_categorical.relaxedonehotcategorical property)": [[39, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature"]], "torch.distributions": [[39, "module-torch.distributions"]], "torch.distributions.bernoulli": [[39, "module-torch.distributions.bernoulli"]], "torch.distributions.beta": [[39, "module-torch.distributions.beta"]], "torch.distributions.binomial": [[39, "module-torch.distributions.binomial"]], "torch.distributions.categorical": [[39, "module-torch.distributions.categorical"]], "torch.distributions.cauchy": [[39, "module-torch.distributions.cauchy"]], "torch.distributions.chi2": [[39, "module-torch.distributions.chi2"]], "torch.distributions.constraint_registry": [[39, "module-torch.distributions.constraint_registry"]], "torch.distributions.constraints": [[39, "module-torch.distributions.constraints"]], "torch.distributions.continuous_bernoulli": [[39, "module-torch.distributions.continuous_bernoulli"]], "torch.distributions.dirichlet": [[39, "module-torch.distributions.dirichlet"]], "torch.distributions.distribution": [[39, "module-torch.distributions.distribution"]], "torch.distributions.exp_family": [[39, "module-torch.distributions.exp_family"]], "torch.distributions.exponential": [[39, "module-torch.distributions.exponential"]], "torch.distributions.fishersnedecor": [[39, "module-torch.distributions.fishersnedecor"]], "torch.distributions.gamma": [[39, "module-torch.distributions.gamma"]], "torch.distributions.geometric": [[39, "module-torch.distributions.geometric"]], "torch.distributions.gumbel": [[39, "module-torch.distributions.gumbel"]], "torch.distributions.half_cauchy": [[39, "module-torch.distributions.half_cauchy"]], "torch.distributions.half_normal": [[39, "module-torch.distributions.half_normal"]], "torch.distributions.independent": [[39, "module-torch.distributions.independent"]], "torch.distributions.inverse_gamma": [[39, "module-torch.distributions.inverse_gamma"]], "torch.distributions.kl": [[39, "module-torch.distributions.kl"]], "torch.distributions.kumaraswamy": [[39, "module-torch.distributions.kumaraswamy"]], "torch.distributions.laplace": [[39, "module-torch.distributions.laplace"]], "torch.distributions.lkj_cholesky": [[39, "module-torch.distributions.lkj_cholesky"]], "torch.distributions.log_normal": [[39, "module-torch.distributions.log_normal"]], "torch.distributions.logistic_normal": [[39, "module-torch.distributions.logistic_normal"]], "torch.distributions.lowrank_multivariate_normal": [[39, "module-torch.distributions.lowrank_multivariate_normal"]], "torch.distributions.mixture_same_family": [[39, "module-torch.distributions.mixture_same_family"]], "torch.distributions.multinomial": [[39, "module-torch.distributions.multinomial"]], "torch.distributions.multivariate_normal": [[39, "module-torch.distributions.multivariate_normal"]], "torch.distributions.negative_binomial": [[39, "module-torch.distributions.negative_binomial"]], "torch.distributions.normal": [[39, "module-torch.distributions.normal"]], "torch.distributions.one_hot_categorical": [[39, "module-torch.distributions.one_hot_categorical"]], "torch.distributions.pareto": [[39, "module-torch.distributions.pareto"]], "torch.distributions.poisson": [[39, "module-torch.distributions.poisson"]], "torch.distributions.relaxed_bernoulli": [[39, "module-torch.distributions.relaxed_bernoulli"]], "torch.distributions.relaxed_categorical": [[39, "module-torch.distributions.relaxed_categorical"]], "torch.distributions.studentt": [[39, "module-torch.distributions.studentT"]], "torch.distributions.transformed_distribution": [[39, "module-torch.distributions.transformed_distribution"]], "torch.distributions.transforms": [[39, "module-torch.distributions.transforms"]], "torch.distributions.uniform": [[39, "module-torch.distributions.uniform"]], "torch.distributions.utils": [[39, "module-torch.distributions.utils"]], "torch.distributions.von_mises": [[39, "module-torch.distributions.von_mises"]], "torch.distributions.weibull": [[39, "module-torch.distributions.weibull"]], "torch.distributions.wishart": [[39, "module-torch.distributions.wishart"]], "total_count (torch.distributions.multinomial.multinomial attribute)": [[39, "torch.distributions.multinomial.Multinomial.total_count"]], "variance (torch.distributions.bernoulli.bernoulli property)": [[39, "torch.distributions.bernoulli.Bernoulli.variance"]], "variance (torch.distributions.beta.beta property)": [[39, "torch.distributions.beta.Beta.variance"]], "variance (torch.distributions.binomial.binomial property)": [[39, "torch.distributions.binomial.Binomial.variance"]], "variance (torch.distributions.categorical.categorical property)": [[39, "torch.distributions.categorical.Categorical.variance"]], "variance (torch.distributions.cauchy.cauchy property)": [[39, "torch.distributions.cauchy.Cauchy.variance"]], "variance (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[39, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.variance"]], "variance (torch.distributions.dirichlet.dirichlet property)": [[39, "torch.distributions.dirichlet.Dirichlet.variance"]], "variance (torch.distributions.distribution.distribution property)": [[39, "torch.distributions.distribution.Distribution.variance"]], "variance (torch.distributions.exponential.exponential property)": [[39, "torch.distributions.exponential.Exponential.variance"]], "variance (torch.distributions.fishersnedecor.fishersnedecor property)": [[39, "torch.distributions.fishersnedecor.FisherSnedecor.variance"]], "variance (torch.distributions.gamma.gamma property)": [[39, "torch.distributions.gamma.Gamma.variance"]], "variance (torch.distributions.geometric.geometric property)": [[39, "torch.distributions.geometric.Geometric.variance"]], "variance (torch.distributions.gumbel.gumbel property)": [[39, "torch.distributions.gumbel.Gumbel.variance"]], "variance (torch.distributions.half_cauchy.halfcauchy property)": [[39, "torch.distributions.half_cauchy.HalfCauchy.variance"]], "variance (torch.distributions.half_normal.halfnormal property)": [[39, "torch.distributions.half_normal.HalfNormal.variance"]], "variance (torch.distributions.independent.independent property)": [[39, "torch.distributions.independent.Independent.variance"]], "variance (torch.distributions.inverse_gamma.inversegamma property)": [[39, "torch.distributions.inverse_gamma.InverseGamma.variance"]], "variance (torch.distributions.kumaraswamy.kumaraswamy property)": [[39, "torch.distributions.kumaraswamy.Kumaraswamy.variance"]], "variance (torch.distributions.laplace.laplace property)": [[39, "torch.distributions.laplace.Laplace.variance"]], "variance (torch.distributions.log_normal.lognormal property)": [[39, "torch.distributions.log_normal.LogNormal.variance"]], "variance (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[39, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.variance"]], "variance (torch.distributions.mixture_same_family.mixturesamefamily property)": [[39, "torch.distributions.mixture_same_family.MixtureSameFamily.variance"]], "variance (torch.distributions.multinomial.multinomial property)": [[39, "torch.distributions.multinomial.Multinomial.variance"]], "variance (torch.distributions.multivariate_normal.multivariatenormal property)": [[39, "torch.distributions.multivariate_normal.MultivariateNormal.variance"]], "variance (torch.distributions.negative_binomial.negativebinomial property)": [[39, "torch.distributions.negative_binomial.NegativeBinomial.variance"]], "variance (torch.distributions.normal.normal property)": [[39, "torch.distributions.normal.Normal.variance"]], "variance (torch.distributions.one_hot_categorical.onehotcategorical property)": [[39, "torch.distributions.one_hot_categorical.OneHotCategorical.variance"]], "variance (torch.distributions.pareto.pareto property)": [[39, "torch.distributions.pareto.Pareto.variance"]], "variance (torch.distributions.poisson.poisson property)": [[39, "torch.distributions.poisson.Poisson.variance"]], "variance (torch.distributions.studentt.studentt property)": [[39, "torch.distributions.studentT.StudentT.variance"]], "variance (torch.distributions.uniform.uniform property)": [[39, "torch.distributions.uniform.Uniform.variance"]], "variance (torch.distributions.von_mises.vonmises property)": [[39, "torch.distributions.von_mises.VonMises.variance"]], "variance (torch.distributions.weibull.weibull property)": [[39, "torch.distributions.weibull.Weibull.variance"]], "variance (torch.distributions.wishart.wishart property)": [[39, "torch.distributions.wishart.Wishart.variance"]], "from_dlpack() (in module torch.utils.dlpack)": [[40, "torch.utils.dlpack.from_dlpack"]], "to_dlpack() (in module torch.utils.dlpack)": [[40, "torch.utils.dlpack.to_dlpack"]], "elasticagent (class in torch.distributed.elastic.agent.server)": [[41, "torch.distributed.elastic.agent.server.ElasticAgent"]], "healthcheckserver (class in torch.distributed.elastic.agent.server.health_check_server)": [[41, "torch.distributed.elastic.agent.server.health_check_server.HealthCheckServer"]], "localelasticagent (class in torch.distributed.elastic.agent.server.local_elastic_agent)": [[41, "torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent"]], "runresult (class in torch.distributed.elastic.agent.server.api)": [[41, "torch.distributed.elastic.agent.server.api.RunResult"]], "simpleelasticagent (class in torch.distributed.elastic.agent.server)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent"]], "worker (class in torch.distributed.elastic.agent.server)": [[41, "torch.distributed.elastic.agent.server.Worker"]], "workergroup (class in torch.distributed.elastic.agent.server)": [[41, "torch.distributed.elastic.agent.server.WorkerGroup"]], "workerspec (class in torch.distributed.elastic.agent.server)": [[41, "torch.distributed.elastic.agent.server.WorkerSpec"]], "workerstate (class in torch.distributed.elastic.agent.server)": [[41, "torch.distributed.elastic.agent.server.WorkerState"]], "_assign_worker_ranks() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._assign_worker_ranks"]], "_exit_barrier() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._exit_barrier"]], "_initialize_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._initialize_workers"]], "_monitor_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._monitor_workers"]], "_rendezvous() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._rendezvous"]], "_restart_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._restart_workers"]], "_shutdown() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._shutdown"]], "_start_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._start_workers"]], "_stop_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[41, "torch.distributed.elastic.agent.server.SimpleElasticAgent._stop_workers"]], "create_healthcheck_server() (in module torch.distributed.elastic.agent.server.health_check_server)": [[41, "torch.distributed.elastic.agent.server.health_check_server.create_healthcheck_server"]], "get_entrypoint_name() (torch.distributed.elastic.agent.server.workerspec method)": [[41, "torch.distributed.elastic.agent.server.WorkerSpec.get_entrypoint_name"]], "get_worker_group() (torch.distributed.elastic.agent.server.elasticagent method)": [[41, "torch.distributed.elastic.agent.server.ElasticAgent.get_worker_group"]], "is_running() (torch.distributed.elastic.agent.server.workerstate static method)": [[41, "torch.distributed.elastic.agent.server.WorkerState.is_running"]], "run() (torch.distributed.elastic.agent.server.elasticagent method)": [[41, "torch.distributed.elastic.agent.server.ElasticAgent.run"]], "start() (torch.distributed.elastic.agent.server.health_check_server.healthcheckserver method)": [[41, "torch.distributed.elastic.agent.server.health_check_server.HealthCheckServer.start"]], "stop() (torch.distributed.elastic.agent.server.health_check_server.healthcheckserver method)": [[41, "torch.distributed.elastic.agent.server.health_check_server.HealthCheckServer.stop"]], "torch.distributed.elastic.agent": [[41, "module-torch.distributed.elastic.agent"]], "torch.distributed.elastic.agent.server": [[41, "module-torch.distributed.elastic.agent.server"]], "torch.distributed.elastic.agent.server.health_check_server": [[41, "module-torch.distributed.elastic.agent.server.health_check_server"]], "torch.distributed.elastic.control_plane": [[42, "module-torch.distributed.elastic.control_plane"]], "worker_main() (in module torch.distributed.elastic.control_plane)": [[42, "torch.distributed.elastic.control_plane.worker_main"]], "childfailederror (class in torch.distributed.elastic.multiprocessing.errors)": [[44, "torch.distributed.elastic.multiprocessing.errors.ChildFailedError"]], "errorhandler (class in torch.distributed.elastic.multiprocessing.errors)": [[44, "torch.distributed.elastic.multiprocessing.errors.ErrorHandler"]], "processfailure (class in torch.distributed.elastic.multiprocessing.errors)": [[44, "torch.distributed.elastic.multiprocessing.errors.ProcessFailure"]], "record() (in module torch.distributed.elastic.multiprocessing.errors)": [[44, "torch.distributed.elastic.multiprocessing.errors.record"]], "torch.distributed.elastic.multiprocessing.errors": [[44, "module-torch.distributed.elastic.multiprocessing.errors"]], "event (class in torch.distributed.elastic.events.api)": [[45, "torch.distributed.elastic.events.api.Event"]], "eventmetadatavalue (in module torch.distributed.elastic.events.api)": [[45, "torch.distributed.elastic.events.api.EventMetadataValue"]], "eventsource (class in torch.distributed.elastic.events.api)": [[45, "torch.distributed.elastic.events.api.EventSource"]], "construct_and_record_rdzv_event() (in module torch.distributed.elastic.events)": [[45, "torch.distributed.elastic.events.construct_and_record_rdzv_event"]], "get_logging_handler() (in module torch.distributed.elastic.events)": [[45, "torch.distributed.elastic.events.get_logging_handler"]], "record() (in module torch.distributed.elastic.events)": [[45, "torch.distributed.elastic.events.record"]], "torch.distributed.elastic.events": [[45, "module-torch.distributed.elastic.events"]], "consolemetrichandler (class in torch.distributed.elastic.metrics.api)": [[48, "torch.distributed.elastic.metrics.api.ConsoleMetricHandler"]], "metrichandler (class in torch.distributed.elastic.metrics.api)": [[48, "torch.distributed.elastic.metrics.api.MetricHandler"]], "nullmetrichandler (class in torch.distributed.elastic.metrics.api)": [[48, "torch.distributed.elastic.metrics.api.NullMetricHandler"]], "configure() (in module torch.distributed.elastic.metrics)": [[48, "torch.distributed.elastic.metrics.configure"]], "prof() (in module torch.distributed.elastic.metrics)": [[48, "torch.distributed.elastic.metrics.prof"]], "put_metric() (in module torch.distributed.elastic.metrics)": [[48, "torch.distributed.elastic.metrics.put_metric"]], "torch.distributed.elastic.metrics": [[48, "module-torch.distributed.elastic.metrics"]], "defaultlogsspecs (class in torch.distributed.elastic.multiprocessing.api)": [[49, "torch.distributed.elastic.multiprocessing.api.DefaultLogsSpecs"]], "logsdest (class in torch.distributed.elastic.multiprocessing.api)": [[49, "torch.distributed.elastic.multiprocessing.api.LogsDest"]], "logsspecs (class in torch.distributed.elastic.multiprocessing.api)": [[49, "torch.distributed.elastic.multiprocessing.api.LogsSpecs"]], "multiprocesscontext (class in torch.distributed.elastic.multiprocessing.api)": [[49, "torch.distributed.elastic.multiprocessing.api.MultiprocessContext"]], "pcontext (class in torch.distributed.elastic.multiprocessing.api)": [[49, "torch.distributed.elastic.multiprocessing.api.PContext"]], "runprocsresult (class in torch.distributed.elastic.multiprocessing.api)": [[49, "torch.distributed.elastic.multiprocessing.api.RunProcsResult"]], "subprocesscontext (class in torch.distributed.elastic.multiprocessing.api)": [[49, "torch.distributed.elastic.multiprocessing.api.SubprocessContext"]], "reify() (torch.distributed.elastic.multiprocessing.api.defaultlogsspecs method)": [[49, "torch.distributed.elastic.multiprocessing.api.DefaultLogsSpecs.reify"]], "reify() (torch.distributed.elastic.multiprocessing.api.logsspecs method)": [[49, "torch.distributed.elastic.multiprocessing.api.LogsSpecs.reify"]], "start_processes() (in module torch.distributed.elastic.multiprocessing)": [[49, "torch.distributed.elastic.multiprocessing.start_processes"]], "torch.distributed.elastic.multiprocessing": [[49, "module-torch.distributed.elastic.multiprocessing"]], "c10drendezvousbackend (class in torch.distributed.elastic.rendezvous.c10d_rendezvous_backend)": [[51, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend"]], "dynamicrendezvoushandler (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler"]], "etcdserver (class in torch.distributed.elastic.rendezvous.etcd_server)": [[51, "torch.distributed.elastic.rendezvous.etcd_server.EtcdServer"]], "rendezvousbackend (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend"]], "rendezvousclosederror (class in torch.distributed.elastic.rendezvous.api)": [[51, "torch.distributed.elastic.rendezvous.api.RendezvousClosedError"]], "rendezvousconnectionerror (class in torch.distributed.elastic.rendezvous.api)": [[51, "torch.distributed.elastic.rendezvous.api.RendezvousConnectionError"]], "rendezvouserror (class in torch.distributed.elastic.rendezvous.api)": [[51, "torch.distributed.elastic.rendezvous.api.RendezvousError"]], "rendezvousgracefulexiterror (class in torch.distributed.elastic.rendezvous.api)": [[51, "torch.distributed.elastic.rendezvous.api.RendezvousGracefulExitError"]], "rendezvoushandler (class in torch.distributed.elastic.rendezvous)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler"]], "rendezvoushandlerregistry (class in torch.distributed.elastic.rendezvous)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry"]], "rendezvousinfo (class in torch.distributed.elastic.rendezvous)": [[51, "torch.distributed.elastic.rendezvous.RendezvousInfo"]], "rendezvousparameters (class in torch.distributed.elastic.rendezvous)": [[51, "torch.distributed.elastic.rendezvous.RendezvousParameters"]], "rendezvousstateerror (class in torch.distributed.elastic.rendezvous.api)": [[51, "torch.distributed.elastic.rendezvous.api.RendezvousStateError"]], "rendezvousstoreinfo (class in torch.distributed.elastic.rendezvous.api)": [[51, "torch.distributed.elastic.rendezvous.api.RendezvousStoreInfo"]], "rendezvoustimeout (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout"]], "rendezvoustimeouterror (class in torch.distributed.elastic.rendezvous.api)": [[51, "torch.distributed.elastic.rendezvous.api.RendezvousTimeoutError"]], "build() (torch.distributed.elastic.rendezvous.api.rendezvousstoreinfo static method)": [[51, "torch.distributed.elastic.rendezvous.api.RendezvousStoreInfo.build"]], "close (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvoustimeout property)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.close"]], "create_backend() (in module torch.distributed.elastic.rendezvous.c10d_rendezvous_backend)": [[51, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.create_backend"]], "create_handler() (in module torch.distributed.elastic.rendezvous.dynamic_rendezvous)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.create_handler"]], "from_backend() (torch.distributed.elastic.rendezvous.dynamic_rendezvous.dynamicrendezvoushandler class method)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler.from_backend"]], "get() (torch.distributed.elastic.rendezvous.rendezvousparameters method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousParameters.get"]], "get_as_bool() (torch.distributed.elastic.rendezvous.rendezvousparameters method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousParameters.get_as_bool"]], "get_as_int() (torch.distributed.elastic.rendezvous.rendezvousparameters method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousParameters.get_as_int"]], "get_backend() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler.get_backend"]], "get_run_id() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler.get_run_id"]], "get_state() (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.c10drendezvousbackend method)": [[51, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.get_state"]], "get_state() (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvousbackend method)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.get_state"]], "heartbeat (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvoustimeout property)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.heartbeat"]], "is_closed() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler.is_closed"]], "join (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvoustimeout property)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.join"]], "last_call (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvoustimeout property)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.last_call"]], "name (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.c10drendezvousbackend property)": [[51, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.name"]], "name (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvousbackend property)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.name"]], "next_rendezvous() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler.next_rendezvous"]], "num_nodes_waiting() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler.num_nodes_waiting"]], "set_closed() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler.set_closed"]], "set_state() (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.c10drendezvousbackend method)": [[51, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.set_state"]], "set_state() (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvousbackend method)": [[51, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.set_state"]], "shutdown() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler.shutdown"]], "torch.distributed.elastic.rendezvous": [[51, "module-torch.distributed.elastic.rendezvous"]], "torch.distributed.elastic.rendezvous.registry": [[51, "module-torch.distributed.elastic.rendezvous.registry"]], "use_agent_store (torch.distributed.elastic.rendezvous.rendezvoushandler property)": [[51, "torch.distributed.elastic.rendezvous.RendezvousHandler.use_agent_store"]], "torch.distributed.run": [[52, "module-torch.distributed.run"]], "subprocesshandler (class in torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler)": [[53, "torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler.SubprocessHandler"]], "get_subprocess_handler() (in module torch.distributed.elastic.multiprocessing.subprocess_handler.handlers)": [[53, "torch.distributed.elastic.multiprocessing.subprocess_handler.handlers.get_subprocess_handler"]], "torch.distributed.elastic.multiprocessing.subprocess_handler": [[53, "module-torch.distributed.elastic.multiprocessing.subprocess_handler"]], "torch.distributed.elastic.multiprocessing.subprocess_handler.handlers": [[53, "module-torch.distributed.elastic.multiprocessing.subprocess_handler.handlers"]], "torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler": [[53, "module-torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler"]], "filetimerclient (class in torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.FileTimerClient"]], "filetimerserver (class in torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.FileTimerServer"]], "localtimerclient (class in torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.LocalTimerClient"]], "localtimerserver (class in torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.LocalTimerServer"]], "timerclient (class in torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.TimerClient"]], "timerrequest (class in torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.TimerRequest"]], "timerserver (class in torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.TimerServer"]], "acquire() (torch.distributed.elastic.timer.timerclient method)": [[54, "torch.distributed.elastic.timer.TimerClient.acquire"]], "clear_timers() (torch.distributed.elastic.timer.timerserver method)": [[54, "torch.distributed.elastic.timer.TimerServer.clear_timers"]], "configure() (in module torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.configure"]], "expires() (in module torch.distributed.elastic.timer)": [[54, "torch.distributed.elastic.timer.expires"]], "get_expired_timers() (torch.distributed.elastic.timer.timerserver method)": [[54, "torch.distributed.elastic.timer.TimerServer.get_expired_timers"]], "log_debug_info_for_expired_timers() (in module torch.distributed.elastic.timer.debug_info_logging)": [[54, "torch.distributed.elastic.timer.debug_info_logging.log_debug_info_for_expired_timers"]], "register_timers() (torch.distributed.elastic.timer.timerserver method)": [[54, "torch.distributed.elastic.timer.TimerServer.register_timers"]], "release() (torch.distributed.elastic.timer.timerclient method)": [[54, "torch.distributed.elastic.timer.TimerClient.release"]], "torch.distributed.elastic.timer": [[54, "module-torch.distributed.elastic.timer"]], "torch.distributed.elastic.timer.debug_info_logging": [[54, "module-torch.distributed.elastic.timer.debug_info_logging"]], "constraint (in module torch.export)": [[56, "torch.export.Constraint"]], "customdecomptable (class in torch.export.decomp_utils)": [[56, "torch.export.decomp_utils.CustomDecompTable"]], "customobjargument (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.CustomObjArgument"]], "dim (class in torch.export.dynamic_shapes)": [[56, "torch.export.dynamic_shapes.Dim"]], "exportbackwardsignature (class in torch.export)": [[56, "torch.export.ExportBackwardSignature"]], "exportgraphsignature (class in torch.export)": [[56, "torch.export.ExportGraphSignature"]], "exportgraphsignature (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.ExportGraphSignature"]], "exportedprogram (class in torch.export)": [[56, "torch.export.ExportedProgram"]], "flatargsadapter (class in torch.export.unflatten)": [[56, "torch.export.unflatten.FlatArgsAdapter"]], "inputkind (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.InputKind"]], "inputspec (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.InputSpec"]], "interpretermodule (class in torch.export.unflatten)": [[56, "torch.export.unflatten.InterpreterModule"]], "interpretermoduledispatcher (class in torch.export.unflatten)": [[56, "torch.export.unflatten.InterpreterModuleDispatcher"]], "modulecallentry (class in torch.export)": [[56, "torch.export.ModuleCallEntry"]], "modulecallsignature (class in torch.export)": [[56, "torch.export.ModuleCallSignature"]], "outputkind (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.OutputKind"]], "outputspec (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.OutputSpec"]], "shapescollection (class in torch.export.dynamic_shapes)": [[56, "torch.export.dynamic_shapes.ShapesCollection"]], "symboolargument (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.SymBoolArgument"]], "symfloatargument (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.SymFloatArgument"]], "symintargument (class in torch.export.graph_signature)": [[56, "torch.export.graph_signature.SymIntArgument"]], "adapt() (torch.export.unflatten.flatargsadapter method)": [[56, "torch.export.unflatten.FlatArgsAdapter.adapt"]], "buffers() (torch.export.exportedprogram method)": [[56, "torch.export.ExportedProgram.buffers"]], "copy() (torch.export.decomp_utils.customdecomptable method)": [[56, "torch.export.decomp_utils.CustomDecompTable.copy"]], "default_decompositions() (in module torch.export.exported_program)": [[56, "torch.export.exported_program.default_decompositions"]], "dims() (in module torch.export)": [[56, "torch.export.dims"]], "dynamic_shapes() (torch.export.dynamic_shapes.shapescollection method)": [[56, "torch.export.dynamic_shapes.ShapesCollection.dynamic_shapes"]], "export() (in module torch.export)": [[56, "torch.export.export"]], "get_replace_hook() (torch.export.graph_signature.exportgraphsignature method)": [[56, "torch.export.graph_signature.ExportGraphSignature.get_replace_hook"]], "items() (torch.export.decomp_utils.customdecomptable method)": [[56, "torch.export.decomp_utils.CustomDecompTable.items"]], "keys() (torch.export.decomp_utils.customdecomptable method)": [[56, "torch.export.decomp_utils.CustomDecompTable.keys"]], "load() (in module torch.export)": [[56, "torch.export.load"]], "materialize() (torch.export.decomp_utils.customdecomptable method)": [[56, "torch.export.decomp_utils.CustomDecompTable.materialize"]], "module() (torch.export.exportedprogram method)": [[56, "torch.export.ExportedProgram.module"]], "move_to_device_pass() (in module torch.export.passes)": [[56, "torch.export.passes.move_to_device_pass"]], "named_buffers() (torch.export.exportedprogram method)": [[56, "torch.export.ExportedProgram.named_buffers"]], "named_parameters() (torch.export.exportedprogram method)": [[56, "torch.export.ExportedProgram.named_parameters"]], "parameters() (torch.export.exportedprogram method)": [[56, "torch.export.ExportedProgram.parameters"]], "pop() (torch.export.decomp_utils.customdecomptable method)": [[56, "torch.export.decomp_utils.CustomDecompTable.pop"]], "refine_dynamic_shapes_from_suggested_fixes() (in module torch.export.dynamic_shapes)": [[56, "torch.export.dynamic_shapes.refine_dynamic_shapes_from_suggested_fixes"]], "register_dataclass() (in module torch.export)": [[56, "torch.export.register_dataclass"]], "replace_all_uses() (torch.export.graph_signature.exportgraphsignature method)": [[56, "torch.export.graph_signature.ExportGraphSignature.replace_all_uses"]], "run_decompositions() (torch.export.exportedprogram method)": [[56, "torch.export.ExportedProgram.run_decompositions"]], "save() (in module torch.export)": [[56, "torch.export.save"]], "torch.export": [[56, "module-torch.export"]], "torch.export.custom_obj": [[56, "module-torch.export.custom_obj"]], "torch.export.custom_ops": [[56, "module-torch.export.custom_ops"]], "torch.export.decomp_utils": [[56, "module-torch.export.decomp_utils"]], "torch.export.dynamic_shapes": [[56, "module-torch.export.dynamic_shapes"]], "torch.export.experimental": [[56, "module-torch.export.experimental"]], "torch.export.exported_program": [[56, "module-torch.export.exported_program"]], "torch.export.graph_signature": [[56, "module-torch.export.graph_signature"]], "torch.export.passes": [[56, "module-torch.export.passes"]], "torch.export.unflatten": [[56, "module-torch.export.unflatten"]], "unflatten() (in module torch.export.unflatten)": [[56, "torch.export.unflatten.unflatten"]], "update() (torch.export.decomp_utils.customdecomptable method)": [[56, "torch.export.decomp_utils.CustomDecompTable.update"]], "torch.fft": [[59, "module-torch.fft"]], "backwardprefetch (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.BackwardPrefetch"]], "cpuoffload (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.CPUOffload"]], "fulloptimstatedictconfig (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.FullOptimStateDictConfig"]], "fullstatedictconfig (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.FullStateDictConfig"]], "fullyshardeddataparallel (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel"]], "localoptimstatedictconfig (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.LocalOptimStateDictConfig"]], "localstatedictconfig (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.LocalStateDictConfig"]], "mixedprecision (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.MixedPrecision"]], "optimstatedictconfig (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.OptimStateDictConfig"]], "shardedoptimstatedictconfig (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.ShardedOptimStateDictConfig"]], "shardedstatedictconfig (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.ShardedStateDictConfig"]], "shardingstrategy (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.ShardingStrategy"]], "statedictconfig (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.StateDictConfig"]], "statedictsettings (class in torch.distributed.fsdp)": [[60, "torch.distributed.fsdp.StateDictSettings"]], "apply() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.apply"]], "check_is_root() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.check_is_root"]], "clip_grad_norm_() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.clip_grad_norm_"]], "flatten_sharded_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.flatten_sharded_optim_state_dict"]], "forward() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.forward"]], "fsdp_modules() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.fsdp_modules"]], "full_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.full_optim_state_dict"]], "get_state_dict_type() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.get_state_dict_type"]], "module (torch.distributed.fsdp.fullyshardeddataparallel property)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.module"]], "named_buffers() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.named_buffers"]], "named_parameters() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.named_parameters"]], "no_sync() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.no_sync"]], "optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict"]], "optim_state_dict_to_load() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict_to_load"]], "register_comm_hook() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.register_comm_hook"]], "rekey_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.rekey_optim_state_dict"]], "scatter_full_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.scatter_full_optim_state_dict"]], "set_state_dict_type() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.set_state_dict_type"]], "shard_full_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.shard_full_optim_state_dict"]], "sharded_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.sharded_optim_state_dict"]], "state_dict_type() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type"]], "summon_full_params() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[60, "torch.distributed.fsdp.FullyShardedDataParallel.summon_full_params"]], "torch.distributed.fsdp": [[60, "module-torch.distributed.fsdp"]], "torch.func": [[62, "module-torch.func"]], "get_overwrite_module_params_on_conversion() (in module torch.__future__)": [[67, "torch.__future__.get_overwrite_module_params_on_conversion"]], "get_swap_module_params_on_conversion() (in module torch.__future__)": [[67, "torch.__future__.get_swap_module_params_on_conversion"]], "set_overwrite_module_params_on_conversion() (in module torch.__future__)": [[67, "torch.__future__.set_overwrite_module_params_on_conversion"]], "set_swap_module_params_on_conversion() (in module torch.__future__)": [[67, "torch.__future__.set_swap_module_params_on_conversion"]], "torch.__future__": [[67, "module-torch.__future__"]], "future (class in torch.futures)": [[68, "torch.futures.Future"]], "add_done_callback() (torch.futures.future method)": [[68, "torch.futures.Future.add_done_callback"]], "collect_all() (in module torch.futures)": [[68, "torch.futures.collect_all"]], "done() (torch.futures.future method)": [[68, "torch.futures.Future.done"]], "set_exception() (torch.futures.future method)": [[68, "torch.futures.Future.set_exception"]], "set_result() (torch.futures.future method)": [[68, "torch.futures.Future.set_result"]], "then() (torch.futures.future method)": [[68, "torch.futures.Future.then"]], "torch.futures": [[68, "module-torch.futures"]], "value() (torch.futures.future method)": [[68, "torch.futures.Future.value"]], "wait() (torch.futures.future method)": [[68, "torch.futures.Future.wait"]], "wait_all() (in module torch.futures)": [[68, "torch.futures.wait_all"]], "graph (class in torch.fx)": [[69, "torch.fx.Graph"]], "graphmodule (class in torch.fx)": [[69, "torch.fx.GraphModule"]], "interpreter (class in torch.fx)": [[69, "torch.fx.Interpreter"]], "node (class in torch.fx)": [[69, "torch.fx.Node"]], "proxy (class in torch.fx)": [[69, "torch.fx.Proxy"]], "tracer (class in torch.fx)": [[69, "torch.fx.Tracer"]], "transformer (class in torch.fx)": [[69, "torch.fx.Transformer"]], "__init__() (torch.fx.graph method)": [[69, "torch.fx.Graph.__init__"]], "__init__() (torch.fx.graphmodule method)": [[69, "torch.fx.GraphModule.__init__"]], "add_submodule() (torch.fx.graphmodule method)": [[69, "torch.fx.GraphModule.add_submodule"]], "all_input_nodes (torch.fx.node property)": [[69, "torch.fx.Node.all_input_nodes"]], "append() (torch.fx.node method)": [[69, "torch.fx.Node.append"]], "args (torch.fx.node property)": [[69, "torch.fx.Node.args"]], "boxed_run() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.boxed_run"]], "call_function() (torch.fx.graph method)": [[69, "torch.fx.Graph.call_function"]], "call_function() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.call_function"]], "call_function() (torch.fx.transformer method)": [[69, "torch.fx.Transformer.call_function"]], "call_method() (torch.fx.graph method)": [[69, "torch.fx.Graph.call_method"]], "call_method() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.call_method"]], "call_module() (torch.fx.graph method)": [[69, "torch.fx.Graph.call_module"]], "call_module() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.call_module"]], "call_module() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.call_module"]], "call_module() (torch.fx.transformer method)": [[69, "torch.fx.Transformer.call_module"]], "code (torch.fx.graphmodule property)": [[69, "torch.fx.GraphModule.code"]], "create_arg() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.create_arg"]], "create_args_for_root() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.create_args_for_root"]], "create_node() (torch.fx.graph method)": [[69, "torch.fx.Graph.create_node"]], "create_node() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.create_node"]], "create_proxy() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.create_proxy"]], "delete_all_unused_submodules() (torch.fx.graphmodule method)": [[69, "torch.fx.GraphModule.delete_all_unused_submodules"]], "delete_submodule() (torch.fx.graphmodule method)": [[69, "torch.fx.GraphModule.delete_submodule"]], "eliminate_dead_code() (torch.fx.graph method)": [[69, "torch.fx.Graph.eliminate_dead_code"]], "erase_node() (torch.fx.graph method)": [[69, "torch.fx.Graph.erase_node"]], "fetch_args_kwargs_from_env() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.fetch_args_kwargs_from_env"]], "fetch_attr() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.fetch_attr"]], "find_nodes() (torch.fx.graph method)": [[69, "torch.fx.Graph.find_nodes"]], "format_node() (torch.fx.node method)": [[69, "torch.fx.Node.format_node"]], "get_attr() (torch.fx.graph method)": [[69, "torch.fx.Graph.get_attr"]], "get_attr() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.get_attr"]], "get_attr() (torch.fx.transformer method)": [[69, "torch.fx.Transformer.get_attr"]], "get_fresh_qualname() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.get_fresh_qualname"]], "getattr() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.getattr"]], "graph (torch.fx.graphmodule property)": [[69, "torch.fx.GraphModule.graph"]], "graph_copy() (torch.fx.graph method)": [[69, "torch.fx.Graph.graph_copy"]], "insert_arg() (torch.fx.node method)": [[69, "torch.fx.Node.insert_arg"]], "inserting_after() (torch.fx.graph method)": [[69, "torch.fx.Graph.inserting_after"]], "inserting_before() (torch.fx.graph method)": [[69, "torch.fx.Graph.inserting_before"]], "is_impure() (torch.fx.node method)": [[69, "torch.fx.Node.is_impure"]], "is_leaf_module() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.is_leaf_module"]], "iter() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.iter"]], "keys() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.keys"]], "kwargs (torch.fx.node property)": [[69, "torch.fx.Node.kwargs"]], "lint() (torch.fx.graph method)": [[69, "torch.fx.Graph.lint"]], "map_nodes_to_values() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.map_nodes_to_values"]], "next (torch.fx.node property)": [[69, "torch.fx.Node.next"]], "node_copy() (torch.fx.graph method)": [[69, "torch.fx.Graph.node_copy"]], "nodes (torch.fx.graph property)": [[69, "torch.fx.Graph.nodes"]], "normalized_arguments() (torch.fx.node method)": [[69, "torch.fx.Node.normalized_arguments"]], "on_generate_code() (torch.fx.graph method)": [[69, "torch.fx.Graph.on_generate_code"]], "output() (torch.fx.graph method)": [[69, "torch.fx.Graph.output"]], "output() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.output"]], "output_node() (torch.fx.graph method)": [[69, "torch.fx.Graph.output_node"]], "path_of_module() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.path_of_module"]], "placeholder() (torch.fx.graph method)": [[69, "torch.fx.Graph.placeholder"]], "placeholder() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.placeholder"]], "placeholder() (torch.fx.transformer method)": [[69, "torch.fx.Transformer.placeholder"]], "prepend() (torch.fx.node method)": [[69, "torch.fx.Node.prepend"]], "prev (torch.fx.node property)": [[69, "torch.fx.Node.prev"]], "print_readable() (torch.fx.graphmodule method)": [[69, "torch.fx.GraphModule.print_readable"]], "print_tabular() (torch.fx.graph method)": [[69, "torch.fx.Graph.print_tabular"]], "process_inputs() (torch.fx.graph method)": [[69, "torch.fx.Graph.process_inputs"]], "process_outputs() (torch.fx.graph method)": [[69, "torch.fx.Graph.process_outputs"]], "proxy() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.proxy"]], "python_code() (torch.fx.graph method)": [[69, "torch.fx.Graph.python_code"]], "recompile() (torch.fx.graphmodule method)": [[69, "torch.fx.GraphModule.recompile"]], "replace_all_uses_with() (torch.fx.node method)": [[69, "torch.fx.Node.replace_all_uses_with"]], "replace_input_with() (torch.fx.node method)": [[69, "torch.fx.Node.replace_input_with"]], "replace_pattern() (in module torch.fx)": [[69, "torch.fx.replace_pattern"]], "run() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.run"]], "run_node() (torch.fx.interpreter method)": [[69, "torch.fx.Interpreter.run_node"]], "set_codegen() (torch.fx.graph method)": [[69, "torch.fx.Graph.set_codegen"]], "stack_trace (torch.fx.node property)": [[69, "torch.fx.Node.stack_trace"]], "symbolic_trace() (in module torch.fx)": [[69, "torch.fx.symbolic_trace"]], "to_bool() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.to_bool"]], "to_folder() (torch.fx.graphmodule method)": [[69, "torch.fx.GraphModule.to_folder"]], "torch.fx": [[69, "module-torch.fx"]], "torch.fx.annotate": [[69, "module-torch.fx.annotate"]], "torch.fx.config": [[69, "module-torch.fx.config"]], "torch.fx.experimental": [[69, "module-torch.fx.experimental"]], "torch.fx.experimental.accelerator_partitioner": [[69, "module-torch.fx.experimental.accelerator_partitioner"]], "torch.fx.experimental.const_fold": [[69, "module-torch.fx.experimental.const_fold"]], "torch.fx.experimental.debug": [[69, "module-torch.fx.experimental.debug"]], "torch.fx.experimental.graph_gradual_typechecker": [[69, "module-torch.fx.experimental.graph_gradual_typechecker"]], "torch.fx.experimental.merge_matmul": [[69, "module-torch.fx.experimental.merge_matmul"]], "torch.fx.experimental.meta_tracer": [[69, "module-torch.fx.experimental.meta_tracer"]], "torch.fx.experimental.migrate_gradual_types": [[69, "module-torch.fx.experimental.migrate_gradual_types"]], "torch.fx.experimental.migrate_gradual_types.constraint": [[69, "module-torch.fx.experimental.migrate_gradual_types.constraint"]], "torch.fx.experimental.migrate_gradual_types.constraint_generator": [[69, "module-torch.fx.experimental.migrate_gradual_types.constraint_generator"]], "torch.fx.experimental.migrate_gradual_types.constraint_transformation": [[69, "module-torch.fx.experimental.migrate_gradual_types.constraint_transformation"]], "torch.fx.experimental.migrate_gradual_types.operation": [[69, "module-torch.fx.experimental.migrate_gradual_types.operation"]], "torch.fx.experimental.migrate_gradual_types.transform_to_z3": [[69, "module-torch.fx.experimental.migrate_gradual_types.transform_to_z3"]], "torch.fx.experimental.migrate_gradual_types.util": [[69, "module-torch.fx.experimental.migrate_gradual_types.util"]], "torch.fx.experimental.migrate_gradual_types.z3_types": [[69, "module-torch.fx.experimental.migrate_gradual_types.z3_types"]], "torch.fx.experimental.normalize": [[69, "module-torch.fx.experimental.normalize"]], "torch.fx.experimental.optimization": [[69, "module-torch.fx.experimental.optimization"]], "torch.fx.experimental.partitioner_utils": [[69, "module-torch.fx.experimental.partitioner_utils"]], "torch.fx.experimental.recording": [[69, "module-torch.fx.experimental.recording"]], "torch.fx.experimental.refinement_types": [[69, "module-torch.fx.experimental.refinement_types"]], "torch.fx.experimental.rewriter": [[69, "module-torch.fx.experimental.rewriter"]], "torch.fx.experimental.schema_type_annotation": [[69, "module-torch.fx.experimental.schema_type_annotation"]], "torch.fx.experimental.sym_node": [[69, "module-torch.fx.experimental.sym_node"]], "torch.fx.experimental.unification": [[69, "module-torch.fx.experimental.unification"]], "torch.fx.experimental.unification.core": [[69, "module-torch.fx.experimental.unification.core"]], "torch.fx.experimental.unification.dispatch": [[69, "module-torch.fx.experimental.unification.dispatch"]], "torch.fx.experimental.unification.match": [[69, "module-torch.fx.experimental.unification.match"]], "torch.fx.experimental.unification.more": [[69, "module-torch.fx.experimental.unification.more"]], "torch.fx.experimental.unification.multipledispatch": [[69, "module-torch.fx.experimental.unification.multipledispatch"]], "torch.fx.experimental.unification.multipledispatch.conflict": [[69, "module-torch.fx.experimental.unification.multipledispatch.conflict"]], "torch.fx.experimental.unification.multipledispatch.core": [[69, "module-torch.fx.experimental.unification.multipledispatch.core"]], "torch.fx.experimental.unification.multipledispatch.dispatcher": [[69, "module-torch.fx.experimental.unification.multipledispatch.dispatcher"]], "torch.fx.experimental.unification.multipledispatch.utils": [[69, "module-torch.fx.experimental.unification.multipledispatch.utils"]], "torch.fx.experimental.unification.multipledispatch.variadic": [[69, "module-torch.fx.experimental.unification.multipledispatch.variadic"]], "torch.fx.experimental.unification.unification_tools": [[69, "module-torch.fx.experimental.unification.unification_tools"]], "torch.fx.experimental.unification.utils": [[69, "module-torch.fx.experimental.unification.utils"]], "torch.fx.experimental.unification.variable": [[69, "module-torch.fx.experimental.unification.variable"]], "torch.fx.experimental.unify_refinements": [[69, "module-torch.fx.experimental.unify_refinements"]], "torch.fx.experimental.validator": [[69, "module-torch.fx.experimental.validator"]], "torch.fx.graph": [[69, "module-torch.fx.graph"]], "torch.fx.graph_module": [[69, "module-torch.fx.graph_module"]], "torch.fx.immutable_collections": [[69, "module-torch.fx.immutable_collections"]], "torch.fx.interpreter": [[69, "module-torch.fx.interpreter"]], "torch.fx.node": [[69, "module-torch.fx.node"]], "torch.fx.operator_schemas": [[69, "module-torch.fx.operator_schemas"]], "torch.fx.passes": [[69, "module-torch.fx.passes"]], "torch.fx.passes.annotate_getitem_nodes": [[69, "module-torch.fx.passes.annotate_getitem_nodes"]], "torch.fx.passes.backends": [[69, "module-torch.fx.passes.backends"]], "torch.fx.passes.backends.cudagraphs": [[69, "module-torch.fx.passes.backends.cudagraphs"]], "torch.fx.passes.dialect": [[69, "module-torch.fx.passes.dialect"]], "torch.fx.passes.dialect.common": [[69, "module-torch.fx.passes.dialect.common"]], "torch.fx.passes.dialect.common.cse_pass": [[69, "module-torch.fx.passes.dialect.common.cse_pass"]], "torch.fx.passes.fake_tensor_prop": [[69, "module-torch.fx.passes.fake_tensor_prop"]], "torch.fx.passes.graph_drawer": [[69, "module-torch.fx.passes.graph_drawer"]], "torch.fx.passes.graph_manipulation": [[69, "module-torch.fx.passes.graph_manipulation"]], "torch.fx.passes.graph_transform_observer": [[69, "module-torch.fx.passes.graph_transform_observer"]], "torch.fx.passes.infra": [[69, "module-torch.fx.passes.infra"]], "torch.fx.passes.infra.partitioner": [[69, "module-torch.fx.passes.infra.partitioner"]], "torch.fx.passes.infra.pass_base": [[69, "module-torch.fx.passes.infra.pass_base"]], "torch.fx.passes.infra.pass_manager": [[69, "module-torch.fx.passes.infra.pass_manager"]], "torch.fx.passes.net_min_base": [[69, "module-torch.fx.passes.net_min_base"]], "torch.fx.passes.operator_support": [[69, "module-torch.fx.passes.operator_support"]], "torch.fx.passes.param_fetch": [[69, "module-torch.fx.passes.param_fetch"]], "torch.fx.passes.pass_manager": [[69, "module-torch.fx.passes.pass_manager"]], "torch.fx.passes.reinplace": [[69, "module-torch.fx.passes.reinplace"]], "torch.fx.passes.runtime_assert": [[69, "module-torch.fx.passes.runtime_assert"]], "torch.fx.passes.shape_prop": [[69, "module-torch.fx.passes.shape_prop"]], "torch.fx.passes.split_module": [[69, "module-torch.fx.passes.split_module"]], "torch.fx.passes.split_utils": [[69, "module-torch.fx.passes.split_utils"]], "torch.fx.passes.splitter_base": [[69, "module-torch.fx.passes.splitter_base"]], "torch.fx.passes.tests": [[69, "module-torch.fx.passes.tests"]], "torch.fx.passes.tests.test_pass_manager": [[69, "module-torch.fx.passes.tests.test_pass_manager"]], "torch.fx.passes.tools_common": [[69, "module-torch.fx.passes.tools_common"]], "torch.fx.passes.utils": [[69, "module-torch.fx.passes.utils"]], "torch.fx.passes.utils.common": [[69, "module-torch.fx.passes.utils.common"]], "torch.fx.passes.utils.fuser_utils": [[69, "module-torch.fx.passes.utils.fuser_utils"]], "torch.fx.passes.utils.matcher_utils": [[69, "module-torch.fx.passes.utils.matcher_utils"]], "torch.fx.passes.utils.matcher_with_name_node_map_utils": [[69, "module-torch.fx.passes.utils.matcher_with_name_node_map_utils"]], "torch.fx.passes.utils.source_matcher_utils": [[69, "module-torch.fx.passes.utils.source_matcher_utils"]], "torch.fx.proxy": [[69, "module-torch.fx.proxy"]], "torch.fx.subgraph_rewriter": [[69, "module-torch.fx.subgraph_rewriter"]], "torch.fx.tensor_type": [[69, "module-torch.fx.tensor_type"]], "torch.fx.traceback": [[69, "module-torch.fx.traceback"]], "trace() (torch.fx.tracer method)": [[69, "torch.fx.Tracer.trace"]], "transform() (torch.fx.transformer method)": [[69, "torch.fx.Transformer.transform"]], "update_arg() (torch.fx.node method)": [[69, "torch.fx.Node.update_arg"]], "update_kwarg() (torch.fx.node method)": [[69, "torch.fx.Node.update_kwarg"]], "wrap() (in module torch.fx)": [[69, "torch.fx.wrap"]], "torch.fx.experimental.proxy_tensor": [[70, "module-torch.fx.experimental.proxy_tensor"]], "torch.fx.experimental.symbolic_shapes": [[70, "module-torch.fx.experimental.symbolic_shapes"]], "event (class in torch)": [[86, "torch.Event"]], "elapsed_time() (torch.event method)": [[86, "torch.Event.elapsed_time"]], "query() (torch.event method)": [[86, "torch.Event.query"]], "record() (torch.event method)": [[86, "torch.Event.record"]], "synchronize() (torch.event method)": [[86, "torch.Event.synchronize"]], "wait() (torch.event method)": [[86, "torch.Event.wait"]], "generator (class in torch)": [[87, "torch.Generator"]], "clone_state() (torch.generator method)": [[87, "torch.Generator.clone_state"]], "device (torch.generator attribute)": [[87, "torch.Generator.device"]], "get_state() (torch.generator method)": [[87, "torch.Generator.get_state"]], "graphsafe_get_state() (torch.generator method)": [[87, "torch.Generator.graphsafe_get_state"]], "graphsafe_set_state() (torch.generator method)": [[87, "torch.Generator.graphsafe_set_state"]], "initial_seed() (torch.generator method)": [[87, "torch.Generator.initial_seed"]], "manual_seed() (torch.generator method)": [[87, "torch.Generator.manual_seed"]], "seed() (torch.generator method)": [[87, "torch.Generator.seed"]], "set_state() (torch.generator method)": [[87, "torch.Generator.set_state"]], "stream (class in torch)": [[88, "torch.Stream"]], "query() (torch.stream method)": [[88, "torch.Stream.query"]], "record_event() (torch.stream method)": [[88, "torch.Stream.record_event"]], "synchronize() (torch.stream method)": [[88, "torch.Stream.synchronize"]], "wait_event() (torch.stream method)": [[88, "torch.Stream.wait_event"]], "wait_stream() (torch.stream method)": [[88, "torch.Stream.wait_stream"]], "abs() (torch.tensor method)": [[89, "torch.Tensor.abs"]], "abs_() (torch.tensor method)": [[90, "torch.Tensor.abs_"]], "absolute() (torch.tensor method)": [[91, "torch.Tensor.absolute"]], "absolute_() (torch.tensor method)": [[92, "torch.Tensor.absolute_"]], "acos() (torch.tensor method)": [[93, "torch.Tensor.acos"]], "acos_() (torch.tensor method)": [[94, "torch.Tensor.acos_"]], "acosh() (torch.tensor method)": [[95, "torch.Tensor.acosh"]], "acosh_() (torch.tensor method)": [[96, "torch.Tensor.acosh_"]], "add() (torch.tensor method)": [[97, "torch.Tensor.add"]], "add_() (torch.tensor method)": [[98, "torch.Tensor.add_"]], "addbmm() (torch.tensor method)": [[99, "torch.Tensor.addbmm"]], "addbmm_() (torch.tensor method)": [[100, "torch.Tensor.addbmm_"]], "addcdiv() (torch.tensor method)": [[101, "torch.Tensor.addcdiv"]], "addcdiv_() (torch.tensor method)": [[102, "torch.Tensor.addcdiv_"]], "addcmul() (torch.tensor method)": [[103, "torch.Tensor.addcmul"]], "addcmul_() (torch.tensor method)": [[104, "torch.Tensor.addcmul_"]], "addmm() (torch.tensor method)": [[105, "torch.Tensor.addmm"]], "addmm_() (torch.tensor method)": [[106, "torch.Tensor.addmm_"]], "addmv() (torch.tensor method)": [[107, "torch.Tensor.addmv"]], "addmv_() (torch.tensor method)": [[108, "torch.Tensor.addmv_"]], "addr() (torch.tensor method)": [[109, "torch.Tensor.addr"]], "addr_() (torch.tensor method)": [[110, "torch.Tensor.addr_"]], "adjoint() (torch.tensor method)": [[111, "torch.Tensor.adjoint"]], "all() (torch.tensor method)": [[112, "torch.Tensor.all"]], "allclose() (torch.tensor method)": [[113, "torch.Tensor.allclose"]], "amax() (torch.tensor method)": [[114, "torch.Tensor.amax"]], "amin() (torch.tensor method)": [[115, "torch.Tensor.amin"]], "aminmax() (torch.tensor method)": [[116, "torch.Tensor.aminmax"]], "angle() (torch.tensor method)": [[117, "torch.Tensor.angle"]], "any() (torch.tensor method)": [[118, "torch.Tensor.any"]], "apply_() (torch.tensor method)": [[119, "torch.Tensor.apply_"]], "arccos() (torch.tensor method)": [[120, "torch.Tensor.arccos"]], "arccos_() (torch.tensor method)": [[121, "torch.Tensor.arccos_"]], "arccosh() (torch.tensor method)": [[122, "torch.Tensor.arccosh"]], "arccosh_() (torch.tensor method)": [[123, "torch.Tensor.arccosh_"]], "arcsin() (torch.tensor method)": [[124, "torch.Tensor.arcsin"]], "arcsin_() (torch.tensor method)": [[125, "torch.Tensor.arcsin_"]], "arcsinh() (torch.tensor method)": [[126, "torch.Tensor.arcsinh"]], "arcsinh_() (torch.tensor method)": [[127, "torch.Tensor.arcsinh_"]], "arctan() (torch.tensor method)": [[128, "torch.Tensor.arctan"]], "arctan2() (torch.tensor method)": [[129, "torch.Tensor.arctan2"]], "arctan2_() (torch.tensor method)": [[130, "torch.Tensor.arctan2_"]], "arctan_() (torch.tensor method)": [[131, "torch.Tensor.arctan_"]], "arctanh() (torch.tensor method)": [[132, "torch.Tensor.arctanh"]], "arctanh_() (torch.tensor method)": [[133, "torch.Tensor.arctanh_"]], "argmax() (torch.tensor method)": [[134, "torch.Tensor.argmax"]], "argmin() (torch.tensor method)": [[135, "torch.Tensor.argmin"]], "argsort() (torch.tensor method)": [[136, "torch.Tensor.argsort"]], "argwhere() (torch.tensor method)": [[137, "torch.Tensor.argwhere"]], "as_strided() (torch.tensor method)": [[138, "torch.Tensor.as_strided"]], "as_subclass() (torch.tensor method)": [[139, "torch.Tensor.as_subclass"]], "asin() (torch.tensor method)": [[140, "torch.Tensor.asin"]], "asin_() (torch.tensor method)": [[141, "torch.Tensor.asin_"]], "asinh() (torch.tensor method)": [[142, "torch.Tensor.asinh"]], "asinh_() (torch.tensor method)": [[143, "torch.Tensor.asinh_"]], "atan() (torch.tensor method)": [[144, "torch.Tensor.atan"]], "atan2() (torch.tensor method)": [[145, "torch.Tensor.atan2"]], "atan2_() (torch.tensor method)": [[146, "torch.Tensor.atan2_"]], "atan_() (torch.tensor method)": [[147, "torch.Tensor.atan_"]], "atanh() (torch.tensor method)": [[148, "torch.Tensor.atanh"]], "atanh_() (torch.tensor method)": [[149, "torch.Tensor.atanh_"]], "backward() (torch.tensor method)": [[150, "torch.Tensor.backward"]], "baddbmm() (torch.tensor method)": [[151, "torch.Tensor.baddbmm"]], "baddbmm_() (torch.tensor method)": [[152, "torch.Tensor.baddbmm_"]], "bernoulli() (torch.tensor method)": [[153, "torch.Tensor.bernoulli"]], "bernoulli_() (torch.tensor method)": [[154, "torch.Tensor.bernoulli_"]], "bfloat16() (torch.tensor method)": [[155, "torch.Tensor.bfloat16"]], "bincount() (torch.tensor method)": [[156, "torch.Tensor.bincount"]], "bitwise_and() (torch.tensor method)": [[157, "torch.Tensor.bitwise_and"]], "bitwise_and_() (torch.tensor method)": [[158, "torch.Tensor.bitwise_and_"]], "bitwise_left_shift() (torch.tensor method)": [[159, "torch.Tensor.bitwise_left_shift"]], "bitwise_left_shift_() (torch.tensor method)": [[160, "torch.Tensor.bitwise_left_shift_"]], "bitwise_not() (torch.tensor method)": [[161, "torch.Tensor.bitwise_not"]], "bitwise_not_() (torch.tensor method)": [[162, "torch.Tensor.bitwise_not_"]], "bitwise_or() (torch.tensor method)": [[163, "torch.Tensor.bitwise_or"]], "bitwise_or_() (torch.tensor method)": [[164, "torch.Tensor.bitwise_or_"]], "bitwise_right_shift() (torch.tensor method)": [[165, "torch.Tensor.bitwise_right_shift"]], "bitwise_right_shift_() (torch.tensor method)": [[166, "torch.Tensor.bitwise_right_shift_"]], "bitwise_xor() (torch.tensor method)": [[167, "torch.Tensor.bitwise_xor"]], "bitwise_xor_() (torch.tensor method)": [[168, "torch.Tensor.bitwise_xor_"]], "bmm() (torch.tensor method)": [[169, "torch.Tensor.bmm"]], "bool() (torch.tensor method)": [[170, "torch.Tensor.bool"]], "broadcast_to() (torch.tensor method)": [[171, "torch.Tensor.broadcast_to"]], "byte() (torch.tensor method)": [[172, "torch.Tensor.byte"]], "cauchy_() (torch.tensor method)": [[173, "torch.Tensor.cauchy_"]], "ccol_indices() (torch.tensor method)": [[174, "torch.Tensor.ccol_indices"]], "cdouble() (torch.tensor method)": [[175, "torch.Tensor.cdouble"]], "ceil() (torch.tensor method)": [[176, "torch.Tensor.ceil"]], "ceil_() (torch.tensor method)": [[177, "torch.Tensor.ceil_"]], "cfloat() (torch.tensor method)": [[178, "torch.Tensor.cfloat"]], "chalf() (torch.tensor method)": [[179, "torch.Tensor.chalf"]], "char() (torch.tensor method)": [[180, "torch.Tensor.char"]], "cholesky() (torch.tensor method)": [[181, "torch.Tensor.cholesky"]], "cholesky_inverse() (torch.tensor method)": [[182, "torch.Tensor.cholesky_inverse"]], "cholesky_solve() (torch.tensor method)": [[183, "torch.Tensor.cholesky_solve"]], "chunk() (torch.tensor method)": [[184, "torch.Tensor.chunk"]], "clamp() (torch.tensor method)": [[185, "torch.Tensor.clamp"]], "clamp_() (torch.tensor method)": [[186, "torch.Tensor.clamp_"]], "clip() (torch.tensor method)": [[187, "torch.Tensor.clip"]], "clip_() (torch.tensor method)": [[188, "torch.Tensor.clip_"]], "clone() (torch.tensor method)": [[189, "torch.Tensor.clone"]], "coalesce() (torch.tensor method)": [[190, "torch.Tensor.coalesce"]], "col_indices() (torch.tensor method)": [[191, "torch.Tensor.col_indices"]], "conj() (torch.tensor method)": [[192, "torch.Tensor.conj"]], "conj_physical() (torch.tensor method)": [[193, "torch.Tensor.conj_physical"]], "conj_physical_() (torch.tensor method)": [[194, "torch.Tensor.conj_physical_"]], "contiguous() (torch.tensor method)": [[195, "torch.Tensor.contiguous"]], "copy_() (torch.tensor method)": [[196, "torch.Tensor.copy_"]], "copysign() (torch.tensor method)": [[197, "torch.Tensor.copysign"]], "copysign_() (torch.tensor method)": [[198, "torch.Tensor.copysign_"]], "corrcoef() (torch.tensor method)": [[199, "torch.Tensor.corrcoef"]], "cos() (torch.tensor method)": [[200, "torch.Tensor.cos"]], "cos_() (torch.tensor method)": [[201, "torch.Tensor.cos_"]], "cosh() (torch.tensor method)": [[202, "torch.Tensor.cosh"]], "cosh_() (torch.tensor method)": [[203, "torch.Tensor.cosh_"]], "count_nonzero() (torch.tensor method)": [[204, "torch.Tensor.count_nonzero"]], "cov() (torch.tensor method)": [[205, "torch.Tensor.cov"]], "cpu() (torch.tensor method)": [[206, "torch.Tensor.cpu"]], "cross() (torch.tensor method)": [[207, "torch.Tensor.cross"]], "crow_indices() (torch.tensor method)": [[208, "torch.Tensor.crow_indices"]], "cuda() (torch.tensor method)": [[209, "torch.Tensor.cuda"]], "cummax() (torch.tensor method)": [[210, "torch.Tensor.cummax"]], "cummin() (torch.tensor method)": [[211, "torch.Tensor.cummin"]], "cumprod() (torch.tensor method)": [[212, "torch.Tensor.cumprod"]], "cumprod_() (torch.tensor method)": [[213, "torch.Tensor.cumprod_"]], "cumsum() (torch.tensor method)": [[214, "torch.Tensor.cumsum"]], "cumsum_() (torch.tensor method)": [[215, "torch.Tensor.cumsum_"]], "data_ptr() (torch.tensor method)": [[216, "torch.Tensor.data_ptr"]], "deg2rad() (torch.tensor method)": [[217, "torch.Tensor.deg2rad"]], "dense_dim() (torch.tensor method)": [[218, "torch.Tensor.dense_dim"]], "dequantize() (torch.tensor method)": [[219, "torch.Tensor.dequantize"]], "det() (torch.tensor method)": [[220, "torch.Tensor.det"]], "detach() (torch.tensor method)": [[221, "torch.Tensor.detach"]], "detach_() (torch.tensor method)": [[222, "torch.Tensor.detach_"]], "device (torch.tensor attribute)": [[223, "torch.Tensor.device"]], "diag() (torch.tensor method)": [[224, "torch.Tensor.diag"]], "diag_embed() (torch.tensor method)": [[225, "torch.Tensor.diag_embed"]], "diagflat() (torch.tensor method)": [[226, "torch.Tensor.diagflat"]], "diagonal() (torch.tensor method)": [[227, "torch.Tensor.diagonal"]], "diagonal_scatter() (torch.tensor method)": [[228, "torch.Tensor.diagonal_scatter"]], "diff() (torch.tensor method)": [[229, "torch.Tensor.diff"]], "digamma() (torch.tensor method)": [[230, "torch.Tensor.digamma"]], "digamma_() (torch.tensor method)": [[231, "torch.Tensor.digamma_"]], "dim() (torch.tensor method)": [[232, "torch.Tensor.dim"]], "dim_order() (torch.tensor method)": [[233, "torch.Tensor.dim_order"]], "dist() (torch.tensor method)": [[234, "torch.Tensor.dist"]], "div() (torch.tensor method)": [[235, "torch.Tensor.div"]], "div_() (torch.tensor method)": [[236, "torch.Tensor.div_"]], "divide() (torch.tensor method)": [[237, "torch.Tensor.divide"]], "divide_() (torch.tensor method)": [[238, "torch.Tensor.divide_"]], "dot() (torch.tensor method)": [[239, "torch.Tensor.dot"]], "double() (torch.tensor method)": [[240, "torch.Tensor.double"]], "dsplit() (torch.tensor method)": [[241, "torch.Tensor.dsplit"]], "element_size() (torch.tensor method)": [[242, "torch.Tensor.element_size"]], "eq() (torch.tensor method)": [[243, "torch.Tensor.eq"]], "eq_() (torch.tensor method)": [[244, "torch.Tensor.eq_"]], "equal() (torch.tensor method)": [[245, "torch.Tensor.equal"]], "erf() (torch.tensor method)": [[246, "torch.Tensor.erf"]], "erf_() (torch.tensor method)": [[247, "torch.Tensor.erf_"]], "erfc() (torch.tensor method)": [[248, "torch.Tensor.erfc"]], "erfc_() (torch.tensor method)": [[249, "torch.Tensor.erfc_"]], "erfinv() (torch.tensor method)": [[250, "torch.Tensor.erfinv"]], "erfinv_() (torch.tensor method)": [[251, "torch.Tensor.erfinv_"]], "exp() (torch.tensor method)": [[252, "torch.Tensor.exp"]], "exp_() (torch.tensor method)": [[253, "torch.Tensor.exp_"]], "expand() (torch.tensor method)": [[254, "torch.Tensor.expand"]], "expand_as() (torch.tensor method)": [[255, "torch.Tensor.expand_as"]], "expm1() (torch.tensor method)": [[256, "torch.Tensor.expm1"]], "expm1_() (torch.tensor method)": [[257, "torch.Tensor.expm1_"]], "exponential_() (torch.tensor method)": [[258, "torch.Tensor.exponential_"]], "fill_() (torch.tensor method)": [[259, "torch.Tensor.fill_"]], "fill_diagonal_() (torch.tensor method)": [[260, "torch.Tensor.fill_diagonal_"]], "fix() (torch.tensor method)": [[261, "torch.Tensor.fix"]], "fix_() (torch.tensor method)": [[262, "torch.Tensor.fix_"]], "flatten() (torch.tensor method)": [[263, "torch.Tensor.flatten"]], "flip() (torch.tensor method)": [[264, "torch.Tensor.flip"]], "fliplr() (torch.tensor method)": [[265, "torch.Tensor.fliplr"]], "flipud() (torch.tensor method)": [[266, "torch.Tensor.flipud"]], "float() (torch.tensor method)": [[267, "torch.Tensor.float"]], "float_power() (torch.tensor method)": [[268, "torch.Tensor.float_power"]], "float_power_() (torch.tensor method)": [[269, "torch.Tensor.float_power_"]], "floor() (torch.tensor method)": [[270, "torch.Tensor.floor"]], "floor_() (torch.tensor method)": [[271, "torch.Tensor.floor_"]], "floor_divide() (torch.tensor method)": [[272, "torch.Tensor.floor_divide"]], "floor_divide_() (torch.tensor method)": [[273, "torch.Tensor.floor_divide_"]], "fmax() (torch.tensor method)": [[274, "torch.Tensor.fmax"]], "fmin() (torch.tensor method)": [[275, "torch.Tensor.fmin"]], "fmod() (torch.tensor method)": [[276, "torch.Tensor.fmod"]], "fmod_() (torch.tensor method)": [[277, "torch.Tensor.fmod_"]], "frac() (torch.tensor method)": [[278, "torch.Tensor.frac"]], "frac_() (torch.tensor method)": [[279, "torch.Tensor.frac_"]], "frexp() (torch.tensor method)": [[280, "torch.Tensor.frexp"]], "gather() (torch.tensor method)": [[281, "torch.Tensor.gather"]], "gcd() (torch.tensor method)": [[282, "torch.Tensor.gcd"]], "gcd_() (torch.tensor method)": [[283, "torch.Tensor.gcd_"]], "ge() (torch.tensor method)": [[284, "torch.Tensor.ge"]], "ge_() (torch.tensor method)": [[285, "torch.Tensor.ge_"]], "geometric_() (torch.tensor method)": [[286, "torch.Tensor.geometric_"]], "geqrf() (torch.tensor method)": [[287, "torch.Tensor.geqrf"]], "ger() (torch.tensor method)": [[288, "torch.Tensor.ger"]], "get_device() (torch.tensor method)": [[289, "torch.Tensor.get_device"]], "grad (torch.tensor attribute)": [[290, "torch.Tensor.grad"]], "greater() (torch.tensor method)": [[291, "torch.Tensor.greater"]], "greater_() (torch.tensor method)": [[292, "torch.Tensor.greater_"]], "greater_equal() (torch.tensor method)": [[293, "torch.Tensor.greater_equal"]], "greater_equal_() (torch.tensor method)": [[294, "torch.Tensor.greater_equal_"]], "gt() (torch.tensor method)": [[295, "torch.Tensor.gt"]], "gt_() (torch.tensor method)": [[296, "torch.Tensor.gt_"]], "half() (torch.tensor method)": [[297, "torch.Tensor.half"]], "hardshrink() (torch.tensor method)": [[298, "torch.Tensor.hardshrink"]], "heaviside() (torch.tensor method)": [[299, "torch.Tensor.heaviside"]], "histc() (torch.tensor method)": [[300, "torch.Tensor.histc"]], "histogram() (torch.tensor method)": [[301, "torch.Tensor.histogram"]], "hsplit() (torch.tensor method)": [[302, "torch.Tensor.hsplit"]], "hypot() (torch.tensor method)": [[303, "torch.Tensor.hypot"]], "hypot_() (torch.tensor method)": [[304, "torch.Tensor.hypot_"]], "i0() (torch.tensor method)": [[305, "torch.Tensor.i0"]], "i0_() (torch.tensor method)": [[306, "torch.Tensor.i0_"]], "igamma() (torch.tensor method)": [[307, "torch.Tensor.igamma"]], "igamma_() (torch.tensor method)": [[308, "torch.Tensor.igamma_"]], "igammac() (torch.tensor method)": [[309, "torch.Tensor.igammac"]], "igammac_() (torch.tensor method)": [[310, "torch.Tensor.igammac_"]], "imag (torch.tensor attribute)": [[311, "torch.Tensor.imag"]], "index_add() (torch.tensor method)": [[312, "torch.Tensor.index_add"]], "index_add_() (torch.tensor method)": [[313, "torch.Tensor.index_add_"]], "index_copy() (torch.tensor method)": [[314, "torch.Tensor.index_copy"]], "index_copy_() (torch.tensor method)": [[315, "torch.Tensor.index_copy_"]], "index_fill() (torch.tensor method)": [[316, "torch.Tensor.index_fill"]], "index_fill_() (torch.tensor method)": [[317, "torch.Tensor.index_fill_"]], "index_put() (torch.tensor method)": [[318, "torch.Tensor.index_put"]], "index_put_() (torch.tensor method)": [[319, "torch.Tensor.index_put_"]], "index_reduce() (torch.tensor method)": [[320, "torch.Tensor.index_reduce"]], "index_reduce_() (torch.tensor method)": [[321, "torch.Tensor.index_reduce_"]], "index_select() (torch.tensor method)": [[322, "torch.Tensor.index_select"]], "indices() (torch.tensor method)": [[323, "torch.Tensor.indices"]], "inner() (torch.tensor method)": [[324, "torch.Tensor.inner"]], "int() (torch.tensor method)": [[325, "torch.Tensor.int"]], "int_repr() (torch.tensor method)": [[326, "torch.Tensor.int_repr"]], "inverse() (torch.tensor method)": [[327, "torch.Tensor.inverse"]], "is_coalesced() (torch.tensor method)": [[328, "torch.Tensor.is_coalesced"]], "is_complex() (torch.tensor method)": [[329, "torch.Tensor.is_complex"]], "is_conj() (torch.tensor method)": [[330, "torch.Tensor.is_conj"]], "is_contiguous() (torch.tensor method)": [[331, "torch.Tensor.is_contiguous"]], "is_cuda (torch.tensor attribute)": [[332, "torch.Tensor.is_cuda"]], "is_floating_point() (torch.tensor method)": [[333, "torch.Tensor.is_floating_point"]], "is_inference() (torch.tensor method)": [[334, "torch.Tensor.is_inference"]], "is_leaf (torch.tensor attribute)": [[335, "torch.Tensor.is_leaf"]], "is_meta (torch.tensor attribute)": [[336, "torch.Tensor.is_meta"]], "is_pinned() (torch.tensor method)": [[337, "torch.Tensor.is_pinned"]], "is_quantized (torch.tensor attribute)": [[338, "torch.Tensor.is_quantized"]], "is_set_to() (torch.tensor method)": [[339, "torch.Tensor.is_set_to"]], "is_shared() (torch.tensor method)": [[340, "torch.Tensor.is_shared"]], "is_signed() (torch.tensor method)": [[341, "torch.Tensor.is_signed"]], "is_sparse (torch.tensor attribute)": [[342, "torch.Tensor.is_sparse"]], "is_sparse_csr (torch.tensor attribute)": [[343, "torch.Tensor.is_sparse_csr"]], "isclose() (torch.tensor method)": [[344, "torch.Tensor.isclose"]], "isfinite() (torch.tensor method)": [[345, "torch.Tensor.isfinite"]], "isinf() (torch.tensor method)": [[346, "torch.Tensor.isinf"]], "isnan() (torch.tensor method)": [[347, "torch.Tensor.isnan"]], "isneginf() (torch.tensor method)": [[348, "torch.Tensor.isneginf"]], "isposinf() (torch.tensor method)": [[349, "torch.Tensor.isposinf"]], "isreal() (torch.tensor method)": [[350, "torch.Tensor.isreal"]], "istft() (torch.tensor method)": [[351, "torch.Tensor.istft"]], "item() (torch.tensor method)": [[352, "torch.Tensor.item"]], "itemsize (torch.tensor attribute)": [[353, "torch.Tensor.itemsize"]], "kthvalue() (torch.tensor method)": [[354, "torch.Tensor.kthvalue"]], "lcm() (torch.tensor method)": [[355, "torch.Tensor.lcm"]], "lcm_() (torch.tensor method)": [[356, "torch.Tensor.lcm_"]], "ldexp() (torch.tensor method)": [[357, "torch.Tensor.ldexp"]], "ldexp_() (torch.tensor method)": [[358, "torch.Tensor.ldexp_"]], "le() (torch.tensor method)": [[359, "torch.Tensor.le"]], "le_() (torch.tensor method)": [[360, "torch.Tensor.le_"]], "lerp() (torch.tensor method)": [[361, "torch.Tensor.lerp"]], "lerp_() (torch.tensor method)": [[362, "torch.Tensor.lerp_"]], "less() (torch.tensor method)": [[363, "torch.Tensor.less"]], "less_() (torch.tensor method)": [[364, "torch.Tensor.less_"]], "less_equal() (torch.tensor method)": [[365, "torch.Tensor.less_equal"]], "less_equal_() (torch.tensor method)": [[366, "torch.Tensor.less_equal_"]], "lgamma() (torch.tensor method)": [[367, "torch.Tensor.lgamma"]], "lgamma_() (torch.tensor method)": [[368, "torch.Tensor.lgamma_"]], "log() (torch.tensor method)": [[369, "torch.Tensor.log"]], "log10() (torch.tensor method)": [[370, "torch.Tensor.log10"]], "log10_() (torch.tensor method)": [[371, "torch.Tensor.log10_"]], "log1p() (torch.tensor method)": [[372, "torch.Tensor.log1p"]], "log1p_() (torch.tensor method)": [[373, "torch.Tensor.log1p_"]], "log2() (torch.tensor method)": [[374, "torch.Tensor.log2"]], "log2_() (torch.tensor method)": [[375, "torch.Tensor.log2_"]], "log_() (torch.tensor method)": [[376, "torch.Tensor.log_"]], "log_normal_() (torch.tensor method)": [[377, "torch.Tensor.log_normal_"]], "logaddexp() (torch.tensor method)": [[378, "torch.Tensor.logaddexp"]], "logaddexp2() (torch.tensor method)": [[379, "torch.Tensor.logaddexp2"]], "logcumsumexp() (torch.tensor method)": [[380, "torch.Tensor.logcumsumexp"]], "logdet() (torch.tensor method)": [[381, "torch.Tensor.logdet"]], "logical_and() (torch.tensor method)": [[382, "torch.Tensor.logical_and"]], "logical_and_() (torch.tensor method)": [[383, "torch.Tensor.logical_and_"]], "logical_not() (torch.tensor method)": [[384, "torch.Tensor.logical_not"]], "logical_not_() (torch.tensor method)": [[385, "torch.Tensor.logical_not_"]], "logical_or() (torch.tensor method)": [[386, "torch.Tensor.logical_or"]], "logical_or_() (torch.tensor method)": [[387, "torch.Tensor.logical_or_"]], "logical_xor() (torch.tensor method)": [[388, "torch.Tensor.logical_xor"]], "logical_xor_() (torch.tensor method)": [[389, "torch.Tensor.logical_xor_"]], "logit() (torch.tensor method)": [[390, "torch.Tensor.logit"]], "logit_() (torch.tensor method)": [[391, "torch.Tensor.logit_"]], "logsumexp() (torch.tensor method)": [[392, "torch.Tensor.logsumexp"]], "long() (torch.tensor method)": [[393, "torch.Tensor.long"]], "lt() (torch.tensor method)": [[394, "torch.Tensor.lt"]], "lt_() (torch.tensor method)": [[395, "torch.Tensor.lt_"]], "lu() (torch.tensor method)": [[396, "torch.Tensor.lu"]], "lu_solve() (torch.tensor method)": [[397, "torch.Tensor.lu_solve"]], "map_() (torch.tensor method)": [[398, "torch.Tensor.map_"]], "masked_fill() (torch.tensor method)": [[399, "torch.Tensor.masked_fill"]], "masked_fill_() (torch.tensor method)": [[400, "torch.Tensor.masked_fill_"]], "masked_scatter() (torch.tensor method)": [[401, "torch.Tensor.masked_scatter"]], "masked_scatter_() (torch.tensor method)": [[402, "torch.Tensor.masked_scatter_"]], "masked_select() (torch.tensor method)": [[403, "torch.Tensor.masked_select"]], "matmul() (torch.tensor method)": [[404, "torch.Tensor.matmul"]], "matrix_exp() (torch.tensor method)": [[405, "torch.Tensor.matrix_exp"]], "matrix_power() (torch.tensor method)": [[406, "torch.Tensor.matrix_power"]], "max() (torch.tensor method)": [[407, "torch.Tensor.max"]], "maximum() (torch.tensor method)": [[408, "torch.Tensor.maximum"]], "mean() (torch.tensor method)": [[409, "torch.Tensor.mean"]], "median() (torch.tensor method)": [[410, "torch.Tensor.median"]], "min() (torch.tensor method)": [[411, "torch.Tensor.min"]], "minimum() (torch.tensor method)": [[412, "torch.Tensor.minimum"]], "mm() (torch.tensor method)": [[413, "torch.Tensor.mm"]], "mode() (torch.tensor method)": [[414, "torch.Tensor.mode"]], "module_load() (torch.tensor method)": [[415, "torch.Tensor.module_load"]], "moveaxis() (torch.tensor method)": [[416, "torch.Tensor.moveaxis"]], "movedim() (torch.tensor method)": [[417, "torch.Tensor.movedim"]], "msort() (torch.tensor method)": [[418, "torch.Tensor.msort"]], "mul() (torch.tensor method)": [[419, "torch.Tensor.mul"]], "mul_() (torch.tensor method)": [[420, "torch.Tensor.mul_"]], "multinomial() (torch.tensor method)": [[421, "torch.Tensor.multinomial"]], "multiply() (torch.tensor method)": [[422, "torch.Tensor.multiply"]], "multiply_() (torch.tensor method)": [[423, "torch.Tensor.multiply_"]], "mv() (torch.tensor method)": [[424, "torch.Tensor.mv"]], "mvlgamma() (torch.tensor method)": [[425, "torch.Tensor.mvlgamma"]], "mvlgamma_() (torch.tensor method)": [[426, "torch.Tensor.mvlgamma_"]], "nan_to_num() (torch.tensor method)": [[427, "torch.Tensor.nan_to_num"]], "nan_to_num_() (torch.tensor method)": [[428, "torch.Tensor.nan_to_num_"]], "nanmean() (torch.tensor method)": [[429, "torch.Tensor.nanmean"]], "nanmedian() (torch.tensor method)": [[430, "torch.Tensor.nanmedian"]], "nanquantile() (torch.tensor method)": [[431, "torch.Tensor.nanquantile"]], "nansum() (torch.tensor method)": [[432, "torch.Tensor.nansum"]], "narrow() (torch.tensor method)": [[433, "torch.Tensor.narrow"]], "narrow_copy() (torch.tensor method)": [[434, "torch.Tensor.narrow_copy"]], "nbytes (torch.tensor attribute)": [[435, "torch.Tensor.nbytes"]], "ndim (torch.tensor attribute)": [[436, "torch.Tensor.ndim"]], "ndimension() (torch.tensor method)": [[437, "torch.Tensor.ndimension"]], "ne() (torch.tensor method)": [[438, "torch.Tensor.ne"]], "ne_() (torch.tensor method)": [[439, "torch.Tensor.ne_"]], "neg() (torch.tensor method)": [[440, "torch.Tensor.neg"]], "neg_() (torch.tensor method)": [[441, "torch.Tensor.neg_"]], "negative() (torch.tensor method)": [[442, "torch.Tensor.negative"]], "negative_() (torch.tensor method)": [[443, "torch.Tensor.negative_"]], "nelement() (torch.tensor method)": [[444, "torch.Tensor.nelement"]], "new_empty() (torch.tensor method)": [[445, "torch.Tensor.new_empty"]], "new_full() (torch.tensor method)": [[446, "torch.Tensor.new_full"]], "new_ones() (torch.tensor method)": [[447, "torch.Tensor.new_ones"]], "new_tensor() (torch.tensor method)": [[448, "torch.Tensor.new_tensor"]], "new_zeros() (torch.tensor method)": [[449, "torch.Tensor.new_zeros"]], "nextafter() (torch.tensor method)": [[450, "torch.Tensor.nextafter"]], "nextafter_() (torch.tensor method)": [[451, "torch.Tensor.nextafter_"]], "nonzero() (torch.tensor method)": [[452, "torch.Tensor.nonzero"]], "norm() (torch.tensor method)": [[453, "torch.Tensor.norm"]], "normal_() (torch.tensor method)": [[454, "torch.Tensor.normal_"]], "not_equal() (torch.tensor method)": [[455, "torch.Tensor.not_equal"]], "not_equal_() (torch.tensor method)": [[456, "torch.Tensor.not_equal_"]], "numel() (torch.tensor method)": [[457, "torch.Tensor.numel"]], "numpy() (torch.tensor method)": [[458, "torch.Tensor.numpy"]], "orgqr() (torch.tensor method)": [[459, "torch.Tensor.orgqr"]], "ormqr() (torch.tensor method)": [[460, "torch.Tensor.ormqr"]], "outer() (torch.tensor method)": [[461, "torch.Tensor.outer"]], "permute() (torch.tensor method)": [[462, "torch.Tensor.permute"]], "pin_memory() (torch.tensor method)": [[463, "torch.Tensor.pin_memory"]], "pinverse() (torch.tensor method)": [[464, "torch.Tensor.pinverse"]], "polygamma() (torch.tensor method)": [[465, "torch.Tensor.polygamma"]], "polygamma_() (torch.tensor method)": [[466, "torch.Tensor.polygamma_"]], "positive() (torch.tensor method)": [[467, "torch.Tensor.positive"]], "pow() (torch.tensor method)": [[468, "torch.Tensor.pow"]], "pow_() (torch.tensor method)": [[469, "torch.Tensor.pow_"]], "prod() (torch.tensor method)": [[470, "torch.Tensor.prod"]], "put_() (torch.tensor method)": [[471, "torch.Tensor.put_"]], "q_per_channel_axis() (torch.tensor method)": [[472, "torch.Tensor.q_per_channel_axis"]], "q_per_channel_scales() (torch.tensor method)": [[473, "torch.Tensor.q_per_channel_scales"]], "q_per_channel_zero_points() (torch.tensor method)": [[474, "torch.Tensor.q_per_channel_zero_points"]], "q_scale() (torch.tensor method)": [[475, "torch.Tensor.q_scale"]], "q_zero_point() (torch.tensor method)": [[476, "torch.Tensor.q_zero_point"]], "qr() (torch.tensor method)": [[477, "torch.Tensor.qr"]], "qscheme() (torch.tensor method)": [[478, "torch.Tensor.qscheme"]], "quantile() (torch.tensor method)": [[479, "torch.Tensor.quantile"]], "rad2deg() (torch.tensor method)": [[480, "torch.Tensor.rad2deg"]], "random_() (torch.tensor method)": [[481, "torch.Tensor.random_"]], "ravel() (torch.tensor method)": [[482, "torch.Tensor.ravel"]], "real (torch.tensor attribute)": [[483, "torch.Tensor.real"]], "reciprocal() (torch.tensor method)": [[484, "torch.Tensor.reciprocal"]], "reciprocal_() (torch.tensor method)": [[485, "torch.Tensor.reciprocal_"]], "record_stream() (torch.tensor method)": [[486, "torch.Tensor.record_stream"]], "register_hook() (torch.tensor method)": [[487, "torch.Tensor.register_hook"]], "register_post_accumulate_grad_hook() (torch.tensor method)": [[488, "torch.Tensor.register_post_accumulate_grad_hook"]], "remainder() (torch.tensor method)": [[489, "torch.Tensor.remainder"]], "remainder_() (torch.tensor method)": [[490, "torch.Tensor.remainder_"]], "renorm() (torch.tensor method)": [[491, "torch.Tensor.renorm"]], "renorm_() (torch.tensor method)": [[492, "torch.Tensor.renorm_"]], "repeat() (torch.tensor method)": [[493, "torch.Tensor.repeat"]], "repeat_interleave() (torch.tensor method)": [[494, "torch.Tensor.repeat_interleave"]], "requires_grad (torch.tensor attribute)": [[495, "torch.Tensor.requires_grad"]], "requires_grad_() (torch.tensor method)": [[496, "torch.Tensor.requires_grad_"]], "reshape() (torch.tensor method)": [[497, "torch.Tensor.reshape"]], "reshape_as() (torch.tensor method)": [[498, "torch.Tensor.reshape_as"]], "resize_() (torch.tensor method)": [[499, "torch.Tensor.resize_"]], "resize_as_() (torch.tensor method)": [[500, "torch.Tensor.resize_as_"]], "resolve_conj() (torch.tensor method)": [[501, "torch.Tensor.resolve_conj"]], "resolve_neg() (torch.tensor method)": [[502, "torch.Tensor.resolve_neg"]], "retain_grad() (torch.tensor method)": [[503, "torch.Tensor.retain_grad"]], "retains_grad (torch.tensor attribute)": [[504, "torch.Tensor.retains_grad"]], "roll() (torch.tensor method)": [[505, "torch.Tensor.roll"]], "rot90() (torch.tensor method)": [[506, "torch.Tensor.rot90"]], "round() (torch.tensor method)": [[507, "torch.Tensor.round"]], "round_() (torch.tensor method)": [[508, "torch.Tensor.round_"]], "row_indices() (torch.tensor method)": [[509, "torch.Tensor.row_indices"]], "rsqrt() (torch.tensor method)": [[510, "torch.Tensor.rsqrt"]], "rsqrt_() (torch.tensor method)": [[511, "torch.Tensor.rsqrt_"]], "scatter() (torch.tensor method)": [[512, "torch.Tensor.scatter"]], "scatter_() (torch.tensor method)": [[513, "torch.Tensor.scatter_"]], "scatter_add() (torch.tensor method)": [[514, "torch.Tensor.scatter_add"]], "scatter_add_() (torch.tensor method)": [[515, "torch.Tensor.scatter_add_"]], "scatter_reduce() (torch.tensor method)": [[516, "torch.Tensor.scatter_reduce"]], "scatter_reduce_() (torch.tensor method)": [[517, "torch.Tensor.scatter_reduce_"]], "select() (torch.tensor method)": [[518, "torch.Tensor.select"]], "select_scatter() (torch.tensor method)": [[519, "torch.Tensor.select_scatter"]], "set_() (torch.tensor method)": [[520, "torch.Tensor.set_"]], "sgn() (torch.tensor method)": [[521, "torch.Tensor.sgn"]], "sgn_() (torch.tensor method)": [[522, "torch.Tensor.sgn_"]], "shape (torch.tensor attribute)": [[523, "torch.Tensor.shape"]], "share_memory_() (torch.tensor method)": [[524, "torch.Tensor.share_memory_"]], "short() (torch.tensor method)": [[525, "torch.Tensor.short"]], "sigmoid() (torch.tensor method)": [[526, "torch.Tensor.sigmoid"]], "sigmoid_() (torch.tensor method)": [[527, "torch.Tensor.sigmoid_"]], "sign() (torch.tensor method)": [[528, "torch.Tensor.sign"]], "sign_() (torch.tensor method)": [[529, "torch.Tensor.sign_"]], "signbit() (torch.tensor method)": [[530, "torch.Tensor.signbit"]], "sin() (torch.tensor method)": [[531, "torch.Tensor.sin"]], "sin_() (torch.tensor method)": [[532, "torch.Tensor.sin_"]], "sinc() (torch.tensor method)": [[533, "torch.Tensor.sinc"]], "sinc_() (torch.tensor method)": [[534, "torch.Tensor.sinc_"]], "sinh() (torch.tensor method)": [[535, "torch.Tensor.sinh"]], "sinh_() (torch.tensor method)": [[536, "torch.Tensor.sinh_"]], "size() (torch.tensor method)": [[537, "torch.Tensor.size"]], "slice_scatter() (torch.tensor method)": [[538, "torch.Tensor.slice_scatter"]], "slogdet() (torch.tensor method)": [[539, "torch.Tensor.slogdet"]], "smm() (torch.tensor method)": [[540, "torch.Tensor.smm"]], "softmax() (torch.tensor method)": [[541, "torch.Tensor.softmax"]], "sort() (torch.tensor method)": [[542, "torch.Tensor.sort"]], "sparse_dim() (torch.tensor method)": [[543, "torch.Tensor.sparse_dim"]], "sparse_mask() (torch.tensor method)": [[544, "torch.Tensor.sparse_mask"]], "sparse_resize_() (torch.tensor method)": [[545, "torch.Tensor.sparse_resize_"]], "sparse_resize_and_clear_() (torch.tensor method)": [[546, "torch.Tensor.sparse_resize_and_clear_"]], "split() (torch.tensor method)": [[547, "torch.Tensor.split"]], "sqrt() (torch.tensor method)": [[548, "torch.Tensor.sqrt"]], "sqrt_() (torch.tensor method)": [[549, "torch.Tensor.sqrt_"]], "square() (torch.tensor method)": [[550, "torch.Tensor.square"]], "square_() (torch.tensor method)": [[551, "torch.Tensor.square_"]], "squeeze() (torch.tensor method)": [[552, "torch.Tensor.squeeze"]], "squeeze_() (torch.tensor method)": [[553, "torch.Tensor.squeeze_"]], "sspaddmm() (torch.tensor method)": [[554, "torch.Tensor.sspaddmm"]], "std() (torch.tensor method)": [[555, "torch.Tensor.std"]], "stft() (torch.tensor method)": [[556, "torch.Tensor.stft"]], "storage() (torch.tensor method)": [[557, "torch.Tensor.storage"]], "storage_offset() (torch.tensor method)": [[558, "torch.Tensor.storage_offset"]], "storage_type() (torch.tensor method)": [[559, "torch.Tensor.storage_type"]], "stride() (torch.tensor method)": [[560, "torch.Tensor.stride"]], "sub() (torch.tensor method)": [[561, "torch.Tensor.sub"]], "sub_() (torch.tensor method)": [[562, "torch.Tensor.sub_"]], "subtract() (torch.tensor method)": [[563, "torch.Tensor.subtract"]], "subtract_() (torch.tensor method)": [[564, "torch.Tensor.subtract_"]], "sum() (torch.tensor method)": [[565, "torch.Tensor.sum"]], "sum_to_size() (torch.tensor method)": [[566, "torch.Tensor.sum_to_size"]], "svd() (torch.tensor method)": [[567, "torch.Tensor.svd"]], "swapaxes() (torch.tensor method)": [[568, "torch.Tensor.swapaxes"]], "swapdims() (torch.tensor method)": [[569, "torch.Tensor.swapdims"]], "t() (torch.tensor method)": [[570, "torch.Tensor.t"]], "t_() (torch.tensor method)": [[571, "torch.Tensor.t_"]], "take() (torch.tensor method)": [[572, "torch.Tensor.take"]], "take_along_dim() (torch.tensor method)": [[573, "torch.Tensor.take_along_dim"]], "tan() (torch.tensor method)": [[574, "torch.Tensor.tan"]], "tan_() (torch.tensor method)": [[575, "torch.Tensor.tan_"]], "tanh() (torch.tensor method)": [[576, "torch.Tensor.tanh"]], "tanh_() (torch.tensor method)": [[577, "torch.Tensor.tanh_"]], "tensor_split() (torch.tensor method)": [[578, "torch.Tensor.tensor_split"]], "tile() (torch.tensor method)": [[579, "torch.Tensor.tile"]], "to() (torch.tensor method)": [[580, "torch.Tensor.to"]], "to_dense() (torch.tensor method)": [[581, "torch.Tensor.to_dense"]], "to_mkldnn() (torch.tensor method)": [[582, "torch.Tensor.to_mkldnn"]], "to_sparse() (torch.tensor method)": [[583, "torch.Tensor.to_sparse"]], "to_sparse_bsc() (torch.tensor method)": [[584, "torch.Tensor.to_sparse_bsc"]], "to_sparse_bsr() (torch.tensor method)": [[585, "torch.Tensor.to_sparse_bsr"]], "to_sparse_coo() (torch.tensor method)": [[586, "torch.Tensor.to_sparse_coo"]], "to_sparse_csc() (torch.tensor method)": [[587, "torch.Tensor.to_sparse_csc"]], "to_sparse_csr() (torch.tensor method)": [[588, "torch.Tensor.to_sparse_csr"]], "tolist() (torch.tensor method)": [[589, "torch.Tensor.tolist"]], "topk() (torch.tensor method)": [[590, "torch.Tensor.topk"]], "trace() (torch.tensor method)": [[591, "torch.Tensor.trace"]], "transpose() (torch.tensor method)": [[592, "torch.Tensor.transpose"]], "transpose_() (torch.tensor method)": [[593, "torch.Tensor.transpose_"]], "triangular_solve() (torch.tensor method)": [[594, "torch.Tensor.triangular_solve"]], "tril() (torch.tensor method)": [[595, "torch.Tensor.tril"]], "tril_() (torch.tensor method)": [[596, "torch.Tensor.tril_"]], "triu() (torch.tensor method)": [[597, "torch.Tensor.triu"]], "triu_() (torch.tensor method)": [[598, "torch.Tensor.triu_"]], "true_divide() (torch.tensor method)": [[599, "torch.Tensor.true_divide"]], "true_divide_() (torch.tensor method)": [[600, "torch.Tensor.true_divide_"]], "trunc() (torch.tensor method)": [[601, "torch.Tensor.trunc"]], "trunc_() (torch.tensor method)": [[602, "torch.Tensor.trunc_"]], "type() (torch.tensor method)": [[603, "torch.Tensor.type"]], "type_as() (torch.tensor method)": [[604, "torch.Tensor.type_as"]], "unbind() (torch.tensor method)": [[605, "torch.Tensor.unbind"]], "unflatten() (torch.tensor method)": [[606, "torch.Tensor.unflatten"]], "unfold() (torch.tensor method)": [[607, "torch.Tensor.unfold"]], "uniform_() (torch.tensor method)": [[608, "torch.Tensor.uniform_"]], "unique() (torch.tensor method)": [[609, "torch.Tensor.unique"]], "unique_consecutive() (torch.tensor method)": [[610, "torch.Tensor.unique_consecutive"]], "unsqueeze() (torch.tensor method)": [[611, "torch.Tensor.unsqueeze"]], "unsqueeze_() (torch.tensor method)": [[612, "torch.Tensor.unsqueeze_"]], "untyped_storage() (torch.tensor method)": [[613, "torch.Tensor.untyped_storage"]], "values() (torch.tensor method)": [[614, "torch.Tensor.values"]], "var() (torch.tensor method)": [[615, "torch.Tensor.var"]], "vdot() (torch.tensor method)": [[616, "torch.Tensor.vdot"]], "view() (torch.tensor method)": [[617, "torch.Tensor.view"]], "view_as() (torch.tensor method)": [[618, "torch.Tensor.view_as"]], "vsplit() (torch.tensor method)": [[619, "torch.Tensor.vsplit"]], "where() (torch.tensor method)": [[620, "torch.Tensor.where"]], "xlogy() (torch.tensor method)": [[621, "torch.Tensor.xlogy"]], "xlogy_() (torch.tensor method)": [[622, "torch.Tensor.xlogy_"]], "xpu() (torch.tensor method)": [[623, "torch.Tensor.xpu"]], "zero_() (torch.tensor method)": [[624, "torch.Tensor.zero_"]], "_assert() (in module torch)": [[625, "torch._assert"]], "_foreach_abs() (in module torch)": [[626, "torch._foreach_abs"]], "_foreach_abs_() (in module torch)": [[627, "torch._foreach_abs_"]], "_foreach_acos() (in module torch)": [[628, "torch._foreach_acos"]], "_foreach_acos_() (in module torch)": [[629, "torch._foreach_acos_"]], "_foreach_asin() (in module torch)": [[630, "torch._foreach_asin"]], "_foreach_asin_() (in module torch)": [[631, "torch._foreach_asin_"]], "_foreach_atan() (in module torch)": [[632, "torch._foreach_atan"]], "_foreach_atan_() (in module torch)": [[633, "torch._foreach_atan_"]], "_foreach_ceil() (in module torch)": [[634, "torch._foreach_ceil"]], "_foreach_ceil_() (in module torch)": [[635, "torch._foreach_ceil_"]], "_foreach_cos() (in module torch)": [[636, "torch._foreach_cos"]], "_foreach_cos_() (in module torch)": [[637, "torch._foreach_cos_"]], "_foreach_cosh() (in module torch)": [[638, "torch._foreach_cosh"]], "_foreach_cosh_() (in module torch)": [[639, "torch._foreach_cosh_"]], "_foreach_erf() (in module torch)": [[640, "torch._foreach_erf"]], "_foreach_erf_() (in module torch)": [[641, "torch._foreach_erf_"]], "_foreach_erfc() (in module torch)": [[642, "torch._foreach_erfc"]], "_foreach_erfc_() (in module torch)": [[643, "torch._foreach_erfc_"]], "_foreach_exp() (in module torch)": [[644, "torch._foreach_exp"]], "_foreach_exp_() (in module torch)": [[645, "torch._foreach_exp_"]], "_foreach_expm1() (in module torch)": [[646, "torch._foreach_expm1"]], "_foreach_expm1_() (in module torch)": [[647, "torch._foreach_expm1_"]], "_foreach_floor() (in module torch)": [[648, "torch._foreach_floor"]], "_foreach_floor_() (in module torch)": [[649, "torch._foreach_floor_"]], "_foreach_frac() (in module torch)": [[650, "torch._foreach_frac"]], "_foreach_frac_() (in module torch)": [[651, "torch._foreach_frac_"]], "_foreach_lgamma() (in module torch)": [[652, "torch._foreach_lgamma"]], "_foreach_lgamma_() (in module torch)": [[653, "torch._foreach_lgamma_"]], "_foreach_log() (in module torch)": [[654, "torch._foreach_log"]], "_foreach_log10() (in module torch)": [[655, "torch._foreach_log10"]], "_foreach_log10_() (in module torch)": [[656, "torch._foreach_log10_"]], "_foreach_log1p() (in module torch)": [[657, "torch._foreach_log1p"]], "_foreach_log1p_() (in module torch)": [[658, "torch._foreach_log1p_"]], "_foreach_log2() (in module torch)": [[659, "torch._foreach_log2"]], "_foreach_log2_() (in module torch)": [[660, "torch._foreach_log2_"]], "_foreach_log_() (in module torch)": [[661, "torch._foreach_log_"]], "_foreach_neg() (in module torch)": [[662, "torch._foreach_neg"]], "_foreach_neg_() (in module torch)": [[663, "torch._foreach_neg_"]], "_foreach_reciprocal() (in module torch)": [[664, "torch._foreach_reciprocal"]], "_foreach_reciprocal_() (in module torch)": [[665, "torch._foreach_reciprocal_"]], "_foreach_round() (in module torch)": [[666, "torch._foreach_round"]], "_foreach_round_() (in module torch)": [[667, "torch._foreach_round_"]], "_foreach_sigmoid() (in module torch)": [[668, "torch._foreach_sigmoid"]], "_foreach_sigmoid_() (in module torch)": [[669, "torch._foreach_sigmoid_"]], "_foreach_sin() (in module torch)": [[670, "torch._foreach_sin"]], "_foreach_sin_() (in module torch)": [[671, "torch._foreach_sin_"]], "_foreach_sinh() (in module torch)": [[672, "torch._foreach_sinh"]], "_foreach_sinh_() (in module torch)": [[673, "torch._foreach_sinh_"]], "_foreach_sqrt() (in module torch)": [[674, "torch._foreach_sqrt"]], "_foreach_sqrt_() (in module torch)": [[675, "torch._foreach_sqrt_"]], "_foreach_tan() (in module torch)": [[676, "torch._foreach_tan"]], "_foreach_tan_() (in module torch)": [[677, "torch._foreach_tan_"]], "_foreach_trunc() (in module torch)": [[678, "torch._foreach_trunc"]], "_foreach_trunc_() (in module torch)": [[679, "torch._foreach_trunc_"]], "_foreach_zero_() (in module torch)": [[680, "torch._foreach_zero_"]], "set_logs() (in module torch._logging)": [[681, "torch._logging.set_logs"]], "abs() (in module torch)": [[682, "torch.abs"]], "absolute() (in module torch)": [[683, "torch.absolute"]], "current_accelerator() (in module torch.accelerator)": [[684, "torch.accelerator.current_accelerator"]], "current_device_idx() (in module torch.accelerator)": [[685, "torch.accelerator.current_device_idx"]], "current_device_index() (in module torch.accelerator)": [[686, "torch.accelerator.current_device_index"]], "current_stream() (in module torch.accelerator)": [[687, "torch.accelerator.current_stream"]], "device_count() (in module torch.accelerator)": [[688, "torch.accelerator.device_count"]], "is_available() (in module torch.accelerator)": [[689, "torch.accelerator.is_available"]], "set_device_idx() (in module torch.accelerator)": [[690, "torch.accelerator.set_device_idx"]], "set_device_index() (in module torch.accelerator)": [[691, "torch.accelerator.set_device_index"]], "set_stream() (in module torch.accelerator)": [[692, "torch.accelerator.set_stream"]], "synchronize() (in module torch.accelerator)": [[693, "torch.accelerator.synchronize"]], "acos() (in module torch)": [[694, "torch.acos"]], "acosh() (in module torch)": [[695, "torch.acosh"]], "add() (in module torch)": [[696, "torch.add"]], "addbmm() (in module torch)": [[697, "torch.addbmm"]], "addcdiv() (in module torch)": [[698, "torch.addcdiv"]], "addcmul() (in module torch)": [[699, "torch.addcmul"]], "addmm() (in module torch)": [[700, "torch.addmm"]], "addmv() (in module torch)": [[701, "torch.addmv"]], "addr() (in module torch)": [[702, "torch.addr"]], "adjoint() (in module torch)": [[703, "torch.adjoint"]], "all() (in module torch)": [[704, "torch.all"]], "allclose() (in module torch)": [[705, "torch.allclose"]], "amax() (in module torch)": [[706, "torch.amax"]], "amin() (in module torch)": [[707, "torch.amin"]], "aminmax() (in module torch)": [[708, "torch.aminmax"]], "angle() (in module torch)": [[709, "torch.angle"]], "any() (in module torch)": [[710, "torch.any"]], "bnrelu2d (class in torch.ao.nn.intrinsic)": [[711, "torch.ao.nn.intrinsic.BNReLU2d"]], "bnrelu3d (class in torch.ao.nn.intrinsic)": [[712, "torch.ao.nn.intrinsic.BNReLU3d"]], "convbn1d (class in torch.ao.nn.intrinsic)": [[713, "torch.ao.nn.intrinsic.ConvBn1d"]], "convbn2d (class in torch.ao.nn.intrinsic)": [[714, "torch.ao.nn.intrinsic.ConvBn2d"]], "convbn3d (class in torch.ao.nn.intrinsic)": [[715, "torch.ao.nn.intrinsic.ConvBn3d"]], "convbnrelu1d (class in torch.ao.nn.intrinsic)": [[716, "torch.ao.nn.intrinsic.ConvBnReLU1d"]], "convbnrelu2d (class in torch.ao.nn.intrinsic)": [[717, "torch.ao.nn.intrinsic.ConvBnReLU2d"]], "convbnrelu3d (class in torch.ao.nn.intrinsic)": [[718, "torch.ao.nn.intrinsic.ConvBnReLU3d"]], "convrelu1d (class in torch.ao.nn.intrinsic)": [[719, "torch.ao.nn.intrinsic.ConvReLU1d"]], "convrelu2d (class in torch.ao.nn.intrinsic)": [[720, "torch.ao.nn.intrinsic.ConvReLU2d"]], "convrelu3d (class in torch.ao.nn.intrinsic)": [[721, "torch.ao.nn.intrinsic.ConvReLU3d"]], "linearrelu (class in torch.ao.nn.intrinsic)": [[722, "torch.ao.nn.intrinsic.LinearReLU"]], "convbn1d (class in torch.ao.nn.intrinsic.qat)": [[723, "torch.ao.nn.intrinsic.qat.ConvBn1d"]], "convbn2d (class in torch.ao.nn.intrinsic.qat)": [[724, "torch.ao.nn.intrinsic.qat.ConvBn2d"]], "convbn3d (class in torch.ao.nn.intrinsic.qat)": [[725, "torch.ao.nn.intrinsic.qat.ConvBn3d"]], "convbnrelu1d (class in torch.ao.nn.intrinsic.qat)": [[726, "torch.ao.nn.intrinsic.qat.ConvBnReLU1d"]], "convbnrelu2d (class in torch.ao.nn.intrinsic.qat)": [[727, "torch.ao.nn.intrinsic.qat.ConvBnReLU2d"]], "convbnrelu3d (class in torch.ao.nn.intrinsic.qat)": [[728, "torch.ao.nn.intrinsic.qat.ConvBnReLU3d"]], "convrelu2d (class in torch.ao.nn.intrinsic.qat)": [[729, "torch.ao.nn.intrinsic.qat.ConvReLU2d"]], "convrelu3d (class in torch.ao.nn.intrinsic.qat)": [[730, "torch.ao.nn.intrinsic.qat.ConvReLU3d"]], "linearrelu (class in torch.ao.nn.intrinsic.qat)": [[731, "torch.ao.nn.intrinsic.qat.LinearReLU"]], "freeze_bn_stats (class in torch.ao.nn.intrinsic.qat)": [[732, "torch.ao.nn.intrinsic.qat.freeze_bn_stats"]], "update_bn_stats (class in torch.ao.nn.intrinsic.qat)": [[733, "torch.ao.nn.intrinsic.qat.update_bn_stats"]], "bnrelu2d (class in torch.ao.nn.intrinsic.quantized)": [[734, "torch.ao.nn.intrinsic.quantized.BNReLU2d"]], "bnrelu3d (class in torch.ao.nn.intrinsic.quantized)": [[735, "torch.ao.nn.intrinsic.quantized.BNReLU3d"]], "convrelu1d (class in torch.ao.nn.intrinsic.quantized)": [[736, "torch.ao.nn.intrinsic.quantized.ConvReLU1d"]], "convrelu2d (class in torch.ao.nn.intrinsic.quantized)": [[737, "torch.ao.nn.intrinsic.quantized.ConvReLU2d"]], "convrelu3d (class in torch.ao.nn.intrinsic.quantized)": [[738, "torch.ao.nn.intrinsic.quantized.ConvReLU3d"]], "linearrelu (class in torch.ao.nn.intrinsic.quantized)": [[739, "torch.ao.nn.intrinsic.quantized.LinearReLU"]], "linearrelu (class in torch.ao.nn.intrinsic.quantized.dynamic)": [[740, "torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU"]], "conv2d (class in torch.ao.nn.qat)": [[741, "torch.ao.nn.qat.Conv2d"]], "conv3d (class in torch.ao.nn.qat)": [[742, "torch.ao.nn.qat.Conv3d"]], "linear (class in torch.ao.nn.qat)": [[743, "torch.ao.nn.qat.Linear"]], "from_float() (torch.ao.nn.qat.linear class method)": [[743, "torch.ao.nn.qat.Linear.from_float"]], "linear (class in torch.ao.nn.qat.dynamic)": [[744, "torch.ao.nn.qat.dynamic.Linear"]], "lstm (class in torch.ao.nn.quantizable)": [[745, "torch.ao.nn.quantizable.LSTM"]], "multiheadattention (class in torch.ao.nn.quantizable)": [[746, "torch.ao.nn.quantizable.MultiheadAttention"]], "dequantize() (torch.ao.nn.quantizable.multiheadattention method)": [[746, "torch.ao.nn.quantizable.MultiheadAttention.dequantize"]], "forward() (torch.ao.nn.quantizable.multiheadattention method)": [[746, "torch.ao.nn.quantizable.MultiheadAttention.forward"]], "batchnorm2d (class in torch.ao.nn.quantized)": [[747, "torch.ao.nn.quantized.BatchNorm2d"]], "batchnorm3d (class in torch.ao.nn.quantized)": [[748, "torch.ao.nn.quantized.BatchNorm3d"]], "conv1d (class in torch.ao.nn.quantized)": [[749, "torch.ao.nn.quantized.Conv1d"]], "from_float() (torch.ao.nn.quantized.conv1d class method)": [[749, "torch.ao.nn.quantized.Conv1d.from_float"]], "conv2d (class in torch.ao.nn.quantized)": [[750, "torch.ao.nn.quantized.Conv2d"]], "from_float() (torch.ao.nn.quantized.conv2d class method)": [[750, "torch.ao.nn.quantized.Conv2d.from_float"]], "conv3d (class in torch.ao.nn.quantized)": [[751, "torch.ao.nn.quantized.Conv3d"]], "from_float() (torch.ao.nn.quantized.conv3d class method)": [[751, "torch.ao.nn.quantized.Conv3d.from_float"]], "convtranspose1d (class in torch.ao.nn.quantized)": [[752, "torch.ao.nn.quantized.ConvTranspose1d"]], "convtranspose2d (class in torch.ao.nn.quantized)": [[753, "torch.ao.nn.quantized.ConvTranspose2d"]], "convtranspose3d (class in torch.ao.nn.quantized)": [[754, "torch.ao.nn.quantized.ConvTranspose3d"]], "elu (class in torch.ao.nn.quantized)": [[755, "torch.ao.nn.quantized.ELU"]], "embedding (class in torch.ao.nn.quantized)": [[756, "torch.ao.nn.quantized.Embedding"]], "from_float() (torch.ao.nn.quantized.embedding class method)": [[756, "torch.ao.nn.quantized.Embedding.from_float"]], "embeddingbag (class in torch.ao.nn.quantized)": [[757, "torch.ao.nn.quantized.EmbeddingBag"]], "from_float() (torch.ao.nn.quantized.embeddingbag class method)": [[757, "torch.ao.nn.quantized.EmbeddingBag.from_float"]], "fxfloatfunctional (class in torch.ao.nn.quantized)": [[758, "torch.ao.nn.quantized.FXFloatFunctional"]], "floatfunctional (class in torch.ao.nn.quantized)": [[759, "torch.ao.nn.quantized.FloatFunctional"]], "groupnorm (class in torch.ao.nn.quantized)": [[760, "torch.ao.nn.quantized.GroupNorm"]], "hardswish (class in torch.ao.nn.quantized)": [[761, "torch.ao.nn.quantized.Hardswish"]], "instancenorm1d (class in torch.ao.nn.quantized)": [[762, "torch.ao.nn.quantized.InstanceNorm1d"]], "instancenorm2d (class in torch.ao.nn.quantized)": [[763, "torch.ao.nn.quantized.InstanceNorm2d"]], "instancenorm3d (class in torch.ao.nn.quantized)": [[764, "torch.ao.nn.quantized.InstanceNorm3d"]], "layernorm (class in torch.ao.nn.quantized)": [[765, "torch.ao.nn.quantized.LayerNorm"]], "leakyrelu (class in torch.ao.nn.quantized)": [[766, "torch.ao.nn.quantized.LeakyReLU"]], "linear (class in torch.ao.nn.quantized)": [[767, "torch.ao.nn.quantized.Linear"]], "from_float() (torch.ao.nn.quantized.linear class method)": [[767, "torch.ao.nn.quantized.Linear.from_float"]], "from_reference() (torch.ao.nn.quantized.linear class method)": [[767, "torch.ao.nn.quantized.Linear.from_reference"]], "qfunctional (class in torch.ao.nn.quantized)": [[768, "torch.ao.nn.quantized.QFunctional"]], "relu6 (class in torch.ao.nn.quantized)": [[769, "torch.ao.nn.quantized.ReLU6"]], "sigmoid (class in torch.ao.nn.quantized)": [[770, "torch.ao.nn.quantized.Sigmoid"]], "gru (class in torch.ao.nn.quantized.dynamic)": [[771, "torch.ao.nn.quantized.dynamic.GRU"]], "grucell (class in torch.ao.nn.quantized.dynamic)": [[772, "torch.ao.nn.quantized.dynamic.GRUCell"]], "lstm (class in torch.ao.nn.quantized.dynamic)": [[773, "torch.ao.nn.quantized.dynamic.LSTM"]], "lstmcell (class in torch.ao.nn.quantized.dynamic)": [[774, "torch.ao.nn.quantized.dynamic.LSTMCell"]], "linear (class in torch.ao.nn.quantized.dynamic)": [[775, "torch.ao.nn.quantized.dynamic.Linear"]], "from_float() (torch.ao.nn.quantized.dynamic.linear class method)": [[775, "torch.ao.nn.quantized.dynamic.Linear.from_float"]], "from_reference() (torch.ao.nn.quantized.dynamic.linear class method)": [[775, "torch.ao.nn.quantized.dynamic.Linear.from_reference"]], "rnncell (class in torch.ao.nn.quantized.dynamic)": [[776, "torch.ao.nn.quantized.dynamic.RNNCell"]], "adaptive_avg_pool2d (class in torch.ao.nn.quantized.functional)": [[777, "torch.ao.nn.quantized.functional.adaptive_avg_pool2d"]], "adaptive_avg_pool3d (class in torch.ao.nn.quantized.functional)": [[778, "torch.ao.nn.quantized.functional.adaptive_avg_pool3d"]], "avg_pool2d (class in torch.ao.nn.quantized.functional)": [[779, "torch.ao.nn.quantized.functional.avg_pool2d"]], "avg_pool3d (class in torch.ao.nn.quantized.functional)": [[780, "torch.ao.nn.quantized.functional.avg_pool3d"]], "celu (class in torch.ao.nn.quantized.functional)": [[781, "torch.ao.nn.quantized.functional.celu"]], "clamp (class in torch.ao.nn.quantized.functional)": [[782, "torch.ao.nn.quantized.functional.clamp"]], "conv1d (class in torch.ao.nn.quantized.functional)": [[783, "torch.ao.nn.quantized.functional.conv1d"]], "conv2d (class in torch.ao.nn.quantized.functional)": [[784, "torch.ao.nn.quantized.functional.conv2d"]], "conv3d (class in torch.ao.nn.quantized.functional)": [[785, "torch.ao.nn.quantized.functional.conv3d"]], "elu (class in torch.ao.nn.quantized.functional)": [[786, "torch.ao.nn.quantized.functional.elu"]], "hardsigmoid (class in torch.ao.nn.quantized.functional)": [[787, "torch.ao.nn.quantized.functional.hardsigmoid"]], "hardswish (class in torch.ao.nn.quantized.functional)": [[788, "torch.ao.nn.quantized.functional.hardswish"]], "hardtanh (class in torch.ao.nn.quantized.functional)": [[789, "torch.ao.nn.quantized.functional.hardtanh"]], "interpolate (class in torch.ao.nn.quantized.functional)": [[790, "torch.ao.nn.quantized.functional.interpolate"]], "leaky_relu (class in torch.ao.nn.quantized.functional)": [[791, "torch.ao.nn.quantized.functional.leaky_relu"]], "linear (class in torch.ao.nn.quantized.functional)": [[792, "torch.ao.nn.quantized.functional.linear"]], "max_pool1d (class in torch.ao.nn.quantized.functional)": [[793, "torch.ao.nn.quantized.functional.max_pool1d"]], "max_pool2d (class in torch.ao.nn.quantized.functional)": [[794, "torch.ao.nn.quantized.functional.max_pool2d"]], "threshold (class in torch.ao.nn.quantized.functional)": [[795, "torch.ao.nn.quantized.functional.threshold"]], "upsample (class in torch.ao.nn.quantized.functional)": [[796, "torch.ao.nn.quantized.functional.upsample"]], "upsample_bilinear (class in torch.ao.nn.quantized.functional)": [[797, "torch.ao.nn.quantized.functional.upsample_bilinear"]], "upsample_nearest (class in torch.ao.nn.quantized.functional)": [[798, "torch.ao.nn.quantized.functional.upsample_nearest"]], "custom_key (in module torch.ao.quantization)": [[799, "torch.ao.quantization.CUSTOM_KEY"]], "dequantstub (class in torch.ao.quantization)": [[800, "torch.ao.quantization.DeQuantStub"]], "numeric_debug_handle_key (in module torch.ao.quantization)": [[801, "torch.ao.quantization.NUMERIC_DEBUG_HANDLE_KEY"]], "quantstub (class in torch.ao.quantization)": [[802, "torch.ao.quantization.QuantStub"]], "quantwrapper (class in torch.ao.quantization)": [[803, "torch.ao.quantization.QuantWrapper"]], "add_quant_dequant (class in torch.ao.quantization)": [[804, "torch.ao.quantization.add_quant_dequant"]], "backendconfig (class in torch.ao.quantization.backend_config)": [[805, "torch.ao.quantization.backend_config.BackendConfig"]], "configs (torch.ao.quantization.backend_config.backendconfig property)": [[805, "torch.ao.quantization.backend_config.BackendConfig.configs"]], "from_dict() (torch.ao.quantization.backend_config.backendconfig class method)": [[805, "torch.ao.quantization.backend_config.BackendConfig.from_dict"]], "set_backend_pattern_config() (torch.ao.quantization.backend_config.backendconfig method)": [[805, "torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_config"]], "set_backend_pattern_configs() (torch.ao.quantization.backend_config.backendconfig method)": [[805, "torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_configs"]], "set_name() (torch.ao.quantization.backend_config.backendconfig method)": [[805, "torch.ao.quantization.backend_config.BackendConfig.set_name"]], "to_dict() (torch.ao.quantization.backend_config.backendconfig method)": [[805, "torch.ao.quantization.backend_config.BackendConfig.to_dict"]], "backendpatternconfig (class in torch.ao.quantization.backend_config)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig"]], "add_dtype_config() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.add_dtype_config"]], "from_dict() (torch.ao.quantization.backend_config.backendpatternconfig class method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.from_dict"]], "set_dtype_configs() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.set_dtype_configs"]], "set_fused_module() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.set_fused_module"]], "set_fuser_method() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.set_fuser_method"]], "set_observation_type() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.set_observation_type"]], "set_pattern() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.set_pattern"]], "set_qat_module() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.set_qat_module"]], "set_reference_quantized_module() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.set_reference_quantized_module"]], "set_root_module() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.set_root_module"]], "to_dict() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[806, "torch.ao.quantization.backend_config.BackendPatternConfig.to_dict"]], "dtypeconfig (class in torch.ao.quantization.backend_config)": [[807, "torch.ao.quantization.backend_config.DTypeConfig"]], "from_dict() (torch.ao.quantization.backend_config.dtypeconfig class method)": [[807, "torch.ao.quantization.backend_config.DTypeConfig.from_dict"]], "to_dict() (torch.ao.quantization.backend_config.dtypeconfig method)": [[807, "torch.ao.quantization.backend_config.DTypeConfig.to_dict"]], "dtypewithconstraints (class in torch.ao.quantization.backend_config)": [[808, "torch.ao.quantization.backend_config.DTypeWithConstraints"]], "input_output_not_observed (torch.ao.quantization.backend_config.observationtype attribute)": [[809, "torch.ao.quantization.backend_config.ObservationType.INPUT_OUTPUT_NOT_OBSERVED"]], "output_share_observer_with_input (torch.ao.quantization.backend_config.observationtype attribute)": [[809, "torch.ao.quantization.backend_config.ObservationType.OUTPUT_SHARE_OBSERVER_WITH_INPUT"]], "output_use_different_observer_as_input (torch.ao.quantization.backend_config.observationtype attribute)": [[809, "torch.ao.quantization.backend_config.ObservationType.OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT"]], "observationtype (class in torch.ao.quantization.backend_config)": [[809, "torch.ao.quantization.backend_config.ObservationType"]], "compare_results (class in torch.ao.quantization)": [[810, "torch.ao.quantization.compare_results"]], "convert (class in torch.ao.quantization)": [[811, "torch.ao.quantization.convert"]], "default_eval_fn (class in torch.ao.quantization)": [[812, "torch.ao.quantization.default_eval_fn"]], "extract_results_from_loggers (class in torch.ao.quantization)": [[813, "torch.ao.quantization.extract_results_from_loggers"]], "fakequantize (class in torch.ao.quantization.fake_quantize)": [[814, "torch.ao.quantization.fake_quantize.FakeQuantize"]], "fakequantizebase (class in torch.ao.quantization.fake_quantize)": [[815, "torch.ao.quantization.fake_quantize.FakeQuantizeBase"]], "fixedqparamsfakequantize (class in torch.ao.quantization.fake_quantize)": [[816, "torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize"]], "extra_repr() (torch.ao.quantization.fake_quantize.fixedqparamsfakequantize method)": [[816, "torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.extra_repr"]], "fusedmovingavgobsfakequantize (class in torch.ao.quantization.fake_quantize)": [[817, "torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize"]], "default_fake_quant (in module torch.ao.quantization.fake_quantize)": [[818, "torch.ao.quantization.fake_quantize.default_fake_quant"]], "default_fused_act_fake_quant (in module torch.ao.quantization.fake_quantize)": [[819, "torch.ao.quantization.fake_quantize.default_fused_act_fake_quant"]], "default_fused_per_channel_wt_fake_quant (in module torch.ao.quantization.fake_quantize)": [[820, "torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant"]], "default_fused_wt_fake_quant (in module torch.ao.quantization.fake_quantize)": [[821, "torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant"]], "default_histogram_fake_quant (in module torch.ao.quantization.fake_quantize)": [[822, "torch.ao.quantization.fake_quantize.default_histogram_fake_quant"]], "default_per_channel_weight_fake_quant (in module torch.ao.quantization.fake_quantize)": [[823, "torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant"]], "default_weight_fake_quant (in module torch.ao.quantization.fake_quantize)": [[824, "torch.ao.quantization.fake_quantize.default_weight_fake_quant"]], "disable_fake_quant (class in torch.ao.quantization.fake_quantize)": [[825, "torch.ao.quantization.fake_quantize.disable_fake_quant"]], "disable_observer (class in torch.ao.quantization.fake_quantize)": [[826, "torch.ao.quantization.fake_quantize.disable_observer"]], "enable_fake_quant (class in torch.ao.quantization.fake_quantize)": [[827, "torch.ao.quantization.fake_quantize.enable_fake_quant"]], "enable_observer (class in torch.ao.quantization.fake_quantize)": [[828, "torch.ao.quantization.fake_quantize.enable_observer"]], "fuse_modules (class in torch.ao.quantization.fuse_modules)": [[829, "torch.ao.quantization.fuse_modules.fuse_modules"]], "convertcustomconfig (class in torch.ao.quantization.fx.custom_config)": [[830, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig"]], "from_dict() (torch.ao.quantization.fx.custom_config.convertcustomconfig class method)": [[830, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig.from_dict"]], "set_observed_to_quantized_mapping() (torch.ao.quantization.fx.custom_config.convertcustomconfig method)": [[830, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig.set_observed_to_quantized_mapping"]], "set_preserved_attributes() (torch.ao.quantization.fx.custom_config.convertcustomconfig method)": [[830, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig.set_preserved_attributes"]], "to_dict() (torch.ao.quantization.fx.custom_config.convertcustomconfig method)": [[830, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig.to_dict"]], "fusecustomconfig (class in torch.ao.quantization.fx.custom_config)": [[831, "torch.ao.quantization.fx.custom_config.FuseCustomConfig"]], "from_dict() (torch.ao.quantization.fx.custom_config.fusecustomconfig class method)": [[831, "torch.ao.quantization.fx.custom_config.FuseCustomConfig.from_dict"]], "set_preserved_attributes() (torch.ao.quantization.fx.custom_config.fusecustomconfig method)": [[831, "torch.ao.quantization.fx.custom_config.FuseCustomConfig.set_preserved_attributes"]], "to_dict() (torch.ao.quantization.fx.custom_config.fusecustomconfig method)": [[831, "torch.ao.quantization.fx.custom_config.FuseCustomConfig.to_dict"]], "preparecustomconfig (class in torch.ao.quantization.fx.custom_config)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig"]], "from_dict() (torch.ao.quantization.fx.custom_config.preparecustomconfig class method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.from_dict"]], "set_float_to_observed_mapping() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_float_to_observed_mapping"]], "set_input_quantized_indexes() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_input_quantized_indexes"]], "set_non_traceable_module_classes() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_non_traceable_module_classes"]], "set_non_traceable_module_names() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_non_traceable_module_names"]], "set_output_quantized_indexes() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_output_quantized_indexes"]], "set_preserved_attributes() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_preserved_attributes"]], "set_standalone_module_class() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_standalone_module_class"]], "set_standalone_module_name() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_standalone_module_name"]], "to_dict() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[832, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.to_dict"]], "standalonemoduleconfigentry (class in torch.ao.quantization.fx.custom_config)": [[833, "torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry"]], "generate_numeric_debug_handle (class in torch.ao.quantization)": [[834, "torch.ao.quantization.generate_numeric_debug_handle"]], "histogramobserver (class in torch.ao.quantization.observer)": [[837, "torch.ao.quantization.observer.HistogramObserver"]], "minmaxobserver (class in torch.ao.quantization.observer)": [[839, "torch.ao.quantization.observer.MinMaxObserver"]], "calculate_qparams() (torch.ao.quantization.observer.minmaxobserver method)": [[839, "torch.ao.quantization.observer.MinMaxObserver.calculate_qparams"]], "forward() (torch.ao.quantization.observer.minmaxobserver method)": [[839, "torch.ao.quantization.observer.MinMaxObserver.forward"]], "reset_min_max_vals() (torch.ao.quantization.observer.minmaxobserver method)": [[839, "torch.ao.quantization.observer.MinMaxObserver.reset_min_max_vals"]], "movingaverageminmaxobserver (class in torch.ao.quantization.observer)": [[840, "torch.ao.quantization.observer.MovingAverageMinMaxObserver"]], "movingaverageperchannelminmaxobserver (class in torch.ao.quantization.observer)": [[841, "torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver"]], "noopobserver (class in torch.ao.quantization.observer)": [[842, "torch.ao.quantization.observer.NoopObserver"]], "observerbase (class in torch.ao.quantization.observer)": [[843, "torch.ao.quantization.observer.ObserverBase"]], "with_args() (torch.ao.quantization.observer.observerbase class method)": [[843, "torch.ao.quantization.observer.ObserverBase.with_args"]], "with_callable_args() (torch.ao.quantization.observer.observerbase class method)": [[843, "torch.ao.quantization.observer.ObserverBase.with_callable_args"]], "perchannelminmaxobserver (class in torch.ao.quantization.observer)": [[846, "torch.ao.quantization.observer.PerChannelMinMaxObserver"]], "reset_min_max_vals() (torch.ao.quantization.observer.perchannelminmaxobserver method)": [[846, "torch.ao.quantization.observer.PerChannelMinMaxObserver.reset_min_max_vals"]], "placeholderobserver (class in torch.ao.quantization.observer)": [[851, "torch.ao.quantization.observer.PlaceholderObserver"]], "recordingobserver (class in torch.ao.quantization.observer)": [[852, "torch.ao.quantization.observer.RecordingObserver"]], "default_debug_observer (in module torch.ao.quantization.observer)": [[855, "torch.ao.quantization.observer.default_debug_observer"]], "default_dynamic_quant_observer (in module torch.ao.quantization.observer)": [[856, "torch.ao.quantization.observer.default_dynamic_quant_observer"]], "default_float_qparams_observer (in module torch.ao.quantization.observer)": [[857, "torch.ao.quantization.observer.default_float_qparams_observer"]], "default_histogram_observer (in module torch.ao.quantization.observer)": [[858, "torch.ao.quantization.observer.default_histogram_observer"]], "default_observer (in module torch.ao.quantization.observer)": [[859, "torch.ao.quantization.observer.default_observer"]], "default_per_channel_weight_observer (in module torch.ao.quantization.observer)": [[860, "torch.ao.quantization.observer.default_per_channel_weight_observer"]], "default_placeholder_observer (in module torch.ao.quantization.observer)": [[861, "torch.ao.quantization.observer.default_placeholder_observer"]], "default_weight_observer (in module torch.ao.quantization.observer)": [[862, "torch.ao.quantization.observer.default_weight_observer"]], "get_observer_state_dict (class in torch.ao.quantization.observer)": [[864, "torch.ao.quantization.observer.get_observer_state_dict"]], "load_observer_state_dict (class in torch.ao.quantization.observer)": [[865, "torch.ao.quantization.observer.load_observer_state_dict"]], "prepare (class in torch.ao.quantization)": [[866, "torch.ao.quantization.prepare"]], "prepare_for_propagation_comparison (class in torch.ao.quantization)": [[867, "torch.ao.quantization.prepare_for_propagation_comparison"]], "prepare_qat (class in torch.ao.quantization)": [[868, "torch.ao.quantization.prepare_qat"]], "propagate_qconfig_ (class in torch.ao.quantization)": [[869, "torch.ao.quantization.propagate_qconfig_"]], "model_is_exported (class in torch.ao.quantization.pt2e.export_utils)": [[870, "torch.ao.quantization.pt2e.export_utils.model_is_exported"]], "qconfig (class in torch.ao.quantization.qconfig)": [[871, "torch.ao.quantization.qconfig.QConfig"]], "default_activation_only_qconfig (in module torch.ao.quantization.qconfig)": [[872, "torch.ao.quantization.qconfig.default_activation_only_qconfig"]], "default_debug_qconfig (in module torch.ao.quantization.qconfig)": [[873, "torch.ao.quantization.qconfig.default_debug_qconfig"]], "default_dynamic_qconfig (in module torch.ao.quantization.qconfig)": [[874, "torch.ao.quantization.qconfig.default_dynamic_qconfig"]], "default_per_channel_qconfig (in module torch.ao.quantization.qconfig)": [[875, "torch.ao.quantization.qconfig.default_per_channel_qconfig"]], "default_qat_qconfig (in module torch.ao.quantization.qconfig)": [[876, "torch.ao.quantization.qconfig.default_qat_qconfig"]], "default_qat_qconfig_v2 (in module torch.ao.quantization.qconfig)": [[877, "torch.ao.quantization.qconfig.default_qat_qconfig_v2"]], "default_qconfig (in module torch.ao.quantization.qconfig)": [[878, "torch.ao.quantization.qconfig.default_qconfig"]], "default_weight_only_qconfig (in module torch.ao.quantization.qconfig)": [[879, "torch.ao.quantization.qconfig.default_weight_only_qconfig"]], "float16_dynamic_qconfig (in module torch.ao.quantization.qconfig)": [[880, "torch.ao.quantization.qconfig.float16_dynamic_qconfig"]], "float16_static_qconfig (in module torch.ao.quantization.qconfig)": [[881, "torch.ao.quantization.qconfig.float16_static_qconfig"]], "float_qparams_weight_only_qconfig (in module torch.ao.quantization.qconfig)": [[882, "torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig"]], "per_channel_dynamic_qconfig (in module torch.ao.quantization.qconfig)": [[883, "torch.ao.quantization.qconfig.per_channel_dynamic_qconfig"]], "qconfigmapping (class in torch.ao.quantization.qconfig_mapping)": [[884, "torch.ao.quantization.qconfig_mapping.QConfigMapping"]], "from_dict() (torch.ao.quantization.qconfig_mapping.qconfigmapping class method)": [[884, "torch.ao.quantization.qconfig_mapping.QConfigMapping.from_dict"]], "set_global() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[884, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_global"]], "set_module_name() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[884, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name"]], "set_module_name_object_type_order() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[884, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name_object_type_order"]], "set_module_name_regex() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[884, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name_regex"]], "set_object_type() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[884, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_object_type"]], "to_dict() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[884, "torch.ao.quantization.qconfig_mapping.QConfigMapping.to_dict"]], "get_default_qat_qconfig_mapping (class in torch.ao.quantization.qconfig_mapping)": [[885, "torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping"]], "get_default_qconfig_mapping (class in torch.ao.quantization.qconfig_mapping)": [[886, "torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping"]], "quantize (class in torch.ao.quantization)": [[887, "torch.ao.quantization.quantize"]], "quantize_dynamic (class in torch.ao.quantization)": [[888, "torch.ao.quantization.quantize_dynamic"]], "convert_fx (class in torch.ao.quantization.quantize_fx)": [[889, "torch.ao.quantization.quantize_fx.convert_fx"]], "fuse_fx (class in torch.ao.quantization.quantize_fx)": [[890, "torch.ao.quantization.quantize_fx.fuse_fx"]], "prepare_fx (class in torch.ao.quantization.quantize_fx)": [[891, "torch.ao.quantization.quantize_fx.prepare_fx"]], "prepare_qat_fx (class in torch.ao.quantization.quantize_fx)": [[892, "torch.ao.quantization.quantize_fx.prepare_qat_fx"]], "quantize_qat (class in torch.ao.quantization)": [[893, "torch.ao.quantization.quantize_qat"]], "swap_module (class in torch.ao.quantization)": [[894, "torch.ao.quantization.swap_module"]], "arange() (in module torch)": [[895, "torch.arange"]], "arccos() (in module torch)": [[896, "torch.arccos"]], "arccosh() (in module torch)": [[897, "torch.arccosh"]], "arcsin() (in module torch)": [[898, "torch.arcsin"]], "arcsinh() (in module torch)": [[899, "torch.arcsinh"]], "arctan() (in module torch)": [[900, "torch.arctan"]], "arctan2() (in module torch)": [[901, "torch.arctan2"]], "arctanh() (in module torch)": [[902, "torch.arctanh"]], "are_deterministic_algorithms_enabled() (in module torch)": [[903, "torch.are_deterministic_algorithms_enabled"]], "argmax() (in module torch)": [[904, "torch.argmax"]], "argmin() (in module torch)": [[905, "torch.argmin"]], "argsort() (in module torch)": [[906, "torch.argsort"]], "argwhere() (in module torch)": [[907, "torch.argwhere"]], "as_strided() (in module torch)": [[908, "torch.as_strided"]], "as_tensor() (in module torch)": [[909, "torch.as_tensor"]], "asarray() (in module torch)": [[910, "torch.asarray"]], "asin() (in module torch)": [[911, "torch.asin"]], "asinh() (in module torch)": [[912, "torch.asinh"]], "atan() (in module torch)": [[913, "torch.atan"]], "atan2() (in module torch)": [[914, "torch.atan2"]], "atanh() (in module torch)": [[915, "torch.atanh"]], "atleast_1d() (in module torch)": [[916, "torch.atleast_1d"]], "atleast_2d() (in module torch)": [[917, "torch.atleast_2d"]], "atleast_3d() (in module torch)": [[918, "torch.atleast_3d"]], "backward() (torch.autograd.function static method)": [[919, "torch.autograd.Function.backward"]], "forward() (torch.autograd.function static method)": [[920, "torch.autograd.Function.forward"]], "jvp() (torch.autograd.function static method)": [[921, "torch.autograd.Function.jvp"]], "vmap() (torch.autograd.function static method)": [[922, "torch.autograd.Function.vmap"]], "backward() (in module torch.autograd)": [[923, "torch.autograd.backward"]], "unpackeddualtensor (class in torch.autograd.forward_ad)": [[924, "torch.autograd.forward_ad.UnpackedDualTensor"]], "count() (torch.autograd.forward_ad.unpackeddualtensor method)": [[924, "torch.autograd.forward_ad.UnpackedDualTensor.count"]], "index() (torch.autograd.forward_ad.unpackeddualtensor method)": [[924, "torch.autograd.forward_ad.UnpackedDualTensor.index"]], "primal (torch.autograd.forward_ad.unpackeddualtensor attribute)": [[924, "torch.autograd.forward_ad.UnpackedDualTensor.primal"]], "tangent (torch.autograd.forward_ad.unpackeddualtensor attribute)": [[924, "torch.autograd.forward_ad.UnpackedDualTensor.tangent"]], "dual_level (class in torch.autograd.forward_ad)": [[925, "torch.autograd.forward_ad.dual_level"]], "enter_dual_level() (in module torch.autograd.forward_ad)": [[926, "torch.autograd.forward_ad.enter_dual_level"]], "exit_dual_level() (in module torch.autograd.forward_ad)": [[927, "torch.autograd.forward_ad.exit_dual_level"]], "make_dual() (in module torch.autograd.forward_ad)": [[928, "torch.autograd.forward_ad.make_dual"]], "unpack_dual() (in module torch.autograd.forward_ad)": [[929, "torch.autograd.forward_ad.unpack_dual"]], "backwardcfunction (class in torch.autograd.function)": [[930, "torch.autograd.function.BackwardCFunction"]], "apply() (torch.autograd.function.backwardcfunction method)": [[930, "torch.autograd.function.BackwardCFunction.apply"]], "apply_jvp() (torch.autograd.function.backwardcfunction method)": [[930, "torch.autograd.function.BackwardCFunction.apply_jvp"]], "mark_dirty() (torch.autograd.function.backwardcfunction method)": [[930, "torch.autograd.function.BackwardCFunction.mark_dirty"]], "mark_non_differentiable() (torch.autograd.function.backwardcfunction method)": [[930, "torch.autograd.function.BackwardCFunction.mark_non_differentiable"]], "save_for_backward() (torch.autograd.function.backwardcfunction method)": [[930, "torch.autograd.function.BackwardCFunction.save_for_backward"]], "save_for_forward() (torch.autograd.function.backwardcfunction method)": [[930, "torch.autograd.function.BackwardCFunction.save_for_forward"]], "set_materialize_grads() (torch.autograd.function.backwardcfunction method)": [[930, "torch.autograd.function.BackwardCFunction.set_materialize_grads"]], "mark_dirty() (torch.autograd.function.functionctx method)": [[931, "torch.autograd.function.FunctionCtx.mark_dirty"]], "mark_non_differentiable() (torch.autograd.function.functionctx method)": [[932, "torch.autograd.function.FunctionCtx.mark_non_differentiable"]], "save_for_backward() (torch.autograd.function.functionctx method)": [[933, "torch.autograd.function.FunctionCtx.save_for_backward"]], "set_materialize_grads() (torch.autograd.function.functionctx method)": [[934, "torch.autograd.function.FunctionCtx.set_materialize_grads"]], "inplacefunction (class in torch.autograd.function)": [[935, "torch.autograd.function.InplaceFunction"]], "backward() (torch.autograd.function.inplacefunction static method)": [[935, "torch.autograd.function.InplaceFunction.backward"]], "forward() (torch.autograd.function.inplacefunction static method)": [[935, "torch.autograd.function.InplaceFunction.forward"]], "jvp() (torch.autograd.function.inplacefunction static method)": [[935, "torch.autograd.function.InplaceFunction.jvp"]], "mark_dirty() (torch.autograd.function.inplacefunction method)": [[935, "torch.autograd.function.InplaceFunction.mark_dirty"]], "mark_non_differentiable() (torch.autograd.function.inplacefunction method)": [[935, "torch.autograd.function.InplaceFunction.mark_non_differentiable"]], "save_for_backward() (torch.autograd.function.inplacefunction method)": [[935, "torch.autograd.function.InplaceFunction.save_for_backward"]], "save_for_forward() (torch.autograd.function.inplacefunction method)": [[935, "torch.autograd.function.InplaceFunction.save_for_forward"]], "set_materialize_grads() (torch.autograd.function.inplacefunction method)": [[935, "torch.autograd.function.InplaceFunction.set_materialize_grads"]], "setup_context() (torch.autograd.function.inplacefunction static method)": [[935, "torch.autograd.function.InplaceFunction.setup_context"]], "vjp() (torch.autograd.function.inplacefunction static method)": [[935, "torch.autograd.function.InplaceFunction.vjp"]], "vmap() (torch.autograd.function.inplacefunction static method)": [[935, "torch.autograd.function.InplaceFunction.vmap"]], "nestediofunction (class in torch.autograd.function)": [[936, "torch.autograd.function.NestedIOFunction"]], "backward() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.backward"]], "backward_extended() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.backward_extended"]], "forward() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.forward"]], "forward_extended() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.forward_extended"]], "jvp() (torch.autograd.function.nestediofunction static method)": [[936, "torch.autograd.function.NestedIOFunction.jvp"]], "mark_dirty() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.mark_dirty"]], "mark_non_differentiable() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.mark_non_differentiable"]], "save_for_backward() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.save_for_backward"]], "save_for_forward() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.save_for_forward"]], "saved_tensors (torch.autograd.function.nestediofunction property)": [[936, "torch.autograd.function.NestedIOFunction.saved_tensors"]], "set_materialize_grads() (torch.autograd.function.nestediofunction method)": [[936, "torch.autograd.function.NestedIOFunction.set_materialize_grads"]], "setup_context() (torch.autograd.function.nestediofunction static method)": [[936, "torch.autograd.function.NestedIOFunction.setup_context"]], "vjp() (torch.autograd.function.nestediofunction static method)": [[936, "torch.autograd.function.NestedIOFunction.vjp"]], "vmap() (torch.autograd.function.nestediofunction static method)": [[936, "torch.autograd.function.NestedIOFunction.vmap"]], "once_differentiable() (in module torch.autograd.function)": [[937, "torch.autograd.function.once_differentiable"]], "hessian() (in module torch.autograd.functional)": [[938, "torch.autograd.functional.hessian"]], "hvp() (in module torch.autograd.functional)": [[939, "torch.autograd.functional.hvp"]], "jacobian() (in module torch.autograd.functional)": [[940, "torch.autograd.functional.jacobian"]], "jvp() (in module torch.autograd.functional)": [[941, "torch.autograd.functional.jvp"]], "vhp() (in module torch.autograd.functional)": [[942, "torch.autograd.functional.vhp"]], "vjp() (in module torch.autograd.functional)": [[943, "torch.autograd.functional.vjp"]], "grad() (in module torch.autograd)": [[944, "torch.autograd.grad"]], "clone() (torch.autograd.grad_mode.inference_mode method)": [[945, "torch.autograd.grad_mode.inference_mode.clone"]], "inference_mode (class in torch.autograd.grad_mode)": [[945, "torch.autograd.grad_mode.inference_mode"]], "clone() (torch.autograd.grad_mode.set_grad_enabled method)": [[946, "torch.autograd.grad_mode.set_grad_enabled.clone"]], "set_grad_enabled (class in torch.autograd.grad_mode)": [[946, "torch.autograd.grad_mode.set_grad_enabled"]], "clone() (torch.autograd.grad_mode.set_multithreading_enabled method)": [[947, "torch.autograd.grad_mode.set_multithreading_enabled.clone"]], "set_multithreading_enabled (class in torch.autograd.grad_mode)": [[947, "torch.autograd.grad_mode.set_multithreading_enabled"]], "gradcheckerror": [[948, "torch.autograd.gradcheck.GradcheckError"]], "gradcheck() (in module torch.autograd.gradcheck)": [[949, "torch.autograd.gradcheck.gradcheck"]], "gradgradcheck() (in module torch.autograd.gradcheck)": [[950, "torch.autograd.gradcheck.gradgradcheck"]], "metadata() (torch.autograd.graph.node method)": [[951, "torch.autograd.graph.Node.metadata"]], "name() (torch.autograd.graph.node method)": [[952, "torch.autograd.graph.Node.name"]], "next_functions (torch.autograd.graph.node property)": [[953, "torch.autograd.graph.Node.next_functions"]], "register_hook() (torch.autograd.graph.node method)": [[954, "torch.autograd.graph.Node.register_hook"]], "register_prehook() (torch.autograd.graph.node method)": [[955, "torch.autograd.graph.Node.register_prehook"]], "increment_version() (in module torch.autograd.graph)": [[956, "torch.autograd.graph.increment_version"]], "enforceunique (class in torch.autograd.profiler)": [[957, "torch.autograd.profiler.EnforceUnique"]], "see() (torch.autograd.profiler.enforceunique method)": [[957, "torch.autograd.profiler.EnforceUnique.see"]], "kinetosteptracker (class in torch.autograd.profiler)": [[958, "torch.autograd.profiler.KinetoStepTracker"]], "current_step() (torch.autograd.profiler.kinetosteptracker class method)": [[958, "torch.autograd.profiler.KinetoStepTracker.current_step"]], "erase_step_count() (torch.autograd.profiler.kinetosteptracker class method)": [[958, "torch.autograd.profiler.KinetoStepTracker.erase_step_count"]], "increment_step() (torch.autograd.profiler.kinetosteptracker class method)": [[958, "torch.autograd.profiler.KinetoStepTracker.increment_step"]], "init_step_count() (torch.autograd.profiler.kinetosteptracker class method)": [[958, "torch.autograd.profiler.KinetoStepTracker.init_step_count"]], "load_nvprof() (in module torch.autograd.profiler)": [[959, "torch.autograd.profiler.load_nvprof"]], "parse_nvprof_trace() (in module torch.autograd.profiler)": [[960, "torch.autograd.profiler.parse_nvprof_trace"]], "export_chrome_trace() (torch.autograd.profiler.profile method)": [[961, "torch.autograd.profiler.profile.export_chrome_trace"]], "key_averages() (torch.autograd.profiler.profile method)": [[962, "torch.autograd.profiler.profile.key_averages"]], "self_cpu_time_total (torch.autograd.profiler.profile property)": [[963, "torch.autograd.profiler.profile.self_cpu_time_total"]], "total_average() (torch.autograd.profiler.profile method)": [[964, "torch.autograd.profiler.profile.total_average"]], "record_function (class in torch.autograd.profiler)": [[965, "torch.autograd.profiler.record_function"]], "interval (class in torch.autograd.profiler_util)": [[966, "torch.autograd.profiler_util.Interval"]], "elapsed_us() (torch.autograd.profiler_util.interval method)": [[966, "torch.autograd.profiler_util.Interval.elapsed_us"]], "kernel (class in torch.autograd.profiler_util)": [[967, "torch.autograd.profiler_util.Kernel"]], "count() (torch.autograd.profiler_util.kernel method)": [[967, "torch.autograd.profiler_util.Kernel.count"]], "device (torch.autograd.profiler_util.kernel attribute)": [[967, "torch.autograd.profiler_util.Kernel.device"]], "duration (torch.autograd.profiler_util.kernel attribute)": [[967, "torch.autograd.profiler_util.Kernel.duration"]], "index() (torch.autograd.profiler_util.kernel method)": [[967, "torch.autograd.profiler_util.Kernel.index"]], "name (torch.autograd.profiler_util.kernel attribute)": [[967, "torch.autograd.profiler_util.Kernel.name"]], "memrecordsacc (class in torch.autograd.profiler_util)": [[968, "torch.autograd.profiler_util.MemRecordsAcc"]], "in_interval() (torch.autograd.profiler_util.memrecordsacc method)": [[968, "torch.autograd.profiler_util.MemRecordsAcc.in_interval"]], "stringtable (class in torch.autograd.profiler_util)": [[969, "torch.autograd.profiler_util.StringTable"]], "clear() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.clear"]], "copy() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.copy"]], "default_factory (torch.autograd.profiler_util.stringtable attribute)": [[969, "torch.autograd.profiler_util.StringTable.default_factory"]], "fromkeys() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.fromkeys"]], "get() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.get"]], "items() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.items"]], "keys() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.keys"]], "pop() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.pop"]], "popitem() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.popitem"]], "setdefault() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.setdefault"]], "update() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.update"]], "values() (torch.autograd.profiler_util.stringtable method)": [[969, "torch.autograd.profiler_util.StringTable.values"]], "baddbmm() (in module torch)": [[970, "torch.baddbmm"]], "bartlett_window() (in module torch)": [[971, "torch.bartlett_window"]], "bernoulli() (in module torch)": [[972, "torch.bernoulli"]], "bincount() (in module torch)": [[973, "torch.bincount"]], "bitwise_and() (in module torch)": [[974, "torch.bitwise_and"]], "bitwise_left_shift() (in module torch)": [[975, "torch.bitwise_left_shift"]], "bitwise_not() (in module torch)": [[976, "torch.bitwise_not"]], "bitwise_or() (in module torch)": [[977, "torch.bitwise_or"]], "bitwise_right_shift() (in module torch)": [[978, "torch.bitwise_right_shift"]], "bitwise_xor() (in module torch)": [[979, "torch.bitwise_xor"]], "blackman_window() (in module torch)": [[980, "torch.blackman_window"]], "block_diag() (in module torch)": [[981, "torch.block_diag"]], "bmm() (in module torch)": [[982, "torch.bmm"]], "broadcast_shapes() (in module torch)": [[983, "torch.broadcast_shapes"]], "broadcast_tensors() (in module torch)": [[984, "torch.broadcast_tensors"]], "broadcast_to() (in module torch)": [[985, "torch.broadcast_to"]], "bucketize() (in module torch)": [[986, "torch.bucketize"]], "can_cast() (in module torch)": [[987, "torch.can_cast"]], "cartesian_prod() (in module torch)": [[988, "torch.cartesian_prod"]], "cat() (in module torch)": [[989, "torch.cat"]], "cdist() (in module torch)": [[990, "torch.cdist"]], "ceil() (in module torch)": [[991, "torch.ceil"]], "chain_matmul() (in module torch)": [[992, "torch.chain_matmul"]], "cholesky() (in module torch)": [[993, "torch.cholesky"]], "cholesky_inverse() (in module torch)": [[994, "torch.cholesky_inverse"]], "cholesky_solve() (in module torch)": [[995, "torch.cholesky_solve"]], "chunk() (in module torch)": [[996, "torch.chunk"]], "clamp() (in module torch)": [[997, "torch.clamp"]], "clip() (in module torch)": [[998, "torch.clip"]], "clone() (in module torch)": [[999, "torch.clone"]], "column_stack() (in module torch)": [[1000, "torch.column_stack"]], "combinations() (in module torch)": [[1001, "torch.combinations"]], "compile() (in module torch)": [[1002, "torch.compile"]], "compiled_with_cxx11_abi() (in module torch)": [[1003, "torch.compiled_with_cxx11_abi"]], "allow_in_graph() (in module torch.compiler)": [[1004, "torch.compiler.allow_in_graph"]], "assume_constant_result() (in module torch.compiler)": [[1005, "torch.compiler.assume_constant_result"]], "compile() (in module torch.compiler)": [[1006, "torch.compiler.compile"]], "cudagraph_mark_step_begin() (in module torch.compiler)": [[1007, "torch.compiler.cudagraph_mark_step_begin"]], "disable() (in module torch.compiler)": [[1008, "torch.compiler.disable"]], "is_compiling() (in module torch.compiler)": [[1009, "torch.compiler.is_compiling"]], "is_dynamo_compiling() (in module torch.compiler)": [[1010, "torch.compiler.is_dynamo_compiling"]], "list_backends() (in module torch.compiler)": [[1012, "torch.compiler.list_backends"]], "reset() (in module torch.compiler)": [[1013, "torch.compiler.reset"]], "set_stance() (in module torch.compiler)": [[1014, "torch.compiler.set_stance"]], "substitute_in_graph() (in module torch.compiler)": [[1015, "torch.compiler.substitute_in_graph"]], "complex() (in module torch)": [[1016, "torch.complex"]], "concat() (in module torch)": [[1017, "torch.concat"]], "concatenate() (in module torch)": [[1018, "torch.concatenate"]], "cond() (in module torch)": [[1019, "torch.cond"]], "conj() (in module torch)": [[1020, "torch.conj"]], "conj_physical() (in module torch)": [[1021, "torch.conj_physical"]], "copysign() (in module torch)": [[1022, "torch.copysign"]], "corrcoef() (in module torch)": [[1023, "torch.corrcoef"]], "cos() (in module torch)": [[1024, "torch.cos"]], "cosh() (in module torch)": [[1025, "torch.cosh"]], "count_nonzero() (in module torch)": [[1026, "torch.count_nonzero"]], "cov() (in module torch)": [[1027, "torch.cov"]], "stream() (in module torch.cpu)": [[1028, "torch.cpu.stream"]], "streamcontext (class in torch.cpu)": [[1029, "torch.cpu.StreamContext"]], "current_device() (in module torch.cpu)": [[1030, "torch.cpu.current_device"]], "current_stream() (in module torch.cpu)": [[1031, "torch.cpu.current_stream"]], "device_count() (in module torch.cpu)": [[1032, "torch.cpu.device_count"]], "is_available() (in module torch.cpu)": [[1033, "torch.cpu.is_available"]], "set_device() (in module torch.cpu)": [[1034, "torch.cpu.set_device"]], "synchronize() (in module torch.cpu)": [[1035, "torch.cpu.synchronize"]], "cross() (in module torch)": [[1036, "torch.cross"]], "cudagraph (class in torch.cuda)": [[1037, "torch.cuda.CUDAGraph"]], "capture_begin() (torch.cuda.cudagraph method)": [[1037, "torch.cuda.CUDAGraph.capture_begin"]], "capture_end() (torch.cuda.cudagraph method)": [[1037, "torch.cuda.CUDAGraph.capture_end"]], "debug_dump() (torch.cuda.cudagraph method)": [[1037, "torch.cuda.CUDAGraph.debug_dump"]], "enable_debug_mode() (torch.cuda.cudagraph method)": [[1037, "torch.cuda.CUDAGraph.enable_debug_mode"]], "pool() (torch.cuda.cudagraph method)": [[1037, "torch.cuda.CUDAGraph.pool"]], "replay() (torch.cuda.cudagraph method)": [[1037, "torch.cuda.CUDAGraph.replay"]], "reset() (torch.cuda.cudagraph method)": [[1037, "torch.cuda.CUDAGraph.reset"]], "cudapluggableallocator (class in torch.cuda)": [[1038, "torch.cuda.CUDAPluggableAllocator"]], "event (class in torch.cuda)": [[1039, "torch.cuda.Event"]], "elapsed_time() (torch.cuda.event method)": [[1039, "torch.cuda.Event.elapsed_time"]], "from_ipc_handle() (torch.cuda.event class method)": [[1039, "torch.cuda.Event.from_ipc_handle"]], "ipc_handle() (torch.cuda.event method)": [[1039, "torch.cuda.Event.ipc_handle"]], "query() (torch.cuda.event method)": [[1039, "torch.cuda.Event.query"]], "record() (torch.cuda.event method)": [[1039, "torch.cuda.Event.record"]], "synchronize() (torch.cuda.event method)": [[1039, "torch.cuda.Event.synchronize"]], "wait() (torch.cuda.event method)": [[1039, "torch.cuda.Event.wait"]], "externalstream (class in torch.cuda)": [[1040, "torch.cuda.ExternalStream"]], "query() (torch.cuda.externalstream method)": [[1040, "torch.cuda.ExternalStream.query"]], "record_event() (torch.cuda.externalstream method)": [[1040, "torch.cuda.ExternalStream.record_event"]], "synchronize() (torch.cuda.externalstream method)": [[1040, "torch.cuda.ExternalStream.synchronize"]], "wait_event() (torch.cuda.externalstream method)": [[1040, "torch.cuda.ExternalStream.wait_event"]], "wait_stream() (torch.cuda.externalstream method)": [[1040, "torch.cuda.ExternalStream.wait_stream"]], "mempool (class in torch.cuda)": [[1041, "torch.cuda.MemPool"]], "allocator (torch.cuda.mempool property)": [[1041, "torch.cuda.MemPool.allocator"]], "id (torch.cuda.mempool property)": [[1041, "torch.cuda.MemPool.id"]], "snapshot() (torch.cuda.mempool method)": [[1041, "torch.cuda.MemPool.snapshot"]], "use_count() (torch.cuda.mempool method)": [[1041, "torch.cuda.MemPool.use_count"]], "mempoolcontext (class in torch.cuda)": [[1042, "torch.cuda.MemPoolContext"]], "active_pool() (torch.cuda.mempoolcontext static method)": [[1042, "torch.cuda.MemPoolContext.active_pool"]], "outofmemoryerror": [[1043, "torch.cuda.OutOfMemoryError"]], "stream() (in module torch.cuda)": [[1044, "torch.cuda.stream"]], "streamcontext (class in torch.cuda)": [[1045, "torch.cuda.StreamContext"]], "caching_allocator_alloc() (in module torch.cuda)": [[1046, "torch.cuda.caching_allocator_alloc"]], "caching_allocator_delete() (in module torch.cuda)": [[1047, "torch.cuda.caching_allocator_delete"]], "can_device_access_peer() (in module torch.cuda)": [[1048, "torch.cuda.can_device_access_peer"]], "change_current_allocator() (in module torch.cuda)": [[1049, "torch.cuda.change_current_allocator"]], "clock_rate() (in module torch.cuda)": [[1050, "torch.cuda.clock_rate"]], "broadcast() (in module torch.cuda.comm)": [[1051, "torch.cuda.comm.broadcast"]], "broadcast_coalesced() (in module torch.cuda.comm)": [[1052, "torch.cuda.comm.broadcast_coalesced"]], "gather() (in module torch.cuda.comm)": [[1053, "torch.cuda.comm.gather"]], "reduce_add() (in module torch.cuda.comm)": [[1054, "torch.cuda.comm.reduce_add"]], "reduce_add_coalesced() (in module torch.cuda.comm)": [[1055, "torch.cuda.comm.reduce_add_coalesced"]], "scatter() (in module torch.cuda.comm)": [[1056, "torch.cuda.comm.scatter"]], "cudart() (in module torch.cuda)": [[1057, "torch.cuda.cudart"]], "current_blas_handle() (in module torch.cuda)": [[1058, "torch.cuda.current_blas_handle"]], "current_device() (in module torch.cuda)": [[1059, "torch.cuda.current_device"]], "current_stream() (in module torch.cuda)": [[1060, "torch.cuda.current_stream"]], "default_stream() (in module torch.cuda)": [[1061, "torch.cuda.default_stream"]], "device (class in torch.cuda)": [[1062, "torch.cuda.device"]], "device_count() (in module torch.cuda)": [[1063, "torch.cuda.device_count"]], "device_memory_used() (in module torch.cuda)": [[1064, "torch.cuda.device_memory_used"]], "device_of (class in torch.cuda)": [[1065, "torch.cuda.device_of"]], "empty_cache() (in module torch.cuda)": [[1066, "torch.cuda.empty_cache"]], "get_allocator_backend() (in module torch.cuda)": [[1067, "torch.cuda.get_allocator_backend"]], "get_arch_list() (in module torch.cuda)": [[1068, "torch.cuda.get_arch_list"]], "get_device_capability() (in module torch.cuda)": [[1069, "torch.cuda.get_device_capability"]], "get_device_name() (in module torch.cuda)": [[1070, "torch.cuda.get_device_name"]], "get_device_properties() (in module torch.cuda)": [[1071, "torch.cuda.get_device_properties"]], "get_gencode_flags() (in module torch.cuda)": [[1072, "torch.cuda.get_gencode_flags"]], "get_per_process_memory_fraction() (in module torch.cuda)": [[1073, "torch.cuda.get_per_process_memory_fraction"]], "get_rng_state() (in module torch.cuda)": [[1074, "torch.cuda.get_rng_state"]], "get_rng_state_all() (in module torch.cuda)": [[1075, "torch.cuda.get_rng_state_all"]], "get_sync_debug_mode() (in module torch.cuda)": [[1077, "torch.cuda.get_sync_debug_mode"]], "graph (class in torch.cuda)": [[1078, "torch.cuda.graph"]], "graph_pool_handle() (in module torch.cuda)": [[1079, "torch.cuda.graph_pool_handle"]], "init() (in module torch.cuda)": [[1080, "torch.cuda.init"]], "initial_seed() (in module torch.cuda)": [[1081, "torch.cuda.initial_seed"]], "ipc_collect() (in module torch.cuda)": [[1082, "torch.cuda.ipc_collect"]], "is_available() (in module torch.cuda)": [[1083, "torch.cuda.is_available"]], "is_current_stream_capturing() (in module torch.cuda)": [[1084, "torch.cuda.is_current_stream_capturing"]], "is_initialized() (in module torch.cuda)": [[1085, "torch.cuda.is_initialized"]], "_create_jit_fn() (in module torch.cuda.jiterator)": [[1086, "torch.cuda.jiterator._create_jit_fn"]], "_create_multi_output_jit_fn() (in module torch.cuda.jiterator)": [[1087, "torch.cuda.jiterator._create_multi_output_jit_fn"]], "list_gpu_processes() (in module torch.cuda)": [[1088, "torch.cuda.list_gpu_processes"]], "make_graphed_callables() (in module torch.cuda)": [[1089, "torch.cuda.make_graphed_callables"]], "manual_seed() (in module torch.cuda)": [[1090, "torch.cuda.manual_seed"]], "manual_seed_all() (in module torch.cuda)": [[1091, "torch.cuda.manual_seed_all"]], "max_memory_allocated() (in module torch.cuda)": [[1092, "torch.cuda.max_memory_allocated"]], "max_memory_cached() (in module torch.cuda)": [[1093, "torch.cuda.max_memory_cached"]], "max_memory_reserved() (in module torch.cuda)": [[1094, "torch.cuda.max_memory_reserved"]], "mem_get_info() (in module torch.cuda)": [[1095, "torch.cuda.mem_get_info"]], "caching_allocator_enable() (in module torch.cuda.memory)": [[1096, "torch.cuda.memory.caching_allocator_enable"]], "memory_allocated() (in module torch.cuda)": [[1097, "torch.cuda.memory_allocated"]], "memory_cached() (in module torch.cuda)": [[1098, "torch.cuda.memory_cached"]], "memory_reserved() (in module torch.cuda)": [[1099, "torch.cuda.memory_reserved"]], "memory_snapshot() (in module torch.cuda)": [[1100, "torch.cuda.memory_snapshot"]], "memory_stats() (in module torch.cuda)": [[1101, "torch.cuda.memory_stats"]], "memory_summary() (in module torch.cuda)": [[1102, "torch.cuda.memory_summary"]], "memory_usage() (in module torch.cuda)": [[1103, "torch.cuda.memory_usage"]], "mark() (in module torch.cuda.nvtx)": [[1104, "torch.cuda.nvtx.mark"]], "range() (in module torch.cuda.nvtx)": [[1105, "torch.cuda.nvtx.range"]], "range_pop() (in module torch.cuda.nvtx)": [[1106, "torch.cuda.nvtx.range_pop"]], "range_push() (in module torch.cuda.nvtx)": [[1107, "torch.cuda.nvtx.range_push"]], "power_draw() (in module torch.cuda)": [[1108, "torch.cuda.power_draw"]], "reset_max_memory_allocated() (in module torch.cuda)": [[1109, "torch.cuda.reset_max_memory_allocated"]], "reset_max_memory_cached() (in module torch.cuda)": [[1110, "torch.cuda.reset_max_memory_cached"]], "reset_peak_memory_stats() (in module torch.cuda)": [[1111, "torch.cuda.reset_peak_memory_stats"]], "seed() (in module torch.cuda)": [[1112, "torch.cuda.seed"]], "seed_all() (in module torch.cuda)": [[1113, "torch.cuda.seed_all"]], "set_device() (in module torch.cuda)": [[1114, "torch.cuda.set_device"]], "set_per_process_memory_fraction() (in module torch.cuda)": [[1115, "torch.cuda.set_per_process_memory_fraction"]], "set_rng_state() (in module torch.cuda)": [[1116, "torch.cuda.set_rng_state"]], "set_rng_state_all() (in module torch.cuda)": [[1117, "torch.cuda.set_rng_state_all"]], "set_stream() (in module torch.cuda)": [[1118, "torch.cuda.set_stream"]], "set_sync_debug_mode() (in module torch.cuda)": [[1119, "torch.cuda.set_sync_debug_mode"]], "synchronize() (in module torch.cuda)": [[1120, "torch.cuda.synchronize"]], "temperature() (in module torch.cuda)": [[1121, "torch.cuda.temperature"]], "utilization() (in module torch.cuda)": [[1122, "torch.cuda.utilization"]], "cummax() (in module torch)": [[1123, "torch.cummax"]], "cummin() (in module torch)": [[1124, "torch.cummin"]], "cumprod() (in module torch)": [[1125, "torch.cumprod"]], "cumsum() (in module torch)": [[1126, "torch.cumsum"]], "cumulative_trapezoid() (in module torch)": [[1127, "torch.cumulative_trapezoid"]], "deg2rad() (in module torch)": [[1128, "torch.deg2rad"]], "dequantize() (in module torch)": [[1129, "torch.dequantize"]], "det() (in module torch)": [[1130, "torch.det"]], "diag() (in module torch)": [[1131, "torch.diag"]], "diag_embed() (in module torch)": [[1132, "torch.diag_embed"]], "diagflat() (in module torch)": [[1133, "torch.diagflat"]], "diagonal() (in module torch)": [[1134, "torch.diagonal"]], "diagonal_scatter() (in module torch)": [[1135, "torch.diagonal_scatter"]], "diff() (in module torch)": [[1136, "torch.diff"]], "digamma() (in module torch)": [[1137, "torch.digamma"]], "dist() (in module torch)": [[1138, "torch.dist"]], "div() (in module torch)": [[1139, "torch.div"]], "divide() (in module torch)": [[1140, "torch.divide"]], "dot() (in module torch)": [[1141, "torch.dot"]], "dsplit() (in module torch)": [[1142, "torch.dsplit"]], "dstack() (in module torch)": [[1143, "torch.dstack"]], "einsum() (in module torch)": [[1144, "torch.einsum"]], "empty() (in module torch)": [[1145, "torch.empty"]], "empty_like() (in module torch)": [[1146, "torch.empty_like"]], "empty_strided() (in module torch)": [[1147, "torch.empty_strided"]], "enable_grad (class in torch)": [[1148, "torch.enable_grad"]], "eq() (in module torch)": [[1149, "torch.eq"]], "equal() (in module torch)": [[1150, "torch.equal"]], "erf() (in module torch)": [[1151, "torch.erf"]], "erfc() (in module torch)": [[1152, "torch.erfc"]], "erfinv() (in module torch)": [[1153, "torch.erfinv"]], "exp() (in module torch)": [[1154, "torch.exp"]], "exp2() (in module torch)": [[1155, "torch.exp2"]], "expm1() (in module torch)": [[1156, "torch.expm1"]], "eye() (in module torch)": [[1157, "torch.eye"]], "fake_quantize_per_channel_affine() (in module torch)": [[1158, "torch.fake_quantize_per_channel_affine"]], "fake_quantize_per_tensor_affine() (in module torch)": [[1159, "torch.fake_quantize_per_tensor_affine"]], "fft() (in module torch.fft)": [[1160, "torch.fft.fft"]], "fft2() (in module torch.fft)": [[1161, "torch.fft.fft2"]], "fftfreq() (in module torch.fft)": [[1162, "torch.fft.fftfreq"]], "fftn() (in module torch.fft)": [[1163, "torch.fft.fftn"]], "fftshift() (in module torch.fft)": [[1164, "torch.fft.fftshift"]], "hfft() (in module torch.fft)": [[1165, "torch.fft.hfft"]], "hfft2() (in module torch.fft)": [[1166, "torch.fft.hfft2"]], "hfftn() (in module torch.fft)": [[1167, "torch.fft.hfftn"]], "ifft() (in module torch.fft)": [[1168, "torch.fft.ifft"]], "ifft2() (in module torch.fft)": [[1169, "torch.fft.ifft2"]], "ifftn() (in module torch.fft)": [[1170, "torch.fft.ifftn"]], "ifftshift() (in module torch.fft)": [[1171, "torch.fft.ifftshift"]], "ihfft() (in module torch.fft)": [[1172, "torch.fft.ihfft"]], "ihfft2() (in module torch.fft)": [[1173, "torch.fft.ihfft2"]], "ihfftn() (in module torch.fft)": [[1174, "torch.fft.ihfftn"]], "irfft() (in module torch.fft)": [[1175, "torch.fft.irfft"]], "irfft2() (in module torch.fft)": [[1176, "torch.fft.irfft2"]], "irfftn() (in module torch.fft)": [[1177, "torch.fft.irfftn"]], "rfft() (in module torch.fft)": [[1178, "torch.fft.rfft"]], "rfft2() (in module torch.fft)": [[1179, "torch.fft.rfft2"]], "rfftfreq() (in module torch.fft)": [[1180, "torch.fft.rfftfreq"]], "rfftn() (in module torch.fft)": [[1181, "torch.fft.rfftn"]], "fix() (in module torch)": [[1182, "torch.fix"]], "flatten() (in module torch)": [[1183, "torch.flatten"]], "flip() (in module torch)": [[1184, "torch.flip"]], "fliplr() (in module torch)": [[1185, "torch.fliplr"]], "flipud() (in module torch)": [[1186, "torch.flipud"]], "float_power() (in module torch)": [[1187, "torch.float_power"]], "floor() (in module torch)": [[1188, "torch.floor"]], "floor_divide() (in module torch)": [[1189, "torch.floor_divide"]], "fmax() (in module torch)": [[1190, "torch.fmax"]], "fmin() (in module torch)": [[1191, "torch.fmin"]], "fmod() (in module torch)": [[1192, "torch.fmod"]], "frac() (in module torch)": [[1193, "torch.frac"]], "frexp() (in module torch)": [[1194, "torch.frexp"]], "from_dlpack() (in module torch)": [[1195, "torch.from_dlpack"]], "from_file() (in module torch)": [[1196, "torch.from_file"]], "from_numpy() (in module torch)": [[1197, "torch.from_numpy"]], "frombuffer() (in module torch)": [[1198, "torch.frombuffer"]], "full() (in module torch)": [[1199, "torch.full"]], "full_like() (in module torch)": [[1200, "torch.full_like"]], "functional_call() (in module torch.func)": [[1201, "torch.func.functional_call"]], "functionalize() (in module torch.func)": [[1202, "torch.func.functionalize"]], "grad() (in module torch.func)": [[1203, "torch.func.grad"]], "grad_and_value() (in module torch.func)": [[1204, "torch.func.grad_and_value"]], "hessian() (in module torch.func)": [[1205, "torch.func.hessian"]], "jacfwd() (in module torch.func)": [[1206, "torch.func.jacfwd"]], "jacrev() (in module torch.func)": [[1207, "torch.func.jacrev"]], "jvp() (in module torch.func)": [[1208, "torch.func.jvp"]], "linearize() (in module torch.func)": [[1209, "torch.func.linearize"]], "replace_all_batch_norm_modules_() (in module torch.func)": [[1210, "torch.func.replace_all_batch_norm_modules_"]], "stack_module_state() (in module torch.func)": [[1211, "torch.func.stack_module_state"]], "vjp() (in module torch.func)": [[1212, "torch.func.vjp"]], "vmap() (in module torch.func)": [[1213, "torch.func.vmap"]], "get_proxy_mode() (in module torch.fx.experimental.proxy_tensor)": [[1214, "torch.fx.experimental.proxy_tensor.get_proxy_mode"]], "handle_sym_dispatch() (in module torch.fx.experimental.proxy_tensor)": [[1215, "torch.fx.experimental.proxy_tensor.handle_sym_dispatch"]], "make_fx() (in module torch.fx.experimental.proxy_tensor)": [[1216, "torch.fx.experimental.proxy_tensor.make_fx"]], "maybe_disable_thunkify() (in module torch.fx.experimental.proxy_tensor)": [[1217, "torch.fx.experimental.proxy_tensor.maybe_disable_thunkify"]], "maybe_enable_thunkify() (in module torch.fx.experimental.proxy_tensor)": [[1218, "torch.fx.experimental.proxy_tensor.maybe_enable_thunkify"]], "callmethodkey (class in torch.fx.experimental.symbolic_shapes)": [[1219, "torch.fx.experimental.symbolic_shapes.CallMethodKey"]], "get() (torch.fx.experimental.symbolic_shapes.callmethodkey method)": [[1219, "torch.fx.experimental.symbolic_shapes.CallMethodKey.get"]], "convertintkey (class in torch.fx.experimental.symbolic_shapes)": [[1220, "torch.fx.experimental.symbolic_shapes.ConvertIntKey"]], "get() (torch.fx.experimental.symbolic_shapes.convertintkey method)": [[1220, "torch.fx.experimental.symbolic_shapes.ConvertIntKey.get"]], "dimconstraints (class in torch.fx.experimental.symbolic_shapes)": [[1221, "torch.fx.experimental.symbolic_shapes.DimConstraints"]], "add() (torch.fx.experimental.symbolic_shapes.dimconstraints method)": [[1221, "torch.fx.experimental.symbolic_shapes.DimConstraints.add"]], "add_equality() (torch.fx.experimental.symbolic_shapes.dimconstraints method)": [[1221, "torch.fx.experimental.symbolic_shapes.DimConstraints.add_equality"]], "forced_specializations() (torch.fx.experimental.symbolic_shapes.dimconstraints method)": [[1221, "torch.fx.experimental.symbolic_shapes.DimConstraints.forced_specializations"]], "prettify_results() (torch.fx.experimental.symbolic_shapes.dimconstraints method)": [[1221, "torch.fx.experimental.symbolic_shapes.DimConstraints.prettify_results"]], "rewrite_with_congruences() (torch.fx.experimental.symbolic_shapes.dimconstraints method)": [[1221, "torch.fx.experimental.symbolic_shapes.DimConstraints.rewrite_with_congruences"]], "solve() (torch.fx.experimental.symbolic_shapes.dimconstraints method)": [[1221, "torch.fx.experimental.symbolic_shapes.DimConstraints.solve"]], "dimdynamic (class in torch.fx.experimental.symbolic_shapes)": [[1222, "torch.fx.experimental.symbolic_shapes.DimDynamic"]], "dividebykey (class in torch.fx.experimental.symbolic_shapes)": [[1223, "torch.fx.experimental.symbolic_shapes.DivideByKey"]], "get() (torch.fx.experimental.symbolic_shapes.dividebykey method)": [[1223, "torch.fx.experimental.symbolic_shapes.DivideByKey.get"]], "equalityconstraint (class in torch.fx.experimental.symbolic_shapes)": [[1224, "torch.fx.experimental.symbolic_shapes.EqualityConstraint"]], "innertensorkey (class in torch.fx.experimental.symbolic_shapes)": [[1225, "torch.fx.experimental.symbolic_shapes.InnerTensorKey"]], "get() (torch.fx.experimental.symbolic_shapes.innertensorkey method)": [[1225, "torch.fx.experimental.symbolic_shapes.InnerTensorKey.get"]], "propagateunbackedsymints (class in torch.fx.experimental.symbolic_shapes)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts"]], "boxed_run() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.boxed_run"]], "call_function() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.call_function"]], "call_method() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.call_method"]], "call_module() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.call_module"]], "fetch_args_kwargs_from_env() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.fetch_args_kwargs_from_env"]], "fetch_attr() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.fetch_attr"]], "get_attr() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.get_attr"]], "map_nodes_to_values() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.map_nodes_to_values"]], "output() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.output"]], "placeholder() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.placeholder"]], "run() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.run"]], "run_node() (torch.fx.experimental.symbolic_shapes.propagateunbackedsymints method)": [[1226, "torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts.run_node"]], "relaxedunspecconstraint (class in torch.fx.experimental.symbolic_shapes)": [[1227, "torch.fx.experimental.symbolic_shapes.RelaxedUnspecConstraint"]], "shapeenv (class in torch.fx.experimental.symbolic_shapes)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv"]], "add_var_to_val() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.add_var_to_val"]], "bind_symbols() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.bind_symbols"]], "bound_sympy() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.bound_sympy"]], "check_equal() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.check_equal"]], "cleanup() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.cleanup"]], "create_symbol() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symbol"]], "create_symbolic_sizes_strides_storage_offset() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symbolic_sizes_strides_storage_offset"]], "create_symboolnode() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symboolnode"]], "create_symfloatnode() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symfloatnode"]], "create_symintnode() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symintnode"]], "create_unbacked_symbool() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unbacked_symbool"]], "create_unbacked_symfloat() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unbacked_symfloat"]], "create_unbacked_symint() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unbacked_symint"]], "create_unspecified_symbol() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unspecified_symbol"]], "create_unspecified_symint_and_symbol() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unspecified_symint_and_symbol"]], "defer_runtime_assert() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.defer_runtime_assert"]], "deserialize_symexpr() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.deserialize_symexpr"]], "evaluate_guards_expression() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.evaluate_guards_expression"]], "evaluate_guards_for_args() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.evaluate_guards_for_args"]], "evaluate_symexpr() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.evaluate_symexpr"]], "format_guards() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.format_guards"]], "freeze() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.freeze"]], "freeze_runtime_asserts() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.freeze_runtime_asserts"]], "get_axioms() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.get_axioms"]], "get_implications() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.get_implications"]], "get_nontrivial_guards() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.get_nontrivial_guards"]], "get_pruned_guards() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.get_pruned_guards"]], "ignore_fresh_unbacked_symbols() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.ignore_fresh_unbacked_symbols"]], "is_unbacked_symint() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.is_unbacked_symint"]], "produce_guards() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.produce_guards"]], "produce_guards_expression() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.produce_guards_expression"]], "produce_guards_verbose() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.produce_guards_verbose"]], "replace() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.replace"]], "set_unbacked_var_to_val() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.set_unbacked_var_to_val"]], "simplify() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.simplify"]], "size_hint() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.size_hint"]], "suppress_guards() (torch.fx.experimental.symbolic_shapes.shapeenv method)": [[1228, "torch.fx.experimental.symbolic_shapes.ShapeEnv.suppress_guards"]], "shapeenvsettings (class in torch.fx.experimental.symbolic_shapes)": [[1229, "torch.fx.experimental.symbolic_shapes.ShapeEnvSettings"]], "statefulsymboliccontext (class in torch.fx.experimental.symbolic_shapes)": [[1230, "torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext"]], "statelesssymboliccontext (class in torch.fx.experimental.symbolic_shapes)": [[1231, "torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext"]], "strictminmaxconstraint (class in torch.fx.experimental.symbolic_shapes)": [[1232, "torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint"]], "render() (torch.fx.experimental.symbolic_shapes.strictminmaxconstraint method)": [[1232, "torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint.render"]], "subclasssymboliccontext (class in torch.fx.experimental.symbolic_shapes)": [[1233, "torch.fx.experimental.symbolic_shapes.SubclassSymbolicContext"]], "symboliccontext (class in torch.fx.experimental.symbolic_shapes)": [[1234, "torch.fx.experimental.symbolic_shapes.SymbolicContext"]], "canonicalize_bool_expr() (in module torch.fx.experimental.symbolic_shapes)": [[1235, "torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr"]], "check_consistent() (in module torch.fx.experimental.symbolic_shapes)": [[1236, "torch.fx.experimental.symbolic_shapes.check_consistent"]], "compute_unbacked_bindings() (in module torch.fx.experimental.symbolic_shapes)": [[1237, "torch.fx.experimental.symbolic_shapes.compute_unbacked_bindings"]], "constrain_range() (in module torch.fx.experimental.symbolic_shapes)": [[1238, "torch.fx.experimental.symbolic_shapes.constrain_range"]], "constrain_unify() (in module torch.fx.experimental.symbolic_shapes)": [[1239, "torch.fx.experimental.symbolic_shapes.constrain_unify"]], "definitely_false() (in module torch.fx.experimental.symbolic_shapes)": [[1240, "torch.fx.experimental.symbolic_shapes.definitely_false"]], "definitely_true() (in module torch.fx.experimental.symbolic_shapes)": [[1241, "torch.fx.experimental.symbolic_shapes.definitely_true"]], "guard_size_oblivious() (in module torch.fx.experimental.symbolic_shapes)": [[1242, "torch.fx.experimental.symbolic_shapes.guard_size_oblivious"]], "has_free_symbols() (in module torch.fx.experimental.symbolic_shapes)": [[1243, "torch.fx.experimental.symbolic_shapes.has_free_symbols"]], "has_free_unbacked_symbols() (in module torch.fx.experimental.symbolic_shapes)": [[1244, "torch.fx.experimental.symbolic_shapes.has_free_unbacked_symbols"]], "hint_int() (in module torch.fx.experimental.symbolic_shapes)": [[1245, "torch.fx.experimental.symbolic_shapes.hint_int"]], "is_accessor_node() (in module torch.fx.experimental.symbolic_shapes)": [[1246, "torch.fx.experimental.symbolic_shapes.is_accessor_node"]], "is_concrete_bool() (in module torch.fx.experimental.symbolic_shapes)": [[1247, "torch.fx.experimental.symbolic_shapes.is_concrete_bool"]], "is_concrete_float() (in module torch.fx.experimental.symbolic_shapes)": [[1248, "torch.fx.experimental.symbolic_shapes.is_concrete_float"]], "is_concrete_int() (in module torch.fx.experimental.symbolic_shapes)": [[1249, "torch.fx.experimental.symbolic_shapes.is_concrete_int"]], "lru_cache() (in module torch.fx.experimental.symbolic_shapes)": [[1250, "torch.fx.experimental.symbolic_shapes.lru_cache"]], "rebind_unbacked() (in module torch.fx.experimental.symbolic_shapes)": [[1251, "torch.fx.experimental.symbolic_shapes.rebind_unbacked"]], "resolve_unbacked_bindings() (in module torch.fx.experimental.symbolic_shapes)": [[1252, "torch.fx.experimental.symbolic_shapes.resolve_unbacked_bindings"]], "statically_known_true() (in module torch.fx.experimental.symbolic_shapes)": [[1253, "torch.fx.experimental.symbolic_shapes.statically_known_true"]], "sym_eq() (in module torch.fx.experimental.symbolic_shapes)": [[1254, "torch.fx.experimental.symbolic_shapes.sym_eq"]], "gather() (in module torch)": [[1255, "torch.gather"]], "gcd() (in module torch)": [[1256, "torch.gcd"]], "ge() (in module torch)": [[1257, "torch.ge"]], "geqrf() (in module torch)": [[1258, "torch.geqrf"]], "ger() (in module torch)": [[1259, "torch.ger"]], "get_default_device() (in module torch)": [[1260, "torch.get_default_device"]], "get_default_dtype() (in module torch)": [[1261, "torch.get_default_dtype"]], "get_deterministic_debug_mode() (in module torch)": [[1262, "torch.get_deterministic_debug_mode"]], "get_device_module() (in module torch)": [[1263, "torch.get_device_module"]], "get_float32_matmul_precision() (in module torch)": [[1264, "torch.get_float32_matmul_precision"]], "get_num_interop_threads() (in module torch)": [[1265, "torch.get_num_interop_threads"]], "get_num_threads() (in module torch)": [[1266, "torch.get_num_threads"]], "get_rng_state() (in module torch)": [[1267, "torch.get_rng_state"]], "gradient() (in module torch)": [[1268, "torch.gradient"]], "greater() (in module torch)": [[1269, "torch.greater"]], "greater_equal() (in module torch)": [[1270, "torch.greater_equal"]], "gt() (in module torch)": [[1271, "torch.gt"]], "hamming_window() (in module torch)": [[1272, "torch.hamming_window"]], "hann_window() (in module torch)": [[1273, "torch.hann_window"]], "heaviside() (in module torch)": [[1274, "torch.heaviside"]], "histc() (in module torch)": [[1275, "torch.histc"]], "histogram() (in module torch)": [[1276, "torch.histogram"]], "histogramdd() (in module torch)": [[1277, "torch.histogramdd"]], "hsplit() (in module torch)": [[1278, "torch.hsplit"]], "hspmm() (in module torch)": [[1279, "torch.hspmm"]], "hstack() (in module torch)": [[1280, "torch.hstack"]], "hypot() (in module torch)": [[1281, "torch.hypot"]], "i0() (in module torch)": [[1282, "torch.i0"]], "igamma() (in module torch)": [[1283, "torch.igamma"]], "igammac() (in module torch)": [[1284, "torch.igammac"]], "imag() (in module torch)": [[1285, "torch.imag"]], "index_add() (in module torch)": [[1286, "torch.index_add"]], "index_copy() (in module torch)": [[1287, "torch.index_copy"]], "index_reduce() (in module torch)": [[1288, "torch.index_reduce"]], "index_select() (in module torch)": [[1289, "torch.index_select"]], "initial_seed() (in module torch)": [[1290, "torch.initial_seed"]], "inner() (in module torch)": [[1291, "torch.inner"]], "inverse() (in module torch)": [[1292, "torch.inverse"]], "is_complex() (in module torch)": [[1293, "torch.is_complex"]], "is_conj() (in module torch)": [[1294, "torch.is_conj"]], "is_deterministic_algorithms_warn_only_enabled() (in module torch)": [[1295, "torch.is_deterministic_algorithms_warn_only_enabled"]], "is_floating_point() (in module torch)": [[1296, "torch.is_floating_point"]], "is_grad_enabled() (in module torch)": [[1297, "torch.is_grad_enabled"]], "is_inference_mode_enabled() (in module torch)": [[1298, "torch.is_inference_mode_enabled"]], "is_nonzero() (in module torch)": [[1299, "torch.is_nonzero"]], "is_storage() (in module torch)": [[1300, "torch.is_storage"]], "is_tensor() (in module torch)": [[1301, "torch.is_tensor"]], "is_warn_always_enabled() (in module torch)": [[1302, "torch.is_warn_always_enabled"]], "isclose() (in module torch)": [[1303, "torch.isclose"]], "isfinite() (in module torch)": [[1304, "torch.isfinite"]], "isin() (in module torch)": [[1305, "torch.isin"]], "isinf() (in module torch)": [[1306, "torch.isinf"]], "isnan() (in module torch)": [[1307, "torch.isnan"]], "isneginf() (in module torch)": [[1308, "torch.isneginf"]], "isposinf() (in module torch)": [[1309, "torch.isposinf"]], "isreal() (in module torch)": [[1310, "torch.isreal"]], "istft() (in module torch)": [[1311, "torch.istft"]], "attribute (class in torch.jit)": [[1312, "torch.jit.Attribute"]], "count() (torch.jit.attribute method)": [[1312, "torch.jit.Attribute.count"]], "index() (torch.jit.attribute method)": [[1312, "torch.jit.Attribute.index"]], "type (torch.jit.attribute attribute)": [[1312, "torch.jit.Attribute.type"]], "value (torch.jit.attribute attribute)": [[1312, "torch.jit.Attribute.value"]], "scriptfunction (class in torch.jit)": [[1313, "torch.jit.ScriptFunction"]], "get_debug_state() (torch.jit.scriptfunction method)": [[1313, "torch.jit.ScriptFunction.get_debug_state"]], "save() (torch.jit.scriptfunction method)": [[1313, "torch.jit.ScriptFunction.save"]], "save_to_buffer() (torch.jit.scriptfunction method)": [[1313, "torch.jit.ScriptFunction.save_to_buffer"]], "scriptmodule (class in torch.jit)": [[1314, "torch.jit.ScriptModule"]], "add_module() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.add_module"]], "apply() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.apply"]], "bfloat16() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.bfloat16"]], "buffers() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.buffers"]], "children() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.children"]], "code (torch.jit.scriptmodule property)": [[1314, "torch.jit.ScriptModule.code"]], "code_with_constants (torch.jit.scriptmodule property)": [[1314, "torch.jit.ScriptModule.code_with_constants"]], "compile() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.compile"]], "cpu() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.cpu"]], "cuda() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.cuda"]], "double() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.double"]], "eval() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.eval"]], "extra_repr() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.extra_repr"]], "float() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.float"]], "get_buffer() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.get_buffer"]], "get_extra_state() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.get_extra_state"]], "get_parameter() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.get_parameter"]], "get_submodule() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.get_submodule"]], "graph (torch.jit.scriptmodule property)": [[1314, "torch.jit.ScriptModule.graph"]], "half() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.half"]], "inlined_graph (torch.jit.scriptmodule property)": [[1314, "torch.jit.ScriptModule.inlined_graph"]], "ipu() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.ipu"]], "load_state_dict() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.load_state_dict"]], "modules() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.modules"]], "mtia() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.mtia"]], "named_buffers() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.named_buffers"]], "named_children() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.named_children"]], "named_modules() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.named_modules"]], "named_parameters() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.named_parameters"]], "parameters() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.parameters"]], "register_backward_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_backward_hook"]], "register_buffer() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_buffer"]], "register_forward_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_forward_hook"]], "register_forward_pre_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_forward_pre_hook"]], "register_full_backward_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_full_backward_hook"]], "register_full_backward_pre_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_load_state_dict_pre_hook"]], "register_module() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_module"]], "register_parameter() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_parameter"]], "register_state_dict_post_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.register_state_dict_pre_hook"]], "requires_grad_() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.requires_grad_"]], "save() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.save"]], "set_extra_state() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.set_extra_state"]], "set_submodule() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.set_submodule"]], "share_memory() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.share_memory"]], "state_dict() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.state_dict"]], "to() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.to"]], "to_empty() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.to_empty"]], "train() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.train"]], "type() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.type"]], "xpu() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.xpu"]], "zero_grad() (torch.jit.scriptmodule method)": [[1314, "torch.jit.ScriptModule.zero_grad"]], "annotate() (in module torch.jit)": [[1315, "torch.jit.annotate"]], "enable_onednn_fusion() (in module torch.jit)": [[1316, "torch.jit.enable_onednn_fusion"]], "fork() (in module torch.jit)": [[1317, "torch.jit.fork"]], "freeze() (in module torch.jit)": [[1318, "torch.jit.freeze"]], "ignore() (in module torch.jit)": [[1319, "torch.jit.ignore"]], "interface() (in module torch.jit)": [[1320, "torch.jit.interface"]], "isinstance() (in module torch.jit)": [[1321, "torch.jit.isinstance"]], "load() (in module torch.jit)": [[1322, "torch.jit.load"]], "onednn_fusion_enabled() (in module torch.jit)": [[1323, "torch.jit.onednn_fusion_enabled"]], "optimize_for_inference() (in module torch.jit)": [[1324, "torch.jit.optimize_for_inference"]], "save() (in module torch.jit)": [[1325, "torch.jit.save"]], "script() (in module torch.jit)": [[1326, "torch.jit.script"]], "script_if_tracing() (in module torch.jit)": [[1327, "torch.jit.script_if_tracing"]], "set_fusion_strategy() (in module torch.jit)": [[1328, "torch.jit.set_fusion_strategy"]], "strict_fusion (class in torch.jit)": [[1329, "torch.jit.strict_fusion"]], "trace() (in module torch.jit)": [[1330, "torch.jit.trace"]], "trace_module() (in module torch.jit)": [[1331, "torch.jit.trace_module"]], "unused() (in module torch.jit)": [[1332, "torch.jit.unused"]], "wait() (in module torch.jit)": [[1333, "torch.jit.wait"]], "kaiser_window() (in module torch)": [[1334, "torch.kaiser_window"]], "kron() (in module torch)": [[1335, "torch.kron"]], "kthvalue() (in module torch)": [[1336, "torch.kthvalue"]], "lcm() (in module torch)": [[1337, "torch.lcm"]], "ldexp() (in module torch)": [[1338, "torch.ldexp"]], "le() (in module torch)": [[1339, "torch.le"]], "lerp() (in module torch)": [[1340, "torch.lerp"]], "less() (in module torch)": [[1341, "torch.less"]], "less_equal() (in module torch)": [[1342, "torch.less_equal"]], "lgamma() (in module torch)": [[1343, "torch.lgamma"]], "cholesky() (in module torch.linalg)": [[1344, "torch.linalg.cholesky"]], "cholesky_ex() (in module torch.linalg)": [[1345, "torch.linalg.cholesky_ex"]], "cond() (in module torch.linalg)": [[1346, "torch.linalg.cond"]], "cross() (in module torch.linalg)": [[1347, "torch.linalg.cross"]], "det() (in module torch.linalg)": [[1348, "torch.linalg.det"]], "diagonal() (in module torch.linalg)": [[1349, "torch.linalg.diagonal"]], "eig() (in module torch.linalg)": [[1350, "torch.linalg.eig"]], "eigh() (in module torch.linalg)": [[1351, "torch.linalg.eigh"]], "eigvals() (in module torch.linalg)": [[1352, "torch.linalg.eigvals"]], "eigvalsh() (in module torch.linalg)": [[1353, "torch.linalg.eigvalsh"]], "householder_product() (in module torch.linalg)": [[1354, "torch.linalg.householder_product"]], "inv() (in module torch.linalg)": [[1355, "torch.linalg.inv"]], "inv_ex() (in module torch.linalg)": [[1356, "torch.linalg.inv_ex"]], "ldl_factor() (in module torch.linalg)": [[1357, "torch.linalg.ldl_factor"]], "ldl_factor_ex() (in module torch.linalg)": [[1358, "torch.linalg.ldl_factor_ex"]], "ldl_solve() (in module torch.linalg)": [[1359, "torch.linalg.ldl_solve"]], "lstsq() (in module torch.linalg)": [[1360, "torch.linalg.lstsq"]], "lu() (in module torch.linalg)": [[1361, "torch.linalg.lu"]], "lu_factor() (in module torch.linalg)": [[1362, "torch.linalg.lu_factor"]], "lu_factor_ex() (in module torch.linalg)": [[1363, "torch.linalg.lu_factor_ex"]], "lu_solve() (in module torch.linalg)": [[1364, "torch.linalg.lu_solve"]], "matmul() (in module torch.linalg)": [[1365, "torch.linalg.matmul"]], "matrix_exp() (in module torch.linalg)": [[1366, "torch.linalg.matrix_exp"]], "matrix_norm() (in module torch.linalg)": [[1367, "torch.linalg.matrix_norm"]], "matrix_power() (in module torch.linalg)": [[1368, "torch.linalg.matrix_power"]], "matrix_rank() (in module torch.linalg)": [[1369, "torch.linalg.matrix_rank"]], "multi_dot() (in module torch.linalg)": [[1370, "torch.linalg.multi_dot"]], "norm() (in module torch.linalg)": [[1371, "torch.linalg.norm"]], "pinv() (in module torch.linalg)": [[1372, "torch.linalg.pinv"]], "qr() (in module torch.linalg)": [[1373, "torch.linalg.qr"]], "slogdet() (in module torch.linalg)": [[1374, "torch.linalg.slogdet"]], "solve() (in module torch.linalg)": [[1375, "torch.linalg.solve"]], "solve_ex() (in module torch.linalg)": [[1376, "torch.linalg.solve_ex"]], "solve_triangular() (in module torch.linalg)": [[1377, "torch.linalg.solve_triangular"]], "svd() (in module torch.linalg)": [[1378, "torch.linalg.svd"]], "svdvals() (in module torch.linalg)": [[1379, "torch.linalg.svdvals"]], "tensorinv() (in module torch.linalg)": [[1380, "torch.linalg.tensorinv"]], "tensorsolve() (in module torch.linalg)": [[1381, "torch.linalg.tensorsolve"]], "vander() (in module torch.linalg)": [[1382, "torch.linalg.vander"]], "vecdot() (in module torch.linalg)": [[1383, "torch.linalg.vecdot"]], "vector_norm() (in module torch.linalg)": [[1384, "torch.linalg.vector_norm"]], "linspace() (in module torch)": [[1385, "torch.linspace"]], "load() (in module torch)": [[1386, "torch.load"]], "lobpcg() (in module torch)": [[1387, "torch.lobpcg"]], "log() (in module torch)": [[1388, "torch.log"]], "log10() (in module torch)": [[1389, "torch.log10"]], "log1p() (in module torch)": [[1390, "torch.log1p"]], "log2() (in module torch)": [[1391, "torch.log2"]], "logaddexp() (in module torch)": [[1392, "torch.logaddexp"]], "logaddexp2() (in module torch)": [[1393, "torch.logaddexp2"]], "logcumsumexp() (in module torch)": [[1394, "torch.logcumsumexp"]], "logdet() (in module torch)": [[1395, "torch.logdet"]], "logical_and() (in module torch)": [[1396, "torch.logical_and"]], "logical_not() (in module torch)": [[1397, "torch.logical_not"]], "logical_or() (in module torch)": [[1398, "torch.logical_or"]], "logical_xor() (in module torch)": [[1399, "torch.logical_xor"]], "logit() (in module torch)": [[1400, "torch.logit"]], "logspace() (in module torch)": [[1401, "torch.logspace"]], "logsumexp() (in module torch)": [[1402, "torch.logsumexp"]], "lt() (in module torch)": [[1403, "torch.lt"]], "lu() (in module torch)": [[1404, "torch.lu"]], "lu_solve() (in module torch)": [[1405, "torch.lu_solve"]], "lu_unpack() (in module torch)": [[1406, "torch.lu_unpack"]], "manual_seed() (in module torch)": [[1407, "torch.manual_seed"]], "masked_select() (in module torch)": [[1408, "torch.masked_select"]], "matmul() (in module torch)": [[1409, "torch.matmul"]], "matrix_exp() (in module torch)": [[1410, "torch.matrix_exp"]], "matrix_power() (in module torch)": [[1411, "torch.matrix_power"]], "max() (in module torch)": [[1412, "torch.max"]], "maximum() (in module torch)": [[1413, "torch.maximum"]], "mean() (in module torch)": [[1414, "torch.mean"]], "median() (in module torch)": [[1415, "torch.median"]], "meshgrid() (in module torch)": [[1416, "torch.meshgrid"]], "min() (in module torch)": [[1417, "torch.min"]], "minimum() (in module torch)": [[1418, "torch.minimum"]], "mm() (in module torch)": [[1419, "torch.mm"]], "mode() (in module torch)": [[1420, "torch.mode"]], "moveaxis() (in module torch)": [[1421, "torch.moveaxis"]], "movedim() (in module torch)": [[1422, "torch.movedim"]], "current_allocated_memory() (in module torch.mps)": [[1423, "torch.mps.current_allocated_memory"]], "device_count() (in module torch.mps)": [[1424, "torch.mps.device_count"]], "driver_allocated_memory() (in module torch.mps)": [[1425, "torch.mps.driver_allocated_memory"]], "empty_cache() (in module torch.mps)": [[1426, "torch.mps.empty_cache"]], "event (class in torch.mps.event)": [[1427, "torch.mps.event.Event"]], "elapsed_time() (torch.mps.event.event method)": [[1427, "torch.mps.event.Event.elapsed_time"]], "query() (torch.mps.event.event method)": [[1427, "torch.mps.event.Event.query"]], "record() (torch.mps.event.event method)": [[1427, "torch.mps.event.Event.record"]], "synchronize() (torch.mps.event.event method)": [[1427, "torch.mps.event.Event.synchronize"]], "wait() (torch.mps.event.event method)": [[1427, "torch.mps.event.Event.wait"]], "get_rng_state() (in module torch.mps)": [[1428, "torch.mps.get_rng_state"]], "manual_seed() (in module torch.mps)": [[1429, "torch.mps.manual_seed"]], "profile() (in module torch.mps.profiler)": [[1433, "torch.mps.profiler.profile"]], "start() (in module torch.mps.profiler)": [[1434, "torch.mps.profiler.start"]], "stop() (in module torch.mps.profiler)": [[1435, "torch.mps.profiler.stop"]], "recommended_max_memory() (in module torch.mps)": [[1436, "torch.mps.recommended_max_memory"]], "seed() (in module torch.mps)": [[1437, "torch.mps.seed"]], "set_per_process_memory_fraction() (in module torch.mps)": [[1438, "torch.mps.set_per_process_memory_fraction"]], "set_rng_state() (in module torch.mps)": [[1439, "torch.mps.set_rng_state"]], "synchronize() (in module torch.mps)": [[1440, "torch.mps.synchronize"]], "msort() (in module torch)": [[1441, "torch.msort"]], "deferredmtiacallerror": [[1442, "torch.mtia.DeferredMtiaCallError"]], "event (class in torch.mtia)": [[1443, "torch.mtia.Event"]], "elapsed_time() (torch.mtia.event method)": [[1443, "torch.mtia.Event.elapsed_time"]], "query() (torch.mtia.event method)": [[1443, "torch.mtia.Event.query"]], "record() (torch.mtia.event method)": [[1443, "torch.mtia.Event.record"]], "synchronize() (torch.mtia.event method)": [[1443, "torch.mtia.Event.synchronize"]], "wait() (torch.mtia.event method)": [[1443, "torch.mtia.Event.wait"]], "stream() (in module torch.mtia)": [[1444, "torch.mtia.stream"]], "streamcontext (class in torch.mtia)": [[1445, "torch.mtia.StreamContext"]], "current_device() (in module torch.mtia)": [[1446, "torch.mtia.current_device"]], "current_stream() (in module torch.mtia)": [[1447, "torch.mtia.current_stream"]], "default_stream() (in module torch.mtia)": [[1448, "torch.mtia.default_stream"]], "device (class in torch.mtia)": [[1449, "torch.mtia.device"]], "device_count() (in module torch.mtia)": [[1450, "torch.mtia.device_count"]], "empty_cache() (in module torch.mtia)": [[1451, "torch.mtia.empty_cache"]], "get_device_capability() (in module torch.mtia)": [[1452, "torch.mtia.get_device_capability"]], "get_rng_state() (in module torch.mtia)": [[1453, "torch.mtia.get_rng_state"]], "init() (in module torch.mtia)": [[1454, "torch.mtia.init"]], "is_available() (in module torch.mtia)": [[1455, "torch.mtia.is_available"]], "is_initialized() (in module torch.mtia)": [[1456, "torch.mtia.is_initialized"]], "memory_stats() (in module torch.mtia.memory)": [[1457, "torch.mtia.memory.memory_stats"]], "memory_stats() (in module torch.mtia)": [[1458, "torch.mtia.memory_stats"]], "set_device() (in module torch.mtia)": [[1460, "torch.mtia.set_device"]], "set_rng_state() (in module torch.mtia)": [[1461, "torch.mtia.set_rng_state"]], "set_stream() (in module torch.mtia)": [[1462, "torch.mtia.set_stream"]], "synchronize() (in module torch.mtia)": [[1464, "torch.mtia.synchronize"]], "mul() (in module torch)": [[1465, "torch.mul"]], "multinomial() (in module torch)": [[1466, "torch.multinomial"]], "multiply() (in module torch)": [[1467, "torch.multiply"]], "mv() (in module torch)": [[1468, "torch.mv"]], "mvlgamma() (in module torch)": [[1469, "torch.mvlgamma"]], "nan_to_num() (in module torch)": [[1470, "torch.nan_to_num"]], "nanmean() (in module torch)": [[1471, "torch.nanmean"]], "nanmedian() (in module torch)": [[1472, "torch.nanmedian"]], "nanquantile() (in module torch)": [[1473, "torch.nanquantile"]], "nansum() (in module torch)": [[1474, "torch.nansum"]], "narrow() (in module torch)": [[1475, "torch.narrow"]], "narrow_copy() (in module torch)": [[1476, "torch.narrow_copy"]], "ne() (in module torch)": [[1477, "torch.ne"]], "neg() (in module torch)": [[1478, "torch.neg"]], "negative() (in module torch)": [[1479, "torch.negative"]], "nextafter() (in module torch)": [[1480, "torch.nextafter"]], "adaptiveavgpool1d (class in torch.nn)": [[1481, "torch.nn.AdaptiveAvgPool1d"]], "adaptiveavgpool2d (class in torch.nn)": [[1482, "torch.nn.AdaptiveAvgPool2d"]], "adaptiveavgpool3d (class in torch.nn)": [[1483, "torch.nn.AdaptiveAvgPool3d"]], "adaptivelogsoftmaxwithloss (class in torch.nn)": [[1484, "torch.nn.AdaptiveLogSoftmaxWithLoss"]], "log_prob() (torch.nn.adaptivelogsoftmaxwithloss method)": [[1484, "torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob"]], "predict() (torch.nn.adaptivelogsoftmaxwithloss method)": [[1484, "torch.nn.AdaptiveLogSoftmaxWithLoss.predict"]], "adaptivemaxpool1d (class in torch.nn)": [[1485, "torch.nn.AdaptiveMaxPool1d"]], "adaptivemaxpool2d (class in torch.nn)": [[1486, "torch.nn.AdaptiveMaxPool2d"]], "adaptivemaxpool3d (class in torch.nn)": [[1487, "torch.nn.AdaptiveMaxPool3d"]], "alphadropout (class in torch.nn)": [[1488, "torch.nn.AlphaDropout"]], "avgpool1d (class in torch.nn)": [[1489, "torch.nn.AvgPool1d"]], "avgpool2d (class in torch.nn)": [[1490, "torch.nn.AvgPool2d"]], "avgpool3d (class in torch.nn)": [[1491, "torch.nn.AvgPool3d"]], "bceloss (class in torch.nn)": [[1492, "torch.nn.BCELoss"]], "bcewithlogitsloss (class in torch.nn)": [[1493, "torch.nn.BCEWithLogitsLoss"]], "batchnorm1d (class in torch.nn)": [[1494, "torch.nn.BatchNorm1d"]], "batchnorm2d (class in torch.nn)": [[1495, "torch.nn.BatchNorm2d"]], "batchnorm3d (class in torch.nn)": [[1496, "torch.nn.BatchNorm3d"]], "bilinear (class in torch.nn)": [[1497, "torch.nn.Bilinear"]], "celu (class in torch.nn)": [[1498, "torch.nn.CELU"]], "ctcloss (class in torch.nn)": [[1499, "torch.nn.CTCLoss"]], "channelshuffle (class in torch.nn)": [[1500, "torch.nn.ChannelShuffle"]], "circularpad1d (class in torch.nn)": [[1501, "torch.nn.CircularPad1d"]], "circularpad2d (class in torch.nn)": [[1502, "torch.nn.CircularPad2d"]], "circularpad3d (class in torch.nn)": [[1503, "torch.nn.CircularPad3d"]], "constantpad1d (class in torch.nn)": [[1504, "torch.nn.ConstantPad1d"]], "constantpad2d (class in torch.nn)": [[1505, "torch.nn.ConstantPad2d"]], "constantpad3d (class in torch.nn)": [[1506, "torch.nn.ConstantPad3d"]], "conv1d (class in torch.nn)": [[1507, "torch.nn.Conv1d"]], "conv2d (class in torch.nn)": [[1508, "torch.nn.Conv2d"]], "conv3d (class in torch.nn)": [[1509, "torch.nn.Conv3d"]], "convtranspose1d (class in torch.nn)": [[1510, "torch.nn.ConvTranspose1d"]], "convtranspose2d (class in torch.nn)": [[1511, "torch.nn.ConvTranspose2d"]], "convtranspose3d (class in torch.nn)": [[1512, "torch.nn.ConvTranspose3d"]], "cosineembeddingloss (class in torch.nn)": [[1513, "torch.nn.CosineEmbeddingLoss"]], "cosinesimilarity (class in torch.nn)": [[1514, "torch.nn.CosineSimilarity"]], "crossentropyloss (class in torch.nn)": [[1515, "torch.nn.CrossEntropyLoss"]], "dataparallel (class in torch.nn)": [[1516, "torch.nn.DataParallel"]], "dropout (class in torch.nn)": [[1517, "torch.nn.Dropout"]], "dropout1d (class in torch.nn)": [[1518, "torch.nn.Dropout1d"]], "dropout2d (class in torch.nn)": [[1519, "torch.nn.Dropout2d"]], "dropout3d (class in torch.nn)": [[1520, "torch.nn.Dropout3d"]], "elu (class in torch.nn)": [[1521, "torch.nn.ELU"]], "embedding (class in torch.nn)": [[1522, "torch.nn.Embedding"]], "from_pretrained() (torch.nn.embedding class method)": [[1522, "torch.nn.Embedding.from_pretrained"]], "embeddingbag (class in torch.nn)": [[1523, "torch.nn.EmbeddingBag"]], "forward() (torch.nn.embeddingbag method)": [[1523, "torch.nn.EmbeddingBag.forward"]], "from_pretrained() (torch.nn.embeddingbag class method)": [[1523, "torch.nn.EmbeddingBag.from_pretrained"]], "featurealphadropout (class in torch.nn)": [[1524, "torch.nn.FeatureAlphaDropout"]], "flatten (class in torch.nn)": [[1525, "torch.nn.Flatten"]], "fold (class in torch.nn)": [[1526, "torch.nn.Fold"]], "fractionalmaxpool2d (class in torch.nn)": [[1527, "torch.nn.FractionalMaxPool2d"]], "fractionalmaxpool3d (class in torch.nn)": [[1528, "torch.nn.FractionalMaxPool3d"]], "gelu (class in torch.nn)": [[1529, "torch.nn.GELU"]], "glu (class in torch.nn)": [[1530, "torch.nn.GLU"]], "gru (class in torch.nn)": [[1531, "torch.nn.GRU"]], "grucell (class in torch.nn)": [[1532, "torch.nn.GRUCell"]], "gaussiannllloss (class in torch.nn)": [[1533, "torch.nn.GaussianNLLLoss"]], "groupnorm (class in torch.nn)": [[1534, "torch.nn.GroupNorm"]], "hardshrink (class in torch.nn)": [[1535, "torch.nn.Hardshrink"]], "hardsigmoid (class in torch.nn)": [[1536, "torch.nn.Hardsigmoid"]], "hardswish (class in torch.nn)": [[1537, "torch.nn.Hardswish"]], "hardtanh (class in torch.nn)": [[1538, "torch.nn.Hardtanh"]], "hingeembeddingloss (class in torch.nn)": [[1539, "torch.nn.HingeEmbeddingLoss"]], "huberloss (class in torch.nn)": [[1540, "torch.nn.HuberLoss"]], "identity (class in torch.nn)": [[1541, "torch.nn.Identity"]], "instancenorm1d (class in torch.nn)": [[1542, "torch.nn.InstanceNorm1d"]], "instancenorm2d (class in torch.nn)": [[1543, "torch.nn.InstanceNorm2d"]], "instancenorm3d (class in torch.nn)": [[1544, "torch.nn.InstanceNorm3d"]], "kldivloss (class in torch.nn)": [[1545, "torch.nn.KLDivLoss"]], "l1loss (class in torch.nn)": [[1546, "torch.nn.L1Loss"]], "lppool1d (class in torch.nn)": [[1547, "torch.nn.LPPool1d"]], "lppool2d (class in torch.nn)": [[1548, "torch.nn.LPPool2d"]], "lppool3d (class in torch.nn)": [[1549, "torch.nn.LPPool3d"]], "lstm (class in torch.nn)": [[1550, "torch.nn.LSTM"]], "lstmcell (class in torch.nn)": [[1551, "torch.nn.LSTMCell"]], "layernorm (class in torch.nn)": [[1552, "torch.nn.LayerNorm"]], "lazybatchnorm1d (class in torch.nn)": [[1553, "torch.nn.LazyBatchNorm1d"]], "cls_to_become (torch.nn.lazybatchnorm1d attribute)": [[1553, "torch.nn.LazyBatchNorm1d.cls_to_become"]], "lazybatchnorm2d (class in torch.nn)": [[1554, "torch.nn.LazyBatchNorm2d"]], "cls_to_become (torch.nn.lazybatchnorm2d attribute)": [[1554, "torch.nn.LazyBatchNorm2d.cls_to_become"]], "lazybatchnorm3d (class in torch.nn)": [[1555, "torch.nn.LazyBatchNorm3d"]], "cls_to_become (torch.nn.lazybatchnorm3d attribute)": [[1555, "torch.nn.LazyBatchNorm3d.cls_to_become"]], "lazyconv1d (class in torch.nn)": [[1556, "torch.nn.LazyConv1d"]], "cls_to_become (torch.nn.lazyconv1d attribute)": [[1556, "torch.nn.LazyConv1d.cls_to_become"]], "lazyconv2d (class in torch.nn)": [[1557, "torch.nn.LazyConv2d"]], "cls_to_become (torch.nn.lazyconv2d attribute)": [[1557, "torch.nn.LazyConv2d.cls_to_become"]], "lazyconv3d (class in torch.nn)": [[1558, "torch.nn.LazyConv3d"]], "cls_to_become (torch.nn.lazyconv3d attribute)": [[1558, "torch.nn.LazyConv3d.cls_to_become"]], "lazyconvtranspose1d (class in torch.nn)": [[1559, "torch.nn.LazyConvTranspose1d"]], "cls_to_become (torch.nn.lazyconvtranspose1d attribute)": [[1559, "torch.nn.LazyConvTranspose1d.cls_to_become"]], "lazyconvtranspose2d (class in torch.nn)": [[1560, "torch.nn.LazyConvTranspose2d"]], "cls_to_become (torch.nn.lazyconvtranspose2d attribute)": [[1560, "torch.nn.LazyConvTranspose2d.cls_to_become"]], "lazyconvtranspose3d (class in torch.nn)": [[1561, "torch.nn.LazyConvTranspose3d"]], "cls_to_become (torch.nn.lazyconvtranspose3d attribute)": [[1561, "torch.nn.LazyConvTranspose3d.cls_to_become"]], "lazyinstancenorm1d (class in torch.nn)": [[1562, "torch.nn.LazyInstanceNorm1d"]], "cls_to_become (torch.nn.lazyinstancenorm1d attribute)": [[1562, "torch.nn.LazyInstanceNorm1d.cls_to_become"]], "lazyinstancenorm2d (class in torch.nn)": [[1563, "torch.nn.LazyInstanceNorm2d"]], "cls_to_become (torch.nn.lazyinstancenorm2d attribute)": [[1563, "torch.nn.LazyInstanceNorm2d.cls_to_become"]], "lazyinstancenorm3d (class in torch.nn)": [[1564, "torch.nn.LazyInstanceNorm3d"]], "cls_to_become (torch.nn.lazyinstancenorm3d attribute)": [[1564, "torch.nn.LazyInstanceNorm3d.cls_to_become"]], "lazylinear (class in torch.nn)": [[1565, "torch.nn.LazyLinear"]], "cls_to_become (torch.nn.lazylinear attribute)": [[1565, "torch.nn.LazyLinear.cls_to_become"]], "leakyrelu (class in torch.nn)": [[1566, "torch.nn.LeakyReLU"]], "linear (class in torch.nn)": [[1567, "torch.nn.Linear"]], "localresponsenorm (class in torch.nn)": [[1568, "torch.nn.LocalResponseNorm"]], "logsigmoid (class in torch.nn)": [[1569, "torch.nn.LogSigmoid"]], "logsoftmax (class in torch.nn)": [[1570, "torch.nn.LogSoftmax"]], "mseloss (class in torch.nn)": [[1571, "torch.nn.MSELoss"]], "marginrankingloss (class in torch.nn)": [[1572, "torch.nn.MarginRankingLoss"]], "maxpool1d (class in torch.nn)": [[1573, "torch.nn.MaxPool1d"]], "maxpool2d (class in torch.nn)": [[1574, "torch.nn.MaxPool2d"]], "maxpool3d (class in torch.nn)": [[1575, "torch.nn.MaxPool3d"]], "maxunpool1d (class in torch.nn)": [[1576, "torch.nn.MaxUnpool1d"]], "maxunpool2d (class in torch.nn)": [[1577, "torch.nn.MaxUnpool2d"]], "maxunpool3d (class in torch.nn)": [[1578, "torch.nn.MaxUnpool3d"]], "mish (class in torch.nn)": [[1579, "torch.nn.Mish"]], "module (class in torch.nn)": [[1580, "torch.nn.Module"]], "add_module() (torch.nn.module method)": [[1580, "torch.nn.Module.add_module"]], "apply() (torch.nn.module method)": [[1580, "torch.nn.Module.apply"]], "bfloat16() (torch.nn.module method)": [[1580, "torch.nn.Module.bfloat16"]], "buffers() (torch.nn.module method)": [[1580, "torch.nn.Module.buffers"]], "children() (torch.nn.module method)": [[1580, "torch.nn.Module.children"]], "compile() (torch.nn.module method)": [[1580, "torch.nn.Module.compile"]], "cpu() (torch.nn.module method)": [[1580, "torch.nn.Module.cpu"]], "cuda() (torch.nn.module method)": [[1580, "torch.nn.Module.cuda"]], "double() (torch.nn.module method)": [[1580, "torch.nn.Module.double"]], "eval() (torch.nn.module method)": [[1580, "torch.nn.Module.eval"]], "extra_repr() (torch.nn.module method)": [[1580, "torch.nn.Module.extra_repr"]], "float() (torch.nn.module method)": [[1580, "torch.nn.Module.float"]], "forward() (torch.nn.module method)": [[1580, "torch.nn.Module.forward"]], "get_buffer() (torch.nn.module method)": [[1580, "torch.nn.Module.get_buffer"]], "get_extra_state() (torch.nn.module method)": [[1580, "torch.nn.Module.get_extra_state"]], "get_parameter() (torch.nn.module method)": [[1580, "torch.nn.Module.get_parameter"]], "get_submodule() (torch.nn.module method)": [[1580, "torch.nn.Module.get_submodule"]], "half() (torch.nn.module method)": [[1580, "torch.nn.Module.half"]], "ipu() (torch.nn.module method)": [[1580, "torch.nn.Module.ipu"]], "load_state_dict() (torch.nn.module method)": [[1580, "torch.nn.Module.load_state_dict"]], "modules() (torch.nn.module method)": [[1580, "torch.nn.Module.modules"]], "mtia() (torch.nn.module method)": [[1580, "torch.nn.Module.mtia"]], "named_buffers() (torch.nn.module method)": [[1580, "torch.nn.Module.named_buffers"]], "named_children() (torch.nn.module method)": [[1580, "torch.nn.Module.named_children"]], "named_modules() (torch.nn.module method)": [[1580, "torch.nn.Module.named_modules"]], "named_parameters() (torch.nn.module method)": [[1580, "torch.nn.Module.named_parameters"]], "parameters() (torch.nn.module method)": [[1580, "torch.nn.Module.parameters"]], "register_backward_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_backward_hook"]], "register_buffer() (torch.nn.module method)": [[1580, "torch.nn.Module.register_buffer"]], "register_forward_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_forward_hook"]], "register_forward_pre_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_forward_pre_hook"]], "register_full_backward_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_full_backward_hook"]], "register_full_backward_pre_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_load_state_dict_pre_hook"]], "register_module() (torch.nn.module method)": [[1580, "torch.nn.Module.register_module"]], "register_parameter() (torch.nn.module method)": [[1580, "torch.nn.Module.register_parameter"]], "register_state_dict_post_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.nn.module method)": [[1580, "torch.nn.Module.register_state_dict_pre_hook"]], "requires_grad_() (torch.nn.module method)": [[1580, "torch.nn.Module.requires_grad_"]], "set_extra_state() (torch.nn.module method)": [[1580, "torch.nn.Module.set_extra_state"]], "set_submodule() (torch.nn.module method)": [[1580, "torch.nn.Module.set_submodule"]], "share_memory() (torch.nn.module method)": [[1580, "torch.nn.Module.share_memory"]], "state_dict() (torch.nn.module method)": [[1580, "torch.nn.Module.state_dict"]], "to() (torch.nn.module method)": [[1580, "torch.nn.Module.to"]], "to_empty() (torch.nn.module method)": [[1580, "torch.nn.Module.to_empty"]], "train() (torch.nn.module method)": [[1580, "torch.nn.Module.train"]], "type() (torch.nn.module method)": [[1580, "torch.nn.Module.type"]], "xpu() (torch.nn.module method)": [[1580, "torch.nn.Module.xpu"]], "zero_grad() (torch.nn.module method)": [[1580, "torch.nn.Module.zero_grad"]], "moduledict (class in torch.nn)": [[1581, "torch.nn.ModuleDict"]], "clear() (torch.nn.moduledict method)": [[1581, "torch.nn.ModuleDict.clear"]], "items() (torch.nn.moduledict method)": [[1581, "torch.nn.ModuleDict.items"]], "keys() (torch.nn.moduledict method)": [[1581, "torch.nn.ModuleDict.keys"]], "pop() (torch.nn.moduledict method)": [[1581, "torch.nn.ModuleDict.pop"]], "update() (torch.nn.moduledict method)": [[1581, "torch.nn.ModuleDict.update"]], "values() (torch.nn.moduledict method)": [[1581, "torch.nn.ModuleDict.values"]], "modulelist (class in torch.nn)": [[1582, "torch.nn.ModuleList"]], "append() (torch.nn.modulelist method)": [[1582, "torch.nn.ModuleList.append"]], "extend() (torch.nn.modulelist method)": [[1582, "torch.nn.ModuleList.extend"]], "insert() (torch.nn.modulelist method)": [[1582, "torch.nn.ModuleList.insert"]], "multilabelmarginloss (class in torch.nn)": [[1583, "torch.nn.MultiLabelMarginLoss"]], "multilabelsoftmarginloss (class in torch.nn)": [[1584, "torch.nn.MultiLabelSoftMarginLoss"]], "multimarginloss (class in torch.nn)": [[1585, "torch.nn.MultiMarginLoss"]], "multiheadattention (class in torch.nn)": [[1586, "torch.nn.MultiheadAttention"]], "forward() (torch.nn.multiheadattention method)": [[1586, "torch.nn.MultiheadAttention.forward"]], "merge_masks() (torch.nn.multiheadattention method)": [[1586, "torch.nn.MultiheadAttention.merge_masks"]], "nllloss (class in torch.nn)": [[1587, "torch.nn.NLLLoss"]], "prelu (class in torch.nn)": [[1588, "torch.nn.PReLU"]], "pairwisedistance (class in torch.nn)": [[1589, "torch.nn.PairwiseDistance"]], "parameterdict (class in torch.nn)": [[1590, "torch.nn.ParameterDict"]], "clear() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.clear"]], "copy() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.copy"]], "fromkeys() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.fromkeys"]], "get() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.get"]], "items() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.items"]], "keys() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.keys"]], "pop() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.pop"]], "popitem() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.popitem"]], "setdefault() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.setdefault"]], "update() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.update"]], "values() (torch.nn.parameterdict method)": [[1590, "torch.nn.ParameterDict.values"]], "parameterlist (class in torch.nn)": [[1591, "torch.nn.ParameterList"]], "append() (torch.nn.parameterlist method)": [[1591, "torch.nn.ParameterList.append"]], "extend() (torch.nn.parameterlist method)": [[1591, "torch.nn.ParameterList.extend"]], "pixelshuffle (class in torch.nn)": [[1592, "torch.nn.PixelShuffle"]], "pixelunshuffle (class in torch.nn)": [[1593, "torch.nn.PixelUnshuffle"]], "poissonnllloss (class in torch.nn)": [[1594, "torch.nn.PoissonNLLLoss"]], "rmsnorm (class in torch.nn)": [[1595, "torch.nn.RMSNorm"]], "extra_repr() (torch.nn.rmsnorm method)": [[1595, "torch.nn.RMSNorm.extra_repr"]], "forward() (torch.nn.rmsnorm method)": [[1595, "torch.nn.RMSNorm.forward"]], "reset_parameters() (torch.nn.rmsnorm method)": [[1595, "torch.nn.RMSNorm.reset_parameters"]], "rnn (class in torch.nn)": [[1596, "torch.nn.RNN"]], "rnnbase (class in torch.nn)": [[1597, "torch.nn.RNNBase"]], "flatten_parameters() (torch.nn.rnnbase method)": [[1597, "torch.nn.RNNBase.flatten_parameters"]], "rnncell (class in torch.nn)": [[1598, "torch.nn.RNNCell"]], "rrelu (class in torch.nn)": [[1599, "torch.nn.RReLU"]], "relu (class in torch.nn)": [[1600, "torch.nn.ReLU"]], "relu6 (class in torch.nn)": [[1601, "torch.nn.ReLU6"]], "reflectionpad1d (class in torch.nn)": [[1602, "torch.nn.ReflectionPad1d"]], "reflectionpad2d (class in torch.nn)": [[1603, "torch.nn.ReflectionPad2d"]], "reflectionpad3d (class in torch.nn)": [[1604, "torch.nn.ReflectionPad3d"]], "replicationpad1d (class in torch.nn)": [[1605, "torch.nn.ReplicationPad1d"]], "replicationpad2d (class in torch.nn)": [[1606, "torch.nn.ReplicationPad2d"]], "replicationpad3d (class in torch.nn)": [[1607, "torch.nn.ReplicationPad3d"]], "selu (class in torch.nn)": [[1608, "torch.nn.SELU"]], "sequential (class in torch.nn)": [[1609, "torch.nn.Sequential"]], "append() (torch.nn.sequential method)": [[1609, "torch.nn.Sequential.append"]], "silu (class in torch.nn)": [[1610, "torch.nn.SiLU"]], "sigmoid (class in torch.nn)": [[1611, "torch.nn.Sigmoid"]], "smoothl1loss (class in torch.nn)": [[1612, "torch.nn.SmoothL1Loss"]], "softmarginloss (class in torch.nn)": [[1613, "torch.nn.SoftMarginLoss"]], "softmax (class in torch.nn)": [[1614, "torch.nn.Softmax"]], "softmax2d (class in torch.nn)": [[1615, "torch.nn.Softmax2d"]], "softmin (class in torch.nn)": [[1616, "torch.nn.Softmin"]], "softplus (class in torch.nn)": [[1617, "torch.nn.Softplus"]], "softshrink (class in torch.nn)": [[1618, "torch.nn.Softshrink"]], "softsign (class in torch.nn)": [[1619, "torch.nn.Softsign"]], "syncbatchnorm (class in torch.nn)": [[1620, "torch.nn.SyncBatchNorm"]], "convert_sync_batchnorm() (torch.nn.syncbatchnorm class method)": [[1620, "torch.nn.SyncBatchNorm.convert_sync_batchnorm"]], "tanh (class in torch.nn)": [[1621, "torch.nn.Tanh"]], "tanhshrink (class in torch.nn)": [[1622, "torch.nn.Tanhshrink"]], "threshold (class in torch.nn)": [[1623, "torch.nn.Threshold"]], "transformer (class in torch.nn)": [[1624, "torch.nn.Transformer"]], "forward() (torch.nn.transformer method)": [[1624, "torch.nn.Transformer.forward"]], "generate_square_subsequent_mask() (torch.nn.transformer static method)": [[1624, "torch.nn.Transformer.generate_square_subsequent_mask"]], "transformerdecoder (class in torch.nn)": [[1625, "torch.nn.TransformerDecoder"]], "forward() (torch.nn.transformerdecoder method)": [[1625, "torch.nn.TransformerDecoder.forward"]], "transformerdecoderlayer (class in torch.nn)": [[1626, "torch.nn.TransformerDecoderLayer"]], "forward() (torch.nn.transformerdecoderlayer method)": [[1626, "torch.nn.TransformerDecoderLayer.forward"]], "transformerencoder (class in torch.nn)": [[1627, "torch.nn.TransformerEncoder"]], "forward() (torch.nn.transformerencoder method)": [[1627, "torch.nn.TransformerEncoder.forward"]], "transformerencoderlayer (class in torch.nn)": [[1628, "torch.nn.TransformerEncoderLayer"]], "forward() (torch.nn.transformerencoderlayer method)": [[1628, "torch.nn.TransformerEncoderLayer.forward"]], "tripletmarginloss (class in torch.nn)": [[1629, "torch.nn.TripletMarginLoss"]], "tripletmarginwithdistanceloss (class in torch.nn)": [[1630, "torch.nn.TripletMarginWithDistanceLoss"]], "unflatten (class in torch.nn)": [[1631, "torch.nn.Unflatten"]], "unfold (class in torch.nn)": [[1632, "torch.nn.Unfold"]], "upsample (class in torch.nn)": [[1633, "torch.nn.Upsample"]], "upsamplingbilinear2d (class in torch.nn)": [[1634, "torch.nn.UpsamplingBilinear2d"]], "upsamplingnearest2d (class in torch.nn)": [[1635, "torch.nn.UpsamplingNearest2d"]], "zeropad1d (class in torch.nn)": [[1636, "torch.nn.ZeroPad1d"]], "zeropad2d (class in torch.nn)": [[1637, "torch.nn.ZeroPad2d"]], "zeropad3d (class in torch.nn)": [[1638, "torch.nn.ZeroPad3d"]], "sdpbackend (class in torch.nn.attention)": [[1639, "torch.nn.attention.SDPBackend"]], "name (torch.nn.attention.sdpbackend property)": [[1639, "torch.nn.attention.SDPBackend.name"]], "causalbias (class in torch.nn.attention.bias)": [[1640, "torch.nn.attention.bias.CausalBias"]], "causalvariant (class in torch.nn.attention.bias)": [[1641, "torch.nn.attention.bias.CausalVariant"]], "causal_lower_right() (in module torch.nn.attention.bias)": [[1642, "torch.nn.attention.bias.causal_lower_right"]], "causal_upper_left() (in module torch.nn.attention.bias)": [[1643, "torch.nn.attention.bias.causal_upper_left"]], "sdpa_kernel() (in module torch.nn.attention)": [[1644, "torch.nn.attention.sdpa_kernel"]], "adaptive_avg_pool1d() (in module torch.nn.functional)": [[1645, "torch.nn.functional.adaptive_avg_pool1d"]], "adaptive_avg_pool2d() (in module torch.nn.functional)": [[1646, "torch.nn.functional.adaptive_avg_pool2d"]], "adaptive_avg_pool3d() (in module torch.nn.functional)": [[1647, "torch.nn.functional.adaptive_avg_pool3d"]], "adaptive_max_pool1d() (in module torch.nn.functional)": [[1648, "torch.nn.functional.adaptive_max_pool1d"]], "adaptive_max_pool2d() (in module torch.nn.functional)": [[1649, "torch.nn.functional.adaptive_max_pool2d"]], "adaptive_max_pool3d() (in module torch.nn.functional)": [[1650, "torch.nn.functional.adaptive_max_pool3d"]], "affine_grid() (in module torch.nn.functional)": [[1651, "torch.nn.functional.affine_grid"]], "alpha_dropout() (in module torch.nn.functional)": [[1652, "torch.nn.functional.alpha_dropout"]], "avg_pool1d() (in module torch.nn.functional)": [[1653, "torch.nn.functional.avg_pool1d"]], "avg_pool2d() (in module torch.nn.functional)": [[1654, "torch.nn.functional.avg_pool2d"]], "avg_pool3d() (in module torch.nn.functional)": [[1655, "torch.nn.functional.avg_pool3d"]], "batch_norm() (in module torch.nn.functional)": [[1656, "torch.nn.functional.batch_norm"]], "bilinear() (in module torch.nn.functional)": [[1657, "torch.nn.functional.bilinear"]], "binary_cross_entropy() (in module torch.nn.functional)": [[1658, "torch.nn.functional.binary_cross_entropy"]], "binary_cross_entropy_with_logits() (in module torch.nn.functional)": [[1659, "torch.nn.functional.binary_cross_entropy_with_logits"]], "celu() (in module torch.nn.functional)": [[1660, "torch.nn.functional.celu"]], "conv1d() (in module torch.nn.functional)": [[1661, "torch.nn.functional.conv1d"]], "conv2d() (in module torch.nn.functional)": [[1662, "torch.nn.functional.conv2d"]], "conv3d() (in module torch.nn.functional)": [[1663, "torch.nn.functional.conv3d"]], "conv_transpose1d() (in module torch.nn.functional)": [[1664, "torch.nn.functional.conv_transpose1d"]], "conv_transpose2d() (in module torch.nn.functional)": [[1665, "torch.nn.functional.conv_transpose2d"]], "conv_transpose3d() (in module torch.nn.functional)": [[1666, "torch.nn.functional.conv_transpose3d"]], "cosine_embedding_loss() (in module torch.nn.functional)": [[1667, "torch.nn.functional.cosine_embedding_loss"]], "cosine_similarity() (in module torch.nn.functional)": [[1668, "torch.nn.functional.cosine_similarity"]], "cross_entropy() (in module torch.nn.functional)": [[1669, "torch.nn.functional.cross_entropy"]], "ctc_loss() (in module torch.nn.functional)": [[1670, "torch.nn.functional.ctc_loss"]], "dropout() (in module torch.nn.functional)": [[1671, "torch.nn.functional.dropout"]], "dropout1d() (in module torch.nn.functional)": [[1672, "torch.nn.functional.dropout1d"]], "dropout2d() (in module torch.nn.functional)": [[1673, "torch.nn.functional.dropout2d"]], "dropout3d() (in module torch.nn.functional)": [[1674, "torch.nn.functional.dropout3d"]], "elu() (in module torch.nn.functional)": [[1675, "torch.nn.functional.elu"]], "elu_() (in module torch.nn.functional)": [[1676, "torch.nn.functional.elu_"]], "embedding() (in module torch.nn.functional)": [[1677, "torch.nn.functional.embedding"]], "embedding_bag() (in module torch.nn.functional)": [[1678, "torch.nn.functional.embedding_bag"]], "feature_alpha_dropout() (in module torch.nn.functional)": [[1679, "torch.nn.functional.feature_alpha_dropout"]], "fold() (in module torch.nn.functional)": [[1680, "torch.nn.functional.fold"]], "fractional_max_pool2d() (in module torch.nn.functional)": [[1681, "torch.nn.functional.fractional_max_pool2d"]], "fractional_max_pool3d() (in module torch.nn.functional)": [[1682, "torch.nn.functional.fractional_max_pool3d"]], "gaussian_nll_loss() (in module torch.nn.functional)": [[1683, "torch.nn.functional.gaussian_nll_loss"]], "gelu() (in module torch.nn.functional)": [[1684, "torch.nn.functional.gelu"]], "glu() (in module torch.nn.functional)": [[1685, "torch.nn.functional.glu"]], "grid_sample() (in module torch.nn.functional)": [[1686, "torch.nn.functional.grid_sample"]], "group_norm() (in module torch.nn.functional)": [[1687, "torch.nn.functional.group_norm"]], "gumbel_softmax() (in module torch.nn.functional)": [[1688, "torch.nn.functional.gumbel_softmax"]], "hardshrink() (in module torch.nn.functional)": [[1689, "torch.nn.functional.hardshrink"]], "hardsigmoid() (in module torch.nn.functional)": [[1690, "torch.nn.functional.hardsigmoid"]], "hardswish() (in module torch.nn.functional)": [[1691, "torch.nn.functional.hardswish"]], "hardtanh() (in module torch.nn.functional)": [[1692, "torch.nn.functional.hardtanh"]], "hardtanh_() (in module torch.nn.functional)": [[1693, "torch.nn.functional.hardtanh_"]], "hinge_embedding_loss() (in module torch.nn.functional)": [[1694, "torch.nn.functional.hinge_embedding_loss"]], "huber_loss() (in module torch.nn.functional)": [[1695, "torch.nn.functional.huber_loss"]], "instance_norm() (in module torch.nn.functional)": [[1696, "torch.nn.functional.instance_norm"]], "interpolate() (in module torch.nn.functional)": [[1697, "torch.nn.functional.interpolate"]], "kl_div() (in module torch.nn.functional)": [[1698, "torch.nn.functional.kl_div"]], "l1_loss() (in module torch.nn.functional)": [[1699, "torch.nn.functional.l1_loss"]], "layer_norm() (in module torch.nn.functional)": [[1700, "torch.nn.functional.layer_norm"]], "leaky_relu() (in module torch.nn.functional)": [[1701, "torch.nn.functional.leaky_relu"]], "leaky_relu_() (in module torch.nn.functional)": [[1702, "torch.nn.functional.leaky_relu_"]], "linear() (in module torch.nn.functional)": [[1703, "torch.nn.functional.linear"]], "local_response_norm() (in module torch.nn.functional)": [[1704, "torch.nn.functional.local_response_norm"]], "log_softmax() (in module torch.nn.functional)": [[1705, "torch.nn.functional.log_softmax"]], "logsigmoid() (in module torch.nn.functional)": [[1706, "torch.nn.functional.logsigmoid"]], "lp_pool1d() (in module torch.nn.functional)": [[1707, "torch.nn.functional.lp_pool1d"]], "lp_pool2d() (in module torch.nn.functional)": [[1708, "torch.nn.functional.lp_pool2d"]], "lp_pool3d() (in module torch.nn.functional)": [[1709, "torch.nn.functional.lp_pool3d"]], "margin_ranking_loss() (in module torch.nn.functional)": [[1710, "torch.nn.functional.margin_ranking_loss"]], "max_pool1d() (in module torch.nn.functional)": [[1711, "torch.nn.functional.max_pool1d"]], "max_pool2d() (in module torch.nn.functional)": [[1712, "torch.nn.functional.max_pool2d"]], "max_pool3d() (in module torch.nn.functional)": [[1713, "torch.nn.functional.max_pool3d"]], "max_unpool1d() (in module torch.nn.functional)": [[1714, "torch.nn.functional.max_unpool1d"]], "max_unpool2d() (in module torch.nn.functional)": [[1715, "torch.nn.functional.max_unpool2d"]], "max_unpool3d() (in module torch.nn.functional)": [[1716, "torch.nn.functional.max_unpool3d"]], "mish() (in module torch.nn.functional)": [[1717, "torch.nn.functional.mish"]], "mse_loss() (in module torch.nn.functional)": [[1718, "torch.nn.functional.mse_loss"]], "multi_margin_loss() (in module torch.nn.functional)": [[1719, "torch.nn.functional.multi_margin_loss"]], "multilabel_margin_loss() (in module torch.nn.functional)": [[1720, "torch.nn.functional.multilabel_margin_loss"]], "multilabel_soft_margin_loss() (in module torch.nn.functional)": [[1721, "torch.nn.functional.multilabel_soft_margin_loss"]], "nll_loss() (in module torch.nn.functional)": [[1722, "torch.nn.functional.nll_loss"]], "normalize() (in module torch.nn.functional)": [[1723, "torch.nn.functional.normalize"]], "one_hot() (in module torch.nn.functional)": [[1724, "torch.nn.functional.one_hot"]], "pad() (in module torch.nn.functional)": [[1725, "torch.nn.functional.pad"]], "pairwise_distance() (in module torch.nn.functional)": [[1726, "torch.nn.functional.pairwise_distance"]], "pdist() (in module torch.nn.functional)": [[1727, "torch.nn.functional.pdist"]], "pixel_shuffle() (in module torch.nn.functional)": [[1728, "torch.nn.functional.pixel_shuffle"]], "pixel_unshuffle() (in module torch.nn.functional)": [[1729, "torch.nn.functional.pixel_unshuffle"]], "poisson_nll_loss() (in module torch.nn.functional)": [[1730, "torch.nn.functional.poisson_nll_loss"]], "prelu() (in module torch.nn.functional)": [[1731, "torch.nn.functional.prelu"]], "relu() (in module torch.nn.functional)": [[1732, "torch.nn.functional.relu"]], "relu6() (in module torch.nn.functional)": [[1733, "torch.nn.functional.relu6"]], "relu_() (in module torch.nn.functional)": [[1734, "torch.nn.functional.relu_"]], "rms_norm() (in module torch.nn.functional)": [[1735, "torch.nn.functional.rms_norm"]], "rrelu() (in module torch.nn.functional)": [[1736, "torch.nn.functional.rrelu"]], "rrelu_() (in module torch.nn.functional)": [[1737, "torch.nn.functional.rrelu_"]], "scaled_dot_product_attention() (in module torch.nn.functional)": [[1738, "torch.nn.functional.scaled_dot_product_attention"]], "selu() (in module torch.nn.functional)": [[1739, "torch.nn.functional.selu"]], "sigmoid() (in module torch.nn.functional)": [[1740, "torch.nn.functional.sigmoid"]], "silu() (in module torch.nn.functional)": [[1741, "torch.nn.functional.silu"]], "smooth_l1_loss() (in module torch.nn.functional)": [[1742, "torch.nn.functional.smooth_l1_loss"]], "soft_margin_loss() (in module torch.nn.functional)": [[1743, "torch.nn.functional.soft_margin_loss"]], "softmax() (in module torch.nn.functional)": [[1744, "torch.nn.functional.softmax"]], "softmin() (in module torch.nn.functional)": [[1745, "torch.nn.functional.softmin"]], "softplus() (in module torch.nn.functional)": [[1746, "torch.nn.functional.softplus"]], "softshrink() (in module torch.nn.functional)": [[1747, "torch.nn.functional.softshrink"]], "softsign() (in module torch.nn.functional)": [[1748, "torch.nn.functional.softsign"]], "tanh() (in module torch.nn.functional)": [[1749, "torch.nn.functional.tanh"]], "tanhshrink() (in module torch.nn.functional)": [[1750, "torch.nn.functional.tanhshrink"]], "threshold() (in module torch.nn.functional)": [[1751, "torch.nn.functional.threshold"]], "threshold_() (in module torch.nn.functional)": [[1752, "torch.nn.functional.threshold_"]], "data_parallel() (in module torch.nn.parallel)": [[1753, "torch.nn.parallel.data_parallel"]], "triplet_margin_loss() (in module torch.nn.functional)": [[1754, "torch.nn.functional.triplet_margin_loss"]], "triplet_margin_with_distance_loss() (in module torch.nn.functional)": [[1755, "torch.nn.functional.triplet_margin_with_distance_loss"]], "unfold() (in module torch.nn.functional)": [[1756, "torch.nn.functional.unfold"]], "upsample() (in module torch.nn.functional)": [[1757, "torch.nn.functional.upsample"]], "upsample_bilinear() (in module torch.nn.functional)": [[1758, "torch.nn.functional.upsample_bilinear"]], "upsample_nearest() (in module torch.nn.functional)": [[1759, "torch.nn.functional.upsample_nearest"]], "lazymodulemixin (class in torch.nn.modules.lazy)": [[1760, "torch.nn.modules.lazy.LazyModuleMixin"]], "has_uninitialized_params() (torch.nn.modules.lazy.lazymodulemixin method)": [[1760, "torch.nn.modules.lazy.LazyModuleMixin.has_uninitialized_params"]], "initialize_parameters() (torch.nn.modules.lazy.lazymodulemixin method)": [[1760, "torch.nn.modules.lazy.LazyModuleMixin.initialize_parameters"]], "register_module_backward_hook() (in module torch.nn.modules.module)": [[1761, "torch.nn.modules.module.register_module_backward_hook"]], "register_module_buffer_registration_hook() (in module torch.nn.modules.module)": [[1762, "torch.nn.modules.module.register_module_buffer_registration_hook"]], "register_module_forward_hook() (in module torch.nn.modules.module)": [[1763, "torch.nn.modules.module.register_module_forward_hook"]], "register_module_forward_pre_hook() (in module torch.nn.modules.module)": [[1764, "torch.nn.modules.module.register_module_forward_pre_hook"]], "register_module_full_backward_hook() (in module torch.nn.modules.module)": [[1765, "torch.nn.modules.module.register_module_full_backward_hook"]], "register_module_full_backward_pre_hook() (in module torch.nn.modules.module)": [[1766, "torch.nn.modules.module.register_module_full_backward_pre_hook"]], "register_module_module_registration_hook() (in module torch.nn.modules.module)": [[1767, "torch.nn.modules.module.register_module_module_registration_hook"]], "register_module_parameter_registration_hook() (in module torch.nn.modules.module)": [[1768, "torch.nn.modules.module.register_module_parameter_registration_hook"]], "rmsnorm (class in torch.nn.modules.normalization)": [[1769, "torch.nn.modules.normalization.RMSNorm"]], "extra_repr() (torch.nn.modules.normalization.rmsnorm method)": [[1769, "torch.nn.modules.normalization.RMSNorm.extra_repr"]], "forward() (torch.nn.modules.normalization.rmsnorm method)": [[1769, "torch.nn.modules.normalization.RMSNorm.forward"]], "reset_parameters() (torch.nn.modules.normalization.rmsnorm method)": [[1769, "torch.nn.modules.normalization.RMSNorm.reset_parameters"]], "distributeddataparallel (class in torch.nn.parallel)": [[1770, "torch.nn.parallel.DistributedDataParallel"]], "join() (torch.nn.parallel.distributeddataparallel method)": [[1770, "torch.nn.parallel.DistributedDataParallel.join"]], "join_hook() (torch.nn.parallel.distributeddataparallel method)": [[1770, "torch.nn.parallel.DistributedDataParallel.join_hook"]], "no_sync() (torch.nn.parallel.distributeddataparallel method)": [[1770, "torch.nn.parallel.DistributedDataParallel.no_sync"]], "register_comm_hook() (torch.nn.parallel.distributeddataparallel method)": [[1770, "torch.nn.parallel.DistributedDataParallel.register_comm_hook"]], "buffer (class in torch.nn.parameter)": [[1771, "torch.nn.parameter.Buffer"]], "parameter (class in torch.nn.parameter)": [[1772, "torch.nn.parameter.Parameter"]], "uninitializedbuffer (class in torch.nn.parameter)": [[1773, "torch.nn.parameter.UninitializedBuffer"]], "uninitializedparameter (class in torch.nn.parameter)": [[1774, "torch.nn.parameter.UninitializedParameter"]], "cls_to_become (torch.nn.parameter.uninitializedparameter attribute)": [[1774, "torch.nn.parameter.UninitializedParameter.cls_to_become"]], "clip_grad_norm() (in module torch.nn.utils)": [[1775, "torch.nn.utils.clip_grad_norm"]], "clip_grad_norm_() (in module torch.nn.utils)": [[1776, "torch.nn.utils.clip_grad_norm_"]], "clip_grad_value_() (in module torch.nn.utils)": [[1777, "torch.nn.utils.clip_grad_value_"]], "clip_grads_with_norm_() (in module torch.nn.utils)": [[1778, "torch.nn.utils.clip_grads_with_norm_"]], "convert_conv2d_weight_memory_format() (in module torch.nn.utils)": [[1779, "torch.nn.utils.convert_conv2d_weight_memory_format"]], "convert_conv3d_weight_memory_format() (in module torch.nn.utils)": [[1780, "torch.nn.utils.convert_conv3d_weight_memory_format"]], "fuse_conv_bn_eval() (in module torch.nn.utils)": [[1781, "torch.nn.utils.fuse_conv_bn_eval"]], "fuse_conv_bn_weights() (in module torch.nn.utils)": [[1782, "torch.nn.utils.fuse_conv_bn_weights"]], "fuse_linear_bn_eval() (in module torch.nn.utils)": [[1783, "torch.nn.utils.fuse_linear_bn_eval"]], "fuse_linear_bn_weights() (in module torch.nn.utils)": [[1784, "torch.nn.utils.fuse_linear_bn_weights"]], "get_total_norm() (in module torch.nn.utils)": [[1785, "torch.nn.utils.get_total_norm"]], "parameters_to_vector() (in module torch.nn.utils)": [[1786, "torch.nn.utils.parameters_to_vector"]], "orthogonal() (in module torch.nn.utils.parametrizations)": [[1787, "torch.nn.utils.parametrizations.orthogonal"]], "spectral_norm() (in module torch.nn.utils.parametrizations)": [[1788, "torch.nn.utils.parametrizations.spectral_norm"]], "weight_norm() (in module torch.nn.utils.parametrizations)": [[1789, "torch.nn.utils.parametrizations.weight_norm"]], "parametrizationlist (class in torch.nn.utils.parametrize)": [[1790, "torch.nn.utils.parametrize.ParametrizationList"]], "right_inverse() (torch.nn.utils.parametrize.parametrizationlist method)": [[1790, "torch.nn.utils.parametrize.ParametrizationList.right_inverse"]], "cached() (in module torch.nn.utils.parametrize)": [[1791, "torch.nn.utils.parametrize.cached"]], "is_parametrized() (in module torch.nn.utils.parametrize)": [[1792, "torch.nn.utils.parametrize.is_parametrized"]], "register_parametrization() (in module torch.nn.utils.parametrize)": [[1793, "torch.nn.utils.parametrize.register_parametrization"]], "remove_parametrizations() (in module torch.nn.utils.parametrize)": [[1794, "torch.nn.utils.parametrize.remove_parametrizations"]], "basepruningmethod (class in torch.nn.utils.prune)": [[1795, "torch.nn.utils.prune.BasePruningMethod"]], "apply() (torch.nn.utils.prune.basepruningmethod class method)": [[1795, "torch.nn.utils.prune.BasePruningMethod.apply"]], "apply_mask() (torch.nn.utils.prune.basepruningmethod method)": [[1795, "torch.nn.utils.prune.BasePruningMethod.apply_mask"]], "compute_mask() (torch.nn.utils.prune.basepruningmethod method)": [[1795, "torch.nn.utils.prune.BasePruningMethod.compute_mask"]], "prune() (torch.nn.utils.prune.basepruningmethod method)": [[1795, "torch.nn.utils.prune.BasePruningMethod.prune"]], "remove() (torch.nn.utils.prune.basepruningmethod method)": [[1795, "torch.nn.utils.prune.BasePruningMethod.remove"]], "customfrommask (class in torch.nn.utils.prune)": [[1796, "torch.nn.utils.prune.CustomFromMask"]], "apply() (torch.nn.utils.prune.customfrommask class method)": [[1796, "torch.nn.utils.prune.CustomFromMask.apply"]], "apply_mask() (torch.nn.utils.prune.customfrommask method)": [[1796, "torch.nn.utils.prune.CustomFromMask.apply_mask"]], "prune() (torch.nn.utils.prune.customfrommask method)": [[1796, "torch.nn.utils.prune.CustomFromMask.prune"]], "remove() (torch.nn.utils.prune.customfrommask method)": [[1796, "torch.nn.utils.prune.CustomFromMask.remove"]], "identity() (in module torch.nn.utils.prune)": [[1797, "torch.nn.utils.prune.identity"]], "l1unstructured (class in torch.nn.utils.prune)": [[1798, "torch.nn.utils.prune.L1Unstructured"]], "apply() (torch.nn.utils.prune.l1unstructured class method)": [[1798, "torch.nn.utils.prune.L1Unstructured.apply"]], "apply_mask() (torch.nn.utils.prune.l1unstructured method)": [[1798, "torch.nn.utils.prune.L1Unstructured.apply_mask"]], "prune() (torch.nn.utils.prune.l1unstructured method)": [[1798, "torch.nn.utils.prune.L1Unstructured.prune"]], "remove() (torch.nn.utils.prune.l1unstructured method)": [[1798, "torch.nn.utils.prune.L1Unstructured.remove"]], "lnstructured (class in torch.nn.utils.prune)": [[1799, "torch.nn.utils.prune.LnStructured"]], "apply() (torch.nn.utils.prune.lnstructured class method)": [[1799, "torch.nn.utils.prune.LnStructured.apply"]], "apply_mask() (torch.nn.utils.prune.lnstructured method)": [[1799, "torch.nn.utils.prune.LnStructured.apply_mask"]], "compute_mask() (torch.nn.utils.prune.lnstructured method)": [[1799, "torch.nn.utils.prune.LnStructured.compute_mask"]], "prune() (torch.nn.utils.prune.lnstructured method)": [[1799, "torch.nn.utils.prune.LnStructured.prune"]], "remove() (torch.nn.utils.prune.lnstructured method)": [[1799, "torch.nn.utils.prune.LnStructured.remove"]], "pruningcontainer (class in torch.nn.utils.prune)": [[1800, "torch.nn.utils.prune.PruningContainer"]], "add_pruning_method() (torch.nn.utils.prune.pruningcontainer method)": [[1800, "torch.nn.utils.prune.PruningContainer.add_pruning_method"]], "apply() (torch.nn.utils.prune.pruningcontainer class method)": [[1800, "torch.nn.utils.prune.PruningContainer.apply"]], "apply_mask() (torch.nn.utils.prune.pruningcontainer method)": [[1800, "torch.nn.utils.prune.PruningContainer.apply_mask"]], "compute_mask() (torch.nn.utils.prune.pruningcontainer method)": [[1800, "torch.nn.utils.prune.PruningContainer.compute_mask"]], "prune() (torch.nn.utils.prune.pruningcontainer method)": [[1800, "torch.nn.utils.prune.PruningContainer.prune"]], "remove() (torch.nn.utils.prune.pruningcontainer method)": [[1800, "torch.nn.utils.prune.PruningContainer.remove"]], "randomstructured (class in torch.nn.utils.prune)": [[1801, "torch.nn.utils.prune.RandomStructured"]], "apply() (torch.nn.utils.prune.randomstructured class method)": [[1801, "torch.nn.utils.prune.RandomStructured.apply"]], "apply_mask() (torch.nn.utils.prune.randomstructured method)": [[1801, "torch.nn.utils.prune.RandomStructured.apply_mask"]], "compute_mask() (torch.nn.utils.prune.randomstructured method)": [[1801, "torch.nn.utils.prune.RandomStructured.compute_mask"]], "prune() (torch.nn.utils.prune.randomstructured method)": [[1801, "torch.nn.utils.prune.RandomStructured.prune"]], "remove() (torch.nn.utils.prune.randomstructured method)": [[1801, "torch.nn.utils.prune.RandomStructured.remove"]], "randomunstructured (class in torch.nn.utils.prune)": [[1802, "torch.nn.utils.prune.RandomUnstructured"]], "apply() (torch.nn.utils.prune.randomunstructured class method)": [[1802, "torch.nn.utils.prune.RandomUnstructured.apply"]], "apply_mask() (torch.nn.utils.prune.randomunstructured method)": [[1802, "torch.nn.utils.prune.RandomUnstructured.apply_mask"]], "prune() (torch.nn.utils.prune.randomunstructured method)": [[1802, "torch.nn.utils.prune.RandomUnstructured.prune"]], "remove() (torch.nn.utils.prune.randomunstructured method)": [[1802, "torch.nn.utils.prune.RandomUnstructured.remove"]], "custom_from_mask() (in module torch.nn.utils.prune)": [[1803, "torch.nn.utils.prune.custom_from_mask"]], "global_unstructured() (in module torch.nn.utils.prune)": [[1804, "torch.nn.utils.prune.global_unstructured"]], "is_pruned() (in module torch.nn.utils.prune)": [[1805, "torch.nn.utils.prune.is_pruned"]], "l1_unstructured() (in module torch.nn.utils.prune)": [[1806, "torch.nn.utils.prune.l1_unstructured"]], "ln_structured() (in module torch.nn.utils.prune)": [[1807, "torch.nn.utils.prune.ln_structured"]], "random_structured() (in module torch.nn.utils.prune)": [[1808, "torch.nn.utils.prune.random_structured"]], "random_unstructured() (in module torch.nn.utils.prune)": [[1809, "torch.nn.utils.prune.random_unstructured"]], "remove() (in module torch.nn.utils.prune)": [[1810, "torch.nn.utils.prune.remove"]], "remove_spectral_norm() (in module torch.nn.utils)": [[1811, "torch.nn.utils.remove_spectral_norm"]], "remove_weight_norm() (in module torch.nn.utils)": [[1812, "torch.nn.utils.remove_weight_norm"]], "packedsequence (class in torch.nn.utils.rnn)": [[1813, "torch.nn.utils.rnn.PackedSequence"]], "batch_sizes (torch.nn.utils.rnn.packedsequence attribute)": [[1813, "torch.nn.utils.rnn.PackedSequence.batch_sizes"]], "count() (torch.nn.utils.rnn.packedsequence method)": [[1813, "torch.nn.utils.rnn.PackedSequence.count"]], "data (torch.nn.utils.rnn.packedsequence attribute)": [[1813, "torch.nn.utils.rnn.PackedSequence.data"]], "index() (torch.nn.utils.rnn.packedsequence method)": [[1813, "torch.nn.utils.rnn.PackedSequence.index"]], "is_cuda (torch.nn.utils.rnn.packedsequence property)": [[1813, "torch.nn.utils.rnn.PackedSequence.is_cuda"]], "is_pinned() (torch.nn.utils.rnn.packedsequence method)": [[1813, "torch.nn.utils.rnn.PackedSequence.is_pinned"]], "sorted_indices (torch.nn.utils.rnn.packedsequence attribute)": [[1813, "torch.nn.utils.rnn.PackedSequence.sorted_indices"]], "to() (torch.nn.utils.rnn.packedsequence method)": [[1813, "torch.nn.utils.rnn.PackedSequence.to"]], "unsorted_indices (torch.nn.utils.rnn.packedsequence attribute)": [[1813, "torch.nn.utils.rnn.PackedSequence.unsorted_indices"]], "pack_padded_sequence() (in module torch.nn.utils.rnn)": [[1814, "torch.nn.utils.rnn.pack_padded_sequence"]], "pack_sequence() (in module torch.nn.utils.rnn)": [[1815, "torch.nn.utils.rnn.pack_sequence"]], "pad_packed_sequence() (in module torch.nn.utils.rnn)": [[1816, "torch.nn.utils.rnn.pad_packed_sequence"]], "pad_sequence() (in module torch.nn.utils.rnn)": [[1817, "torch.nn.utils.rnn.pad_sequence"]], "unpack_sequence() (in module torch.nn.utils.rnn)": [[1818, "torch.nn.utils.rnn.unpack_sequence"]], "unpad_sequence() (in module torch.nn.utils.rnn)": [[1819, "torch.nn.utils.rnn.unpad_sequence"]], "skip_init() (in module torch.nn.utils)": [[1820, "torch.nn.utils.skip_init"]], "spectral_norm() (in module torch.nn.utils)": [[1821, "torch.nn.utils.spectral_norm"]], "functional_call() (in module torch.nn.utils.stateless)": [[1822, "torch.nn.utils.stateless.functional_call"]], "vector_to_parameters() (in module torch.nn.utils)": [[1823, "torch.nn.utils.vector_to_parameters"]], "weight_norm() (in module torch.nn.utils)": [[1824, "torch.nn.utils.weight_norm"]], "no_grad (class in torch)": [[1825, "torch.no_grad"]], "nonzero() (in module torch)": [[1826, "torch.nonzero"]], "norm() (in module torch)": [[1827, "torch.norm"]], "normal() (in module torch)": [[1828, "torch.normal"]], "not_equal() (in module torch)": [[1829, "torch.not_equal"]], "numel() (in module torch)": [[1830, "torch.numel"]], "ones() (in module torch)": [[1831, "torch.ones"]], "ones_like() (in module torch)": [[1832, "torch.ones_like"]], "jitscalartype (class in torch.onnx)": [[1833, "torch.onnx.JitScalarType"]], "dtype() (torch.onnx.jitscalartype method)": [[1833, "torch.onnx.JitScalarType.dtype"]], "from_dtype() (torch.onnx.jitscalartype class method)": [[1833, "torch.onnx.JitScalarType.from_dtype"]], "from_onnx_type() (torch.onnx.jitscalartype class method)": [[1833, "torch.onnx.JitScalarType.from_onnx_type"]], "from_value() (torch.onnx.jitscalartype class method)": [[1833, "torch.onnx.JitScalarType.from_value"]], "onnx_compatible() (torch.onnx.jitscalartype method)": [[1833, "torch.onnx.JitScalarType.onnx_compatible"]], "onnx_type() (torch.onnx.jitscalartype method)": [[1833, "torch.onnx.JitScalarType.onnx_type"]], "scalar_name() (torch.onnx.jitscalartype method)": [[1833, "torch.onnx.JitScalarType.scalar_name"]], "torch_name() (torch.onnx.jitscalartype method)": [[1833, "torch.onnx.JitScalarType.torch_name"]], "graphinfo (class in torch.onnx.verification)": [[1834, "torch.onnx.verification.GraphInfo"], [2156, "torch.onnx.verification.GraphInfo"]], "all_mismatch_leaf_graph_info() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.all_mismatch_leaf_graph_info"]], "clear() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.clear"]], "essential_node_count() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.essential_node_count"]], "essential_node_kinds() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.essential_node_kinds"]], "export_repro() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.export_repro"]], "find_mismatch() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.find_mismatch"]], "find_partition() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.find_partition"]], "has_mismatch() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.has_mismatch"]], "pretty_print_mismatch() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.pretty_print_mismatch"]], "pretty_print_tree() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.pretty_print_tree"]], "verify_export() (torch.onnx.verification.graphinfo method)": [[1834, "torch.onnx.verification.GraphInfo.verify_export"]], "verificationoptions (class in torch.onnx.verification)": [[1835, "torch.onnx.verification.VerificationOptions"], [2156, "torch.onnx.verification.VerificationOptions"]], "asgd (class in torch.optim)": [[1836, "torch.optim.ASGD"]], "add_param_group() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.add_param_group"]], "load_state_dict() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.register_step_pre_hook"]], "state_dict() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.state_dict"]], "step() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.step"]], "zero_grad() (torch.optim.asgd method)": [[1836, "torch.optim.ASGD.zero_grad"]], "adadelta (class in torch.optim)": [[1837, "torch.optim.Adadelta"]], "add_param_group() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.add_param_group"]], "load_state_dict() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.register_step_pre_hook"]], "state_dict() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.state_dict"]], "step() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.step"]], "zero_grad() (torch.optim.adadelta method)": [[1837, "torch.optim.Adadelta.zero_grad"]], "adafactor (class in torch.optim)": [[1838, "torch.optim.Adafactor"]], "add_param_group() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.add_param_group"]], "load_state_dict() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.register_step_pre_hook"]], "state_dict() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.state_dict"]], "step() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.step"]], "zero_grad() (torch.optim.adafactor method)": [[1838, "torch.optim.Adafactor.zero_grad"]], "adagrad (class in torch.optim)": [[1839, "torch.optim.Adagrad"]], "add_param_group() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.add_param_group"]], "load_state_dict() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.register_step_pre_hook"]], "state_dict() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.state_dict"]], "step() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.step"]], "zero_grad() (torch.optim.adagrad method)": [[1839, "torch.optim.Adagrad.zero_grad"]], "adam (class in torch.optim)": [[1840, "torch.optim.Adam"]], "add_param_group() (torch.optim.adam method)": [[1840, "torch.optim.Adam.add_param_group"]], "load_state_dict() (torch.optim.adam method)": [[1840, "torch.optim.Adam.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.adam method)": [[1840, "torch.optim.Adam.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.adam method)": [[1840, "torch.optim.Adam.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.adam method)": [[1840, "torch.optim.Adam.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.adam method)": [[1840, "torch.optim.Adam.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.adam method)": [[1840, "torch.optim.Adam.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adam method)": [[1840, "torch.optim.Adam.register_step_pre_hook"]], "state_dict() (torch.optim.adam method)": [[1840, "torch.optim.Adam.state_dict"]], "step() (torch.optim.adam method)": [[1840, "torch.optim.Adam.step"]], "zero_grad() (torch.optim.adam method)": [[1840, "torch.optim.Adam.zero_grad"]], "adamw (class in torch.optim)": [[1841, "torch.optim.AdamW"]], "add_param_group() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.add_param_group"]], "load_state_dict() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.register_step_pre_hook"]], "state_dict() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.state_dict"]], "step() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.step"]], "zero_grad() (torch.optim.adamw method)": [[1841, "torch.optim.AdamW.zero_grad"]], "adamax (class in torch.optim)": [[1842, "torch.optim.Adamax"]], "add_param_group() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.add_param_group"]], "load_state_dict() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.register_step_pre_hook"]], "state_dict() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.state_dict"]], "step() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.step"]], "zero_grad() (torch.optim.adamax method)": [[1842, "torch.optim.Adamax.zero_grad"]], "lbfgs (class in torch.optim)": [[1843, "torch.optim.LBFGS"]], "add_param_group() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.add_param_group"]], "load_state_dict() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.register_step_pre_hook"]], "state_dict() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.state_dict"]], "step() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.step"]], "zero_grad() (torch.optim.lbfgs method)": [[1843, "torch.optim.LBFGS.zero_grad"]], "nadam (class in torch.optim)": [[1844, "torch.optim.NAdam"]], "add_param_group() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.add_param_group"]], "load_state_dict() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.register_step_pre_hook"]], "state_dict() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.state_dict"]], "step() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.step"]], "zero_grad() (torch.optim.nadam method)": [[1844, "torch.optim.NAdam.zero_grad"]], "add_param_group() (torch.optim.optimizer method)": [[1845, "torch.optim.Optimizer.add_param_group"]], "load_state_dict() (torch.optim.optimizer method)": [[1846, "torch.optim.Optimizer.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.optimizer method)": [[1847, "torch.optim.Optimizer.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.optimizer method)": [[1848, "torch.optim.Optimizer.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.optimizer method)": [[1849, "torch.optim.Optimizer.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.optimizer method)": [[1850, "torch.optim.Optimizer.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.optimizer method)": [[1851, "torch.optim.Optimizer.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.optimizer method)": [[1852, "torch.optim.Optimizer.register_step_pre_hook"]], "state_dict() (torch.optim.optimizer method)": [[1853, "torch.optim.Optimizer.state_dict"]], "step() (torch.optim.optimizer method)": [[1854, "torch.optim.Optimizer.step"]], "zero_grad() (torch.optim.optimizer method)": [[1855, "torch.optim.Optimizer.zero_grad"]], "radam (class in torch.optim)": [[1856, "torch.optim.RAdam"]], "add_param_group() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.add_param_group"]], "load_state_dict() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.register_step_pre_hook"]], "state_dict() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.state_dict"]], "step() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.step"]], "zero_grad() (torch.optim.radam method)": [[1856, "torch.optim.RAdam.zero_grad"]], "rmsprop (class in torch.optim)": [[1857, "torch.optim.RMSprop"]], "add_param_group() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.add_param_group"]], "load_state_dict() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.register_step_pre_hook"]], "state_dict() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.state_dict"]], "step() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.step"]], "zero_grad() (torch.optim.rmsprop method)": [[1857, "torch.optim.RMSprop.zero_grad"]], "rprop (class in torch.optim)": [[1858, "torch.optim.Rprop"]], "add_param_group() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.add_param_group"]], "load_state_dict() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.register_step_pre_hook"]], "state_dict() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.state_dict"]], "step() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.step"]], "zero_grad() (torch.optim.rprop method)": [[1858, "torch.optim.Rprop.zero_grad"]], "sgd (class in torch.optim)": [[1859, "torch.optim.SGD"]], "add_param_group() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.add_param_group"]], "load_state_dict() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.register_step_pre_hook"]], "state_dict() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.state_dict"]], "step() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.step"]], "zero_grad() (torch.optim.sgd method)": [[1859, "torch.optim.SGD.zero_grad"]], "sparseadam (class in torch.optim)": [[1860, "torch.optim.SparseAdam"]], "add_param_group() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.add_param_group"]], "load_state_dict() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.load_state_dict"]], "register_load_state_dict_post_hook() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.register_load_state_dict_pre_hook"]], "register_state_dict_post_hook() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.register_state_dict_pre_hook"]], "register_step_post_hook() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.register_step_pre_hook"]], "state_dict() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.state_dict"]], "step() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.step"]], "zero_grad() (torch.optim.sparseadam method)": [[1860, "torch.optim.SparseAdam.zero_grad"]], "chainedscheduler (class in torch.optim.lr_scheduler)": [[1861, "torch.optim.lr_scheduler.ChainedScheduler"]], "get_last_lr() (torch.optim.lr_scheduler.chainedscheduler method)": [[1861, "torch.optim.lr_scheduler.ChainedScheduler.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.chainedscheduler method)": [[1861, "torch.optim.lr_scheduler.ChainedScheduler.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.chainedscheduler method)": [[1861, "torch.optim.lr_scheduler.ChainedScheduler.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.chainedscheduler method)": [[1861, "torch.optim.lr_scheduler.ChainedScheduler.print_lr"]], "state_dict() (torch.optim.lr_scheduler.chainedscheduler method)": [[1861, "torch.optim.lr_scheduler.ChainedScheduler.state_dict"]], "step() (torch.optim.lr_scheduler.chainedscheduler method)": [[1861, "torch.optim.lr_scheduler.ChainedScheduler.step"]], "constantlr (class in torch.optim.lr_scheduler)": [[1862, "torch.optim.lr_scheduler.ConstantLR"]], "get_last_lr() (torch.optim.lr_scheduler.constantlr method)": [[1862, "torch.optim.lr_scheduler.ConstantLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.constantlr method)": [[1862, "torch.optim.lr_scheduler.ConstantLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.constantlr method)": [[1862, "torch.optim.lr_scheduler.ConstantLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.constantlr method)": [[1862, "torch.optim.lr_scheduler.ConstantLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.constantlr method)": [[1862, "torch.optim.lr_scheduler.ConstantLR.state_dict"]], "step() (torch.optim.lr_scheduler.constantlr method)": [[1862, "torch.optim.lr_scheduler.ConstantLR.step"]], "cosineannealinglr (class in torch.optim.lr_scheduler)": [[1863, "torch.optim.lr_scheduler.CosineAnnealingLR"]], "get_last_lr() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1863, "torch.optim.lr_scheduler.CosineAnnealingLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1863, "torch.optim.lr_scheduler.CosineAnnealingLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1863, "torch.optim.lr_scheduler.CosineAnnealingLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1863, "torch.optim.lr_scheduler.CosineAnnealingLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1863, "torch.optim.lr_scheduler.CosineAnnealingLR.state_dict"]], "step() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1863, "torch.optim.lr_scheduler.CosineAnnealingLR.step"]], "cosineannealingwarmrestarts (class in torch.optim.lr_scheduler)": [[1864, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts"]], "get_last_lr() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1864, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1864, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1864, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1864, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.print_lr"]], "state_dict() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1864, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.state_dict"]], "step() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1864, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step"]], "cycliclr (class in torch.optim.lr_scheduler)": [[1865, "torch.optim.lr_scheduler.CyclicLR"]], "get_last_lr() (torch.optim.lr_scheduler.cycliclr method)": [[1865, "torch.optim.lr_scheduler.CyclicLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.cycliclr method)": [[1865, "torch.optim.lr_scheduler.CyclicLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.cycliclr method)": [[1865, "torch.optim.lr_scheduler.CyclicLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.cycliclr method)": [[1865, "torch.optim.lr_scheduler.CyclicLR.print_lr"]], "scale_fn() (torch.optim.lr_scheduler.cycliclr method)": [[1865, "torch.optim.lr_scheduler.CyclicLR.scale_fn"]], "step() (torch.optim.lr_scheduler.cycliclr method)": [[1865, "torch.optim.lr_scheduler.CyclicLR.step"]], "exponentiallr (class in torch.optim.lr_scheduler)": [[1866, "torch.optim.lr_scheduler.ExponentialLR"]], "get_last_lr() (torch.optim.lr_scheduler.exponentiallr method)": [[1866, "torch.optim.lr_scheduler.ExponentialLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.exponentiallr method)": [[1866, "torch.optim.lr_scheduler.ExponentialLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.exponentiallr method)": [[1866, "torch.optim.lr_scheduler.ExponentialLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.exponentiallr method)": [[1866, "torch.optim.lr_scheduler.ExponentialLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.exponentiallr method)": [[1866, "torch.optim.lr_scheduler.ExponentialLR.state_dict"]], "step() (torch.optim.lr_scheduler.exponentiallr method)": [[1866, "torch.optim.lr_scheduler.ExponentialLR.step"]], "lrscheduler (class in torch.optim.lr_scheduler)": [[1867, "torch.optim.lr_scheduler.LRScheduler"]], "get_last_lr() (torch.optim.lr_scheduler.lrscheduler method)": [[1867, "torch.optim.lr_scheduler.LRScheduler.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.lrscheduler method)": [[1867, "torch.optim.lr_scheduler.LRScheduler.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.lrscheduler method)": [[1867, "torch.optim.lr_scheduler.LRScheduler.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.lrscheduler method)": [[1867, "torch.optim.lr_scheduler.LRScheduler.print_lr"]], "state_dict() (torch.optim.lr_scheduler.lrscheduler method)": [[1867, "torch.optim.lr_scheduler.LRScheduler.state_dict"]], "step() (torch.optim.lr_scheduler.lrscheduler method)": [[1867, "torch.optim.lr_scheduler.LRScheduler.step"]], "lambdalr (class in torch.optim.lr_scheduler)": [[1868, "torch.optim.lr_scheduler.LambdaLR"]], "get_last_lr() (torch.optim.lr_scheduler.lambdalr method)": [[1868, "torch.optim.lr_scheduler.LambdaLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.lambdalr method)": [[1868, "torch.optim.lr_scheduler.LambdaLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.lambdalr method)": [[1868, "torch.optim.lr_scheduler.LambdaLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.lambdalr method)": [[1868, "torch.optim.lr_scheduler.LambdaLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.lambdalr method)": [[1868, "torch.optim.lr_scheduler.LambdaLR.state_dict"]], "step() (torch.optim.lr_scheduler.lambdalr method)": [[1868, "torch.optim.lr_scheduler.LambdaLR.step"]], "linearlr (class in torch.optim.lr_scheduler)": [[1869, "torch.optim.lr_scheduler.LinearLR"]], "get_last_lr() (torch.optim.lr_scheduler.linearlr method)": [[1869, "torch.optim.lr_scheduler.LinearLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.linearlr method)": [[1869, "torch.optim.lr_scheduler.LinearLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.linearlr method)": [[1869, "torch.optim.lr_scheduler.LinearLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.linearlr method)": [[1869, "torch.optim.lr_scheduler.LinearLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.linearlr method)": [[1869, "torch.optim.lr_scheduler.LinearLR.state_dict"]], "step() (torch.optim.lr_scheduler.linearlr method)": [[1869, "torch.optim.lr_scheduler.LinearLR.step"]], "multisteplr (class in torch.optim.lr_scheduler)": [[1870, "torch.optim.lr_scheduler.MultiStepLR"]], "get_last_lr() (torch.optim.lr_scheduler.multisteplr method)": [[1870, "torch.optim.lr_scheduler.MultiStepLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.multisteplr method)": [[1870, "torch.optim.lr_scheduler.MultiStepLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.multisteplr method)": [[1870, "torch.optim.lr_scheduler.MultiStepLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.multisteplr method)": [[1870, "torch.optim.lr_scheduler.MultiStepLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.multisteplr method)": [[1870, "torch.optim.lr_scheduler.MultiStepLR.state_dict"]], "step() (torch.optim.lr_scheduler.multisteplr method)": [[1870, "torch.optim.lr_scheduler.MultiStepLR.step"]], "multiplicativelr (class in torch.optim.lr_scheduler)": [[1871, "torch.optim.lr_scheduler.MultiplicativeLR"]], "get_last_lr() (torch.optim.lr_scheduler.multiplicativelr method)": [[1871, "torch.optim.lr_scheduler.MultiplicativeLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.multiplicativelr method)": [[1871, "torch.optim.lr_scheduler.MultiplicativeLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.multiplicativelr method)": [[1871, "torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.multiplicativelr method)": [[1871, "torch.optim.lr_scheduler.MultiplicativeLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.multiplicativelr method)": [[1871, "torch.optim.lr_scheduler.MultiplicativeLR.state_dict"]], "step() (torch.optim.lr_scheduler.multiplicativelr method)": [[1871, "torch.optim.lr_scheduler.MultiplicativeLR.step"]], "onecyclelr (class in torch.optim.lr_scheduler)": [[1872, "torch.optim.lr_scheduler.OneCycleLR"]], "get_last_lr() (torch.optim.lr_scheduler.onecyclelr method)": [[1872, "torch.optim.lr_scheduler.OneCycleLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.onecyclelr method)": [[1872, "torch.optim.lr_scheduler.OneCycleLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.onecyclelr method)": [[1872, "torch.optim.lr_scheduler.OneCycleLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.onecyclelr method)": [[1872, "torch.optim.lr_scheduler.OneCycleLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.onecyclelr method)": [[1872, "torch.optim.lr_scheduler.OneCycleLR.state_dict"]], "step() (torch.optim.lr_scheduler.onecyclelr method)": [[1872, "torch.optim.lr_scheduler.OneCycleLR.step"]], "polynomiallr (class in torch.optim.lr_scheduler)": [[1873, "torch.optim.lr_scheduler.PolynomialLR"]], "get_last_lr() (torch.optim.lr_scheduler.polynomiallr method)": [[1873, "torch.optim.lr_scheduler.PolynomialLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.polynomiallr method)": [[1873, "torch.optim.lr_scheduler.PolynomialLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.polynomiallr method)": [[1873, "torch.optim.lr_scheduler.PolynomialLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.polynomiallr method)": [[1873, "torch.optim.lr_scheduler.PolynomialLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.polynomiallr method)": [[1873, "torch.optim.lr_scheduler.PolynomialLR.state_dict"]], "step() (torch.optim.lr_scheduler.polynomiallr method)": [[1873, "torch.optim.lr_scheduler.PolynomialLR.step"]], "reducelronplateau (class in torch.optim.lr_scheduler)": [[1874, "torch.optim.lr_scheduler.ReduceLROnPlateau"]], "get_last_lr() (torch.optim.lr_scheduler.reducelronplateau method)": [[1874, "torch.optim.lr_scheduler.ReduceLROnPlateau.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.reducelronplateau method)": [[1874, "torch.optim.lr_scheduler.ReduceLROnPlateau.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.reducelronplateau method)": [[1874, "torch.optim.lr_scheduler.ReduceLROnPlateau.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.reducelronplateau method)": [[1874, "torch.optim.lr_scheduler.ReduceLROnPlateau.print_lr"]], "step() (torch.optim.lr_scheduler.reducelronplateau method)": [[1874, "torch.optim.lr_scheduler.ReduceLROnPlateau.step"]], "sequentiallr (class in torch.optim.lr_scheduler)": [[1875, "torch.optim.lr_scheduler.SequentialLR"]], "get_last_lr() (torch.optim.lr_scheduler.sequentiallr method)": [[1875, "torch.optim.lr_scheduler.SequentialLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.sequentiallr method)": [[1875, "torch.optim.lr_scheduler.SequentialLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.sequentiallr method)": [[1875, "torch.optim.lr_scheduler.SequentialLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.sequentiallr method)": [[1875, "torch.optim.lr_scheduler.SequentialLR.print_lr"]], "recursive_undo() (torch.optim.lr_scheduler.sequentiallr method)": [[1875, "torch.optim.lr_scheduler.SequentialLR.recursive_undo"]], "state_dict() (torch.optim.lr_scheduler.sequentiallr method)": [[1875, "torch.optim.lr_scheduler.SequentialLR.state_dict"]], "step() (torch.optim.lr_scheduler.sequentiallr method)": [[1875, "torch.optim.lr_scheduler.SequentialLR.step"]], "steplr (class in torch.optim.lr_scheduler)": [[1876, "torch.optim.lr_scheduler.StepLR"]], "get_last_lr() (torch.optim.lr_scheduler.steplr method)": [[1876, "torch.optim.lr_scheduler.StepLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.steplr method)": [[1876, "torch.optim.lr_scheduler.StepLR.get_lr"]], "load_state_dict() (torch.optim.lr_scheduler.steplr method)": [[1876, "torch.optim.lr_scheduler.StepLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.steplr method)": [[1876, "torch.optim.lr_scheduler.StepLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.steplr method)": [[1876, "torch.optim.lr_scheduler.StepLR.state_dict"]], "step() (torch.optim.lr_scheduler.steplr method)": [[1876, "torch.optim.lr_scheduler.StepLR.step"]], "averagedmodel (class in torch.optim.swa_utils)": [[1877, "torch.optim.swa_utils.AveragedModel"]], "add_module() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.add_module"]], "apply() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.apply"]], "bfloat16() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.bfloat16"]], "buffers() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.buffers"]], "children() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.children"]], "compile() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.compile"]], "cpu() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.cpu"]], "cuda() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.cuda"]], "double() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.double"]], "eval() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.eval"]], "extra_repr() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.extra_repr"]], "float() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.float"]], "forward() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.forward"]], "get_buffer() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.get_buffer"]], "get_extra_state() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.get_extra_state"]], "get_parameter() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.get_parameter"]], "get_submodule() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.get_submodule"]], "half() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.half"]], "ipu() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.ipu"]], "load_state_dict() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.load_state_dict"]], "modules() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.modules"]], "mtia() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.mtia"]], "named_buffers() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.named_buffers"]], "named_children() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.named_children"]], "named_modules() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.named_modules"]], "named_parameters() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.named_parameters"]], "parameters() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.parameters"]], "register_backward_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_backward_hook"]], "register_buffer() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_buffer"]], "register_forward_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_forward_hook"]], "register_forward_pre_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_forward_pre_hook"]], "register_full_backward_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_full_backward_hook"]], "register_full_backward_pre_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_load_state_dict_post_hook"]], "register_load_state_dict_pre_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_load_state_dict_pre_hook"]], "register_module() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_module"]], "register_parameter() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_parameter"]], "register_state_dict_post_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_state_dict_post_hook"]], "register_state_dict_pre_hook() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.register_state_dict_pre_hook"]], "requires_grad_() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.requires_grad_"]], "set_extra_state() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.set_extra_state"]], "set_submodule() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.set_submodule"]], "share_memory() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.share_memory"]], "state_dict() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.state_dict"]], "to() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.to"]], "to_empty() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.to_empty"]], "train() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.train"]], "type() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.type"]], "update_parameters() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.update_parameters"]], "xpu() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.xpu"]], "zero_grad() (torch.optim.swa_utils.averagedmodel method)": [[1877, "torch.optim.swa_utils.AveragedModel.zero_grad"]], "swalr (class in torch.optim.swa_utils)": [[1878, "torch.optim.swa_utils.SWALR"]], "get_last_lr() (torch.optim.swa_utils.swalr method)": [[1878, "torch.optim.swa_utils.SWALR.get_last_lr"]], "get_lr() (torch.optim.swa_utils.swalr method)": [[1878, "torch.optim.swa_utils.SWALR.get_lr"]], "load_state_dict() (torch.optim.swa_utils.swalr method)": [[1878, "torch.optim.swa_utils.SWALR.load_state_dict"]], "print_lr() (torch.optim.swa_utils.swalr method)": [[1878, "torch.optim.swa_utils.SWALR.print_lr"]], "state_dict() (torch.optim.swa_utils.swalr method)": [[1878, "torch.optim.swa_utils.SWALR.state_dict"]], "step() (torch.optim.swa_utils.swalr method)": [[1878, "torch.optim.swa_utils.SWALR.step"]], "orgqr() (in module torch)": [[1879, "torch.orgqr"]], "ormqr() (in module torch)": [[1880, "torch.ormqr"]], "outer() (in module torch)": [[1881, "torch.outer"]], "pca_lowrank() (in module torch)": [[1882, "torch.pca_lowrank"]], "permute() (in module torch)": [[1883, "torch.permute"]], "pinverse() (in module torch)": [[1884, "torch.pinverse"]], "poisson() (in module torch)": [[1885, "torch.poisson"]], "polar() (in module torch)": [[1886, "torch.polar"]], "polygamma() (in module torch)": [[1887, "torch.polygamma"]], "positive() (in module torch)": [[1888, "torch.positive"]], "pow() (in module torch)": [[1889, "torch.pow"]], "prod() (in module torch)": [[1890, "torch.prod"]], "promote_types() (in module torch)": [[1891, "torch.promote_types"]], "qr() (in module torch)": [[1892, "torch.qr"]], "quantile() (in module torch)": [[1893, "torch.quantile"]], "quantize_per_channel() (in module torch)": [[1894, "torch.quantize_per_channel"]], "quantize_per_tensor() (in module torch)": [[1895, "torch.quantize_per_tensor"]], "quantized_batch_norm() (in module torch)": [[1896, "torch.quantized_batch_norm"]], "quantized_max_pool1d() (in module torch)": [[1897, "torch.quantized_max_pool1d"]], "quantized_max_pool2d() (in module torch)": [[1898, "torch.quantized_max_pool2d"]], "sobolengine (class in torch.quasirandom)": [[1899, "torch.quasirandom.SobolEngine"]], "draw() (torch.quasirandom.sobolengine method)": [[1899, "torch.quasirandom.SobolEngine.draw"]], "draw_base2() (torch.quasirandom.sobolengine method)": [[1899, "torch.quasirandom.SobolEngine.draw_base2"]], "fast_forward() (torch.quasirandom.sobolengine method)": [[1899, "torch.quasirandom.SobolEngine.fast_forward"]], "reset() (torch.quasirandom.sobolengine method)": [[1899, "torch.quasirandom.SobolEngine.reset"]], "rad2deg() (in module torch)": [[1900, "torch.rad2deg"]], "rand() (in module torch)": [[1901, "torch.rand"]], "rand_like() (in module torch)": [[1902, "torch.rand_like"]], "randint() (in module torch)": [[1903, "torch.randint"]], "randint_like() (in module torch)": [[1904, "torch.randint_like"]], "randn() (in module torch)": [[1905, "torch.randn"]], "randn_like() (in module torch)": [[1906, "torch.randn_like"]], "randperm() (in module torch)": [[1907, "torch.randperm"]], "range() (in module torch)": [[1908, "torch.range"]], "ravel() (in module torch)": [[1909, "torch.ravel"]], "real() (in module torch)": [[1910, "torch.real"]], "reciprocal() (in module torch)": [[1911, "torch.reciprocal"]], "remainder() (in module torch)": [[1912, "torch.remainder"]], "renorm() (in module torch)": [[1913, "torch.renorm"]], "repeat_interleave() (in module torch)": [[1914, "torch.repeat_interleave"]], "reshape() (in module torch)": [[1915, "torch.reshape"]], "resolve_conj() (in module torch)": [[1916, "torch.resolve_conj"]], "resolve_neg() (in module torch)": [[1917, "torch.resolve_neg"]], "result_type() (in module torch)": [[1918, "torch.result_type"]], "roll() (in module torch)": [[1919, "torch.roll"]], "rot90() (in module torch)": [[1920, "torch.rot90"]], "round() (in module torch)": [[1921, "torch.round"]], "row_stack() (in module torch)": [[1922, "torch.row_stack"]], "rsqrt() (in module torch)": [[1923, "torch.rsqrt"]], "save() (in module torch)": [[1924, "torch.save"]], "scatter() (in module torch)": [[1925, "torch.scatter"]], "scatter_add() (in module torch)": [[1926, "torch.scatter_add"]], "scatter_reduce() (in module torch)": [[1927, "torch.scatter_reduce"]], "searchsorted() (in module torch)": [[1928, "torch.searchsorted"]], "seed() (in module torch)": [[1929, "torch.seed"]], "select() (in module torch)": [[1930, "torch.select"]], "select_scatter() (in module torch)": [[1931, "torch.select_scatter"]], "set_default_device() (in module torch)": [[1932, "torch.set_default_device"]], "set_default_dtype() (in module torch)": [[1933, "torch.set_default_dtype"]], "set_default_tensor_type() (in module torch)": [[1934, "torch.set_default_tensor_type"]], "set_deterministic_debug_mode() (in module torch)": [[1935, "torch.set_deterministic_debug_mode"]], "set_float32_matmul_precision() (in module torch)": [[1936, "torch.set_float32_matmul_precision"]], "set_flush_denormal() (in module torch)": [[1937, "torch.set_flush_denormal"]], "set_num_interop_threads() (in module torch)": [[1938, "torch.set_num_interop_threads"]], "set_num_threads() (in module torch)": [[1939, "torch.set_num_threads"]], "set_printoptions() (in module torch)": [[1940, "torch.set_printoptions"]], "set_rng_state() (in module torch)": [[1941, "torch.set_rng_state"]], "set_warn_always() (in module torch)": [[1942, "torch.set_warn_always"]], "sgn() (in module torch)": [[1943, "torch.sgn"]], "sigmoid() (in module torch)": [[1944, "torch.sigmoid"]], "sign() (in module torch)": [[1945, "torch.sign"]], "bartlett() (in module torch.signal.windows)": [[1946, "torch.signal.windows.bartlett"]], "blackman() (in module torch.signal.windows)": [[1947, "torch.signal.windows.blackman"]], "cosine() (in module torch.signal.windows)": [[1948, "torch.signal.windows.cosine"]], "exponential() (in module torch.signal.windows)": [[1949, "torch.signal.windows.exponential"]], "gaussian() (in module torch.signal.windows)": [[1950, "torch.signal.windows.gaussian"]], "general_cosine() (in module torch.signal.windows)": [[1951, "torch.signal.windows.general_cosine"]], "general_hamming() (in module torch.signal.windows)": [[1952, "torch.signal.windows.general_hamming"]], "hamming() (in module torch.signal.windows)": [[1953, "torch.signal.windows.hamming"]], "hann() (in module torch.signal.windows)": [[1954, "torch.signal.windows.hann"]], "kaiser() (in module torch.signal.windows)": [[1955, "torch.signal.windows.kaiser"]], "nuttall() (in module torch.signal.windows)": [[1956, "torch.signal.windows.nuttall"]], "signbit() (in module torch)": [[1957, "torch.signbit"]], "sin() (in module torch)": [[1958, "torch.sin"]], "sinc() (in module torch)": [[1959, "torch.sinc"]], "sinh() (in module torch)": [[1960, "torch.sinh"]], "slice_scatter() (in module torch)": [[1961, "torch.slice_scatter"]], "slogdet() (in module torch)": [[1962, "torch.slogdet"]], "smm() (in module torch)": [[1963, "torch.smm"]], "softmax() (in module torch)": [[1964, "torch.softmax"]], "sort() (in module torch)": [[1965, "torch.sort"]], "addmm() (in module torch.sparse)": [[1966, "torch.sparse.addmm"]], "as_sparse_gradcheck() (in module torch.sparse)": [[1967, "torch.sparse.as_sparse_gradcheck"]], "check_sparse_tensor_invariants (class in torch.sparse)": [[1968, "torch.sparse.check_sparse_tensor_invariants"]], "disable() (torch.sparse.check_sparse_tensor_invariants static method)": [[1968, "torch.sparse.check_sparse_tensor_invariants.disable"]], "enable() (torch.sparse.check_sparse_tensor_invariants static method)": [[1968, "torch.sparse.check_sparse_tensor_invariants.enable"]], "is_enabled() (torch.sparse.check_sparse_tensor_invariants static method)": [[1968, "torch.sparse.check_sparse_tensor_invariants.is_enabled"]], "log_softmax() (in module torch.sparse)": [[1969, "torch.sparse.log_softmax"]], "mm() (in module torch.sparse)": [[1970, "torch.sparse.mm"]], "sampled_addmm() (in module torch.sparse)": [[1971, "torch.sparse.sampled_addmm"]], "softmax() (in module torch.sparse)": [[1972, "torch.sparse.softmax"]], "spdiags() (in module torch.sparse)": [[1973, "torch.sparse.spdiags"]], "spsolve() (in module torch.sparse)": [[1974, "torch.sparse.spsolve"]], "sum() (in module torch.sparse)": [[1975, "torch.sparse.sum"]], "sparse_bsc_tensor() (in module torch)": [[1976, "torch.sparse_bsc_tensor"]], "sparse_bsr_tensor() (in module torch)": [[1977, "torch.sparse_bsr_tensor"]], "sparse_compressed_tensor() (in module torch)": [[1978, "torch.sparse_compressed_tensor"]], "sparse_coo_tensor() (in module torch)": [[1979, "torch.sparse_coo_tensor"]], "sparse_csc_tensor() (in module torch)": [[1980, "torch.sparse_csc_tensor"]], "sparse_csr_tensor() (in module torch)": [[1981, "torch.sparse_csr_tensor"]], "split() (in module torch)": [[1982, "torch.split"]], "sqrt() (in module torch)": [[1983, "torch.sqrt"]], "square() (in module torch)": [[1984, "torch.square"]], "squeeze() (in module torch)": [[1985, "torch.squeeze"]], "sspaddmm() (in module torch)": [[1986, "torch.sspaddmm"]], "stack() (in module torch)": [[1987, "torch.stack"]], "std() (in module torch)": [[1988, "torch.std"]], "std_mean() (in module torch)": [[1989, "torch.std_mean"]], "stft() (in module torch)": [[1990, "torch.stft"]], "sub() (in module torch)": [[1991, "torch.sub"]], "subtract() (in module torch)": [[1992, "torch.subtract"]], "sum() (in module torch)": [[1993, "torch.sum"]], "svd() (in module torch)": [[1994, "torch.svd"]], "svd_lowrank() (in module torch)": [[1995, "torch.svd_lowrank"]], "swapaxes() (in module torch)": [[1996, "torch.swapaxes"]], "swapdims() (in module torch)": [[1997, "torch.swapdims"]], "sym_float() (in module torch)": [[1998, "torch.sym_float"]], "sym_fresh_size() (in module torch)": [[1999, "torch.sym_fresh_size"]], "sym_int() (in module torch)": [[2000, "torch.sym_int"]], "sym_ite() (in module torch)": [[2001, "torch.sym_ite"]], "sym_max() (in module torch)": [[2002, "torch.sym_max"]], "sym_min() (in module torch)": [[2003, "torch.sym_min"]], "sym_not() (in module torch)": [[2004, "torch.sym_not"]], "sym_sum() (in module torch)": [[2005, "torch.sym_sum"]], "t() (in module torch)": [[2006, "torch.t"]], "take() (in module torch)": [[2007, "torch.take"]], "take_along_dim() (in module torch)": [[2008, "torch.take_along_dim"]], "tan() (in module torch)": [[2009, "torch.tan"]], "tanh() (in module torch)": [[2010, "torch.tanh"]], "tensor() (in module torch)": [[2011, "torch.tensor"]], "tensor_split() (in module torch)": [[2012, "torch.tensor_split"]], "tensordot() (in module torch)": [[2013, "torch.tensordot"]], "tile() (in module torch)": [[2014, "torch.tile"]], "topk() (in module torch)": [[2015, "torch.topk"]], "trace() (in module torch)": [[2016, "torch.trace"]], "transpose() (in module torch)": [[2017, "torch.transpose"]], "trapezoid() (in module torch)": [[2018, "torch.trapezoid"]], "trapz() (in module torch)": [[2019, "torch.trapz"]], "triangular_solve() (in module torch)": [[2020, "torch.triangular_solve"]], "tril() (in module torch)": [[2021, "torch.tril"]], "tril_indices() (in module torch)": [[2022, "torch.tril_indices"]], "triu() (in module torch)": [[2023, "torch.triu"]], "triu_indices() (in module torch)": [[2024, "torch.triu_indices"]], "true_divide() (in module torch)": [[2025, "torch.true_divide"]], "trunc() (in module torch)": [[2026, "torch.trunc"]], "unbind() (in module torch)": [[2027, "torch.unbind"]], "unflatten() (in module torch)": [[2028, "torch.unflatten"]], "unique() (in module torch)": [[2029, "torch.unique"]], "unique_consecutive() (in module torch)": [[2030, "torch.unique_consecutive"]], "unravel_index() (in module torch)": [[2031, "torch.unravel_index"]], "unsqueeze() (in module torch)": [[2032, "torch.unsqueeze"]], "use_deterministic_algorithms() (in module torch)": [[2033, "torch.use_deterministic_algorithms"]], "generate_methods_for_privateuse1_backend() (in module torch.utils)": [[2034, "torch.utils.generate_methods_for_privateuse1_backend"]], "get_cpp_backtrace() (in module torch.utils)": [[2035, "torch.utils.get_cpp_backtrace"]], "rename_privateuse1_backend() (in module torch.utils)": [[2036, "torch.utils.rename_privateuse1_backend"]], "set_module() (in module torch.utils)": [[2037, "torch.utils.set_module"]], "swap_tensors() (in module torch.utils)": [[2038, "torch.utils.swap_tensors"]], "vander() (in module torch)": [[2039, "torch.vander"]], "var() (in module torch)": [[2040, "torch.var"]], "var_mean() (in module torch)": [[2041, "torch.var_mean"]], "vdot() (in module torch)": [[2042, "torch.vdot"]], "view_as_complex() (in module torch)": [[2043, "torch.view_as_complex"]], "view_as_real() (in module torch)": [[2044, "torch.view_as_real"]], "vmap() (in module torch)": [[2045, "torch.vmap"]], "vsplit() (in module torch)": [[2046, "torch.vsplit"]], "vstack() (in module torch)": [[2047, "torch.vstack"]], "where() (in module torch)": [[2048, "torch.where"]], "xlogy() (in module torch)": [[2049, "torch.xlogy"]], "event (class in torch.xpu)": [[2050, "torch.xpu.Event"]], "elapsed_time() (torch.xpu.event method)": [[2050, "torch.xpu.Event.elapsed_time"]], "query() (torch.xpu.event method)": [[2050, "torch.xpu.Event.query"]], "record() (torch.xpu.event method)": [[2050, "torch.xpu.Event.record"]], "synchronize() (torch.xpu.event method)": [[2050, "torch.xpu.Event.synchronize"]], "wait() (torch.xpu.event method)": [[2050, "torch.xpu.Event.wait"]], "stream() (in module torch.xpu)": [[2051, "torch.xpu.stream"]], "streamcontext (class in torch.xpu)": [[2052, "torch.xpu.StreamContext"]], "current_device() (in module torch.xpu)": [[2053, "torch.xpu.current_device"]], "current_stream() (in module torch.xpu)": [[2054, "torch.xpu.current_stream"]], "device (class in torch.xpu)": [[2055, "torch.xpu.device"]], "device_count() (in module torch.xpu)": [[2056, "torch.xpu.device_count"]], "device_of (class in torch.xpu)": [[2057, "torch.xpu.device_of"]], "empty_cache() (in module torch.xpu)": [[2058, "torch.xpu.empty_cache"]], "get_arch_list() (in module torch.xpu)": [[2059, "torch.xpu.get_arch_list"]], "get_device_capability() (in module torch.xpu)": [[2060, "torch.xpu.get_device_capability"]], "get_device_name() (in module torch.xpu)": [[2061, "torch.xpu.get_device_name"]], "get_device_properties() (in module torch.xpu)": [[2062, "torch.xpu.get_device_properties"]], "get_gencode_flags() (in module torch.xpu)": [[2063, "torch.xpu.get_gencode_flags"]], "get_rng_state() (in module torch.xpu)": [[2064, "torch.xpu.get_rng_state"]], "get_rng_state_all() (in module torch.xpu)": [[2065, "torch.xpu.get_rng_state_all"]], "init() (in module torch.xpu)": [[2067, "torch.xpu.init"]], "initial_seed() (in module torch.xpu)": [[2068, "torch.xpu.initial_seed"]], "is_available() (in module torch.xpu)": [[2069, "torch.xpu.is_available"]], "is_initialized() (in module torch.xpu)": [[2070, "torch.xpu.is_initialized"]], "manual_seed() (in module torch.xpu)": [[2071, "torch.xpu.manual_seed"]], "manual_seed_all() (in module torch.xpu)": [[2072, "torch.xpu.manual_seed_all"]], "max_memory_allocated() (in module torch.xpu)": [[2073, "torch.xpu.max_memory_allocated"]], "max_memory_reserved() (in module torch.xpu)": [[2074, "torch.xpu.max_memory_reserved"]], "mem_get_info() (in module torch.xpu)": [[2075, "torch.xpu.mem_get_info"]], "memory_allocated() (in module torch.xpu)": [[2076, "torch.xpu.memory_allocated"]], "memory_reserved() (in module torch.xpu)": [[2077, "torch.xpu.memory_reserved"]], "memory_stats() (in module torch.xpu)": [[2078, "torch.xpu.memory_stats"]], "memory_stats_as_nested_dict() (in module torch.xpu)": [[2079, "torch.xpu.memory_stats_as_nested_dict"]], "reset_accumulated_memory_stats() (in module torch.xpu)": [[2080, "torch.xpu.reset_accumulated_memory_stats"]], "reset_peak_memory_stats() (in module torch.xpu)": [[2081, "torch.xpu.reset_peak_memory_stats"]], "seed() (in module torch.xpu)": [[2082, "torch.xpu.seed"]], "seed_all() (in module torch.xpu)": [[2083, "torch.xpu.seed_all"]], "set_device() (in module torch.xpu)": [[2084, "torch.xpu.set_device"]], "set_rng_state() (in module torch.xpu)": [[2085, "torch.xpu.set_rng_state"]], "set_rng_state_all() (in module torch.xpu)": [[2086, "torch.xpu.set_rng_state_all"]], "set_stream() (in module torch.xpu)": [[2087, "torch.xpu.set_stream"]], "synchronize() (in module torch.xpu)": [[2088, "torch.xpu.synchronize"]], "zeros() (in module torch)": [[2089, "torch.zeros"]], "zeros_like() (in module torch)": [[2090, "torch.zeros_like"]], "download_url_to_file() (in module torch.hub)": [[2091, "torch.hub.download_url_to_file"]], "get_dir() (in module torch.hub)": [[2091, "torch.hub.get_dir"]], "help() (in module torch.hub)": [[2091, "torch.hub.help"]], "list() (in module torch.hub)": [[2091, "torch.hub.list"]], "load() (in module torch.hub)": [[2091, "torch.hub.load"]], "load_state_dict_from_url() (in module torch.hub)": [[2091, "torch.hub.load_state_dict_from_url"]], "set_dir() (in module torch.hub)": [[2091, "torch.hub.set_dir"]], "torch.hub": [[2091, "module-torch.hub"]], "pytorch_jit": [[2093, "envvar-PYTORCH_JIT"]], "environment variable": [[2093, "envvar-PYTORCH_JIT"], [2184, "index-0"]], "export() (in module torch.jit)": [[2093, "torch.jit.export"]], "torch.jit": [[2093, "module-torch.jit"]], "torch.jit.annotations": [[2093, "module-torch.jit.annotations"]], "torch.jit.frontend": [[2093, "module-torch.jit.frontend"]], "torch.jit.generate_bytecode": [[2093, "module-torch.jit.generate_bytecode"]], "torch.jit.mobile": [[2093, "module-torch.jit.mobile"]], "torch.jit.quantized": [[2093, "module-torch.jit.quantized"]], "torch.jit.supported_ops": [[2094, "module-torch.jit.supported_ops"]], "is_scripting() (in module torch.jit)": [[2095, "torch.jit.is_scripting"]], "is_tracing() (in module torch.jit)": [[2095, "torch.jit.is_tracing"]], "torch.jit.unsupported_tensor_ops": [[2098, "module-torch.jit.unsupported_tensor_ops"]], "torch.utils.jit": [[2099, "module-torch.utils.jit"]], "customopdef (class in torch._library.custom_ops)": [[2100, "torch._library.custom_ops.CustomOpDef"]], "library (class in torch.library)": [[2100, "torch.library.Library"]], "custom_op() (in module torch.library)": [[2100, "torch.library.custom_op"]], "define() (in module torch.library)": [[2100, "torch.library.define"]], "define() (torch.library.library method)": [[2100, "torch.library.Library.define"]], "fallback() (torch.library.library method)": [[2100, "torch.library.Library.fallback"]], "fallthrough_kernel() (in module torch.library)": [[2100, "torch.library.fallthrough_kernel"]], "get_ctx() (in module torch.library)": [[2100, "torch.library.get_ctx"]], "impl() (in module torch.library)": [[2100, "torch.library.impl"]], "impl() (torch.library.library method)": [[2100, "torch.library.Library.impl"]], "impl_abstract() (in module torch.library)": [[2100, "torch.library.impl_abstract"]], "infer_schema() (in module torch.library)": [[2100, "torch.library.infer_schema"]], "opcheck() (in module torch.library)": [[2100, "torch.library.opcheck"]], "register_autograd() (in module torch.library)": [[2100, "torch.library.register_autograd"]], "register_fake() (in module torch.library)": [[2100, "torch.library.register_fake"]], "register_kernel() (in module torch.library)": [[2100, "torch.library.register_kernel"]], "register_torch_dispatch() (in module torch.library)": [[2100, "torch.library.register_torch_dispatch"]], "register_vmap() (in module torch.library)": [[2100, "torch.library.register_vmap"]], "set_kernel_enabled() (torch._library.custom_ops.customopdef method)": [[2100, "torch._library.custom_ops.CustomOpDef.set_kernel_enabled"]], "torch.library": [[2100, "module-torch.library"]], "triton_op() (in module torch.library)": [[2100, "torch.library.triton_op"]], "wrap_triton() (in module torch.library)": [[2100, "torch.library.wrap_triton"]], "torch.linalg": [[2101, "module-torch.linalg"]], "torch._logging": [[2102, "module-torch._logging"]], "torch.masked": [[2103, "module-torch.masked"]], "torch.masked.maskedtensor": [[2103, "module-torch.masked.maskedtensor"]], "torch.masked.maskedtensor.binary": [[2103, "module-torch.masked.maskedtensor.binary"]], "torch.masked.maskedtensor.core": [[2103, "module-torch.masked.maskedtensor.core"]], "torch.masked.maskedtensor.creation": [[2103, "module-torch.masked.maskedtensor.creation"]], "torch.masked.maskedtensor.passthrough": [[2103, "module-torch.masked.maskedtensor.passthrough"]], "torch.masked.maskedtensor.reductions": [[2103, "module-torch.masked.maskedtensor.reductions"]], "torch.masked.maskedtensor.unary": [[2103, "module-torch.masked.maskedtensor.unary"]], "optimize_for_mobile() (in module torch.utils.mobile_optimizer)": [[2106, "torch.utils.mobile_optimizer.optimize_for_mobile"]], "load_url() (in module torch.utils.model_zoo)": [[2107, "torch.utils.model_zoo.load_url"]], "torch.utils.model_zoo": [[2107, "module-torch.utils.model_zoo"]], "moduletracker (class in torch.utils.module_tracker)": [[2108, "torch.utils.module_tracker.ModuleTracker"]], "torch.utils.module_tracker": [[2108, "module-torch.utils.module_tracker"]], "aggregation (class in torch.monitor)": [[2109, "torch.monitor.Aggregation"]], "event (class in torch.monitor)": [[2109, "torch.monitor.Event"]], "eventhandlerhandle (class in torch.monitor)": [[2109, "torch.monitor.EventHandlerHandle"]], "stat (class in torch.monitor)": [[2109, "torch.monitor.Stat"]], "tensorboardeventhandler (class in torch.monitor)": [[2109, "torch.monitor.TensorboardEventHandler"]], "__init__() (torch.monitor.event method)": [[2109, "torch.monitor.Event.__init__"]], "__init__() (torch.monitor.stat method)": [[2109, "torch.monitor.Stat.__init__"]], "__init__() (torch.monitor.tensorboardeventhandler method)": [[2109, "torch.monitor.TensorboardEventHandler.__init__"]], "add() (torch.monitor.stat method)": [[2109, "torch.monitor.Stat.add"]], "count (torch.monitor.stat property)": [[2109, "torch.monitor.Stat.count"]], "data (torch.monitor.event property)": [[2109, "torch.monitor.Event.data"]], "data_value_t (class in torch.monitor)": [[2109, "torch.monitor.data_value_t"]], "get() (torch.monitor.stat method)": [[2109, "torch.monitor.Stat.get"]], "log_event() (in module torch.monitor)": [[2109, "torch.monitor.log_event"]], "name (torch.monitor.aggregation property)": [[2109, "torch.monitor.Aggregation.name"]], "name (torch.monitor.event property)": [[2109, "torch.monitor.Event.name"]], "name (torch.monitor.stat property)": [[2109, "torch.monitor.Stat.name"]], "register_event_handler() (in module torch.monitor)": [[2109, "torch.monitor.register_event_handler"]], "timestamp (torch.monitor.event property)": [[2109, "torch.monitor.Event.timestamp"]], "torch.monitor": [[2109, "module-torch.monitor"]], "unregister_event_handler() (in module torch.monitor)": [[2109, "torch.monitor.unregister_event_handler"]], "torch.mps": [[2110, "module-torch.mps"]], "torch.mps.event": [[2110, "module-torch.mps.event"]], "torch.mps.profiler": [[2110, "module-torch.mps.profiler"]], "torch.mtia": [[2112, "module-torch.mtia"]], "torch.mtia.memory": [[2113, "module-torch.mtia.memory"]], "spawncontext (class in torch.multiprocessing)": [[2114, "torch.multiprocessing.SpawnContext"]], "get_all_sharing_strategies() (in module torch.multiprocessing)": [[2114, "torch.multiprocessing.get_all_sharing_strategies"]], "get_sharing_strategy() (in module torch.multiprocessing)": [[2114, "torch.multiprocessing.get_sharing_strategy"]], "join() (torch.multiprocessing.spawncontext method)": [[2114, "torch.multiprocessing.SpawnContext.join"]], "set_sharing_strategy() (in module torch.multiprocessing)": [[2114, "torch.multiprocessing.set_sharing_strategy"]], "spawn() (in module torch.multiprocessing.spawn)": [[2114, "torch.multiprocessing.spawn.spawn"]], "torch.multiprocessing": [[2114, "module-torch.multiprocessing"]], "torch.multiprocessing.pool": [[2114, "module-torch.multiprocessing.pool"]], "torch.multiprocessing.queue": [[2114, "module-torch.multiprocessing.queue"]], "torch.multiprocessing.reductions": [[2114, "module-torch.multiprocessing.reductions"]], "torch.multiprocessing.spawn": [[2114, "module-torch.multiprocessing.spawn"]], "align_as() (torch.tensor method)": [[2116, "torch.Tensor.align_as"]], "align_to() (torch.tensor method)": [[2116, "torch.Tensor.align_to"]], "names (torch.tensor attribute)": [[2116, "torch.Tensor.names"]], "refine_names() (torch.tensor method)": [[2116, "torch.Tensor.refine_names"]], "rename() (torch.tensor method)": [[2116, "torch.Tensor.rename"]], "rename_() (torch.tensor method)": [[2116, "torch.Tensor.rename_"]], "as_nested_tensor() (in module torch.nested)": [[2117, "torch.nested.as_nested_tensor"]], "masked_select() (in module torch.nested)": [[2117, "torch.nested.masked_select"]], "narrow() (in module torch.nested)": [[2117, "torch.nested.narrow"]], "nested_tensor() (in module torch.nested)": [[2117, "torch.nested.nested_tensor"]], "nested_tensor_from_jagged() (in module torch.nested)": [[2117, "torch.nested.nested_tensor_from_jagged"]], "to_padded_tensor() (in module torch.nested)": [[2117, "torch.nested.to_padded_tensor"]], "torch.nested": [[2117, "module-torch.nested"]], "torch.nn": [[2118, "module-torch.nn"]], "torch.nn.backends": [[2118, "module-torch.nn.backends"]], "torch.nn.backends.thnn": [[2118, "module-torch.nn.backends.thnn"]], "torch.nn.common_types": [[2118, "module-torch.nn.common_types"]], "torch.nn.cpp": [[2118, "module-torch.nn.cpp"]], "torch.nn.functional": [[2118, "module-torch.nn.functional"]], "torch.nn.grad": [[2118, "module-torch.nn.grad"]], "torch.nn.init": [[2118, "module-torch.nn.init"]], "torch.nn.modules": [[2118, "module-torch.nn.modules"]], "torch.nn.modules.activation": [[2118, "module-torch.nn.modules.activation"]], "torch.nn.modules.adaptive": [[2118, "module-torch.nn.modules.adaptive"]], "torch.nn.modules.batchnorm": [[2118, "module-torch.nn.modules.batchnorm"]], "torch.nn.modules.channelshuffle": [[2118, "module-torch.nn.modules.channelshuffle"]], "torch.nn.modules.container": [[2118, "module-torch.nn.modules.container"]], "torch.nn.modules.conv": [[2118, "module-torch.nn.modules.conv"]], "torch.nn.modules.distance": [[2118, "module-torch.nn.modules.distance"]], "torch.nn.modules.dropout": [[2118, "module-torch.nn.modules.dropout"]], "torch.nn.modules.flatten": [[2118, "module-torch.nn.modules.flatten"]], "torch.nn.modules.fold": [[2118, "module-torch.nn.modules.fold"]], "torch.nn.modules.instancenorm": [[2118, "module-torch.nn.modules.instancenorm"]], "torch.nn.modules.lazy": [[2118, "module-torch.nn.modules.lazy"]], "torch.nn.modules.linear": [[2118, "module-torch.nn.modules.linear"]], "torch.nn.modules.loss": [[2118, "module-torch.nn.modules.loss"]], "torch.nn.modules.module": [[2118, "module-torch.nn.modules.module"]], "torch.nn.modules.normalization": [[2118, "module-torch.nn.modules.normalization"]], "torch.nn.modules.padding": [[2118, "module-torch.nn.modules.padding"]], "torch.nn.modules.pixelshuffle": [[2118, "module-torch.nn.modules.pixelshuffle"]], "torch.nn.modules.pooling": [[2118, "module-torch.nn.modules.pooling"]], "torch.nn.modules.rnn": [[2118, "module-torch.nn.modules.rnn"]], "torch.nn.modules.sparse": [[2118, "module-torch.nn.modules.sparse"]], "torch.nn.modules.transformer": [[2118, "module-torch.nn.modules.transformer"]], "torch.nn.modules.upsampling": [[2118, "module-torch.nn.modules.upsampling"]], "torch.nn.modules.utils": [[2118, "module-torch.nn.modules.utils"]], "torch.nn.parallel": [[2118, "module-torch.nn.parallel"]], "torch.nn.parallel.comm": [[2118, "module-torch.nn.parallel.comm"]], "torch.nn.parallel.distributed": [[2118, "module-torch.nn.parallel.distributed"]], "torch.nn.parallel.parallel_apply": [[2118, "module-torch.nn.parallel.parallel_apply"]], "torch.nn.parallel.replicate": [[2118, "module-torch.nn.parallel.replicate"]], "torch.nn.parallel.scatter_gather": [[2118, "module-torch.nn.parallel.scatter_gather"]], "torch.nn.parameter": [[2118, "module-torch.nn.parameter"]], "torch.nn.utils": [[2118, "module-torch.nn.utils"]], "torch.nn.utils.clip_grad": [[2118, "module-torch.nn.utils.clip_grad"]], "torch.nn.utils.convert_parameters": [[2118, "module-torch.nn.utils.convert_parameters"]], "torch.nn.utils.fusion": [[2118, "module-torch.nn.utils.fusion"]], "torch.nn.utils.init": [[2118, "module-torch.nn.utils.init"]], "torch.nn.utils.memory_format": [[2118, "module-torch.nn.utils.memory_format"]], "torch.nn.utils.parametrizations": [[2118, "module-torch.nn.utils.parametrizations"]], "torch.nn.utils.parametrize": [[2118, "module-torch.nn.utils.parametrize"]], "torch.nn.utils.prune": [[2118, "module-torch.nn.utils.prune"]], "torch.nn.utils.rnn": [[2118, "module-torch.nn.utils.rnn"]], "torch.nn.utils.stateless": [[2118, "module-torch.nn.utils.stateless"]], "torch.nn.attention": [[2119, "module-torch.nn.attention"]], "torch.nn.attention.bias": [[2120, "module-torch.nn.attention.bias"]], "torch.nn.attention.experimental": [[2121, "module-torch.nn.attention.experimental"]], "block_size (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.BLOCK_SIZE"]], "blockmask (class in torch.nn.attention.flex_attention)": [[2122, "torch.nn.attention.flex_attention.BlockMask"]], "and_masks() (in module torch.nn.attention.flex_attention)": [[2122, "torch.nn.attention.flex_attention.and_masks"]], "as_tuple() (torch.nn.attention.flex_attention.blockmask method)": [[2122, "torch.nn.attention.flex_attention.BlockMask.as_tuple"]], "create_block_mask() (in module torch.nn.attention.flex_attention)": [[2122, "torch.nn.attention.flex_attention.create_block_mask"]], "create_mask() (in module torch.nn.attention.flex_attention)": [[2122, "torch.nn.attention.flex_attention.create_mask"]], "create_nested_block_mask() (in module torch.nn.attention.flex_attention)": [[2122, "torch.nn.attention.flex_attention.create_nested_block_mask"]], "flex_attention() (in module torch.nn.attention.flex_attention)": [[2122, "torch.nn.attention.flex_attention.flex_attention"]], "from_kv_blocks() (torch.nn.attention.flex_attention.blockmask class method)": [[2122, "torch.nn.attention.flex_attention.BlockMask.from_kv_blocks"]], "full_kv_indices (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.full_kv_indices"]], "full_kv_num_blocks (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.full_kv_num_blocks"]], "full_q_indices (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.full_q_indices"]], "full_q_num_blocks (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.full_q_num_blocks"]], "kv_indices (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.kv_indices"]], "kv_num_blocks (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.kv_num_blocks"]], "mask_mod (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.mask_mod"]], "noop_mask() (in module torch.nn.attention.flex_attention)": [[2122, "torch.nn.attention.flex_attention.noop_mask"]], "numel() (torch.nn.attention.flex_attention.blockmask method)": [[2122, "torch.nn.attention.flex_attention.BlockMask.numel"]], "or_masks() (in module torch.nn.attention.flex_attention)": [[2122, "torch.nn.attention.flex_attention.or_masks"]], "q_indices (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.q_indices"]], "q_num_blocks (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.q_num_blocks"]], "seq_lengths (torch.nn.attention.flex_attention.blockmask attribute)": [[2122, "torch.nn.attention.flex_attention.BlockMask.seq_lengths"]], "shape (torch.nn.attention.flex_attention.blockmask property)": [[2122, "torch.nn.attention.flex_attention.BlockMask.shape"]], "sparsity() (torch.nn.attention.flex_attention.blockmask method)": [[2122, "torch.nn.attention.flex_attention.BlockMask.sparsity"]], "to() (torch.nn.attention.flex_attention.blockmask method)": [[2122, "torch.nn.attention.flex_attention.BlockMask.to"]], "to_dense() (torch.nn.attention.flex_attention.blockmask method)": [[2122, "torch.nn.attention.flex_attention.BlockMask.to_dense"]], "to_string() (torch.nn.attention.flex_attention.blockmask method)": [[2122, "torch.nn.attention.flex_attention.BlockMask.to_string"]], "torch.nn.attention.flex_attention": [[2122, "module-torch.nn.attention.flex_attention"]], "calculate_gain() (in module torch.nn.init)": [[2124, "torch.nn.init.calculate_gain"]], "constant_() (in module torch.nn.init)": [[2124, "torch.nn.init.constant_"]], "dirac_() (in module torch.nn.init)": [[2124, "torch.nn.init.dirac_"]], "eye_() (in module torch.nn.init)": [[2124, "torch.nn.init.eye_"]], "kaiming_normal_() (in module torch.nn.init)": [[2124, "torch.nn.init.kaiming_normal_"]], "kaiming_uniform_() (in module torch.nn.init)": [[2124, "torch.nn.init.kaiming_uniform_"]], "normal_() (in module torch.nn.init)": [[2124, "torch.nn.init.normal_"]], "ones_() (in module torch.nn.init)": [[2124, "torch.nn.init.ones_"]], "orthogonal_() (in module torch.nn.init)": [[2124, "torch.nn.init.orthogonal_"]], "sparse_() (in module torch.nn.init)": [[2124, "torch.nn.init.sparse_"]], "trunc_normal_() (in module torch.nn.init)": [[2124, "torch.nn.init.trunc_normal_"]], "uniform_() (in module torch.nn.init)": [[2124, "torch.nn.init.uniform_"]], "xavier_normal_() (in module torch.nn.init)": [[2124, "torch.nn.init.xavier_normal_"]], "xavier_uniform_() (in module torch.nn.init)": [[2124, "torch.nn.init.xavier_uniform_"]], "zeros_() (in module torch.nn.init)": [[2124, "torch.nn.init.zeros_"]], "add_safe_globals() (in module torch.serialization)": [[2147, "torch.serialization.add_safe_globals"]], "clear_safe_globals() (in module torch.serialization)": [[2147, "torch.serialization.clear_safe_globals"]], "get_crc32_options() (in module torch.serialization)": [[2147, "torch.serialization.get_crc32_options"]], "get_default_load_endianness() (in module torch.serialization)": [[2147, "torch.serialization.get_default_load_endianness"]], "get_default_mmap_options() (in module torch.serialization)": [[2147, "torch.serialization.get_default_mmap_options"]], "get_safe_globals() (in module torch.serialization)": [[2147, "torch.serialization.get_safe_globals"]], "get_unsafe_globals_in_checkpoint() (in module torch.serialization)": [[2147, "torch.serialization.get_unsafe_globals_in_checkpoint"]], "register_package() (in module torch.serialization)": [[2147, "torch.serialization.register_package"]], "safe_globals (class in torch.serialization)": [[2147, "torch.serialization.safe_globals"]], "set_crc32_options() (in module torch.serialization)": [[2147, "torch.serialization.set_crc32_options"]], "set_default_load_endianness() (in module torch.serialization)": [[2147, "torch.serialization.set_default_load_endianness"]], "set_default_mmap_options() (in module torch.serialization)": [[2147, "torch.serialization.set_default_mmap_options"]], "skip_data (class in torch.serialization)": [[2147, "torch.serialization.skip_data"]], "torch.utils.serialization": [[2147, "module-torch.utils.serialization"]], "torch.utils.serialization.config": [[2147, "module-torch.utils.serialization.config"]], "torch.onnx.errors": [[2149, "module-torch.onnx.errors"]], "torch.onnx.operators": [[2149, "module-torch.onnx.operators"]], "torch.onnx.symbolic_caffe2": [[2149, "module-torch.onnx.symbolic_caffe2"]], "torch.onnx.symbolic_helper": [[2149, "module-torch.onnx.symbolic_helper"]], "torch.onnx.symbolic_opset10": [[2149, "module-torch.onnx.symbolic_opset10"]], "torch.onnx.symbolic_opset11": [[2149, "module-torch.onnx.symbolic_opset11"]], "torch.onnx.symbolic_opset12": [[2149, "module-torch.onnx.symbolic_opset12"]], "torch.onnx.symbolic_opset13": [[2149, "module-torch.onnx.symbolic_opset13"]], "torch.onnx.symbolic_opset14": [[2149, "module-torch.onnx.symbolic_opset14"]], "torch.onnx.symbolic_opset15": [[2149, "module-torch.onnx.symbolic_opset15"]], "torch.onnx.symbolic_opset16": [[2149, "module-torch.onnx.symbolic_opset16"]], "torch.onnx.symbolic_opset17": [[2149, "module-torch.onnx.symbolic_opset17"]], "torch.onnx.symbolic_opset18": [[2149, "module-torch.onnx.symbolic_opset18"]], "torch.onnx.symbolic_opset19": [[2149, "module-torch.onnx.symbolic_opset19"]], "torch.onnx.symbolic_opset20": [[2149, "module-torch.onnx.symbolic_opset20"]], "torch.onnx.symbolic_opset7": [[2149, "module-torch.onnx.symbolic_opset7"]], "torch.onnx.symbolic_opset8": [[2149, "module-torch.onnx.symbolic_opset8"]], "torch.onnx.symbolic_opset9": [[2149, "module-torch.onnx.symbolic_opset9"]], "torch.onnx.utils": [[2149, "module-torch.onnx.utils"]], "exportoptions (class in torch.onnx)": [[2150, "torch.onnx.ExportOptions"]], "onnxprogram (class in torch.onnx)": [[2150, "torch.onnx.ONNXProgram"]], "onnxexportererror (class in torch.onnx)": [[2150, "torch.onnx.OnnxExporterError"]], "apply_weights() (torch.onnx.onnxprogram method)": [[2150, "torch.onnx.ONNXProgram.apply_weights"]], "dynamo_export() (in module torch.onnx)": [[2150, "torch.onnx.dynamo_export"]], "enable_fake_mode() (in module torch.onnx)": [[2150, "torch.onnx.enable_fake_mode"]], "export() (in module torch.onnx)": [[2150, "torch.onnx.export"]], "initialize_inference_session() (torch.onnx.onnxprogram method)": [[2150, "torch.onnx.ONNXProgram.initialize_inference_session"]], "is_in_onnx_export() (in module torch.onnx)": [[2150, "torch.onnx.is_in_onnx_export"]], "model_proto (torch.onnx.onnxprogram property)": [[2150, "torch.onnx.ONNXProgram.model_proto"]], "optimize() (torch.onnx.onnxprogram method)": [[2150, "torch.onnx.ONNXProgram.optimize"]], "release() (torch.onnx.onnxprogram method)": [[2150, "torch.onnx.ONNXProgram.release"]], "save() (torch.onnx.onnxprogram method)": [[2150, "torch.onnx.ONNXProgram.save"]], "is_onnxrt_backend_supported() (in module torch.onnx)": [[2152, "torch.onnx.is_onnxrt_backend_supported"]], "register_custom_op_symbolic() (in module torch.onnx)": [[2154, "torch.onnx.register_custom_op_symbolic"]], "select_model_mode_for_export() (in module torch.onnx)": [[2154, "torch.onnx.select_model_mode_for_export"]], "torch.onnx": [[2154, "module-torch.onnx"]], "unregister_custom_op_symbolic() (in module torch.onnx)": [[2154, "torch.onnx.unregister_custom_op_symbolic"]], "graphinfoprettyprinter (class in torch.onnx.verification)": [[2156, "torch.onnx.verification.GraphInfoPrettyPrinter"]], "onnxbackend (class in torch.onnx.verification)": [[2156, "torch.onnx.verification.OnnxBackend"]], "onnxtestcaserepro (class in torch.onnx.verification)": [[2156, "torch.onnx.verification.OnnxTestCaseRepro"]], "check_export_model_diff (class in torch.onnx.verification)": [[2156, "torch.onnx.verification.check_export_model_diff"]], "find_mismatch() (in module torch.onnx.verification)": [[2156, "torch.onnx.verification.find_mismatch"]], "torch.onnx.verification": [[2156, "module-torch.onnx.verification"]], "verify() (in module torch.onnx.verification)": [[2156, "torch.onnx.verification.verify"]], "verify_aten_graph() (in module torch.onnx.verification)": [[2156, "torch.onnx.verification.verify_aten_graph"]], "optimizer (class in torch.optim)": [[2157, "torch.optim.Optimizer"]], "get_ema_multi_avg_fn() (in module torch.optim.swa_utils)": [[2157, "torch.optim.swa_utils.get_ema_multi_avg_fn"]], "torch.optim": [[2157, "module-torch.optim"]], "torch.optim.adadelta": [[2157, "module-torch.optim.adadelta"]], "torch.optim.adagrad": [[2157, "module-torch.optim.adagrad"]], "torch.optim.adam": [[2157, "module-torch.optim.adam"]], "torch.optim.adamax": [[2157, "module-torch.optim.adamax"]], "torch.optim.adamw": [[2157, "module-torch.optim.adamw"]], "torch.optim.asgd": [[2157, "module-torch.optim.asgd"]], "torch.optim.lbfgs": [[2157, "module-torch.optim.lbfgs"]], "torch.optim.lr_scheduler": [[2157, "module-torch.optim.lr_scheduler"]], "torch.optim.nadam": [[2157, "module-torch.optim.nadam"]], "torch.optim.optimizer": [[2157, "module-torch.optim.optimizer"]], "torch.optim.radam": [[2157, "module-torch.optim.radam"]], "torch.optim.rmsprop": [[2157, "module-torch.optim.rmsprop"]], "torch.optim.rprop": [[2157, "module-torch.optim.rprop"]], "torch.optim.sgd": [[2157, "module-torch.optim.sgd"]], "torch.optim.sparse_adam": [[2157, "module-torch.optim.sparse_adam"]], "torch.optim.swa_utils": [[2157, "module-torch.optim.swa_utils"]], "update_bn() (in module torch.optim.swa_utils)": [[2157, "torch.optim.swa_utils.update_bn"]], "directory (class in torch.package)": [[2158, "torch.package.Directory"]], "emptymatcherror (class in torch.package)": [[2158, "torch.package.EmptyMatchError"]], "packageexporter (class in torch.package)": [[2158, "torch.package.PackageExporter"]], "packageimporter (class in torch.package)": [[2158, "torch.package.PackageImporter"]], "packagingerror (class in torch.package)": [[2158, "torch.package.PackagingError"]], "__init__() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.__init__"]], "__init__() (torch.package.packageimporter method)": [[2158, "torch.package.PackageImporter.__init__"]], "add_dependency() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.add_dependency"]], "all_paths() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.all_paths"]], "close() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.close"]], "denied_modules() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.denied_modules"]], "deny() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.deny"]], "dependency_graph_string() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.dependency_graph_string"]], "extern() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.extern"]], "externed_modules() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.externed_modules"]], "file_structure() (torch.package.packageimporter method)": [[2158, "torch.package.PackageImporter.file_structure"]], "get_rdeps() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.get_rdeps"]], "get_unique_id() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.get_unique_id"]], "has_file() (torch.package.directory method)": [[2158, "torch.package.Directory.has_file"]], "id() (torch.package.packageimporter method)": [[2158, "torch.package.PackageImporter.id"]], "import_module() (torch.package.packageimporter method)": [[2158, "torch.package.PackageImporter.import_module"]], "intern() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.intern"]], "interned_modules() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.interned_modules"]], "load_binary() (torch.package.packageimporter method)": [[2158, "torch.package.PackageImporter.load_binary"]], "load_pickle() (torch.package.packageimporter method)": [[2158, "torch.package.PackageImporter.load_pickle"]], "load_text() (torch.package.packageimporter method)": [[2158, "torch.package.PackageImporter.load_text"]], "mock() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.mock"]], "mocked_modules() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.mocked_modules"]], "python_version() (torch.package.packageimporter method)": [[2158, "torch.package.PackageImporter.python_version"]], "register_extern_hook() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.register_extern_hook"]], "register_intern_hook() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.register_intern_hook"]], "register_mock_hook() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.register_mock_hook"]], "save_binary() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.save_binary"]], "save_module() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.save_module"]], "save_pickle() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.save_pickle"]], "save_source_file() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.save_source_file"]], "save_source_string() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.save_source_string"]], "save_text() (torch.package.packageexporter method)": [[2158, "torch.package.PackageExporter.save_text"]], "torch.package": [[2158, "module-torch.package"]], "torch.package.analyze": [[2158, "module-torch.package.analyze"]], "torch.package.analyze.find_first_use_of_broken_modules": [[2158, "module-torch.package.analyze.find_first_use_of_broken_modules"]], "torch.package.analyze.is_from_package": [[2158, "module-torch.package.analyze.is_from_package"]], "torch.package.analyze.trace_dependencies": [[2158, "module-torch.package.analyze.trace_dependencies"]], "torch.package.file_structure_representation": [[2158, "module-torch.package.file_structure_representation"]], "torch.package.find_file_dependencies": [[2158, "module-torch.package.find_file_dependencies"]], "torch.package.glob_group": [[2158, "module-torch.package.glob_group"]], "torch.package.importer": [[2158, "module-torch.package.importer"]], "torch.package.package_exporter": [[2158, "module-torch.package.package_exporter"]], "torch.package.package_importer": [[2158, "module-torch.package.package_importer"]], "profileraction (class in torch.profiler)": [[2159, "torch.profiler.ProfilerAction"]], "profileractivity (class in torch.profiler)": [[2159, "torch.profiler.ProfilerActivity"]], "_kinetoprofile (class in torch.profiler)": [[2159, "torch.profiler._KinetoProfile"]], "add_metadata() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.add_metadata"]], "add_metadata_json() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.add_metadata_json"]], "events() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.events"]], "export_chrome_trace() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.export_chrome_trace"]], "export_memory_timeline() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.export_memory_timeline"]], "export_stacks() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.export_stacks"]], "get_trace_id() (torch.profiler.profile method)": [[2159, "torch.profiler.profile.get_trace_id"]], "is_available() (in module torch.profiler.itt)": [[2159, "torch.profiler.itt.is_available"]], "key_averages() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.key_averages"]], "mark() (in module torch.profiler.itt)": [[2159, "torch.profiler.itt.mark"]], "name (torch.profiler.profileractivity property)": [[2159, "torch.profiler.ProfilerActivity.name"]], "preset_metadata_json() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.preset_metadata_json"]], "profile (class in torch.profiler)": [[2159, "torch.profiler.profile"]], "range_pop() (in module torch.profiler.itt)": [[2159, "torch.profiler.itt.range_pop"]], "range_push() (in module torch.profiler.itt)": [[2159, "torch.profiler.itt.range_push"]], "schedule() (in module torch.profiler)": [[2159, "torch.profiler.schedule"]], "set_custom_trace_id_callback() (torch.profiler.profile method)": [[2159, "torch.profiler.profile.set_custom_trace_id_callback"]], "step() (torch.profiler.profile method)": [[2159, "torch.profiler.profile.step"]], "tensorboard_trace_handler() (in module torch.profiler)": [[2159, "torch.profiler.tensorboard_trace_handler"]], "toggle_collection_dynamic() (torch.profiler._kinetoprofile method)": [[2159, "torch.profiler._KinetoProfile.toggle_collection_dynamic"]], "torch.profiler": [[2159, "module-torch.profiler"]], "torch.profiler.itt": [[2159, "module-torch.profiler.itt"]], "torch.profiler.profiler": [[2159, "module-torch.profiler.profiler"]], "torch.profiler.python_tracer": [[2159, "module-torch.profiler.python_tracer"]], "torch.ao": [[2161, "module-torch.ao"]], "torch.ao.nn": [[2161, "module-torch.ao.nn"]], "torch.ao.nn.intrinsic.modules.fused": [[2161, "module-torch.ao.nn.intrinsic.modules.fused"]], "torch.ao.nn.intrinsic.qat.modules.conv_fused": [[2161, "module-torch.ao.nn.intrinsic.qat.modules.conv_fused"]], "torch.ao.nn.intrinsic.qat.modules.linear_fused": [[2161, "module-torch.ao.nn.intrinsic.qat.modules.linear_fused"]], "torch.ao.nn.intrinsic.qat.modules.linear_relu": [[2161, "module-torch.ao.nn.intrinsic.qat.modules.linear_relu"]], "torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu": [[2161, "module-torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu"]], "torch.ao.nn.intrinsic.quantized.modules.bn_relu": [[2161, "module-torch.ao.nn.intrinsic.quantized.modules.bn_relu"]], "torch.ao.nn.intrinsic.quantized.modules.conv_add": [[2161, "module-torch.ao.nn.intrinsic.quantized.modules.conv_add"]], "torch.ao.nn.intrinsic.quantized.modules.conv_relu": [[2161, "module-torch.ao.nn.intrinsic.quantized.modules.conv_relu"]], "torch.ao.nn.intrinsic.quantized.modules.linear_relu": [[2161, "module-torch.ao.nn.intrinsic.quantized.modules.linear_relu"]], "torch.ao.nn.qat.dynamic.modules.linear": [[2161, "module-torch.ao.nn.qat.dynamic.modules.linear"]], "torch.ao.nn.qat.modules.conv": [[2161, "module-torch.ao.nn.qat.modules.conv"]], "torch.ao.nn.qat.modules.embedding_ops": [[2161, "module-torch.ao.nn.qat.modules.embedding_ops"]], "torch.ao.nn.qat.modules.linear": [[2161, "module-torch.ao.nn.qat.modules.linear"]], "torch.ao.nn.quantizable": [[2161, "module-torch.ao.nn.quantizable"]], "torch.ao.nn.quantizable.modules": [[2161, "module-torch.ao.nn.quantizable.modules"]], "torch.ao.nn.quantizable.modules.activation": [[2161, "module-torch.ao.nn.quantizable.modules.activation"]], "torch.ao.nn.quantizable.modules.rnn": [[2161, "module-torch.ao.nn.quantizable.modules.rnn"]], "torch.ao.nn.quantized": [[2161, "module-torch.ao.nn.quantized"]], "torch.ao.nn.quantized.dynamic.modules.conv": [[2161, "module-torch.ao.nn.quantized.dynamic.modules.conv"]], "torch.ao.nn.quantized.dynamic.modules.linear": [[2161, "module-torch.ao.nn.quantized.dynamic.modules.linear"]], "torch.ao.nn.quantized.dynamic.modules.rnn": [[2161, "module-torch.ao.nn.quantized.dynamic.modules.rnn"]], "torch.ao.nn.quantized.modules.activation": [[2161, "module-torch.ao.nn.quantized.modules.activation"]], "torch.ao.nn.quantized.modules.batchnorm": [[2161, "module-torch.ao.nn.quantized.modules.batchnorm"]], "torch.ao.nn.quantized.modules.conv": [[2161, "module-torch.ao.nn.quantized.modules.conv"]], "torch.ao.nn.quantized.modules.dropout": [[2161, "module-torch.ao.nn.quantized.modules.dropout"]], "torch.ao.nn.quantized.modules.embedding_ops": [[2161, "module-torch.ao.nn.quantized.modules.embedding_ops"]], "torch.ao.nn.quantized.modules.functional_modules": [[2161, "module-torch.ao.nn.quantized.modules.functional_modules"]], "torch.ao.nn.quantized.modules.linear": [[2161, "module-torch.ao.nn.quantized.modules.linear"]], "torch.ao.nn.quantized.modules.normalization": [[2161, "module-torch.ao.nn.quantized.modules.normalization"]], "torch.ao.nn.quantized.modules.rnn": [[2161, "module-torch.ao.nn.quantized.modules.rnn"]], "torch.ao.nn.quantized.modules.utils": [[2161, "module-torch.ao.nn.quantized.modules.utils"]], "torch.ao.nn.quantized.reference": [[2161, "module-torch.ao.nn.quantized.reference"]], "torch.ao.nn.quantized.reference.modules": [[2161, "module-torch.ao.nn.quantized.reference.modules"]], "torch.ao.nn.quantized.reference.modules.conv": [[2161, "module-torch.ao.nn.quantized.reference.modules.conv"]], "torch.ao.nn.quantized.reference.modules.linear": [[2161, "module-torch.ao.nn.quantized.reference.modules.linear"]], "torch.ao.nn.quantized.reference.modules.rnn": [[2161, "module-torch.ao.nn.quantized.reference.modules.rnn"]], "torch.ao.nn.quantized.reference.modules.sparse": [[2161, "module-torch.ao.nn.quantized.reference.modules.sparse"]], "torch.ao.nn.quantized.reference.modules.utils": [[2161, "module-torch.ao.nn.quantized.reference.modules.utils"]], "torch.ao.nn.sparse": [[2161, "module-torch.ao.nn.sparse"]], "torch.ao.nn.sparse.quantized": [[2161, "module-torch.ao.nn.sparse.quantized"]], "torch.ao.nn.sparse.quantized.dynamic": [[2161, "module-torch.ao.nn.sparse.quantized.dynamic"]], "torch.ao.nn.sparse.quantized.dynamic.linear": [[2161, "module-torch.ao.nn.sparse.quantized.dynamic.linear"]], "torch.ao.nn.sparse.quantized.linear": [[2161, "module-torch.ao.nn.sparse.quantized.linear"]], "torch.ao.nn.sparse.quantized.utils": [[2161, "module-torch.ao.nn.sparse.quantized.utils"]], "torch.ao.ns": [[2161, "module-torch.ao.ns"]], "torch.ao.ns.fx": [[2161, "module-torch.ao.ns.fx"]], "torch.ao.ns.fx.graph_matcher": [[2161, "module-torch.ao.ns.fx.graph_matcher"]], "torch.ao.ns.fx.graph_passes": [[2161, "module-torch.ao.ns.fx.graph_passes"]], "torch.ao.ns.fx.mappings": [[2161, "module-torch.ao.ns.fx.mappings"]], "torch.ao.ns.fx.n_shadows_utils": [[2161, "module-torch.ao.ns.fx.n_shadows_utils"]], "torch.ao.ns.fx.ns_types": [[2161, "module-torch.ao.ns.fx.ns_types"]], "torch.ao.ns.fx.pattern_utils": [[2161, "module-torch.ao.ns.fx.pattern_utils"]], "torch.ao.ns.fx.qconfig_multi_mapping": [[2161, "module-torch.ao.ns.fx.qconfig_multi_mapping"]], "torch.ao.ns.fx.utils": [[2161, "module-torch.ao.ns.fx.utils"]], "torch.ao.ns.fx.weight_utils": [[2161, "module-torch.ao.ns.fx.weight_utils"]], "torch.ao.pruning": [[2161, "module-torch.ao.pruning"]], "torch.ao.pruning.scheduler": [[2161, "module-torch.ao.pruning.scheduler"]], "torch.ao.pruning.scheduler.base_scheduler": [[2161, "module-torch.ao.pruning.scheduler.base_scheduler"]], "torch.ao.pruning.scheduler.cubic_scheduler": [[2161, "module-torch.ao.pruning.scheduler.cubic_scheduler"]], "torch.ao.pruning.scheduler.lambda_scheduler": [[2161, "module-torch.ao.pruning.scheduler.lambda_scheduler"]], "torch.ao.pruning.sparsifier": [[2161, "module-torch.ao.pruning.sparsifier"]], "torch.ao.pruning.sparsifier.base_sparsifier": [[2161, "module-torch.ao.pruning.sparsifier.base_sparsifier"]], "torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier": [[2161, "module-torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier"]], "torch.ao.pruning.sparsifier.utils": [[2161, "module-torch.ao.pruning.sparsifier.utils"]], "torch.ao.pruning.sparsifier.weight_norm_sparsifier": [[2161, "module-torch.ao.pruning.sparsifier.weight_norm_sparsifier"]], "torch.ao.quantization": [[2161, "module-torch.ao.quantization"]], "torch.ao.quantization.backend_config": [[2161, "module-torch.ao.quantization.backend_config"]], "torch.ao.quantization.backend_config.backend_config": [[2161, "module-torch.ao.quantization.backend_config.backend_config"]], "torch.ao.quantization.backend_config.executorch": [[2161, "module-torch.ao.quantization.backend_config.executorch"]], "torch.ao.quantization.backend_config.fbgemm": [[2161, "module-torch.ao.quantization.backend_config.fbgemm"]], "torch.ao.quantization.backend_config.native": [[2161, "module-torch.ao.quantization.backend_config.native"]], "torch.ao.quantization.backend_config.observation_type": [[2161, "module-torch.ao.quantization.backend_config.observation_type"]], "torch.ao.quantization.backend_config.onednn": [[2161, "module-torch.ao.quantization.backend_config.onednn"]], "torch.ao.quantization.backend_config.qnnpack": [[2161, "module-torch.ao.quantization.backend_config.qnnpack"]], "torch.ao.quantization.backend_config.tensorrt": [[2161, "module-torch.ao.quantization.backend_config.tensorrt"]], "torch.ao.quantization.backend_config.utils": [[2161, "module-torch.ao.quantization.backend_config.utils"]], "torch.ao.quantization.backend_config.x86": [[2161, "module-torch.ao.quantization.backend_config.x86"]], "torch.ao.quantization.fake_quantize": [[2161, "module-torch.ao.quantization.fake_quantize"]], "torch.ao.quantization.fuse_modules": [[2161, "module-torch.ao.quantization.fuse_modules"]], "torch.ao.quantization.fuser_method_mappings": [[2161, "module-torch.ao.quantization.fuser_method_mappings"]], "torch.ao.quantization.fx": [[2161, "module-torch.ao.quantization.fx"]], "torch.ao.quantization.fx.convert": [[2161, "module-torch.ao.quantization.fx.convert"]], "torch.ao.quantization.fx.custom_config": [[2161, "module-torch.ao.quantization.fx.custom_config"]], "torch.ao.quantization.fx.fuse": [[2161, "module-torch.ao.quantization.fx.fuse"]], "torch.ao.quantization.fx.fuse_handler": [[2161, "module-torch.ao.quantization.fx.fuse_handler"]], "torch.ao.quantization.fx.graph_module": [[2161, "module-torch.ao.quantization.fx.graph_module"]], "torch.ao.quantization.fx.lower_to_fbgemm": [[2161, "module-torch.ao.quantization.fx.lower_to_fbgemm"]], "torch.ao.quantization.fx.lower_to_qnnpack": [[2161, "module-torch.ao.quantization.fx.lower_to_qnnpack"]], "torch.ao.quantization.fx.lstm_utils": [[2161, "module-torch.ao.quantization.fx.lstm_utils"]], "torch.ao.quantization.fx.match_utils": [[2161, "module-torch.ao.quantization.fx.match_utils"]], "torch.ao.quantization.fx.pattern_utils": [[2161, "module-torch.ao.quantization.fx.pattern_utils"]], "torch.ao.quantization.fx.prepare": [[2161, "module-torch.ao.quantization.fx.prepare"]], "torch.ao.quantization.fx.qconfig_mapping_utils": [[2161, "module-torch.ao.quantization.fx.qconfig_mapping_utils"]], "torch.ao.quantization.fx.quantize_handler": [[2161, "module-torch.ao.quantization.fx.quantize_handler"]], "torch.ao.quantization.fx.tracer": [[2161, "module-torch.ao.quantization.fx.tracer"]], "torch.ao.quantization.fx.utils": [[2161, "module-torch.ao.quantization.fx.utils"]], "torch.ao.quantization.observer": [[2161, "module-torch.ao.quantization.observer"]], "torch.ao.quantization.pt2e.duplicate_dq_pass": [[2161, "module-torch.ao.quantization.pt2e.duplicate_dq_pass"]], "torch.ao.quantization.pt2e.export_utils": [[2161, "module-torch.ao.quantization.pt2e.export_utils"]], "torch.ao.quantization.pt2e.graph_utils": [[2161, "module-torch.ao.quantization.pt2e.graph_utils"]], "torch.ao.quantization.pt2e.port_metadata_pass": [[2161, "module-torch.ao.quantization.pt2e.port_metadata_pass"]], "torch.ao.quantization.pt2e.prepare": [[2161, "module-torch.ao.quantization.pt2e.prepare"]], "torch.ao.quantization.pt2e.qat_utils": [[2161, "module-torch.ao.quantization.pt2e.qat_utils"]], "torch.ao.quantization.pt2e.representation.rewrite": [[2161, "module-torch.ao.quantization.pt2e.representation.rewrite"]], "torch.ao.quantization.pt2e.utils": [[2161, "module-torch.ao.quantization.pt2e.utils"]], "torch.ao.quantization.qconfig": [[2161, "module-torch.ao.quantization.qconfig"]], "torch.ao.quantization.qconfig_mapping": [[2161, "module-torch.ao.quantization.qconfig_mapping"]], "torch.ao.quantization.quant_type": [[2161, "module-torch.ao.quantization.quant_type"]], "torch.ao.quantization.quantization_mappings": [[2161, "module-torch.ao.quantization.quantization_mappings"]], "torch.ao.quantization.quantize_fx": [[2161, "module-torch.ao.quantization.quantize_fx"]], "torch.ao.quantization.quantize_jit": [[2161, "module-torch.ao.quantization.quantize_jit"]], "torch.ao.quantization.quantize_pt2e": [[2161, "module-torch.ao.quantization.quantize_pt2e"]], "torch.ao.quantization.quantizer.composable_quantizer": [[2161, "module-torch.ao.quantization.quantizer.composable_quantizer"]], "torch.ao.quantization.quantizer.embedding_quantizer": [[2161, "module-torch.ao.quantization.quantizer.embedding_quantizer"]], "torch.ao.quantization.quantizer.quantizer": [[2161, "module-torch.ao.quantization.quantizer.quantizer"]], "torch.ao.quantization.quantizer.utils": [[2161, "module-torch.ao.quantization.quantizer.utils"]], "torch.ao.quantization.quantizer.x86_inductor_quantizer": [[2161, "module-torch.ao.quantization.quantizer.x86_inductor_quantizer"]], "torch.ao.quantization.quantizer.xnnpack_quantizer": [[2161, "module-torch.ao.quantization.quantizer.xnnpack_quantizer"]], "torch.ao.quantization.quantizer.xnnpack_quantizer_utils": [[2161, "module-torch.ao.quantization.quantizer.xnnpack_quantizer_utils"]], "torch.ao.quantization.quantizer.xpu_inductor_quantizer": [[2161, "module-torch.ao.quantization.quantizer.xpu_inductor_quantizer"]], "torch.ao.quantization.stubs": [[2161, "module-torch.ao.quantization.stubs"]], "torch.ao.quantization.utils": [[2161, "module-torch.ao.quantization.utils"]], "torch.nn.intrinsic.modules.fused": [[2161, "module-torch.nn.intrinsic.modules.fused"]], "torch.nn.intrinsic.qat.modules.conv_fused": [[2161, "module-torch.nn.intrinsic.qat.modules.conv_fused"]], "torch.nn.intrinsic.qat.modules.linear_fused": [[2161, "module-torch.nn.intrinsic.qat.modules.linear_fused"]], "torch.nn.intrinsic.qat.modules.linear_relu": [[2161, "module-torch.nn.intrinsic.qat.modules.linear_relu"]], "torch.nn.intrinsic.quantized.dynamic.modules.linear_relu": [[2161, "module-torch.nn.intrinsic.quantized.dynamic.modules.linear_relu"]], "torch.nn.intrinsic.quantized.modules.bn_relu": [[2161, "module-torch.nn.intrinsic.quantized.modules.bn_relu"]], "torch.nn.intrinsic.quantized.modules.conv_relu": [[2161, "module-torch.nn.intrinsic.quantized.modules.conv_relu"]], "torch.nn.intrinsic.quantized.modules.linear_relu": [[2161, "module-torch.nn.intrinsic.quantized.modules.linear_relu"]], "torch.nn.qat.dynamic.modules.linear": [[2161, "module-torch.nn.qat.dynamic.modules.linear"]], "torch.nn.qat.modules.conv": [[2161, "module-torch.nn.qat.modules.conv"]], "torch.nn.qat.modules.embedding_ops": [[2161, "module-torch.nn.qat.modules.embedding_ops"]], "torch.nn.qat.modules.linear": [[2161, "module-torch.nn.qat.modules.linear"]], "torch.nn.quantizable.modules.activation": [[2161, "module-torch.nn.quantizable.modules.activation"]], "torch.nn.quantizable.modules.rnn": [[2161, "module-torch.nn.quantizable.modules.rnn"]], "torch.nn.quantized.dynamic.modules.conv": [[2161, "module-torch.nn.quantized.dynamic.modules.conv"]], "torch.nn.quantized.dynamic.modules.linear": [[2161, "module-torch.nn.quantized.dynamic.modules.linear"]], "torch.nn.quantized.dynamic.modules.rnn": [[2161, "module-torch.nn.quantized.dynamic.modules.rnn"]], "torch.nn.quantized.functional": [[2161, "module-torch.nn.quantized.functional"]], "torch.nn.quantized.modules.activation": [[2161, "module-torch.nn.quantized.modules.activation"]], "torch.nn.quantized.modules.batchnorm": [[2161, "module-torch.nn.quantized.modules.batchnorm"]], "torch.nn.quantized.modules.conv": [[2161, "module-torch.nn.quantized.modules.conv"]], "torch.nn.quantized.modules.dropout": [[2161, "module-torch.nn.quantized.modules.dropout"]], "torch.nn.quantized.modules.embedding_ops": [[2161, "module-torch.nn.quantized.modules.embedding_ops"]], "torch.nn.quantized.modules.functional_modules": [[2161, "module-torch.nn.quantized.modules.functional_modules"]], "torch.nn.quantized.modules.linear": [[2161, "module-torch.nn.quantized.modules.linear"]], "torch.nn.quantized.modules.normalization": [[2161, "module-torch.nn.quantized.modules.normalization"]], "torch.nn.quantized.modules.rnn": [[2161, "module-torch.nn.quantized.modules.rnn"]], "torch.nn.quantized.modules.utils": [[2161, "module-torch.nn.quantized.modules.utils"]], "torch.quantization.fake_quantize": [[2161, "module-torch.quantization.fake_quantize"]], "torch.quantization.fuse_modules": [[2161, "module-torch.quantization.fuse_modules"]], "torch.quantization.fuser_method_mappings": [[2161, "module-torch.quantization.fuser_method_mappings"]], "torch.quantization.fx.convert": [[2161, "module-torch.quantization.fx.convert"]], "torch.quantization.fx.fuse": [[2161, "module-torch.quantization.fx.fuse"]], "torch.quantization.fx.fusion_patterns": [[2161, "module-torch.quantization.fx.fusion_patterns"]], "torch.quantization.fx.graph_module": [[2161, "module-torch.quantization.fx.graph_module"]], "torch.quantization.fx.match_utils": [[2161, "module-torch.quantization.fx.match_utils"]], "torch.quantization.fx.pattern_utils": [[2161, "module-torch.quantization.fx.pattern_utils"]], "torch.quantization.fx.prepare": [[2161, "module-torch.quantization.fx.prepare"]], "torch.quantization.fx.quantization_patterns": [[2161, "module-torch.quantization.fx.quantization_patterns"]], "torch.quantization.fx.quantization_types": [[2161, "module-torch.quantization.fx.quantization_types"]], "torch.quantization.fx.utils": [[2161, "module-torch.quantization.fx.utils"]], "torch.quantization.observer": [[2161, "module-torch.quantization.observer"]], "torch.quantization.qconfig": [[2161, "module-torch.quantization.qconfig"]], "torch.quantization.quant_type": [[2161, "module-torch.quantization.quant_type"]], "torch.quantization.quantization_mappings": [[2161, "module-torch.quantization.quantization_mappings"]], "torch.quantization.quantize": [[2161, "module-torch.quantization.quantize"]], "torch.quantization.quantize_fx": [[2161, "module-torch.quantization.quantize_fx"]], "torch.quantization.quantize_jit": [[2161, "module-torch.quantization.quantize_jit"]], "torch.quantization.stubs": [[2161, "module-torch.quantization.stubs"]], "torch.quantization.utils": [[2161, "module-torch.quantization.utils"]], "torch.ao.nn.intrinsic": [[2164, "module-torch.ao.nn.intrinsic"]], "torch.ao.nn.intrinsic.modules": [[2164, "module-torch.ao.nn.intrinsic.modules"]], "torch.ao.nn.intrinsic.qat": [[2164, "module-torch.ao.nn.intrinsic.qat"]], "torch.ao.nn.intrinsic.qat.modules": [[2164, "module-torch.ao.nn.intrinsic.qat.modules"]], "torch.ao.nn.intrinsic.quantized": [[2164, "module-torch.ao.nn.intrinsic.quantized"]], "torch.ao.nn.intrinsic.quantized.dynamic": [[2164, "module-torch.ao.nn.intrinsic.quantized.dynamic"]], "torch.ao.nn.intrinsic.quantized.dynamic.modules": [[2164, "module-torch.ao.nn.intrinsic.quantized.dynamic.modules"]], "torch.ao.nn.intrinsic.quantized.modules": [[2164, "module-torch.ao.nn.intrinsic.quantized.modules"]], "torch.ao.nn.qat": [[2164, "module-torch.ao.nn.qat"]], "torch.ao.nn.qat.dynamic": [[2164, "module-torch.ao.nn.qat.dynamic"]], "torch.ao.nn.qat.dynamic.modules": [[2164, "module-torch.ao.nn.qat.dynamic.modules"]], "torch.ao.nn.qat.modules": [[2164, "module-torch.ao.nn.qat.modules"]], "torch.ao.nn.quantized.dynamic": [[2164, "module-torch.ao.nn.quantized.dynamic"]], "torch.ao.nn.quantized.dynamic.modules": [[2164, "module-torch.ao.nn.quantized.dynamic.modules"]], "torch.ao.nn.quantized.functional": [[2164, "module-torch.ao.nn.quantized.functional"]], "torch.ao.nn.quantized.modules": [[2164, "module-torch.ao.nn.quantized.modules"]], "torch.ao.quantization.pt2e": [[2164, "module-torch.ao.quantization.pt2e"]], "torch.ao.quantization.pt2e.representation": [[2164, "module-torch.ao.quantization.pt2e.representation"]], "torch.ao.quantization.quantizer": [[2164, "module-torch.ao.quantization.quantizer"]], "torch.nn.intrinsic": [[2164, "module-torch.nn.intrinsic"]], "torch.nn.intrinsic.modules": [[2164, "module-torch.nn.intrinsic.modules"]], "torch.nn.intrinsic.qat": [[2164, "module-torch.nn.intrinsic.qat"]], "torch.nn.intrinsic.qat.modules": [[2164, "module-torch.nn.intrinsic.qat.modules"]], "torch.nn.intrinsic.quantized": [[2164, "module-torch.nn.intrinsic.quantized"]], "torch.nn.intrinsic.quantized.dynamic": [[2164, "module-torch.nn.intrinsic.quantized.dynamic"]], "torch.nn.intrinsic.quantized.dynamic.modules": [[2164, "module-torch.nn.intrinsic.quantized.dynamic.modules"]], "torch.nn.intrinsic.quantized.modules": [[2164, "module-torch.nn.intrinsic.quantized.modules"]], "torch.nn.qat": [[2164, "module-torch.nn.qat"]], "torch.nn.qat.dynamic": [[2164, "module-torch.nn.qat.dynamic"]], "torch.nn.qat.dynamic.modules": [[2164, "module-torch.nn.qat.dynamic.modules"]], "torch.nn.qat.modules": [[2164, "module-torch.nn.qat.modules"]], "torch.nn.quantizable": [[2164, "module-torch.nn.quantizable"]], "torch.nn.quantizable.modules": [[2164, "module-torch.nn.quantizable.modules"]], "torch.nn.quantized": [[2164, "module-torch.nn.quantized"]], "torch.nn.quantized.dynamic": [[2164, "module-torch.nn.quantized.dynamic"]], "torch.nn.quantized.dynamic.modules": [[2164, "module-torch.nn.quantized.dynamic.modules"]], "torch.nn.quantized.modules": [[2164, "module-torch.nn.quantized.modules"]], "torch.quantization": [[2164, "module-torch.quantization"]], "torch.quantization.fx": [[2164, "module-torch.quantization.fx"]], "fork_rng() (in module torch.random)": [[2165, "torch.random.fork_rng"]], "get_rng_state() (in module torch.random)": [[2165, "torch.random.get_rng_state"]], "initial_seed() (in module torch.random)": [[2165, "torch.random.initial_seed"]], "manual_seed() (in module torch.random)": [[2165, "torch.random.manual_seed"]], "seed() (in module torch.random)": [[2165, "torch.random.seed"]], "set_rng_state() (in module torch.random)": [[2165, "torch.random.set_rng_state"]], "torch.random": [[2165, "module-torch.random"]], "backendtype (class in torch.distributed.rpc)": [[2166, "torch.distributed.rpc.BackendType"]], "pyrref (class in torch.distributed.rpc)": [[2166, "torch.distributed.rpc.PyRRef"]], "remotemodule (class in torch.distributed.nn.api.remote_module)": [[2166, "torch.distributed.nn.api.remote_module.RemoteModule"]], "rpcbackendoptions (class in torch.distributed.rpc)": [[2166, "torch.distributed.rpc.RpcBackendOptions"]], "tensorpiperpcbackendoptions (class in torch.distributed.rpc)": [[2166, "torch.distributed.rpc.TensorPipeRpcBackendOptions"]], "workerinfo (class in torch.distributed.rpc)": [[2166, "torch.distributed.rpc.WorkerInfo"]], "async_execution() (in module torch.distributed.rpc.functions)": [[2166, "torch.distributed.rpc.functions.async_execution"]], "backward() (in module torch.distributed.autograd)": [[2166, "torch.distributed.autograd.backward"]], "backward() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.backward"]], "confirmed_by_owner() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.confirmed_by_owner"]], "context (class in torch.distributed.autograd)": [[2166, "torch.distributed.autograd.context"]], "device_maps (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[2166, "torch.distributed.rpc.TensorPipeRpcBackendOptions.device_maps"]], "devices (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[2166, "torch.distributed.rpc.TensorPipeRpcBackendOptions.devices"]], "get_gradients() (in module torch.distributed.autograd)": [[2166, "torch.distributed.autograd.get_gradients"]], "get_module_rref() (torch.distributed.nn.api.remote_module.remotemodule method)": [[2166, "torch.distributed.nn.api.remote_module.RemoteModule.get_module_rref"]], "get_worker_info() (in module torch.distributed.rpc)": [[2166, "torch.distributed.rpc.get_worker_info"]], "id (torch.distributed.rpc.workerinfo property)": [[2166, "torch.distributed.rpc.WorkerInfo.id"]], "init_method (torch.distributed.rpc.rpcbackendoptions property)": [[2166, "torch.distributed.rpc.RpcBackendOptions.init_method"]], "init_method (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[2166, "torch.distributed.rpc.TensorPipeRpcBackendOptions.init_method"]], "init_rpc() (in module torch.distributed.rpc)": [[2166, "torch.distributed.rpc.init_rpc"]], "is_owner() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.is_owner"]], "local_value() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.local_value"]], "name (torch.distributed.rpc.workerinfo property)": [[2166, "torch.distributed.rpc.WorkerInfo.name"]], "num_worker_threads (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[2166, "torch.distributed.rpc.TensorPipeRpcBackendOptions.num_worker_threads"]], "owner() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.owner"]], "owner_name() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.owner_name"]], "remote() (in module torch.distributed.rpc)": [[2166, "torch.distributed.rpc.remote"]], "remote() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.remote"]], "remote_parameters() (torch.distributed.nn.api.remote_module.remotemodule method)": [[2166, "torch.distributed.nn.api.remote_module.RemoteModule.remote_parameters"]], "rpc_async() (in module torch.distributed.rpc)": [[2166, "torch.distributed.rpc.rpc_async"]], "rpc_async() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.rpc_async"]], "rpc_sync() (in module torch.distributed.rpc)": [[2166, "torch.distributed.rpc.rpc_sync"]], "rpc_sync() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.rpc_sync"]], "rpc_timeout (torch.distributed.rpc.rpcbackendoptions property)": [[2166, "torch.distributed.rpc.RpcBackendOptions.rpc_timeout"]], "rpc_timeout (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[2166, "torch.distributed.rpc.TensorPipeRpcBackendOptions.rpc_timeout"]], "set_device_map() (torch.distributed.rpc.tensorpiperpcbackendoptions method)": [[2166, "torch.distributed.rpc.TensorPipeRpcBackendOptions.set_device_map"]], "set_devices() (torch.distributed.rpc.tensorpiperpcbackendoptions method)": [[2166, "torch.distributed.rpc.TensorPipeRpcBackendOptions.set_devices"]], "shutdown() (in module torch.distributed.rpc)": [[2166, "torch.distributed.rpc.shutdown"]], "to_here() (torch.distributed.rpc.pyrref method)": [[2166, "torch.distributed.rpc.PyRRef.to_here"]], "torch.distributed.autograd": [[2166, "module-torch.distributed.autograd"]], "torch.distributed.rpc": [[2166, "module-torch.distributed.rpc"]], "torch.signal": [[2169, "module-torch.signal"]], "torch.signal.windows": [[2169, "module-torch.signal.windows"]], "size (class in torch)": [[2170, "torch.Size"]], "count() (torch.size method)": [[2170, "torch.Size.count"]], "index() (torch.size method)": [[2170, "torch.Size.index"]], "numel() (torch.size method)": [[2170, "torch.Size.numel"]], "torch.sparse": [[2171, "module-torch.sparse"]], "airy_ai() (in module torch.special)": [[2172, "torch.special.airy_ai"]], "bessel_j0() (in module torch.special)": [[2172, "torch.special.bessel_j0"]], "bessel_j1() (in module torch.special)": [[2172, "torch.special.bessel_j1"]], "digamma() (in module torch.special)": [[2172, "torch.special.digamma"]], "entr() (in module torch.special)": [[2172, "torch.special.entr"]], "erf() (in module torch.special)": [[2172, "torch.special.erf"]], "erfc() (in module torch.special)": [[2172, "torch.special.erfc"]], "erfcx() (in module torch.special)": [[2172, "torch.special.erfcx"]], "erfinv() (in module torch.special)": [[2172, "torch.special.erfinv"]], "exp2() (in module torch.special)": [[2172, "torch.special.exp2"]], "expit() (in module torch.special)": [[2172, "torch.special.expit"]], "expm1() (in module torch.special)": [[2172, "torch.special.expm1"]], "gammainc() (in module torch.special)": [[2172, "torch.special.gammainc"]], "gammaincc() (in module torch.special)": [[2172, "torch.special.gammaincc"]], "gammaln() (in module torch.special)": [[2172, "torch.special.gammaln"]], "i0() (in module torch.special)": [[2172, "torch.special.i0"]], "i0e() (in module torch.special)": [[2172, "torch.special.i0e"]], "i1() (in module torch.special)": [[2172, "torch.special.i1"]], "i1e() (in module torch.special)": [[2172, "torch.special.i1e"]], "log1p() (in module torch.special)": [[2172, "torch.special.log1p"]], "log_ndtr() (in module torch.special)": [[2172, "torch.special.log_ndtr"]], "log_softmax() (in module torch.special)": [[2172, "torch.special.log_softmax"]], "logit() (in module torch.special)": [[2172, "torch.special.logit"]], "logsumexp() (in module torch.special)": [[2172, "torch.special.logsumexp"]], "multigammaln() (in module torch.special)": [[2172, "torch.special.multigammaln"]], "ndtr() (in module torch.special)": [[2172, "torch.special.ndtr"]], "ndtri() (in module torch.special)": [[2172, "torch.special.ndtri"]], "polygamma() (in module torch.special)": [[2172, "torch.special.polygamma"]], "psi() (in module torch.special)": [[2172, "torch.special.psi"]], "round() (in module torch.special)": [[2172, "torch.special.round"]], "scaled_modified_bessel_k0() (in module torch.special)": [[2172, "torch.special.scaled_modified_bessel_k0"]], "scaled_modified_bessel_k1() (in module torch.special)": [[2172, "torch.special.scaled_modified_bessel_k1"]], "sinc() (in module torch.special)": [[2172, "torch.special.sinc"]], "softmax() (in module torch.special)": [[2172, "torch.special.softmax"]], "spherical_bessel_j0() (in module torch.special)": [[2172, "torch.special.spherical_bessel_j0"]], "torch.special": [[2172, "module-torch.special"]], "xlog1py() (in module torch.special)": [[2172, "torch.special.xlog1py"]], "xlogy() (in module torch.special)": [[2172, "torch.special.xlogy"]], "zeta() (in module torch.special)": [[2172, "torch.special.zeta"]], "bfloat16storage (class in torch)": [[2173, "torch.BFloat16Storage"]], "boolstorage (class in torch)": [[2173, "torch.BoolStorage"]], "bytestorage (class in torch)": [[2173, "torch.ByteStorage"]], "charstorage (class in torch)": [[2173, "torch.CharStorage"]], "complexdoublestorage (class in torch)": [[2173, "torch.ComplexDoubleStorage"]], "complexfloatstorage (class in torch)": [[2173, "torch.ComplexFloatStorage"]], "doublestorage (class in torch)": [[2173, "torch.DoubleStorage"]], "floatstorage (class in torch)": [[2173, "torch.FloatStorage"]], "halfstorage (class in torch)": [[2173, "torch.HalfStorage"]], "intstorage (class in torch)": [[2173, "torch.IntStorage"]], "longstorage (class in torch)": [[2173, "torch.LongStorage"]], "qint32storage (class in torch)": [[2173, "torch.QInt32Storage"]], "qint8storage (class in torch)": [[2173, "torch.QInt8Storage"]], "quint2x4storage (class in torch)": [[2173, "torch.QUInt2x4Storage"]], "quint4x2storage (class in torch)": [[2173, "torch.QUInt4x2Storage"]], "quint8storage (class in torch)": [[2173, "torch.QUInt8Storage"]], "shortstorage (class in torch)": [[2173, "torch.ShortStorage"]], "typedstorage (class in torch)": [[2173, "torch.TypedStorage"]], "untypedstorage (class in torch)": [[2173, "torch.UntypedStorage"]], "bfloat16() (torch.typedstorage method)": [[2173, "torch.TypedStorage.bfloat16"]], "bfloat16() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.bfloat16"]], "bool() (torch.typedstorage method)": [[2173, "torch.TypedStorage.bool"]], "bool() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.bool"]], "byte() (torch.typedstorage method)": [[2173, "torch.TypedStorage.byte"]], "byte() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.byte"]], "byteswap() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.byteswap"]], "char() (torch.typedstorage method)": [[2173, "torch.TypedStorage.char"]], "char() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.char"]], "clone() (torch.typedstorage method)": [[2173, "torch.TypedStorage.clone"]], "clone() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.clone"]], "complex_double() (torch.typedstorage method)": [[2173, "torch.TypedStorage.complex_double"]], "complex_double() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.complex_double"]], "complex_float() (torch.typedstorage method)": [[2173, "torch.TypedStorage.complex_float"]], "complex_float() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.complex_float"]], "copy_() (torch.typedstorage method)": [[2173, "torch.TypedStorage.copy_"]], "copy_() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.copy_"]], "cpu() (torch.typedstorage method)": [[2173, "torch.TypedStorage.cpu"]], "cpu() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.cpu"]], "cuda() (torch.typedstorage method)": [[2173, "torch.TypedStorage.cuda"]], "cuda() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.cuda"]], "data_ptr() (torch.typedstorage method)": [[2173, "torch.TypedStorage.data_ptr"]], "data_ptr() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.data_ptr"]], "device (torch.typedstorage property)": [[2173, "torch.TypedStorage.device"]], "device (torch.untypedstorage attribute)": [[2173, "torch.UntypedStorage.device"]], "double() (torch.typedstorage method)": [[2173, "torch.TypedStorage.double"]], "double() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.double"]], "dtype (torch.bfloat16storage attribute)": [[2173, "torch.BFloat16Storage.dtype"]], "dtype (torch.boolstorage attribute)": [[2173, "torch.BoolStorage.dtype"]], "dtype (torch.bytestorage attribute)": [[2173, "torch.ByteStorage.dtype"]], "dtype (torch.charstorage attribute)": [[2173, "torch.CharStorage.dtype"]], "dtype (torch.complexdoublestorage attribute)": [[2173, "torch.ComplexDoubleStorage.dtype"]], "dtype (torch.complexfloatstorage attribute)": [[2173, "torch.ComplexFloatStorage.dtype"]], "dtype (torch.doublestorage attribute)": [[2173, "torch.DoubleStorage.dtype"]], "dtype (torch.floatstorage attribute)": [[2173, "torch.FloatStorage.dtype"]], "dtype (torch.halfstorage attribute)": [[2173, "torch.HalfStorage.dtype"]], "dtype (torch.intstorage attribute)": [[2173, "torch.IntStorage.dtype"]], "dtype (torch.longstorage attribute)": [[2173, "torch.LongStorage.dtype"]], "dtype (torch.qint32storage attribute)": [[2173, "torch.QInt32Storage.dtype"]], "dtype (torch.qint8storage attribute)": [[2173, "torch.QInt8Storage.dtype"]], "dtype (torch.quint2x4storage attribute)": [[2173, "torch.QUInt2x4Storage.dtype"]], "dtype (torch.quint4x2storage attribute)": [[2173, "torch.QUInt4x2Storage.dtype"]], "dtype (torch.quint8storage attribute)": [[2173, "torch.QUInt8Storage.dtype"]], "dtype (torch.shortstorage attribute)": [[2173, "torch.ShortStorage.dtype"]], "dtype (torch.typedstorage attribute)": [[2173, "torch.TypedStorage.dtype"]], "element_size() (torch.typedstorage method)": [[2173, "torch.TypedStorage.element_size"]], "element_size() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.element_size"]], "filename (torch.typedstorage property)": [[2173, "torch.TypedStorage.filename"]], "filename (torch.untypedstorage property)": [[2173, "torch.UntypedStorage.filename"]], "fill_() (torch.typedstorage method)": [[2173, "torch.TypedStorage.fill_"]], "fill_() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.fill_"]], "float() (torch.typedstorage method)": [[2173, "torch.TypedStorage.float"]], "float() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.float"]], "float8_e4m3fn() (torch.typedstorage method)": [[2173, "torch.TypedStorage.float8_e4m3fn"]], "float8_e4m3fn() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.float8_e4m3fn"]], "float8_e4m3fnuz() (torch.typedstorage method)": [[2173, "torch.TypedStorage.float8_e4m3fnuz"]], "float8_e4m3fnuz() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.float8_e4m3fnuz"]], "float8_e5m2() (torch.typedstorage method)": [[2173, "torch.TypedStorage.float8_e5m2"]], "float8_e5m2() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.float8_e5m2"]], "float8_e5m2fnuz() (torch.typedstorage method)": [[2173, "torch.TypedStorage.float8_e5m2fnuz"]], "float8_e5m2fnuz() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.float8_e5m2fnuz"]], "from_buffer() (torch.typedstorage class method)": [[2173, "torch.TypedStorage.from_buffer"]], "from_buffer() (torch.untypedstorage static method)": [[2173, "torch.UntypedStorage.from_buffer"]], "from_file() (torch.typedstorage class method)": [[2173, "torch.TypedStorage.from_file"]], "from_file() (torch.untypedstorage static method)": [[2173, "torch.UntypedStorage.from_file"]], "get_device() (torch.typedstorage method)": [[2173, "torch.TypedStorage.get_device"]], "get_device() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.get_device"]], "half() (torch.typedstorage method)": [[2173, "torch.TypedStorage.half"]], "half() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.half"]], "hpu() (torch.typedstorage method)": [[2173, "torch.TypedStorage.hpu"]], "hpu() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.hpu"]], "int() (torch.typedstorage method)": [[2173, "torch.TypedStorage.int"]], "int() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.int"]], "is_cuda (torch.typedstorage property)": [[2173, "torch.TypedStorage.is_cuda"]], "is_cuda (torch.untypedstorage property)": [[2173, "torch.UntypedStorage.is_cuda"]], "is_hpu (torch.typedstorage property)": [[2173, "torch.TypedStorage.is_hpu"]], "is_hpu (torch.untypedstorage property)": [[2173, "torch.UntypedStorage.is_hpu"]], "is_pinned() (torch.typedstorage method)": [[2173, "torch.TypedStorage.is_pinned"]], "is_pinned() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.is_pinned"]], "is_shared() (torch.typedstorage method)": [[2173, "torch.TypedStorage.is_shared"]], "is_shared() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.is_shared"]], "is_sparse (torch.typedstorage attribute)": [[2173, "torch.TypedStorage.is_sparse"]], "is_sparse (torch.untypedstorage attribute)": [[2173, "torch.UntypedStorage.is_sparse"]], "is_sparse_csr (torch.untypedstorage attribute)": [[2173, "torch.UntypedStorage.is_sparse_csr"]], "long() (torch.typedstorage method)": [[2173, "torch.TypedStorage.long"]], "long() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.long"]], "mps() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.mps"]], "nbytes() (torch.typedstorage method)": [[2173, "torch.TypedStorage.nbytes"]], "nbytes() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.nbytes"]], "new() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.new"]], "pickle_storage_type() (torch.typedstorage method)": [[2173, "torch.TypedStorage.pickle_storage_type"]], "pin_memory() (torch.typedstorage method)": [[2173, "torch.TypedStorage.pin_memory"]], "pin_memory() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.pin_memory"]], "resizable() (torch.typedstorage method)": [[2173, "torch.TypedStorage.resizable"]], "resizable() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.resizable"]], "resize_() (torch.typedstorage method)": [[2173, "torch.TypedStorage.resize_"]], "resize_() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.resize_"]], "share_memory_() (torch.typedstorage method)": [[2173, "torch.TypedStorage.share_memory_"]], "share_memory_() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.share_memory_"]], "short() (torch.typedstorage method)": [[2173, "torch.TypedStorage.short"]], "short() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.short"]], "size() (torch.typedstorage method)": [[2173, "torch.TypedStorage.size"]], "size() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.size"]], "to() (torch.typedstorage method)": [[2173, "torch.TypedStorage.to"]], "to() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.to"]], "tolist() (torch.typedstorage method)": [[2173, "torch.TypedStorage.tolist"]], "tolist() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.tolist"]], "type() (torch.typedstorage method)": [[2173, "torch.TypedStorage.type"]], "type() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.type"]], "untyped() (torch.typedstorage method)": [[2173, "torch.TypedStorage.untyped"]], "untyped() (torch.untypedstorage method)": [[2173, "torch.UntypedStorage.untyped"]], "device (class in torch)": [[2174, "torch.device"]], "dtype (class in torch)": [[2174, "torch.dtype"]], "layout (class in torch)": [[2174, "torch.layout"]], "memory_format (class in torch)": [[2174, "torch.memory_format"]], "summarywriter (class in torch.utils.tensorboard.writer)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter"]], "__init__() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.__init__"]], "add_audio() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_audio"]], "add_custom_scalars() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars"]], "add_embedding() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_embedding"]], "add_figure() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_figure"]], "add_graph() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_graph"]], "add_histogram() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_histogram"]], "add_hparams() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_hparams"]], "add_image() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_image"]], "add_images() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_images"]], "add_mesh() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_mesh"]], "add_pr_curve() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve"]], "add_scalar() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_scalar"]], "add_scalars() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_scalars"]], "add_text() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_text"]], "add_video() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.add_video"]], "close() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.close"]], "flush() (torch.utils.tensorboard.writer.summarywriter method)": [[2176, "torch.utils.tensorboard.writer.SummaryWriter.flush"]], "torch.utils.tensorboard": [[2176, "module-torch.utils.tensorboard"]], "h (torch.tensor attribute)": [[2177, "torch.Tensor.H"]], "t (torch.tensor attribute)": [[2177, "torch.Tensor.T"]], "tensor (class in torch)": [[2177, "torch.Tensor"]], "__init__() (torch.tensor method)": [[2177, "torch.Tensor.__init__"]], "mh (torch.tensor attribute)": [[2177, "torch.Tensor.mH"]], "mt (torch.tensor attribute)": [[2177, "torch.Tensor.mT"]], "assert_allclose() (in module torch.testing)": [[2178, "torch.testing.assert_allclose"]], "assert_close() (in module torch.testing)": [[2178, "torch.testing.assert_close"]], "make_tensor() (in module torch.testing)": [[2178, "torch.testing.make_tensor"]], "torch.testing": [[2178, "module-torch.testing"]], "symbool (class in torch)": [[2180, "torch.SymBool"]], "symfloat (class in torch)": [[2180, "torch.SymFloat"]], "symint (class in torch)": [[2180, "torch.SymInt"]], "tag (class in torch)": [[2180, "torch.Tag"]], "as_integer_ratio() (torch.symfloat method)": [[2180, "torch.SymFloat.as_integer_ratio"]], "as_integer_ratio() (torch.symint method)": [[2180, "torch.SymInt.as_integer_ratio"]], "conjugate() (torch.symfloat method)": [[2180, "torch.SymFloat.conjugate"]], "default_generator (torch.torch attribute)": [[2180, "torch.torch.default_generator"]], "hex() (torch.symfloat method)": [[2180, "torch.SymFloat.hex"]], "is_integer() (torch.symfloat method)": [[2180, "torch.SymFloat.is_integer"]], "name (torch.tag property)": [[2180, "torch.Tag.name"]], "torch": [[2180, "module-torch"]], "torch.contrib": [[2180, "module-torch.contrib"]], "torch.functional": [[2180, "module-torch.functional"]], "torch.quasirandom": [[2180, "module-torch.quasirandom"]], "torch.return_types": [[2180, "module-torch.return_types"]], "torch.serialization": [[2180, "module-torch.serialization"]], "torch.signal.windows.windows": [[2180, "module-torch.signal.windows.windows"]], "torch.sparse.semi_structured": [[2180, "module-torch.sparse.semi_structured"]], "torch.storage": [[2180, "module-torch.storage"]], "torch.torch_version": [[2180, "module-torch.torch_version"]], "torch.types": [[2180, "module-torch.types"]], "torch.utils.backcompat": [[2180, "module-torch.utils.backcompat"]], "torch.utils.hipify": [[2180, "module-torch.utils.hipify"]], "torch.utils.model_dump": [[2180, "module-torch.utils.model_dump"]], "torch.utils.viz": [[2180, "module-torch.utils.viz"]], "torch.version": [[2180, "module-torch.version"]], "logger (class in torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.Logger"]], "outputlogger (class in torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.OutputLogger"]], "shadow (class in torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.Shadow"]], "shadowlogger (class in torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.ShadowLogger"]], "add() (torch.ao.ns._numeric_suite.shadow method)": [[2181, "torch.ao.ns._numeric_suite.Shadow.add"]], "add_relu() (torch.ao.ns._numeric_suite.shadow method)": [[2181, "torch.ao.ns._numeric_suite.Shadow.add_relu"]], "add_scalar() (torch.ao.ns._numeric_suite.shadow method)": [[2181, "torch.ao.ns._numeric_suite.Shadow.add_scalar"]], "cat() (torch.ao.ns._numeric_suite.shadow method)": [[2181, "torch.ao.ns._numeric_suite.Shadow.cat"]], "compare_model_outputs() (in module torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.compare_model_outputs"]], "compare_model_stub() (in module torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.compare_model_stub"]], "compare_weights() (in module torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.compare_weights"]], "forward() (torch.ao.ns._numeric_suite.logger method)": [[2181, "torch.ao.ns._numeric_suite.Logger.forward"]], "forward() (torch.ao.ns._numeric_suite.outputlogger method)": [[2181, "torch.ao.ns._numeric_suite.OutputLogger.forward"]], "forward() (torch.ao.ns._numeric_suite.shadow method)": [[2181, "torch.ao.ns._numeric_suite.Shadow.forward"]], "forward() (torch.ao.ns._numeric_suite.shadowlogger method)": [[2181, "torch.ao.ns._numeric_suite.ShadowLogger.forward"]], "get_logger_dict() (in module torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.get_logger_dict"]], "get_matching_activations() (in module torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.get_matching_activations"]], "mul() (torch.ao.ns._numeric_suite.shadow method)": [[2181, "torch.ao.ns._numeric_suite.Shadow.mul"]], "mul_scalar() (torch.ao.ns._numeric_suite.shadow method)": [[2181, "torch.ao.ns._numeric_suite.Shadow.mul_scalar"]], "prepare_model_outputs() (in module torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.prepare_model_outputs"]], "prepare_model_with_stubs() (in module torch.ao.ns._numeric_suite)": [[2181, "torch.ao.ns._numeric_suite.prepare_model_with_stubs"]], "torch.ao.ns._numeric_suite": [[2181, "module-torch.ao.ns._numeric_suite"]], "nstracer (class in torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.NSTracer"]], "outputcomparisonlogger (class in torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.OutputComparisonLogger"]], "outputlogger (class in torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.OutputLogger"]], "add_loggers() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.add_loggers"]], "add_shadow_loggers() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.add_shadow_loggers"]], "compute_cosine_similarity() (in module torch.ao.ns.fx.utils)": [[2182, "torch.ao.ns.fx.utils.compute_cosine_similarity"]], "compute_normalized_l2_error() (in module torch.ao.ns.fx.utils)": [[2182, "torch.ao.ns.fx.utils.compute_normalized_l2_error"]], "compute_sqnr() (in module torch.ao.ns.fx.utils)": [[2182, "torch.ao.ns.fx.utils.compute_sqnr"]], "convert_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.convert_n_shadows_model"]], "extend_logger_results_with_comparison() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.extend_logger_results_with_comparison"]], "extract_logger_info() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.extract_logger_info"]], "extract_results_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.extract_results_n_shadows_model"]], "extract_shadow_logger_info() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.extract_shadow_logger_info"]], "extract_weights() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.extract_weights"]], "forward() (torch.ao.ns._numeric_suite_fx.outputcomparisonlogger method)": [[2182, "torch.ao.ns._numeric_suite_fx.OutputComparisonLogger.forward"]], "forward() (torch.ao.ns._numeric_suite_fx.outputlogger method)": [[2182, "torch.ao.ns._numeric_suite_fx.OutputLogger.forward"]], "is_leaf_module() (torch.ao.ns._numeric_suite_fx.nstracer method)": [[2182, "torch.ao.ns._numeric_suite_fx.NSTracer.is_leaf_module"]], "loggers_set_enabled() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.loggers_set_enabled"]], "loggers_set_save_activations() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.loggers_set_save_activations"]], "prepare_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.prepare_n_shadows_model"]], "print_comparisons_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)": [[2182, "torch.ao.ns._numeric_suite_fx.print_comparisons_n_shadows_model"]], "torch.ao.ns._numeric_suite_fx": [[2182, "module-torch.ao.ns._numeric_suite_fx"]], "torch_compile_job_id": [[2184, "index-0"]], "job_id (in module torch.compiler.config)": [[2184, "torch.compiler.config.job_id"]], "torch.compiler.config": [[2184, "module-torch.compiler.config"]], "aoti_compile_and_package() (in module torch._inductor)": [[2185, "torch._inductor.aoti_compile_and_package"]], "aoti_load_package() (in module torch._inductor)": [[2185, "torch._inductor.aoti_load_package"]], "torch.compiler": [[2187, "module-torch.compiler"]], "get_ignored_functions() (in module torch.overrides)": [[2206, "torch.overrides.get_ignored_functions"]], "get_overridable_functions() (in module torch.overrides)": [[2206, "torch.overrides.get_overridable_functions"]], "get_testing_overrides() (in module torch.overrides)": [[2206, "torch.overrides.get_testing_overrides"]], "handle_torch_function() (in module torch.overrides)": [[2206, "torch.overrides.handle_torch_function"]], "has_torch_function() (in module torch.overrides)": [[2206, "torch.overrides.has_torch_function"]], "is_tensor_like() (in module torch.overrides)": [[2206, "torch.overrides.is_tensor_like"]], "is_tensor_method_or_property() (in module torch.overrides)": [[2206, "torch.overrides.is_tensor_method_or_property"]], "resolve_name() (in module torch.overrides)": [[2206, "torch.overrides.resolve_name"]], "torch.overrides": [[2206, "module-torch.overrides"]], "wrap_torch_function() (in module torch.overrides)": [[2206, "torch.overrides.wrap_torch_function"]], "_dump_snapshot() (in module torch.cuda.memory)": [[2207, "torch.cuda.memory._dump_snapshot"]], "_record_memory_history() (in module torch.cuda.memory)": [[2207, "torch.cuda.memory._record_memory_history"]], "_snapshot() (in module torch.cuda.memory)": [[2207, "torch.cuda.memory._snapshot"]], "torch.finfo (class in torch)": [[2210, "torch.torch.finfo"]], "torch.iinfo (class in torch)": [[2210, "torch.torch.iinfo"]], "torch.utils": [[2211, "module-torch.utils"]], "torch.utils.backend_registration": [[2211, "module-torch.utils.backend_registration"]], "torch.utils.benchmark.examples.blas_compare_setup": [[2211, "module-torch.utils.benchmark.examples.blas_compare_setup"]], "torch.utils.benchmark.examples.compare": [[2211, "module-torch.utils.benchmark.examples.compare"]], "torch.utils.benchmark.examples.fuzzer": [[2211, "module-torch.utils.benchmark.examples.fuzzer"]], "torch.utils.benchmark.examples.op_benchmark": [[2211, "module-torch.utils.benchmark.examples.op_benchmark"]], "torch.utils.benchmark.examples.simple_timeit": [[2211, "module-torch.utils.benchmark.examples.simple_timeit"]], "torch.utils.benchmark.examples.spectral_ops_fuzz_test": [[2211, "module-torch.utils.benchmark.examples.spectral_ops_fuzz_test"]], "torch.utils.benchmark.op_fuzzers.binary": [[2211, "module-torch.utils.benchmark.op_fuzzers.binary"]], "torch.utils.benchmark.op_fuzzers.sparse_binary": [[2211, "module-torch.utils.benchmark.op_fuzzers.sparse_binary"]], "torch.utils.benchmark.op_fuzzers.sparse_unary": [[2211, "module-torch.utils.benchmark.op_fuzzers.sparse_unary"]], "torch.utils.benchmark.op_fuzzers.spectral": [[2211, "module-torch.utils.benchmark.op_fuzzers.spectral"]], "torch.utils.benchmark.op_fuzzers.unary": [[2211, "module-torch.utils.benchmark.op_fuzzers.unary"]], "torch.utils.benchmark.utils.common": [[2211, "module-torch.utils.benchmark.utils.common"]], "torch.utils.benchmark.utils.compare": [[2211, "module-torch.utils.benchmark.utils.compare"]], "torch.utils.benchmark.utils.compile": [[2211, "module-torch.utils.benchmark.utils.compile"]], "torch.utils.benchmark.utils.cpp_jit": [[2211, "module-torch.utils.benchmark.utils.cpp_jit"]], "torch.utils.benchmark.utils.fuzzer": [[2211, "module-torch.utils.benchmark.utils.fuzzer"]], "torch.utils.benchmark.utils.sparse_fuzzer": [[2211, "module-torch.utils.benchmark.utils.sparse_fuzzer"]], "torch.utils.benchmark.utils.timer": [[2211, "module-torch.utils.benchmark.utils.timer"]], "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface": [[2211, "module-torch.utils.benchmark.utils.valgrind_wrapper.timer_interface"]], "torch.utils.bundled_inputs": [[2211, "module-torch.utils.bundled_inputs"]], "torch.utils.checkpoint": [[2211, "module-torch.utils.checkpoint"]], "torch.utils.collect_env": [[2211, "module-torch.utils.collect_env"]], "torch.utils.cpp_backtrace": [[2211, "module-torch.utils.cpp_backtrace"]], "torch.utils.cpp_extension": [[2211, "module-torch.utils.cpp_extension"]], "torch.utils.data.backward_compatibility": [[2211, "module-torch.utils.data.backward_compatibility"]], "torch.utils.data.dataloader": [[2211, "module-torch.utils.data.dataloader"]], "torch.utils.data.datapipes.dataframe.dataframe_wrapper": [[2211, "module-torch.utils.data.datapipes.dataframe.dataframe_wrapper"]], "torch.utils.data.datapipes.dataframe.dataframes": [[2211, "module-torch.utils.data.datapipes.dataframe.dataframes"]], "torch.utils.data.datapipes.dataframe.datapipes": [[2211, "module-torch.utils.data.datapipes.dataframe.datapipes"]], "torch.utils.data.datapipes.dataframe.structures": [[2211, "module-torch.utils.data.datapipes.dataframe.structures"]], "torch.utils.data.datapipes.datapipe": [[2211, "module-torch.utils.data.datapipes.datapipe"]], "torch.utils.data.datapipes.gen_pyi": [[2211, "module-torch.utils.data.datapipes.gen_pyi"]], "torch.utils.data.datapipes.iter.callable": [[2211, "module-torch.utils.data.datapipes.iter.callable"]], "torch.utils.data.datapipes.iter.combinatorics": [[2211, "module-torch.utils.data.datapipes.iter.combinatorics"]], "torch.utils.data.datapipes.iter.combining": [[2211, "module-torch.utils.data.datapipes.iter.combining"]], "torch.utils.data.datapipes.iter.filelister": [[2211, "module-torch.utils.data.datapipes.iter.filelister"]], "torch.utils.data.datapipes.iter.fileopener": [[2211, "module-torch.utils.data.datapipes.iter.fileopener"]], "torch.utils.data.datapipes.iter.grouping": [[2211, "module-torch.utils.data.datapipes.iter.grouping"]], "torch.utils.data.datapipes.iter.routeddecoder": [[2211, "module-torch.utils.data.datapipes.iter.routeddecoder"]], "torch.utils.data.datapipes.iter.selecting": [[2211, "module-torch.utils.data.datapipes.iter.selecting"]], "torch.utils.data.datapipes.iter.sharding": [[2211, "module-torch.utils.data.datapipes.iter.sharding"]], "torch.utils.data.datapipes.iter.streamreader": [[2211, "module-torch.utils.data.datapipes.iter.streamreader"]], "torch.utils.data.datapipes.iter.utils": [[2211, "module-torch.utils.data.datapipes.iter.utils"]], "torch.utils.data.datapipes.map.callable": [[2211, "module-torch.utils.data.datapipes.map.callable"]], "torch.utils.data.datapipes.map.combinatorics": [[2211, "module-torch.utils.data.datapipes.map.combinatorics"]], "torch.utils.data.datapipes.map.combining": [[2211, "module-torch.utils.data.datapipes.map.combining"]], "torch.utils.data.datapipes.map.grouping": [[2211, "module-torch.utils.data.datapipes.map.grouping"]], "torch.utils.data.datapipes.map.utils": [[2211, "module-torch.utils.data.datapipes.map.utils"]], "torch.utils.data.datapipes.utils.common": [[2211, "module-torch.utils.data.datapipes.utils.common"]], "torch.utils.data.datapipes.utils.decoder": [[2211, "module-torch.utils.data.datapipes.utils.decoder"]], "torch.utils.data.datapipes.utils.snapshot": [[2211, "module-torch.utils.data.datapipes.utils.snapshot"]], "torch.utils.data.dataset": [[2211, "module-torch.utils.data.dataset"]], "torch.utils.data.distributed": [[2211, "module-torch.utils.data.distributed"]], "torch.utils.data.graph": [[2211, "module-torch.utils.data.graph"]], "torch.utils.data.graph_settings": [[2211, "module-torch.utils.data.graph_settings"]], "torch.utils.data.sampler": [[2211, "module-torch.utils.data.sampler"]], "torch.utils.dlpack": [[2211, "module-torch.utils.dlpack"]], "torch.utils.file_baton": [[2211, "module-torch.utils.file_baton"]], "torch.utils.flop_counter": [[2211, "module-torch.utils.flop_counter"]], "torch.utils.hipify.constants": [[2211, "module-torch.utils.hipify.constants"]], "torch.utils.hipify.cuda_to_hip_mappings": [[2211, "module-torch.utils.hipify.cuda_to_hip_mappings"]], "torch.utils.hipify.hipify_python": [[2211, "module-torch.utils.hipify.hipify_python"]], "torch.utils.hipify.version": [[2211, "module-torch.utils.hipify.version"]], "torch.utils.hooks": [[2211, "module-torch.utils.hooks"]], "torch.utils.jit.log_extract": [[2211, "module-torch.utils.jit.log_extract"]], "torch.utils.mkldnn": [[2211, "module-torch.utils.mkldnn"]], "torch.utils.mobile_optimizer": [[2211, "module-torch.utils.mobile_optimizer"]], "torch.utils.show_pickle": [[2211, "module-torch.utils.show_pickle"]], "torch.utils.tensorboard.summary": [[2211, "module-torch.utils.tensorboard.summary"]], "torch.utils.tensorboard.writer": [[2211, "module-torch.utils.tensorboard.writer"]], "torch.utils.throughput_benchmark": [[2211, "module-torch.utils.throughput_benchmark"]], "torch.utils.weak": [[2211, "module-torch.utils.weak"]], "torch.xpu": [[2212, "module-torch.xpu"]], "torch.xpu.memory": [[2212, "module-torch.xpu.memory"]], "torch.xpu.random": [[2212, "module-torch.xpu.random"]], "torch.xpu.streams": [[2212, "module-torch.xpu.streams"]]}})