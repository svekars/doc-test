

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<meta property="og:title" content="PyTorch 2.0 Troubleshooting (old)" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://pytorch.org/torch.compiler_troubleshooting_old.html" />
<meta property="og:site_name" content="PyTorch" />
<meta property="og:description" content="Author: Michael Lazos We are actively developing debug tools, profilers, and improving our error and warning messages. Below is a table of the available tools and their typical usage. For additiona..." />
<meta property="og:image" content="https://pytorch.org/docs/stable/_static/img/pytorch-logo-dark.svg" />
<meta property="og:image:alt" content="PyTorch" />
<meta name="description" content="Author: Michael Lazos We are actively developing debug tools, profilers, and improving our error and warning messages. Below is a table of the available tools and their typical usage. For additiona..." />

    <title>PyTorch 2.0 Troubleshooting (old) &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/katex-math.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/jit.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/design-tabs.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'torch.compiler_troubleshooting_old';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://pytorch.org/docs/pytorch-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<link rel="stylesheet" type="text/css" href="_static/css/theme.css">
<script type="text/javascript" src="_static/js/theme.js"></script>
<link rel="stylesheet" href="_static/webfonts/all.min.css">

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
   height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
   <!-- End Google Tag Manager (noscript) -->
   <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
   new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
   j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
   'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
   j.onload = function() {
     window.dispatchEvent(new Event('gtm_loaded'));
     console.log('GTM loaded successfully');
   };
   })(window,document,'script','dataLayer','GTM-T8XT4PS');
</script>
 <!-- End Google Tag Manager -->
 <!-- Facebook Pixel Code -->
<script>
   !function(f,b,e,v,n,t,s)
   {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
   n.callMethod.apply(n,arguments):n.queue.push(arguments)};
   if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
   n.queue=[];t=b.createElement(e);t.async=!0;
   t.src=v;s=b.getElementsByTagName(e)[0];
   s.parentNode.insertBefore(t,s)}(window,document,'script',
   'https://connect.facebook.net/en_US/fbevents.js');
   fbq('init', '243028289693773');
   fbq('track', 'PageView');
</script>
<noscript>
   <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1"/>
</noscript>
<script>
   function gtag() {
    window.dataLayer.push(arguments);
   }
</script>
<!-- End Facebook Pixel Code -->

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

   <!--
   Search engines should not index the main version of documentation.
   Stable documentation are built without release == 'main'.
   -->
   <meta name="robots" content="noindex">


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>
<body data-feedback-url="https://github.com/pytorch/pytorch" class="pytorch-body">
     <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later.
          <li>
            <div class="main-menu-item">
             <a href="" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="">Get Started</a>
           </li>
           <li>
             <a href="">Tutorials</a>
           </li>
           <li>
             <a href="">Learn the Basics</a>
           </li>
           <li>
             <a href="">PyTorch Recipes</a>
           </li>
           <li>
             <a href="">Introduction to PyTorch - YouTube Series</a>
           </li>
         </ul>
         <li class="resources-mobile-menu-title">
           <a>Ecosystem</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="">Tools</a>
           </li>
           <li>
             <a href="">Community</a>
           </li>
           <li>
             <a href="">Forums</a>
           </li>
           <li>
             <a href="">Developer Resources</a>
           </li>
           <li>
             <a href="">Contributor Awards - 2024</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Edge</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="">About PyTorch Edge</a>
           </li>

           <li>
             <a href="">ExecuTorch</a>
           </li>
           <li>
             <a href="">ExecuTorch Documentation</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="">PyTorch</a>
          </li>

          <li>
            <a href="">PyTorch Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="">PyTorch Blog</a>
          </li>
          <li>
            <a href="">Community Blog</a>
          </li>

          <li>
            <a href="">Videos</a>
          </li>

          <li>
            <a href="">Community Stories</a>
          </li>
          <li>
            <a href="">Events</a>
          </li>
          <li>
             <a href="">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="">PyTorch Foundation</a>
          </li>
          <li>
            <a href="">Governing Board</a>
          </li>
          <li>
             <a href="">Cloud Credit Program</a>
          </li>
          <li>
             <a href="">Technical Advisory Council</a>
          </li>
          <li>
             <a href="">Staff</a>
          </li>
          <li>
             <a href="">Contact Us</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
   
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">Home</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="pytorch-api.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    // Define the search callback
    const myWebSearchStartingCallback = (gname, query) => {
      if (typeof dataLayer !== 'undefined' && query) {
        dataLayer.push({
          'event': 'google_search',
          'search_term': query,
          'event_category': 'Search',
          'event_label': 'Google Search'
        });
        console.log('GA event sent via callback: google_search - ' + query);
      }
      return '';
    };

    // Set up the GCSE search callbacks
    window.__gcse || (window.__gcse = {});
    window.__gcse.searchCallbacks = {
      web: {
        starting: myWebSearchStartingCallback,
      },
    };
    if (window.location.pathname.includes('/search.html')) {
      document.body.classList.add('search-page');
    }

    // Function to reinitialize Google CSE
    function reinitializeGoogleSearch() {
      if (window.__gcse) {
        // Force Google CSE to reinitialize
        if (window.__gcse.initializationCallback) {
          window.__gcse.initializationCallback();
        }
      }
    }

    // Function to handle search toggle
    function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
      if (!toggle || !sphinxSearch || !googleSearch) return;

      // Check if the URL contains /stable/ or /tutorials/
      const currentUrl = window.location.href;
      const shouldDefaultToGoogle = currentUrl.includes('/stable/') || currentUrl.includes('/tutorials/');

      // Check if there's a saved preference, otherwise use the URL-based default
      const savedPreference = localStorage.getItem('searchPreference');
      if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
        toggle.checked = true;
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        // Save the preference if it wasn't already saved
        if (savedPreference === null) {
          localStorage.setItem('searchPreference', 'google');
        }
        // Ensure Google search is properly initialized
        reinitializeGoogleSearch();
      } else {
        toggle.checked = false;
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
      }

      // Update tooltip based on initial state
      const tooltipElement = document.querySelector('.search-toggle-container');
      if (tooltipElement) {
        tooltipElement.setAttribute('data-bs-title', toggle.checked ? 'Google Search On' : 'Google Search Off');
        // Reinitialize tooltip if Bootstrap's tooltip is already initialized
        if (bootstrap && bootstrap.Tooltip) {
          const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
          if (tooltipInstance) tooltipInstance.dispose();
          new bootstrap.Tooltip(tooltipElement);
        }
      }

      // Add a data attribute to track if this toggle has been initialized
      if (toggle.hasAttribute('data-initialized')) {
        return; // Skip adding another event listener if already initialized
      }
      toggle.setAttribute('data-initialized', 'true');

      toggle.addEventListener('change', function() {
        if (this.checked) {
          sphinxSearch.style.display = 'none';
          googleSearch.style.display = 'block';
          localStorage.setItem('searchPreference', 'google');
          // Reinitialize Google search when switching to it
          reinitializeGoogleSearch();
          const tooltipElement = document.querySelector('.search-toggle-container');
          if (tooltipElement) {
            tooltipElement.setAttribute('data-bs-title', 'Google Search On');
            // Refresh tooltip
            if (bootstrap && bootstrap.Tooltip) {
              const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
              if (tooltipInstance) tooltipInstance.dispose();
              new bootstrap.Tooltip(tooltipElement);
            }
          }
          if (typeof dataLayer !== 'undefined') {
            dataLayer.push({
              'event': 'search_engine_switch',
              'event_category': 'Search',
              'event_label': 'Google'
            });
            console.log('GA event sent via dataLayer: search_engine_switch - Google');
          } else {
            console.log('GA not available: Cannot track Google search switch');
          }
        } else {
          sphinxSearch.style.display = 'block';
          googleSearch.style.display = 'none';
          localStorage.setItem('searchPreference', 'sphinx');
          const tooltipElement = document.querySelector('.search-toggle-container');
          if (tooltipElement) {
            tooltipElement.setAttribute('data-bs-title', 'Google Search Off');
            // Refresh tooltip
            if (bootstrap && bootstrap.Tooltip) {
              const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
              if (tooltipInstance) tooltipInstance.dispose();
              new bootstrap.Tooltip(tooltipElement);
            }
          }
          if (typeof dataLayer !== 'undefined') {
            dataLayer.push({
              'event': 'search_engine_switch',
              'event_category': 'Search',
              'event_label': 'Sphinx'
            });
            console.log('GA event sent via dataLayer: search_engine_switch - Sphinx');
          } else {
            console.log('GA not available: Cannot track Sphinx search switch');
          }
        }

        // Also update mobile search if it exists
        updateMobileSearch(false); // Pass false to prevent triggering another event
      });
    }


    // Function to update mobile search based on current toggle state
    function updateMobileSearch() {
      const toggle = document.getElementById('search-toggle');
      if (!toggle) return;

      // Find mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (mobileSearchContainer) {
        const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
        const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

        if (mobileSphinxSearch && mobileGoogleSearch) {
          if (toggle.checked) {
            mobileSphinxSearch.style.display = 'none';
            mobileGoogleSearch.style.display = 'block';
            // Reinitialize Google search in mobile view
            reinitializeGoogleSearch();
          } else {
            mobileSphinxSearch.style.display = 'block';
            mobileGoogleSearch.style.display = 'none';
          }
        }
      }
    }

    // Initialize desktop search toggle
    const toggle = document.getElementById('search-toggle');
    const sphinxSearch = document.getElementById('sphinx-search');
    const googleSearch = document.getElementById('google-search');
    handleSearchToggle(toggle, sphinxSearch, googleSearch);

    // Set placeholder text for Google search input
    const observer = new MutationObserver(function(mutations, obs) {
      const searchInputs = document.querySelectorAll('.gsc-input input');
      searchInputs.forEach(input => {
      if (input) {
        input.setAttribute('placeholder', 'Search the docs ...');

        if (!input.hasAttribute('data-tracking-added')) {
          input.setAttribute('data-tracking-added', 'true');
        }
      }
      });
    });

    observer.observe(document.body, { childList: true, subtree: true });

    // Watch for mobile menu creation
    const mobileMenuObserver = new MutationObserver(function(mutations) {
      for (const mutation of mutations) {
        const mobileSearchInputs = document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input');
      mobileSearchInputs.forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
          }
        });
        if (mutation.addedNodes.length) {
          // Check if the mobile search container was added
          const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
          if (mobileSearchContainer) {
            // Clone the toggle for mobile if needed
            const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
            if (mobileToggle) {
              // Sync mobile toggle with desktop toggle
              mobileToggle.checked = toggle.checked;

              // Update mobile search display
              updateMobileSearch();

              // Add event listener to mobile toggle
              mobileToggle.addEventListener('change', function() {
                // Sync desktop toggle with mobile toggle
                toggle.checked = this.checked;
                // Trigger change event on desktop toggle to update both
                toggle.dispatchEvent(new Event('change'));
              });
            }
          }
        }
      }
    });

    mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

    // Ensure Google CSE is properly loaded
    if (window.__gcse) {
      window.__gcse.callback = function() {
        // This will run after Google CSE is fully loaded
        if (toggle && toggle.checked) {
          // If Google search is active, make sure it's properly initialized
          reinitializeGoogleSearch();
        }
      };
    } else {
      // If Google CSE hasn't loaded yet, set up a callback
      window.__gcse = {
        callback: function() {
          if (toggle && toggle.checked) {
            reinitializeGoogleSearch();
          }
        }
      };
    }
  });
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="pytorch-api.html">
    Python API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="notes.html">
    Developer Notes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/tutorials/">
    Tutorials
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    // Define the search callback
    const myWebSearchStartingCallback = (gname, query) => {
      if (typeof dataLayer !== 'undefined' && query) {
        dataLayer.push({
          'event': 'google_search',
          'search_term': query,
          'event_category': 'Search',
          'event_label': 'Google Search'
        });
        console.log('GA event sent via callback: google_search - ' + query);
      }
      return '';
    };

    // Set up the GCSE search callbacks
    window.__gcse || (window.__gcse = {});
    window.__gcse.searchCallbacks = {
      web: {
        starting: myWebSearchStartingCallback,
      },
    };
    if (window.location.pathname.includes('/search.html')) {
      document.body.classList.add('search-page');
    }

    // Function to reinitialize Google CSE
    function reinitializeGoogleSearch() {
      if (window.__gcse) {
        // Force Google CSE to reinitialize
        if (window.__gcse.initializationCallback) {
          window.__gcse.initializationCallback();
        }
      }
    }

    // Function to handle search toggle
    function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
      if (!toggle || !sphinxSearch || !googleSearch) return;

      // Check if the URL contains /stable/ or /tutorials/
      const currentUrl = window.location.href;
      const shouldDefaultToGoogle = currentUrl.includes('/stable/') || currentUrl.includes('/tutorials/');

      // Check if there's a saved preference, otherwise use the URL-based default
      const savedPreference = localStorage.getItem('searchPreference');
      if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
        toggle.checked = true;
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        // Save the preference if it wasn't already saved
        if (savedPreference === null) {
          localStorage.setItem('searchPreference', 'google');
        }
        // Ensure Google search is properly initialized
        reinitializeGoogleSearch();
      } else {
        toggle.checked = false;
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
      }

      // Update tooltip based on initial state
      const tooltipElement = document.querySelector('.search-toggle-container');
      if (tooltipElement) {
        tooltipElement.setAttribute('data-bs-title', toggle.checked ? 'Google Search On' : 'Google Search Off');
        // Reinitialize tooltip if Bootstrap's tooltip is already initialized
        if (bootstrap && bootstrap.Tooltip) {
          const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
          if (tooltipInstance) tooltipInstance.dispose();
          new bootstrap.Tooltip(tooltipElement);
        }
      }

      // Add a data attribute to track if this toggle has been initialized
      if (toggle.hasAttribute('data-initialized')) {
        return; // Skip adding another event listener if already initialized
      }
      toggle.setAttribute('data-initialized', 'true');

      toggle.addEventListener('change', function() {
        if (this.checked) {
          sphinxSearch.style.display = 'none';
          googleSearch.style.display = 'block';
          localStorage.setItem('searchPreference', 'google');
          // Reinitialize Google search when switching to it
          reinitializeGoogleSearch();
          const tooltipElement = document.querySelector('.search-toggle-container');
          if (tooltipElement) {
            tooltipElement.setAttribute('data-bs-title', 'Google Search On');
            // Refresh tooltip
            if (bootstrap && bootstrap.Tooltip) {
              const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
              if (tooltipInstance) tooltipInstance.dispose();
              new bootstrap.Tooltip(tooltipElement);
            }
          }
          if (typeof dataLayer !== 'undefined') {
            dataLayer.push({
              'event': 'search_engine_switch',
              'event_category': 'Search',
              'event_label': 'Google'
            });
            console.log('GA event sent via dataLayer: search_engine_switch - Google');
          } else {
            console.log('GA not available: Cannot track Google search switch');
          }
        } else {
          sphinxSearch.style.display = 'block';
          googleSearch.style.display = 'none';
          localStorage.setItem('searchPreference', 'sphinx');
          const tooltipElement = document.querySelector('.search-toggle-container');
          if (tooltipElement) {
            tooltipElement.setAttribute('data-bs-title', 'Google Search Off');
            // Refresh tooltip
            if (bootstrap && bootstrap.Tooltip) {
              const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
              if (tooltipInstance) tooltipInstance.dispose();
              new bootstrap.Tooltip(tooltipElement);
            }
          }
          if (typeof dataLayer !== 'undefined') {
            dataLayer.push({
              'event': 'search_engine_switch',
              'event_category': 'Search',
              'event_label': 'Sphinx'
            });
            console.log('GA event sent via dataLayer: search_engine_switch - Sphinx');
          } else {
            console.log('GA not available: Cannot track Sphinx search switch');
          }
        }

        // Also update mobile search if it exists
        updateMobileSearch(false); // Pass false to prevent triggering another event
      });
    }


    // Function to update mobile search based on current toggle state
    function updateMobileSearch() {
      const toggle = document.getElementById('search-toggle');
      if (!toggle) return;

      // Find mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (mobileSearchContainer) {
        const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
        const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

        if (mobileSphinxSearch && mobileGoogleSearch) {
          if (toggle.checked) {
            mobileSphinxSearch.style.display = 'none';
            mobileGoogleSearch.style.display = 'block';
            // Reinitialize Google search in mobile view
            reinitializeGoogleSearch();
          } else {
            mobileSphinxSearch.style.display = 'block';
            mobileGoogleSearch.style.display = 'none';
          }
        }
      }
    }

    // Initialize desktop search toggle
    const toggle = document.getElementById('search-toggle');
    const sphinxSearch = document.getElementById('sphinx-search');
    const googleSearch = document.getElementById('google-search');
    handleSearchToggle(toggle, sphinxSearch, googleSearch);

    // Set placeholder text for Google search input
    const observer = new MutationObserver(function(mutations, obs) {
      const searchInputs = document.querySelectorAll('.gsc-input input');
      searchInputs.forEach(input => {
      if (input) {
        input.setAttribute('placeholder', 'Search the docs ...');

        if (!input.hasAttribute('data-tracking-added')) {
          input.setAttribute('data-tracking-added', 'true');
        }
      }
      });
    });

    observer.observe(document.body, { childList: true, subtree: true });

    // Watch for mobile menu creation
    const mobileMenuObserver = new MutationObserver(function(mutations) {
      for (const mutation of mutations) {
        const mobileSearchInputs = document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input');
      mobileSearchInputs.forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
          }
        });
        if (mutation.addedNodes.length) {
          // Check if the mobile search container was added
          const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
          if (mobileSearchContainer) {
            // Clone the toggle for mobile if needed
            const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
            if (mobileToggle) {
              // Sync mobile toggle with desktop toggle
              mobileToggle.checked = toggle.checked;

              // Update mobile search display
              updateMobileSearch();

              // Add event listener to mobile toggle
              mobileToggle.addEventListener('change', function() {
                // Sync desktop toggle with mobile toggle
                toggle.checked = this.checked;
                // Trigger change event on desktop toggle to update both
                toggle.dispatchEvent(new Event('change'));
              });
            }
          }
        }
      }
    });

    mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

    // Ensure Google CSE is properly loaded
    if (window.__gcse) {
      window.__gcse.callback = function() {
        // This will run after Google CSE is fully loaded
        if (toggle && toggle.checked) {
          // If Google search is active, make sure it's properly initialized
          reinitializeGoogleSearch();
        }
      };
    } else {
      // If Google CSE hasn't loaded yet, set up a callback
      window.__gcse = {
        callback: function() {
          if (toggle && toggle.checked) {
            reinitializeGoogleSearch();
          }
        }
      };
    }
  });
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">PyTorch 2.0...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5"></span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article">
    
    
  <section id="pytorch-2-0-troubleshooting-old">
<span id="torch-compiler-troubleshooting-old"></span><h1>PyTorch 2.0 Troubleshooting (old)<a class="headerlink" href="#pytorch-2-0-troubleshooting-old" title="Permalink to this heading">#</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/mlazos">Michael Lazos</a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This document is outdated and is now mainly a primary resource on how to run the <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> minifier.
Please see the <a class="reference external" href="https://pytorch.org/docs/main/torch.compiler_troubleshooting.html">updated troubleshooting document</a>.
There is also a more <a class="reference external" href="https://docs.google.com/document/d/1y5CRfMLdwEoF1nTk9q8qEu1mgMUuUtvhklPKJ2emLU8/edit#heading=h.ivdr7fmrbeab">comprehensive manual for torch.compile</a>
available.</p>
</div>
<p>We are actively developing debug tools, profilers, and improving our
error and warning messages. Below is a table of the available
tools and their typical usage. For additional help see
<a class="reference external" href="#diagnosing-runtime-errors">Diagnosing Runtime Errors</a>.</p>
<div class="pst-scrollable-table-container"><table class="table" id="id1">
<caption><span class="caption-text">Title</span><a class="headerlink" href="#id1" title="Permalink to this table">#</a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Tool</p></th>
<th class="head"><p>Purpose</p></th>
<th class="head"><p>Usage</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Info logging</p></td>
<td><p>View summarized steps of compilation</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch._logging.set_logs(dynamo</span> <span class="pre">=</span> <span class="pre">logging.INFO)</span></code> or <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS=&quot;dynamo&quot;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Debug logging</p></td>
<td><p>View detailed steps of compilation (print every instruction traced)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch._logging.set_logs(dynamo</span> <span class="pre">=</span> <span class="pre">logging.DEBUG)</span></code> and
<code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.verbose</span> <span class="pre">=</span> <span class="pre">True</span></code>, or <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS=&quot;+dynamo&quot;</span> <span class="pre">TORCHDYNAMO_VERBOSE=1</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Minifier for any backend</p></td>
<td><p>Find smallest subgraph which reproduces errors for any backend</p></td>
<td><p>set environment variable <code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_AFTER=&quot;dynamo&quot;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Minifier for <code class="docutils literal notranslate"><span class="pre">TorchInductor</span></code></p></td>
<td><p>If the error is known to occur after <code class="docutils literal notranslate"><span class="pre">AOTAutograd</span></code> find
smallest subgraph which reproduces errors during <code class="docutils literal notranslate"><span class="pre">TorchInductor</span></code> lowering</p></td>
<td><p>set environment variable <code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_AFTER=&quot;aot&quot;</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Dynamo accuracy minifier</p></td>
<td><p>Finds the smallest subgraph which reproduces an accuracy issue
between an eager mode model and optimized model, when you
suspect the problem is in <code class="docutils literal notranslate"><span class="pre">AOTAutograd</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_AFTER=&quot;dynamo&quot;</span> <span class="pre">TORCHDYNAMO_REPRO_LEVEL=4</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Inductor accuracy minifier</p></td>
<td><p>Finds the smallest subgraph which reproduces an accuracy issue
between an eager mode model and optimized model, when you
suspect the problem is in the backend (e.g., inductor).
If this doesnt work, try the Dynamo accuracy minifier
instead.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_AFTER=&quot;aot&quot;</span> <span class="pre">TORCHDYNAMO_REPRO_LEVEL=4</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">torch._dynamo.explain</span></code></p></td>
<td><p>Find graph breaks and display reasoning for them</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch._dynamo.explain(fn)(*inputs)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Record/Replay</p></td>
<td><p>Record and replay frames which to reproduce errors during graph capture</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.replay_record_enabled</span> <span class="pre">=</span> <span class="pre">True</span></code></p></td>
</tr>
<tr class="row-even"><td><p>TorchDynamo function name filtering</p></td>
<td><p>Only compile functions with the given name to reduce noise when
debugging an issue</p></td>
<td><p>set environment variable <code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_DEBUG_FUNCTION=&lt;name&gt;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>TorchInductor Debug logging</p></td>
<td><p>Print general TorchInductor debug info and generated Triton/C++ code</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch._inductor.config.debug</span> <span class="pre">=</span> <span class="pre">True</span></code></p></td>
</tr>
<tr class="row-even"><td><p>TorchInductor Tracing</p></td>
<td><p>Show time taken in each TorchInductor stage + output code and graph
visualization</p></td>
<td><p>set the environment variable TORCH_COMPILE_DEBUG=1 or
<code class="docutils literal notranslate"><span class="pre">torch._inductor.config.trace.enabled</span> <span class="pre">=</span> <span class="pre">True</span></code></p></td>
</tr>
</tbody>
</table>
</div>
<p>In addition to info and debug logging,
you can use <a class="reference external" href="https://pytorch.org/docs/main/logging.html">torch._logging</a>
for more fine-grained logging.</p>
<section id="diagnosing-runtime-errors">
<h2>Diagnosing Runtime Errors<a class="headerlink" href="#diagnosing-runtime-errors" title="Permalink to this heading">#</a></h2>
<p>At a high level, the TorchDynamo stack consists of a graph capture from
Python code (TorchDynamo) and a backend compiler. For example, a
backend compiler may consist of backward graph tracing (AOTAutograd) and
graph lowering (TorchInductor)*. Errors can occur in any component of
the stack and will provide full stack traces.</p>
<p>To determine in which component an error occurred,
you may use info-level logging
<code class="docutils literal notranslate"><span class="pre">torch._logging.set_logs(dynamo</span> <span class="pre">=</span> <span class="pre">logging.INFO)</span></code> or <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS=&quot;dynamo&quot;</span></code>
and look for <code class="docutils literal notranslate"><span class="pre">Step</span> <span class="pre">#:</span> <span class="pre">...</span></code> outputs. Logs are made at the beginning and end of
each step, so the step that an error should correspond to is the most recently
logged step whose end has not yet been logged. The steps correspond to the
following parts of the stack:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head"><p>Component</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>TorchDynamo</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Compiler Backend</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>TorchInductor</p></td>
</tr>
</tbody>
</table>
</div>
<p>If info logging is insufficient, you can use available backend
options. These options include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;eager&quot;</span></code>: only runs TorchDynamo forward graph capture and then
runs the captured graph with PyTorch. This provides an indication as
to whether TorchDynamo is raising the error.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;aot_eager&quot;</span></code>: runs TorchDynamo to capture a forward graph, and
then AOTAutograd to trace the backward graph without any additional
backend compiler steps. PyTorch eager will then be used to run the
forward and backward graphs. This is useful to narrow down the issue
to AOTAutograd.</p></li>
</ul>
<p>The general procedure to narrow down an issue is the following:</p>
<ol class="arabic simple">
<li><p>Run your program with the <code class="docutils literal notranslate"><span class="pre">&quot;eager&quot;</span></code> backend. If the error no longer
occurs, the issue is in the backend compiler that is being used (if
using TorchInductor, proceed to step 2. If not, see <a class="reference external" href="#minifying-backend-compiler-errors">this
section</a>). If the error still
occurs with the <code class="docutils literal notranslate"><span class="pre">&quot;eager&quot;</span></code> backend, it is an <a class="reference external" href="#torchdynamo-errors">error while running
torchdynamo</a>.</p></li>
<li><p>This step is only necessary if <code class="docutils literal notranslate"><span class="pre">TorchInductor</span></code> is used as the backend
compiler. Run the model with the <code class="docutils literal notranslate"><span class="pre">&quot;aot_eager&quot;</span></code> backend. If this
backend raises an error then the error is occurring during
AOTAutograd tracing. If the error no longer occurs with this backend,
then <a class="reference external" href="#minifying-torchinductor-errors">the error is in
TorchInductor*</a>.</p></li>
</ol>
<p>Each of these cases are analyzed in the following sections.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The TorchInductor backend consists of
both AOTAutograd tracing and the TorchInductor compiler itself. We will
disambiguate by referring to <code class="docutils literal notranslate"><span class="pre">TorchInductor</span></code> as the backend, and
TorchInductor lowering as the phase which lowers the graph traced by
AOTAutograd.</p>
</div>
<section id="torchdynamo-errors">
<h3>Torchdynamo Errors<a class="headerlink" href="#torchdynamo-errors" title="Permalink to this heading">#</a></h3>
<p>If the error that is generated occurs with the <code class="docutils literal notranslate"><span class="pre">&quot;eager&quot;</span></code> backend, then
TorchDynamo is most likely the source of the error. Here is a sample code
which will generate an error.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch._dynamo</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dynamo</span>


<span class="k">def</span><span class="w"> </span><span class="nf">test_assertion_error</span><span class="p">():</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">{</span><span class="n">y</span><span class="p">:</span> <span class="mi">5</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">z</span>

<span class="n">compiled_test_assertion_error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">test_assertion_error</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;eager&quot;</span><span class="p">)</span>

<span class="n">compiled_test_assertion_error</span><span class="p">()</span>
</pre></div>
</div>
<p>The code above generates the following error:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">convert_frame</span><span class="p">:</span> <span class="p">[</span><span class="n">ERROR</span><span class="p">]</span> <span class="n">WON</span><span class="s1">&#39;T CONVERT test_assertion_error /scratch/mlazos/torchdynamo/../test/errors.py line 26</span>
<span class="n">due</span> <span class="n">to</span><span class="p">:</span>
<span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
  <span class="n">File</span> <span class="s2">&quot;/scratch/mlazos/torchdynamo/torchdynamo/symbolic_convert.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">837</span><span class="p">,</span> <span class="ow">in</span> <span class="n">BUILD_MAP</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">ConstantVariable</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
<span class="ne">AssertionError</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">user</span> <span class="n">code</span><span class="p">:</span>
   <span class="n">File</span> <span class="s2">&quot;/scratch/mlazos/torchdynamo/../test/errors.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">34</span><span class="p">,</span> <span class="ow">in</span> <span class="n">test_assertion_error</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">{</span><span class="n">y</span><span class="p">:</span> <span class="mi">5</span><span class="p">}</span>

<span class="n">Set</span> <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span> <span class="k">for</span> <span class="n">more</span> <span class="n">information</span>
<span class="o">==========</span>
</pre></div>
</div>
<p>As the message suggests you can set
<code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.verbose=True</span></code> to get a full stack trace to both
the error in TorchDynamo and the user code. In addition to this flag,
you can also set the <code class="docutils literal notranslate"><span class="pre">log_level</span></code> of TorchDynamo through
<code class="docutils literal notranslate"><span class="pre">torch._logging.set_logs(dynamo</span> <span class="pre">=</span> <span class="pre">logging.INFO)</span></code> or <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS=&quot;dynamo&quot;</span></code>. These levels include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">logging.DEBUG</span></code> or <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS=&quot;+dynamo&quot;</span></code>: Print every instruction that is
encountered in addition to all the log levels listed below.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logging.INFO</span></code>:
Print each function that is compiled (original and modified bytecode)
and the graph that is captured in addition to all the log levels listed below.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logging.WARNING</span></code> (default): Print graph breaks in addition to all
the log levels listed below.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logging.ERROR</span></code>: Print errors only.</p></li>
</ul>
<p>If a model is very large, the logs can become overwhelming. If
an error occurs deep within a models Python code, it can be useful to
execute only the frame in which the error occurs to enable easier
debugging. There are two tools available to enable this:</p>
<ul class="simple">
<li><p>Setting the environment variable <code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_DEBUG_FUNCTION</span></code>
to the desired function name will only run torchdynamo on functions with that
name.</p></li>
<li><p>Enabling the record/replay tool (set <code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.replay_record_enabled</span> <span class="pre">=</span> <span class="pre">True</span></code>)
which dumps an execution record when an error is encountered. This record can
then be replayed to run only the frame where an error occurred.</p></li>
</ul>
</section>
<section id="diagnosing-torchinductor-errors">
<h3>Diagnosing TorchInductor Errors<a class="headerlink" href="#diagnosing-torchinductor-errors" title="Permalink to this heading">#</a></h3>
<p>If the error does not occur with the <code class="docutils literal notranslate"><span class="pre">&quot;eager&quot;</span></code> backend, then the
backend compiler is the source of the error (<a class="reference external" href="https://gist.github.com/mlazos/2f13681e3cc6c43b3911f336327032de%5D">example
error</a>).
There are <a class="reference external" href="./torch.compiler.rst">different choices</a>
for backend compilers for TorchDynamo, with TorchInductor
fitting the needs of most users. This section focuses on TorchInductor
as the motivating example, but some tools can also be used with other
backend compilers.</p>
<p>Below is the portion of the stack which we are focusing on:</p>
<p>With TorchInductor as the chosen backend, AOTAutograd is used to
generate the backward graph from the forward graph captured by
torchdynamo. It is important to note that errors can occur during this
tracing and also while TorchInductor lowers the forward and backward
graphs to GPU code or C++. A model can often consist of hundreds or
thousands of FX nodes, so narrowing the exact nodes where this problem
occurred can be very difficult. Fortunately, there are tools available to
automatically minify these input graphs to the nodes which are causing
the issue. The first step is to determine whether the error occurs
during tracing of the backward graph with AOTAutograd or during
TorchInductor lowering. As mentioned above in step 2, the
<code class="docutils literal notranslate"><span class="pre">&quot;aot_eager&quot;</span></code> backend can be used to run only AOTAutograd in isolation
without lowering. If the error still occurs with this backend, this
indicates that the error is occurring during AOTAutograd tracing.</p>
<p>Here is an example:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch._dynamo</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dynamo</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_backend_error</span><span class="p">():</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">_foobar</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>  <span class="c1"># dummy function which errors</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>


<span class="n">compiled_test_backend_error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">test_backend_error</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;inductor&quot;</span><span class="p">)</span>
<span class="n">compiled_test_backend_error</span><span class="p">()</span>
</pre></div>
</div>
<p>Running this should give you this error with a longer stack trace below
it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
  <span class="n">File</span> <span class="s2">&quot;/scratch/mlazos/torchdynamo/torchinductor/graph.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">246</span><span class="p">,</span> <span class="ow">in</span> <span class="n">call_function</span>
    <span class="k">return</span> <span class="n">lowerings</span><span class="p">[</span><span class="n">target</span><span class="p">](</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="n">File</span> <span class="s2">&quot;/scratch/mlazos/torchdynamo/torchinductor/lowering.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">185</span><span class="p">,</span> <span class="ow">in</span> <span class="n">wrapped</span>
    <span class="k">return</span> <span class="n">decomp_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="n">File</span> <span class="s2">&quot;/scratch/mlazos/torchdynamo/torchinductor/lowering.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">810</span><span class="p">,</span> <span class="ow">in</span> <span class="n">_foobar</span>
    <span class="k">assert</span> <span class="kc">False</span>
<span class="ne">AssertionError</span>
<span class="o">...</span>
</pre></div>
</div>
<p><a class="reference external" href="https://gist.github.com/mlazos/d6947854aa56d686800259a164c62100">error with full stack
trace</a></p>
<p>If you then change <code class="docutils literal notranslate"><span class="pre">torch.compile(backend=&quot;inductor&quot;)</span></code> to
<code class="docutils literal notranslate"><span class="pre">torch.compile(backend=&quot;aot_eager&quot;)</span></code>, it will run without error, because
<a class="reference external" href="https://github.com/pytorch/torchdynamo/blob/d09e50fbee388d466b5252a63045643166006f77/torchinductor/lowering.py#:~:text=%23%20This%20shouldn%27t%20be,assert%20False">the
issue</a>
is in the TorchInductor lowering process, not in AOTAutograd.</p>
</section>
<section id="minifying-torchinductor-errors">
<h3>Minifying TorchInductor Errors<a class="headerlink" href="#minifying-torchinductor-errors" title="Permalink to this heading">#</a></h3>
<p>From here, lets run the minifier to get a minimal repro. Setting the
environment variable <code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_AFTER=&quot;aot&quot;</span></code> (or setting
<code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.repro_after=&quot;aot&quot;</span></code> directly) will generate a
Python program which reduces the graph produced by AOTAutograd to the
smallest subgraph which reproduces the error. (See below for an example
where we minify the graph produced by TorchDynamo) Running the program
with this environment variable should show nearly <a class="reference external" href="https://gist.github.com/mlazos/0458ab828aa403c779fe73c012aa5982">identical
output</a>,
with an additional line indicating where <code class="docutils literal notranslate"><span class="pre">minifier_launcher.py</span></code> has
been written to. The output directory is configurable by setting
<code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.base_dir</span></code> to a valid directory name. The final
step is to run the minifier and check that it runs successfully. A
successful run looks like
<a class="reference external" href="https://gist.github.com/mlazos/e6ea41ccce68a7b1b8a7a09acb1b206a">this</a>.
If the minifier runs successfully, it generates runnable python code
which reproduces the exact error. For our example this is the following
code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">device</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.fx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">fx</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._dynamo.testing</span><span class="w"> </span><span class="kn">import</span> <span class="n">rand_strided</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">inf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.fx.experimental.proxy_tensor</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_fx</span>

<span class="c1"># torch version: 1.13.0a0+gitfddfc44</span>
<span class="c1"># torch cuda version: 11.6</span>
<span class="c1"># torch git version: fddfc4488afb207971c54ad4bf58130fdc8a4dc5</span>


<span class="c1"># CUDA Info:</span>
<span class="c1"># nvcc: NVIDIA (R) Cuda compiler driver</span>
<span class="c1"># Copyright (c) 2005-2022 NVIDIA Corporation</span>
<span class="c1"># Built on Thu_Feb_10_18:23:41_PST_2022</span>
<span class="c1"># Cuda compilation tools, release 11.6, V11.6.112</span>
<span class="c1"># Build cuda_11.6.r11.6/compiler.30978841_0</span>

<span class="c1"># GPU Hardware Info:</span>
<span class="c1"># NVIDIA A100-SXM4-40GB : 8</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Repro</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">add</span><span class="p">):</span>
        <span class="n">_foobar</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">_foobar</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">add</span><span class="p">);</span>  <span class="n">add</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">_foobar</span><span class="p">,)</span>

<span class="n">args</span> <span class="o">=</span> <span class="p">[((</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)]</span>
<span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">rand_strided</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">device</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">make_fx</span><span class="p">(</span><span class="n">Repro</span><span class="p">())(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._inductor.compile_fx</span><span class="w"> </span><span class="kn">import</span> <span class="n">compile_fx_inner</span>

<span class="n">compiled</span> <span class="o">=</span> <span class="n">compile_fx_inner</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
<span class="n">compiled</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of the <code class="docutils literal notranslate"><span class="pre">Repro</span></code> module contains the exact op
which causes the issue. When filing an issue, please include any
minified repros to aid in debugging.</p>
</section>
<section id="minifying-backend-compiler-errors">
<h3>Minifying Backend Compiler Errors<a class="headerlink" href="#minifying-backend-compiler-errors" title="Permalink to this heading">#</a></h3>
<p>With backend compilers other than TorchInductor the process for finding
the subgraph causing the error is nearly identical to the procedure in
<a class="reference external" href="#torchinductor-errors">errors in TorchInductor</a> with one important
caveat. Namely, that the minifier will now be run on the graph that is
traced by TorchDynamo, not the output graph of AOTAutograd. Lets walk
through an example.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch._dynamo</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dynamo</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
<span class="c1"># toy compiler which fails if graph contains relu</span>
<span class="k">def</span><span class="w"> </span><span class="nf">toy_compiler</span><span class="p">(</span><span class="n">gm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">:</span>
            <span class="k">assert</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">gm</span>


<span class="k">def</span><span class="w"> </span><span class="nf">test_backend_error</span><span class="p">():</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>


<span class="n">compiled_test_backend_error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">test_backend_error</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">toy_compiler</span><span class="p">)</span>
<span class="n">compiled_test_backend_error</span><span class="p">()</span>
</pre></div>
</div>
<p>In order to run the code after TorchDynamo has traced the forward graph,
you can use the <code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_AFTER</span></code> environment variable. Running
this program with <code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_AFTER=&quot;dynamo&quot;</span></code> (or
<code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.repro_after=&quot;dynamo&quot;</span></code>) should produce <a class="reference external" href="https://gist.github.com/mlazos/244e3d5b53667e44078e194762c0c92b">this
output</a>and
the following code in <code class="docutils literal notranslate"><span class="pre">{torch._dynamo.config.base_dir}/repro.py</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The other option for TORCHDYNAMO_REPRO_AFTER is <code class="docutils literal notranslate"><span class="pre">&quot;aot&quot;</span></code>, which
will run the minifier after the backward graph has been generated.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch._dynamo</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dynamo</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">device</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.fx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">fx</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._dynamo.testing</span><span class="w"> </span><span class="kn">import</span> <span class="n">rand_strided</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">inf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._dynamo.debug_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">run_fwd_maybe_bwd</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Repro</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">add</span><span class="p">):</span>
        <span class="n">relu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">add</span><span class="p">);</span>  <span class="n">add</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">relu</span><span class="p">,)</span>


<span class="n">mod</span> <span class="o">=</span> <span class="n">Repro</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">opt_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">)</span>


<span class="n">args</span> <span class="o">=</span> <span class="p">[((</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)]</span>
<span class="n">args</span> <span class="o">=</span> <span class="p">[</span><span class="n">rand_strided</span><span class="p">(</span><span class="n">sh</span><span class="p">,</span> <span class="n">st</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">dev</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="n">rg</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">sh</span><span class="p">,</span> <span class="n">st</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">dev</span><span class="p">,</span> <span class="n">rg</span><span class="p">)</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>


<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">ref</span> <span class="o">=</span> <span class="n">run_fwd_maybe_bwd</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">run_fwd_maybe_bwd</span><span class="p">(</span><span class="n">opt_mod</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
<p>The minifier successfully reduced the graph to the op that raises the
error in <code class="docutils literal notranslate"><span class="pre">toy_compiler</span></code>. The other difference from the procedure in
<a class="reference external" href="#torchinductor-errors">TorchInductor Errors</a> is that the minifier is
automatically run after encountering a backend compiler error. After a
successful run, the minifier writes <code class="docutils literal notranslate"><span class="pre">repro.py</span></code> to
<code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.base_dir</span></code>.</p>
</section>
</section>
<section id="performance-profiling">
<h2>Performance Profiling<a class="headerlink" href="#performance-profiling" title="Permalink to this heading">#</a></h2>
<section id="accessing-torchdynamo-profiler">
<h3>Accessing TorchDynamo Profiler<a class="headerlink" href="#accessing-torchdynamo-profiler" title="Permalink to this heading">#</a></h3>
<p>TorchDynamo has a built-in stats function for collecting and displaying
the time spent in each compilation phase. These stats can be accessed by
calling <code class="docutils literal notranslate"><span class="pre">torch._dynamo.utils.compile_times()</span></code> after executing
Torch._Dynamo. By default, this returns a string representation of the
compile times spent in each TorchDynamo function by name.</p>
</section>
<section id="torchinductor-debugging-using-torch-compile-debug">
<h3>TorchInductor Debugging using TORCH_COMPILE_DEBUG<a class="headerlink" href="#torchinductor-debugging-using-torch-compile-debug" title="Permalink to this heading">#</a></h3>
<p>TorchInductor has a builtin stats and trace function for displaying time
spent in each compilation phase, output code, output graph visualization
and IR dump. This is a debugging tool designed to make it easier to
understand and troubleshoot the internals of TorchInductor.</p>
<p>Lets run an example with the following test program (<code class="docutils literal notranslate"><span class="pre">repro.py</span></code>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_model</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="n">y</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<p>Setting the environment variable <code class="docutils literal notranslate"><span class="pre">TORCH_COMPILE_DEBUG=1</span></code> will cause a
debug trace directory to be created, by default this directory will be in the
current directory and named torch_compile_debug (this can be overridden in
the torchdynamo configuration field <code class="docutils literal notranslate"><span class="pre">debug_dir_root</span></code> and also the
<code class="docutils literal notranslate"><span class="pre">env</span> <span class="pre">var</span> <span class="pre">TORCH_COMPILE_DEBUG_DIR</span></code>). Inside this directory, each run will
have a separate folder named with the timestamp and process id of the run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ env TORCH_COMPILE_DEBUG=1 python repro.py
$ cd torch_compile_debug
$ ls
run_2023_03_01_08_20_52_143510-pid_180167
</pre></div>
</div>
<p>In the run folder there will be a <code class="docutils literal notranslate"><span class="pre">torchdynamo</span></code> directory which contains
debug logs, and an <code class="docutils literal notranslate"><span class="pre">torchinductor</span></code> folder which contains a subfolder for each
compiled kernel with inductor debug artifacts.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cd
run_2023_03_01_08_20_52_143510-pid_180167
$ ls
torchinductor  torchdynamo
</pre></div>
</div>
<p>Moving further into the <code class="docutils literal notranslate"><span class="pre">torchinductor</span></code> directory, the <code class="docutils literal notranslate"><span class="pre">\*.log</span></code> files are
logs from the AOT Autograd phase of compilation, <code class="docutils literal notranslate"><span class="pre">model__0_forward_1.0</span></code> contains
the inductor debug artifacts.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cd torchinductor
$ ls
aot_model___0_debug.log  model__0_forward_1.0
$ cd model__0_forward_1.0
$ ls
debug.log  fx_graph_readable.py  fx_graph_runnable.py  fx_graph_transformed.py  ir_post_fusion.txt  ir_pre_fusion.txt  output_code.py
</pre></div>
</div>
<p>Here is a summary of the contents:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fx_graph_readable.py</span></code> and <code class="docutils literal notranslate"><span class="pre">fx_graph_runnable.py</span></code> are the readable and
runnable versions of the <code class="docutils literal notranslate"><span class="pre">fx_graph</span></code> received by inductor.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fx_graph_transformed.py</span></code> is the fx graph after inductor has run all fx passes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ir\*.txt</span></code> is the inductor ir pre and post fusion.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">output_code.py</span></code> is the compiled triton kernel for the subgraph.</p></li>
</ul>
<p>Here are <a class="reference external" href="https://gist.github.com/jansel/f4af078791ad681a0d4094adeb844396">example debug directory contents</a>
for the test program:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_model</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="n">y</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<p>Each file in that debug trace can be enabled and disabled through
<code class="docutils literal notranslate"><span class="pre">torch._inductor.config.trace.*</span></code>. The profile and the diagram are both
disabled by default since they are expensive to generate.</p>
<p>A single node in this new debug format looks like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">buf1</span><span class="p">:</span> <span class="n">SchedulerNode</span><span class="p">(</span><span class="n">ComputedBuffer</span><span class="p">)</span>
<span class="n">buf1</span><span class="o">.</span><span class="n">writes</span> <span class="o">=</span>
    <span class="p">{</span>   <span class="n">MemoryDep</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;buf1&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">()),</span>
        <span class="n">MemoryDep</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;buf1&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">s0</span><span class="p">,))}</span>
<span class="n">buf1</span><span class="o">.</span><span class="n">unmet_dependencies</span> <span class="o">=</span> <span class="p">{</span><span class="n">MemoryDep</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;buf0&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">c0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">s0</span><span class="p">,))}</span>
<span class="n">buf1</span><span class="o">.</span><span class="n">met_dependencies</span> <span class="o">=</span> <span class="p">{</span><span class="n">MemoryDep</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;primals_2&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">c0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">s0</span><span class="p">,))}</span>
<span class="n">buf1</span><span class="o">.</span><span class="n">group</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">cuda</span><span class="p">:</span><span class="mi">0</span>
<span class="n">buf1</span><span class="o">.</span><span class="n">group</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">s0</span><span class="p">)</span>
<span class="n">buf1</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[</span><span class="n">s0</span><span class="p">])</span>
<span class="k">class</span><span class="w"> </span><span class="nc">buf1_loop_body</span><span class="p">:</span>
    <span class="n">var_ranges</span> <span class="o">=</span> <span class="p">{</span><span class="n">z0</span><span class="p">:</span> <span class="n">s0</span><span class="p">}</span>
    <span class="n">index0</span> <span class="o">=</span> <span class="n">z0</span>
    <span class="n">index1</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">body</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ops</span><span class="p">):</span>
        <span class="n">get_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s1">&#39;index0&#39;</span><span class="p">)</span>
        <span class="n">load</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;buf0&#39;</span><span class="p">,</span> <span class="n">get_index</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">get_index_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s1">&#39;index0&#39;</span><span class="p">)</span>
        <span class="n">load_1</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;primals_2&#39;</span><span class="p">,</span> <span class="n">get_index_1</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">load</span><span class="p">,</span> <span class="n">load_1</span><span class="p">)</span>
        <span class="n">get_index_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_index</span><span class="p">(</span><span class="s1">&#39;index1&#39;</span><span class="p">)</span>
        <span class="n">reduction</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">reduction</span><span class="p">(</span><span class="s1">&#39;buf1&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="n">get_index_2</span><span class="p">,</span> <span class="n">add</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">reduction</span>
</pre></div>
</div>
<p>See the <a class="reference external" href="https://gist.github.com/jansel/f4af078791ad681a0d4094adeb844396">example debug directory
output</a>
for more examples.</p>
</section>
<section id="graph-breaks">
<h3>Graph Breaks<a class="headerlink" href="#graph-breaks" title="Permalink to this heading">#</a></h3>
<p>Given a program like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">some_fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="o">...</span>

<span class="n">compiled_fun</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">some_fun</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
<p>TorchDynamo will attempt to compile all of the torch/tensor operations
within some_fun into a single FX graph, but it may fail to capture
everything into one graph.</p>
<p>Some graph break reasons are insurmountable to TorchDynamo, and cant be
easily fixed. - calling into a C extension other than torch is invisible
to torchdynamo, and could do arbitrary things without TorchDynamo being
able to introduce necessary guards (see <a class="reference internal" href="torch.compiler_dynamo_deepdive.html#making-dynamo-sound-guards"><span class="std std-ref">Making Dynamo Sound: Guards</span></a>)
to ensure that the compiled program would be safe to reuse. Graph breaks
can hinder performance if the resulting fragments are small. To maximize
performance, its important to have as few graph breaks as possible.</p>
</section>
</section>
<section id="identifying-the-cause-of-a-graph-break">
<h2>Identifying the Cause of a Graph Break<a class="headerlink" href="#identifying-the-cause-of-a-graph-break" title="Permalink to this heading">#</a></h2>
<p>To identify all graph breaks in a program and the associated reasons for
the breaks, <code class="docutils literal notranslate"><span class="pre">torch._dynamo.explain</span></code> can be used. This tool runs
TorchDynamo on the supplied function and aggregates the graph breaks
that are encountered. Here is an example usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch._dynamo</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dynamo</span>
<span class="k">def</span><span class="w"> </span><span class="nf">toy_example</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;woo&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">b</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">dynamo</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">toy_example</span><span class="p">)(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">explanation_verbose</span><span class="p">)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Graph Count: 3</span>
<span class="sd">Graph Break Count: 2</span>
<span class="sd">Op Count: 5</span>
<span class="sd">Break Reasons:</span>
<span class="sd">  Break Reason 1:</span>
<span class="sd">    Reason: builtin: print [&lt;class &#39;torch._dynamo.variables.constant.ConstantVariable&#39;&gt;] False</span>
<span class="sd">    User Stack:</span>
<span class="sd">      &lt;FrameSummary file foo.py, line 5 in toy_example&gt;</span>
<span class="sd">  Break Reason 2:</span>
<span class="sd">    Reason: generic_jump TensorVariable()</span>
<span class="sd">    User Stack:</span>
<span class="sd">      &lt;FrameSummary file foo.py, line 6 in torch_dynamo_resume_in_toy_example_at_5&gt;</span>
<span class="sd">Ops per Graph:</span>
<span class="sd">  ...</span>
<span class="sd">Out Guards:</span>
<span class="sd">  ...</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>Outputs include:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">out_guards</span></code> - a list of lists where each sublist contains the guards that must pass to ensure the traced graphs are valid.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">graphs</span></code> - a list of graph modules which were successfully traced.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ops_per_graph</span></code> - a list of lists where each sublist contains the ops that are run in the graph.</p></li>
</ul>
<p>To throw an error on the first graph break encountered, use the <code class="docutils literal notranslate"><span class="pre">fullgraph</span></code>
mode. This mode disables TorchDynamos Python fallback, and only
succeeds if the entire program is convertible into a single graph. Example
usage:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">toy_example</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
   <span class="o">...</span>

<span class="n">compiled_toy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">toy_example</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">backend</span><span class="o">=&lt;</span><span class="n">compiler</span><span class="o">&gt;</span><span class="p">)(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<section id="excessive-recompilation">
<h3>Excessive Recompilation<a class="headerlink" href="#excessive-recompilation" title="Permalink to this heading">#</a></h3>
<p>When TorchDynamo compiles a function (or part of one), it makes certain
assumptions about locals and globals in order to allow compiler
optimizations, and expresses these assumptions as guards that check
particular values at runtime. If any of these guards fail, Dynamo will
recompile that function (or part) up to
<code class="docutils literal notranslate"><span class="pre">torch._dynamo.config.recompile_limit</span></code> times. If your program is
hitting the cache limit, you will first need to determine which guard is
failing and what part of your program is triggering it.</p>
<p>If your program exhibits a bounded amount of dynamism, you may be able
to tune the TorchDynamo cache limit to allow for each variation to be
compiled and cached, but if the cache limit is too high you may find the
cost of recompilation outweighs any optimization benefits.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">recompile_limit</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">your</span> <span class="n">desired</span> <span class="n">cache</span> <span class="n">limit</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>TorchDynamo plans to support many common cases of dynamic tensor shapes,
such as varying batch size or sequence length. It does not plan to
support rank-dynamism. In the meantime, setting a specific cache limit
can be used in coordination with bucketing techniques to achieve an
acceptable number of recompilations for some dynamic models.</p>
</section>
</section>
<section id="accuracy-debugging">
<h2>Accuracy Debugging<a class="headerlink" href="#accuracy-debugging" title="Permalink to this heading">#</a></h2>
<p>Accuracy issues can also be minified if you set the environment variable
<code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_LEVEL=4</span></code>, it operates with a similar git bisect
model and a full repro might be something like
<code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_REPRO_AFTER=&quot;aot&quot;</span> <span class="pre">TORCHDYNAMO_REPRO_LEVEL=4</span></code> the reason
we need this is downstream compilers will codegen code whether its
Triton code or the C++ backend, the numerics from those downstream
compilers can be different in subtle ways yet have dramatic impact on
your training stability. So the accuracy debugger is very useful for us
to detect bugs in our codegen or with a backend compiler.</p>
<p>If youd like to ensure that random number generation is the same across both torch
and triton then you can enable <code class="docutils literal notranslate"><span class="pre">torch._inductor.config.fallback_random</span> <span class="pre">=</span> <span class="pre">True</span></code></p>
</section>
<section id="extended-debugging">
<h2>Extended Debugging<a class="headerlink" href="#extended-debugging" title="Permalink to this heading">#</a></h2>
<p>Extended debugging can be enabled by using the following experimental flags.</p>
<p><code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED</span></code> - provides extended debug information if the
string representation of a guard matches this flag value. For example, set it to
Ne(s0, 10) to generate full Python and C++ backtrace whenever guard was issued.
<code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL</span></code> - provides extended debug information when
a particular symbol is allocated. For example, set this to u2 to generate full Python
and C++ backtrace whenever this symbol was created.
<code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_EXTENDED_DEBUG_CPP</span></code> - provides extended debug information (C++ backtrace)
for all extended debug settings as well as errors. For example, set this to 1. The C++
backtrace is slow and very spammy so it is not included by default with extended debugging.</p>
</section>
<section id="cold-start-timing-and-cache-corruption-debugging">
<h2>Cold Start Timing and Cache Corruption Debugging<a class="headerlink" href="#cold-start-timing-and-cache-corruption-debugging" title="Permalink to this heading">#</a></h2>
<p>In order to measure the cold start compilation time or debug a cache corruption,
it is possible pass <code class="docutils literal notranslate"><span class="pre">TORCHINDUCTOR_FORCE_DISABLE_CACHES=1</span></code> or set
<code class="docutils literal notranslate"><span class="pre">torch._inductor.config.force_disable_caches</span> <span class="pre">=</span> <span class="pre">True</span></code> which will override any
other caching config option and disable all compile time caching.</p>
</section>
</section>


  </article>

              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4"></span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5"></span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip">Send Feedback
    </button>
  </div>
</div>


<div class="prev-next-area">
</div>

<div class="footer-info">
  <p class="copyright">
    
      
         Copyright PyTorch Contributors.
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div></div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diagnosing-runtime-errors">Diagnosing Runtime Errors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchdynamo-errors">Torchdynamo Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diagnosing-torchinductor-errors">Diagnosing TorchInductor Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minifying-torchinductor-errors">Minifying TorchInductor Errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#minifying-backend-compiler-errors">Minifying Backend Compiler Errors</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-profiling">Performance Profiling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accessing-torchdynamo-profiler">Accessing TorchDynamo Profiler</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torchinductor-debugging-using-torch-compile-debug">TorchInductor Debugging using TORCH_COMPILE_DEBUG</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-breaks">Graph Breaks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifying-the-cause-of-a-graph-break">Identifying the Cause of a Graph Break</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#excessive-recompilation">Excessive Recompilation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-debugging">Accuracy Debugging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extended-debugging">Extended Debugging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cold-start-timing-and-cache-corruption-debugging">Cold Start Timing and Cache Corruption Debugging</a></li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pytorch/pytorch/edit/main/docs/cpp/source/torch.compiler_troubleshooting_old.rst">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="_sources/torch.compiler_troubleshooting_old.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    


<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Community</div>
  <ul style="list-style-type: none; padding: 0;">
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/docs/stable/community/index.html" style="color: var(--pst-color-text-muted)">PyTorch Governance</a></li>
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/docs/stable/community/design.html" style="color: var(--pst-color-text-muted)">PyTorch Design Philosophy</a></li>
  
   <li><a class="nav-link nav-external" href="https://github.com/pytorch/pytorch/wiki/The-Ultimate-Guide-to-PyTorch-Contributions" style="color: var(--pst-color-text-muted)">The Ultimate Guide to PyTorch Contributions</a></li>
  
  </ul>
</div>


<div class="sidebar-secondary-item">
 <div class="sidebar-heading">Language Bindings</div>
 <ul style="list-style-type: none; padding: 0;">
 
  <li><a class="nav-link nav-external" href="https://pytorch.org/docs/stable/cpp_index.html" style="color: var(--pst-color-text-muted)">C++</a></li>
 
  <li><a class="nav-link nav-external" href="https://pytorch.org/javadoc/" style="color: var(--pst-color-text-muted)">Javadoc</a></li>
 
  <li><a class="nav-link nav-external" href="https://github.com/pytorch/multipy" style="color: var(--pst-color-text-muted)">torch.multiply</a></li>
 
 </ul>
</div>


<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/audio/stable/" style="color: var(--pst-color-text-muted)">torchaudio</a></li>
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/serve/" style="color: var(--pst-color-text-muted)">torchserve</a></li>
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/data" style="color: var(--pst-color-text-muted)">torchdata</a></li>
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/data" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

   <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
      <div class="container">
        <div class="row">
          <div class="col-md-4 text-center">
            <h2>Docs</h2>
            <p>Access comprehensive developer documentation for PyTorch</p>
            <a class="with-right-arrow" href="">View Docs</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Tutorials</h2>
            <p>Get in-depth tutorials for beginners and advanced developers</p>
            <a class="with-right-arrow" href="">View Tutorials</a>
          </div>

          <div class="col-md-4 text-center">
            <h2>Resources</h2>
            <p>Find development resources and get your questions answered</p>
            <a class="with-right-arrow" href="">View Resources</a>
          </div>
        </div>
      </div>
  </div>

  <footer class="site-footer">
      <div class="container footer-container">
        <div class="footer-logo-wrapper">
          <a href="" class="footer-logo"></a>
        </div>

        <div class="footer-links-wrapper">
          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">PyTorch</a></li>
              <li><a href="">Get Started</a></li>
              <li><a href="">Features</a></li>
              <li><a href="">Ecosystem</a></li>
              <li><a href="">Blog</a></li>
              <li><a href="">Contributing</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title"><a href="">Resources</a></li>
              <li><a href="">Tutorials</a></li>
              <li><a href="">Docs</a></li>
              <li><a href="" target="_blank">Discuss</a></li>
              <li><a href="" target="_blank">Github Issues</a></li>
              <li><a href="" target="_blank">Brand Guidelines</a></li>
            </ul>
          </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">Stay up to date</li>
              <li><a href="" target="_blank">Facebook</a></li>
              <li><a href="" target="_blank">Twitter</a></li>
              <li><a href="" target="_blank">YouTube</a></li>
              <li><a href="" target="_blank">LinkedIn</a></li>
            </ul>
            </div>

          <div class="footer-links-col">
            <ul>
              <li class="list-title">PyTorch Podcasts</li>
              <li><a href="" target="_blank">Spotify</a></li>
              <li><a href="" target="_blank">Apple</a></li>
              <li><a href="" target="_blank">Google</a></li>
              <li><a href="" target="_blank">Amazon</a></li>
            </ul>
           </div>
          </div>

          <div class="privacy-policy">
            <ul>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
              <li class="privacy-policy-links">|</li>
              <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
            </ul>
          </div>
          <div class="copyright">
          <p> Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
            For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
            <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
            project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
            please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
        </div>
       </div>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/img/pytorch-x.svg">
  </div>
</div>
 </footer>
   
  <footer class="bd-footer"><div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/img/pytorch-x.svg">
  </div>
</div>
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>

  </body>
</html>